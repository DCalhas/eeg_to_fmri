Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(21, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(42, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(63, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(84, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(105, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(126, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(147, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(168, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(189, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(210, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(21, 2607, 16)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-12-13 14:07:20.856828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-12-13 14:07:20.860858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-12-13 14:07:20.861027: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-13 14:07:20.862299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-12-13 14:07:20.863584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-12-13 14:07:20.863819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-12-13 14:07:20.864975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-12-13 14:07:20.865597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-12-13 14:07:20.868480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-13 14:07:20.870044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-12-13 14:07:20.870271: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-12-13 14:07:20.891780: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-12-13 14:07:20.892328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e2088a0190 executing computations on platform Host. Devices:
2019-12-13 14:07:20.892352: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-13 14:07:20.893006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-12-13 14:07:20.893035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-13 14:07:20.893043: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-12-13 14:07:20.893051: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-12-13 14:07:20.893058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-12-13 14:07:20.893065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-12-13 14:07:20.893073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-12-13 14:07:20.893081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-13 14:07:20.894177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-12-13 14:07:20.894208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-13 14:07:20.952669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-13 14:07:20.952707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-12-13 14:07:20.952716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-12-13 14:07:20.954453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-12-13 14:07:20.955677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e209c3ad70 executing computations on platform CUDA. Devices:
2019-12-13 14:07:20.955696: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-12-13 14:07:21.383961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(42, 2607, 16)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 95, 16, 16, 1)     257       
_________________________________________________________________
reshape (Reshape)            (None, 1520, 16, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1520, 16, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 16, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.029110009  || Decoder Loss:  0.0057251677 Validation Decoder Loss:  0.39515054
Encoder Loss:  0.028683783  || Decoder Loss:  0.0057311133 Validation Decoder Loss:  0.39509207
Encoder Loss:  0.028278045  || Decoder Loss:  0.0057568527 Validation Decoder Loss:  0.39484757
Encoder Loss:  0.027876679  || Decoder Loss:  0.0057578036 Validation Decoder Loss:  0.39416632
Encoder Loss:  0.027454339  || Decoder Loss:  0.005711216 Validation Decoder Loss:  0.39379352
Encoder Loss:  0.02706553  || Decoder Loss:  0.0056853364 Validation Decoder Loss:  0.39339873
Encoder Loss:  0.026695607  || Decoder Loss:  0.00564569 Validation Decoder Loss:  0.39310476
Encoder Loss:  0.026321508  || Decoder Loss:  0.0055845813 Validation Decoder Loss:  0.3929626
Encoder Loss:  0.02597333  || Decoder Loss:  0.0055278735 Validation Decoder Loss:  0.39287814
Encoder Loss:  0.025654912  || Decoder Loss:  0.005461166 Validation Decoder Loss:  0.39247948
Encoder Loss:  0.025343321  || Decoder Loss:  0.0053968704 Validation Decoder Loss:  0.39216006
Encoder Loss:  0.025031552  || Decoder Loss:  0.005326403 Validation Decoder Loss:  0.39197734
Encoder Loss:  0.024737448  || Decoder Loss:  0.0052655754 Validation Decoder Loss:  0.3919973
Encoder Loss:  0.02446382  || Decoder Loss:  0.005216016 Validation Decoder Loss:  0.39212453
Encoder Loss:  0.02420354  || Decoder Loss:  0.0051676687 Validation Decoder Loss:  0.39232504
Encoder Loss:  0.023961524  || Decoder Loss:  0.005116692 Validation Decoder Loss:  0.39254826
Encoder Loss:  0.02375298  || Decoder Loss:  0.0050798594 Validation Decoder Loss:  0.39271855
Encoder Loss:  0.023565719  || Decoder Loss:  0.005052351 Validation Decoder Loss:  0.39273676
Encoder Loss:  0.023402585  || Decoder Loss:  0.0050463956 Validation Decoder Loss:  0.39313498
Encoder Loss:  0.023228265  || Decoder Loss:  0.005017973 Validation Decoder Loss:  0.39348704
Encoder Loss:  0.023048304  || Decoder Loss:  0.004980011 Validation Decoder Loss:  0.3937665
Encoder Loss:  0.022891011  || Decoder Loss:  0.004969128 Validation Decoder Loss:  0.39393425
Encoder Loss:  0.02274013  || Decoder Loss:  0.0049593966 Validation Decoder Loss:  0.39403316
Encoder Loss:  0.022591058  || Decoder Loss:  0.004949982 Validation Decoder Loss:  0.39414352
Encoder Loss:  0.02243903  || Decoder Loss:  0.00492944 Validation Decoder Loss:  0.39440566
Encoder Loss:  0.02229461  || Decoder Loss:  0.004906101 Validation Decoder Loss:  0.39473566
Encoder Loss:  0.022165854  || Decoder Loss:  0.004890171 Validation Decoder Loss:  0.39513344
Encoder Loss:  0.02204162  || Decoder Loss:  0.004868852 Validation Decoder Loss:  0.39558873
Encoder Loss:  0.021922665  || Decoder Loss:  0.0048486707 Validation Decoder Loss:  0.3961511
Encoder Loss:  0.021803634  || Decoder Loss:  0.004827476 Validation Decoder Loss:  0.39664575
Encoder Loss:  0.021690274  || Decoder Loss:  0.004808286 Validation Decoder Loss:  0.39710182
Encoder Loss:  0.021577843  || Decoder Loss:  0.004786692 Validation Decoder Loss:  0.39750555
Encoder Loss:  0.021484205  || Decoder Loss:  0.004783893 Validation Decoder Loss:  0.39782923
Encoder Loss:  0.021398703  || Decoder Loss:  0.004790586 Validation Decoder Loss:  0.3981017
Encoder Loss:  0.021319753  || Decoder Loss:  0.004805057 Validation Decoder Loss:  0.39816922
Encoder Loss:  0.021237161  || Decoder Loss:  0.0048031276 Validation Decoder Loss:  0.39811945
Encoder Loss:  0.021155838  || Decoder Loss:  0.0047961683 Validation Decoder Loss:  0.3980529
Encoder Loss:  0.021077558  || Decoder Loss:  0.0047886726 Validation Decoder Loss:  0.3978706
Encoder Loss:  0.020997206  || Decoder Loss:  0.004774214 Validation Decoder Loss:  0.3976225
Encoder Loss:  0.020922236  || Decoder Loss:  0.004764354 Validation Decoder Loss:  0.39727432
Model: bold_synthesis_net_lr_7.338636405723086e-05 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.39727432
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 92, 10, 16, 1)     59        
_________________________________________________________________
reshape_1 (Reshape)          (None, 920, 16, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 920, 16, 1)        1689      
=================================================================
Total params: 1,689
Trainable params: 1,689
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 16, 1)       1689      
=================================================================
Total params: 1,689
Trainable params: 1,689
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.017377857  || Decoder Loss:  0.0041187997 Validation Decoder Loss:  0.43000633
Encoder Loss:  0.013173329  || Decoder Loss:  0.0042196107 Validation Decoder Loss:  0.42576513
Encoder Loss:  0.011964537  || Decoder Loss:  0.0042530806 Validation Decoder Loss:  0.42537475
Encoder Loss:  0.011763659  || Decoder Loss:  0.004201208 Validation Decoder Loss:  0.4254836
Encoder Loss:  0.011607122  || Decoder Loss:  0.0041369703 Validation Decoder Loss:  0.42547718
Encoder Loss:  0.011454378  || Decoder Loss:  0.0040552528 Validation Decoder Loss:  0.4255684
Encoder Loss:  0.011335323  || Decoder Loss:  0.0040130145 Validation Decoder Loss:  0.42592552
Encoder Loss:  0.011221936  || Decoder Loss:  0.003963862 Validation Decoder Loss:  0.4260642
Encoder Loss:  0.011093865  || Decoder Loss:  0.0038936157 Validation Decoder Loss:  0.42639363
Encoder Loss:  0.01095685  || Decoder Loss:  0.0038002646 Validation Decoder Loss:  0.4266261
Encoder Loss:  0.0108389435  || Decoder Loss:  0.0037199336 Validation Decoder Loss:  0.4268425
Encoder Loss:  0.010748609  || Decoder Loss:  0.0036667981 Validation Decoder Loss:  0.4266896
Encoder Loss:  0.010653026  || Decoder Loss:  0.0036013457 Validation Decoder Loss:  0.4266792
Encoder Loss:  0.0105672665  || Decoder Loss:  0.003542783 Validation Decoder Loss:  0.42671135
Encoder Loss:  0.010491902  || Decoder Loss:  0.0034931588 Validation Decoder Loss:  0.42682937
Encoder Loss:  0.010397277  || Decoder Loss:  0.0034250123 Validation Decoder Loss:  0.4263965
Encoder Loss:  0.010290746  || Decoder Loss:  0.0033333849 Validation Decoder Loss:  0.42618734
Encoder Loss:  0.010217751  || Decoder Loss:  0.0032823752 Validation Decoder Loss:  0.425729
Encoder Loss:  0.010154884  || Decoder Loss:  0.0032348689 Validation Decoder Loss:  0.4253997
Encoder Loss:  0.010099372  || Decoder Loss:  0.003194154 Validation Decoder Loss:  0.4249778
Encoder Loss:  0.010049835  || Decoder Loss:  0.003158751 Validation Decoder Loss:  0.42477956
Encoder Loss:  0.010001952  || Decoder Loss:  0.0031246508 Validation Decoder Loss:  0.42472976
Encoder Loss:  0.009957444  || Decoder Loss:  0.003100173 Validation Decoder Loss:  0.42453504
Encoder Loss:  0.009915652  || Decoder Loss:  0.003078562 Validation Decoder Loss:  0.42436045
Encoder Loss:  0.009864704  || Decoder Loss:  0.0030523245 Validation Decoder Loss:  0.42415896
Encoder Loss:  0.009810882  || Decoder Loss:  0.0030263984 Validation Decoder Loss:  0.42391384
Encoder Loss:  0.009758144  || Decoder Loss:  0.0029989323 Validation Decoder Loss:  0.4240027
Encoder Loss:  0.009700712  || Decoder Loss:  0.0029690117 Validation Decoder Loss:  0.42419952
Encoder Loss:  0.009651539  || Decoder Loss:  0.002945332 Validation Decoder Loss:  0.42455947
Encoder Loss:  0.009604633  || Decoder Loss:  0.0029288912 Validation Decoder Loss:  0.4247383
Encoder Loss:  0.00955822  || Decoder Loss:  0.0029162925 Validation Decoder Loss:  0.42479643
Encoder Loss:  0.009508337  || Decoder Loss:  0.0029028687 Validation Decoder Loss:  0.42480245
Encoder Loss:  0.009453833  || Decoder Loss:  0.0028842618 Validation Decoder Loss:  0.4248973
Encoder Loss:  0.009400371  || Decoder Loss:  0.00286639 Validation Decoder Loss:  0.42518127
Encoder Loss:  0.009351653  || Decoder Loss:  0.0028532026 Validation Decoder Loss:  0.42516342
Encoder Loss:  0.009312662  || Decoder Loss:  0.0028520646 Validation Decoder Loss:  0.42496052
Encoder Loss:  0.0092729665  || Decoder Loss:  0.0028518082 Validation Decoder Loss:  0.42487127
Encoder Loss:  0.009230864  || Decoder Loss:  0.002846539 Validation Decoder Loss:  0.42462465
Encoder Loss:  0.00918205  || Decoder Loss:  0.002835224 Validation Decoder Loss:  0.4243845
Encoder Loss:  0.009130625  || Decoder Loss:  0.0028242483 Validation Decoder Loss:  0.42398208
Model: bold_synthesis_net_lr_0.00019197715310866883 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.42398208
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 157, 10, 16, 1)    63        
_________________________________________________________________
reshape_2 (Reshape)          (None, 1570, 16, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 1570, 16, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 16, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08055781  || Decoder Loss:  0.005519521 Validation Decoder Loss:  0.38760823
Encoder Loss:  0.08025047  || Decoder Loss:  0.0054995455 Validation Decoder Loss:  0.38805646
Encoder Loss:  0.07993303  || Decoder Loss:  0.0054826867 Validation Decoder Loss:  0.3884839
Encoder Loss:  0.079611346  || Decoder Loss:  0.005469041 Validation Decoder Loss:  0.3889464
Encoder Loss:  0.079288445  || Decoder Loss:  0.0054604216 Validation Decoder Loss:  0.38945863
Encoder Loss:  0.07896284  || Decoder Loss:  0.0054551717 Validation Decoder Loss:  0.38996744
Encoder Loss:  0.07863704  || Decoder Loss:  0.005443014 Validation Decoder Loss:  0.39043266
Encoder Loss:  0.07830864  || Decoder Loss:  0.0054250276 Validation Decoder Loss:  0.3908722
Encoder Loss:  0.077984765  || Decoder Loss:  0.005418657 Validation Decoder Loss:  0.39155632
Encoder Loss:  0.077662975  || Decoder Loss:  0.0054140114 Validation Decoder Loss:  0.39228293
Encoder Loss:  0.07733853  || Decoder Loss:  0.0053948397 Validation Decoder Loss:  0.39303678
Encoder Loss:  0.07701547  || Decoder Loss:  0.005381203 Validation Decoder Loss:  0.39380884
Encoder Loss:  0.07669064  || Decoder Loss:  0.005376806 Validation Decoder Loss:  0.39454484
Encoder Loss:  0.07635704  || Decoder Loss:  0.005370441 Validation Decoder Loss:  0.3952403
Encoder Loss:  0.07602072  || Decoder Loss:  0.005367454 Validation Decoder Loss:  0.39592382
Encoder Loss:  0.07568161  || Decoder Loss:  0.0053682206 Validation Decoder Loss:  0.396622
Encoder Loss:  0.075345285  || Decoder Loss:  0.0053619053 Validation Decoder Loss:  0.39740193
Encoder Loss:  0.07501436  || Decoder Loss:  0.0053810943 Validation Decoder Loss:  0.398179
Encoder Loss:  0.074678235  || Decoder Loss:  0.0053913253 Validation Decoder Loss:  0.39894864
Encoder Loss:  0.07433418  || Decoder Loss:  0.0053734984 Validation Decoder Loss:  0.39972347
Encoder Loss:  0.07399064  || Decoder Loss:  0.005358841 Validation Decoder Loss:  0.4004481
Encoder Loss:  0.073649496  || Decoder Loss:  0.0053580794 Validation Decoder Loss:  0.40113682
Encoder Loss:  0.07331351  || Decoder Loss:  0.005370042 Validation Decoder Loss:  0.4017737
Encoder Loss:  0.07298072  || Decoder Loss:  0.005364714 Validation Decoder Loss:  0.4023434
Encoder Loss:  0.07265565  || Decoder Loss:  0.0053505134 Validation Decoder Loss:  0.40289903
Encoder Loss:  0.072339185  || Decoder Loss:  0.005362601 Validation Decoder Loss:  0.40348703
Encoder Loss:  0.072028205  || Decoder Loss:  0.005389694 Validation Decoder Loss:  0.40406692
Encoder Loss:  0.07172541  || Decoder Loss:  0.005414372 Validation Decoder Loss:  0.40462947
Encoder Loss:  0.07143294  || Decoder Loss:  0.0054360386 Validation Decoder Loss:  0.40524995
Encoder Loss:  0.07114679  || Decoder Loss:  0.0054803733 Validation Decoder Loss:  0.40612897
Encoder Loss:  0.070863836  || Decoder Loss:  0.005530721 Validation Decoder Loss:  0.40698805
Encoder Loss:  0.07058633  || Decoder Loss:  0.005576652 Validation Decoder Loss:  0.40781727
Encoder Loss:  0.070313685  || Decoder Loss:  0.005631791 Validation Decoder Loss:  0.40864098
Encoder Loss:  0.07004274  || Decoder Loss:  0.005669986 Validation Decoder Loss:  0.40942872
Encoder Loss:  0.069776304  || Decoder Loss:  0.0056969314 Validation Decoder Loss:  0.41022
Encoder Loss:  0.0695211  || Decoder Loss:  0.0057279672 Validation Decoder Loss:  0.41101286
Encoder Loss:  0.06927237  || Decoder Loss:  0.0057574273 Validation Decoder Loss:  0.41184044
Encoder Loss:  0.06902169  || Decoder Loss:  0.005776653 Validation Decoder Loss:  0.41269708
Encoder Loss:  0.06876808  || Decoder Loss:  0.005787891 Validation Decoder Loss:  0.41356558
Encoder Loss:  0.06850697  || Decoder Loss:  0.0058022053 Validation Decoder Loss:  0.41440916
Model: bold_synthesis_net_lr_8.439854043106965e-06 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.41440916
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 71, 20, 16, 1)     65        
_________________________________________________________________
reshape_3 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0831298  || Decoder Loss:  0.006191684 Validation Decoder Loss:  0.41714162
Encoder Loss:  0.07777079  || Decoder Loss:  0.0058122044 Validation Decoder Loss:  0.42147878
Encoder Loss:  0.07274906  || Decoder Loss:  0.0056933854 Validation Decoder Loss:  0.42467296
Encoder Loss:  0.065175675  || Decoder Loss:  0.005661667 Validation Decoder Loss:  0.4275319
Encoder Loss:  0.05960246  || Decoder Loss:  0.005580417 Validation Decoder Loss:  0.42832673
Encoder Loss:  0.056279745  || Decoder Loss:  0.005418974 Validation Decoder Loss:  0.4293478
Encoder Loss:  0.05376028  || Decoder Loss:  0.0053723617 Validation Decoder Loss:  0.43099034
Encoder Loss:  0.052115902  || Decoder Loss:  0.0051607047 Validation Decoder Loss:  0.43231606
Encoder Loss:  0.050921306  || Decoder Loss:  0.00500067 Validation Decoder Loss:  0.434281
Encoder Loss:  0.050022874  || Decoder Loss:  0.0048790914 Validation Decoder Loss:  0.43479106
Encoder Loss:  0.049192946  || Decoder Loss:  0.004696696 Validation Decoder Loss:  0.43620655
Encoder Loss:  0.048416886  || Decoder Loss:  0.0045425785 Validation Decoder Loss:  0.437699
Encoder Loss:  0.04762293  || Decoder Loss:  0.004404285 Validation Decoder Loss:  0.43863472
Encoder Loss:  0.046756633  || Decoder Loss:  0.0042574327 Validation Decoder Loss:  0.43966854
Encoder Loss:  0.045743227  || Decoder Loss:  0.004062662 Validation Decoder Loss:  0.44307452
Encoder Loss:  0.04436166  || Decoder Loss:  0.0039267256 Validation Decoder Loss:  0.44543892
Encoder Loss:  0.04284228  || Decoder Loss:  0.0038380132 Validation Decoder Loss:  0.44521058
Encoder Loss:  0.04120853  || Decoder Loss:  0.003716616 Validation Decoder Loss:  0.4425993
Encoder Loss:  0.039400842  || Decoder Loss:  0.0036318481 Validation Decoder Loss:  0.43692264
Encoder Loss:  0.03737714  || Decoder Loss:  0.0036440017 Validation Decoder Loss:  0.42953408
Encoder Loss:  0.035689637  || Decoder Loss:  0.0036545254 Validation Decoder Loss:  0.42225158
Encoder Loss:  0.034337673  || Decoder Loss:  0.0036006193 Validation Decoder Loss:  0.41300112
Encoder Loss:  0.03346112  || Decoder Loss:  0.003275263 Validation Decoder Loss:  0.4060805
Encoder Loss:  0.03286676  || Decoder Loss:  0.0029526083 Validation Decoder Loss:  0.3973918
Encoder Loss:  0.032378316  || Decoder Loss:  0.0027888266 Validation Decoder Loss:  0.39091203
Encoder Loss:  0.03197126  || Decoder Loss:  0.0026651933 Validation Decoder Loss:  0.38428146
Encoder Loss:  0.031678878  || Decoder Loss:  0.0025774124 Validation Decoder Loss:  0.38162005
Encoder Loss:  0.03147996  || Decoder Loss:  0.0024362972 Validation Decoder Loss:  0.38100776
Encoder Loss:  0.031326845  || Decoder Loss:  0.002360018 Validation Decoder Loss:  0.37950185
Encoder Loss:  0.031217339  || Decoder Loss:  0.0023005265 Validation Decoder Loss:  0.37635058
Encoder Loss:  0.031131722  || Decoder Loss:  0.0022638305 Validation Decoder Loss:  0.37338704
Encoder Loss:  0.031047864  || Decoder Loss:  0.0022319444 Validation Decoder Loss:  0.37005365
Encoder Loss:  0.030962378  || Decoder Loss:  0.002203097 Validation Decoder Loss:  0.36590815
Encoder Loss:  0.030872587  || Decoder Loss:  0.0021684272 Validation Decoder Loss:  0.36240578
Encoder Loss:  0.030800315  || Decoder Loss:  0.0021483395 Validation Decoder Loss:  0.35833088
Encoder Loss:  0.030735245  || Decoder Loss:  0.0021236169 Validation Decoder Loss:  0.35457587
Encoder Loss:  0.030680113  || Decoder Loss:  0.0021056344 Validation Decoder Loss:  0.35126907
Encoder Loss:  0.030617703  || Decoder Loss:  0.0020834226 Validation Decoder Loss:  0.34827298
Encoder Loss:  0.030566905  || Decoder Loss:  0.0020522457 Validation Decoder Loss:  0.3455466
Encoder Loss:  0.030519996  || Decoder Loss:  0.0020207074 Validation Decoder Loss:  0.34253258
Model: bold_synthesis_net_lr_0.0005997823736709334 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3425326
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 76, 20, 16, 1)     157       
_________________________________________________________________
reshape_4 (Reshape)          (None, 1520, 16, 1)       0         
=================================================================
Total params: 157
Trainable params: 157
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 1520, 16, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 16, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.013855062  || Decoder Loss:  0.0057041966 Validation Decoder Loss:  0.38561064
Encoder Loss:  0.011217436  || Decoder Loss:  0.004838428 Validation Decoder Loss:  0.39612186
Encoder Loss:  0.010065859  || Decoder Loss:  0.004528492 Validation Decoder Loss:  0.40747154
Encoder Loss:  0.009362967  || Decoder Loss:  0.0042526494 Validation Decoder Loss:  0.41163108
Encoder Loss:  0.008817909  || Decoder Loss:  0.004050702 Validation Decoder Loss:  0.41220033
Encoder Loss:  0.0084274495  || Decoder Loss:  0.0040464224 Validation Decoder Loss:  0.42651966
Encoder Loss:  0.007909286  || Decoder Loss:  0.0038673007 Validation Decoder Loss:  0.4322127
Encoder Loss:  0.007421418  || Decoder Loss:  0.0036205957 Validation Decoder Loss:  0.4344021
Encoder Loss:  0.0071242377  || Decoder Loss:  0.0034413363 Validation Decoder Loss:  0.43763915
Encoder Loss:  0.006875274  || Decoder Loss:  0.0032477623 Validation Decoder Loss:  0.43930888
Encoder Loss:  0.006666877  || Decoder Loss:  0.0030782195 Validation Decoder Loss:  0.43816093
Encoder Loss:  0.006527603  || Decoder Loss:  0.002966781 Validation Decoder Loss:  0.43551245
Encoder Loss:  0.0064031966  || Decoder Loss:  0.002867599 Validation Decoder Loss:  0.42811054
Encoder Loss:  0.00629474  || Decoder Loss:  0.0027769161 Validation Decoder Loss:  0.42416996
Encoder Loss:  0.0062254025  || Decoder Loss:  0.0027213322 Validation Decoder Loss:  0.42217252
Encoder Loss:  0.006177064  || Decoder Loss:  0.0026869427 Validation Decoder Loss:  0.41946742
Encoder Loss:  0.006097577  || Decoder Loss:  0.002615653 Validation Decoder Loss:  0.4176093
Encoder Loss:  0.006059537  || Decoder Loss:  0.0025875245 Validation Decoder Loss:  0.4168622
Encoder Loss:  0.006040577  || Decoder Loss:  0.0025799766 Validation Decoder Loss:  0.4123178
Encoder Loss:  0.006063346  || Decoder Loss:  0.0026168823 Validation Decoder Loss:  0.40948638
Encoder Loss:  0.0060254675  || Decoder Loss:  0.00258498 Validation Decoder Loss:  0.40730554
Encoder Loss:  0.005971377  || Decoder Loss:  0.0025322228 Validation Decoder Loss:  0.4028103
Encoder Loss:  0.0058992775  || Decoder Loss:  0.002459074 Validation Decoder Loss:  0.40018076
Encoder Loss:  0.005829552  || Decoder Loss:  0.0023877008 Validation Decoder Loss:  0.39956355
Encoder Loss:  0.0057616704  || Decoder Loss:  0.0023174502 Validation Decoder Loss:  0.39888793
Encoder Loss:  0.0057008406  || Decoder Loss:  0.002256111 Validation Decoder Loss:  0.39641702
Encoder Loss:  0.005629912  || Decoder Loss:  0.0021832895 Validation Decoder Loss:  0.39000332
Encoder Loss:  0.0055476213  || Decoder Loss:  0.0020993392 Validation Decoder Loss:  0.38530603
Encoder Loss:  0.005425071  || Decoder Loss:  0.0019688886 Validation Decoder Loss:  0.38391694
Encoder Loss:  0.005330049  || Decoder Loss:  0.0018677299 Validation Decoder Loss:  0.3813752
Encoder Loss:  0.005272839  || Decoder Loss:  0.0018093141 Validation Decoder Loss:  0.37830782
Encoder Loss:  0.005228244  || Decoder Loss:  0.0017635803 Validation Decoder Loss:  0.377128
Encoder Loss:  0.005197583  || Decoder Loss:  0.0017325483 Validation Decoder Loss:  0.3757848
Encoder Loss:  0.005164848  || Decoder Loss:  0.0016981192 Validation Decoder Loss:  0.3746428
Encoder Loss:  0.005141258  || Decoder Loss:  0.00167347 Validation Decoder Loss:  0.3729614
Encoder Loss:  0.0051182765  || Decoder Loss:  0.0016504404 Validation Decoder Loss:  0.37103337
Encoder Loss:  0.005099899  || Decoder Loss:  0.001631648 Validation Decoder Loss:  0.37023038
Encoder Loss:  0.0050776186  || Decoder Loss:  0.0016089826 Validation Decoder Loss:  0.36837268
Encoder Loss:  0.005056729  || Decoder Loss:  0.0015875376 Validation Decoder Loss:  0.36892503
Encoder Loss:  0.005044623  || Decoder Loss:  0.0015758578 Validation Decoder Loss:  0.3681755
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: bold_synthesis_net_lr_0.0008155819075885726 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3681755
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 142, 10, 16, 1)    97        
_________________________________________________________________
reshape_5 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08775576  || Decoder Loss:  0.006173593 Validation Decoder Loss:  0.38174933
Encoder Loss:  0.08154643  || Decoder Loss:  0.0056429515 Validation Decoder Loss:  0.3818063
Encoder Loss:  0.07531302  || Decoder Loss:  0.00534539 Validation Decoder Loss:  0.38323623
Encoder Loss:  0.07029539  || Decoder Loss:  0.00509664 Validation Decoder Loss:  0.3854971
Encoder Loss:  0.06320275  || Decoder Loss:  0.0048611984 Validation Decoder Loss:  0.3878996
Encoder Loss:  0.058230665  || Decoder Loss:  0.0046406826 Validation Decoder Loss:  0.39048272
Encoder Loss:  0.05554047  || Decoder Loss:  0.004485528 Validation Decoder Loss:  0.39207977
Encoder Loss:  0.053593144  || Decoder Loss:  0.0044047837 Validation Decoder Loss:  0.39418676
Encoder Loss:  0.05201538  || Decoder Loss:  0.0043004225 Validation Decoder Loss:  0.3975282
Encoder Loss:  0.050810054  || Decoder Loss:  0.0042384053 Validation Decoder Loss:  0.40197623
Encoder Loss:  0.049745232  || Decoder Loss:  0.004153714 Validation Decoder Loss:  0.40637773
Encoder Loss:  0.048744928  || Decoder Loss:  0.004042837 Validation Decoder Loss:  0.41183656
Encoder Loss:  0.04734243  || Decoder Loss:  0.003999016 Validation Decoder Loss:  0.42043075
Encoder Loss:  0.044960137  || Decoder Loss:  0.003989591 Validation Decoder Loss:  0.4310388
Encoder Loss:  0.042935226  || Decoder Loss:  0.0039439034 Validation Decoder Loss:  0.43565917
Encoder Loss:  0.041165106  || Decoder Loss:  0.0037753328 Validation Decoder Loss:  0.43701184
Encoder Loss:  0.039801717  || Decoder Loss:  0.0036244537 Validation Decoder Loss:  0.43681994
Encoder Loss:  0.038425807  || Decoder Loss:  0.0034788093 Validation Decoder Loss:  0.43580842
Encoder Loss:  0.037236743  || Decoder Loss:  0.003435593 Validation Decoder Loss:  0.43321958
Encoder Loss:  0.036291786  || Decoder Loss:  0.0033331546 Validation Decoder Loss:  0.43067807
Encoder Loss:  0.035495922  || Decoder Loss:  0.0033135933 Validation Decoder Loss:  0.42712826
Encoder Loss:  0.03457937  || Decoder Loss:  0.0031433003 Validation Decoder Loss:  0.41904688
Encoder Loss:  0.03368385  || Decoder Loss:  0.0029305087 Validation Decoder Loss:  0.40868282
Encoder Loss:  0.0329971  || Decoder Loss:  0.0027328276 Validation Decoder Loss:  0.40013525
Encoder Loss:  0.032485414  || Decoder Loss:  0.0026096774 Validation Decoder Loss:  0.39070255
Encoder Loss:  0.032081712  || Decoder Loss:  0.0024936853 Validation Decoder Loss:  0.38255066
Encoder Loss:  0.031721536  || Decoder Loss:  0.0023320194 Validation Decoder Loss:  0.37702048
Encoder Loss:  0.0314597  || Decoder Loss:  0.0022630284 Validation Decoder Loss:  0.37184876
Encoder Loss:  0.031226262  || Decoder Loss:  0.002186987 Validation Decoder Loss:  0.3641478
Encoder Loss:  0.0310411  || Decoder Loss:  0.0021165584 Validation Decoder Loss:  0.3629285
Encoder Loss:  0.030910425  || Decoder Loss:  0.002049419 Validation Decoder Loss:  0.36028332
Encoder Loss:  0.030784251  || Decoder Loss:  0.001966474 Validation Decoder Loss:  0.3587767
Encoder Loss:  0.030653613  || Decoder Loss:  0.0019014662 Validation Decoder Loss:  0.35678026
Encoder Loss:  0.030545969  || Decoder Loss:  0.0018527936 Validation Decoder Loss:  0.35707897
Encoder Loss:  0.030457282  || Decoder Loss:  0.0018128423 Validation Decoder Loss:  0.35488403
Encoder Loss:  0.030373216  || Decoder Loss:  0.0017627074 Validation Decoder Loss:  0.3538854
Encoder Loss:  0.030310532  || Decoder Loss:  0.0017330466 Validation Decoder Loss:  0.35334587
Encoder Loss:  0.030255174  || Decoder Loss:  0.0017082235 Validation Decoder Loss:  0.35103565
Encoder Loss:  0.030195257  || Decoder Loss:  0.0016777471 Validation Decoder Loss:  0.34885567
Encoder Loss:  0.030148523  || Decoder Loss:  0.0016462221 Validation Decoder Loss:  0.3487115
Model: bold_synthesis_net_lr_0.0005997827046450813 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3487115
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 71, 20, 16, 1)     129       
_________________________________________________________________
reshape_6 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.043672852  || Decoder Loss:  0.005681498 Validation Decoder Loss:  0.37448132
Encoder Loss:  0.041783933  || Decoder Loss:  0.005391021 Validation Decoder Loss:  0.37260935
Encoder Loss:  0.039553892  || Decoder Loss:  0.005239095 Validation Decoder Loss:  0.3710637
Encoder Loss:  0.037695676  || Decoder Loss:  0.005280497 Validation Decoder Loss:  0.37038556
Encoder Loss:  0.036098633  || Decoder Loss:  0.0051513906 Validation Decoder Loss:  0.37014645
Encoder Loss:  0.033974096  || Decoder Loss:  0.0051096147 Validation Decoder Loss:  0.37124857
Encoder Loss:  0.03126257  || Decoder Loss:  0.005041869 Validation Decoder Loss:  0.37254333
Encoder Loss:  0.029629275  || Decoder Loss:  0.0049384977 Validation Decoder Loss:  0.37404972
Encoder Loss:  0.028694069  || Decoder Loss:  0.004853652 Validation Decoder Loss:  0.37536925
Encoder Loss:  0.027945025  || Decoder Loss:  0.0047830176 Validation Decoder Loss:  0.37632978
Encoder Loss:  0.02725896  || Decoder Loss:  0.0047241165 Validation Decoder Loss:  0.37740776
Encoder Loss:  0.026680764  || Decoder Loss:  0.0046490934 Validation Decoder Loss:  0.37881392
Encoder Loss:  0.026212439  || Decoder Loss:  0.004595973 Validation Decoder Loss:  0.3800541
Encoder Loss:  0.02574611  || Decoder Loss:  0.0045388695 Validation Decoder Loss:  0.3813427
Encoder Loss:  0.025301648  || Decoder Loss:  0.0045058457 Validation Decoder Loss:  0.38309667
Encoder Loss:  0.024824832  || Decoder Loss:  0.00448934 Validation Decoder Loss:  0.38768575
Encoder Loss:  0.024213724  || Decoder Loss:  0.0045092665 Validation Decoder Loss:  0.39219904
Encoder Loss:  0.023492124  || Decoder Loss:  0.004527241 Validation Decoder Loss:  0.39591667
Encoder Loss:  0.022681957  || Decoder Loss:  0.0044612642 Validation Decoder Loss:  0.39895386
Encoder Loss:  0.021829654  || Decoder Loss:  0.004399292 Validation Decoder Loss:  0.40238738
Encoder Loss:  0.02074904  || Decoder Loss:  0.004301341 Validation Decoder Loss:  0.40677604
Encoder Loss:  0.019582657  || Decoder Loss:  0.004299615 Validation Decoder Loss:  0.410859
Encoder Loss:  0.018519783  || Decoder Loss:  0.0043349485 Validation Decoder Loss:  0.41379887
Encoder Loss:  0.01773572  || Decoder Loss:  0.0042947396 Validation Decoder Loss:  0.41498026
Encoder Loss:  0.017214736  || Decoder Loss:  0.0042646606 Validation Decoder Loss:  0.4122692
Encoder Loss:  0.016715635  || Decoder Loss:  0.0040534423 Validation Decoder Loss:  0.40594363
Encoder Loss:  0.016335914  || Decoder Loss:  0.0038819374 Validation Decoder Loss:  0.4007707
Encoder Loss:  0.01604404  || Decoder Loss:  0.003786267 Validation Decoder Loss:  0.39536402
Encoder Loss:  0.015802892  || Decoder Loss:  0.003712869 Validation Decoder Loss:  0.39045656
Encoder Loss:  0.015605636  || Decoder Loss:  0.0036322325 Validation Decoder Loss:  0.3859399
Encoder Loss:  0.015423438  || Decoder Loss:  0.0035327647 Validation Decoder Loss:  0.38077825
Encoder Loss:  0.015278865  || Decoder Loss:  0.0034724565 Validation Decoder Loss:  0.37516356
Encoder Loss:  0.0151553815  || Decoder Loss:  0.0033958042 Validation Decoder Loss:  0.36890042
Encoder Loss:  0.015032785  || Decoder Loss:  0.0032931024 Validation Decoder Loss:  0.36550027
Encoder Loss:  0.0149110295  || Decoder Loss:  0.003175771 Validation Decoder Loss:  0.36203036
Encoder Loss:  0.014800197  || Decoder Loss:  0.0030716474 Validation Decoder Loss:  0.3588788
Encoder Loss:  0.014708495  || Decoder Loss:  0.0029942968 Validation Decoder Loss:  0.35690624
Encoder Loss:  0.014604267  || Decoder Loss:  0.0028899743 Validation Decoder Loss:  0.35427168
Encoder Loss:  0.014508926  || Decoder Loss:  0.002789673 Validation Decoder Loss:  0.35105574
Encoder Loss:  0.014423544  || Decoder Loss:  0.002698977 Validation Decoder Loss:  0.34846666
Model: bold_synthesis_net_lr_0.0003645488198571223 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.34846666
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 142, 10, 16, 1)    33        
_________________________________________________________________
reshape_7 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10638096  || Decoder Loss:  0.005968419 Validation Decoder Loss:  0.39823192
Encoder Loss:  0.10175092  || Decoder Loss:  0.0060125166 Validation Decoder Loss:  0.40608045
Encoder Loss:  0.09770295  || Decoder Loss:  0.0056889546 Validation Decoder Loss:  0.40792647
Encoder Loss:  0.09369672  || Decoder Loss:  0.0055632535 Validation Decoder Loss:  0.40876675
Encoder Loss:  0.088055946  || Decoder Loss:  0.005402441 Validation Decoder Loss:  0.40824306
Encoder Loss:  0.081695266  || Decoder Loss:  0.005163532 Validation Decoder Loss:  0.4082694
Encoder Loss:  0.076954626  || Decoder Loss:  0.0049307137 Validation Decoder Loss:  0.4062338
Encoder Loss:  0.074283965  || Decoder Loss:  0.004808943 Validation Decoder Loss:  0.40575647
Encoder Loss:  0.07264541  || Decoder Loss:  0.0047087586 Validation Decoder Loss:  0.40514135
Encoder Loss:  0.071320735  || Decoder Loss:  0.004621373 Validation Decoder Loss:  0.40532795
Encoder Loss:  0.07020627  || Decoder Loss:  0.0045801373 Validation Decoder Loss:  0.40644303
Encoder Loss:  0.069352  || Decoder Loss:  0.0045317244 Validation Decoder Loss:  0.4083414
Encoder Loss:  0.06841935  || Decoder Loss:  0.004524976 Validation Decoder Loss:  0.40961093
Encoder Loss:  0.06735708  || Decoder Loss:  0.0044354093 Validation Decoder Loss:  0.41193998
Encoder Loss:  0.0662586  || Decoder Loss:  0.0043751365 Validation Decoder Loss:  0.414105
Encoder Loss:  0.06520005  || Decoder Loss:  0.0042919186 Validation Decoder Loss:  0.4154241
Encoder Loss:  0.06431889  || Decoder Loss:  0.004243431 Validation Decoder Loss:  0.41770256
Encoder Loss:  0.063538164  || Decoder Loss:  0.0042120037 Validation Decoder Loss:  0.4190331
Encoder Loss:  0.0628705  || Decoder Loss:  0.004110771 Validation Decoder Loss:  0.4209308
Encoder Loss:  0.062229957  || Decoder Loss:  0.003939731 Validation Decoder Loss:  0.42272323
Encoder Loss:  0.06160363  || Decoder Loss:  0.0038178274 Validation Decoder Loss:  0.42390162
Encoder Loss:  0.060972463  || Decoder Loss:  0.0037290428 Validation Decoder Loss:  0.42515063
Encoder Loss:  0.060142823  || Decoder Loss:  0.0036513559 Validation Decoder Loss:  0.42554948
Encoder Loss:  0.059150595  || Decoder Loss:  0.0035723133 Validation Decoder Loss:  0.4263079
Encoder Loss:  0.058382317  || Decoder Loss:  0.0035321498 Validation Decoder Loss:  0.42647606
Encoder Loss:  0.057598677  || Decoder Loss:  0.0034868226 Validation Decoder Loss:  0.42639008
Encoder Loss:  0.056661684  || Decoder Loss:  0.0034278866 Validation Decoder Loss:  0.42611244
Encoder Loss:  0.05582427  || Decoder Loss:  0.0033779903 Validation Decoder Loss:  0.42580914
Encoder Loss:  0.05514169  || Decoder Loss:  0.0033401472 Validation Decoder Loss:  0.4253725
Encoder Loss:  0.05438253  || Decoder Loss:  0.0033086722 Validation Decoder Loss:  0.4248737
Encoder Loss:  0.053346466  || Decoder Loss:  0.0032813 Validation Decoder Loss:  0.42422837
Encoder Loss:  0.05253883  || Decoder Loss:  0.0032635469 Validation Decoder Loss:  0.42262757
Encoder Loss:  0.05162225  || Decoder Loss:  0.0032580723 Validation Decoder Loss:  0.42067334
Encoder Loss:  0.050534535  || Decoder Loss:  0.0032595478 Validation Decoder Loss:  0.4168899
Encoder Loss:  0.049681645  || Decoder Loss:  0.0032472787 Validation Decoder Loss:  0.41401607
Encoder Loss:  0.049012765  || Decoder Loss:  0.003230837 Validation Decoder Loss:  0.4107275
Encoder Loss:  0.04855567  || Decoder Loss:  0.0031781415 Validation Decoder Loss:  0.40752846
Encoder Loss:  0.048098583  || Decoder Loss:  0.0030953502 Validation Decoder Loss:  0.40389195
Encoder Loss:  0.047662746  || Decoder Loss:  0.0030422206 Validation Decoder Loss:  0.4012251
Encoder Loss:  0.047135208  || Decoder Loss:  0.002944721 Validation Decoder Loss:  0.39647537
Model: bold_synthesis_net_lr_0.0003694471693285899 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.39647537
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 142, 10, 16, 1)    159       
_________________________________________________________________
reshape_8 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04574696  || Decoder Loss:  0.004754852 Validation Decoder Loss:  0.43265983
Encoder Loss:  0.04205995  || Decoder Loss:  0.004490069 Validation Decoder Loss:  0.4171951
Encoder Loss:  0.039510295  || Decoder Loss:  0.0044679223 Validation Decoder Loss:  0.40104002
Encoder Loss:  0.03502594  || Decoder Loss:  0.004456445 Validation Decoder Loss:  0.36940655
Encoder Loss:  0.027923744  || Decoder Loss:  0.0044666566 Validation Decoder Loss:  0.35807592
Encoder Loss:  0.02545866  || Decoder Loss:  0.0045457077 Validation Decoder Loss:  0.3499753
Encoder Loss:  0.023825271  || Decoder Loss:  0.0046018115 Validation Decoder Loss:  0.34875253
Encoder Loss:  0.023230547  || Decoder Loss:  0.0046232175 Validation Decoder Loss:  0.35476828
Encoder Loss:  0.022636682  || Decoder Loss:  0.004510402 Validation Decoder Loss:  0.35921264
Encoder Loss:  0.021998826  || Decoder Loss:  0.0043674204 Validation Decoder Loss:  0.36296508
Encoder Loss:  0.021384563  || Decoder Loss:  0.00423661 Validation Decoder Loss:  0.36575246
Encoder Loss:  0.02079403  || Decoder Loss:  0.0040884926 Validation Decoder Loss:  0.37164867
Encoder Loss:  0.020218423  || Decoder Loss:  0.0039402633 Validation Decoder Loss:  0.3794485
Encoder Loss:  0.019701298  || Decoder Loss:  0.0038329144 Validation Decoder Loss:  0.38372827
Encoder Loss:  0.019250568  || Decoder Loss:  0.0037678622 Validation Decoder Loss:  0.38545507
Encoder Loss:  0.018821644  || Decoder Loss:  0.0035925976 Validation Decoder Loss:  0.38440877
Encoder Loss:  0.01849681  || Decoder Loss:  0.003429447 Validation Decoder Loss:  0.3810843
Encoder Loss:  0.01823729  || Decoder Loss:  0.003281803 Validation Decoder Loss:  0.37723947
Encoder Loss:  0.018072875  || Decoder Loss:  0.0032038307 Validation Decoder Loss:  0.37542385
Encoder Loss:  0.017934587  || Decoder Loss:  0.0031359175 Validation Decoder Loss:  0.3729898
Encoder Loss:  0.017799433  || Decoder Loss:  0.0030603567 Validation Decoder Loss:  0.3715334
Encoder Loss:  0.017683836  || Decoder Loss:  0.0029938675 Validation Decoder Loss:  0.37039053
Encoder Loss:  0.017568968  || Decoder Loss:  0.0029105635 Validation Decoder Loss:  0.3690768
Encoder Loss:  0.017478539  || Decoder Loss:  0.0028486592 Validation Decoder Loss:  0.3688525
Encoder Loss:  0.017399887  || Decoder Loss:  0.0028055538 Validation Decoder Loss:  0.36751163
Encoder Loss:  0.017329518  || Decoder Loss:  0.0027687852 Validation Decoder Loss:  0.3656914
Encoder Loss:  0.017264977  || Decoder Loss:  0.002728629 Validation Decoder Loss:  0.3637545
Encoder Loss:  0.017196164  || Decoder Loss:  0.002672702 Validation Decoder Loss:  0.36227188
Encoder Loss:  0.01709806  || Decoder Loss:  0.0025621392 Validation Decoder Loss:  0.35962045
Encoder Loss:  0.016990092  || Decoder Loss:  0.0024288243 Validation Decoder Loss:  0.35665146
Encoder Loss:  0.016912844  || Decoder Loss:  0.0023444865 Validation Decoder Loss:  0.35521698
Encoder Loss:  0.016848847  || Decoder Loss:  0.0022725975 Validation Decoder Loss:  0.35423756
Encoder Loss:  0.016791318  || Decoder Loss:  0.0022125223 Validation Decoder Loss:  0.3522714
Encoder Loss:  0.01673573  || Decoder Loss:  0.0021535098 Validation Decoder Loss:  0.34992093
Encoder Loss:  0.016678423  || Decoder Loss:  0.0020913833 Validation Decoder Loss:  0.34633523
Encoder Loss:  0.016626673  || Decoder Loss:  0.0020385971 Validation Decoder Loss:  0.34442812
Encoder Loss:  0.016592206  || Decoder Loss:  0.0020042157 Validation Decoder Loss:  0.34336245
Encoder Loss:  0.016553309  || Decoder Loss:  0.0019714748 Validation Decoder Loss:  0.34187767
Encoder Loss:  0.016521854  || Decoder Loss:  0.0019422655 Validation Decoder Loss:  0.3409056
Encoder Loss:  0.016486729  || Decoder Loss:  0.0019082912 Validation Decoder Loss:  0.34045005
Model: bold_synthesis_net_lr_0.000744082155145856 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.34045005
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 71, 20, 16, 1)     33        
_________________________________________________________________
reshape_9 (Reshape)          (None, 1420, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.028919384  || Decoder Loss:  0.0057306197 Validation Decoder Loss:  0.41651088
Encoder Loss:  0.02541991  || Decoder Loss:  0.005541974 Validation Decoder Loss:  0.41473484
Encoder Loss:  0.022099987  || Decoder Loss:  0.0052078976 Validation Decoder Loss:  0.409833
Encoder Loss:  0.021232795  || Decoder Loss:  0.0051156348 Validation Decoder Loss:  0.40855402
Encoder Loss:  0.020656921  || Decoder Loss:  0.0050105886 Validation Decoder Loss:  0.4117128
Encoder Loss:  0.020170389  || Decoder Loss:  0.004994099 Validation Decoder Loss:  0.4140854
Encoder Loss:  0.019732634  || Decoder Loss:  0.0048560654 Validation Decoder Loss:  0.4144407
Encoder Loss:  0.01925824  || Decoder Loss:  0.0046409722 Validation Decoder Loss:  0.41369963
Encoder Loss:  0.018646194  || Decoder Loss:  0.004405639 Validation Decoder Loss:  0.41135108
Encoder Loss:  0.018143576  || Decoder Loss:  0.0042215623 Validation Decoder Loss:  0.40966374
Encoder Loss:  0.017448764  || Decoder Loss:  0.004059641 Validation Decoder Loss:  0.4102563
Encoder Loss:  0.016609792  || Decoder Loss:  0.003936468 Validation Decoder Loss:  0.41339052
Encoder Loss:  0.015434846  || Decoder Loss:  0.0037693984 Validation Decoder Loss:  0.41263068
Encoder Loss:  0.01439519  || Decoder Loss:  0.0036151786 Validation Decoder Loss:  0.40887356
Encoder Loss:  0.013859729  || Decoder Loss:  0.003484395 Validation Decoder Loss:  0.40858966
Encoder Loss:  0.013478712  || Decoder Loss:  0.0034224172 Validation Decoder Loss:  0.40659642
Encoder Loss:  0.013249823  || Decoder Loss:  0.0034304378 Validation Decoder Loss:  0.40427765
Encoder Loss:  0.013089317  || Decoder Loss:  0.0034289183 Validation Decoder Loss:  0.40116036
Encoder Loss:  0.012980448  || Decoder Loss:  0.0033868083 Validation Decoder Loss:  0.39729857
Encoder Loss:  0.012868393  || Decoder Loss:  0.0033285886 Validation Decoder Loss:  0.39445817
Encoder Loss:  0.0127828065  || Decoder Loss:  0.003290036 Validation Decoder Loss:  0.39120632
Encoder Loss:  0.012707603  || Decoder Loss:  0.0032376784 Validation Decoder Loss:  0.38949874
Encoder Loss:  0.012600605  || Decoder Loss:  0.0031575945 Validation Decoder Loss:  0.38612312
Encoder Loss:  0.012498596  || Decoder Loss:  0.0030719338 Validation Decoder Loss:  0.38145587
Encoder Loss:  0.012429239  || Decoder Loss:  0.0030038322 Validation Decoder Loss:  0.37732303
Encoder Loss:  0.012324747  || Decoder Loss:  0.0028899335 Validation Decoder Loss:  0.37261847
Encoder Loss:  0.012216097  || Decoder Loss:  0.0027806177 Validation Decoder Loss:  0.367966
Encoder Loss:  0.012160926  || Decoder Loss:  0.002738725 Validation Decoder Loss:  0.36131322
Encoder Loss:  0.012101108  || Decoder Loss:  0.0026820386 Validation Decoder Loss:  0.35445157
Encoder Loss:  0.012003172  || Decoder Loss:  0.0025791891 Validation Decoder Loss:  0.34438518
Encoder Loss:  0.011935718  || Decoder Loss:  0.0025301026 Validation Decoder Loss:  0.33722347
Encoder Loss:  0.011888284  || Decoder Loss:  0.0025029513 Validation Decoder Loss:  0.332653
Encoder Loss:  0.0118201375  || Decoder Loss:  0.0024434915 Validation Decoder Loss:  0.32674396
Encoder Loss:  0.011708405  || Decoder Loss:  0.0023332664 Validation Decoder Loss:  0.3199342
Encoder Loss:  0.011631615  || Decoder Loss:  0.0022729398 Validation Decoder Loss:  0.31095552
Encoder Loss:  0.011522491  || Decoder Loss:  0.0021692656 Validation Decoder Loss:  0.30059034
Encoder Loss:  0.011393487  || Decoder Loss:  0.0020286953 Validation Decoder Loss:  0.2903238
Encoder Loss:  0.011334451  || Decoder Loss:  0.0019786092 Validation Decoder Loss:  0.28560814
Encoder Loss:  0.01128213  || Decoder Loss:  0.0019388545 Validation Decoder Loss:  0.2810684
Encoder Loss:  0.011213009  || Decoder Loss:  0.0018872749 Validation Decoder Loss:  0.27606198
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.27606198
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 284, 5, 16, 1)     96        
_________________________________________________________________
reshape_10 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 96
Trainable params: 96
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0127655575  || Decoder Loss:  0.0051817577 Validation Decoder Loss:  0.39426273
Encoder Loss:  0.010870609  || Decoder Loss:  0.0047611455 Validation Decoder Loss:  0.3675308
Encoder Loss:  0.009367334  || Decoder Loss:  0.0046791397 Validation Decoder Loss:  0.3363732
Encoder Loss:  0.008377301  || Decoder Loss:  0.004334847 Validation Decoder Loss:  0.3241857
Encoder Loss:  0.008161932  || Decoder Loss:  0.0043880735 Validation Decoder Loss:  0.3232655
Encoder Loss:  0.007993694  || Decoder Loss:  0.004248444 Validation Decoder Loss:  0.32472634
Encoder Loss:  0.0077428105  || Decoder Loss:  0.004017358 Validation Decoder Loss:  0.32856762
Encoder Loss:  0.0075393394  || Decoder Loss:  0.0038351144 Validation Decoder Loss:  0.33394304
Encoder Loss:  0.007437618  || Decoder Loss:  0.003761606 Validation Decoder Loss:  0.33936507
Encoder Loss:  0.007256694  || Decoder Loss:  0.0036084221 Validation Decoder Loss:  0.3433324
Encoder Loss:  0.00711542  || Decoder Loss:  0.0034968387 Validation Decoder Loss:  0.3471958
Encoder Loss:  0.007006521  || Decoder Loss:  0.0034261197 Validation Decoder Loss:  0.35207778
Encoder Loss:  0.006822613  || Decoder Loss:  0.0032823833 Validation Decoder Loss:  0.35488385
Encoder Loss:  0.006714151  || Decoder Loss:  0.0032217826 Validation Decoder Loss:  0.35761058
Encoder Loss:  0.006585521  || Decoder Loss:  0.0031500005 Validation Decoder Loss:  0.3608894
Encoder Loss:  0.006439727  || Decoder Loss:  0.0030616426 Validation Decoder Loss:  0.3646384
Encoder Loss:  0.006284366  || Decoder Loss:  0.0029665874 Validation Decoder Loss:  0.36760843
Encoder Loss:  0.006152797  || Decoder Loss:  0.0028956914 Validation Decoder Loss:  0.36894003
Encoder Loss:  0.0060119214  || Decoder Loss:  0.002809408 Validation Decoder Loss:  0.36985815
Encoder Loss:  0.0058971634  || Decoder Loss:  0.00274835 Validation Decoder Loss:  0.37013647
Encoder Loss:  0.0058117122  || Decoder Loss:  0.0027124078 Validation Decoder Loss:  0.3698315
Encoder Loss:  0.005739742  || Decoder Loss:  0.0026851336 Validation Decoder Loss:  0.3688863
Encoder Loss:  0.0057250317  || Decoder Loss:  0.002709184 Validation Decoder Loss:  0.36737862
Encoder Loss:  0.0056685987  || Decoder Loss:  0.0026756665 Validation Decoder Loss:  0.36639598
Encoder Loss:  0.0056083356  || Decoder Loss:  0.0026343192 Validation Decoder Loss:  0.36330622
Encoder Loss:  0.0055416985  || Decoder Loss:  0.0025848611 Validation Decoder Loss:  0.35827845
Encoder Loss:  0.0054511502  || Decoder Loss:  0.0025059732 Validation Decoder Loss:  0.3519583
Encoder Loss:  0.005383081  || Decoder Loss:  0.0024494126 Validation Decoder Loss:  0.34647715
Encoder Loss:  0.005337434  || Decoder Loss:  0.0024145308 Validation Decoder Loss:  0.34163827
Encoder Loss:  0.005275257  || Decoder Loss:  0.002363685 Validation Decoder Loss:  0.3368319
Encoder Loss:  0.0052190186  || Decoder Loss:  0.0023170807 Validation Decoder Loss:  0.33160895
Encoder Loss:  0.0051862416  || Decoder Loss:  0.002293204 Validation Decoder Loss:  0.3294169
Encoder Loss:  0.005160958  || Decoder Loss:  0.0022737037 Validation Decoder Loss:  0.32669932
Encoder Loss:  0.0051394063  || Decoder Loss:  0.0022576635 Validation Decoder Loss:  0.32412818
Encoder Loss:  0.0051065083  || Decoder Loss:  0.002229019 Validation Decoder Loss:  0.32162702
Encoder Loss:  0.0050886394  || Decoder Loss:  0.0022168038 Validation Decoder Loss:  0.3198703
Encoder Loss:  0.0050688772  || Decoder Loss:  0.0022026673 Validation Decoder Loss:  0.3152874
Encoder Loss:  0.005055945  || Decoder Loss:  0.0021944153 Validation Decoder Loss:  0.31093186
Encoder Loss:  0.0050461106  || Decoder Loss:  0.0021877415 Validation Decoder Loss:  0.3075074
Encoder Loss:  0.005025704  || Decoder Loss:  0.0021695192 Validation Decoder Loss:  0.30580902
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.30580902
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 284, 5, 16, 1)     96        
_________________________________________________________________
reshape_11 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 96
Trainable params: 96
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0051389304  || Decoder Loss:  0.0051389304 Validation Decoder Loss:  0.4097899
Encoder Loss:  0.004620861  || Decoder Loss:  0.004620861 Validation Decoder Loss:  0.40754756
Encoder Loss:  0.0042883498  || Decoder Loss:  0.0042883498 Validation Decoder Loss:  0.40761995
Encoder Loss:  0.004189382  || Decoder Loss:  0.004189382 Validation Decoder Loss:  0.40767217
Encoder Loss:  0.004052519  || Decoder Loss:  0.004052519 Validation Decoder Loss:  0.40761128
Encoder Loss:  0.003963713  || Decoder Loss:  0.003963713 Validation Decoder Loss:  0.4078969
Encoder Loss:  0.0038838573  || Decoder Loss:  0.0038838573 Validation Decoder Loss:  0.40783364
Encoder Loss:  0.0038168314  || Decoder Loss:  0.0038168314 Validation Decoder Loss:  0.40782005
Encoder Loss:  0.0037480537  || Decoder Loss:  0.0037480537 Validation Decoder Loss:  0.40794727
Encoder Loss:  0.0037009325  || Decoder Loss:  0.0037009325 Validation Decoder Loss:  0.40805197
Encoder Loss:  0.0036533063  || Decoder Loss:  0.0036533063 Validation Decoder Loss:  0.4080762
Encoder Loss:  0.003591961  || Decoder Loss:  0.003591961 Validation Decoder Loss:  0.4081294
Encoder Loss:  0.0035172144  || Decoder Loss:  0.0035172144 Validation Decoder Loss:  0.4080893
Encoder Loss:  0.0034469147  || Decoder Loss:  0.0034469147 Validation Decoder Loss:  0.40811688
Encoder Loss:  0.003386234  || Decoder Loss:  0.003386234 Validation Decoder Loss:  0.4081865
Encoder Loss:  0.0033373304  || Decoder Loss:  0.0033373304 Validation Decoder Loss:  0.4082737
Encoder Loss:  0.0032942677  || Decoder Loss:  0.0032942677 Validation Decoder Loss:  0.40836027
Encoder Loss:  0.00325046  || Decoder Loss:  0.00325046 Validation Decoder Loss:  0.40845525
Encoder Loss:  0.0032034165  || Decoder Loss:  0.0032034165 Validation Decoder Loss:  0.40858632
Encoder Loss:  0.0031574836  || Decoder Loss:  0.0031574836 Validation Decoder Loss:  0.40879324
Encoder Loss:  0.0031244212  || Decoder Loss:  0.0031244212 Validation Decoder Loss:  0.4089282
Encoder Loss:  0.0030846787  || Decoder Loss:  0.0030846787 Validation Decoder Loss:  0.40905437
Encoder Loss:  0.003062423  || Decoder Loss:  0.003062423 Validation Decoder Loss:  0.4089561
Encoder Loss:  0.0030006699  || Decoder Loss:  0.0030006699 Validation Decoder Loss:  0.40921468
Encoder Loss:  0.0029610575  || Decoder Loss:  0.0029610575 Validation Decoder Loss:  0.4092851
Encoder Loss:  0.0029260889  || Decoder Loss:  0.0029260889 Validation Decoder Loss:  0.40904194
Encoder Loss:  0.002897471  || Decoder Loss:  0.002897471 Validation Decoder Loss:  0.40898463
Encoder Loss:  0.0028718726  || Decoder Loss:  0.0028718726 Validation Decoder Loss:  0.40895665
Encoder Loss:  0.0028314274  || Decoder Loss:  0.0028314274 Validation Decoder Loss:  0.4090839
Encoder Loss:  0.0027898843  || Decoder Loss:  0.0027898843 Validation Decoder Loss:  0.4089099
Encoder Loss:  0.0027654595  || Decoder Loss:  0.0027654595 Validation Decoder Loss:  0.4087217
Encoder Loss:  0.0027443725  || Decoder Loss:  0.0027443725 Validation Decoder Loss:  0.40869522
Encoder Loss:  0.0027116255  || Decoder Loss:  0.0027116255 Validation Decoder Loss:  0.40856335
Encoder Loss:  0.0026835254  || Decoder Loss:  0.0026835254 Validation Decoder Loss:  0.40851262
Encoder Loss:  0.0026542302  || Decoder Loss:  0.0026542302 Validation Decoder Loss:  0.40843654
Encoder Loss:  0.002621009  || Decoder Loss:  0.002621009 Validation Decoder Loss:  0.40824294
Encoder Loss:  0.0025801677  || Decoder Loss:  0.0025801677 Validation Decoder Loss:  0.40799162
Encoder Loss:  0.0025355213  || Decoder Loss:  0.0025355213 Validation Decoder Loss:  0.40795657
Encoder Loss:  0.0024949184  || Decoder Loss:  0.0024949184 Validation Decoder Loss:  0.408071
Encoder Loss:  0.0024605012  || Decoder Loss:  0.0024605012 Validation Decoder Loss:  0.4082281
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4082281
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 142, 10, 16, 1)    475       
_________________________________________________________________
reshape_12 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 475
Trainable params: 475
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054439325  || Decoder Loss:  0.004040673 Validation Decoder Loss:  0.38522238
Encoder Loss:  0.04692372  || Decoder Loss:  0.0037850346 Validation Decoder Loss:  0.38958892
Encoder Loss:  0.04229195  || Decoder Loss:  0.0038211737 Validation Decoder Loss:  0.39202505
Encoder Loss:  0.038122613  || Decoder Loss:  0.0038315873 Validation Decoder Loss:  0.39284128
Encoder Loss:  0.03264663  || Decoder Loss:  0.0039210035 Validation Decoder Loss:  0.39939025
Encoder Loss:  0.027829248  || Decoder Loss:  0.004011994 Validation Decoder Loss:  0.3925084
Encoder Loss:  0.025225831  || Decoder Loss:  0.003903966 Validation Decoder Loss:  0.3881542
Encoder Loss:  0.023933679  || Decoder Loss:  0.0038290683 Validation Decoder Loss:  0.3883209
Encoder Loss:  0.023061976  || Decoder Loss:  0.0037008708 Validation Decoder Loss:  0.38870478
Encoder Loss:  0.022415273  || Decoder Loss:  0.0036393888 Validation Decoder Loss:  0.3884915
Encoder Loss:  0.021881014  || Decoder Loss:  0.0035289945 Validation Decoder Loss:  0.3874413
Encoder Loss:  0.021382947  || Decoder Loss:  0.0034318112 Validation Decoder Loss:  0.38654342
Encoder Loss:  0.020941025  || Decoder Loss:  0.0033390569 Validation Decoder Loss:  0.38566542
Encoder Loss:  0.020561738  || Decoder Loss:  0.0032639937 Validation Decoder Loss:  0.38530675
Encoder Loss:  0.020214487  || Decoder Loss:  0.0031969643 Validation Decoder Loss:  0.38542318
Encoder Loss:  0.019903822  || Decoder Loss:  0.0031250785 Validation Decoder Loss:  0.38541055
Encoder Loss:  0.019658482  || Decoder Loss:  0.0030662802 Validation Decoder Loss:  0.38588905
Encoder Loss:  0.019463666  || Decoder Loss:  0.0030117165 Validation Decoder Loss:  0.38629436
Encoder Loss:  0.019294355  || Decoder Loss:  0.0029569028 Validation Decoder Loss:  0.38665915
Encoder Loss:  0.01916473  || Decoder Loss:  0.0028933212 Validation Decoder Loss:  0.38669384
Encoder Loss:  0.019065095  || Decoder Loss:  0.0028329447 Validation Decoder Loss:  0.3864569
Encoder Loss:  0.018989552  || Decoder Loss:  0.0027812214 Validation Decoder Loss:  0.3861457
Encoder Loss:  0.018910028  || Decoder Loss:  0.0027293304 Validation Decoder Loss:  0.38579103
Encoder Loss:  0.01884095  || Decoder Loss:  0.0026879206 Validation Decoder Loss:  0.3855271
Encoder Loss:  0.018779773  || Decoder Loss:  0.0026525059 Validation Decoder Loss:  0.38537169
Encoder Loss:  0.018722316  || Decoder Loss:  0.0026254973 Validation Decoder Loss:  0.3853952
Encoder Loss:  0.01867455  || Decoder Loss:  0.0026029234 Validation Decoder Loss:  0.38549268
Encoder Loss:  0.018626586  || Decoder Loss:  0.00257169 Validation Decoder Loss:  0.38549995
Encoder Loss:  0.018587738  || Decoder Loss:  0.002547377 Validation Decoder Loss:  0.38551277
Encoder Loss:  0.018545596  || Decoder Loss:  0.0025148185 Validation Decoder Loss:  0.38564074
Encoder Loss:  0.018505903  || Decoder Loss:  0.0024813833 Validation Decoder Loss:  0.38560766
Encoder Loss:  0.018469498  || Decoder Loss:  0.0024544564 Validation Decoder Loss:  0.38566452
Encoder Loss:  0.018437006  || Decoder Loss:  0.0024289135 Validation Decoder Loss:  0.38565713
Encoder Loss:  0.018403819  || Decoder Loss:  0.002405563 Validation Decoder Loss:  0.3856416
Encoder Loss:  0.018361194  || Decoder Loss:  0.002382092 Validation Decoder Loss:  0.38546488
Encoder Loss:  0.018329177  || Decoder Loss:  0.0023595672 Validation Decoder Loss:  0.38531998
Encoder Loss:  0.018299362  || Decoder Loss:  0.0023397924 Validation Decoder Loss:  0.3851765
Encoder Loss:  0.018270519  || Decoder Loss:  0.0023214757 Validation Decoder Loss:  0.3850635
Encoder Loss:  0.018246932  || Decoder Loss:  0.0023076262 Validation Decoder Loss:  0.38496143
Encoder Loss:  0.018220872  || Decoder Loss:  0.0022901872 Validation Decoder Loss:  0.38478783
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.38478783
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 71, 20, 16, 1)     129       
_________________________________________________________________
reshape_13 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.029998252  || Decoder Loss:  0.005477143 Validation Decoder Loss:  0.37294936
Encoder Loss:  0.02686823  || Decoder Loss:  0.0052204076 Validation Decoder Loss:  0.37074733
Encoder Loss:  0.024271943  || Decoder Loss:  0.0050884057 Validation Decoder Loss:  0.37223226
Encoder Loss:  0.021152638  || Decoder Loss:  0.004882761 Validation Decoder Loss:  0.37473547
Encoder Loss:  0.019617174  || Decoder Loss:  0.0046290364 Validation Decoder Loss:  0.3779149
Encoder Loss:  0.018695025  || Decoder Loss:  0.00447942 Validation Decoder Loss:  0.38048774
Encoder Loss:  0.018070579  || Decoder Loss:  0.004498978 Validation Decoder Loss:  0.3845523
Encoder Loss:  0.017187519  || Decoder Loss:  0.004481429 Validation Decoder Loss:  0.39602292
Encoder Loss:  0.01582563  || Decoder Loss:  0.004295343 Validation Decoder Loss:  0.40654618
Encoder Loss:  0.014074315  || Decoder Loss:  0.004215532 Validation Decoder Loss:  0.42429736
Encoder Loss:  0.012832093  || Decoder Loss:  0.0042186067 Validation Decoder Loss:  0.4269915
Encoder Loss:  0.012041291  || Decoder Loss:  0.0037131137 Validation Decoder Loss:  0.42595762
Encoder Loss:  0.011502599  || Decoder Loss:  0.0033785275 Validation Decoder Loss:  0.4206146
Encoder Loss:  0.0110939955  || Decoder Loss:  0.003077639 Validation Decoder Loss:  0.41734368
Encoder Loss:  0.010785886  || Decoder Loss:  0.0028294513 Validation Decoder Loss:  0.41386834
Encoder Loss:  0.010566201  || Decoder Loss:  0.0026518602 Validation Decoder Loss:  0.4116581
Encoder Loss:  0.010386506  || Decoder Loss:  0.0024959783 Validation Decoder Loss:  0.41135612
Encoder Loss:  0.010258436  || Decoder Loss:  0.0023922967 Validation Decoder Loss:  0.41028482
Encoder Loss:  0.01015875  || Decoder Loss:  0.0023144512 Validation Decoder Loss:  0.40845495
Encoder Loss:  0.010066048  || Decoder Loss:  0.0022326924 Validation Decoder Loss:  0.40749606
Encoder Loss:  0.010008547  || Decoder Loss:  0.0021934716 Validation Decoder Loss:  0.40487003
Encoder Loss:  0.009944652  || Decoder Loss:  0.0021446869 Validation Decoder Loss:  0.40044934
Encoder Loss:  0.009883602  || Decoder Loss:  0.0020947102 Validation Decoder Loss:  0.3958007
Encoder Loss:  0.009832992  || Decoder Loss:  0.0020552925 Validation Decoder Loss:  0.39132315
Encoder Loss:  0.009783824  || Decoder Loss:  0.0020146135 Validation Decoder Loss:  0.38801077
Encoder Loss:  0.009717472  || Decoder Loss:  0.0019500396 Validation Decoder Loss:  0.3837005
Encoder Loss:  0.009671637  || Decoder Loss:  0.0019069854 Validation Decoder Loss:  0.3792733
Encoder Loss:  0.009629269  || Decoder Loss:  0.0018648605 Validation Decoder Loss:  0.3767553
Encoder Loss:  0.009568259  || Decoder Loss:  0.0018030613 Validation Decoder Loss:  0.37213588
Encoder Loss:  0.009527557  || Decoder Loss:  0.0017622565 Validation Decoder Loss:  0.36562723
Encoder Loss:  0.009492488  || Decoder Loss:  0.001727097 Validation Decoder Loss:  0.36127514
Encoder Loss:  0.009450909  || Decoder Loss:  0.0016848812 Validation Decoder Loss:  0.3550503
Encoder Loss:  0.009419225  || Decoder Loss:  0.001652668 Validation Decoder Loss:  0.3506015
Encoder Loss:  0.009396273  || Decoder Loss:  0.0016322036 Validation Decoder Loss:  0.34663367
Encoder Loss:  0.009373085  || Decoder Loss:  0.0016101225 Validation Decoder Loss:  0.34039032
Encoder Loss:  0.009346747  || Decoder Loss:  0.0015823395 Validation Decoder Loss:  0.3368152
Encoder Loss:  0.009325732  || Decoder Loss:  0.0015622342 Validation Decoder Loss:  0.3324384
Encoder Loss:  0.009307944  || Decoder Loss:  0.001543481 Validation Decoder Loss:  0.3275445
Encoder Loss:  0.009288458  || Decoder Loss:  0.0015243101 Validation Decoder Loss:  0.32443318
Encoder Loss:  0.0092591215  || Decoder Loss:  0.0014937914 Validation Decoder Loss:  0.32249328
Model: bold_synthesis_net_lr_0.000863894759021086 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.32249328
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 284, 5, 16, 1)     159       
_________________________________________________________________
reshape_14 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030176794  || Decoder Loss:  0.004702501 Validation Decoder Loss:  0.42625302
Encoder Loss:  0.02742114  || Decoder Loss:  0.004612406 Validation Decoder Loss:  0.40668827
Encoder Loss:  0.024125358  || Decoder Loss:  0.0045590634 Validation Decoder Loss:  0.3725972
Encoder Loss:  0.01882561  || Decoder Loss:  0.004491048 Validation Decoder Loss:  0.356225
Encoder Loss:  0.017260578  || Decoder Loss:  0.004732737 Validation Decoder Loss:  0.34079054
Encoder Loss:  0.016434027  || Decoder Loss:  0.0048127915 Validation Decoder Loss:  0.3360814
Encoder Loss:  0.016066635  || Decoder Loss:  0.0049075554 Validation Decoder Loss:  0.33163357
Encoder Loss:  0.015654625  || Decoder Loss:  0.0048213867 Validation Decoder Loss:  0.334932
Encoder Loss:  0.015066582  || Decoder Loss:  0.004580853 Validation Decoder Loss:  0.3398149
Encoder Loss:  0.014309045  || Decoder Loss:  0.0041664485 Validation Decoder Loss:  0.345857
Encoder Loss:  0.013533963  || Decoder Loss:  0.0036853547 Validation Decoder Loss:  0.35305858
Encoder Loss:  0.012932652  || Decoder Loss:  0.0032914493 Validation Decoder Loss:  0.35931146
Encoder Loss:  0.012604121  || Decoder Loss:  0.0031292674 Validation Decoder Loss:  0.36174595
Encoder Loss:  0.012311379  || Decoder Loss:  0.0029148348 Validation Decoder Loss:  0.36023247
Encoder Loss:  0.012104651  || Decoder Loss:  0.0027586832 Validation Decoder Loss:  0.35908616
Encoder Loss:  0.011931945  || Decoder Loss:  0.0026205827 Validation Decoder Loss:  0.35624087
Encoder Loss:  0.011805161  || Decoder Loss:  0.0025234986 Validation Decoder Loss:  0.3574327
Encoder Loss:  0.0117417155  || Decoder Loss:  0.0025052289 Validation Decoder Loss:  0.35745186
Encoder Loss:  0.011689692  || Decoder Loss:  0.0024958984 Validation Decoder Loss:  0.3568012
Encoder Loss:  0.011628968  || Decoder Loss:  0.0024698665 Validation Decoder Loss:  0.35560465
Encoder Loss:  0.011531983  || Decoder Loss:  0.0023914832 Validation Decoder Loss:  0.35112697
Encoder Loss:  0.011470251  || Decoder Loss:  0.0023472442 Validation Decoder Loss:  0.34634167
Encoder Loss:  0.011357564  || Decoder Loss:  0.0022313036 Validation Decoder Loss:  0.33521742
Encoder Loss:  0.011230533  || Decoder Loss:  0.0020866427 Validation Decoder Loss:  0.32851073
Encoder Loss:  0.011164872  || Decoder Loss:  0.0020178247 Validation Decoder Loss:  0.32625732
Encoder Loss:  0.011112166  || Decoder Loss:  0.0019643917 Validation Decoder Loss:  0.3249895
Encoder Loss:  0.011070215  || Decoder Loss:  0.0019192232 Validation Decoder Loss:  0.3240424
Encoder Loss:  0.011028378  || Decoder Loss:  0.0018823277 Validation Decoder Loss:  0.32318038
Encoder Loss:  0.011001033  || Decoder Loss:  0.0018532925 Validation Decoder Loss:  0.3224907
Encoder Loss:  0.010977377  || Decoder Loss:  0.0018350324 Validation Decoder Loss:  0.3218462
Encoder Loss:  0.010957097  || Decoder Loss:  0.0018148008 Validation Decoder Loss:  0.3209116
Encoder Loss:  0.0109356465  || Decoder Loss:  0.0017937606 Validation Decoder Loss:  0.31986743
Encoder Loss:  0.010912695  || Decoder Loss:  0.0017771539 Validation Decoder Loss:  0.31876034
Encoder Loss:  0.010894271  || Decoder Loss:  0.0017664368 Validation Decoder Loss:  0.3177412
Encoder Loss:  0.0108814845  || Decoder Loss:  0.0017604688 Validation Decoder Loss:  0.31721532
Encoder Loss:  0.010870746  || Decoder Loss:  0.0017562165 Validation Decoder Loss:  0.3163979
Encoder Loss:  0.010860657  || Decoder Loss:  0.001750722 Validation Decoder Loss:  0.31579816
Encoder Loss:  0.010847351  || Decoder Loss:  0.0017409807 Validation Decoder Loss:  0.31541947
Encoder Loss:  0.01083362  || Decoder Loss:  0.0017300991 Validation Decoder Loss:  0.3151173
Encoder Loss:  0.010821899  || Decoder Loss:  0.0017199469 Validation Decoder Loss:  0.31502646
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.31502646
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 142, 10, 16, 1)    159       
_________________________________________________________________
reshape_15 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.029632833  || Decoder Loss:  0.004719189 Validation Decoder Loss:  0.42840815
Encoder Loss:  0.02692108  || Decoder Loss:  0.004522352 Validation Decoder Loss:  0.4107489
Encoder Loss:  0.024070075  || Decoder Loss:  0.004513926 Validation Decoder Loss:  0.37650204
Encoder Loss:  0.018860152  || Decoder Loss:  0.0045366627 Validation Decoder Loss:  0.35604033
Encoder Loss:  0.016947296  || Decoder Loss:  0.0046638893 Validation Decoder Loss:  0.35123792
Encoder Loss:  0.016200563  || Decoder Loss:  0.0047439993 Validation Decoder Loss:  0.35768196
Encoder Loss:  0.015707524  || Decoder Loss:  0.0046259556 Validation Decoder Loss:  0.36236715
Encoder Loss:  0.0151888225  || Decoder Loss:  0.0045067905 Validation Decoder Loss:  0.3692765
Encoder Loss:  0.014540776  || Decoder Loss:  0.0041699926 Validation Decoder Loss:  0.37770495
Encoder Loss:  0.013925514  || Decoder Loss:  0.0038715252 Validation Decoder Loss:  0.38742015
Encoder Loss:  0.013376883  || Decoder Loss:  0.0036482434 Validation Decoder Loss:  0.39282185
Encoder Loss:  0.012917609  || Decoder Loss:  0.003452081 Validation Decoder Loss:  0.39560497
Encoder Loss:  0.012634737  || Decoder Loss:  0.0033315665 Validation Decoder Loss:  0.39518607
Encoder Loss:  0.012428733  || Decoder Loss:  0.0032210273 Validation Decoder Loss:  0.3950328
Encoder Loss:  0.012284111  || Decoder Loss:  0.0031351866 Validation Decoder Loss:  0.39436567
Encoder Loss:  0.012128614  || Decoder Loss:  0.0030142302 Validation Decoder Loss:  0.39397043
Encoder Loss:  0.0119917225  || Decoder Loss:  0.0029045404 Validation Decoder Loss:  0.39324862
Encoder Loss:  0.011908666  || Decoder Loss:  0.0028554094 Validation Decoder Loss:  0.39267132
Encoder Loss:  0.011835846  || Decoder Loss:  0.0028148817 Validation Decoder Loss:  0.39154434
Encoder Loss:  0.01176315  || Decoder Loss:  0.0027720076 Validation Decoder Loss:  0.38964838
Encoder Loss:  0.011648626  || Decoder Loss:  0.0026670592 Validation Decoder Loss:  0.38681453
Encoder Loss:  0.011563395  || Decoder Loss:  0.0025944668 Validation Decoder Loss:  0.38475752
Encoder Loss:  0.011502932  || Decoder Loss:  0.002544257 Validation Decoder Loss:  0.38229483
Encoder Loss:  0.01145481  || Decoder Loss:  0.0025075818 Validation Decoder Loss:  0.37865582
Encoder Loss:  0.011382907  || Decoder Loss:  0.0024374335 Validation Decoder Loss:  0.37631112
Encoder Loss:  0.011334764  || Decoder Loss:  0.002394223 Validation Decoder Loss:  0.37442636
Encoder Loss:  0.0112847565  || Decoder Loss:  0.0023517627 Validation Decoder Loss:  0.37259266
Encoder Loss:  0.011247965  || Decoder Loss:  0.0023190295 Validation Decoder Loss:  0.37077194
Encoder Loss:  0.011199298  || Decoder Loss:  0.00226943 Validation Decoder Loss:  0.36888584
Encoder Loss:  0.01115458  || Decoder Loss:  0.0022292414 Validation Decoder Loss:  0.36673427
Encoder Loss:  0.011127248  || Decoder Loss:  0.0022062727 Validation Decoder Loss:  0.3650729
Encoder Loss:  0.0111002475  || Decoder Loss:  0.0021829857 Validation Decoder Loss:  0.36321276
Encoder Loss:  0.011068452  || Decoder Loss:  0.002151209 Validation Decoder Loss:  0.36216623
Encoder Loss:  0.011034429  || Decoder Loss:  0.0021192566 Validation Decoder Loss:  0.36016527
Encoder Loss:  0.0109966565  || Decoder Loss:  0.0020797944 Validation Decoder Loss:  0.35792264
Encoder Loss:  0.010959223  || Decoder Loss:  0.0020440093 Validation Decoder Loss:  0.35650605
Encoder Loss:  0.010925516  || Decoder Loss:  0.002007091 Validation Decoder Loss:  0.35596392
Encoder Loss:  0.010894649  || Decoder Loss:  0.0019770116 Validation Decoder Loss:  0.35593128
Encoder Loss:  0.010871266  || Decoder Loss:  0.001951218 Validation Decoder Loss:  0.35650343
Encoder Loss:  0.010845532  || Decoder Loss:  0.0019276724 Validation Decoder Loss:  0.35659868
Model: bold_synthesis_net_lr_0.000982629296929181 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.35659868
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 71, 20, 16, 1)     33        
_________________________________________________________________
reshape_16 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.014738413  || Decoder Loss:  0.005740924 Validation Decoder Loss:  0.41589585
Encoder Loss:  0.013315864  || Decoder Loss:  0.005535153 Validation Decoder Loss:  0.41358846
Encoder Loss:  0.011749452  || Decoder Loss:  0.005181386 Validation Decoder Loss:  0.40981954
Encoder Loss:  0.011326216  || Decoder Loss:  0.005069452 Validation Decoder Loss:  0.40961725
Encoder Loss:  0.01108416  || Decoder Loss:  0.0050139027 Validation Decoder Loss:  0.41219485
Encoder Loss:  0.010798156  || Decoder Loss:  0.0049060066 Validation Decoder Loss:  0.41654608
Encoder Loss:  0.010512417  || Decoder Loss:  0.0047428813 Validation Decoder Loss:  0.41719088
Encoder Loss:  0.010247687  || Decoder Loss:  0.0045757703 Validation Decoder Loss:  0.416529
Encoder Loss:  0.009957394  || Decoder Loss:  0.004421336 Validation Decoder Loss:  0.41374815
Encoder Loss:  0.009677967  || Decoder Loss:  0.0042547155 Validation Decoder Loss:  0.4107421
Encoder Loss:  0.009351831  || Decoder Loss:  0.004096979 Validation Decoder Loss:  0.41037673
Encoder Loss:  0.008917823  || Decoder Loss:  0.0039481334 Validation Decoder Loss:  0.41353905
Encoder Loss:  0.008463779  || Decoder Loss:  0.003787103 Validation Decoder Loss:  0.4139163
Encoder Loss:  0.0077869347  || Decoder Loss:  0.003605487 Validation Decoder Loss:  0.41414675
Encoder Loss:  0.007558324  || Decoder Loss:  0.003459074 Validation Decoder Loss:  0.4123273
Encoder Loss:  0.007373522  || Decoder Loss:  0.0033499263 Validation Decoder Loss:  0.40992868
Encoder Loss:  0.0072255246  || Decoder Loss:  0.0032837235 Validation Decoder Loss:  0.4070526
Encoder Loss:  0.0070922193  || Decoder Loss:  0.0032330519 Validation Decoder Loss:  0.40549284
Encoder Loss:  0.0070595834  || Decoder Loss:  0.0032561033 Validation Decoder Loss:  0.40263247
Encoder Loss:  0.0070313844  || Decoder Loss:  0.0032769742 Validation Decoder Loss:  0.4008425
Encoder Loss:  0.0070114955  || Decoder Loss:  0.0032885657 Validation Decoder Loss:  0.39850163
Encoder Loss:  0.0069779404  || Decoder Loss:  0.0032877985 Validation Decoder Loss:  0.39519745
Encoder Loss:  0.0069516706  || Decoder Loss:  0.0032951494 Validation Decoder Loss:  0.39080304
Encoder Loss:  0.006897193  || Decoder Loss:  0.0032597836 Validation Decoder Loss:  0.38331637
Encoder Loss:  0.006864252  || Decoder Loss:  0.0032543573 Validation Decoder Loss:  0.37281096
Encoder Loss:  0.006748578  || Decoder Loss:  0.0031496733 Validation Decoder Loss:  0.36360744
Encoder Loss:  0.0066189836  || Decoder Loss:  0.003032254 Validation Decoder Loss:  0.35221344
Encoder Loss:  0.0064121927  || Decoder Loss:  0.0028199751 Validation Decoder Loss:  0.3405193
Encoder Loss:  0.0062639015  || Decoder Loss:  0.002671874 Validation Decoder Loss:  0.329803
Encoder Loss:  0.0061888476  || Decoder Loss:  0.0026022599 Validation Decoder Loss:  0.32059792
Encoder Loss:  0.006006339  || Decoder Loss:  0.002412103 Validation Decoder Loss:  0.307698
Encoder Loss:  0.005873945  || Decoder Loss:  0.0022764502 Validation Decoder Loss:  0.29887938
Encoder Loss:  0.005770397  || Decoder Loss:  0.0021716575 Validation Decoder Loss:  0.28840855
Encoder Loss:  0.005681043  || Decoder Loss:  0.0020819667 Validation Decoder Loss:  0.28217682
Encoder Loss:  0.005615368  || Decoder Loss:  0.0020175849 Validation Decoder Loss:  0.27589095
Encoder Loss:  0.00556112  || Decoder Loss:  0.0019658618 Validation Decoder Loss:  0.271377
Encoder Loss:  0.005513751  || Decoder Loss:  0.0019201797 Validation Decoder Loss:  0.2666201
Encoder Loss:  0.005463665  || Decoder Loss:  0.0018687275 Validation Decoder Loss:  0.26355225
Encoder Loss:  0.0054127434  || Decoder Loss:  0.0018159923 Validation Decoder Loss:  0.25967553
Encoder Loss:  0.0053753126  || Decoder Loss:  0.0017776054 Validation Decoder Loss:  0.2551359
Model: bold_synthesis_net_lr_0.00098163203526265 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.2551359
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 71, 20, 16, 1)     129       
_________________________________________________________________
reshape_17 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.016829737  || Decoder Loss:  0.00544486 Validation Decoder Loss:  0.37260017
Encoder Loss:  0.015113556  || Decoder Loss:  0.0052100043 Validation Decoder Loss:  0.37038186
Encoder Loss:  0.013614729  || Decoder Loss:  0.005039128 Validation Decoder Loss:  0.3721793
Encoder Loss:  0.0120665645  || Decoder Loss:  0.0047810986 Validation Decoder Loss:  0.37526143
Encoder Loss:  0.011421159  || Decoder Loss:  0.0046661734 Validation Decoder Loss:  0.37893528
Encoder Loss:  0.011022349  || Decoder Loss:  0.0046344735 Validation Decoder Loss:  0.3837875
Encoder Loss:  0.010486444  || Decoder Loss:  0.0045393114 Validation Decoder Loss:  0.39837798
Encoder Loss:  0.009589318  || Decoder Loss:  0.0043700864 Validation Decoder Loss:  0.41402677
Encoder Loss:  0.008642277  || Decoder Loss:  0.004307808 Validation Decoder Loss:  0.43603688
Encoder Loss:  0.008118391  || Decoder Loss:  0.0042090113 Validation Decoder Loss:  0.44145215
Encoder Loss:  0.00765879  || Decoder Loss:  0.0038808638 Validation Decoder Loss:  0.4427325
Encoder Loss:  0.007185429  || Decoder Loss:  0.0034675433 Validation Decoder Loss:  0.44441712
Encoder Loss:  0.0068079685  || Decoder Loss:  0.0031199402 Validation Decoder Loss:  0.44391495
Encoder Loss:  0.006618169  || Decoder Loss:  0.0029610533 Validation Decoder Loss:  0.4428543
Encoder Loss:  0.006496184  || Decoder Loss:  0.0028636972 Validation Decoder Loss:  0.44063014
Encoder Loss:  0.0063170623  || Decoder Loss:  0.00269362 Validation Decoder Loss:  0.4384181
Encoder Loss:  0.0062001753  || Decoder Loss:  0.0025847426 Validation Decoder Loss:  0.43840215
Encoder Loss:  0.0061207274  || Decoder Loss:  0.002512683 Validation Decoder Loss:  0.43575487
Encoder Loss:  0.006062524  || Decoder Loss:  0.0024615305 Validation Decoder Loss:  0.43341392
Encoder Loss:  0.005988433  || Decoder Loss:  0.0023913507 Validation Decoder Loss:  0.42349535
Encoder Loss:  0.005868493  || Decoder Loss:  0.0022691975 Validation Decoder Loss:  0.4162897
Encoder Loss:  0.0057927757  || Decoder Loss:  0.002193154 Validation Decoder Loss:  0.40997905
Encoder Loss:  0.0057266518  || Decoder Loss:  0.002125906 Validation Decoder Loss:  0.40819138
Encoder Loss:  0.0056826104  || Decoder Loss:  0.002082453 Validation Decoder Loss:  0.40605032
Encoder Loss:  0.005646571  || Decoder Loss:  0.0020471856 Validation Decoder Loss:  0.4013788
Encoder Loss:  0.005610817  || Decoder Loss:  0.0020120936 Validation Decoder Loss:  0.39948577
Encoder Loss:  0.0055918647  || Decoder Loss:  0.0019934895 Validation Decoder Loss:  0.3945651
Encoder Loss:  0.005557563  || Decoder Loss:  0.001959059 Validation Decoder Loss:  0.38788897
Encoder Loss:  0.005520353  || Decoder Loss:  0.0019206179 Validation Decoder Loss:  0.3811473
Encoder Loss:  0.005476036  || Decoder Loss:  0.0018740337 Validation Decoder Loss:  0.3737928
Encoder Loss:  0.0054364125  || Decoder Loss:  0.0018326857 Validation Decoder Loss:  0.36822152
Encoder Loss:  0.0054  || Decoder Loss:  0.0017941605 Validation Decoder Loss:  0.3623067
Encoder Loss:  0.0053628376  || Decoder Loss:  0.0017556004 Validation Decoder Loss:  0.3570798
Encoder Loss:  0.005331474  || Decoder Loss:  0.0017225475 Validation Decoder Loss:  0.35119194
Encoder Loss:  0.005296295  || Decoder Loss:  0.0016845812 Validation Decoder Loss:  0.34742674
Encoder Loss:  0.0052638934  || Decoder Loss:  0.0016503078 Validation Decoder Loss:  0.34343055
Encoder Loss:  0.00523684  || Decoder Loss:  0.0016210864 Validation Decoder Loss:  0.33941224
Encoder Loss:  0.005203589  || Decoder Loss:  0.0015863375 Validation Decoder Loss:  0.33727056
Encoder Loss:  0.0051761046  || Decoder Loss:  0.001557297 Validation Decoder Loss:  0.33202422
Encoder Loss:  0.0051459414  || Decoder Loss:  0.0015244586 Validation Decoder Loss:  0.33073872
Model: bold_synthesis_net_lr_0.0009803738967222662 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.33073872
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 284, 5, 16, 1)     222       
_________________________________________________________________
reshape_18 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 222
Trainable params: 222
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.020028992  || Decoder Loss:  0.004221735 Validation Decoder Loss:  0.46148312
Encoder Loss:  0.017769663  || Decoder Loss:  0.003937743 Validation Decoder Loss:  0.46063203
Encoder Loss:  0.016641619  || Decoder Loss:  0.0038187215 Validation Decoder Loss:  0.45941025
Encoder Loss:  0.016071428  || Decoder Loss:  0.0040094196 Validation Decoder Loss:  0.46339878
Encoder Loss:  0.014341971  || Decoder Loss:  0.0039197244 Validation Decoder Loss:  0.4661372
Encoder Loss:  0.012787881  || Decoder Loss:  0.0038882322 Validation Decoder Loss:  0.46833423
Encoder Loss:  0.011978763  || Decoder Loss:  0.003778318 Validation Decoder Loss:  0.46727335
Encoder Loss:  0.010981018  || Decoder Loss:  0.0037116578 Validation Decoder Loss:  0.46530682
Encoder Loss:  0.010088838  || Decoder Loss:  0.0035959503 Validation Decoder Loss:  0.45981526
Encoder Loss:  0.009404545  || Decoder Loss:  0.0034503492 Validation Decoder Loss:  0.4589165
Encoder Loss:  0.009012141  || Decoder Loss:  0.0033198602 Validation Decoder Loss:  0.45786047
Encoder Loss:  0.008767404  || Decoder Loss:  0.0032036628 Validation Decoder Loss:  0.457313
Encoder Loss:  0.008647025  || Decoder Loss:  0.0031432707 Validation Decoder Loss:  0.45698488
Encoder Loss:  0.0085598985  || Decoder Loss:  0.0030789478 Validation Decoder Loss:  0.45700672
Encoder Loss:  0.008487926  || Decoder Loss:  0.0030179634 Validation Decoder Loss:  0.45696145
Encoder Loss:  0.008447457  || Decoder Loss:  0.0029919557 Validation Decoder Loss:  0.45692527
Encoder Loss:  0.008426959  || Decoder Loss:  0.0029838183 Validation Decoder Loss:  0.4571038
Encoder Loss:  0.008405889  || Decoder Loss:  0.0029738115 Validation Decoder Loss:  0.45687634
Encoder Loss:  0.008382478  || Decoder Loss:  0.0029625483 Validation Decoder Loss:  0.45663348
Encoder Loss:  0.008349667  || Decoder Loss:  0.0029367695 Validation Decoder Loss:  0.45667452
Encoder Loss:  0.008322845  || Decoder Loss:  0.0029172872 Validation Decoder Loss:  0.45651236
Encoder Loss:  0.008284847  || Decoder Loss:  0.0028816878 Validation Decoder Loss:  0.45635846
Encoder Loss:  0.008256655  || Decoder Loss:  0.002858031 Validation Decoder Loss:  0.45633376
Encoder Loss:  0.008228924  || Decoder Loss:  0.002832914 Validation Decoder Loss:  0.45652425
Encoder Loss:  0.008208759  || Decoder Loss:  0.002814395 Validation Decoder Loss:  0.45653158
Encoder Loss:  0.008190031  || Decoder Loss:  0.0027971382 Validation Decoder Loss:  0.456591
Encoder Loss:  0.008166276  || Decoder Loss:  0.0027743536 Validation Decoder Loss:  0.45653358
Encoder Loss:  0.00814583  || Decoder Loss:  0.0027540592 Validation Decoder Loss:  0.45646754
Encoder Loss:  0.0081268065  || Decoder Loss:  0.0027344862 Validation Decoder Loss:  0.4561573
Encoder Loss:  0.008103401  || Decoder Loss:  0.0027111634 Validation Decoder Loss:  0.45614916
Encoder Loss:  0.008085903  || Decoder Loss:  0.002693123 Validation Decoder Loss:  0.45603642
Encoder Loss:  0.008074279  || Decoder Loss:  0.0026819569 Validation Decoder Loss:  0.4561326
Encoder Loss:  0.008064341  || Decoder Loss:  0.0026718515 Validation Decoder Loss:  0.45600364
Encoder Loss:  0.00805365  || Decoder Loss:  0.002661402 Validation Decoder Loss:  0.4555227
Encoder Loss:  0.008045716  || Decoder Loss:  0.0026556943 Validation Decoder Loss:  0.45544547
Encoder Loss:  0.008032555  || Decoder Loss:  0.0026395028 Validation Decoder Loss:  0.4555418
Encoder Loss:  0.008018434  || Decoder Loss:  0.0026247052 Validation Decoder Loss:  0.4551634
Encoder Loss:  0.008009051  || Decoder Loss:  0.0026170795 Validation Decoder Loss:  0.45501524
Encoder Loss:  0.007995795  || Decoder Loss:  0.0026029635 Validation Decoder Loss:  0.4548561
Encoder Loss:  0.007986644  || Decoder Loss:  0.002592961 Validation Decoder Loss:  0.45481697
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.45481697
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 142, 10, 16, 1)    33        
_________________________________________________________________
reshape_19 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.021626893  || Decoder Loss:  0.005973369 Validation Decoder Loss:  0.39754254
Encoder Loss:  0.021020828  || Decoder Loss:  0.0060815713 Validation Decoder Loss:  0.4054197
Encoder Loss:  0.020092716  || Decoder Loss:  0.005714019 Validation Decoder Loss:  0.40748176
Encoder Loss:  0.019421227  || Decoder Loss:  0.0056078504 Validation Decoder Loss:  0.40840983
Encoder Loss:  0.018476577  || Decoder Loss:  0.005443698 Validation Decoder Loss:  0.4081142
Encoder Loss:  0.01733639  || Decoder Loss:  0.0052413065 Validation Decoder Loss:  0.40604535
Encoder Loss:  0.016306533  || Decoder Loss:  0.004961608 Validation Decoder Loss:  0.40658796
Encoder Loss:  0.015707344  || Decoder Loss:  0.0047748596 Validation Decoder Loss:  0.4055615
Encoder Loss:  0.015349048  || Decoder Loss:  0.004677043 Validation Decoder Loss:  0.40506595
Encoder Loss:  0.015091981  || Decoder Loss:  0.0046240333 Validation Decoder Loss:  0.40511355
Encoder Loss:  0.014882161  || Decoder Loss:  0.0045851185 Validation Decoder Loss:  0.4059599
Encoder Loss:  0.014712808  || Decoder Loss:  0.004553638 Validation Decoder Loss:  0.40838662
Encoder Loss:  0.014535635  || Decoder Loss:  0.0044963183 Validation Decoder Loss:  0.41116333
Encoder Loss:  0.014370535  || Decoder Loss:  0.0044717686 Validation Decoder Loss:  0.41253912
Encoder Loss:  0.014201022  || Decoder Loss:  0.0044598533 Validation Decoder Loss:  0.41496134
Encoder Loss:  0.014000279  || Decoder Loss:  0.004430719 Validation Decoder Loss:  0.41744667
Encoder Loss:  0.013801782  || Decoder Loss:  0.0043766745 Validation Decoder Loss:  0.41926795
Encoder Loss:  0.013634806  || Decoder Loss:  0.0043350686 Validation Decoder Loss:  0.42075884
Encoder Loss:  0.013459455  || Decoder Loss:  0.0042527383 Validation Decoder Loss:  0.42236948
Encoder Loss:  0.013305244  || Decoder Loss:  0.0041883043 Validation Decoder Loss:  0.42441848
Encoder Loss:  0.013093493  || Decoder Loss:  0.004049588 Validation Decoder Loss:  0.4256696
Encoder Loss:  0.012929984  || Decoder Loss:  0.0039667203 Validation Decoder Loss:  0.4271376
Encoder Loss:  0.012750374  || Decoder Loss:  0.003869339 Validation Decoder Loss:  0.42769653
Encoder Loss:  0.012545834  || Decoder Loss:  0.0037844866 Validation Decoder Loss:  0.42799073
Encoder Loss:  0.012264671  || Decoder Loss:  0.0036262758 Validation Decoder Loss:  0.42778057
Encoder Loss:  0.012062015  || Decoder Loss:  0.0035180547 Validation Decoder Loss:  0.42818695
Encoder Loss:  0.011905494  || Decoder Loss:  0.0034699335 Validation Decoder Loss:  0.4283869
Encoder Loss:  0.011713382  || Decoder Loss:  0.00339684 Validation Decoder Loss:  0.42798963
Encoder Loss:  0.011531757  || Decoder Loss:  0.0033380562 Validation Decoder Loss:  0.42786953
Encoder Loss:  0.011391169  || Decoder Loss:  0.0033072585 Validation Decoder Loss:  0.42774096
Encoder Loss:  0.011246938  || Decoder Loss:  0.003277974 Validation Decoder Loss:  0.42682576
Encoder Loss:  0.011082746  || Decoder Loss:  0.0032534131 Validation Decoder Loss:  0.425846
Encoder Loss:  0.010926652  || Decoder Loss:  0.0032385185 Validation Decoder Loss:  0.42457104
Encoder Loss:  0.010769346  || Decoder Loss:  0.0032261733 Validation Decoder Loss:  0.4223392
Encoder Loss:  0.010591509  || Decoder Loss:  0.0032166077 Validation Decoder Loss:  0.4191025
Encoder Loss:  0.010444753  || Decoder Loss:  0.0031855605 Validation Decoder Loss:  0.41636372
Encoder Loss:  0.010302996  || Decoder Loss:  0.0031432316 Validation Decoder Loss:  0.4135661
Encoder Loss:  0.010183866  || Decoder Loss:  0.0031102716 Validation Decoder Loss:  0.41142777
Encoder Loss:  0.010041423  || Decoder Loss:  0.00303819 Validation Decoder Loss:  0.40917346
Encoder Loss:  0.009928605  || Decoder Loss:  0.0029892498 Validation Decoder Loss:  0.40727288
Model: bold_synthesis_net_lr_0.0003550809148739989 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.40727288
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 71, 20, 16, 1)     33        
_________________________________________________________________
reshape_20 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.029686922  || Decoder Loss:  0.0057306197 Validation Decoder Loss:  0.41651076
Encoder Loss:  0.026077075  || Decoder Loss:  0.005541972 Validation Decoder Loss:  0.4147349
Encoder Loss:  0.022659095  || Decoder Loss:  0.005207879 Validation Decoder Loss:  0.40982646
Encoder Loss:  0.021764595  || Decoder Loss:  0.0051133167 Validation Decoder Loss:  0.40847573
Encoder Loss:  0.021175493  || Decoder Loss:  0.005011468 Validation Decoder Loss:  0.41127938
Encoder Loss:  0.020671435  || Decoder Loss:  0.0049924185 Validation Decoder Loss:  0.4131948
Encoder Loss:  0.020218678  || Decoder Loss:  0.004847523 Validation Decoder Loss:  0.4142358
Encoder Loss:  0.019724183  || Decoder Loss:  0.004617151 Validation Decoder Loss:  0.41383076
Encoder Loss:  0.019095475  || Decoder Loss:  0.004375858 Validation Decoder Loss:  0.41127682
Encoder Loss:  0.01859037  || Decoder Loss:  0.0042022457 Validation Decoder Loss:  0.40883282
Encoder Loss:  0.017847158  || Decoder Loss:  0.003997851 Validation Decoder Loss:  0.41008484
Encoder Loss:  0.016981572  || Decoder Loss:  0.0038720178 Validation Decoder Loss:  0.4117107
Encoder Loss:  0.015759258  || Decoder Loss:  0.0036898968 Validation Decoder Loss:  0.41041958
Encoder Loss:  0.014647692  || Decoder Loss:  0.0034904282 Validation Decoder Loss:  0.40681326
Encoder Loss:  0.01407167  || Decoder Loss:  0.003338141 Validation Decoder Loss:  0.40608394
Encoder Loss:  0.01366948  || Decoder Loss:  0.003253973 Validation Decoder Loss:  0.40448266
Encoder Loss:  0.013435482  || Decoder Loss:  0.003260592 Validation Decoder Loss:  0.402757
Encoder Loss:  0.013293427  || Decoder Loss:  0.0032807274 Validation Decoder Loss:  0.39983696
Encoder Loss:  0.013194355  || Decoder Loss:  0.0032589643 Validation Decoder Loss:  0.39748758
Encoder Loss:  0.013103682  || Decoder Loss:  0.0032419101 Validation Decoder Loss:  0.39300343
Encoder Loss:  0.013040146  || Decoder Loss:  0.0032233829 Validation Decoder Loss:  0.38919026
Encoder Loss:  0.012945098  || Decoder Loss:  0.003159501 Validation Decoder Loss:  0.38644946
Encoder Loss:  0.012849479  || Decoder Loss:  0.0030991044 Validation Decoder Loss:  0.3823397
Encoder Loss:  0.0127638485  || Decoder Loss:  0.003036714 Validation Decoder Loss:  0.37778053
Encoder Loss:  0.012679464  || Decoder Loss:  0.0029573895 Validation Decoder Loss:  0.3723082
Encoder Loss:  0.012556471  || Decoder Loss:  0.0028178946 Validation Decoder Loss:  0.36528128
Encoder Loss:  0.01246335  || Decoder Loss:  0.0027256634 Validation Decoder Loss:  0.3585559
Encoder Loss:  0.012366977  || Decoder Loss:  0.002623127 Validation Decoder Loss:  0.35019726
Encoder Loss:  0.012311149  || Decoder Loss:  0.002578772 Validation Decoder Loss:  0.34273073
Encoder Loss:  0.0122341225  || Decoder Loss:  0.0025065343 Validation Decoder Loss:  0.3327106
Encoder Loss:  0.01212454  || Decoder Loss:  0.002396775 Validation Decoder Loss:  0.32361913
Encoder Loss:  0.012033836  || Decoder Loss:  0.002318062 Validation Decoder Loss:  0.3130849
Encoder Loss:  0.011938013  || Decoder Loss:  0.0022261068 Validation Decoder Loss:  0.30166623
Encoder Loss:  0.011821515  || Decoder Loss:  0.0021043885 Validation Decoder Loss:  0.29066402
Encoder Loss:  0.011720931  || Decoder Loss:  0.002002704 Validation Decoder Loss:  0.27904683
Encoder Loss:  0.011643386  || Decoder Loss:  0.00193075 Validation Decoder Loss:  0.26827183
Encoder Loss:  0.01159094  || Decoder Loss:  0.0018910636 Validation Decoder Loss:  0.2623897
Encoder Loss:  0.01152789  || Decoder Loss:  0.0018329093 Validation Decoder Loss:  0.25594515
Encoder Loss:  0.011467799  || Decoder Loss:  0.0017811941 Validation Decoder Loss:  0.25009027
Encoder Loss:  0.01141134  || Decoder Loss:  0.0017256684 Validation Decoder Loss:  0.24470784
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.24470782
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 142, 10, 16, 1)    159       
_________________________________________________________________
reshape_21 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1018883  || Decoder Loss:  0.0048149526 Validation Decoder Loss:  0.43654996
Encoder Loss:  0.09595652  || Decoder Loss:  0.0047200597 Validation Decoder Loss:  0.42809904
Encoder Loss:  0.09195066  || Decoder Loss:  0.0046245614 Validation Decoder Loss:  0.41917738
Encoder Loss:  0.08848017  || Decoder Loss:  0.004633042 Validation Decoder Loss:  0.41141653
Encoder Loss:  0.08522861  || Decoder Loss:  0.0046857623 Validation Decoder Loss:  0.40254793
Encoder Loss:  0.08072847  || Decoder Loss:  0.00466357 Validation Decoder Loss:  0.39033422
Encoder Loss:  0.07293057  || Decoder Loss:  0.004612726 Validation Decoder Loss:  0.37073672
Encoder Loss:  0.061955802  || Decoder Loss:  0.0046077305 Validation Decoder Loss:  0.35963023
Encoder Loss:  0.057713594  || Decoder Loss:  0.004601928 Validation Decoder Loss:  0.3583756
Encoder Loss:  0.055198804  || Decoder Loss:  0.004706328 Validation Decoder Loss:  0.35626182
Encoder Loss:  0.052283976  || Decoder Loss:  0.004753294 Validation Decoder Loss:  0.35554892
Encoder Loss:  0.050315987  || Decoder Loss:  0.004741007 Validation Decoder Loss:  0.35540622
Encoder Loss:  0.049037542  || Decoder Loss:  0.004759317 Validation Decoder Loss:  0.3558411
Encoder Loss:  0.0482429  || Decoder Loss:  0.004735216 Validation Decoder Loss:  0.35919684
Encoder Loss:  0.04763939  || Decoder Loss:  0.0047247014 Validation Decoder Loss:  0.3632313
Encoder Loss:  0.047016673  || Decoder Loss:  0.0047208252 Validation Decoder Loss:  0.36568177
Encoder Loss:  0.04642873  || Decoder Loss:  0.004677205 Validation Decoder Loss:  0.36827427
Encoder Loss:  0.04586628  || Decoder Loss:  0.004583381 Validation Decoder Loss:  0.3711247
Encoder Loss:  0.04530584  || Decoder Loss:  0.004501363 Validation Decoder Loss:  0.37374425
Encoder Loss:  0.044673152  || Decoder Loss:  0.004453889 Validation Decoder Loss:  0.3771629
Encoder Loss:  0.043986466  || Decoder Loss:  0.004351724 Validation Decoder Loss:  0.3804351
Encoder Loss:  0.04328401  || Decoder Loss:  0.004274152 Validation Decoder Loss:  0.38296866
Encoder Loss:  0.042567383  || Decoder Loss:  0.0041957367 Validation Decoder Loss:  0.3840567
Encoder Loss:  0.041875172  || Decoder Loss:  0.0041268994 Validation Decoder Loss:  0.38566804
Encoder Loss:  0.041245244  || Decoder Loss:  0.0040885787 Validation Decoder Loss:  0.38690948
Encoder Loss:  0.04067785  || Decoder Loss:  0.0040538185 Validation Decoder Loss:  0.3886581
Encoder Loss:  0.04015756  || Decoder Loss:  0.0040228767 Validation Decoder Loss:  0.3898503
Encoder Loss:  0.03973127  || Decoder Loss:  0.003959812 Validation Decoder Loss:  0.39041448
Encoder Loss:  0.039339628  || Decoder Loss:  0.003903888 Validation Decoder Loss:  0.39090654
Encoder Loss:  0.038989317  || Decoder Loss:  0.0038341577 Validation Decoder Loss:  0.39147612
Encoder Loss:  0.038699128  || Decoder Loss:  0.0037700834 Validation Decoder Loss:  0.39247468
Encoder Loss:  0.038438596  || Decoder Loss:  0.003720691 Validation Decoder Loss:  0.3930355
Encoder Loss:  0.038244125  || Decoder Loss:  0.0036773991 Validation Decoder Loss:  0.39301342
Encoder Loss:  0.038097326  || Decoder Loss:  0.0036087413 Validation Decoder Loss:  0.3931355
Encoder Loss:  0.037975725  || Decoder Loss:  0.003559869 Validation Decoder Loss:  0.39288387
Encoder Loss:  0.037861712  || Decoder Loss:  0.0035290965 Validation Decoder Loss:  0.3925814
Encoder Loss:  0.037755903  || Decoder Loss:  0.0034943826 Validation Decoder Loss:  0.39197975
Encoder Loss:  0.0376634  || Decoder Loss:  0.0034577765 Validation Decoder Loss:  0.39115536
Encoder Loss:  0.037569515  || Decoder Loss:  0.0034041996 Validation Decoder Loss:  0.39033538
Encoder Loss:  0.037475627  || Decoder Loss:  0.0033490576 Validation Decoder Loss:  0.389254
Model: bold_synthesis_net_lr_0.0002433565972626111 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.389254
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 180, 9, 16, 1)     271       
_________________________________________________________________
reshape_22 (Reshape)         (None, 1620, 16, 1)       0         
=================================================================
Total params: 271
Trainable params: 271
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 1620, 16, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 16, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05751864  || Decoder Loss:  0.006496437 Validation Decoder Loss:  0.3881534
Encoder Loss:  0.05690853  || Decoder Loss:  0.0064340252 Validation Decoder Loss:  0.38848963
Encoder Loss:  0.056330968  || Decoder Loss:  0.0063663917 Validation Decoder Loss:  0.3888038
Encoder Loss:  0.05576925  || Decoder Loss:  0.0062946505 Validation Decoder Loss:  0.3891212
Encoder Loss:  0.0552344  || Decoder Loss:  0.006225918 Validation Decoder Loss:  0.38931328
Encoder Loss:  0.054706708  || Decoder Loss:  0.0061587775 Validation Decoder Loss:  0.38942835
Encoder Loss:  0.05421073  || Decoder Loss:  0.0060950434 Validation Decoder Loss:  0.38953626
Encoder Loss:  0.053781245  || Decoder Loss:  0.006043515 Validation Decoder Loss:  0.38963795
Encoder Loss:  0.05339359  || Decoder Loss:  0.0059922365 Validation Decoder Loss:  0.38970304
Encoder Loss:  0.05304029  || Decoder Loss:  0.0059475526 Validation Decoder Loss:  0.38974312
Encoder Loss:  0.05268852  || Decoder Loss:  0.005899624 Validation Decoder Loss:  0.38976252
Encoder Loss:  0.05234648  || Decoder Loss:  0.0058485866 Validation Decoder Loss:  0.38981023
Encoder Loss:  0.052018236  || Decoder Loss:  0.0058030784 Validation Decoder Loss:  0.38982224
Encoder Loss:  0.0516963  || Decoder Loss:  0.0057591433 Validation Decoder Loss:  0.38989604
Encoder Loss:  0.05138515  || Decoder Loss:  0.0057278695 Validation Decoder Loss:  0.38994792
Encoder Loss:  0.051064562  || Decoder Loss:  0.005691697 Validation Decoder Loss:  0.39002872
Encoder Loss:  0.050734054  || Decoder Loss:  0.0056484505 Validation Decoder Loss:  0.39014953
Encoder Loss:  0.050392278  || Decoder Loss:  0.0056038727 Validation Decoder Loss:  0.39020628
Encoder Loss:  0.050058953  || Decoder Loss:  0.0055708387 Validation Decoder Loss:  0.39017665
Encoder Loss:  0.049739614  || Decoder Loss:  0.005549182 Validation Decoder Loss:  0.39011514
Encoder Loss:  0.049422707  || Decoder Loss:  0.0055282298 Validation Decoder Loss:  0.39005607
Encoder Loss:  0.049111523  || Decoder Loss:  0.005510731 Validation Decoder Loss:  0.3900294
Encoder Loss:  0.048814844  || Decoder Loss:  0.005493037 Validation Decoder Loss:  0.39000612
Encoder Loss:  0.048524335  || Decoder Loss:  0.005474132 Validation Decoder Loss:  0.3899485
Encoder Loss:  0.048232995  || Decoder Loss:  0.005452712 Validation Decoder Loss:  0.3898474
Encoder Loss:  0.04793948  || Decoder Loss:  0.005427178 Validation Decoder Loss:  0.38973027
Encoder Loss:  0.047655426  || Decoder Loss:  0.0053957324 Validation Decoder Loss:  0.38958925
Encoder Loss:  0.047399547  || Decoder Loss:  0.0053730384 Validation Decoder Loss:  0.389486
Encoder Loss:  0.047159888  || Decoder Loss:  0.005357876 Validation Decoder Loss:  0.38941044
Encoder Loss:  0.0469172  || Decoder Loss:  0.0053436058 Validation Decoder Loss:  0.38932332
Encoder Loss:  0.046662066  || Decoder Loss:  0.0053120153 Validation Decoder Loss:  0.38921064
Encoder Loss:  0.04640375  || Decoder Loss:  0.005262554 Validation Decoder Loss:  0.38903362
Encoder Loss:  0.04616765  || Decoder Loss:  0.0052291895 Validation Decoder Loss:  0.3888728
Encoder Loss:  0.045949563  || Decoder Loss:  0.005204023 Validation Decoder Loss:  0.38871908
Encoder Loss:  0.04573786  || Decoder Loss:  0.0051838364 Validation Decoder Loss:  0.3885588
Encoder Loss:  0.045532238  || Decoder Loss:  0.0051681884 Validation Decoder Loss:  0.38837355
Encoder Loss:  0.04534126  || Decoder Loss:  0.0051511806 Validation Decoder Loss:  0.38813835
Encoder Loss:  0.04515864  || Decoder Loss:  0.0051303105 Validation Decoder Loss:  0.38786456
Encoder Loss:  0.04497803  || Decoder Loss:  0.0051138964 Validation Decoder Loss:  0.38764632
Encoder Loss:  0.04480059  || Decoder Loss:  0.005102376 Validation Decoder Loss:  0.3874713
Model: bold_synthesis_net_lr_0.00019835210265856028 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3874713
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 71, 20, 16, 1)     97        
_________________________________________________________________
reshape_23 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.014885105  || Decoder Loss:  0.005897526 Validation Decoder Loss:  0.3814591
Encoder Loss:  0.013264988  || Decoder Loss:  0.00526653 Validation Decoder Loss:  0.38211763
Encoder Loss:  0.011736746  || Decoder Loss:  0.0050139837 Validation Decoder Loss:  0.3836875
Encoder Loss:  0.0106869275  || Decoder Loss:  0.004763978 Validation Decoder Loss:  0.38504407
Encoder Loss:  0.010122324  || Decoder Loss:  0.00459768 Validation Decoder Loss:  0.38936388
Encoder Loss:  0.009719914  || Decoder Loss:  0.004451168 Validation Decoder Loss:  0.39613485
Encoder Loss:  0.009360652  || Decoder Loss:  0.004259993 Validation Decoder Loss:  0.40317145
Encoder Loss:  0.009074853  || Decoder Loss:  0.004144086 Validation Decoder Loss:  0.4152996
Encoder Loss:  0.008588585  || Decoder Loss:  0.0039667906 Validation Decoder Loss:  0.43104643
Encoder Loss:  0.008117989  || Decoder Loss:  0.003874408 Validation Decoder Loss:  0.43977296
Encoder Loss:  0.007696804  || Decoder Loss:  0.0037721733 Validation Decoder Loss:  0.43882316
Encoder Loss:  0.007355508  || Decoder Loss:  0.0036530078 Validation Decoder Loss:  0.43634593
Encoder Loss:  0.007093682  || Decoder Loss:  0.0035076616 Validation Decoder Loss:  0.4331702
Encoder Loss:  0.0068497346  || Decoder Loss:  0.0033782332 Validation Decoder Loss:  0.42653346
Encoder Loss:  0.00637297  || Decoder Loss:  0.002986179 Validation Decoder Loss:  0.42152506
Encoder Loss:  0.006099854  || Decoder Loss:  0.0027591994 Validation Decoder Loss:  0.41437954
Encoder Loss:  0.005913587  || Decoder Loss:  0.002615256 Validation Decoder Loss:  0.40701458
Encoder Loss:  0.0057734395  || Decoder Loss:  0.0025104743 Validation Decoder Loss:  0.39787805
Encoder Loss:  0.005617616  || Decoder Loss:  0.0023708353 Validation Decoder Loss:  0.3851573
Encoder Loss:  0.0054836785  || Decoder Loss:  0.0022500388 Validation Decoder Loss:  0.3760255
Encoder Loss:  0.005345051  || Decoder Loss:  0.0021167204 Validation Decoder Loss:  0.3649355
Encoder Loss:  0.005212785  || Decoder Loss:  0.0019857066 Validation Decoder Loss:  0.35789186
Encoder Loss:  0.0051246765  || Decoder Loss:  0.0019005382 Validation Decoder Loss:  0.349956
Encoder Loss:  0.0050295903  || Decoder Loss:  0.0018071167 Validation Decoder Loss:  0.34482884
Encoder Loss:  0.0049468083  || Decoder Loss:  0.00172609 Validation Decoder Loss:  0.33781523
Encoder Loss:  0.004890482  || Decoder Loss:  0.0016726499 Validation Decoder Loss:  0.33514574
Encoder Loss:  0.0048489543  || Decoder Loss:  0.001635623 Validation Decoder Loss:  0.33142883
Encoder Loss:  0.004820704  || Decoder Loss:  0.0016125047 Validation Decoder Loss:  0.32758254
Encoder Loss:  0.004782167  || Decoder Loss:  0.0015774596 Validation Decoder Loss:  0.3243484
Encoder Loss:  0.004746685  || Decoder Loss:  0.0015449506 Validation Decoder Loss:  0.3206952
Encoder Loss:  0.0047074114  || Decoder Loss:  0.0015076522 Validation Decoder Loss:  0.31920046
Encoder Loss:  0.0046770293  || Decoder Loss:  0.0014798779 Validation Decoder Loss:  0.31822878
Encoder Loss:  0.0046475823  || Decoder Loss:  0.0014530129 Validation Decoder Loss:  0.31433648
Encoder Loss:  0.004599182  || Decoder Loss:  0.0014047071 Validation Decoder Loss:  0.3108709
Encoder Loss:  0.004562881  || Decoder Loss:  0.0013695314 Validation Decoder Loss:  0.3081094
Encoder Loss:  0.004527233  || Decoder Loss:  0.0013336261 Validation Decoder Loss:  0.30623606
Encoder Loss:  0.0044855196  || Decoder Loss:  0.0012910926 Validation Decoder Loss:  0.3019327
Encoder Loss:  0.004461701  || Decoder Loss:  0.0012676013 Validation Decoder Loss:  0.30023205
Encoder Loss:  0.004432528  || Decoder Loss:  0.0012381832 Validation Decoder Loss:  0.29515922
Encoder Loss:  0.004410228  || Decoder Loss:  0.001215802 Validation Decoder Loss:  0.29526377
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.29526377
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 71, 20, 16, 1)     129       
_________________________________________________________________
reshape_24 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.015652178  || Decoder Loss:  0.00545581 Validation Decoder Loss:  0.37271416
Encoder Loss:  0.014139395  || Decoder Loss:  0.0052206055 Validation Decoder Loss:  0.3703624
Encoder Loss:  0.012884833  || Decoder Loss:  0.0050835414 Validation Decoder Loss:  0.37209374
Encoder Loss:  0.011428641  || Decoder Loss:  0.004817729 Validation Decoder Loss:  0.37513
Encoder Loss:  0.01079303  || Decoder Loss:  0.00467428 Validation Decoder Loss:  0.37860683
Encoder Loss:  0.010447212  || Decoder Loss:  0.004649717 Validation Decoder Loss:  0.38199747
Encoder Loss:  0.010021634  || Decoder Loss:  0.004556613 Validation Decoder Loss:  0.3934297
Encoder Loss:  0.009380591  || Decoder Loss:  0.0044068475 Validation Decoder Loss:  0.40597224
Encoder Loss:  0.008530101  || Decoder Loss:  0.0042999713 Validation Decoder Loss:  0.4262899
Encoder Loss:  0.0077658608  || Decoder Loss:  0.0041328603 Validation Decoder Loss:  0.43885338
Encoder Loss:  0.0072882683  || Decoder Loss:  0.003826795 Validation Decoder Loss:  0.4432564
Encoder Loss:  0.0067121205  || Decoder Loss:  0.0033123142 Validation Decoder Loss:  0.44333154
Encoder Loss:  0.0064125285  || Decoder Loss:  0.0030744406 Validation Decoder Loss:  0.44337937
Encoder Loss:  0.0062120594  || Decoder Loss:  0.0029049153 Validation Decoder Loss:  0.43553275
Encoder Loss:  0.0059138276  || Decoder Loss:  0.0026161526 Validation Decoder Loss:  0.42943764
Encoder Loss:  0.005771913  || Decoder Loss:  0.0024879263 Validation Decoder Loss:  0.42652738
Encoder Loss:  0.005602258  || Decoder Loss:  0.0023250754 Validation Decoder Loss:  0.41952962
Encoder Loss:  0.005437807  || Decoder Loss:  0.0021652717 Validation Decoder Loss:  0.40668738
Encoder Loss:  0.0052517145  || Decoder Loss:  0.001976335 Validation Decoder Loss:  0.39325225
Encoder Loss:  0.005114931  || Decoder Loss:  0.0018393999 Validation Decoder Loss:  0.3872921
Encoder Loss:  0.0050508273  || Decoder Loss:  0.0017796241 Validation Decoder Loss:  0.38015258
Encoder Loss:  0.0049865786  || Decoder Loss:  0.001718947 Validation Decoder Loss:  0.37616485
Encoder Loss:  0.0049312995  || Decoder Loss:  0.0016656618 Validation Decoder Loss:  0.3728848
Encoder Loss:  0.0048713065  || Decoder Loss:  0.0016066813 Validation Decoder Loss:  0.3672819
Encoder Loss:  0.0048203226  || Decoder Loss:  0.0015561448 Validation Decoder Loss:  0.35990483
Encoder Loss:  0.004773338  || Decoder Loss:  0.0015092252 Validation Decoder Loss:  0.35536972
Encoder Loss:  0.0047310544  || Decoder Loss:  0.0014664199 Validation Decoder Loss:  0.34934324
Encoder Loss:  0.004692373  || Decoder Loss:  0.0014270786 Validation Decoder Loss:  0.3465054
Encoder Loss:  0.0046577933  || Decoder Loss:  0.0013922618 Validation Decoder Loss:  0.34168398
Encoder Loss:  0.004628902  || Decoder Loss:  0.001363358 Validation Decoder Loss:  0.33630437
Encoder Loss:  0.00460689  || Decoder Loss:  0.0013414951 Validation Decoder Loss:  0.3303181
Encoder Loss:  0.0045844847  || Decoder Loss:  0.0013197182 Validation Decoder Loss:  0.32441205
Encoder Loss:  0.004554163  || Decoder Loss:  0.0012896963 Validation Decoder Loss:  0.3168375
Encoder Loss:  0.0045360313  || Decoder Loss:  0.0012701874 Validation Decoder Loss:  0.31291652
Encoder Loss:  0.004513246  || Decoder Loss:  0.0012485016 Validation Decoder Loss:  0.30753714
Encoder Loss:  0.004494777  || Decoder Loss:  0.001228994 Validation Decoder Loss:  0.30212656
Encoder Loss:  0.004476403  || Decoder Loss:  0.0012109187 Validation Decoder Loss:  0.29775983
Encoder Loss:  0.0044555743  || Decoder Loss:  0.0011893993 Validation Decoder Loss:  0.29407606
Encoder Loss:  0.0044377674  || Decoder Loss:  0.0011707763 Validation Decoder Loss:  0.28907108
Encoder Loss:  0.0044211484  || Decoder Loss:  0.0011535264 Validation Decoder Loss:  0.2853275
Model: bold_synthesis_net_lr_0.0009354424881962922 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.28532743
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 71, 20, 16, 1)     97        
_________________________________________________________________
reshape_25 (Reshape)         (None, 1420, 16, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 1420, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2607, 16, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08933545  || Decoder Loss:  0.0065487716 Validation Decoder Loss:  0.3808239
Encoder Loss:  0.0885181  || Decoder Loss:  0.006368905 Validation Decoder Loss:  0.3804915
Encoder Loss:  0.08771912  || Decoder Loss:  0.0062298086 Validation Decoder Loss:  0.38011226
Encoder Loss:  0.08688106  || Decoder Loss:  0.006112997 Validation Decoder Loss:  0.3799411
Encoder Loss:  0.086051404  || Decoder Loss:  0.00600603 Validation Decoder Loss:  0.37972498
Encoder Loss:  0.08528083  || Decoder Loss:  0.005930159 Validation Decoder Loss:  0.3795333
Encoder Loss:  0.08449086  || Decoder Loss:  0.0058629345 Validation Decoder Loss:  0.3794242
Encoder Loss:  0.0835999  || Decoder Loss:  0.00579885 Validation Decoder Loss:  0.37930593
Encoder Loss:  0.082596704  || Decoder Loss:  0.0057531903 Validation Decoder Loss:  0.37916383
Encoder Loss:  0.08153963  || Decoder Loss:  0.005712591 Validation Decoder Loss:  0.37906754
Encoder Loss:  0.08056483  || Decoder Loss:  0.0056676134 Validation Decoder Loss:  0.3789892
Encoder Loss:  0.079641715  || Decoder Loss:  0.005607527 Validation Decoder Loss:  0.37894055
Encoder Loss:  0.078770414  || Decoder Loss:  0.005537008 Validation Decoder Loss:  0.37892443
Encoder Loss:  0.0779713  || Decoder Loss:  0.005482785 Validation Decoder Loss:  0.37890896
Encoder Loss:  0.077251524  || Decoder Loss:  0.005417836 Validation Decoder Loss:  0.37889645
Encoder Loss:  0.07663817  || Decoder Loss:  0.0053581875 Validation Decoder Loss:  0.3787866
Encoder Loss:  0.07609619  || Decoder Loss:  0.0053105606 Validation Decoder Loss:  0.3786783
Encoder Loss:  0.07554921  || Decoder Loss:  0.0052821273 Validation Decoder Loss:  0.3785377
Encoder Loss:  0.07493456  || Decoder Loss:  0.0052597877 Validation Decoder Loss:  0.3784275
Encoder Loss:  0.07422831  || Decoder Loss:  0.0052314065 Validation Decoder Loss:  0.37837994
Encoder Loss:  0.073382296  || Decoder Loss:  0.005196382 Validation Decoder Loss:  0.378425
Encoder Loss:  0.072433874  || Decoder Loss:  0.005169315 Validation Decoder Loss:  0.3787052
Encoder Loss:  0.07141964  || Decoder Loss:  0.005149599 Validation Decoder Loss:  0.3790743
Encoder Loss:  0.070251614  || Decoder Loss:  0.005135165 Validation Decoder Loss:  0.37953272
Encoder Loss:  0.0690398  || Decoder Loss:  0.005127251 Validation Decoder Loss:  0.37999463
Encoder Loss:  0.06776971  || Decoder Loss:  0.0051241736 Validation Decoder Loss:  0.38041723
Encoder Loss:  0.06634179  || Decoder Loss:  0.0051194225 Validation Decoder Loss:  0.38085318
Encoder Loss:  0.06515285  || Decoder Loss:  0.005117514 Validation Decoder Loss:  0.38126045
Encoder Loss:  0.06428641  || Decoder Loss:  0.005113862 Validation Decoder Loss:  0.38156268
Encoder Loss:  0.0634979  || Decoder Loss:  0.0051097116 Validation Decoder Loss:  0.38180703
Encoder Loss:  0.06282512  || Decoder Loss:  0.00510722 Validation Decoder Loss:  0.3820405
Encoder Loss:  0.06217759  || Decoder Loss:  0.0051003615 Validation Decoder Loss:  0.38225636
Encoder Loss:  0.061645597  || Decoder Loss:  0.0050867037 Validation Decoder Loss:  0.3823984
Encoder Loss:  0.06114756  || Decoder Loss:  0.0050698924 Validation Decoder Loss:  0.3824978
Encoder Loss:  0.060640782  || Decoder Loss:  0.005053693 Validation Decoder Loss:  0.38261038
Encoder Loss:  0.060147893  || Decoder Loss:  0.0050356705 Validation Decoder Loss:  0.38276234
Encoder Loss:  0.059655998  || Decoder Loss:  0.0050171292 Validation Decoder Loss:  0.38291106
Encoder Loss:  0.059145592  || Decoder Loss:  0.004995664 Validation Decoder Loss:  0.38307196
Encoder Loss:  0.058650505  || Decoder Loss:  0.0049829884 Validation Decoder Loss:  0.38323623
Encoder Loss:  0.058178816  || Decoder Loss:  0.004974842 Validation Decoder Loss:  0.38337773
Model: bold_synthesis_net_lr_0.00015202029000670506 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.38337773
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 70, 26, 16, 1)     99        
_________________________________________________________________
reshape_26 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051153876  || Decoder Loss:  0.009504692 Validation Decoder Loss:  0.37761435
Encoder Loss:  0.041811462  || Decoder Loss:  0.006663617 Validation Decoder Loss:  0.37876585
Encoder Loss:  0.03884215  || Decoder Loss:  0.006070862 Validation Decoder Loss:  0.38838884
Encoder Loss:  0.037140492  || Decoder Loss:  0.0058185467 Validation Decoder Loss:  0.39435995
Encoder Loss:  0.035692465  || Decoder Loss:  0.00574205 Validation Decoder Loss:  0.3997364
Encoder Loss:  0.034853827  || Decoder Loss:  0.00551064 Validation Decoder Loss:  0.40005416
Encoder Loss:  0.034280177  || Decoder Loss:  0.0053257644 Validation Decoder Loss:  0.39868498
Encoder Loss:  0.033770885  || Decoder Loss:  0.0053229704 Validation Decoder Loss:  0.39658716
Encoder Loss:  0.033265956  || Decoder Loss:  0.005344016 Validation Decoder Loss:  0.39262933
Encoder Loss:  0.03261798  || Decoder Loss:  0.0052969847 Validation Decoder Loss:  0.3841154
Encoder Loss:  0.03176354  || Decoder Loss:  0.005305417 Validation Decoder Loss:  0.37094226
Encoder Loss:  0.030821087  || Decoder Loss:  0.0051886514 Validation Decoder Loss:  0.35251898
Encoder Loss:  0.02972058  || Decoder Loss:  0.0048997337 Validation Decoder Loss:  0.32452345
Encoder Loss:  0.028645718  || Decoder Loss:  0.0045127855 Validation Decoder Loss:  0.30253825
Encoder Loss:  0.027897436  || Decoder Loss:  0.0043326276 Validation Decoder Loss:  0.27755696
Encoder Loss:  0.027183233  || Decoder Loss:  0.003909218 Validation Decoder Loss:  0.24794662
Encoder Loss:  0.026598718  || Decoder Loss:  0.0036520555 Validation Decoder Loss:  0.23084566
Encoder Loss:  0.026098728  || Decoder Loss:  0.0033343474 Validation Decoder Loss:  0.21623528
Encoder Loss:  0.02563104  || Decoder Loss:  0.0029724848 Validation Decoder Loss:  0.20339158
Encoder Loss:  0.025227956  || Decoder Loss:  0.002563329 Validation Decoder Loss:  0.18963926
Encoder Loss:  0.02489202  || Decoder Loss:  0.0022406804 Validation Decoder Loss:  0.1793778
Encoder Loss:  0.02467214  || Decoder Loss:  0.0020819467 Validation Decoder Loss:  0.17466079
Encoder Loss:  0.024462976  || Decoder Loss:  0.00189184 Validation Decoder Loss:  0.16514355
Encoder Loss:  0.02428957  || Decoder Loss:  0.0016961092 Validation Decoder Loss:  0.16157125
Encoder Loss:  0.02419126  || Decoder Loss:  0.0016129795 Validation Decoder Loss:  0.15737344
Encoder Loss:  0.024092657  || Decoder Loss:  0.0015216664 Validation Decoder Loss:  0.15434927
Encoder Loss:  0.024003506  || Decoder Loss:  0.0014428947 Validation Decoder Loss:  0.15046148
Encoder Loss:  0.023910636  || Decoder Loss:  0.0013561886 Validation Decoder Loss:  0.14788854
Encoder Loss:  0.023831164  || Decoder Loss:  0.0013004047 Validation Decoder Loss:  0.14477214
Encoder Loss:  0.023753583  || Decoder Loss:  0.0012432982 Validation Decoder Loss:  0.14499584
Encoder Loss:  0.023692193  || Decoder Loss:  0.0012033969 Validation Decoder Loss:  0.14434351
Encoder Loss:  0.0236396  || Decoder Loss:  0.0011739006 Validation Decoder Loss:  0.1433649
Encoder Loss:  0.023586912  || Decoder Loss:  0.0011400694 Validation Decoder Loss:  0.14262997
Encoder Loss:  0.023544386  || Decoder Loss:  0.0011133894 Validation Decoder Loss:  0.1406936
Encoder Loss:  0.02350266  || Decoder Loss:  0.0010829784 Validation Decoder Loss:  0.14158487
Encoder Loss:  0.023463456  || Decoder Loss:  0.0010492451 Validation Decoder Loss:  0.14213882
Encoder Loss:  0.02343331  || Decoder Loss:  0.0010274906 Validation Decoder Loss:  0.14032471
Encoder Loss:  0.023402628  || Decoder Loss:  0.0010103509 Validation Decoder Loss:  0.14016098
Encoder Loss:  0.023376023  || Decoder Loss:  0.0009988652 Validation Decoder Loss:  0.14002925
Encoder Loss:  0.023341114  || Decoder Loss:  0.0009706056 Validation Decoder Loss:  0.13908355
Model: bold_synthesis_net_lr_0.0002540353544830422 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.13908356
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 260, 7, 16, 1)     25        
_________________________________________________________________
reshape_27 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05951991  || Decoder Loss:  0.00867827 Validation Decoder Loss:  0.3182608
Encoder Loss:  0.046767898  || Decoder Loss:  0.0071840133 Validation Decoder Loss:  0.35245234
Encoder Loss:  0.03727671  || Decoder Loss:  0.006123265 Validation Decoder Loss:  0.38379464
Encoder Loss:  0.034110587  || Decoder Loss:  0.0054447833 Validation Decoder Loss:  0.3984164
Encoder Loss:  0.032791924  || Decoder Loss:  0.004896373 Validation Decoder Loss:  0.39932936
Encoder Loss:  0.032004364  || Decoder Loss:  0.0045777992 Validation Decoder Loss:  0.39641342
Encoder Loss:  0.031366307  || Decoder Loss:  0.0043371296 Validation Decoder Loss:  0.39437282
Encoder Loss:  0.030726017  || Decoder Loss:  0.0041286377 Validation Decoder Loss:  0.39390922
Encoder Loss:  0.0301551  || Decoder Loss:  0.0039585982 Validation Decoder Loss:  0.39270097
Encoder Loss:  0.029631188  || Decoder Loss:  0.0037940843 Validation Decoder Loss:  0.38928282
Encoder Loss:  0.029083526  || Decoder Loss:  0.0036479167 Validation Decoder Loss:  0.3868167
Encoder Loss:  0.028614039  || Decoder Loss:  0.0035474878 Validation Decoder Loss:  0.3861205
Encoder Loss:  0.028198536  || Decoder Loss:  0.0034661505 Validation Decoder Loss:  0.38332143
Encoder Loss:  0.027782204  || Decoder Loss:  0.0033773202 Validation Decoder Loss:  0.3800767
Encoder Loss:  0.027378445  || Decoder Loss:  0.0033108385 Validation Decoder Loss:  0.37559992
Encoder Loss:  0.026995549  || Decoder Loss:  0.0032901037 Validation Decoder Loss:  0.3650133
Encoder Loss:  0.026554765  || Decoder Loss:  0.003230863 Validation Decoder Loss:  0.35034007
Encoder Loss:  0.026095757  || Decoder Loss:  0.0032862548 Validation Decoder Loss:  0.33062565
Encoder Loss:  0.025669694  || Decoder Loss:  0.0033527997 Validation Decoder Loss:  0.29907402
Encoder Loss:  0.025278274  || Decoder Loss:  0.0032850406 Validation Decoder Loss:  0.26629663
Encoder Loss:  0.024917202  || Decoder Loss:  0.0031511628 Validation Decoder Loss:  0.26109433
Encoder Loss:  0.02461043  || Decoder Loss:  0.0029980808 Validation Decoder Loss:  0.25543347
Encoder Loss:  0.024314208  || Decoder Loss:  0.0026791634 Validation Decoder Loss:  0.23721083
Encoder Loss:  0.024081016  || Decoder Loss:  0.0023657402 Validation Decoder Loss:  0.2279485
Encoder Loss:  0.02391037  || Decoder Loss:  0.0021036624 Validation Decoder Loss:  0.22155455
Encoder Loss:  0.02380087  || Decoder Loss:  0.00194506 Validation Decoder Loss:  0.216346
Encoder Loss:  0.023710562  || Decoder Loss:  0.0018088358 Validation Decoder Loss:  0.21173829
Encoder Loss:  0.023629576  || Decoder Loss:  0.0016796658 Validation Decoder Loss:  0.20627178
Encoder Loss:  0.023568776  || Decoder Loss:  0.0015929719 Validation Decoder Loss:  0.20132397
Encoder Loss:  0.023510506  || Decoder Loss:  0.0015098428 Validation Decoder Loss:  0.19584551
Encoder Loss:  0.023459638  || Decoder Loss:  0.0014466476 Validation Decoder Loss:  0.19342476
Encoder Loss:  0.023422534  || Decoder Loss:  0.0014030371 Validation Decoder Loss:  0.19188175
Encoder Loss:  0.023392232  || Decoder Loss:  0.0013666378 Validation Decoder Loss:  0.18835244
Encoder Loss:  0.02336201  || Decoder Loss:  0.0013246621 Validation Decoder Loss:  0.1844636
Encoder Loss:  0.023331473  || Decoder Loss:  0.001281256 Validation Decoder Loss:  0.18176544
Encoder Loss:  0.023303883  || Decoder Loss:  0.0012424143 Validation Decoder Loss:  0.17769822
Encoder Loss:  0.023275778  || Decoder Loss:  0.0012051559 Validation Decoder Loss:  0.17157468
Encoder Loss:  0.02324689  || Decoder Loss:  0.0011582058 Validation Decoder Loss:  0.16626981
Encoder Loss:  0.023220163  || Decoder Loss:  0.001111752 Validation Decoder Loss:  0.16059078
Encoder Loss:  0.023197953  || Decoder Loss:  0.001072442 Validation Decoder Loss:  0.15528458
Model: bold_synthesis_net_lr_0.00025403517759956814 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.15528458
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 70, 26, 16, 1)     43        
_________________________________________________________________
reshape_28 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 43
Trainable params: 43
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04469462  || Decoder Loss:  0.008504922 Validation Decoder Loss:  0.36435598
Encoder Loss:  0.040069085  || Decoder Loss:  0.0062211407 Validation Decoder Loss:  0.37440324
Encoder Loss:  0.03853176  || Decoder Loss:  0.0055903653 Validation Decoder Loss:  0.38060588
Encoder Loss:  0.037550885  || Decoder Loss:  0.005623769 Validation Decoder Loss:  0.3875563
Encoder Loss:  0.036310807  || Decoder Loss:  0.0057542208 Validation Decoder Loss:  0.39769083
Encoder Loss:  0.035125826  || Decoder Loss:  0.0056740334 Validation Decoder Loss:  0.40306258
Encoder Loss:  0.03428027  || Decoder Loss:  0.0054630963 Validation Decoder Loss:  0.40525538
Encoder Loss:  0.03363564  || Decoder Loss:  0.00526368 Validation Decoder Loss:  0.40771157
Encoder Loss:  0.033085655  || Decoder Loss:  0.004992841 Validation Decoder Loss:  0.40608436
Encoder Loss:  0.032579806  || Decoder Loss:  0.0046876725 Validation Decoder Loss:  0.40510657
Encoder Loss:  0.03206242  || Decoder Loss:  0.0044775847 Validation Decoder Loss:  0.40346682
Encoder Loss:  0.03156648  || Decoder Loss:  0.004251385 Validation Decoder Loss:  0.4027775
Encoder Loss:  0.031124583  || Decoder Loss:  0.00405061 Validation Decoder Loss:  0.39891645
Encoder Loss:  0.030665897  || Decoder Loss:  0.003912278 Validation Decoder Loss:  0.3942565
Encoder Loss:  0.030183382  || Decoder Loss:  0.0038034252 Validation Decoder Loss:  0.38972065
Encoder Loss:  0.029649882  || Decoder Loss:  0.0037363754 Validation Decoder Loss:  0.38523087
Encoder Loss:  0.029086908  || Decoder Loss:  0.0035903503 Validation Decoder Loss:  0.3828319
Encoder Loss:  0.028558554  || Decoder Loss:  0.003506934 Validation Decoder Loss:  0.38020205
Encoder Loss:  0.028090037  || Decoder Loss:  0.0034606757 Validation Decoder Loss:  0.37661892
Encoder Loss:  0.027691144  || Decoder Loss:  0.0034118535 Validation Decoder Loss:  0.3717749
Encoder Loss:  0.027284622  || Decoder Loss:  0.0033327492 Validation Decoder Loss:  0.36580765
Encoder Loss:  0.026923724  || Decoder Loss:  0.0032504674 Validation Decoder Loss:  0.36240894
Encoder Loss:  0.02666599  || Decoder Loss:  0.0031992642 Validation Decoder Loss:  0.3579707
Encoder Loss:  0.02642102  || Decoder Loss:  0.0031356358 Validation Decoder Loss:  0.35459393
Encoder Loss:  0.026243642  || Decoder Loss:  0.0030870163 Validation Decoder Loss:  0.35165367
Encoder Loss:  0.02611881  || Decoder Loss:  0.0030837767 Validation Decoder Loss:  0.3496512
Encoder Loss:  0.02600449  || Decoder Loss:  0.0030845697 Validation Decoder Loss:  0.34739286
Encoder Loss:  0.025850642  || Decoder Loss:  0.0030492293 Validation Decoder Loss:  0.34490913
Encoder Loss:  0.025682176  || Decoder Loss:  0.0029718226 Validation Decoder Loss:  0.34198272
Encoder Loss:  0.025521157  || Decoder Loss:  0.0028909927 Validation Decoder Loss:  0.3390165
Encoder Loss:  0.025364377  || Decoder Loss:  0.002797249 Validation Decoder Loss:  0.3357613
Encoder Loss:  0.025212107  || Decoder Loss:  0.0027118651 Validation Decoder Loss:  0.33271134
Encoder Loss:  0.025073763  || Decoder Loss:  0.0026133705 Validation Decoder Loss:  0.32976556
Encoder Loss:  0.02495831  || Decoder Loss:  0.0025342891 Validation Decoder Loss:  0.32759878
Encoder Loss:  0.024858633  || Decoder Loss:  0.0024847647 Validation Decoder Loss:  0.32626456
Encoder Loss:  0.024774289  || Decoder Loss:  0.0024495667 Validation Decoder Loss:  0.32489103
Encoder Loss:  0.024694365  || Decoder Loss:  0.0024146645 Validation Decoder Loss:  0.32345432
Encoder Loss:  0.024616994  || Decoder Loss:  0.0023888699 Validation Decoder Loss:  0.3222286
Encoder Loss:  0.024531113  || Decoder Loss:  0.002337851 Validation Decoder Loss:  0.32120913
Encoder Loss:  0.024451178  || Decoder Loss:  0.0022905094 Validation Decoder Loss:  0.31937426
Model: bold_synthesis_net_lr_0.0002540345150089726 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.31937426
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 260, 7, 16, 1)     592       
_________________________________________________________________
reshape_29 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 592
Trainable params: 592
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035092715  || Decoder Loss:  0.00446175 Validation Decoder Loss:  0.43987787
Encoder Loss:  0.03287547  || Decoder Loss:  0.0043630856 Validation Decoder Loss:  0.43865883
Encoder Loss:  0.0319484  || Decoder Loss:  0.004262901 Validation Decoder Loss:  0.43805486
Encoder Loss:  0.03150118  || Decoder Loss:  0.004154077 Validation Decoder Loss:  0.43659925
Encoder Loss:  0.031133771  || Decoder Loss:  0.0040810145 Validation Decoder Loss:  0.43501487
Encoder Loss:  0.03078452  || Decoder Loss:  0.0040307227 Validation Decoder Loss:  0.4341119
Encoder Loss:  0.030412959  || Decoder Loss:  0.003996806 Validation Decoder Loss:  0.43247268
Encoder Loss:  0.030082813  || Decoder Loss:  0.0039888523 Validation Decoder Loss:  0.4327911
Encoder Loss:  0.029801495  || Decoder Loss:  0.003954148 Validation Decoder Loss:  0.43307173
Encoder Loss:  0.029530147  || Decoder Loss:  0.003930849 Validation Decoder Loss:  0.4327315
Encoder Loss:  0.029232332  || Decoder Loss:  0.0039049776 Validation Decoder Loss:  0.43234435
Encoder Loss:  0.028883442  || Decoder Loss:  0.0038713212 Validation Decoder Loss:  0.43227196
Encoder Loss:  0.028499763  || Decoder Loss:  0.0038382027 Validation Decoder Loss:  0.4320324
Encoder Loss:  0.028072039  || Decoder Loss:  0.003807605 Validation Decoder Loss:  0.43149203
Encoder Loss:  0.027695574  || Decoder Loss:  0.0037804453 Validation Decoder Loss:  0.4311763
Encoder Loss:  0.027330345  || Decoder Loss:  0.0037431088 Validation Decoder Loss:  0.43122524
Encoder Loss:  0.026991263  || Decoder Loss:  0.0036857834 Validation Decoder Loss:  0.43103448
Encoder Loss:  0.026672238  || Decoder Loss:  0.0036431304 Validation Decoder Loss:  0.43129456
Encoder Loss:  0.026371775  || Decoder Loss:  0.0036129684 Validation Decoder Loss:  0.4316379
Encoder Loss:  0.026056206  || Decoder Loss:  0.003594384 Validation Decoder Loss:  0.43179217
Encoder Loss:  0.025756167  || Decoder Loss:  0.0035747339 Validation Decoder Loss:  0.4319565
Encoder Loss:  0.025523257  || Decoder Loss:  0.0035501686 Validation Decoder Loss:  0.43199208
Encoder Loss:  0.025350852  || Decoder Loss:  0.0035262692 Validation Decoder Loss:  0.43207803
Encoder Loss:  0.025209773  || Decoder Loss:  0.0035024032 Validation Decoder Loss:  0.43230274
Encoder Loss:  0.025083762  || Decoder Loss:  0.0034804305 Validation Decoder Loss:  0.43234658
Encoder Loss:  0.024975564  || Decoder Loss:  0.003457357 Validation Decoder Loss:  0.4324078
Encoder Loss:  0.024895707  || Decoder Loss:  0.0034419168 Validation Decoder Loss:  0.4325018
Encoder Loss:  0.024829507  || Decoder Loss:  0.0034185846 Validation Decoder Loss:  0.43277043
Encoder Loss:  0.024772497  || Decoder Loss:  0.0033927483 Validation Decoder Loss:  0.43294135
Encoder Loss:  0.024718823  || Decoder Loss:  0.0033589061 Validation Decoder Loss:  0.4328522
Encoder Loss:  0.02466759  || Decoder Loss:  0.003325938 Validation Decoder Loss:  0.4327026
Encoder Loss:  0.024620095  || Decoder Loss:  0.003299097 Validation Decoder Loss:  0.43264002
Encoder Loss:  0.024579996  || Decoder Loss:  0.0032780787 Validation Decoder Loss:  0.4326421
Encoder Loss:  0.024534559  || Decoder Loss:  0.0032436852 Validation Decoder Loss:  0.43100515
Encoder Loss:  0.024489684  || Decoder Loss:  0.0031965538 Validation Decoder Loss:  0.43050882
Encoder Loss:  0.02445061  || Decoder Loss:  0.0031532533 Validation Decoder Loss:  0.4299637
Encoder Loss:  0.024415694  || Decoder Loss:  0.0031150403 Validation Decoder Loss:  0.42971882
Encoder Loss:  0.024384705  || Decoder Loss:  0.00308755 Validation Decoder Loss:  0.4295551
Encoder Loss:  0.024358444  || Decoder Loss:  0.0030624457 Validation Decoder Loss:  0.42930722
Encoder Loss:  0.024329718  || Decoder Loss:  0.003033565 Validation Decoder Loss:  0.42898393
Model: bold_synthesis_net_lr_0.00025404760091555953 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.42898396
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 65, 28, 16, 1)     25        
_________________________________________________________________
reshape_30 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05922689  || Decoder Loss:  0.0085379 Validation Decoder Loss:  0.31571454
Encoder Loss:  0.05115484  || Decoder Loss:  0.0072805304 Validation Decoder Loss:  0.3580406
Encoder Loss:  0.042741463  || Decoder Loss:  0.006227041 Validation Decoder Loss:  0.38610685
Encoder Loss:  0.037912402  || Decoder Loss:  0.0051965443 Validation Decoder Loss:  0.40364537
Encoder Loss:  0.035250694  || Decoder Loss:  0.004860217 Validation Decoder Loss:  0.41262412
Encoder Loss:  0.033754658  || Decoder Loss:  0.0045190696 Validation Decoder Loss:  0.4134686
Encoder Loss:  0.032963354  || Decoder Loss:  0.0043379185 Validation Decoder Loss:  0.4120205
Encoder Loss:  0.032199528  || Decoder Loss:  0.0042147413 Validation Decoder Loss:  0.4091
Encoder Loss:  0.031285454  || Decoder Loss:  0.0040792665 Validation Decoder Loss:  0.4026528
Encoder Loss:  0.030414753  || Decoder Loss:  0.003987868 Validation Decoder Loss:  0.39936745
Encoder Loss:  0.029622007  || Decoder Loss:  0.0039045853 Validation Decoder Loss:  0.3957919
Encoder Loss:  0.028819753  || Decoder Loss:  0.003763499 Validation Decoder Loss:  0.39197063
Encoder Loss:  0.02805027  || Decoder Loss:  0.0036206031 Validation Decoder Loss:  0.38803357
Encoder Loss:  0.027402056  || Decoder Loss:  0.0034666192 Validation Decoder Loss:  0.3869394
Encoder Loss:  0.026867181  || Decoder Loss:  0.0033513505 Validation Decoder Loss:  0.38661832
Encoder Loss:  0.026350176  || Decoder Loss:  0.0032303203 Validation Decoder Loss:  0.38528723
Encoder Loss:  0.025930135  || Decoder Loss:  0.0030946 Validation Decoder Loss:  0.38168412
Encoder Loss:  0.025659883  || Decoder Loss:  0.0030300815 Validation Decoder Loss:  0.3794965
Encoder Loss:  0.025470875  || Decoder Loss:  0.0029543878 Validation Decoder Loss:  0.3776245
Encoder Loss:  0.025314119  || Decoder Loss:  0.0028725956 Validation Decoder Loss:  0.37688804
Encoder Loss:  0.025183238  || Decoder Loss:  0.00280436 Validation Decoder Loss:  0.37537885
Encoder Loss:  0.025066717  || Decoder Loss:  0.0027456763 Validation Decoder Loss:  0.3735491
Encoder Loss:  0.024963148  || Decoder Loss:  0.002707039 Validation Decoder Loss:  0.37267965
Encoder Loss:  0.0249038  || Decoder Loss:  0.0027134996 Validation Decoder Loss:  0.3693009
Encoder Loss:  0.024847679  || Decoder Loss:  0.0026938152 Validation Decoder Loss:  0.3662691
Encoder Loss:  0.024780132  || Decoder Loss:  0.0026445799 Validation Decoder Loss:  0.36397368
Encoder Loss:  0.02470843  || Decoder Loss:  0.0025932784 Validation Decoder Loss:  0.3622458
Encoder Loss:  0.024645884  || Decoder Loss:  0.002544247 Validation Decoder Loss:  0.36065733
Encoder Loss:  0.024595808  || Decoder Loss:  0.0025032926 Validation Decoder Loss:  0.35862565
Encoder Loss:  0.02454344  || Decoder Loss:  0.002451181 Validation Decoder Loss:  0.35563967
Encoder Loss:  0.024496604  || Decoder Loss:  0.0024100477 Validation Decoder Loss:  0.35431653
Encoder Loss:  0.02444966  || Decoder Loss:  0.002360004 Validation Decoder Loss:  0.35261023
Encoder Loss:  0.02441149  || Decoder Loss:  0.0023246522 Validation Decoder Loss:  0.35015863
Encoder Loss:  0.024373105  || Decoder Loss:  0.0022923397 Validation Decoder Loss:  0.34860033
Encoder Loss:  0.02433583  || Decoder Loss:  0.0022679423 Validation Decoder Loss:  0.34627652
Encoder Loss:  0.024296623  || Decoder Loss:  0.002227027 Validation Decoder Loss:  0.34500247
Encoder Loss:  0.024259413  || Decoder Loss:  0.0021845952 Validation Decoder Loss:  0.34371346
Encoder Loss:  0.024228174  || Decoder Loss:  0.0021567387 Validation Decoder Loss:  0.34213355
Encoder Loss:  0.024204198  || Decoder Loss:  0.0021551636 Validation Decoder Loss:  0.3397789
Encoder Loss:  0.024176368  || Decoder Loss:  0.0021361085 Validation Decoder Loss:  0.33746606
Model: bold_synthesis_net_lr_0.0002540268783919354 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.33746606
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 364, 5, 16, 1)     50        
_________________________________________________________________
reshape_31 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04040398  || Decoder Loss:  0.0064492775 Validation Decoder Loss:  0.3800865
Encoder Loss:  0.03792255  || Decoder Loss:  0.0058846413 Validation Decoder Loss:  0.38738966
Encoder Loss:  0.03650587  || Decoder Loss:  0.0052491794 Validation Decoder Loss:  0.39197624
Encoder Loss:  0.035624705  || Decoder Loss:  0.0050575263 Validation Decoder Loss:  0.3935625
Encoder Loss:  0.03503222  || Decoder Loss:  0.005000568 Validation Decoder Loss:  0.3932814
Encoder Loss:  0.03447625  || Decoder Loss:  0.0049655363 Validation Decoder Loss:  0.3940611
Encoder Loss:  0.034060504  || Decoder Loss:  0.004985516 Validation Decoder Loss:  0.3941684
Encoder Loss:  0.03366929  || Decoder Loss:  0.0049937563 Validation Decoder Loss:  0.3942045
Encoder Loss:  0.03329134  || Decoder Loss:  0.0049901586 Validation Decoder Loss:  0.39316034
Encoder Loss:  0.03292919  || Decoder Loss:  0.0049952967 Validation Decoder Loss:  0.39121956
Encoder Loss:  0.03247968  || Decoder Loss:  0.0048905453 Validation Decoder Loss:  0.389457
Encoder Loss:  0.03200434  || Decoder Loss:  0.0048306338 Validation Decoder Loss:  0.3873714
Encoder Loss:  0.03154789  || Decoder Loss:  0.004708641 Validation Decoder Loss:  0.38557017
Encoder Loss:  0.031100322  || Decoder Loss:  0.0045653833 Validation Decoder Loss:  0.38371867
Encoder Loss:  0.030636705  || Decoder Loss:  0.00443212 Validation Decoder Loss:  0.38118458
Encoder Loss:  0.030137917  || Decoder Loss:  0.004237167 Validation Decoder Loss:  0.3768433
Encoder Loss:  0.029718269  || Decoder Loss:  0.00416937 Validation Decoder Loss:  0.37420204
Encoder Loss:  0.029343667  || Decoder Loss:  0.0040709046 Validation Decoder Loss:  0.37112197
Encoder Loss:  0.02899206  || Decoder Loss:  0.0039685094 Validation Decoder Loss:  0.36960483
Encoder Loss:  0.028637465  || Decoder Loss:  0.0039044688 Validation Decoder Loss:  0.3679089
Encoder Loss:  0.028319161  || Decoder Loss:  0.003902403 Validation Decoder Loss:  0.3650683
Encoder Loss:  0.027978197  || Decoder Loss:  0.0039024858 Validation Decoder Loss:  0.3607503
Encoder Loss:  0.027609667  || Decoder Loss:  0.0038887651 Validation Decoder Loss:  0.35589463
Encoder Loss:  0.02723683  || Decoder Loss:  0.0038913668 Validation Decoder Loss:  0.34664738
Encoder Loss:  0.026907109  || Decoder Loss:  0.003931452 Validation Decoder Loss:  0.33014345
Encoder Loss:  0.026541831  || Decoder Loss:  0.0038732702 Validation Decoder Loss:  0.31563216
Encoder Loss:  0.026200594  || Decoder Loss:  0.0037287506 Validation Decoder Loss:  0.30330348
Encoder Loss:  0.02590988  || Decoder Loss:  0.0035923733 Validation Decoder Loss:  0.28820896
Encoder Loss:  0.025658105  || Decoder Loss:  0.0035326143 Validation Decoder Loss:  0.26888543
Encoder Loss:  0.025396042  || Decoder Loss:  0.0034233183 Validation Decoder Loss:  0.25040805
Encoder Loss:  0.025147744  || Decoder Loss:  0.0032573238 Validation Decoder Loss:  0.2399247
Encoder Loss:  0.024931919  || Decoder Loss:  0.0030717226 Validation Decoder Loss:  0.23301104
Encoder Loss:  0.024758887  || Decoder Loss:  0.0028961333 Validation Decoder Loss:  0.22868533
Encoder Loss:  0.024618391  || Decoder Loss:  0.0027635975 Validation Decoder Loss:  0.22289658
Encoder Loss:  0.024488738  || Decoder Loss:  0.002648992 Validation Decoder Loss:  0.21847528
Encoder Loss:  0.024383886  || Decoder Loss:  0.0025694692 Validation Decoder Loss:  0.21490833
Encoder Loss:  0.02428879  || Decoder Loss:  0.0024946223 Validation Decoder Loss:  0.21015194
Encoder Loss:  0.024196165  || Decoder Loss:  0.0024136424 Validation Decoder Loss:  0.20476267
Encoder Loss:  0.024115367  || Decoder Loss:  0.002344613 Validation Decoder Loss:  0.20093802
Encoder Loss:  0.024049677  || Decoder Loss:  0.002301647 Validation Decoder Loss:  0.1973529
Model: bold_synthesis_net_lr_0.000254025964130404 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.19735292
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 70, 26, 16, 1)     155       
_________________________________________________________________
reshape_32 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 155
Trainable params: 155
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.057289474  || Decoder Loss:  0.008449999 Validation Decoder Loss:  0.36859012
Encoder Loss:  0.045014586  || Decoder Loss:  0.0071668625 Validation Decoder Loss:  0.35643518
Encoder Loss:  0.03898542  || Decoder Loss:  0.006449809 Validation Decoder Loss:  0.36462042
Encoder Loss:  0.037486006  || Decoder Loss:  0.005845606 Validation Decoder Loss:  0.36864316
Encoder Loss:  0.036823105  || Decoder Loss:  0.005525789 Validation Decoder Loss:  0.37051284
Encoder Loss:  0.036281414  || Decoder Loss:  0.0053475257 Validation Decoder Loss:  0.37212753
Encoder Loss:  0.035725858  || Decoder Loss:  0.005197128 Validation Decoder Loss:  0.37160286
Encoder Loss:  0.0349227  || Decoder Loss:  0.0049933894 Validation Decoder Loss:  0.3644688
Encoder Loss:  0.033572786  || Decoder Loss:  0.0049368306 Validation Decoder Loss:  0.3566888
Encoder Loss:  0.0322569  || Decoder Loss:  0.004797981 Validation Decoder Loss:  0.35105783
Encoder Loss:  0.031138869  || Decoder Loss:  0.0045668264 Validation Decoder Loss:  0.34505922
Encoder Loss:  0.030212907  || Decoder Loss:  0.0042781164 Validation Decoder Loss:  0.33982623
Encoder Loss:  0.029541954  || Decoder Loss:  0.004242725 Validation Decoder Loss:  0.33493134
Encoder Loss:  0.028926155  || Decoder Loss:  0.0042178934 Validation Decoder Loss:  0.32604578
Encoder Loss:  0.028260583  || Decoder Loss:  0.0040289504 Validation Decoder Loss:  0.31366777
Encoder Loss:  0.027562743  || Decoder Loss:  0.0038410157 Validation Decoder Loss:  0.29917607
Encoder Loss:  0.026882477  || Decoder Loss:  0.0036068715 Validation Decoder Loss:  0.2816023
Encoder Loss:  0.026275426  || Decoder Loss:  0.0034659847 Validation Decoder Loss:  0.26679996
Encoder Loss:  0.025774078  || Decoder Loss:  0.0034196875 Validation Decoder Loss:  0.25367546
Encoder Loss:  0.025354348  || Decoder Loss:  0.003280233 Validation Decoder Loss:  0.24063674
Encoder Loss:  0.024954742  || Decoder Loss:  0.0029066864 Validation Decoder Loss:  0.23131105
Encoder Loss:  0.02472844  || Decoder Loss:  0.0027620513 Validation Decoder Loss:  0.2252624
Encoder Loss:  0.024563072  || Decoder Loss:  0.0026218886 Validation Decoder Loss:  0.2246078
Encoder Loss:  0.02443969  || Decoder Loss:  0.0025167232 Validation Decoder Loss:  0.22484675
Encoder Loss:  0.024346132  || Decoder Loss:  0.0024478268 Validation Decoder Loss:  0.22438526
Encoder Loss:  0.024264367  || Decoder Loss:  0.0023818978 Validation Decoder Loss:  0.22489193
Encoder Loss:  0.024191868  || Decoder Loss:  0.0023276974 Validation Decoder Loss:  0.22489813
Encoder Loss:  0.024124118  || Decoder Loss:  0.0022849743 Validation Decoder Loss:  0.22521433
Encoder Loss:  0.024063116  || Decoder Loss:  0.0022436844 Validation Decoder Loss:  0.22565606
Encoder Loss:  0.024006376  || Decoder Loss:  0.0022011977 Validation Decoder Loss:  0.22478917
Encoder Loss:  0.023953404  || Decoder Loss:  0.0021628344 Validation Decoder Loss:  0.22466922
Encoder Loss:  0.023897132  || Decoder Loss:  0.0021104636 Validation Decoder Loss:  0.22460887
Encoder Loss:  0.023842372  || Decoder Loss:  0.0020522315 Validation Decoder Loss:  0.22397974
Encoder Loss:  0.023794992  || Decoder Loss:  0.0020030204 Validation Decoder Loss:  0.22366622
Encoder Loss:  0.023754427  || Decoder Loss:  0.0019592303 Validation Decoder Loss:  0.2236603
Encoder Loss:  0.023715902  || Decoder Loss:  0.0019161627 Validation Decoder Loss:  0.22370166
Encoder Loss:  0.02368244  || Decoder Loss:  0.0018770391 Validation Decoder Loss:  0.22400387
Encoder Loss:  0.0236539  || Decoder Loss:  0.0018432583 Validation Decoder Loss:  0.22358596
Encoder Loss:  0.023625685  || Decoder Loss:  0.0018087361 Validation Decoder Loss:  0.2233414
Encoder Loss:  0.023602547  || Decoder Loss:  0.0017815729 Validation Decoder Loss:  0.2236605
Model: bold_synthesis_net_lr_0.00025402222371641287 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.2236605
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 260, 7, 16, 1)     592       
_________________________________________________________________
reshape_33 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 592
Trainable params: 592
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035097227  || Decoder Loss:  0.0044617397 Validation Decoder Loss:  0.4398795
Encoder Loss:  0.0328781  || Decoder Loss:  0.0043637315 Validation Decoder Loss:  0.43870288
Encoder Loss:  0.031950492  || Decoder Loss:  0.0042607645 Validation Decoder Loss:  0.43806916
Encoder Loss:  0.031502105  || Decoder Loss:  0.004149278 Validation Decoder Loss:  0.43652162
Encoder Loss:  0.031138452  || Decoder Loss:  0.0040789396 Validation Decoder Loss:  0.43473476
Encoder Loss:  0.030784782  || Decoder Loss:  0.00402382 Validation Decoder Loss:  0.4340605
Encoder Loss:  0.030417908  || Decoder Loss:  0.003993409 Validation Decoder Loss:  0.4326051
Encoder Loss:  0.030088332  || Decoder Loss:  0.00398134 Validation Decoder Loss:  0.43273634
Encoder Loss:  0.029810067  || Decoder Loss:  0.0039548613 Validation Decoder Loss:  0.43287933
Encoder Loss:  0.029534016  || Decoder Loss:  0.003922728 Validation Decoder Loss:  0.43260816
Encoder Loss:  0.029238136  || Decoder Loss:  0.0038974239 Validation Decoder Loss:  0.43239447
Encoder Loss:  0.028890116  || Decoder Loss:  0.003862859 Validation Decoder Loss:  0.43212175
Encoder Loss:  0.028510213  || Decoder Loss:  0.0038392022 Validation Decoder Loss:  0.43183935
Encoder Loss:  0.02808659  || Decoder Loss:  0.0038040755 Validation Decoder Loss:  0.43142337
Encoder Loss:  0.02770605  || Decoder Loss:  0.0037668245 Validation Decoder Loss:  0.43102482
Encoder Loss:  0.027341995  || Decoder Loss:  0.003728981 Validation Decoder Loss:  0.43077996
Encoder Loss:  0.026982026  || Decoder Loss:  0.0036305862 Validation Decoder Loss:  0.4278447
Encoder Loss:  0.026635533  || Decoder Loss:  0.0035172426 Validation Decoder Loss:  0.42689446
Encoder Loss:  0.026327105  || Decoder Loss:  0.003476528 Validation Decoder Loss:  0.42734468
Encoder Loss:  0.02600404  || Decoder Loss:  0.003453169 Validation Decoder Loss:  0.4273721
Encoder Loss:  0.02570361  || Decoder Loss:  0.0034301095 Validation Decoder Loss:  0.42751828
Encoder Loss:  0.025467299  || Decoder Loss:  0.0033992147 Validation Decoder Loss:  0.42760563
Encoder Loss:  0.025292749  || Decoder Loss:  0.0033728178 Validation Decoder Loss:  0.42771405
Encoder Loss:  0.02515019  || Decoder Loss:  0.0033489594 Validation Decoder Loss:  0.4277663
Encoder Loss:  0.025021892  || Decoder Loss:  0.0033191855 Validation Decoder Loss:  0.42762458
Encoder Loss:  0.024910081  || Decoder Loss:  0.0032891193 Validation Decoder Loss:  0.427765
Encoder Loss:  0.024829995  || Decoder Loss:  0.0032660558 Validation Decoder Loss:  0.4279366
Encoder Loss:  0.024763562  || Decoder Loss:  0.0032383595 Validation Decoder Loss:  0.42795837
Encoder Loss:  0.024703266  || Decoder Loss:  0.0032045436 Validation Decoder Loss:  0.4278894
Encoder Loss:  0.024648013  || Decoder Loss:  0.0031698134 Validation Decoder Loss:  0.42763206
Encoder Loss:  0.024597427  || Decoder Loss:  0.003136217 Validation Decoder Loss:  0.42732823
Encoder Loss:  0.024545433  || Decoder Loss:  0.0031024264 Validation Decoder Loss:  0.42714524
Encoder Loss:  0.024504004  || Decoder Loss:  0.0030760064 Validation Decoder Loss:  0.4269861
Encoder Loss:  0.02446794  || Decoder Loss:  0.0030588307 Validation Decoder Loss:  0.42685723
Encoder Loss:  0.02443767  || Decoder Loss:  0.003044634 Validation Decoder Loss:  0.42674786
Encoder Loss:  0.024409343  || Decoder Loss:  0.003031131 Validation Decoder Loss:  0.4265418
Encoder Loss:  0.024382576  || Decoder Loss:  0.0030195836 Validation Decoder Loss:  0.42643583
Encoder Loss:  0.02435649  || Decoder Loss:  0.003006964 Validation Decoder Loss:  0.42627716
Encoder Loss:  0.024333695  || Decoder Loss:  0.0029934605 Validation Decoder Loss:  0.42612755
Encoder Loss:  0.024313405  || Decoder Loss:  0.0029824432 Validation Decoder Loss:  0.42598677
Model: bold_synthesis_net_lr_0.0002539522988559275 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.42598677
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 70, 26, 16, 1)     99        
_________________________________________________________________
reshape_34 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051145967  || Decoder Loss:  0.009504132 Validation Decoder Loss:  0.37761927
Encoder Loss:  0.04180272  || Decoder Loss:  0.0066630417 Validation Decoder Loss:  0.37875825
Encoder Loss:  0.038834926  || Decoder Loss:  0.0060698455 Validation Decoder Loss:  0.3884704
Encoder Loss:  0.03713238  || Decoder Loss:  0.0058172094 Validation Decoder Loss:  0.394386
Encoder Loss:  0.03568609  || Decoder Loss:  0.0057442486 Validation Decoder Loss:  0.40001947
Encoder Loss:  0.034852628  || Decoder Loss:  0.0055246204 Validation Decoder Loss:  0.40015924
Encoder Loss:  0.034274764  || Decoder Loss:  0.0053367955 Validation Decoder Loss:  0.39878097
Encoder Loss:  0.033755653  || Decoder Loss:  0.0053088125 Validation Decoder Loss:  0.39700451
Encoder Loss:  0.033256885  || Decoder Loss:  0.00533903 Validation Decoder Loss:  0.39355642
Encoder Loss:  0.03260744  || Decoder Loss:  0.005281 Validation Decoder Loss:  0.3847338
Encoder Loss:  0.031741988  || Decoder Loss:  0.0052477494 Validation Decoder Loss:  0.37322608
Encoder Loss:  0.030831177  || Decoder Loss:  0.0052062953 Validation Decoder Loss:  0.35185358
Encoder Loss:  0.02976871  || Decoder Loss:  0.0050053257 Validation Decoder Loss:  0.3259943
Encoder Loss:  0.028639663  || Decoder Loss:  0.004484497 Validation Decoder Loss:  0.2999465
Encoder Loss:  0.027793497  || Decoder Loss:  0.0040699122 Validation Decoder Loss:  0.26989305
Encoder Loss:  0.027134044  || Decoder Loss:  0.0037800574 Validation Decoder Loss:  0.24551737
Encoder Loss:  0.026585951  || Decoder Loss:  0.0036279922 Validation Decoder Loss:  0.23277
Encoder Loss:  0.026116269  || Decoder Loss:  0.0033704722 Validation Decoder Loss:  0.22816084
Encoder Loss:  0.025655758  || Decoder Loss:  0.0030059877 Validation Decoder Loss:  0.21231416
Encoder Loss:  0.025259962  || Decoder Loss:  0.0026210404 Validation Decoder Loss:  0.19732568
Encoder Loss:  0.024963183  || Decoder Loss:  0.0023966387 Validation Decoder Loss:  0.18659584
Encoder Loss:  0.024731563  || Decoder Loss:  0.0022345562 Validation Decoder Loss:  0.17770849
Encoder Loss:  0.024562404  || Decoder Loss:  0.002121444 Validation Decoder Loss:  0.17217965
Encoder Loss:  0.024435751  || Decoder Loss:  0.0020405417 Validation Decoder Loss:  0.16880488
Encoder Loss:  0.024348423  || Decoder Loss:  0.002000446 Validation Decoder Loss:  0.1650812
Encoder Loss:  0.024266725  || Decoder Loss:  0.0019524607 Validation Decoder Loss:  0.16239017
Encoder Loss:  0.024185771  || Decoder Loss:  0.0018965745 Validation Decoder Loss:  0.15946078
Encoder Loss:  0.024112323  || Decoder Loss:  0.001851781 Validation Decoder Loss:  0.15594572
Encoder Loss:  0.02404261  || Decoder Loss:  0.0018050956 Validation Decoder Loss:  0.15161018
Encoder Loss:  0.023964295  || Decoder Loss:  0.0017429155 Validation Decoder Loss:  0.15091874
Encoder Loss:  0.023869447  || Decoder Loss:  0.0016333793 Validation Decoder Loss:  0.14839873
Encoder Loss:  0.023780933  || Decoder Loss:  0.001526353 Validation Decoder Loss:  0.14536738
Encoder Loss:  0.023708485  || Decoder Loss:  0.0014622159 Validation Decoder Loss:  0.14497662
Encoder Loss:  0.023651015  || Decoder Loss:  0.0014097223 Validation Decoder Loss:  0.14479613
Encoder Loss:  0.02360018  || Decoder Loss:  0.0013531386 Validation Decoder Loss:  0.14243993
Encoder Loss:  0.02355416  || Decoder Loss:  0.0013067098 Validation Decoder Loss:  0.13981749
Encoder Loss:  0.023512047  || Decoder Loss:  0.0012607209 Validation Decoder Loss:  0.13685718
Encoder Loss:  0.023469463  || Decoder Loss:  0.0012027184 Validation Decoder Loss:  0.1353929
Encoder Loss:  0.02343237  || Decoder Loss:  0.0011584813 Validation Decoder Loss:  0.1327406
Encoder Loss:  0.023399381  || Decoder Loss:  0.0011237396 Validation Decoder Loss:  0.12833756
Model: bold_synthesis_net_lr_0.00025414178864793005 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.12833756
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 260, 7, 16, 1)     592       
_________________________________________________________________
reshape_35 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 592
Trainable params: 592
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035079867  || Decoder Loss:  0.004462224 Validation Decoder Loss:  0.43987626
Encoder Loss:  0.03286153  || Decoder Loss:  0.004363212 Validation Decoder Loss:  0.43862247
Encoder Loss:  0.031935405  || Decoder Loss:  0.0042633624 Validation Decoder Loss:  0.43811315
Encoder Loss:  0.0314864  || Decoder Loss:  0.0041484446 Validation Decoder Loss:  0.43653938
Encoder Loss:  0.031120466  || Decoder Loss:  0.00407748 Validation Decoder Loss:  0.4352681
Encoder Loss:  0.030763214  || Decoder Loss:  0.0040135304 Validation Decoder Loss:  0.43396354
Encoder Loss:  0.030390602  || Decoder Loss:  0.0039721983 Validation Decoder Loss:  0.43256992
Encoder Loss:  0.030055705  || Decoder Loss:  0.003951433 Validation Decoder Loss:  0.4329117
Encoder Loss:  0.029778082  || Decoder Loss:  0.003924051 Validation Decoder Loss:  0.43267635
Encoder Loss:  0.029502338  || Decoder Loss:  0.0038983773 Validation Decoder Loss:  0.43295592
Encoder Loss:  0.0292057  || Decoder Loss:  0.003872813 Validation Decoder Loss:  0.43263176
Encoder Loss:  0.028855862  || Decoder Loss:  0.003839177 Validation Decoder Loss:  0.43270904
Encoder Loss:  0.02846707  || Decoder Loss:  0.0037951085 Validation Decoder Loss:  0.43259314
Encoder Loss:  0.028044585  || Decoder Loss:  0.0037706227 Validation Decoder Loss:  0.43195343
Encoder Loss:  0.027685061  || Decoder Loss:  0.0037665928 Validation Decoder Loss:  0.43133202
Encoder Loss:  0.02731936  || Decoder Loss:  0.0037393076 Validation Decoder Loss:  0.43138093
Encoder Loss:  0.026992068  || Decoder Loss:  0.003709087 Validation Decoder Loss:  0.4315176
Encoder Loss:  0.02667882  || Decoder Loss:  0.0036649273 Validation Decoder Loss:  0.43170676
Encoder Loss:  0.026372395  || Decoder Loss:  0.0036345487 Validation Decoder Loss:  0.43211842
Encoder Loss:  0.02604697  || Decoder Loss:  0.0036138578 Validation Decoder Loss:  0.43279976
Encoder Loss:  0.02574143  || Decoder Loss:  0.0035877454 Validation Decoder Loss:  0.43280756
Encoder Loss:  0.025509756  || Decoder Loss:  0.0035618409 Validation Decoder Loss:  0.43280184
Encoder Loss:  0.02534499  || Decoder Loss:  0.003543921 Validation Decoder Loss:  0.43294495
Encoder Loss:  0.025211845  || Decoder Loss:  0.0035306865 Validation Decoder Loss:  0.43296683
Encoder Loss:  0.025087427  || Decoder Loss:  0.003514056 Validation Decoder Loss:  0.43303734
Encoder Loss:  0.024982207  || Decoder Loss:  0.0034968662 Validation Decoder Loss:  0.43317848
Encoder Loss:  0.024905272  || Decoder Loss:  0.003479461 Validation Decoder Loss:  0.43342713
Encoder Loss:  0.024841709  || Decoder Loss:  0.0034635465 Validation Decoder Loss:  0.43352002
Encoder Loss:  0.02478535  || Decoder Loss:  0.0034456253 Validation Decoder Loss:  0.433489
Encoder Loss:  0.024735725  || Decoder Loss:  0.0034265157 Validation Decoder Loss:  0.43351132
Encoder Loss:  0.02468767  || Decoder Loss:  0.0034039768 Validation Decoder Loss:  0.43363407
Encoder Loss:  0.024639254  || Decoder Loss:  0.0033782925 Validation Decoder Loss:  0.43368402
Encoder Loss:  0.024596192  || Decoder Loss:  0.003350886 Validation Decoder Loss:  0.43371972
Encoder Loss:  0.02455575  || Decoder Loss:  0.0033265408 Validation Decoder Loss:  0.43374783
Encoder Loss:  0.024520265  || Decoder Loss:  0.0033044324 Validation Decoder Loss:  0.4335808
Encoder Loss:  0.02448686  || Decoder Loss:  0.0032771262 Validation Decoder Loss:  0.43359047
Encoder Loss:  0.024448065  || Decoder Loss:  0.00324306 Validation Decoder Loss:  0.43352455
Encoder Loss:  0.024417076  || Decoder Loss:  0.0032159083 Validation Decoder Loss:  0.43343735
Encoder Loss:  0.024387904  || Decoder Loss:  0.0031925447 Validation Decoder Loss:  0.43321624
Encoder Loss:  0.0243616  || Decoder Loss:  0.0031721639 Validation Decoder Loss:  0.433118
Model: bold_synthesis_net_lr_0.00025434572730863124 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.433118
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 140, 13, 16, 1)    127       
_________________________________________________________________
reshape_36 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054836348  || Decoder Loss:  0.008877592 Validation Decoder Loss:  0.37500346
Encoder Loss:  0.044836037  || Decoder Loss:  0.007028614 Validation Decoder Loss:  0.369463
Encoder Loss:  0.038663972  || Decoder Loss:  0.006243203 Validation Decoder Loss:  0.37715125
Encoder Loss:  0.037222724  || Decoder Loss:  0.005767721 Validation Decoder Loss:  0.3823421
Encoder Loss:  0.03627659  || Decoder Loss:  0.005494879 Validation Decoder Loss:  0.38447088
Encoder Loss:  0.03570741  || Decoder Loss:  0.0052345097 Validation Decoder Loss:  0.38516602
Encoder Loss:  0.03525651  || Decoder Loss:  0.0050864555 Validation Decoder Loss:  0.3851902
Encoder Loss:  0.0347946  || Decoder Loss:  0.005017681 Validation Decoder Loss:  0.38343912
Encoder Loss:  0.03419157  || Decoder Loss:  0.0050402423 Validation Decoder Loss:  0.3771519
Encoder Loss:  0.033272658  || Decoder Loss:  0.0048970627 Validation Decoder Loss:  0.36471346
Encoder Loss:  0.031969175  || Decoder Loss:  0.004692314 Validation Decoder Loss:  0.34493098
Encoder Loss:  0.030417431  || Decoder Loss:  0.004565286 Validation Decoder Loss:  0.32471508
Encoder Loss:  0.028775845  || Decoder Loss:  0.0040431553 Validation Decoder Loss:  0.29884857
Encoder Loss:  0.02740509  || Decoder Loss:  0.003776547 Validation Decoder Loss:  0.26143882
Encoder Loss:  0.026224986  || Decoder Loss:  0.0033545985 Validation Decoder Loss:  0.2200674
Encoder Loss:  0.025336966  || Decoder Loss:  0.003126154 Validation Decoder Loss:  0.16540413
Encoder Loss:  0.024718694  || Decoder Loss:  0.002480237 Validation Decoder Loss:  0.14309679
Encoder Loss:  0.024340453  || Decoder Loss:  0.0019674604 Validation Decoder Loss:  0.12964788
Encoder Loss:  0.024145462  || Decoder Loss:  0.0017680993 Validation Decoder Loss:  0.1220029
Encoder Loss:  0.023997061  || Decoder Loss:  0.0016368651 Validation Decoder Loss:  0.11791143
Encoder Loss:  0.023879863  || Decoder Loss:  0.0015238575 Validation Decoder Loss:  0.11361731
Encoder Loss:  0.0237752  || Decoder Loss:  0.0014368563 Validation Decoder Loss:  0.10780518
Encoder Loss:  0.023689752  || Decoder Loss:  0.0013806834 Validation Decoder Loss:  0.10381591
Encoder Loss:  0.023617173  || Decoder Loss:  0.0013369473 Validation Decoder Loss:  0.097157404
Encoder Loss:  0.02354457  || Decoder Loss:  0.0012827499 Validation Decoder Loss:  0.09152907
Encoder Loss:  0.023482662  || Decoder Loss:  0.0012391794 Validation Decoder Loss:  0.08681936
Encoder Loss:  0.023423733  || Decoder Loss:  0.0011855261 Validation Decoder Loss:  0.08335807
Encoder Loss:  0.023369465  || Decoder Loss:  0.0011331489 Validation Decoder Loss:  0.0791323
Encoder Loss:  0.02332308  || Decoder Loss:  0.0010908028 Validation Decoder Loss:  0.077557854
Encoder Loss:  0.023281617  || Decoder Loss:  0.0010536921 Validation Decoder Loss:  0.07407302
Encoder Loss:  0.023244612  || Decoder Loss:  0.0010215587 Validation Decoder Loss:  0.07369064
Encoder Loss:  0.023209833  || Decoder Loss:  0.0009904244 Validation Decoder Loss:  0.073199086
Encoder Loss:  0.023179779  || Decoder Loss:  0.000962182 Validation Decoder Loss:  0.072203636
Encoder Loss:  0.023152651  || Decoder Loss:  0.0009407582 Validation Decoder Loss:  0.071287185
Encoder Loss:  0.02313085  || Decoder Loss:  0.00092347775 Validation Decoder Loss:  0.06979874
Encoder Loss:  0.023111863  || Decoder Loss:  0.00090777734 Validation Decoder Loss:  0.06914968
Encoder Loss:  0.023091797  || Decoder Loss:  0.00088400696 Validation Decoder Loss:  0.068743296
Encoder Loss:  0.023073604  || Decoder Loss:  0.0008632293 Validation Decoder Loss:  0.06732845
Encoder Loss:  0.02305603  || Decoder Loss:  0.00084341783 Validation Decoder Loss:  0.06756216
Encoder Loss:  0.023043122  || Decoder Loss:  0.0008307219 Validation Decoder Loss:  0.066737466
Model: bold_synthesis_net_lr_0.000253960154235717 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.066737466
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 182, 10, 16, 1)    715       
_________________________________________________________________
reshape_37 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 715
Trainable params: 715
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03709823  || Decoder Loss:  0.004475574 Validation Decoder Loss:  0.3774521
Encoder Loss:  0.03451101  || Decoder Loss:  0.0044310396 Validation Decoder Loss:  0.37239212
Encoder Loss:  0.033255637  || Decoder Loss:  0.0041197008 Validation Decoder Loss:  0.36928132
Encoder Loss:  0.03247019  || Decoder Loss:  0.003935569 Validation Decoder Loss:  0.36689675
Encoder Loss:  0.031870045  || Decoder Loss:  0.003942587 Validation Decoder Loss:  0.3652951
Encoder Loss:  0.03127745  || Decoder Loss:  0.003901348 Validation Decoder Loss:  0.36376613
Encoder Loss:  0.030758018  || Decoder Loss:  0.003872722 Validation Decoder Loss:  0.36243773
Encoder Loss:  0.030393243  || Decoder Loss:  0.0038343417 Validation Decoder Loss:  0.3620304
Encoder Loss:  0.030085603  || Decoder Loss:  0.0037709281 Validation Decoder Loss:  0.3621232
Encoder Loss:  0.029837552  || Decoder Loss:  0.0037224367 Validation Decoder Loss:  0.36193514
Encoder Loss:  0.02958609  || Decoder Loss:  0.003645028 Validation Decoder Loss:  0.36180562
Encoder Loss:  0.029332742  || Decoder Loss:  0.0035632553 Validation Decoder Loss:  0.361689
Encoder Loss:  0.029079141  || Decoder Loss:  0.0034909304 Validation Decoder Loss:  0.3614447
Encoder Loss:  0.028823167  || Decoder Loss:  0.0034331079 Validation Decoder Loss:  0.36122704
Encoder Loss:  0.028544197  || Decoder Loss:  0.003365344 Validation Decoder Loss:  0.36106658
Encoder Loss:  0.028256739  || Decoder Loss:  0.0032779595 Validation Decoder Loss:  0.36093608
Encoder Loss:  0.027971236  || Decoder Loss:  0.0031877346 Validation Decoder Loss:  0.3608449
Encoder Loss:  0.02768111  || Decoder Loss:  0.003106841 Validation Decoder Loss:  0.36075053
Encoder Loss:  0.02738936  || Decoder Loss:  0.003047613 Validation Decoder Loss:  0.36060786
Encoder Loss:  0.027079506  || Decoder Loss:  0.0030021498 Validation Decoder Loss:  0.36033508
Encoder Loss:  0.02675702  || Decoder Loss:  0.0029597494 Validation Decoder Loss:  0.36025494
Encoder Loss:  0.02645516  || Decoder Loss:  0.002939756 Validation Decoder Loss:  0.36014473
Encoder Loss:  0.026201129  || Decoder Loss:  0.0029155046 Validation Decoder Loss:  0.3600074
Encoder Loss:  0.025946409  || Decoder Loss:  0.002883656 Validation Decoder Loss:  0.35972145
Encoder Loss:  0.025686016  || Decoder Loss:  0.002864885 Validation Decoder Loss:  0.35937947
Encoder Loss:  0.025429199  || Decoder Loss:  0.0028425297 Validation Decoder Loss:  0.359166
Encoder Loss:  0.025208335  || Decoder Loss:  0.00281698 Validation Decoder Loss:  0.35888487
Encoder Loss:  0.025063701  || Decoder Loss:  0.0027930704 Validation Decoder Loss:  0.35870725
Encoder Loss:  0.024956275  || Decoder Loss:  0.0027679834 Validation Decoder Loss:  0.35863432
Encoder Loss:  0.024865495  || Decoder Loss:  0.0027352679 Validation Decoder Loss:  0.358557
Encoder Loss:  0.024786383  || Decoder Loss:  0.0027007486 Validation Decoder Loss:  0.35848108
Encoder Loss:  0.02472274  || Decoder Loss:  0.0026801736 Validation Decoder Loss:  0.35841393
Encoder Loss:  0.024666693  || Decoder Loss:  0.0026600917 Validation Decoder Loss:  0.35827702
Encoder Loss:  0.024612004  || Decoder Loss:  0.0026308985 Validation Decoder Loss:  0.35813266
Encoder Loss:  0.024556873  || Decoder Loss:  0.002599991 Validation Decoder Loss:  0.3579195
Encoder Loss:  0.02450934  || Decoder Loss:  0.0025778227 Validation Decoder Loss:  0.35769224
Encoder Loss:  0.024468733  || Decoder Loss:  0.0025543233 Validation Decoder Loss:  0.35722816
Encoder Loss:  0.024427189  || Decoder Loss:  0.0025271815 Validation Decoder Loss:  0.35686356
Encoder Loss:  0.02439298  || Decoder Loss:  0.0025078857 Validation Decoder Loss:  0.35669827
Encoder Loss:  0.024362253  || Decoder Loss:  0.0024947869 Validation Decoder Loss:  0.3564551
Model: bold_synthesis_net_lr_0.0002530668009079971 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3564551
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 70, 26, 16, 1)     155       
_________________________________________________________________
reshape_38 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 155
Trainable params: 155
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.057277426  || Decoder Loss:  0.008449402 Validation Decoder Loss:  0.36858347
Encoder Loss:  0.04500125  || Decoder Loss:  0.007164837 Validation Decoder Loss:  0.35654682
Encoder Loss:  0.038968503  || Decoder Loss:  0.006424504 Validation Decoder Loss:  0.36448395
Encoder Loss:  0.037494745  || Decoder Loss:  0.005874476 Validation Decoder Loss:  0.3688938
Encoder Loss:  0.036811747  || Decoder Loss:  0.005510466 Validation Decoder Loss:  0.37093884
Encoder Loss:  0.036257483  || Decoder Loss:  0.005303682 Validation Decoder Loss:  0.37187666
Encoder Loss:  0.035679623  || Decoder Loss:  0.005098959 Validation Decoder Loss:  0.3714738
Encoder Loss:  0.034863792  || Decoder Loss:  0.004865309 Validation Decoder Loss:  0.36363608
Encoder Loss:  0.03352792  || Decoder Loss:  0.0048391405 Validation Decoder Loss:  0.35603628
Encoder Loss:  0.032228384  || Decoder Loss:  0.0047324016 Validation Decoder Loss:  0.35062656
Encoder Loss:  0.03110713  || Decoder Loss:  0.0044975663 Validation Decoder Loss:  0.3471752
Encoder Loss:  0.030196983  || Decoder Loss:  0.0042448784 Validation Decoder Loss:  0.3423769
Encoder Loss:  0.02948452  || Decoder Loss:  0.004120478 Validation Decoder Loss:  0.336577
Encoder Loss:  0.028917462  || Decoder Loss:  0.0042233 Validation Decoder Loss:  0.32879493
Encoder Loss:  0.02830266  || Decoder Loss:  0.004160926 Validation Decoder Loss:  0.3169068
Encoder Loss:  0.027601747  || Decoder Loss:  0.0039738077 Validation Decoder Loss:  0.30218667
Encoder Loss:  0.026931128  || Decoder Loss:  0.0037419181 Validation Decoder Loss:  0.2874181
Encoder Loss:  0.026362963  || Decoder Loss:  0.003644552 Validation Decoder Loss:  0.2762135
Encoder Loss:  0.025846377  || Decoder Loss:  0.0036016346 Validation Decoder Loss:  0.25581223
Encoder Loss:  0.025404159  || Decoder Loss:  0.0034240729 Validation Decoder Loss:  0.24070138
Encoder Loss:  0.025047544  || Decoder Loss:  0.0031881735 Validation Decoder Loss:  0.23197126
Encoder Loss:  0.024803676  || Decoder Loss:  0.00299697 Validation Decoder Loss:  0.23084201
Encoder Loss:  0.024586232  || Decoder Loss:  0.0027081273 Validation Decoder Loss:  0.23151058
Encoder Loss:  0.024424609  || Decoder Loss:  0.0024901838 Validation Decoder Loss:  0.23040919
Encoder Loss:  0.02431036  || Decoder Loss:  0.0023597034 Validation Decoder Loss:  0.23072365
Encoder Loss:  0.024214203  || Decoder Loss:  0.0022617169 Validation Decoder Loss:  0.22978482
Encoder Loss:  0.024136445  || Decoder Loss:  0.002192864 Validation Decoder Loss:  0.23098958
Encoder Loss:  0.024072574  || Decoder Loss:  0.002148123 Validation Decoder Loss:  0.23097864
Encoder Loss:  0.024010481  || Decoder Loss:  0.002097673 Validation Decoder Loss:  0.23036173
Encoder Loss:  0.023952188  || Decoder Loss:  0.0020478647 Validation Decoder Loss:  0.23015794
Encoder Loss:  0.02389534  || Decoder Loss:  0.0019936252 Validation Decoder Loss:  0.23095888
Encoder Loss:  0.023843376  || Decoder Loss:  0.001946028 Validation Decoder Loss:  0.23129275
Encoder Loss:  0.023794014  || Decoder Loss:  0.0018985675 Validation Decoder Loss:  0.2318168
Encoder Loss:  0.023745999  || Decoder Loss:  0.0018499243 Validation Decoder Loss:  0.23052186
Encoder Loss:  0.023705328  || Decoder Loss:  0.0018130123 Validation Decoder Loss:  0.23093814
Encoder Loss:  0.023669774  || Decoder Loss:  0.0017771492 Validation Decoder Loss:  0.23121971
Encoder Loss:  0.023640003  || Decoder Loss:  0.0017525958 Validation Decoder Loss:  0.23046485
Encoder Loss:  0.02361147  || Decoder Loss:  0.0017296929 Validation Decoder Loss:  0.23107255
Encoder Loss:  0.023587419  || Decoder Loss:  0.0017096264 Validation Decoder Loss:  0.23075473
Encoder Loss:  0.023563206  || Decoder Loss:  0.0016894009 Validation Decoder Loss:  0.2299933
Model: bold_synthesis_net_lr_0.0002541628632425712 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.22999331
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 65, 28, 16, 1)     33        
_________________________________________________________________
reshape_39 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06036469  || Decoder Loss:  0.008482364 Validation Decoder Loss:  0.3384891
Encoder Loss:  0.050597336  || Decoder Loss:  0.006293835 Validation Decoder Loss:  0.37247378
Encoder Loss:  0.041148655  || Decoder Loss:  0.0054805186 Validation Decoder Loss:  0.39235425
Encoder Loss:  0.037243627  || Decoder Loss:  0.0052588265 Validation Decoder Loss:  0.40856963
Encoder Loss:  0.035292335  || Decoder Loss:  0.004823639 Validation Decoder Loss:  0.41364998
Encoder Loss:  0.033958428  || Decoder Loss:  0.0045212163 Validation Decoder Loss:  0.41328925
Encoder Loss:  0.03289665  || Decoder Loss:  0.0042644097 Validation Decoder Loss:  0.41349474
Encoder Loss:  0.03183721  || Decoder Loss:  0.004105375 Validation Decoder Loss:  0.4147934
Encoder Loss:  0.030828433  || Decoder Loss:  0.0039360747 Validation Decoder Loss:  0.41643867
Encoder Loss:  0.029815307  || Decoder Loss:  0.0038034513 Validation Decoder Loss:  0.41788846
Encoder Loss:  0.028685395  || Decoder Loss:  0.0036761605 Validation Decoder Loss:  0.42061758
Encoder Loss:  0.027831726  || Decoder Loss:  0.003610187 Validation Decoder Loss:  0.42198998
Encoder Loss:  0.027289515  || Decoder Loss:  0.0035031356 Validation Decoder Loss:  0.4247053
Encoder Loss:  0.026854252  || Decoder Loss:  0.0033936754 Validation Decoder Loss:  0.426511
Encoder Loss:  0.026491012  || Decoder Loss:  0.0033084895 Validation Decoder Loss:  0.42774668
Encoder Loss:  0.026227186  || Decoder Loss:  0.0032527435 Validation Decoder Loss:  0.430043
Encoder Loss:  0.0260216  || Decoder Loss:  0.0032366246 Validation Decoder Loss:  0.43251765
Encoder Loss:  0.025830016  || Decoder Loss:  0.0032023822 Validation Decoder Loss:  0.433876
Encoder Loss:  0.025672585  || Decoder Loss:  0.0031694728 Validation Decoder Loss:  0.43415612
Encoder Loss:  0.025521377  || Decoder Loss:  0.0031095317 Validation Decoder Loss:  0.43380478
Encoder Loss:  0.025368026  || Decoder Loss:  0.0030709011 Validation Decoder Loss:  0.43356997
Encoder Loss:  0.02520287  || Decoder Loss:  0.003032813 Validation Decoder Loss:  0.43085074
Encoder Loss:  0.025053551  || Decoder Loss:  0.0030072804 Validation Decoder Loss:  0.42745307
Encoder Loss:  0.024920588  || Decoder Loss:  0.0029662696 Validation Decoder Loss:  0.42424613
Encoder Loss:  0.02480966  || Decoder Loss:  0.0029237971 Validation Decoder Loss:  0.41951585
Encoder Loss:  0.024692278  || Decoder Loss:  0.002854543 Validation Decoder Loss:  0.41511253
Encoder Loss:  0.024581471  || Decoder Loss:  0.002775936 Validation Decoder Loss:  0.41228333
Encoder Loss:  0.024486432  || Decoder Loss:  0.0026936184 Validation Decoder Loss:  0.4106891
Encoder Loss:  0.024392895  || Decoder Loss:  0.0025982286 Validation Decoder Loss:  0.40851802
Encoder Loss:  0.024312431  || Decoder Loss:  0.0025182895 Validation Decoder Loss:  0.4062835
Encoder Loss:  0.024247624  || Decoder Loss:  0.0024588504 Validation Decoder Loss:  0.4042241
Encoder Loss:  0.0241847  || Decoder Loss:  0.0024008707 Validation Decoder Loss:  0.4020986
Encoder Loss:  0.024133403  || Decoder Loss:  0.00235421 Validation Decoder Loss:  0.39903915
Encoder Loss:  0.024082785  || Decoder Loss:  0.0023078856 Validation Decoder Loss:  0.39597002
Encoder Loss:  0.024029084  || Decoder Loss:  0.0022599061 Validation Decoder Loss:  0.39299214
Encoder Loss:  0.023976572  || Decoder Loss:  0.0022086669 Validation Decoder Loss:  0.39001703
Encoder Loss:  0.023934117  || Decoder Loss:  0.0021650323 Validation Decoder Loss:  0.38682884
Encoder Loss:  0.023893313  || Decoder Loss:  0.0021163714 Validation Decoder Loss:  0.38363147
Encoder Loss:  0.023855451  || Decoder Loss:  0.0020730703 Validation Decoder Loss:  0.38079965
Encoder Loss:  0.02381514  || Decoder Loss:  0.0020267915 Validation Decoder Loss:  0.37813443
Model: bold_synthesis_net_lr_0.0002552023404187972 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.37813446
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 70, 26, 16, 1)     127       
_________________________________________________________________
reshape_40 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05441138  || Decoder Loss:  0.008736608 Validation Decoder Loss:  0.3735553
Encoder Loss:  0.044512875  || Decoder Loss:  0.0068515837 Validation Decoder Loss:  0.36744615
Encoder Loss:  0.039548762  || Decoder Loss:  0.006115249 Validation Decoder Loss:  0.37363124
Encoder Loss:  0.03705208  || Decoder Loss:  0.0057647605 Validation Decoder Loss:  0.37993497
Encoder Loss:  0.035620708  || Decoder Loss:  0.0054764217 Validation Decoder Loss:  0.38189328
Encoder Loss:  0.034867305  || Decoder Loss:  0.0053045703 Validation Decoder Loss:  0.37858403
Encoder Loss:  0.034067363  || Decoder Loss:  0.0052650548 Validation Decoder Loss:  0.37013367
Encoder Loss:  0.03285374  || Decoder Loss:  0.0053049265 Validation Decoder Loss:  0.35726583
Encoder Loss:  0.031368345  || Decoder Loss:  0.0054165307 Validation Decoder Loss:  0.3348643
Encoder Loss:  0.029949369  || Decoder Loss:  0.005100908 Validation Decoder Loss:  0.31543064
Encoder Loss:  0.028768398  || Decoder Loss:  0.0046715224 Validation Decoder Loss:  0.29348683
Encoder Loss:  0.027734714  || Decoder Loss:  0.0042470787 Validation Decoder Loss:  0.2630268
Encoder Loss:  0.026913812  || Decoder Loss:  0.004030444 Validation Decoder Loss:  0.24083142
Encoder Loss:  0.026422132  || Decoder Loss:  0.004109978 Validation Decoder Loss:  0.22780499
Encoder Loss:  0.026064927  || Decoder Loss:  0.0040796925 Validation Decoder Loss:  0.2218322
Encoder Loss:  0.025767783  || Decoder Loss:  0.003993739 Validation Decoder Loss:  0.21458508
Encoder Loss:  0.025559617  || Decoder Loss:  0.003897267 Validation Decoder Loss:  0.21385875
Encoder Loss:  0.02532433  || Decoder Loss:  0.0036475218 Validation Decoder Loss:  0.21567193
Encoder Loss:  0.025069822  || Decoder Loss:  0.0033077528 Validation Decoder Loss:  0.21312937
Encoder Loss:  0.02487529  || Decoder Loss:  0.0030648024 Validation Decoder Loss:  0.2109235
Encoder Loss:  0.02472677  || Decoder Loss:  0.0028964775 Validation Decoder Loss:  0.20521623
Encoder Loss:  0.024588853  || Decoder Loss:  0.0027459832 Validation Decoder Loss:  0.20393048
Encoder Loss:  0.024465889  || Decoder Loss:  0.0026220537 Validation Decoder Loss:  0.20264426
Encoder Loss:  0.024381155  || Decoder Loss:  0.0025714333 Validation Decoder Loss:  0.20256197
Encoder Loss:  0.024293423  || Decoder Loss:  0.002487747 Validation Decoder Loss:  0.20163116
Encoder Loss:  0.02421023  || Decoder Loss:  0.002408888 Validation Decoder Loss:  0.20000541
Encoder Loss:  0.024138512  || Decoder Loss:  0.002348583 Validation Decoder Loss:  0.1981438
Encoder Loss:  0.024068542  || Decoder Loss:  0.0022793848 Validation Decoder Loss:  0.1968451
Encoder Loss:  0.023991957  || Decoder Loss:  0.0021767411 Validation Decoder Loss:  0.1962528
Encoder Loss:  0.023922976  || Decoder Loss:  0.0020885696 Validation Decoder Loss:  0.19649409
Encoder Loss:  0.023873698  || Decoder Loss:  0.0020349908 Validation Decoder Loss:  0.19705847
Encoder Loss:  0.023826422  || Decoder Loss:  0.0019785478 Validation Decoder Loss:  0.19719552
Encoder Loss:  0.0237817  || Decoder Loss:  0.0019201867 Validation Decoder Loss:  0.19756077
Encoder Loss:  0.023737242  || Decoder Loss:  0.0018542426 Validation Decoder Loss:  0.19692878
Encoder Loss:  0.023695419  || Decoder Loss:  0.0017978348 Validation Decoder Loss:  0.19786952
Encoder Loss:  0.023663819  || Decoder Loss:  0.0017578277 Validation Decoder Loss:  0.19831726
Encoder Loss:  0.023633765  || Decoder Loss:  0.0017200005 Validation Decoder Loss:  0.19940326
Encoder Loss:  0.023605265  || Decoder Loss:  0.0016877442 Validation Decoder Loss:  0.19925362
Encoder Loss:  0.023581764  || Decoder Loss:  0.0016605736 Validation Decoder Loss:  0.19989444
Encoder Loss:  0.023557771  || Decoder Loss:  0.0016325096 Validation Decoder Loss:  0.1989901
Model: bold_synthesis_net_lr_0.00025177061295203923 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.19899012
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 140, 13, 16, 1)    386       
_________________________________________________________________
reshape_41 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 386
Trainable params: 386
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037673026  || Decoder Loss:  0.005362787 Validation Decoder Loss:  0.44366717
Encoder Loss:  0.035003096  || Decoder Loss:  0.0050468286 Validation Decoder Loss:  0.44600606
Encoder Loss:  0.033585545  || Decoder Loss:  0.0045694727 Validation Decoder Loss:  0.44492668
Encoder Loss:  0.032876544  || Decoder Loss:  0.0043685073 Validation Decoder Loss:  0.44420353
Encoder Loss:  0.03222265  || Decoder Loss:  0.0042880443 Validation Decoder Loss:  0.44535506
Encoder Loss:  0.031607624  || Decoder Loss:  0.0042694625 Validation Decoder Loss:  0.4449264
Encoder Loss:  0.031111887  || Decoder Loss:  0.004285229 Validation Decoder Loss:  0.44534725
Encoder Loss:  0.03062684  || Decoder Loss:  0.0042210845 Validation Decoder Loss:  0.4443214
Encoder Loss:  0.03019834  || Decoder Loss:  0.0041324184 Validation Decoder Loss:  0.44543722
Encoder Loss:  0.029819671  || Decoder Loss:  0.0040882034 Validation Decoder Loss:  0.44590202
Encoder Loss:  0.02944614  || Decoder Loss:  0.004009964 Validation Decoder Loss:  0.44703895
Encoder Loss:  0.029124556  || Decoder Loss:  0.003939481 Validation Decoder Loss:  0.44758058
Encoder Loss:  0.028855711  || Decoder Loss:  0.003908152 Validation Decoder Loss:  0.44757533
Encoder Loss:  0.028616197  || Decoder Loss:  0.0038462419 Validation Decoder Loss:  0.4470475
Encoder Loss:  0.028368436  || Decoder Loss:  0.0037624554 Validation Decoder Loss:  0.44677377
Encoder Loss:  0.028131051  || Decoder Loss:  0.003716025 Validation Decoder Loss:  0.44637674
Encoder Loss:  0.027896574  || Decoder Loss:  0.0036590816 Validation Decoder Loss:  0.44540632
Encoder Loss:  0.027638348  || Decoder Loss:  0.0036189582 Validation Decoder Loss:  0.4437566
Encoder Loss:  0.027370919  || Decoder Loss:  0.0036349199 Validation Decoder Loss:  0.44149584
Encoder Loss:  0.027093837  || Decoder Loss:  0.0035799919 Validation Decoder Loss:  0.44041795
Encoder Loss:  0.026835283  || Decoder Loss:  0.0035105823 Validation Decoder Loss:  0.4400541
Encoder Loss:  0.02658007  || Decoder Loss:  0.0034715184 Validation Decoder Loss:  0.4400416
Encoder Loss:  0.026309201  || Decoder Loss:  0.0034223287 Validation Decoder Loss:  0.44045025
Encoder Loss:  0.02603635  || Decoder Loss:  0.0033701314 Validation Decoder Loss:  0.44049248
Encoder Loss:  0.025789453  || Decoder Loss:  0.0033365856 Validation Decoder Loss:  0.44088167
Encoder Loss:  0.025573144  || Decoder Loss:  0.0033094755 Validation Decoder Loss:  0.44123286
Encoder Loss:  0.025358276  || Decoder Loss:  0.003282785 Validation Decoder Loss:  0.4416863
Encoder Loss:  0.025154805  || Decoder Loss:  0.0032580185 Validation Decoder Loss:  0.44184595
Encoder Loss:  0.024971062  || Decoder Loss:  0.003226831 Validation Decoder Loss:  0.44215742
Encoder Loss:  0.024810387  || Decoder Loss:  0.0032015531 Validation Decoder Loss:  0.44231805
Encoder Loss:  0.024699572  || Decoder Loss:  0.0031762356 Validation Decoder Loss:  0.44245583
Encoder Loss:  0.02462426  || Decoder Loss:  0.0031488447 Validation Decoder Loss:  0.4425041
Encoder Loss:  0.024561213  || Decoder Loss:  0.0031077443 Validation Decoder Loss:  0.44252515
Encoder Loss:  0.024510833  || Decoder Loss:  0.0030735778 Validation Decoder Loss:  0.44256592
Encoder Loss:  0.024463434  || Decoder Loss:  0.0030414509 Validation Decoder Loss:  0.44272542
Encoder Loss:  0.024426116  || Decoder Loss:  0.0030141557 Validation Decoder Loss:  0.44276306
Encoder Loss:  0.024391482  || Decoder Loss:  0.0029927671 Validation Decoder Loss:  0.44265887
Encoder Loss:  0.024362072  || Decoder Loss:  0.0029755312 Validation Decoder Loss:  0.44263518
Encoder Loss:  0.024333395  || Decoder Loss:  0.002959133 Validation Decoder Loss:  0.44260436
Encoder Loss:  0.024308521  || Decoder Loss:  0.0029425872 Validation Decoder Loss:  0.44264618
Model: bold_synthesis_net_lr_0.00025171431475810976 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.44264615
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 260, 7, 16, 1)     403       
_________________________________________________________________
reshape_42 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 403
Trainable params: 403
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037708186  || Decoder Loss:  0.005255635 Validation Decoder Loss:  0.42488492
Encoder Loss:  0.035316184  || Decoder Loss:  0.0048199533 Validation Decoder Loss:  0.4240111
Encoder Loss:  0.03393509  || Decoder Loss:  0.004637889 Validation Decoder Loss:  0.42286035
Encoder Loss:  0.03298793  || Decoder Loss:  0.0045904145 Validation Decoder Loss:  0.42459726
Encoder Loss:  0.03227901  || Decoder Loss:  0.004538778 Validation Decoder Loss:  0.4251186
Encoder Loss:  0.03170916  || Decoder Loss:  0.0044056587 Validation Decoder Loss:  0.4258722
Encoder Loss:  0.031206932  || Decoder Loss:  0.0042133336 Validation Decoder Loss:  0.42495516
Encoder Loss:  0.03084977  || Decoder Loss:  0.004110392 Validation Decoder Loss:  0.42425233
Encoder Loss:  0.030517936  || Decoder Loss:  0.0040605874 Validation Decoder Loss:  0.42454255
Encoder Loss:  0.030183764  || Decoder Loss:  0.004038227 Validation Decoder Loss:  0.42481315
Encoder Loss:  0.029859805  || Decoder Loss:  0.0040332 Validation Decoder Loss:  0.42557004
Encoder Loss:  0.029543772  || Decoder Loss:  0.003986096 Validation Decoder Loss:  0.42555508
Encoder Loss:  0.029244687  || Decoder Loss:  0.00396394 Validation Decoder Loss:  0.42544574
Encoder Loss:  0.028960098  || Decoder Loss:  0.0039487635 Validation Decoder Loss:  0.42506027
Encoder Loss:  0.028686596  || Decoder Loss:  0.0039345683 Validation Decoder Loss:  0.42518693
Encoder Loss:  0.028419929  || Decoder Loss:  0.0039223055 Validation Decoder Loss:  0.42618024
Encoder Loss:  0.028136674  || Decoder Loss:  0.0038871772 Validation Decoder Loss:  0.42765176
Encoder Loss:  0.027853621  || Decoder Loss:  0.0038613966 Validation Decoder Loss:  0.42848974
Encoder Loss:  0.027557127  || Decoder Loss:  0.0037965595 Validation Decoder Loss:  0.42887634
Encoder Loss:  0.027241878  || Decoder Loss:  0.0037248991 Validation Decoder Loss:  0.42999187
Encoder Loss:  0.026918234  || Decoder Loss:  0.0036725448 Validation Decoder Loss:  0.43060416
Encoder Loss:  0.026602147  || Decoder Loss:  0.0036269727 Validation Decoder Loss:  0.43079606
Encoder Loss:  0.02631496  || Decoder Loss:  0.0035868883 Validation Decoder Loss:  0.43099004
Encoder Loss:  0.02606497  || Decoder Loss:  0.003557071 Validation Decoder Loss:  0.43156216
Encoder Loss:  0.025827702  || Decoder Loss:  0.0035193816 Validation Decoder Loss:  0.43267435
Encoder Loss:  0.025635779  || Decoder Loss:  0.0034916503 Validation Decoder Loss:  0.43324125
Encoder Loss:  0.025480812  || Decoder Loss:  0.0034692567 Validation Decoder Loss:  0.43360347
Encoder Loss:  0.025363298  || Decoder Loss:  0.00343857 Validation Decoder Loss:  0.43383855
Encoder Loss:  0.025265332  || Decoder Loss:  0.0034060553 Validation Decoder Loss:  0.43438601
Encoder Loss:  0.025183348  || Decoder Loss:  0.0033714415 Validation Decoder Loss:  0.43436795
Encoder Loss:  0.02511137  || Decoder Loss:  0.0033329101 Validation Decoder Loss:  0.43449044
Encoder Loss:  0.025045484  || Decoder Loss:  0.0032944975 Validation Decoder Loss:  0.434686
Encoder Loss:  0.024985082  || Decoder Loss:  0.0032696088 Validation Decoder Loss:  0.4347508
Encoder Loss:  0.02492846  || Decoder Loss:  0.0032400151 Validation Decoder Loss:  0.43470782
Encoder Loss:  0.024872286  || Decoder Loss:  0.0032084652 Validation Decoder Loss:  0.4348573
Encoder Loss:  0.024822913  || Decoder Loss:  0.0031861092 Validation Decoder Loss:  0.43525428
Encoder Loss:  0.024775548  || Decoder Loss:  0.003163283 Validation Decoder Loss:  0.43544063
Encoder Loss:  0.024725864  || Decoder Loss:  0.0031335806 Validation Decoder Loss:  0.4355593
Encoder Loss:  0.024680978  || Decoder Loss:  0.0031114577 Validation Decoder Loss:  0.43572575
Encoder Loss:  0.024638016  || Decoder Loss:  0.0030961125 Validation Decoder Loss:  0.4358308
Model: bold_synthesis_net_lr_0.0002546888478897183 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.43583077
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 130, 14, 16, 1)    25        
_________________________________________________________________
reshape_43 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.060154192  || Decoder Loss:  0.008871842 Validation Decoder Loss:  0.3181487
Encoder Loss:  0.04733947  || Decoder Loss:  0.007379784 Validation Decoder Loss:  0.35658646
Encoder Loss:  0.03708211  || Decoder Loss:  0.0062003275 Validation Decoder Loss:  0.38611373
Encoder Loss:  0.034524687  || Decoder Loss:  0.0056475443 Validation Decoder Loss:  0.40250129
Encoder Loss:  0.033218563  || Decoder Loss:  0.005075142 Validation Decoder Loss:  0.40740955
Encoder Loss:  0.032434143  || Decoder Loss:  0.0047548967 Validation Decoder Loss:  0.4078263
Encoder Loss:  0.03182892  || Decoder Loss:  0.0044336254 Validation Decoder Loss:  0.40571004
Encoder Loss:  0.031368557  || Decoder Loss:  0.004268023 Validation Decoder Loss:  0.40274525
Encoder Loss:  0.03088478  || Decoder Loss:  0.004088946 Validation Decoder Loss:  0.3983097
Encoder Loss:  0.03044752  || Decoder Loss:  0.0039248816 Validation Decoder Loss:  0.39433885
Encoder Loss:  0.030020505  || Decoder Loss:  0.003865834 Validation Decoder Loss:  0.39214915
Encoder Loss:  0.029518265  || Decoder Loss:  0.003849862 Validation Decoder Loss:  0.39072388
Encoder Loss:  0.028963324  || Decoder Loss:  0.0038118758 Validation Decoder Loss:  0.38617635
Encoder Loss:  0.028381068  || Decoder Loss:  0.00383552 Validation Decoder Loss:  0.3780489
Encoder Loss:  0.027825426  || Decoder Loss:  0.0038819436 Validation Decoder Loss:  0.3644381
Encoder Loss:  0.027235279  || Decoder Loss:  0.003941682 Validation Decoder Loss:  0.3367085
Encoder Loss:  0.026535422  || Decoder Loss:  0.0038804582 Validation Decoder Loss:  0.27863276
Encoder Loss:  0.025905998  || Decoder Loss:  0.0038642478 Validation Decoder Loss:  0.27554697
Encoder Loss:  0.025307082  || Decoder Loss:  0.0035460216 Validation Decoder Loss:  0.26239088
Encoder Loss:  0.024637917  || Decoder Loss:  0.0026920522 Validation Decoder Loss:  0.22773379
Encoder Loss:  0.024149632  || Decoder Loss:  0.0020862813 Validation Decoder Loss:  0.21594
Encoder Loss:  0.02386871  || Decoder Loss:  0.0018262948 Validation Decoder Loss:  0.20517588
Encoder Loss:  0.023692273  || Decoder Loss:  0.0016448495 Validation Decoder Loss:  0.21225819
Encoder Loss:  0.023581237  || Decoder Loss:  0.0015308394 Validation Decoder Loss:  0.21032111
Encoder Loss:  0.023503006  || Decoder Loss:  0.0014552543 Validation Decoder Loss:  0.21100889
Encoder Loss:  0.02344528  || Decoder Loss:  0.0013976269 Validation Decoder Loss:  0.2071546
Encoder Loss:  0.023397751  || Decoder Loss:  0.0013440413 Validation Decoder Loss:  0.2009605
Encoder Loss:  0.023351813  || Decoder Loss:  0.0012877524 Validation Decoder Loss:  0.19464447
Encoder Loss:  0.023310483  || Decoder Loss:  0.0012323651 Validation Decoder Loss:  0.18819176
Encoder Loss:  0.023279976  || Decoder Loss:  0.0011907793 Validation Decoder Loss:  0.18267334
Encoder Loss:  0.023254676  || Decoder Loss:  0.0011568156 Validation Decoder Loss:  0.1801976
Encoder Loss:  0.023232764  || Decoder Loss:  0.0011291694 Validation Decoder Loss:  0.18116072
Encoder Loss:  0.023212247  || Decoder Loss:  0.001106463 Validation Decoder Loss:  0.17899555
Encoder Loss:  0.023196066  || Decoder Loss:  0.0010838299 Validation Decoder Loss:  0.17648348
Encoder Loss:  0.02318074  || Decoder Loss:  0.001065438 Validation Decoder Loss:  0.17316289
Encoder Loss:  0.023164362  || Decoder Loss:  0.001042871 Validation Decoder Loss:  0.17087355
Encoder Loss:  0.02314753  || Decoder Loss:  0.001017742 Validation Decoder Loss:  0.16986854
Encoder Loss:  0.023130616  || Decoder Loss:  0.0009899973 Validation Decoder Loss:  0.16593122
Encoder Loss:  0.023115456  || Decoder Loss:  0.00096587837 Validation Decoder Loss:  0.16094196
Encoder Loss:  0.02310343  || Decoder Loss:  0.00094825664 Validation Decoder Loss:  0.15835509
Model: bold_synthesis_net_lr_0.0002537915237702509 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.15835509
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 140, 13, 16, 1)    127       
_________________________________________________________________
reshape_44 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054851353  || Decoder Loss:  0.008878725 Validation Decoder Loss:  0.37499714
Encoder Loss:  0.044851355  || Decoder Loss:  0.0070297965 Validation Decoder Loss:  0.36941165
Encoder Loss:  0.038674127  || Decoder Loss:  0.0062446296 Validation Decoder Loss:  0.37711948
Encoder Loss:  0.037234128  || Decoder Loss:  0.005767262 Validation Decoder Loss:  0.38234273
Encoder Loss:  0.036292456  || Decoder Loss:  0.005506755 Validation Decoder Loss:  0.3847754
Encoder Loss:  0.035727717  || Decoder Loss:  0.0052586407 Validation Decoder Loss:  0.38546324
Encoder Loss:  0.03526962  || Decoder Loss:  0.005090546 Validation Decoder Loss:  0.38537484
Encoder Loss:  0.03480625  || Decoder Loss:  0.0050218604 Validation Decoder Loss:  0.3837074
Encoder Loss:  0.034213003  || Decoder Loss:  0.0050530797 Validation Decoder Loss:  0.37770838
Encoder Loss:  0.03331706  || Decoder Loss:  0.0049374104 Validation Decoder Loss:  0.36524028
Encoder Loss:  0.032011397  || Decoder Loss:  0.0047051436 Validation Decoder Loss:  0.34717703
Encoder Loss:  0.030456197  || Decoder Loss:  0.004548377 Validation Decoder Loss:  0.32638294
Encoder Loss:  0.028881831  || Decoder Loss:  0.004204325 Validation Decoder Loss:  0.3019356
Encoder Loss:  0.027443113  || Decoder Loss:  0.0037869413 Validation Decoder Loss:  0.27385283
Encoder Loss:  0.026308  || Decoder Loss:  0.0034813476 Validation Decoder Loss:  0.22831956
Encoder Loss:  0.025349898  || Decoder Loss:  0.00310171 Validation Decoder Loss:  0.18363002
Encoder Loss:  0.024715709  || Decoder Loss:  0.0024465674 Validation Decoder Loss:  0.16321908
Encoder Loss:  0.02441977  || Decoder Loss:  0.0021363397 Validation Decoder Loss:  0.15553
Encoder Loss:  0.024250858  || Decoder Loss:  0.0020048898 Validation Decoder Loss:  0.1472424
Encoder Loss:  0.024078675  || Decoder Loss:  0.001819574 Validation Decoder Loss:  0.14100343
Encoder Loss:  0.023950363  || Decoder Loss:  0.0016832644 Validation Decoder Loss:  0.13634525
Encoder Loss:  0.023855172  || Decoder Loss:  0.0016088629 Validation Decoder Loss:  0.13011539
Encoder Loss:  0.02376434  || Decoder Loss:  0.0015354543 Validation Decoder Loss:  0.12409277
Encoder Loss:  0.023681289  || Decoder Loss:  0.0014702944 Validation Decoder Loss:  0.11718841
Encoder Loss:  0.023614764  || Decoder Loss:  0.0014330952 Validation Decoder Loss:  0.11013549
Encoder Loss:  0.02355606  || Decoder Loss:  0.00140426 Validation Decoder Loss:  0.10575706
Encoder Loss:  0.023499588  || Decoder Loss:  0.0013609829 Validation Decoder Loss:  0.10171488
Encoder Loss:  0.023450634  || Decoder Loss:  0.0013212562 Validation Decoder Loss:  0.097540244
Encoder Loss:  0.023401972  || Decoder Loss:  0.0012733074 Validation Decoder Loss:  0.09415409
Encoder Loss:  0.023359144  || Decoder Loss:  0.0012331303 Validation Decoder Loss:  0.09155284
Encoder Loss:  0.02332306  || Decoder Loss:  0.0012033702 Validation Decoder Loss:  0.08978849
Encoder Loss:  0.023290189  || Decoder Loss:  0.0011726844 Validation Decoder Loss:  0.08939296
Encoder Loss:  0.02326103  || Decoder Loss:  0.00114879 Validation Decoder Loss:  0.08761312
Encoder Loss:  0.023234792  || Decoder Loss:  0.0011234059 Validation Decoder Loss:  0.086272106
Encoder Loss:  0.023211304  || Decoder Loss:  0.0011011418 Validation Decoder Loss:  0.08489526
Encoder Loss:  0.02318707  || Decoder Loss:  0.0010775079 Validation Decoder Loss:  0.08438566
Encoder Loss:  0.023166148  || Decoder Loss:  0.0010563239 Validation Decoder Loss:  0.083298884
Encoder Loss:  0.023146365  || Decoder Loss:  0.0010322949 Validation Decoder Loss:  0.0820563
Encoder Loss:  0.023128778  || Decoder Loss:  0.0010104133 Validation Decoder Loss:  0.08093901
Encoder Loss:  0.023111703  || Decoder Loss:  0.0009874349 Validation Decoder Loss:  0.07923305
Model: bold_synthesis_net_lr_0.0002537408684012842 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.07923304
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 91, 20, 16, 1)     225       
_________________________________________________________________
reshape_45 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 225
Trainable params: 225
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.039468452  || Decoder Loss:  0.006478348 Validation Decoder Loss:  0.41290206
Encoder Loss:  0.037377886  || Decoder Loss:  0.006021383 Validation Decoder Loss:  0.41612476
Encoder Loss:  0.036396425  || Decoder Loss:  0.005832488 Validation Decoder Loss:  0.41881576
Encoder Loss:  0.0356269  || Decoder Loss:  0.0055940957 Validation Decoder Loss:  0.42133677
Encoder Loss:  0.034949657  || Decoder Loss:  0.005364343 Validation Decoder Loss:  0.4251877
Encoder Loss:  0.034453306  || Decoder Loss:  0.005158686 Validation Decoder Loss:  0.42719787
Encoder Loss:  0.034047727  || Decoder Loss:  0.0049849884 Validation Decoder Loss:  0.4305172
Encoder Loss:  0.03364721  || Decoder Loss:  0.0048047677 Validation Decoder Loss:  0.43242592
Encoder Loss:  0.033302434  || Decoder Loss:  0.0047191377 Validation Decoder Loss:  0.43396282
Encoder Loss:  0.032969512  || Decoder Loss:  0.0046217777 Validation Decoder Loss:  0.43539023
Encoder Loss:  0.032638993  || Decoder Loss:  0.00452471 Validation Decoder Loss:  0.43592733
Encoder Loss:  0.0323029  || Decoder Loss:  0.0044445936 Validation Decoder Loss:  0.43597752
Encoder Loss:  0.031968266  || Decoder Loss:  0.004351259 Validation Decoder Loss:  0.43640545
Encoder Loss:  0.031654146  || Decoder Loss:  0.004279095 Validation Decoder Loss:  0.43675077
Encoder Loss:  0.03131984  || Decoder Loss:  0.004206941 Validation Decoder Loss:  0.436872
Encoder Loss:  0.030960122  || Decoder Loss:  0.004127102 Validation Decoder Loss:  0.43754426
Encoder Loss:  0.03061203  || Decoder Loss:  0.0040600575 Validation Decoder Loss:  0.438044
Encoder Loss:  0.03027398  || Decoder Loss:  0.0040038745 Validation Decoder Loss:  0.4385064
Encoder Loss:  0.029943883  || Decoder Loss:  0.003977855 Validation Decoder Loss:  0.43877703
Encoder Loss:  0.029592542  || Decoder Loss:  0.003948057 Validation Decoder Loss:  0.43873942
Encoder Loss:  0.02923059  || Decoder Loss:  0.0038904329 Validation Decoder Loss:  0.43840784
Encoder Loss:  0.028882176  || Decoder Loss:  0.0038445606 Validation Decoder Loss:  0.43754032
Encoder Loss:  0.028578227  || Decoder Loss:  0.0038074376 Validation Decoder Loss:  0.43764725
Encoder Loss:  0.028208897  || Decoder Loss:  0.0036895713 Validation Decoder Loss:  0.43722564
Encoder Loss:  0.027862467  || Decoder Loss:  0.0036052596 Validation Decoder Loss:  0.4368161
Encoder Loss:  0.027522177  || Decoder Loss:  0.003541824 Validation Decoder Loss:  0.43683153
Encoder Loss:  0.027162718  || Decoder Loss:  0.0035437571 Validation Decoder Loss:  0.43707013
Encoder Loss:  0.026791364  || Decoder Loss:  0.0035477828 Validation Decoder Loss:  0.4367318
Encoder Loss:  0.026417375  || Decoder Loss:  0.003546616 Validation Decoder Loss:  0.43632808
Encoder Loss:  0.026127271  || Decoder Loss:  0.0035150608 Validation Decoder Loss:  0.43482468
Encoder Loss:  0.025900217  || Decoder Loss:  0.0035000136 Validation Decoder Loss:  0.4316522
Encoder Loss:  0.025702747  || Decoder Loss:  0.0034351964 Validation Decoder Loss:  0.42940366
Encoder Loss:  0.025548633  || Decoder Loss:  0.0033699048 Validation Decoder Loss:  0.42855638
Encoder Loss:  0.025414644  || Decoder Loss:  0.0033042443 Validation Decoder Loss:  0.42814982
Encoder Loss:  0.025298158  || Decoder Loss:  0.003244948 Validation Decoder Loss:  0.4271079
Encoder Loss:  0.025183652  || Decoder Loss:  0.0031907202 Validation Decoder Loss:  0.42659593
Encoder Loss:  0.025077775  || Decoder Loss:  0.0031455776 Validation Decoder Loss:  0.42672685
Encoder Loss:  0.024971714  || Decoder Loss:  0.003111792 Validation Decoder Loss:  0.42703676
Encoder Loss:  0.024853768  || Decoder Loss:  0.003065686 Validation Decoder Loss:  0.42708343
Encoder Loss:  0.024750382  || Decoder Loss:  0.0030292445 Validation Decoder Loss:  0.4270785
Model: bold_synthesis_net_lr_0.0002521293891337722 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4270785
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 140, 13, 16, 1)    127       
_________________________________________________________________
reshape_46 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05471312  || Decoder Loss:  0.008868613 Validation Decoder Loss:  0.37505925
Encoder Loss:  0.04467938  || Decoder Loss:  0.0070123537 Validation Decoder Loss:  0.3697545
Encoder Loss:  0.038564462  || Decoder Loss:  0.0062312917 Validation Decoder Loss:  0.37731814
Encoder Loss:  0.037126943  || Decoder Loss:  0.00574503 Validation Decoder Loss:  0.38238814
Encoder Loss:  0.036185816  || Decoder Loss:  0.0054850527 Validation Decoder Loss:  0.38462734
Encoder Loss:  0.03564963  || Decoder Loss:  0.0052971 Validation Decoder Loss:  0.3849249
Encoder Loss:  0.035199232  || Decoder Loss:  0.0051496997 Validation Decoder Loss:  0.3847455
Encoder Loss:  0.03472526  || Decoder Loss:  0.005088211 Validation Decoder Loss:  0.38223064
Encoder Loss:  0.034115136  || Decoder Loss:  0.0051126974 Validation Decoder Loss:  0.37571234
Encoder Loss:  0.03322887  || Decoder Loss:  0.0050776065 Validation Decoder Loss:  0.36427957
Encoder Loss:  0.031888574  || Decoder Loss:  0.004847857 Validation Decoder Loss:  0.34632435
Encoder Loss:  0.030302245  || Decoder Loss:  0.0046284404 Validation Decoder Loss:  0.3251447
Encoder Loss:  0.028727306  || Decoder Loss:  0.004290851 Validation Decoder Loss:  0.30308437
Encoder Loss:  0.027315589  || Decoder Loss:  0.0039419704 Validation Decoder Loss:  0.27545998
Encoder Loss:  0.02614629  || Decoder Loss:  0.0035513982 Validation Decoder Loss:  0.23667753
Encoder Loss:  0.025179606  || Decoder Loss:  0.0030275 Validation Decoder Loss:  0.1852296
Encoder Loss:  0.024659436  || Decoder Loss:  0.002522925 Validation Decoder Loss:  0.16704264
Encoder Loss:  0.024335394  || Decoder Loss:  0.0020988658 Validation Decoder Loss:  0.15238678
Encoder Loss:  0.024139788  || Decoder Loss:  0.0018925924 Validation Decoder Loss:  0.14808175
Encoder Loss:  0.02399889  || Decoder Loss:  0.001773217 Validation Decoder Loss:  0.14237522
Encoder Loss:  0.023888642  || Decoder Loss:  0.0016825884 Validation Decoder Loss:  0.13660464
Encoder Loss:  0.02379585  || Decoder Loss:  0.0016229782 Validation Decoder Loss:  0.1300458
Encoder Loss:  0.0237161  || Decoder Loss:  0.0015821556 Validation Decoder Loss:  0.12444061
Encoder Loss:  0.023640897  || Decoder Loss:  0.0015346244 Validation Decoder Loss:  0.11800504
Encoder Loss:  0.023571532  || Decoder Loss:  0.0014911948 Validation Decoder Loss:  0.11170581
Encoder Loss:  0.023506928  || Decoder Loss:  0.0014553155 Validation Decoder Loss:  0.106062226
Encoder Loss:  0.023443721  || Decoder Loss:  0.0014013317 Validation Decoder Loss:  0.10118574
Encoder Loss:  0.023385921  || Decoder Loss:  0.0013446594 Validation Decoder Loss:  0.09963249
Encoder Loss:  0.023339191  || Decoder Loss:  0.001304943 Validation Decoder Loss:  0.094929054
Encoder Loss:  0.023295254  || Decoder Loss:  0.0012586353 Validation Decoder Loss:  0.092560366
Encoder Loss:  0.023251213  || Decoder Loss:  0.0012087281 Validation Decoder Loss:  0.09072248
Encoder Loss:  0.023214303  || Decoder Loss:  0.0011621203 Validation Decoder Loss:  0.088608295
Encoder Loss:  0.023180049  || Decoder Loss:  0.0011212984 Validation Decoder Loss:  0.087584704
Encoder Loss:  0.023153402  || Decoder Loss:  0.0010883235 Validation Decoder Loss:  0.0868523
Encoder Loss:  0.023125924  || Decoder Loss:  0.0010529155 Validation Decoder Loss:  0.085536584
Encoder Loss:  0.02310416  || Decoder Loss:  0.0010287289 Validation Decoder Loss:  0.084621854
Encoder Loss:  0.02308537  || Decoder Loss:  0.0010095135 Validation Decoder Loss:  0.08184622
Encoder Loss:  0.023071054  || Decoder Loss:  0.0009966934 Validation Decoder Loss:  0.080973685
Encoder Loss:  0.023055632  || Decoder Loss:  0.0009794298 Validation Decoder Loss:  0.08074415
Encoder Loss:  0.023042943  || Decoder Loss:  0.0009643905 Validation Decoder Loss:  0.080640614
Model: bold_synthesis_net_lr_0.00025587074356763916 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.080640614
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 140, 13, 16, 1)    694       
_________________________________________________________________
reshape_47 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.038249165  || Decoder Loss:  0.004831568 Validation Decoder Loss:  0.38082248
Encoder Loss:  0.03568722  || Decoder Loss:  0.0048710206 Validation Decoder Loss:  0.38009867
Encoder Loss:  0.03453265  || Decoder Loss:  0.0046626907 Validation Decoder Loss:  0.37829015
Encoder Loss:  0.03372572  || Decoder Loss:  0.0044731474 Validation Decoder Loss:  0.37777013
Encoder Loss:  0.032980185  || Decoder Loss:  0.004378141 Validation Decoder Loss:  0.37693638
Encoder Loss:  0.032106675  || Decoder Loss:  0.004238212 Validation Decoder Loss:  0.3757501
Encoder Loss:  0.031342402  || Decoder Loss:  0.0041100476 Validation Decoder Loss:  0.3746482
Encoder Loss:  0.030748555  || Decoder Loss:  0.003985724 Validation Decoder Loss:  0.37381673
Encoder Loss:  0.03020901  || Decoder Loss:  0.003911508 Validation Decoder Loss:  0.37318403
Encoder Loss:  0.029691657  || Decoder Loss:  0.0038525234 Validation Decoder Loss:  0.37298968
Encoder Loss:  0.02918798  || Decoder Loss:  0.003784409 Validation Decoder Loss:  0.37324905
Encoder Loss:  0.028774625  || Decoder Loss:  0.0037044582 Validation Decoder Loss:  0.37357175
Encoder Loss:  0.028432982  || Decoder Loss:  0.0036355997 Validation Decoder Loss:  0.37385148
Encoder Loss:  0.028088953  || Decoder Loss:  0.003584611 Validation Decoder Loss:  0.37387064
Encoder Loss:  0.027691785  || Decoder Loss:  0.0035476794 Validation Decoder Loss:  0.37369677
Encoder Loss:  0.027247028  || Decoder Loss:  0.0035110116 Validation Decoder Loss:  0.37365162
Encoder Loss:  0.026747337  || Decoder Loss:  0.003445699 Validation Decoder Loss:  0.37373033
Encoder Loss:  0.02625137  || Decoder Loss:  0.0033980873 Validation Decoder Loss:  0.3738576
Encoder Loss:  0.025785245  || Decoder Loss:  0.0033637641 Validation Decoder Loss:  0.37405744
Encoder Loss:  0.025457688  || Decoder Loss:  0.0033304745 Validation Decoder Loss:  0.37429386
Encoder Loss:  0.02524019  || Decoder Loss:  0.0033023506 Validation Decoder Loss:  0.37440413
Encoder Loss:  0.025090788  || Decoder Loss:  0.0032867729 Validation Decoder Loss:  0.37454468
Encoder Loss:  0.024962958  || Decoder Loss:  0.0032706987 Validation Decoder Loss:  0.37471896
Encoder Loss:  0.024853187  || Decoder Loss:  0.003252034 Validation Decoder Loss:  0.37487417
Encoder Loss:  0.024750128  || Decoder Loss:  0.003223778 Validation Decoder Loss:  0.3750062
Encoder Loss:  0.024660105  || Decoder Loss:  0.0031936779 Validation Decoder Loss:  0.37517002
Encoder Loss:  0.024581935  || Decoder Loss:  0.003173302 Validation Decoder Loss:  0.3753379
Encoder Loss:  0.024501817  || Decoder Loss:  0.003154423 Validation Decoder Loss:  0.37548494
Encoder Loss:  0.024429325  || Decoder Loss:  0.003142524 Validation Decoder Loss:  0.3755651
Encoder Loss:  0.024369074  || Decoder Loss:  0.0031273884 Validation Decoder Loss:  0.37554014
Encoder Loss:  0.02431676  || Decoder Loss:  0.0031063445 Validation Decoder Loss:  0.37545228
Encoder Loss:  0.024269164  || Decoder Loss:  0.003086891 Validation Decoder Loss:  0.37536684
Encoder Loss:  0.024225965  || Decoder Loss:  0.0030658573 Validation Decoder Loss:  0.37529755
Encoder Loss:  0.024185654  || Decoder Loss:  0.0030440737 Validation Decoder Loss:  0.37525454
Encoder Loss:  0.024149878  || Decoder Loss:  0.0030298498 Validation Decoder Loss:  0.3752211
Encoder Loss:  0.024114527  || Decoder Loss:  0.0030150146 Validation Decoder Loss:  0.37522137
Encoder Loss:  0.024082119  || Decoder Loss:  0.0030062916 Validation Decoder Loss:  0.37524903
Encoder Loss:  0.024053661  || Decoder Loss:  0.0029971614 Validation Decoder Loss:  0.37521583
Encoder Loss:  0.024026176  || Decoder Loss:  0.0029875364 Validation Decoder Loss:  0.3751488
Encoder Loss:  0.024001118  || Decoder Loss:  0.002979541 Validation Decoder Loss:  0.37514895
Model: bold_synthesis_net_lr_0.00026981496129545703 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.37514895
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 130, 14, 16, 1)    403       
_________________________________________________________________
reshape_48 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 403
Trainable params: 403
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037970234  || Decoder Loss:  0.0053833816 Validation Decoder Loss:  0.4241842
Encoder Loss:  0.03562927  || Decoder Loss:  0.004829058 Validation Decoder Loss:  0.4234411
Encoder Loss:  0.03425865  || Decoder Loss:  0.004617088 Validation Decoder Loss:  0.42314482
Encoder Loss:  0.033309717  || Decoder Loss:  0.00449656 Validation Decoder Loss:  0.42415065
Encoder Loss:  0.032598764  || Decoder Loss:  0.0044781836 Validation Decoder Loss:  0.4245291
Encoder Loss:  0.032001257  || Decoder Loss:  0.004379964 Validation Decoder Loss:  0.42467552
Encoder Loss:  0.031537183  || Decoder Loss:  0.0042775716 Validation Decoder Loss:  0.42520627
Encoder Loss:  0.031184038  || Decoder Loss:  0.0042099888 Validation Decoder Loss:  0.42675182
Encoder Loss:  0.030899277  || Decoder Loss:  0.0041474802 Validation Decoder Loss:  0.42691845
Encoder Loss:  0.03063243  || Decoder Loss:  0.004099864 Validation Decoder Loss:  0.42627463
Encoder Loss:  0.030327467  || Decoder Loss:  0.004048537 Validation Decoder Loss:  0.426088
Encoder Loss:  0.029993642  || Decoder Loss:  0.004017711 Validation Decoder Loss:  0.42632586
Encoder Loss:  0.029673934  || Decoder Loss:  0.0039953054 Validation Decoder Loss:  0.42648664
Encoder Loss:  0.029384814  || Decoder Loss:  0.0039801244 Validation Decoder Loss:  0.42626575
Encoder Loss:  0.02908768  || Decoder Loss:  0.0039618495 Validation Decoder Loss:  0.42640284
Encoder Loss:  0.02876411  || Decoder Loss:  0.003933612 Validation Decoder Loss:  0.4265846
Encoder Loss:  0.028440112  || Decoder Loss:  0.0039043168 Validation Decoder Loss:  0.4273389
Encoder Loss:  0.028144946  || Decoder Loss:  0.0038682215 Validation Decoder Loss:  0.42784378
Encoder Loss:  0.027826944  || Decoder Loss:  0.003815712 Validation Decoder Loss:  0.42876482
Encoder Loss:  0.027505098  || Decoder Loss:  0.0037509915 Validation Decoder Loss:  0.42962658
Encoder Loss:  0.027177075  || Decoder Loss:  0.0037034901 Validation Decoder Loss:  0.43024004
Encoder Loss:  0.026819251  || Decoder Loss:  0.0036463393 Validation Decoder Loss:  0.4303623
Encoder Loss:  0.026454488  || Decoder Loss:  0.0035660197 Validation Decoder Loss:  0.43062824
Encoder Loss:  0.026118767  || Decoder Loss:  0.0035109047 Validation Decoder Loss:  0.43066096
Encoder Loss:  0.025845429  || Decoder Loss:  0.0034410062 Validation Decoder Loss:  0.4311972
Encoder Loss:  0.025640398  || Decoder Loss:  0.00337825 Validation Decoder Loss:  0.43170404
Encoder Loss:  0.025480112  || Decoder Loss:  0.0033339707 Validation Decoder Loss:  0.43241686
Encoder Loss:  0.025368866  || Decoder Loss:  0.003290654 Validation Decoder Loss:  0.43293446
Encoder Loss:  0.025278257  || Decoder Loss:  0.0032509498 Validation Decoder Loss:  0.43328768
Encoder Loss:  0.025198422  || Decoder Loss:  0.0031923742 Validation Decoder Loss:  0.43377513
Encoder Loss:  0.025127964  || Decoder Loss:  0.0031397804 Validation Decoder Loss:  0.43443215
Encoder Loss:  0.025069408  || Decoder Loss:  0.00310263 Validation Decoder Loss:  0.4350186
Encoder Loss:  0.025011549  || Decoder Loss:  0.0030595446 Validation Decoder Loss:  0.4353436
Encoder Loss:  0.02495501  || Decoder Loss:  0.0030171184 Validation Decoder Loss:  0.4356197
Encoder Loss:  0.024907753  || Decoder Loss:  0.0029834665 Validation Decoder Loss:  0.43579668
Encoder Loss:  0.024868282  || Decoder Loss:  0.0029618007 Validation Decoder Loss:  0.43587667
Encoder Loss:  0.024832524  || Decoder Loss:  0.002939386 Validation Decoder Loss:  0.43604952
Encoder Loss:  0.024794074  || Decoder Loss:  0.0029216353 Validation Decoder Loss:  0.43632042
Encoder Loss:  0.024754649  || Decoder Loss:  0.0028988773 Validation Decoder Loss:  0.43643498
Encoder Loss:  0.024716245  || Decoder Loss:  0.0028672975 Validation Decoder Loss:  0.4364254
Model: bold_synthesis_net_lr_0.00024922602815300013 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4364254
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 364, 5, 16, 1)     239       
_________________________________________________________________
reshape_49 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03762606  || Decoder Loss:  0.004952381 Validation Decoder Loss:  0.46710294
Encoder Loss:  0.033361297  || Decoder Loss:  0.004687074 Validation Decoder Loss:  0.46884954
Encoder Loss:  0.031138888  || Decoder Loss:  0.0039050286 Validation Decoder Loss:  0.46864927
Encoder Loss:  0.030599492  || Decoder Loss:  0.0036964114 Validation Decoder Loss:  0.46802163
Encoder Loss:  0.03027385  || Decoder Loss:  0.003636807 Validation Decoder Loss:  0.4674382
Encoder Loss:  0.029961964  || Decoder Loss:  0.0035376856 Validation Decoder Loss:  0.4673774
Encoder Loss:  0.029646523  || Decoder Loss:  0.0034441429 Validation Decoder Loss:  0.4671872
Encoder Loss:  0.029353974  || Decoder Loss:  0.0033127002 Validation Decoder Loss:  0.46730435
Encoder Loss:  0.029109856  || Decoder Loss:  0.0032307364 Validation Decoder Loss:  0.46747613
Encoder Loss:  0.028876562  || Decoder Loss:  0.003164175 Validation Decoder Loss:  0.46762282
Encoder Loss:  0.028666804  || Decoder Loss:  0.0031180147 Validation Decoder Loss:  0.4673586
Encoder Loss:  0.02848533  || Decoder Loss:  0.0030831778 Validation Decoder Loss:  0.46731758
Encoder Loss:  0.02830917  || Decoder Loss:  0.003049562 Validation Decoder Loss:  0.46744856
Encoder Loss:  0.028113594  || Decoder Loss:  0.003016831 Validation Decoder Loss:  0.46766022
Encoder Loss:  0.027857348  || Decoder Loss:  0.002987408 Validation Decoder Loss:  0.468103
Encoder Loss:  0.027592665  || Decoder Loss:  0.002945996 Validation Decoder Loss:  0.46862072
Encoder Loss:  0.027352257  || Decoder Loss:  0.0029070925 Validation Decoder Loss:  0.46921778
Encoder Loss:  0.027097154  || Decoder Loss:  0.0028479556 Validation Decoder Loss:  0.46969217
Encoder Loss:  0.026860617  || Decoder Loss:  0.0028203116 Validation Decoder Loss:  0.47061348
Encoder Loss:  0.026605008  || Decoder Loss:  0.002778007 Validation Decoder Loss:  0.4716102
Encoder Loss:  0.026324179  || Decoder Loss:  0.0027149916 Validation Decoder Loss:  0.47124523
Encoder Loss:  0.026062418  || Decoder Loss:  0.0026568912 Validation Decoder Loss:  0.4701769
Encoder Loss:  0.025837297  || Decoder Loss:  0.0025972805 Validation Decoder Loss:  0.46838775
Encoder Loss:  0.02564666  || Decoder Loss:  0.0025492117 Validation Decoder Loss:  0.4665982
Encoder Loss:  0.025468923  || Decoder Loss:  0.0025300984 Validation Decoder Loss:  0.46499807
Encoder Loss:  0.02533279  || Decoder Loss:  0.0025582248 Validation Decoder Loss:  0.46376705
Encoder Loss:  0.02520086  || Decoder Loss:  0.0025557906 Validation Decoder Loss:  0.46200073
Encoder Loss:  0.025053633  || Decoder Loss:  0.0025203258 Validation Decoder Loss:  0.46069056
Encoder Loss:  0.024928367  || Decoder Loss:  0.002517701 Validation Decoder Loss:  0.4598207
Encoder Loss:  0.02482462  || Decoder Loss:  0.0025044682 Validation Decoder Loss:  0.4587897
Encoder Loss:  0.024721358  || Decoder Loss:  0.0024569342 Validation Decoder Loss:  0.4576168
Encoder Loss:  0.024640018  || Decoder Loss:  0.0024407357 Validation Decoder Loss:  0.4558924
Encoder Loss:  0.02457258  || Decoder Loss:  0.0024421804 Validation Decoder Loss:  0.45408067
Encoder Loss:  0.02450413  || Decoder Loss:  0.0024251419 Validation Decoder Loss:  0.4524284
Encoder Loss:  0.024438918  || Decoder Loss:  0.0023955742 Validation Decoder Loss:  0.45002633
Encoder Loss:  0.024383802  || Decoder Loss:  0.0023739168 Validation Decoder Loss:  0.44764844
Encoder Loss:  0.024339981  || Decoder Loss:  0.0023690143 Validation Decoder Loss:  0.44679865
Encoder Loss:  0.024298444  || Decoder Loss:  0.0023570573 Validation Decoder Loss:  0.44635957
Encoder Loss:  0.02426089  || Decoder Loss:  0.0023424427 Validation Decoder Loss:  0.44639018
Encoder Loss:  0.02422456  || Decoder Loss:  0.0023175972 Validation Decoder Loss:  0.44661295
Model: bold_synthesis_net_lr_0.0002490657213565467 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.44661295
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 70, 26, 16, 1)     155       
_________________________________________________________________
reshape_50 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 155
Trainable params: 155
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.057129968  || Decoder Loss:  0.008441827 Validation Decoder Loss:  0.36847728
Encoder Loss:  0.044806268  || Decoder Loss:  0.0071662283 Validation Decoder Loss:  0.35656425
Encoder Loss:  0.038871273  || Decoder Loss:  0.0064489953 Validation Decoder Loss:  0.3647659
Encoder Loss:  0.037398133  || Decoder Loss:  0.0058556017 Validation Decoder Loss:  0.36856812
Encoder Loss:  0.036738284  || Decoder Loss:  0.005544791 Validation Decoder Loss:  0.37053773
Encoder Loss:  0.036193114  || Decoder Loss:  0.005362196 Validation Decoder Loss:  0.37201864
Encoder Loss:  0.035643406  || Decoder Loss:  0.0052093114 Validation Decoder Loss:  0.37151325
Encoder Loss:  0.034826174  || Decoder Loss:  0.005027458 Validation Decoder Loss:  0.36397827
Encoder Loss:  0.03345161  || Decoder Loss:  0.004952317 Validation Decoder Loss:  0.35663676
Encoder Loss:  0.032141108  || Decoder Loss:  0.004803477 Validation Decoder Loss:  0.35153985
Encoder Loss:  0.031060465  || Decoder Loss:  0.0046426123 Validation Decoder Loss:  0.34756815
Encoder Loss:  0.030205984  || Decoder Loss:  0.0044745645 Validation Decoder Loss:  0.34282452
Encoder Loss:  0.029501935  || Decoder Loss:  0.004379547 Validation Decoder Loss:  0.33621466
Encoder Loss:  0.028881462  || Decoder Loss:  0.004339535 Validation Decoder Loss:  0.32705796
Encoder Loss:  0.02823521  || Decoder Loss:  0.004196822 Validation Decoder Loss:  0.31699473
Encoder Loss:  0.027542416  || Decoder Loss:  0.003999447 Validation Decoder Loss:  0.3022528
Encoder Loss:  0.026825571  || Decoder Loss:  0.003647689 Validation Decoder Loss:  0.2860616
Encoder Loss:  0.026218569  || Decoder Loss:  0.0034740476 Validation Decoder Loss:  0.27019268
Encoder Loss:  0.025642188  || Decoder Loss:  0.0032650465 Validation Decoder Loss:  0.25216287
Encoder Loss:  0.025153928  || Decoder Loss:  0.0030050478 Validation Decoder Loss:  0.234038
Encoder Loss:  0.024843113  || Decoder Loss:  0.0028511614 Validation Decoder Loss:  0.2235932
Encoder Loss:  0.024602095  || Decoder Loss:  0.0026501967 Validation Decoder Loss:  0.22202425
Encoder Loss:  0.024444291  || Decoder Loss:  0.0025027653 Validation Decoder Loss:  0.2201419
Encoder Loss:  0.02433993  || Decoder Loss:  0.00241863 Validation Decoder Loss:  0.2198078
Encoder Loss:  0.024250343  || Decoder Loss:  0.0023493578 Validation Decoder Loss:  0.21926898
Encoder Loss:  0.024168437  || Decoder Loss:  0.0022841848 Validation Decoder Loss:  0.22034973
Encoder Loss:  0.024093837  || Decoder Loss:  0.002216383 Validation Decoder Loss:  0.22107112
Encoder Loss:  0.024024354  || Decoder Loss:  0.0021488706 Validation Decoder Loss:  0.22181195
Encoder Loss:  0.023951812  || Decoder Loss:  0.002069645 Validation Decoder Loss:  0.22167131
Encoder Loss:  0.023885312  || Decoder Loss:  0.0019912873 Validation Decoder Loss:  0.22139913
Encoder Loss:  0.02381989  || Decoder Loss:  0.0019186485 Validation Decoder Loss:  0.2212136
Encoder Loss:  0.023761148  || Decoder Loss:  0.0018628945 Validation Decoder Loss:  0.22022419
Encoder Loss:  0.023708073  || Decoder Loss:  0.0018175668 Validation Decoder Loss:  0.21907003
Encoder Loss:  0.023662578  || Decoder Loss:  0.0017779147 Validation Decoder Loss:  0.21896626
Encoder Loss:  0.023619642  || Decoder Loss:  0.0017388643 Validation Decoder Loss:  0.21926925
Encoder Loss:  0.023582716  || Decoder Loss:  0.0017013054 Validation Decoder Loss:  0.21975529
Encoder Loss:  0.023549499  || Decoder Loss:  0.0016643911 Validation Decoder Loss:  0.22026059
Encoder Loss:  0.023517832  || Decoder Loss:  0.0016277307 Validation Decoder Loss:  0.21936941
Encoder Loss:  0.023489997  || Decoder Loss:  0.001596173 Validation Decoder Loss:  0.2195736
Encoder Loss:  0.023462707  || Decoder Loss:  0.0015659024 Validation Decoder Loss:  0.2200002
Model: bold_synthesis_net_lr_0.00025622823695578507 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.22000019
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 70, 26, 16, 1)     43        
_________________________________________________________________
reshape_51 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 43
Trainable params: 43
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04365277  || Decoder Loss:  0.008412449 Validation Decoder Loss:  0.36496812
Encoder Loss:  0.039060924  || Decoder Loss:  0.006157282 Validation Decoder Loss:  0.37159592
Encoder Loss:  0.037625663  || Decoder Loss:  0.0055957255 Validation Decoder Loss:  0.38014388
Encoder Loss:  0.036389403  || Decoder Loss:  0.0056597716 Validation Decoder Loss:  0.39065006
Encoder Loss:  0.03489083  || Decoder Loss:  0.005631911 Validation Decoder Loss:  0.40128222
Encoder Loss:  0.033940457  || Decoder Loss:  0.005539658 Validation Decoder Loss:  0.40372893
Encoder Loss:  0.03322072  || Decoder Loss:  0.005381359 Validation Decoder Loss:  0.40558657
Encoder Loss:  0.032579917  || Decoder Loss:  0.005117673 Validation Decoder Loss:  0.40538824
Encoder Loss:  0.032042786  || Decoder Loss:  0.0048778513 Validation Decoder Loss:  0.40509093
Encoder Loss:  0.031517882  || Decoder Loss:  0.0046780426 Validation Decoder Loss:  0.4049639
Encoder Loss:  0.030966297  || Decoder Loss:  0.0044222656 Validation Decoder Loss:  0.40233955
Encoder Loss:  0.030364968  || Decoder Loss:  0.0041384217 Validation Decoder Loss:  0.39873743
Encoder Loss:  0.029758202  || Decoder Loss:  0.003945603 Validation Decoder Loss:  0.39502704
Encoder Loss:  0.029118719  || Decoder Loss:  0.0038027149 Validation Decoder Loss:  0.3919041
Encoder Loss:  0.028534543  || Decoder Loss:  0.0036639106 Validation Decoder Loss:  0.3892266
Encoder Loss:  0.028003393  || Decoder Loss:  0.0035389746 Validation Decoder Loss:  0.38474733
Encoder Loss:  0.027548138  || Decoder Loss:  0.0034730008 Validation Decoder Loss:  0.38077658
Encoder Loss:  0.027137494  || Decoder Loss:  0.0033883012 Validation Decoder Loss:  0.37565127
Encoder Loss:  0.026743742  || Decoder Loss:  0.0033303278 Validation Decoder Loss:  0.37284693
Encoder Loss:  0.026362462  || Decoder Loss:  0.003304291 Validation Decoder Loss:  0.37042576
Encoder Loss:  0.026061665  || Decoder Loss:  0.0032633592 Validation Decoder Loss:  0.36999545
Encoder Loss:  0.025818583  || Decoder Loss:  0.003188647 Validation Decoder Loss:  0.3681506
Encoder Loss:  0.02565058  || Decoder Loss:  0.0031265605 Validation Decoder Loss:  0.3664315
Encoder Loss:  0.025532087  || Decoder Loss:  0.00308391 Validation Decoder Loss:  0.3660844
Encoder Loss:  0.025427675  || Decoder Loss:  0.0030465312 Validation Decoder Loss:  0.36673868
Encoder Loss:  0.02532681  || Decoder Loss:  0.0030195706 Validation Decoder Loss:  0.36686373
Encoder Loss:  0.025208183  || Decoder Loss:  0.0029665425 Validation Decoder Loss:  0.3678608
Encoder Loss:  0.025106683  || Decoder Loss:  0.0029213433 Validation Decoder Loss:  0.3691123
Encoder Loss:  0.024996446  || Decoder Loss:  0.0028307666 Validation Decoder Loss:  0.37012756
Encoder Loss:  0.024899855  || Decoder Loss:  0.002737713 Validation Decoder Loss:  0.37010753
Encoder Loss:  0.024818348  || Decoder Loss:  0.0026626925 Validation Decoder Loss:  0.37091333
Encoder Loss:  0.024744142  || Decoder Loss:  0.0026021742 Validation Decoder Loss:  0.372017
Encoder Loss:  0.024681188  || Decoder Loss:  0.0025554725 Validation Decoder Loss:  0.3729059
Encoder Loss:  0.024619382  || Decoder Loss:  0.0025173223 Validation Decoder Loss:  0.3729796
Encoder Loss:  0.024556499  || Decoder Loss:  0.0024759658 Validation Decoder Loss:  0.373271
Encoder Loss:  0.024501778  || Decoder Loss:  0.0024424382 Validation Decoder Loss:  0.37246463
Encoder Loss:  0.0244485  || Decoder Loss:  0.0024065648 Validation Decoder Loss:  0.3728872
Encoder Loss:  0.024396166  || Decoder Loss:  0.0023691976 Validation Decoder Loss:  0.37330943
Encoder Loss:  0.024336135  || Decoder Loss:  0.002306964 Validation Decoder Loss:  0.37224633
Encoder Loss:  0.0242731  || Decoder Loss:  0.0022363716 Validation Decoder Loss:  0.37028736
Model: bold_synthesis_net_lr_0.0002741951605390191 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.37028736
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 364, 5, 16, 1)     302       
_________________________________________________________________
reshape_52 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 302
Trainable params: 302
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.034986105  || Decoder Loss:  0.0043983585 Validation Decoder Loss:  0.47616583
Encoder Loss:  0.031835634  || Decoder Loss:  0.003783614 Validation Decoder Loss:  0.474333
Encoder Loss:  0.03089086  || Decoder Loss:  0.0034929172 Validation Decoder Loss:  0.4729248
Encoder Loss:  0.030439677  || Decoder Loss:  0.0033733668 Validation Decoder Loss:  0.47178274
Encoder Loss:  0.030111887  || Decoder Loss:  0.0032929354 Validation Decoder Loss:  0.47044337
Encoder Loss:  0.029788401  || Decoder Loss:  0.0032411055 Validation Decoder Loss:  0.46975696
Encoder Loss:  0.029465295  || Decoder Loss:  0.003222617 Validation Decoder Loss:  0.4698351
Encoder Loss:  0.029154718  || Decoder Loss:  0.0031819968 Validation Decoder Loss:  0.46943247
Encoder Loss:  0.0288907  || Decoder Loss:  0.003158988 Validation Decoder Loss:  0.4697274
Encoder Loss:  0.02863195  || Decoder Loss:  0.0031340998 Validation Decoder Loss:  0.47000307
Encoder Loss:  0.028404832  || Decoder Loss:  0.0031152677 Validation Decoder Loss:  0.4704736
Encoder Loss:  0.028177258  || Decoder Loss:  0.003098699 Validation Decoder Loss:  0.47087783
Encoder Loss:  0.027927674  || Decoder Loss:  0.0030852514 Validation Decoder Loss:  0.47126842
Encoder Loss:  0.027648624  || Decoder Loss:  0.0030628191 Validation Decoder Loss:  0.47145057
Encoder Loss:  0.027353168  || Decoder Loss:  0.003045476 Validation Decoder Loss:  0.471524
Encoder Loss:  0.02704749  || Decoder Loss:  0.0030209243 Validation Decoder Loss:  0.47138935
Encoder Loss:  0.026750466  || Decoder Loss:  0.0029982137 Validation Decoder Loss:  0.47174585
Encoder Loss:  0.026454637  || Decoder Loss:  0.0029785954 Validation Decoder Loss:  0.47190678
Encoder Loss:  0.02614718  || Decoder Loss:  0.0029558942 Validation Decoder Loss:  0.4720471
Encoder Loss:  0.025831249  || Decoder Loss:  0.0029271145 Validation Decoder Loss:  0.4722152
Encoder Loss:  0.025528008  || Decoder Loss:  0.002895298 Validation Decoder Loss:  0.47242948
Encoder Loss:  0.025272768  || Decoder Loss:  0.0028746459 Validation Decoder Loss:  0.4727334
Encoder Loss:  0.025078723  || Decoder Loss:  0.0028507283 Validation Decoder Loss:  0.47340974
Encoder Loss:  0.02492759  || Decoder Loss:  0.002823194 Validation Decoder Loss:  0.4736979
Encoder Loss:  0.024821874  || Decoder Loss:  0.0027989116 Validation Decoder Loss:  0.47399646
Encoder Loss:  0.02473909  || Decoder Loss:  0.002764474 Validation Decoder Loss:  0.4739599
Encoder Loss:  0.024651686  || Decoder Loss:  0.0027172759 Validation Decoder Loss:  0.47360945
Encoder Loss:  0.024575792  || Decoder Loss:  0.0026798178 Validation Decoder Loss:  0.4730226
Encoder Loss:  0.024503313  || Decoder Loss:  0.0026216912 Validation Decoder Loss:  0.47152272
Encoder Loss:  0.024433142  || Decoder Loss:  0.0025573515 Validation Decoder Loss:  0.47044057
Encoder Loss:  0.024374569  || Decoder Loss:  0.002506481 Validation Decoder Loss:  0.47023714
Encoder Loss:  0.024323676  || Decoder Loss:  0.0024598131 Validation Decoder Loss:  0.4702781
Encoder Loss:  0.02427925  || Decoder Loss:  0.00242277 Validation Decoder Loss:  0.47037578
Encoder Loss:  0.024243724  || Decoder Loss:  0.0023944716 Validation Decoder Loss:  0.4705351
Encoder Loss:  0.02421002  || Decoder Loss:  0.0023650825 Validation Decoder Loss:  0.4705263
Encoder Loss:  0.024179218  || Decoder Loss:  0.002332508 Validation Decoder Loss:  0.47051024
Encoder Loss:  0.024154026  || Decoder Loss:  0.0023103997 Validation Decoder Loss:  0.4707296
Encoder Loss:  0.024131278  || Decoder Loss:  0.002291774 Validation Decoder Loss:  0.47110438
Encoder Loss:  0.024111146  || Decoder Loss:  0.0022767175 Validation Decoder Loss:  0.47155803
Encoder Loss:  0.02409446  || Decoder Loss:  0.0022670794 Validation Decoder Loss:  0.4719671
Model: bold_synthesis_net_lr_0.00024422809637602303 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4719671
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 130, 14, 16, 1)    25        
_________________________________________________________________
reshape_53 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030847643  || Decoder Loss:  0.0076889056 Validation Decoder Loss:  0.37713477
Encoder Loss:  0.02057758  || Decoder Loss:  0.005422985 Validation Decoder Loss:  0.40408587
Encoder Loss:  0.018958693  || Decoder Loss:  0.0044492274 Validation Decoder Loss:  0.39266473
Encoder Loss:  0.017986445  || Decoder Loss:  0.0040068803 Validation Decoder Loss:  0.39125842
Encoder Loss:  0.017241979  || Decoder Loss:  0.0036049532 Validation Decoder Loss:  0.3937326
Encoder Loss:  0.01653328  || Decoder Loss:  0.0033609872 Validation Decoder Loss:  0.38345742
Encoder Loss:  0.01597801  || Decoder Loss:  0.0035433113 Validation Decoder Loss:  0.27785736
Encoder Loss:  0.01514485  || Decoder Loss:  0.0033150923 Validation Decoder Loss:  0.27151403
Encoder Loss:  0.01402944  || Decoder Loss:  0.0021376978 Validation Decoder Loss:  0.26545215
Encoder Loss:  0.0136955585  || Decoder Loss:  0.0017960708 Validation Decoder Loss:  0.2758289
Encoder Loss:  0.0135297  || Decoder Loss:  0.0016169465 Validation Decoder Loss:  0.2539043
Encoder Loss:  0.0134091405  || Decoder Loss:  0.0014844297 Validation Decoder Loss:  0.23610838
Encoder Loss:  0.013299339  || Decoder Loss:  0.0013580221 Validation Decoder Loss:  0.22427656
Encoder Loss:  0.013214204  || Decoder Loss:  0.0012593801 Validation Decoder Loss:  0.21412438
Encoder Loss:  0.013148886  || Decoder Loss:  0.0011835679 Validation Decoder Loss:  0.2055392
Encoder Loss:  0.013090533  || Decoder Loss:  0.0011142457 Validation Decoder Loss:  0.19442165
Encoder Loss:  0.013034865  || Decoder Loss:  0.0010440475 Validation Decoder Loss:  0.18181017
Encoder Loss:  0.012983177  || Decoder Loss:  0.0009783834 Validation Decoder Loss:  0.17502
Encoder Loss:  0.012937835  || Decoder Loss:  0.00092493306 Validation Decoder Loss:  0.16652222
Encoder Loss:  0.01289477  || Decoder Loss:  0.0008712735 Validation Decoder Loss:  0.15677853
Encoder Loss:  0.012855261  || Decoder Loss:  0.0008189396 Validation Decoder Loss:  0.14612927
Encoder Loss:  0.012814302  || Decoder Loss:  0.0007639626 Validation Decoder Loss:  0.1402506
Encoder Loss:  0.012778816  || Decoder Loss:  0.00071780104 Validation Decoder Loss:  0.13436857
Encoder Loss:  0.012751956  || Decoder Loss:  0.0006838062 Validation Decoder Loss:  0.12856579
Encoder Loss:  0.012731377  || Decoder Loss:  0.00066024554 Validation Decoder Loss:  0.124171324
Encoder Loss:  0.0127110435  || Decoder Loss:  0.0006349291 Validation Decoder Loss:  0.12033974
Encoder Loss:  0.01268929  || Decoder Loss:  0.0006086917 Validation Decoder Loss:  0.11311279
Encoder Loss:  0.012672007  || Decoder Loss:  0.00058439374 Validation Decoder Loss:  0.10552679
Encoder Loss:  0.012652431  || Decoder Loss:  0.0005622039 Validation Decoder Loss:  0.10527103
Encoder Loss:  0.012638753  || Decoder Loss:  0.00054330326 Validation Decoder Loss:  0.10266432
Encoder Loss:  0.012625236  || Decoder Loss:  0.00052811165 Validation Decoder Loss:  0.09788349
Encoder Loss:  0.01261572  || Decoder Loss:  0.00051416206 Validation Decoder Loss:  0.091125175
Encoder Loss:  0.012600948  || Decoder Loss:  0.0004977838 Validation Decoder Loss:  0.08299705
Encoder Loss:  0.012588128  || Decoder Loss:  0.00048118932 Validation Decoder Loss:  0.0832427
Encoder Loss:  0.012574898  || Decoder Loss:  0.00046464306 Validation Decoder Loss:  0.07796605
Encoder Loss:  0.0125598395  || Decoder Loss:  0.00044497024 Validation Decoder Loss:  0.07124272
Encoder Loss:  0.01254971  || Decoder Loss:  0.00043046998 Validation Decoder Loss:  0.06778185
Encoder Loss:  0.012540389  || Decoder Loss:  0.0004195763 Validation Decoder Loss:  0.062346637
Encoder Loss:  0.0125333695  || Decoder Loss:  0.00040976302 Validation Decoder Loss:  0.056510046
Encoder Loss:  0.012524424  || Decoder Loss:  0.00040042656 Validation Decoder Loss:  0.055893768
Model: bold_synthesis_net_lr_0.0006781756767737549 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.055893768
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 130, 14, 16, 1)    25        
_________________________________________________________________
reshape_54 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0074629094  || Decoder Loss:  0.0074629094 Validation Decoder Loss:  0.3886539
Encoder Loss:  0.006228147  || Decoder Loss:  0.006228147 Validation Decoder Loss:  0.38517213
Encoder Loss:  0.0056328415  || Decoder Loss:  0.0056328415 Validation Decoder Loss:  0.3802592
Encoder Loss:  0.0050171083  || Decoder Loss:  0.0050171083 Validation Decoder Loss:  0.3752457
Encoder Loss:  0.004499955  || Decoder Loss:  0.004499955 Validation Decoder Loss:  0.3691361
Encoder Loss:  0.0041122325  || Decoder Loss:  0.0041122325 Validation Decoder Loss:  0.36326894
Encoder Loss:  0.0038144384  || Decoder Loss:  0.0038144384 Validation Decoder Loss:  0.3552637
Encoder Loss:  0.0034719927  || Decoder Loss:  0.0034719927 Validation Decoder Loss:  0.34887016
Encoder Loss:  0.003245035  || Decoder Loss:  0.003245035 Validation Decoder Loss:  0.33742023
Encoder Loss:  0.0031176517  || Decoder Loss:  0.0031176517 Validation Decoder Loss:  0.3337473
Encoder Loss:  0.0030340278  || Decoder Loss:  0.0030340278 Validation Decoder Loss:  0.325949
Encoder Loss:  0.0029333243  || Decoder Loss:  0.0029333243 Validation Decoder Loss:  0.3178842
Encoder Loss:  0.0028778373  || Decoder Loss:  0.0028778373 Validation Decoder Loss:  0.3143185
Encoder Loss:  0.0028006127  || Decoder Loss:  0.0028006127 Validation Decoder Loss:  0.3090433
Encoder Loss:  0.0027330283  || Decoder Loss:  0.0027330283 Validation Decoder Loss:  0.3028077
Encoder Loss:  0.002668169  || Decoder Loss:  0.002668169 Validation Decoder Loss:  0.3006771
Encoder Loss:  0.0025920179  || Decoder Loss:  0.0025920179 Validation Decoder Loss:  0.29745376
Encoder Loss:  0.0025306814  || Decoder Loss:  0.0025306814 Validation Decoder Loss:  0.29386118
Encoder Loss:  0.0024779597  || Decoder Loss:  0.0024779597 Validation Decoder Loss:  0.28884947
Encoder Loss:  0.0024191951  || Decoder Loss:  0.0024191951 Validation Decoder Loss:  0.2764869
Encoder Loss:  0.0023591167  || Decoder Loss:  0.0023591167 Validation Decoder Loss:  0.27353418
Encoder Loss:  0.002318949  || Decoder Loss:  0.002318949 Validation Decoder Loss:  0.27193516
Encoder Loss:  0.0022796788  || Decoder Loss:  0.0022796788 Validation Decoder Loss:  0.26910204
Encoder Loss:  0.002236403  || Decoder Loss:  0.002236403 Validation Decoder Loss:  0.2626498
Encoder Loss:  0.0021976759  || Decoder Loss:  0.0021976759 Validation Decoder Loss:  0.25736547
Encoder Loss:  0.0021531247  || Decoder Loss:  0.0021531247 Validation Decoder Loss:  0.2503519
Encoder Loss:  0.0020348893  || Decoder Loss:  0.0020348893 Validation Decoder Loss:  0.23229817
Encoder Loss:  0.0018622169  || Decoder Loss:  0.0018622169 Validation Decoder Loss:  0.22762749
Encoder Loss:  0.0017767801  || Decoder Loss:  0.0017767801 Validation Decoder Loss:  0.22066954
Encoder Loss:  0.0017053471  || Decoder Loss:  0.0017053471 Validation Decoder Loss:  0.21012789
Encoder Loss:  0.0016607938  || Decoder Loss:  0.0016607938 Validation Decoder Loss:  0.20955415
Encoder Loss:  0.0016283772  || Decoder Loss:  0.0016283772 Validation Decoder Loss:  0.21043992
Encoder Loss:  0.001605781  || Decoder Loss:  0.001605781 Validation Decoder Loss:  0.20462078
Encoder Loss:  0.001583138  || Decoder Loss:  0.001583138 Validation Decoder Loss:  0.20085973
Encoder Loss:  0.0015527417  || Decoder Loss:  0.0015527417 Validation Decoder Loss:  0.20031376
Encoder Loss:  0.0015202991  || Decoder Loss:  0.0015202991 Validation Decoder Loss:  0.20036465
Encoder Loss:  0.0014901094  || Decoder Loss:  0.0014901094 Validation Decoder Loss:  0.19829822
Encoder Loss:  0.0014656867  || Decoder Loss:  0.0014656867 Validation Decoder Loss:  0.19236952
Encoder Loss:  0.0014444685  || Decoder Loss:  0.0014444685 Validation Decoder Loss:  0.19416498
Encoder Loss:  0.0014209589  || Decoder Loss:  0.0014209589 Validation Decoder Loss:  0.19400477
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.19400476
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 182, 10, 16, 1)    337       
_________________________________________________________________
reshape_55 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.006234743  || Decoder Loss:  0.006234743 Validation Decoder Loss:  0.38304386
Encoder Loss:  0.004900811  || Decoder Loss:  0.004900811 Validation Decoder Loss:  0.38479236
Encoder Loss:  0.004303313  || Decoder Loss:  0.004303313 Validation Decoder Loss:  0.38456136
Encoder Loss:  0.003982856  || Decoder Loss:  0.003982856 Validation Decoder Loss:  0.3840856
Encoder Loss:  0.0038103743  || Decoder Loss:  0.0038103743 Validation Decoder Loss:  0.3839383
Encoder Loss:  0.0036685828  || Decoder Loss:  0.0036685828 Validation Decoder Loss:  0.38376054
Encoder Loss:  0.0035759846  || Decoder Loss:  0.0035759846 Validation Decoder Loss:  0.38343105
Encoder Loss:  0.0035059028  || Decoder Loss:  0.0035059028 Validation Decoder Loss:  0.3834474
Encoder Loss:  0.0034422306  || Decoder Loss:  0.0034422306 Validation Decoder Loss:  0.38350147
Encoder Loss:  0.0033840968  || Decoder Loss:  0.0033840968 Validation Decoder Loss:  0.38355196
Encoder Loss:  0.0033216998  || Decoder Loss:  0.0033216998 Validation Decoder Loss:  0.38344234
Encoder Loss:  0.0032717413  || Decoder Loss:  0.0032717413 Validation Decoder Loss:  0.38364592
Encoder Loss:  0.003224308  || Decoder Loss:  0.003224308 Validation Decoder Loss:  0.38407513
Encoder Loss:  0.003174781  || Decoder Loss:  0.003174781 Validation Decoder Loss:  0.38430718
Encoder Loss:  0.0031295058  || Decoder Loss:  0.0031295058 Validation Decoder Loss:  0.3844859
Encoder Loss:  0.0030884345  || Decoder Loss:  0.0030884345 Validation Decoder Loss:  0.38463748
Encoder Loss:  0.0030467354  || Decoder Loss:  0.0030467354 Validation Decoder Loss:  0.38467547
Encoder Loss:  0.0030138432  || Decoder Loss:  0.0030138432 Validation Decoder Loss:  0.3847715
Encoder Loss:  0.0029867622  || Decoder Loss:  0.0029867622 Validation Decoder Loss:  0.3847472
Encoder Loss:  0.0029649078  || Decoder Loss:  0.0029649078 Validation Decoder Loss:  0.38477522
Encoder Loss:  0.0029422508  || Decoder Loss:  0.0029422508 Validation Decoder Loss:  0.38477868
Encoder Loss:  0.0029183964  || Decoder Loss:  0.0029183964 Validation Decoder Loss:  0.38477835
Encoder Loss:  0.0028962456  || Decoder Loss:  0.0028962456 Validation Decoder Loss:  0.38478813
Encoder Loss:  0.0028714119  || Decoder Loss:  0.0028714119 Validation Decoder Loss:  0.3847051
Encoder Loss:  0.0028461579  || Decoder Loss:  0.0028461579 Validation Decoder Loss:  0.38466838
Encoder Loss:  0.002822001  || Decoder Loss:  0.002822001 Validation Decoder Loss:  0.3847325
Encoder Loss:  0.0027997321  || Decoder Loss:  0.0027997321 Validation Decoder Loss:  0.38463262
Encoder Loss:  0.002777147  || Decoder Loss:  0.002777147 Validation Decoder Loss:  0.38450873
Encoder Loss:  0.0027598245  || Decoder Loss:  0.0027598245 Validation Decoder Loss:  0.3844221
Encoder Loss:  0.00274171  || Decoder Loss:  0.00274171 Validation Decoder Loss:  0.38435894
Encoder Loss:  0.002725404  || Decoder Loss:  0.002725404 Validation Decoder Loss:  0.3842993
Encoder Loss:  0.0027113364  || Decoder Loss:  0.0027113364 Validation Decoder Loss:  0.384223
Encoder Loss:  0.0026989665  || Decoder Loss:  0.0026989665 Validation Decoder Loss:  0.3841709
Encoder Loss:  0.0026853436  || Decoder Loss:  0.0026853436 Validation Decoder Loss:  0.38410586
Encoder Loss:  0.0026735342  || Decoder Loss:  0.0026735342 Validation Decoder Loss:  0.38404492
Encoder Loss:  0.002661274  || Decoder Loss:  0.002661274 Validation Decoder Loss:  0.38398358
Encoder Loss:  0.0026495776  || Decoder Loss:  0.0026495776 Validation Decoder Loss:  0.3839256
Encoder Loss:  0.0026385447  || Decoder Loss:  0.0026385447 Validation Decoder Loss:  0.383858
Encoder Loss:  0.0026256766  || Decoder Loss:  0.0026256766 Validation Decoder Loss:  0.38380557
Encoder Loss:  0.0026140448  || Decoder Loss:  0.0026140448 Validation Decoder Loss:  0.3837496
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3837496
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 91, 20, 16, 1)     337       
_________________________________________________________________
reshape_56 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.006155381  || Decoder Loss:  0.006155381 Validation Decoder Loss:  0.38294446
Encoder Loss:  0.0047905273  || Decoder Loss:  0.0047905273 Validation Decoder Loss:  0.38305095
Encoder Loss:  0.0043690023  || Decoder Loss:  0.0043690023 Validation Decoder Loss:  0.3825894
Encoder Loss:  0.0041095586  || Decoder Loss:  0.0041095586 Validation Decoder Loss:  0.3822372
Encoder Loss:  0.0038560843  || Decoder Loss:  0.0038560843 Validation Decoder Loss:  0.38229382
Encoder Loss:  0.0036810162  || Decoder Loss:  0.0036810162 Validation Decoder Loss:  0.38208586
Encoder Loss:  0.003555963  || Decoder Loss:  0.003555963 Validation Decoder Loss:  0.38169533
Encoder Loss:  0.0034375787  || Decoder Loss:  0.0034375787 Validation Decoder Loss:  0.38125128
Encoder Loss:  0.0033208968  || Decoder Loss:  0.0033208968 Validation Decoder Loss:  0.38126567
Encoder Loss:  0.0032177656  || Decoder Loss:  0.0032177656 Validation Decoder Loss:  0.3812049
Encoder Loss:  0.0031331594  || Decoder Loss:  0.0031331594 Validation Decoder Loss:  0.38085237
Encoder Loss:  0.0030743026  || Decoder Loss:  0.0030743026 Validation Decoder Loss:  0.38024768
Encoder Loss:  0.00301033  || Decoder Loss:  0.00301033 Validation Decoder Loss:  0.3792934
Encoder Loss:  0.002944428  || Decoder Loss:  0.002944428 Validation Decoder Loss:  0.37903112
Encoder Loss:  0.0029058086  || Decoder Loss:  0.0029058086 Validation Decoder Loss:  0.37903804
Encoder Loss:  0.0028725406  || Decoder Loss:  0.0028725406 Validation Decoder Loss:  0.3791344
Encoder Loss:  0.0028469814  || Decoder Loss:  0.0028469814 Validation Decoder Loss:  0.37917694
Encoder Loss:  0.002825321  || Decoder Loss:  0.002825321 Validation Decoder Loss:  0.37925553
Encoder Loss:  0.0028053892  || Decoder Loss:  0.0028053892 Validation Decoder Loss:  0.37927735
Encoder Loss:  0.0027876496  || Decoder Loss:  0.0027876496 Validation Decoder Loss:  0.3792957
Encoder Loss:  0.0027721925  || Decoder Loss:  0.0027721925 Validation Decoder Loss:  0.37925336
Encoder Loss:  0.002757498  || Decoder Loss:  0.002757498 Validation Decoder Loss:  0.37926424
Encoder Loss:  0.0027424933  || Decoder Loss:  0.0027424933 Validation Decoder Loss:  0.37929666
Encoder Loss:  0.002728825  || Decoder Loss:  0.002728825 Validation Decoder Loss:  0.37930027
Encoder Loss:  0.0027174284  || Decoder Loss:  0.0027174284 Validation Decoder Loss:  0.37927932
Encoder Loss:  0.0027057338  || Decoder Loss:  0.0027057338 Validation Decoder Loss:  0.3792058
Encoder Loss:  0.0026947407  || Decoder Loss:  0.0026947407 Validation Decoder Loss:  0.3791337
Encoder Loss:  0.0026829864  || Decoder Loss:  0.0026829864 Validation Decoder Loss:  0.37901813
Encoder Loss:  0.0026727628  || Decoder Loss:  0.0026727628 Validation Decoder Loss:  0.37892413
Encoder Loss:  0.0026625851  || Decoder Loss:  0.0026625851 Validation Decoder Loss:  0.3788203
Encoder Loss:  0.0026514847  || Decoder Loss:  0.0026514847 Validation Decoder Loss:  0.3787437
Encoder Loss:  0.0026418637  || Decoder Loss:  0.0026418637 Validation Decoder Loss:  0.3786817
Encoder Loss:  0.0026325928  || Decoder Loss:  0.0026325928 Validation Decoder Loss:  0.3786087
Encoder Loss:  0.00262368  || Decoder Loss:  0.00262368 Validation Decoder Loss:  0.37854418
Encoder Loss:  0.0026150714  || Decoder Loss:  0.0026150714 Validation Decoder Loss:  0.37850565
Encoder Loss:  0.0026087442  || Decoder Loss:  0.0026087442 Validation Decoder Loss:  0.37847266
Encoder Loss:  0.0026036454  || Decoder Loss:  0.0026036454 Validation Decoder Loss:  0.37846774
Encoder Loss:  0.002596233  || Decoder Loss:  0.002596233 Validation Decoder Loss:  0.378442
Encoder Loss:  0.0025909096  || Decoder Loss:  0.0025909096 Validation Decoder Loss:  0.37846035
Encoder Loss:  0.0025859596  || Decoder Loss:  0.0025859596 Validation Decoder Loss:  0.37848753
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.37848753
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 70, 26, 16, 1)     99        
_________________________________________________________________
reshape_57 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02641361  || Decoder Loss:  0.0074847676 Validation Decoder Loss:  0.38942903
Encoder Loss:  0.021276621  || Decoder Loss:  0.0055538104 Validation Decoder Loss:  0.4047342
Encoder Loss:  0.019903056  || Decoder Loss:  0.005066586 Validation Decoder Loss:  0.39941657
Encoder Loss:  0.018237283  || Decoder Loss:  0.0045481334 Validation Decoder Loss:  0.31905186
Encoder Loss:  0.015801871  || Decoder Loss:  0.0031007968 Validation Decoder Loss:  0.22957659
Encoder Loss:  0.014740076  || Decoder Loss:  0.002545811 Validation Decoder Loss:  0.16090089
Encoder Loss:  0.013834685  || Decoder Loss:  0.0017685712 Validation Decoder Loss:  0.118296266
Encoder Loss:  0.013358373  || Decoder Loss:  0.0013511302 Validation Decoder Loss:  0.104352415
Encoder Loss:  0.013137493  || Decoder Loss:  0.0011902475 Validation Decoder Loss:  0.0958005
Encoder Loss:  0.012949437  || Decoder Loss:  0.001037725 Validation Decoder Loss:  0.09631133
Encoder Loss:  0.012827224  || Decoder Loss:  0.0009407937 Validation Decoder Loss:  0.086529374
Encoder Loss:  0.012730555  || Decoder Loss:  0.00086642633 Validation Decoder Loss:  0.08008206
Encoder Loss:  0.012662181  || Decoder Loss:  0.0008188073 Validation Decoder Loss:  0.07934374
Encoder Loss:  0.012614327  || Decoder Loss:  0.0007844704 Validation Decoder Loss:  0.075537175
Encoder Loss:  0.012563469  || Decoder Loss:  0.0007435094 Validation Decoder Loss:  0.07319599
Encoder Loss:  0.01251324  || Decoder Loss:  0.0007013298 Validation Decoder Loss:  0.068667516
Encoder Loss:  0.012473425  || Decoder Loss:  0.0006660784 Validation Decoder Loss:  0.070652366
Encoder Loss:  0.01244647  || Decoder Loss:  0.00064290577 Validation Decoder Loss:  0.068221726
Encoder Loss:  0.012423896  || Decoder Loss:  0.00062267575 Validation Decoder Loss:  0.06437223
Encoder Loss:  0.012402224  || Decoder Loss:  0.00060600665 Validation Decoder Loss:  0.06384128
Encoder Loss:  0.012389939  || Decoder Loss:  0.00059757015 Validation Decoder Loss:  0.06393028
Encoder Loss:  0.012372762  || Decoder Loss:  0.0005826252 Validation Decoder Loss:  0.06565715
Encoder Loss:  0.012363954  || Decoder Loss:  0.00057858805 Validation Decoder Loss:  0.059686717
Encoder Loss:  0.012358746  || Decoder Loss:  0.00057560555 Validation Decoder Loss:  0.052875806
Encoder Loss:  0.01234732  || Decoder Loss:  0.00056533614 Validation Decoder Loss:  0.056541476
Encoder Loss:  0.012336991  || Decoder Loss:  0.00055430987 Validation Decoder Loss:  0.05383464
Encoder Loss:  0.012320839  || Decoder Loss:  0.0005408023 Validation Decoder Loss:  0.050534833
Encoder Loss:  0.01231694  || Decoder Loss:  0.00053773174 Validation Decoder Loss:  0.052104406
Encoder Loss:  0.01230964  || Decoder Loss:  0.0005309817 Validation Decoder Loss:  0.048930973
Encoder Loss:  0.012305608  || Decoder Loss:  0.0005268818 Validation Decoder Loss:  0.053407688
Encoder Loss:  0.012297748  || Decoder Loss:  0.0005217525 Validation Decoder Loss:  0.04759062
Encoder Loss:  0.012289025  || Decoder Loss:  0.00051444647 Validation Decoder Loss:  0.05257279
Encoder Loss:  0.012288296  || Decoder Loss:  0.0005119873 Validation Decoder Loss:  0.050649904
Encoder Loss:  0.012282133  || Decoder Loss:  0.00050774333 Validation Decoder Loss:  0.046745323
Encoder Loss:  0.012276688  || Decoder Loss:  0.0005033428 Validation Decoder Loss:  0.05158855
Encoder Loss:  0.012268206  || Decoder Loss:  0.0004928531 Validation Decoder Loss:  0.05082197
Encoder Loss:  0.012267973  || Decoder Loss:  0.0004940409 Validation Decoder Loss:  0.045464553
Encoder Loss:  0.012262645  || Decoder Loss:  0.00048747417 Validation Decoder Loss:  0.047066323
Encoder Loss:  0.012254367  || Decoder Loss:  0.0004802412 Validation Decoder Loss:  0.0450887
Encoder Loss:  0.01225081  || Decoder Loss:  0.00047437754 Validation Decoder Loss:  0.04519023
Model: bold_synthesis_net_lr_0.0008033395885925249 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.04519023
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 65, 28, 16, 1)     25        
_________________________________________________________________
reshape_58 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02541588  || Decoder Loss:  0.006994771 Validation Decoder Loss:  0.41096258
Encoder Loss:  0.017187428  || Decoder Loss:  0.0044493834 Validation Decoder Loss:  0.4195811
Encoder Loss:  0.015632464  || Decoder Loss:  0.004009801 Validation Decoder Loss:  0.4049222
Encoder Loss:  0.01464733  || Decoder Loss:  0.003558315 Validation Decoder Loss:  0.38134992
Encoder Loss:  0.013687317  || Decoder Loss:  0.0030800863 Validation Decoder Loss:  0.3609358
Encoder Loss:  0.013030464  || Decoder Loss:  0.0027964152 Validation Decoder Loss:  0.34607136
Encoder Loss:  0.012646531  || Decoder Loss:  0.002597125 Validation Decoder Loss:  0.33623302
Encoder Loss:  0.012350702  || Decoder Loss:  0.0024021773 Validation Decoder Loss:  0.32537398
Encoder Loss:  0.011986689  || Decoder Loss:  0.002035358 Validation Decoder Loss:  0.30080384
Encoder Loss:  0.011678489  || Decoder Loss:  0.001685118 Validation Decoder Loss:  0.28539395
Encoder Loss:  0.011487267  || Decoder Loss:  0.0014768088 Validation Decoder Loss:  0.267886
Encoder Loss:  0.011351129  || Decoder Loss:  0.0013264996 Validation Decoder Loss:  0.256809
Encoder Loss:  0.011263269  || Decoder Loss:  0.001227755 Validation Decoder Loss:  0.24830292
Encoder Loss:  0.011192585  || Decoder Loss:  0.0011489926 Validation Decoder Loss:  0.23737574
Encoder Loss:  0.011149926  || Decoder Loss:  0.0011098663 Validation Decoder Loss:  0.22392717
Encoder Loss:  0.011115597  || Decoder Loss:  0.0010750841 Validation Decoder Loss:  0.21226573
Encoder Loss:  0.011077484  || Decoder Loss:  0.0010368389 Validation Decoder Loss:  0.20766816
Encoder Loss:  0.011032908  || Decoder Loss:  0.0009883153 Validation Decoder Loss:  0.19585146
Encoder Loss:  0.010989572  || Decoder Loss:  0.00093747367 Validation Decoder Loss:  0.19211645
Encoder Loss:  0.010953597  || Decoder Loss:  0.0008965813 Validation Decoder Loss:  0.18557882
Encoder Loss:  0.010916661  || Decoder Loss:  0.00085214706 Validation Decoder Loss:  0.17746913
Encoder Loss:  0.0108750155  || Decoder Loss:  0.00080586504 Validation Decoder Loss:  0.17568749
Encoder Loss:  0.010841832  || Decoder Loss:  0.00076785655 Validation Decoder Loss:  0.1694
Encoder Loss:  0.01080698  || Decoder Loss:  0.0007272558 Validation Decoder Loss:  0.16523218
Encoder Loss:  0.010778499  || Decoder Loss:  0.00069514016 Validation Decoder Loss:  0.16318703
Encoder Loss:  0.0107569415  || Decoder Loss:  0.0006731441 Validation Decoder Loss:  0.16240579
Encoder Loss:  0.010734182  || Decoder Loss:  0.00064567674 Validation Decoder Loss:  0.15905634
Encoder Loss:  0.010709013  || Decoder Loss:  0.0006195064 Validation Decoder Loss:  0.15724136
Encoder Loss:  0.010690583  || Decoder Loss:  0.0005992917 Validation Decoder Loss:  0.15485534
Encoder Loss:  0.010675466  || Decoder Loss:  0.00057955494 Validation Decoder Loss:  0.15180446
Encoder Loss:  0.010660657  || Decoder Loss:  0.0005655624 Validation Decoder Loss:  0.15028271
Encoder Loss:  0.010644815  || Decoder Loss:  0.00054520776 Validation Decoder Loss:  0.14779028
Encoder Loss:  0.010632954  || Decoder Loss:  0.0005327617 Validation Decoder Loss:  0.14807247
Encoder Loss:  0.010622518  || Decoder Loss:  0.00052214524 Validation Decoder Loss:  0.14901492
Encoder Loss:  0.010616927  || Decoder Loss:  0.00051232293 Validation Decoder Loss:  0.14741868
Encoder Loss:  0.010600821  || Decoder Loss:  0.00049837556 Validation Decoder Loss:  0.14490746
Encoder Loss:  0.010591782  || Decoder Loss:  0.0004873311 Validation Decoder Loss:  0.1451567
Encoder Loss:  0.010581533  || Decoder Loss:  0.00047397194 Validation Decoder Loss:  0.14724447
Encoder Loss:  0.010572482  || Decoder Loss:  0.0004636905 Validation Decoder Loss:  0.14162046
Encoder Loss:  0.010565366  || Decoder Loss:  0.00045550108 Validation Decoder Loss:  0.14710774
Model: bold_synthesis_net_lr_0.0009656825907777232 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.14710775
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 364, 5, 16, 1)     302       
_________________________________________________________________
reshape_59 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 302
Trainable params: 302
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.016648233  || Decoder Loss:  0.0036427323 Validation Decoder Loss:  0.47525072
Encoder Loss:  0.015307525  || Decoder Loss:  0.0032255286 Validation Decoder Loss:  0.47132662
Encoder Loss:  0.014685529  || Decoder Loss:  0.0030507029 Validation Decoder Loss:  0.4706676
Encoder Loss:  0.014249026  || Decoder Loss:  0.0030053677 Validation Decoder Loss:  0.47176474
Encoder Loss:  0.01370054  || Decoder Loss:  0.00295905 Validation Decoder Loss:  0.46958455
Encoder Loss:  0.013175126  || Decoder Loss:  0.0028514527 Validation Decoder Loss:  0.4702944
Encoder Loss:  0.012865987  || Decoder Loss:  0.0027423743 Validation Decoder Loss:  0.46923125
Encoder Loss:  0.012622709  || Decoder Loss:  0.0025839922 Validation Decoder Loss:  0.4693332
Encoder Loss:  0.012452874  || Decoder Loss:  0.002451692 Validation Decoder Loss:  0.4697708
Encoder Loss:  0.012355366  || Decoder Loss:  0.0023748816 Validation Decoder Loss:  0.471298
Encoder Loss:  0.012291593  || Decoder Loss:  0.0023193522 Validation Decoder Loss:  0.46955982
Encoder Loss:  0.012235836  || Decoder Loss:  0.0022616421 Validation Decoder Loss:  0.46965617
Encoder Loss:  0.012208722  || Decoder Loss:  0.0022366622 Validation Decoder Loss:  0.46997565
Encoder Loss:  0.012176615  || Decoder Loss:  0.002205303 Validation Decoder Loss:  0.46993375
Encoder Loss:  0.012164738  || Decoder Loss:  0.002197532 Validation Decoder Loss:  0.47052395
Encoder Loss:  0.012136638  || Decoder Loss:  0.0021645583 Validation Decoder Loss:  0.47057235
Encoder Loss:  0.012125227  || Decoder Loss:  0.0021565007 Validation Decoder Loss:  0.46998608
Encoder Loss:  0.012111258  || Decoder Loss:  0.002144268 Validation Decoder Loss:  0.47054762
Encoder Loss:  0.012101214  || Decoder Loss:  0.0021359697 Validation Decoder Loss:  0.47089088
Encoder Loss:  0.012101943  || Decoder Loss:  0.0021412284 Validation Decoder Loss:  0.47195137
Encoder Loss:  0.012069488  || Decoder Loss:  0.0021011156 Validation Decoder Loss:  0.47113836
Encoder Loss:  0.0120532615  || Decoder Loss:  0.0020813309 Validation Decoder Loss:  0.4709788
Encoder Loss:  0.012065065  || Decoder Loss:  0.0021016197 Validation Decoder Loss:  0.47204745
Encoder Loss:  0.012038943  || Decoder Loss:  0.0020656493 Validation Decoder Loss:  0.4720148
Encoder Loss:  0.0120271  || Decoder Loss:  0.0020540168 Validation Decoder Loss:  0.47217748
Encoder Loss:  0.012025582  || Decoder Loss:  0.0020527523 Validation Decoder Loss:  0.47243333
Encoder Loss:  0.0120160505  || Decoder Loss:  0.002042671 Validation Decoder Loss:  0.47258615
Encoder Loss:  0.012008198  || Decoder Loss:  0.002035621 Validation Decoder Loss:  0.47271186
Encoder Loss:  0.011996982  || Decoder Loss:  0.00202045 Validation Decoder Loss:  0.4724657
Encoder Loss:  0.011991961  || Decoder Loss:  0.0020172847 Validation Decoder Loss:  0.47243142
Encoder Loss:  0.011983783  || Decoder Loss:  0.0020067585 Validation Decoder Loss:  0.47284186
Encoder Loss:  0.011977533  || Decoder Loss:  0.002000072 Validation Decoder Loss:  0.47307837
Encoder Loss:  0.011970249  || Decoder Loss:  0.0019922403 Validation Decoder Loss:  0.47312558
Encoder Loss:  0.011968556  || Decoder Loss:  0.0019905881 Validation Decoder Loss:  0.47296423
Encoder Loss:  0.0119717335  || Decoder Loss:  0.0019973011 Validation Decoder Loss:  0.47365028
Encoder Loss:  0.011963963  || Decoder Loss:  0.0019872335 Validation Decoder Loss:  0.4738761
Encoder Loss:  0.011958444  || Decoder Loss:  0.0019796377 Validation Decoder Loss:  0.4735904
Encoder Loss:  0.011955757  || Decoder Loss:  0.0019776216 Validation Decoder Loss:  0.4736817
Encoder Loss:  0.011953559  || Decoder Loss:  0.001977079 Validation Decoder Loss:  0.47407734
Encoder Loss:  0.011948054  || Decoder Loss:  0.0019719421 Validation Decoder Loss:  0.47378302
Model: bold_synthesis_net_lr_0.0009380382507831585 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.47378296
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 65, 28, 16, 1)     17        
_________________________________________________________________
reshape_60 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.032336526  || Decoder Loss:  0.0072913812 Validation Decoder Loss:  0.32239187
Encoder Loss:  0.023211796  || Decoder Loss:  0.006346423 Validation Decoder Loss:  0.38273495
Encoder Loss:  0.019154023  || Decoder Loss:  0.0045977985 Validation Decoder Loss:  0.39248204
Encoder Loss:  0.0180887  || Decoder Loss:  0.0040152855 Validation Decoder Loss:  0.37107345
Encoder Loss:  0.017115744  || Decoder Loss:  0.0034907253 Validation Decoder Loss:  0.34582356
Encoder Loss:  0.01640328  || Decoder Loss:  0.0032538855 Validation Decoder Loss:  0.33098745
Encoder Loss:  0.015748518  || Decoder Loss:  0.0029894484 Validation Decoder Loss:  0.3067261
Encoder Loss:  0.015279468  || Decoder Loss:  0.0027755816 Validation Decoder Loss:  0.28220153
Encoder Loss:  0.014853201  || Decoder Loss:  0.0025357867 Validation Decoder Loss:  0.2545539
Encoder Loss:  0.014619117  || Decoder Loss:  0.002487383 Validation Decoder Loss:  0.23283884
Encoder Loss:  0.014389179  || Decoder Loss:  0.0023811406 Validation Decoder Loss:  0.21480459
Encoder Loss:  0.01410329  || Decoder Loss:  0.0021626465 Validation Decoder Loss:  0.18870372
Encoder Loss:  0.013904067  || Decoder Loss:  0.0019749678 Validation Decoder Loss:  0.17427707
Encoder Loss:  0.013689118  || Decoder Loss:  0.0017340694 Validation Decoder Loss:  0.14972249
Encoder Loss:  0.013519908  || Decoder Loss:  0.0015371756 Validation Decoder Loss:  0.13214065
Encoder Loss:  0.013386866  || Decoder Loss:  0.0013791826 Validation Decoder Loss:  0.11018069
Encoder Loss:  0.013243727  || Decoder Loss:  0.0012012207 Validation Decoder Loss:  0.08852938
Encoder Loss:  0.013128078  || Decoder Loss:  0.0010622916 Validation Decoder Loss:  0.08329727
Encoder Loss:  0.013055965  || Decoder Loss:  0.0009830125 Validation Decoder Loss:  0.076115996
Encoder Loss:  0.012989316  || Decoder Loss:  0.00090411305 Validation Decoder Loss:  0.06964202
Encoder Loss:  0.012932587  || Decoder Loss:  0.00084151357 Validation Decoder Loss:  0.068114236
Encoder Loss:  0.012884746  || Decoder Loss:  0.00078718754 Validation Decoder Loss:  0.0670459
Encoder Loss:  0.012850904  || Decoder Loss:  0.00075003336 Validation Decoder Loss:  0.06455103
Encoder Loss:  0.0128199225  || Decoder Loss:  0.0007116119 Validation Decoder Loss:  0.0621889
Encoder Loss:  0.012793483  || Decoder Loss:  0.0006764023 Validation Decoder Loss:  0.060321353
Encoder Loss:  0.012767072  || Decoder Loss:  0.0006472017 Validation Decoder Loss:  0.05867013
Encoder Loss:  0.0127504645  || Decoder Loss:  0.0006230479 Validation Decoder Loss:  0.057434313
Encoder Loss:  0.012732764  || Decoder Loss:  0.0006037262 Validation Decoder Loss:  0.056597717
Encoder Loss:  0.012721398  || Decoder Loss:  0.0005893315 Validation Decoder Loss:  0.05651313
Encoder Loss:  0.012710259  || Decoder Loss:  0.00057643425 Validation Decoder Loss:  0.055957615
Encoder Loss:  0.012697039  || Decoder Loss:  0.0005605632 Validation Decoder Loss:  0.05544275
Encoder Loss:  0.012684699  || Decoder Loss:  0.00054758013 Validation Decoder Loss:  0.05399257
Encoder Loss:  0.012677431  || Decoder Loss:  0.0005360366 Validation Decoder Loss:  0.052066524
Encoder Loss:  0.012662816  || Decoder Loss:  0.0005202423 Validation Decoder Loss:  0.050301768
Encoder Loss:  0.012656669  || Decoder Loss:  0.000509542 Validation Decoder Loss:  0.048331097
Encoder Loss:  0.0126425335  || Decoder Loss:  0.00049683294 Validation Decoder Loss:  0.047558248
Encoder Loss:  0.012637453  || Decoder Loss:  0.00048742283 Validation Decoder Loss:  0.04610919
Encoder Loss:  0.012624832  || Decoder Loss:  0.00047137076 Validation Decoder Loss:  0.045648858
Encoder Loss:  0.012619068  || Decoder Loss:  0.00046690705 Validation Decoder Loss:  0.044321805
Encoder Loss:  0.012613351  || Decoder Loss:  0.0004601847 Validation Decoder Loss:  0.044267025
Model: bold_synthesis_net_lr_0.0007042963536628645 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.04426703
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 130, 14, 16, 1)    25        
_________________________________________________________________
reshape_61 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030222856  || Decoder Loss:  0.007619085 Validation Decoder Loss:  0.38104403
Encoder Loss:  0.020146081  || Decoder Loss:  0.0053245854 Validation Decoder Loss:  0.40426707
Encoder Loss:  0.018740004  || Decoder Loss:  0.0044979914 Validation Decoder Loss:  0.39084798
Encoder Loss:  0.017709373  || Decoder Loss:  0.0039857887 Validation Decoder Loss:  0.39215994
Encoder Loss:  0.016914513  || Decoder Loss:  0.0035239484 Validation Decoder Loss:  0.39355734
Encoder Loss:  0.016279858  || Decoder Loss:  0.0034214354 Validation Decoder Loss:  0.35792166
Encoder Loss:  0.015628453  || Decoder Loss:  0.0036245927 Validation Decoder Loss:  0.2845442
Encoder Loss:  0.014365106  || Decoder Loss:  0.0026045584 Validation Decoder Loss:  0.25814372
Encoder Loss:  0.013650326  || Decoder Loss:  0.00182895 Validation Decoder Loss:  0.27781206
Encoder Loss:  0.013455525  || Decoder Loss:  0.0016520355 Validation Decoder Loss:  0.27363044
Encoder Loss:  0.013311743  || Decoder Loss:  0.0014930374 Validation Decoder Loss:  0.2688871
Encoder Loss:  0.013219178  || Decoder Loss:  0.0013957139 Validation Decoder Loss:  0.24945796
Encoder Loss:  0.013152112  || Decoder Loss:  0.0013256958 Validation Decoder Loss:  0.24533498
Encoder Loss:  0.013090775  || Decoder Loss:  0.0012535201 Validation Decoder Loss:  0.23261523
Encoder Loss:  0.013026087  || Decoder Loss:  0.00117344 Validation Decoder Loss:  0.2195252
Encoder Loss:  0.012962582  || Decoder Loss:  0.0010976227 Validation Decoder Loss:  0.20364587
Encoder Loss:  0.01290042  || Decoder Loss:  0.0010177766 Validation Decoder Loss:  0.19482267
Encoder Loss:  0.012852137  || Decoder Loss:  0.0009572011 Validation Decoder Loss:  0.17891356
Encoder Loss:  0.012804494  || Decoder Loss:  0.00089811883 Validation Decoder Loss:  0.1650903
Encoder Loss:  0.012766537  || Decoder Loss:  0.0008484188 Validation Decoder Loss:  0.15834478
Encoder Loss:  0.012731736  || Decoder Loss:  0.00080242945 Validation Decoder Loss:  0.1520828
Encoder Loss:  0.012705723  || Decoder Loss:  0.00076679274 Validation Decoder Loss:  0.1408545
Encoder Loss:  0.012676656  || Decoder Loss:  0.0007309061 Validation Decoder Loss:  0.13430625
Encoder Loss:  0.012649284  || Decoder Loss:  0.00069421914 Validation Decoder Loss:  0.12673382
Encoder Loss:  0.0126275  || Decoder Loss:  0.0006644481 Validation Decoder Loss:  0.11807781
Encoder Loss:  0.012603892  || Decoder Loss:  0.00063335954 Validation Decoder Loss:  0.1089485
Encoder Loss:  0.012579932  || Decoder Loss:  0.00060128904 Validation Decoder Loss:  0.100946516
Encoder Loss:  0.012549693  || Decoder Loss:  0.0005625476 Validation Decoder Loss:  0.091274664
Encoder Loss:  0.012526306  || Decoder Loss:  0.00052994606 Validation Decoder Loss:  0.0845464
Encoder Loss:  0.012505501  || Decoder Loss:  0.0005027585 Validation Decoder Loss:  0.079734586
Encoder Loss:  0.012487847  || Decoder Loss:  0.00048058463 Validation Decoder Loss:  0.070914835
Encoder Loss:  0.012477716  || Decoder Loss:  0.00046665606 Validation Decoder Loss:  0.069784835
Encoder Loss:  0.012462152  || Decoder Loss:  0.00044791368 Validation Decoder Loss:  0.06375795
Encoder Loss:  0.012455494  || Decoder Loss:  0.0004383199 Validation Decoder Loss:  0.061490513
Encoder Loss:  0.012442332  || Decoder Loss:  0.00042407986 Validation Decoder Loss:  0.05770482
Encoder Loss:  0.012436132  || Decoder Loss:  0.00041593952 Validation Decoder Loss:  0.054307573
Encoder Loss:  0.012427675  || Decoder Loss:  0.00040486243 Validation Decoder Loss:  0.053412434
Encoder Loss:  0.012422364  || Decoder Loss:  0.00039935164 Validation Decoder Loss:  0.04729151
Encoder Loss:  0.012415552  || Decoder Loss:  0.00039123016 Validation Decoder Loss:  0.047168642
Encoder Loss:  0.0124080395  || Decoder Loss:  0.00038438904 Validation Decoder Loss:  0.046390053
Model: bold_synthesis_net_lr_0.0007250795570860187 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.046390057
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 140, 13, 16, 1)    694       
_________________________________________________________________
reshape_62 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02272935  || Decoder Loss:  0.004842211 Validation Decoder Loss:  0.3785097
Encoder Loss:  0.020828517  || Decoder Loss:  0.004424177 Validation Decoder Loss:  0.37520933
Encoder Loss:  0.019555924  || Decoder Loss:  0.0040876144 Validation Decoder Loss:  0.37185156
Encoder Loss:  0.018628664  || Decoder Loss:  0.0038589905 Validation Decoder Loss:  0.37160686
Encoder Loss:  0.017858729  || Decoder Loss:  0.0036648044 Validation Decoder Loss:  0.3714925
Encoder Loss:  0.01728335  || Decoder Loss:  0.0035637 Validation Decoder Loss:  0.37166312
Encoder Loss:  0.016565377  || Decoder Loss:  0.003468047 Validation Decoder Loss:  0.37178797
Encoder Loss:  0.015900692  || Decoder Loss:  0.003386116 Validation Decoder Loss:  0.37210196
Encoder Loss:  0.015590824  || Decoder Loss:  0.0033067781 Validation Decoder Loss:  0.37244922
Encoder Loss:  0.01541927  || Decoder Loss:  0.003251006 Validation Decoder Loss:  0.3725841
Encoder Loss:  0.015272389  || Decoder Loss:  0.0031960998 Validation Decoder Loss:  0.372793
Encoder Loss:  0.015178809  || Decoder Loss:  0.003147713 Validation Decoder Loss:  0.3729295
Encoder Loss:  0.015089758  || Decoder Loss:  0.0031078933 Validation Decoder Loss:  0.3730531
Encoder Loss:  0.015020729  || Decoder Loss:  0.003073497 Validation Decoder Loss:  0.3732876
Encoder Loss:  0.014949306  || Decoder Loss:  0.0030291367 Validation Decoder Loss:  0.37374526
Encoder Loss:  0.014890901  || Decoder Loss:  0.002999162 Validation Decoder Loss:  0.3739739
Encoder Loss:  0.014835768  || Decoder Loss:  0.0029758648 Validation Decoder Loss:  0.37418208
Encoder Loss:  0.014797014  || Decoder Loss:  0.0029668834 Validation Decoder Loss:  0.3742035
Encoder Loss:  0.014753575  || Decoder Loss:  0.0029441603 Validation Decoder Loss:  0.37404
Encoder Loss:  0.01471107  || Decoder Loss:  0.0029130974 Validation Decoder Loss:  0.37400684
Encoder Loss:  0.014672546  || Decoder Loss:  0.0028908597 Validation Decoder Loss:  0.37405786
Encoder Loss:  0.014647134  || Decoder Loss:  0.0028725343 Validation Decoder Loss:  0.37400633
Encoder Loss:  0.014619376  || Decoder Loss:  0.002854908 Validation Decoder Loss:  0.3738686
Encoder Loss:  0.0145980185  || Decoder Loss:  0.0028404843 Validation Decoder Loss:  0.37422585
Encoder Loss:  0.014571357  || Decoder Loss:  0.0028187737 Validation Decoder Loss:  0.37433296
Encoder Loss:  0.014541587  || Decoder Loss:  0.002793382 Validation Decoder Loss:  0.37439045
Encoder Loss:  0.014522985  || Decoder Loss:  0.0027713964 Validation Decoder Loss:  0.3744795
Encoder Loss:  0.014498506  || Decoder Loss:  0.0027425077 Validation Decoder Loss:  0.3744288
Encoder Loss:  0.014477163  || Decoder Loss:  0.0027249008 Validation Decoder Loss:  0.37425798
Encoder Loss:  0.014465762  || Decoder Loss:  0.0027136495 Validation Decoder Loss:  0.37432384
Encoder Loss:  0.014454902  || Decoder Loss:  0.0027054674 Validation Decoder Loss:  0.37410814
Encoder Loss:  0.014442472  || Decoder Loss:  0.0026924955 Validation Decoder Loss:  0.37400198
Encoder Loss:  0.01442803  || Decoder Loss:  0.002678364 Validation Decoder Loss:  0.37403262
Encoder Loss:  0.014410032  || Decoder Loss:  0.0026628242 Validation Decoder Loss:  0.37381744
Encoder Loss:  0.014396579  || Decoder Loss:  0.0026430376 Validation Decoder Loss:  0.37366074
Encoder Loss:  0.014381968  || Decoder Loss:  0.0026267339 Validation Decoder Loss:  0.3734532
Encoder Loss:  0.014364486  || Decoder Loss:  0.0026068473 Validation Decoder Loss:  0.37349796
Encoder Loss:  0.014332997  || Decoder Loss:  0.002566983 Validation Decoder Loss:  0.37337017
Encoder Loss:  0.01429358  || Decoder Loss:  0.002516418 Validation Decoder Loss:  0.37288463
Encoder Loss:  0.014266357  || Decoder Loss:  0.002474086 Validation Decoder Loss:  0.37244242
Model: bold_synthesis_net_lr_0.00067218757238548 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.37244242
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 140, 13, 16, 1)    127       
_________________________________________________________________
reshape_63 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.027598267  || Decoder Loss:  0.0074304044 Validation Decoder Loss:  0.38252363
Encoder Loss:  0.021263666  || Decoder Loss:  0.005435434 Validation Decoder Loss:  0.38469774
Encoder Loss:  0.019711167  || Decoder Loss:  0.00509966 Validation Decoder Loss:  0.3428218
Encoder Loss:  0.017008068  || Decoder Loss:  0.0042704046 Validation Decoder Loss:  0.27211058
Encoder Loss:  0.014476511  || Decoder Loss:  0.0029237405 Validation Decoder Loss:  0.20144074
Encoder Loss:  0.013521326  || Decoder Loss:  0.0020781932 Validation Decoder Loss:  0.1826677
Encoder Loss:  0.01318014  || Decoder Loss:  0.0017392314 Validation Decoder Loss:  0.17433485
Encoder Loss:  0.013002668  || Decoder Loss:  0.0015742491 Validation Decoder Loss:  0.14023551
Encoder Loss:  0.012866486  || Decoder Loss:  0.0014393763 Validation Decoder Loss:  0.12707752
Encoder Loss:  0.012730524  || Decoder Loss:  0.0012964815 Validation Decoder Loss:  0.12153509
Encoder Loss:  0.012622939  || Decoder Loss:  0.001178172 Validation Decoder Loss:  0.11663993
Encoder Loss:  0.012539796  || Decoder Loss:  0.0010795658 Validation Decoder Loss:  0.11069007
Encoder Loss:  0.0124585545  || Decoder Loss:  0.000983928 Validation Decoder Loss:  0.1053589
Encoder Loss:  0.012414277  || Decoder Loss:  0.00093289354 Validation Decoder Loss:  0.10244666
Encoder Loss:  0.012373551  || Decoder Loss:  0.0008838017 Validation Decoder Loss:  0.10407807
Encoder Loss:  0.012333103  || Decoder Loss:  0.0008384252 Validation Decoder Loss:  0.09344752
Encoder Loss:  0.012306781  || Decoder Loss:  0.0008075393 Validation Decoder Loss:  0.086513154
Encoder Loss:  0.012280832  || Decoder Loss:  0.0007811117 Validation Decoder Loss:  0.08940336
Encoder Loss:  0.012267856  || Decoder Loss:  0.0007681271 Validation Decoder Loss:  0.084339485
Encoder Loss:  0.012251273  || Decoder Loss:  0.0007463618 Validation Decoder Loss:  0.08129712
Encoder Loss:  0.012232178  || Decoder Loss:  0.0007230097 Validation Decoder Loss:  0.08141901
Encoder Loss:  0.012209528  || Decoder Loss:  0.0006981142 Validation Decoder Loss:  0.081598714
Encoder Loss:  0.012202879  || Decoder Loss:  0.0006898809 Validation Decoder Loss:  0.080331706
Encoder Loss:  0.012194292  || Decoder Loss:  0.0006780972 Validation Decoder Loss:  0.08131418
Encoder Loss:  0.0121832695  || Decoder Loss:  0.0006688599 Validation Decoder Loss:  0.080988735
Encoder Loss:  0.012172428  || Decoder Loss:  0.00065502117 Validation Decoder Loss:  0.07972796
Encoder Loss:  0.012164132  || Decoder Loss:  0.00064756564 Validation Decoder Loss:  0.07689041
Encoder Loss:  0.012160573  || Decoder Loss:  0.00064152176 Validation Decoder Loss:  0.077519245
Encoder Loss:  0.012150509  || Decoder Loss:  0.0006326945 Validation Decoder Loss:  0.07600078
Encoder Loss:  0.012140268  || Decoder Loss:  0.0006201514 Validation Decoder Loss:  0.07501434
Encoder Loss:  0.012137932  || Decoder Loss:  0.0006160375 Validation Decoder Loss:  0.08091718
Encoder Loss:  0.012130345  || Decoder Loss:  0.00060830865 Validation Decoder Loss:  0.07403518
Encoder Loss:  0.012127862  || Decoder Loss:  0.0006039014 Validation Decoder Loss:  0.07149553
Encoder Loss:  0.012123188  || Decoder Loss:  0.0005999773 Validation Decoder Loss:  0.07422577
Encoder Loss:  0.012115997  || Decoder Loss:  0.0005893741 Validation Decoder Loss:  0.07207322
Encoder Loss:  0.012111738  || Decoder Loss:  0.00058645586 Validation Decoder Loss:  0.07191762
Encoder Loss:  0.012112727  || Decoder Loss:  0.00058646814 Validation Decoder Loss:  0.06648377
Encoder Loss:  0.0121023515  || Decoder Loss:  0.00057654124 Validation Decoder Loss:  0.071008965
Encoder Loss:  0.012102405  || Decoder Loss:  0.0005749025 Validation Decoder Loss:  0.070972435
Encoder Loss:  0.012094867  || Decoder Loss:  0.00056744553 Validation Decoder Loss:  0.068747185
Model: bold_synthesis_net_lr_0.0007467882427249562 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.06874719
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_64 (Conv3DT (None, 65, 28, 16, 1)     49        
_________________________________________________________________
reshape_64 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.032737926  || Decoder Loss:  0.0066792704 Validation Decoder Loss:  0.38006383
Encoder Loss:  0.021969983  || Decoder Loss:  0.0047583478 Validation Decoder Loss:  0.3801245
Encoder Loss:  0.021049343  || Decoder Loss:  0.0043608574 Validation Decoder Loss:  0.37845272
Encoder Loss:  0.019895269  || Decoder Loss:  0.0041881097 Validation Decoder Loss:  0.3743209
Encoder Loss:  0.018471088  || Decoder Loss:  0.0040929583 Validation Decoder Loss:  0.35883534
Encoder Loss:  0.017379172  || Decoder Loss:  0.003716499 Validation Decoder Loss:  0.34202743
Encoder Loss:  0.016526313  || Decoder Loss:  0.0035711026 Validation Decoder Loss:  0.30629772
Encoder Loss:  0.015550764  || Decoder Loss:  0.0030266887 Validation Decoder Loss:  0.2550809
Encoder Loss:  0.014903395  || Decoder Loss:  0.0025198173 Validation Decoder Loss:  0.2353226
Encoder Loss:  0.014426196  || Decoder Loss:  0.0020325307 Validation Decoder Loss:  0.21606699
Encoder Loss:  0.01421971  || Decoder Loss:  0.0018249637 Validation Decoder Loss:  0.19594908
Encoder Loss:  0.0140228  || Decoder Loss:  0.0015925864 Validation Decoder Loss:  0.17935781
Encoder Loss:  0.013872802  || Decoder Loss:  0.0014267602 Validation Decoder Loss:  0.16653745
Encoder Loss:  0.013768166  || Decoder Loss:  0.0013134282 Validation Decoder Loss:  0.15265927
Encoder Loss:  0.013673087  || Decoder Loss:  0.0012035769 Validation Decoder Loss:  0.14610699
Encoder Loss:  0.013606751  || Decoder Loss:  0.0011253909 Validation Decoder Loss:  0.13654502
Encoder Loss:  0.013556822  || Decoder Loss:  0.0010676605 Validation Decoder Loss:  0.13127911
Encoder Loss:  0.013505867  || Decoder Loss:  0.0010090711 Validation Decoder Loss:  0.12741031
Encoder Loss:  0.0134784  || Decoder Loss:  0.0009766731 Validation Decoder Loss:  0.12263707
Encoder Loss:  0.013461267  || Decoder Loss:  0.0009605152 Validation Decoder Loss:  0.11858687
Encoder Loss:  0.013436918  || Decoder Loss:  0.0009307372 Validation Decoder Loss:  0.11797696
Encoder Loss:  0.013417484  || Decoder Loss:  0.0009081817 Validation Decoder Loss:  0.11213897
Encoder Loss:  0.013404696  || Decoder Loss:  0.0008935346 Validation Decoder Loss:  0.1071444
Encoder Loss:  0.013378984  || Decoder Loss:  0.0008591939 Validation Decoder Loss:  0.10500872
Encoder Loss:  0.013369434  || Decoder Loss:  0.00084754504 Validation Decoder Loss:  0.10442661
Encoder Loss:  0.013356007  || Decoder Loss:  0.0008321163 Validation Decoder Loss:  0.1039495
Encoder Loss:  0.013337422  || Decoder Loss:  0.0008104803 Validation Decoder Loss:  0.09998271
Encoder Loss:  0.013328686  || Decoder Loss:  0.0008009987 Validation Decoder Loss:  0.101793185
Encoder Loss:  0.013314645  || Decoder Loss:  0.0007818881 Validation Decoder Loss:  0.097388946
Encoder Loss:  0.0133040575  || Decoder Loss:  0.00076633703 Validation Decoder Loss:  0.09427754
Encoder Loss:  0.013298218  || Decoder Loss:  0.0007601346 Validation Decoder Loss:  0.094014436
Encoder Loss:  0.013287722  || Decoder Loss:  0.0007460718 Validation Decoder Loss:  0.092885405
Encoder Loss:  0.013277424  || Decoder Loss:  0.0007346489 Validation Decoder Loss:  0.09014526
Encoder Loss:  0.0132683525  || Decoder Loss:  0.0007224796 Validation Decoder Loss:  0.08890183
Encoder Loss:  0.013258912  || Decoder Loss:  0.0007087089 Validation Decoder Loss:  0.086576596
Encoder Loss:  0.013247047  || Decoder Loss:  0.000693481 Validation Decoder Loss:  0.08598369
Encoder Loss:  0.01324837  || Decoder Loss:  0.0006973775 Validation Decoder Loss:  0.08409018
Encoder Loss:  0.013240253  || Decoder Loss:  0.00068457867 Validation Decoder Loss:  0.08380544
Encoder Loss:  0.013231584  || Decoder Loss:  0.0006722487 Validation Decoder Loss:  0.080012165
Encoder Loss:  0.013225917  || Decoder Loss:  0.0006651179 Validation Decoder Loss:  0.08238861
Model: bold_synthesis_net_lr_0.0006332024305941587 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.08238861
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 70, 26, 16, 1)     127       
_________________________________________________________________
reshape_65 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030361466  || Decoder Loss:  0.0074326703 Validation Decoder Loss:  0.37645584
Encoder Loss:  0.023415191  || Decoder Loss:  0.005530915 Validation Decoder Loss:  0.3872046
Encoder Loss:  0.021759488  || Decoder Loss:  0.0048935167 Validation Decoder Loss:  0.373822
Encoder Loss:  0.01988881  || Decoder Loss:  0.0047893617 Validation Decoder Loss:  0.3280753
Encoder Loss:  0.017540138  || Decoder Loss:  0.0036639166 Validation Decoder Loss:  0.26140535
Encoder Loss:  0.016442377  || Decoder Loss:  0.0033329118 Validation Decoder Loss:  0.18880376
Encoder Loss:  0.015628427  || Decoder Loss:  0.0027588892 Validation Decoder Loss:  0.16208622
Encoder Loss:  0.015169488  || Decoder Loss:  0.0023525972 Validation Decoder Loss:  0.15746564
Encoder Loss:  0.014832989  || Decoder Loss:  0.0020085578 Validation Decoder Loss:  0.1503861
Encoder Loss:  0.014611004  || Decoder Loss:  0.0017943167 Validation Decoder Loss:  0.1494278
Encoder Loss:  0.014410658  || Decoder Loss:  0.0016051304 Validation Decoder Loss:  0.14690432
Encoder Loss:  0.014252732  || Decoder Loss:  0.0014709682 Validation Decoder Loss:  0.14554802
Encoder Loss:  0.01415432  || Decoder Loss:  0.0013991098 Validation Decoder Loss:  0.13596135
Encoder Loss:  0.014009267  || Decoder Loss:  0.0012504852 Validation Decoder Loss:  0.12598598
Encoder Loss:  0.013899455  || Decoder Loss:  0.0011399601 Validation Decoder Loss:  0.1261039
Encoder Loss:  0.013835969  || Decoder Loss:  0.0010824638 Validation Decoder Loss:  0.12386032
Encoder Loss:  0.013784869  || Decoder Loss:  0.0010380594 Validation Decoder Loss:  0.12334443
Encoder Loss:  0.0137398215  || Decoder Loss:  0.0009952019 Validation Decoder Loss:  0.11897484
Encoder Loss:  0.013690921  || Decoder Loss:  0.00094731414 Validation Decoder Loss:  0.11636561
Encoder Loss:  0.013652555  || Decoder Loss:  0.0009083955 Validation Decoder Loss:  0.118093014
Encoder Loss:  0.013613461  || Decoder Loss:  0.00086726603 Validation Decoder Loss:  0.11275627
Encoder Loss:  0.013587466  || Decoder Loss:  0.00083964394 Validation Decoder Loss:  0.11725048
Encoder Loss:  0.013558686  || Decoder Loss:  0.00081104814 Validation Decoder Loss:  0.115302585
Encoder Loss:  0.013533568  || Decoder Loss:  0.0007848037 Validation Decoder Loss:  0.11375771
Encoder Loss:  0.013504056  || Decoder Loss:  0.00075392035 Validation Decoder Loss:  0.11363945
Encoder Loss:  0.01348595  || Decoder Loss:  0.00073534757 Validation Decoder Loss:  0.11807984
Encoder Loss:  0.013472765  || Decoder Loss:  0.00072331337 Validation Decoder Loss:  0.116046086
Encoder Loss:  0.013456088  || Decoder Loss:  0.00070603646 Validation Decoder Loss:  0.1158505
Encoder Loss:  0.013446112  || Decoder Loss:  0.0006978843 Validation Decoder Loss:  0.11307601
Encoder Loss:  0.013439301  || Decoder Loss:  0.0006910603 Validation Decoder Loss:  0.11698935
Encoder Loss:  0.013427998  || Decoder Loss:  0.0006799461 Validation Decoder Loss:  0.11435653
Encoder Loss:  0.013419543  || Decoder Loss:  0.0006723393 Validation Decoder Loss:  0.114657104
Encoder Loss:  0.013407836  || Decoder Loss:  0.00066117354 Validation Decoder Loss:  0.11329473
Encoder Loss:  0.013398556  || Decoder Loss:  0.00064891786 Validation Decoder Loss:  0.11465427
Encoder Loss:  0.0133890305  || Decoder Loss:  0.0006386163 Validation Decoder Loss:  0.114157274
Encoder Loss:  0.013380543  || Decoder Loss:  0.00063247787 Validation Decoder Loss:  0.11799906
Encoder Loss:  0.013377682  || Decoder Loss:  0.0006274786 Validation Decoder Loss:  0.11275747
Encoder Loss:  0.013366056  || Decoder Loss:  0.0006147249 Validation Decoder Loss:  0.11230938
Encoder Loss:  0.013360338  || Decoder Loss:  0.00060968 Validation Decoder Loss:  0.11007251
Encoder Loss:  0.013355293  || Decoder Loss:  0.00060127757 Validation Decoder Loss:  0.10847094
Model: bold_synthesis_net_lr_0.000610656119122753 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.10847093
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 65, 28, 16, 1)     17        
_________________________________________________________________
reshape_66 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03276803  || Decoder Loss:  0.0073009473 Validation Decoder Loss:  0.32702535
Encoder Loss:  0.023953887  || Decoder Loss:  0.0065727304 Validation Decoder Loss:  0.37553412
Encoder Loss:  0.019423908  || Decoder Loss:  0.0046578376 Validation Decoder Loss:  0.3942176
Encoder Loss:  0.018289486  || Decoder Loss:  0.003898392 Validation Decoder Loss:  0.37683916
Encoder Loss:  0.017554088  || Decoder Loss:  0.0037133158 Validation Decoder Loss:  0.35628444
Encoder Loss:  0.01678613  || Decoder Loss:  0.003401058 Validation Decoder Loss:  0.3362714
Encoder Loss:  0.01612667  || Decoder Loss:  0.003248415 Validation Decoder Loss:  0.317196
Encoder Loss:  0.015643744  || Decoder Loss:  0.0030386792 Validation Decoder Loss:  0.29958317
Encoder Loss:  0.015285402  || Decoder Loss:  0.0028255975 Validation Decoder Loss:  0.2783808
Encoder Loss:  0.015048899  || Decoder Loss:  0.0027570252 Validation Decoder Loss:  0.25526798
Encoder Loss:  0.014756035  || Decoder Loss:  0.0025993693 Validation Decoder Loss:  0.2305863
Encoder Loss:  0.014473358  || Decoder Loss:  0.0023632518 Validation Decoder Loss:  0.20090744
Encoder Loss:  0.014165993  || Decoder Loss:  0.0020542818 Validation Decoder Loss:  0.17782027
Encoder Loss:  0.013944107  || Decoder Loss:  0.0018078247 Validation Decoder Loss:  0.14886782
Encoder Loss:  0.013751773  || Decoder Loss:  0.001587563 Validation Decoder Loss:  0.14173454
Encoder Loss:  0.013626301  || Decoder Loss:  0.0014532501 Validation Decoder Loss:  0.1371493
Encoder Loss:  0.013541435  || Decoder Loss:  0.0013663596 Validation Decoder Loss:  0.12786755
Encoder Loss:  0.013456849  || Decoder Loss:  0.0012685143 Validation Decoder Loss:  0.12083344
Encoder Loss:  0.013386211  || Decoder Loss:  0.001188315 Validation Decoder Loss:  0.10395467
Encoder Loss:  0.0132984575  || Decoder Loss:  0.0010783175 Validation Decoder Loss:  0.09432916
Encoder Loss:  0.013217953  || Decoder Loss:  0.00097413803 Validation Decoder Loss:  0.086057
Encoder Loss:  0.013146949  || Decoder Loss:  0.0008892302 Validation Decoder Loss:  0.079477645
Encoder Loss:  0.0130897425  || Decoder Loss:  0.0008205386 Validation Decoder Loss:  0.07430066
Encoder Loss:  0.013046418  || Decoder Loss:  0.0007706762 Validation Decoder Loss:  0.0699985
Encoder Loss:  0.013011986  || Decoder Loss:  0.0007321052 Validation Decoder Loss:  0.06778783
Encoder Loss:  0.01298438  || Decoder Loss:  0.0007011488 Validation Decoder Loss:  0.06354514
Encoder Loss:  0.012950429  || Decoder Loss:  0.00065977656 Validation Decoder Loss:  0.059585497
Encoder Loss:  0.012918025  || Decoder Loss:  0.0006208859 Validation Decoder Loss:  0.055966906
Encoder Loss:  0.01289525  || Decoder Loss:  0.00059291394 Validation Decoder Loss:  0.052850097
Encoder Loss:  0.012870162  || Decoder Loss:  0.00056345714 Validation Decoder Loss:  0.05035837
Encoder Loss:  0.012848593  || Decoder Loss:  0.0005407445 Validation Decoder Loss:  0.049060266
Encoder Loss:  0.012832719  || Decoder Loss:  0.00052154076 Validation Decoder Loss:  0.047589906
Encoder Loss:  0.012815802  || Decoder Loss:  0.0005047301 Validation Decoder Loss:  0.04487668
Encoder Loss:  0.012802515  || Decoder Loss:  0.0004887915 Validation Decoder Loss:  0.044118233
Encoder Loss:  0.012792009  || Decoder Loss:  0.0004801531 Validation Decoder Loss:  0.042828806
Encoder Loss:  0.012780548  || Decoder Loss:  0.00046782455 Validation Decoder Loss:  0.042696375
Encoder Loss:  0.012771623  || Decoder Loss:  0.0004581198 Validation Decoder Loss:  0.041007865
Encoder Loss:  0.012766415  || Decoder Loss:  0.00045486417 Validation Decoder Loss:  0.04061453
Encoder Loss:  0.012757468  || Decoder Loss:  0.00044617007 Validation Decoder Loss:  0.04057911
Encoder Loss:  0.012754037  || Decoder Loss:  0.00044097146 Validation Decoder Loss:  0.0406119
Model: bold_synthesis_net_lr_0.000670771984507212 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.0406119
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_67 (Conv3DT (None, 364, 5, 16, 1)     176       
_________________________________________________________________
reshape_67 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 176
Trainable params: 176
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.022992987  || Decoder Loss:  0.005130405 Validation Decoder Loss:  0.45874065
Encoder Loss:  0.020558054  || Decoder Loss:  0.004602904 Validation Decoder Loss:  0.46350038
Encoder Loss:  0.019512104  || Decoder Loss:  0.004111852 Validation Decoder Loss:  0.4625101
Encoder Loss:  0.018880399  || Decoder Loss:  0.0039234185 Validation Decoder Loss:  0.4607904
Encoder Loss:  0.018429102  || Decoder Loss:  0.004126271 Validation Decoder Loss:  0.4549974
Encoder Loss:  0.01760386  || Decoder Loss:  0.003984534 Validation Decoder Loss:  0.43780342
Encoder Loss:  0.016806602  || Decoder Loss:  0.0035658267 Validation Decoder Loss:  0.4334694
Encoder Loss:  0.016179675  || Decoder Loss:  0.0031085897 Validation Decoder Loss:  0.43301666
Encoder Loss:  0.015792657  || Decoder Loss:  0.0028968928 Validation Decoder Loss:  0.43309307
Encoder Loss:  0.015533053  || Decoder Loss:  0.0028198787 Validation Decoder Loss:  0.43304586
Encoder Loss:  0.015285777  || Decoder Loss:  0.0027498584 Validation Decoder Loss:  0.43320233
Encoder Loss:  0.015066054  || Decoder Loss:  0.0026896992 Validation Decoder Loss:  0.43329662
Encoder Loss:  0.014890125  || Decoder Loss:  0.0026228654 Validation Decoder Loss:  0.43308488
Encoder Loss:  0.014766611  || Decoder Loss:  0.0025617485 Validation Decoder Loss:  0.43296796
Encoder Loss:  0.014647369  || Decoder Loss:  0.0024886762 Validation Decoder Loss:  0.43160093
Encoder Loss:  0.014554726  || Decoder Loss:  0.0024219428 Validation Decoder Loss:  0.43082023
Encoder Loss:  0.014483621  || Decoder Loss:  0.002369902 Validation Decoder Loss:  0.42952666
Encoder Loss:  0.014421101  || Decoder Loss:  0.002323523 Validation Decoder Loss:  0.4271502
Encoder Loss:  0.014373802  || Decoder Loss:  0.002287812 Validation Decoder Loss:  0.42615402
Encoder Loss:  0.014330559  || Decoder Loss:  0.0022418236 Validation Decoder Loss:  0.42430604
Encoder Loss:  0.014286195  || Decoder Loss:  0.002201139 Validation Decoder Loss:  0.42325145
Encoder Loss:  0.014253392  || Decoder Loss:  0.0021731013 Validation Decoder Loss:  0.42218202
Encoder Loss:  0.014224477  || Decoder Loss:  0.002137556 Validation Decoder Loss:  0.42158264
Encoder Loss:  0.0141910575  || Decoder Loss:  0.0021087574 Validation Decoder Loss:  0.4212188
Encoder Loss:  0.014155049  || Decoder Loss:  0.0020698202 Validation Decoder Loss:  0.41999698
Encoder Loss:  0.014121534  || Decoder Loss:  0.00202208 Validation Decoder Loss:  0.41873527
Encoder Loss:  0.014070306  || Decoder Loss:  0.0019584724 Validation Decoder Loss:  0.4171586
Encoder Loss:  0.01400411  || Decoder Loss:  0.0018639558 Validation Decoder Loss:  0.41545227
Encoder Loss:  0.013933253  || Decoder Loss:  0.0017745628 Validation Decoder Loss:  0.4145483
Encoder Loss:  0.013891722  || Decoder Loss:  0.0017194278 Validation Decoder Loss:  0.41433775
Encoder Loss:  0.0138565665  || Decoder Loss:  0.0016756906 Validation Decoder Loss:  0.41392413
Encoder Loss:  0.013829141  || Decoder Loss:  0.0016398744 Validation Decoder Loss:  0.41240424
Encoder Loss:  0.013803362  || Decoder Loss:  0.0016109189 Validation Decoder Loss:  0.41192892
Encoder Loss:  0.013789582  || Decoder Loss:  0.0015926057 Validation Decoder Loss:  0.41090056
Encoder Loss:  0.013775344  || Decoder Loss:  0.0015729262 Validation Decoder Loss:  0.40967506
Encoder Loss:  0.013760277  || Decoder Loss:  0.0015562859 Validation Decoder Loss:  0.4095207
Encoder Loss:  0.013743803  || Decoder Loss:  0.0015403145 Validation Decoder Loss:  0.40900415
Encoder Loss:  0.013729781  || Decoder Loss:  0.0015256738 Validation Decoder Loss:  0.408782
Encoder Loss:  0.0137211615  || Decoder Loss:  0.0015129038 Validation Decoder Loss:  0.40744254
Encoder Loss:  0.013708898  || Decoder Loss:  0.0014998292 Validation Decoder Loss:  0.4072556
Model: bold_synthesis_net_lr_0.0006485811388094041 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.40725556
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 65, 28, 16, 1)     49        
_________________________________________________________________
reshape_68 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03034156  || Decoder Loss:  0.0065410715 Validation Decoder Loss:  0.3809063
Encoder Loss:  0.020862458  || Decoder Loss:  0.004807531 Validation Decoder Loss:  0.3811067
Encoder Loss:  0.019850077  || Decoder Loss:  0.004404464 Validation Decoder Loss:  0.37762827
Encoder Loss:  0.018517544  || Decoder Loss:  0.004384055 Validation Decoder Loss:  0.36599004
Encoder Loss:  0.017176898  || Decoder Loss:  0.004078392 Validation Decoder Loss:  0.34269804
Encoder Loss:  0.016026884  || Decoder Loss:  0.0036656528 Validation Decoder Loss:  0.3055492
Encoder Loss:  0.014936442  || Decoder Loss:  0.0031692942 Validation Decoder Loss:  0.24729463
Encoder Loss:  0.01415047  || Decoder Loss:  0.0025007676 Validation Decoder Loss:  0.22467521
Encoder Loss:  0.0137548  || Decoder Loss:  0.0021156105 Validation Decoder Loss:  0.21113822
Encoder Loss:  0.013486988  || Decoder Loss:  0.0018250048 Validation Decoder Loss:  0.19917704
Encoder Loss:  0.0132328225  || Decoder Loss:  0.0015264568 Validation Decoder Loss:  0.18087173
Encoder Loss:  0.013064798  || Decoder Loss:  0.0013327579 Validation Decoder Loss:  0.16357902
Encoder Loss:  0.012928831  || Decoder Loss:  0.0011720608 Validation Decoder Loss:  0.15886983
Encoder Loss:  0.012858454  || Decoder Loss:  0.0010956854 Validation Decoder Loss:  0.14850597
Encoder Loss:  0.012798605  || Decoder Loss:  0.0010304127 Validation Decoder Loss:  0.1309064
Encoder Loss:  0.012735409  || Decoder Loss:  0.00094744447 Validation Decoder Loss:  0.1251483
Encoder Loss:  0.012689708  || Decoder Loss:  0.00088757736 Validation Decoder Loss:  0.11937788
Encoder Loss:  0.012653887  || Decoder Loss:  0.00084398396 Validation Decoder Loss:  0.11512434
Encoder Loss:  0.012630175  || Decoder Loss:  0.00081647414 Validation Decoder Loss:  0.1065782
Encoder Loss:  0.012596659  || Decoder Loss:  0.0007724039 Validation Decoder Loss:  0.10180316
Encoder Loss:  0.012571856  || Decoder Loss:  0.0007434116 Validation Decoder Loss:  0.10044998
Encoder Loss:  0.012547213  || Decoder Loss:  0.0007120617 Validation Decoder Loss:  0.094610766
Encoder Loss:  0.012524077  || Decoder Loss:  0.00068008126 Validation Decoder Loss:  0.092151865
Encoder Loss:  0.012502271  || Decoder Loss:  0.00065341865 Validation Decoder Loss:  0.08820531
Encoder Loss:  0.012485602  || Decoder Loss:  0.0006305394 Validation Decoder Loss:  0.08709727
Encoder Loss:  0.012479688  || Decoder Loss:  0.0006223359 Validation Decoder Loss:  0.08501228
Encoder Loss:  0.012467444  || Decoder Loss:  0.00060461275 Validation Decoder Loss:  0.08193577
Encoder Loss:  0.012455846  || Decoder Loss:  0.0005920008 Validation Decoder Loss:  0.08141137
Encoder Loss:  0.012441451  || Decoder Loss:  0.00057300716 Validation Decoder Loss:  0.080687255
Encoder Loss:  0.012431829  || Decoder Loss:  0.00056106667 Validation Decoder Loss:  0.077968165
Encoder Loss:  0.012420022  || Decoder Loss:  0.00054619525 Validation Decoder Loss:  0.0770821
Encoder Loss:  0.012409761  || Decoder Loss:  0.00053370243 Validation Decoder Loss:  0.07401405
Encoder Loss:  0.01240391  || Decoder Loss:  0.00052382133 Validation Decoder Loss:  0.07294662
Encoder Loss:  0.012393823  || Decoder Loss:  0.0005128109 Validation Decoder Loss:  0.071933
Encoder Loss:  0.012384265  || Decoder Loss:  0.00050017127 Validation Decoder Loss:  0.06925139
Encoder Loss:  0.012375802  || Decoder Loss:  0.00048747635 Validation Decoder Loss:  0.06645248
Encoder Loss:  0.012366393  || Decoder Loss:  0.00047442145 Validation Decoder Loss:  0.06826097
Encoder Loss:  0.012358414  || Decoder Loss:  0.00046701438 Validation Decoder Loss:  0.06380004
Encoder Loss:  0.012354175  || Decoder Loss:  0.00046211953 Validation Decoder Loss:  0.06424354
Encoder Loss:  0.012350153  || Decoder Loss:  0.0004540158 Validation Decoder Loss:  0.06388952
Model: bold_synthesis_net_lr_0.0007138592120022757 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.06388952
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 140, 13, 16, 1)    127       
_________________________________________________________________
reshape_69 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030305073  || Decoder Loss:  0.007666547 Validation Decoder Loss:  0.37873012
Encoder Loss:  0.023065278  || Decoder Loss:  0.005646243 Validation Decoder Loss:  0.3852362
Encoder Loss:  0.021821644  || Decoder Loss:  0.005265215 Validation Decoder Loss:  0.36877298
Encoder Loss:  0.020043578  || Decoder Loss:  0.0050947964 Validation Decoder Loss:  0.33176172
Encoder Loss:  0.017540345  || Decoder Loss:  0.004290361 Validation Decoder Loss:  0.2646657
Encoder Loss:  0.015182165  || Decoder Loss:  0.0026561916 Validation Decoder Loss:  0.17853448
Encoder Loss:  0.014383787  || Decoder Loss:  0.0019114709 Validation Decoder Loss:  0.15021926
Encoder Loss:  0.01409498  || Decoder Loss:  0.0016239192 Validation Decoder Loss:  0.14660437
Encoder Loss:  0.013940491  || Decoder Loss:  0.0014971559 Validation Decoder Loss:  0.1209666
Encoder Loss:  0.013792098  || Decoder Loss:  0.0013467176 Validation Decoder Loss:  0.11601848
Encoder Loss:  0.013673686  || Decoder Loss:  0.001220826 Validation Decoder Loss:  0.11271669
Encoder Loss:  0.013605968  || Decoder Loss:  0.0011575414 Validation Decoder Loss:  0.11473735
Encoder Loss:  0.013548254  || Decoder Loss:  0.0011008127 Validation Decoder Loss:  0.110268615
Encoder Loss:  0.013512771  || Decoder Loss:  0.001069635 Validation Decoder Loss:  0.11150873
Encoder Loss:  0.013467127  || Decoder Loss:  0.0010158542 Validation Decoder Loss:  0.106576055
Encoder Loss:  0.013431702  || Decoder Loss:  0.0009786328 Validation Decoder Loss:  0.10636223
Encoder Loss:  0.013401557  || Decoder Loss:  0.00094939186 Validation Decoder Loss:  0.10430384
Encoder Loss:  0.013379296  || Decoder Loss:  0.0009236514 Validation Decoder Loss:  0.10111287
Encoder Loss:  0.013351882  || Decoder Loss:  0.0008942035 Validation Decoder Loss:  0.097666085
Encoder Loss:  0.013322501  || Decoder Loss:  0.0008581861 Validation Decoder Loss:  0.09409101
Encoder Loss:  0.013299572  || Decoder Loss:  0.0008323064 Validation Decoder Loss:  0.09503105
Encoder Loss:  0.013280827  || Decoder Loss:  0.00080897467 Validation Decoder Loss:  0.091663636
Encoder Loss:  0.013257868  || Decoder Loss:  0.0007820678 Validation Decoder Loss:  0.08664075
Encoder Loss:  0.013245959  || Decoder Loss:  0.00076930126 Validation Decoder Loss:  0.08807095
Encoder Loss:  0.013227293  || Decoder Loss:  0.0007446782 Validation Decoder Loss:  0.085241236
Encoder Loss:  0.013213557  || Decoder Loss:  0.0007294747 Validation Decoder Loss:  0.081404574
Encoder Loss:  0.01320119  || Decoder Loss:  0.0007119473 Validation Decoder Loss:  0.080323845
Encoder Loss:  0.013185473  || Decoder Loss:  0.0006937109 Validation Decoder Loss:  0.07871995
Encoder Loss:  0.013171136  || Decoder Loss:  0.00067625404 Validation Decoder Loss:  0.07728194
Encoder Loss:  0.013164314  || Decoder Loss:  0.0006658552 Validation Decoder Loss:  0.07953255
Encoder Loss:  0.013158374  || Decoder Loss:  0.00065855 Validation Decoder Loss:  0.07788171
Encoder Loss:  0.01314796  || Decoder Loss:  0.0006463314 Validation Decoder Loss:  0.0782112
Encoder Loss:  0.013137425  || Decoder Loss:  0.00063174375 Validation Decoder Loss:  0.073441
Encoder Loss:  0.013128338  || Decoder Loss:  0.0006218017 Validation Decoder Loss:  0.07660943
Encoder Loss:  0.013123034  || Decoder Loss:  0.0006141559 Validation Decoder Loss:  0.07455822
Encoder Loss:  0.013116099  || Decoder Loss:  0.00060598936 Validation Decoder Loss:  0.06912109
Encoder Loss:  0.01311171  || Decoder Loss:  0.00059990917 Validation Decoder Loss:  0.07074297
Encoder Loss:  0.013107171  || Decoder Loss:  0.00059467676 Validation Decoder Loss:  0.070603706
Encoder Loss:  0.013100813  || Decoder Loss:  0.0005864292 Validation Decoder Loss:  0.07093799
Encoder Loss:  0.01310072  || Decoder Loss:  0.0005864307 Validation Decoder Loss:  0.06792896
Model: bold_synthesis_net_lr_0.0006375739201549915 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.06792896
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_70 (Conv3DT (None, 130, 14, 16, 1)    403       
_________________________________________________________________
reshape_70 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 403
Trainable params: 403
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.024392216  || Decoder Loss:  0.005139188 Validation Decoder Loss:  0.42448887
Encoder Loss:  0.022297317  || Decoder Loss:  0.004577336 Validation Decoder Loss:  0.42532307
Encoder Loss:  0.02133647  || Decoder Loss:  0.0044798376 Validation Decoder Loss:  0.42662776
Encoder Loss:  0.020654334  || Decoder Loss:  0.0042142314 Validation Decoder Loss:  0.42630002
Encoder Loss:  0.020171657  || Decoder Loss:  0.0040662126 Validation Decoder Loss:  0.4261746
Encoder Loss:  0.019727325  || Decoder Loss:  0.003959303 Validation Decoder Loss:  0.42562413
Encoder Loss:  0.019306703  || Decoder Loss:  0.0038567444 Validation Decoder Loss:  0.4264074
Encoder Loss:  0.018877085  || Decoder Loss:  0.003757692 Validation Decoder Loss:  0.42703563
Encoder Loss:  0.018434655  || Decoder Loss:  0.003642831 Validation Decoder Loss:  0.42879784
Encoder Loss:  0.017975023  || Decoder Loss:  0.0035517544 Validation Decoder Loss:  0.42847717
Encoder Loss:  0.017441964  || Decoder Loss:  0.0034371573 Validation Decoder Loss:  0.42984203
Encoder Loss:  0.017012998  || Decoder Loss:  0.003321419 Validation Decoder Loss:  0.43039864
Encoder Loss:  0.016723763  || Decoder Loss:  0.003194927 Validation Decoder Loss:  0.4313568
Encoder Loss:  0.016549608  || Decoder Loss:  0.0031033657 Validation Decoder Loss:  0.4325642
Encoder Loss:  0.016419275  || Decoder Loss:  0.003019459 Validation Decoder Loss:  0.4329749
Encoder Loss:  0.016310347  || Decoder Loss:  0.002937097 Validation Decoder Loss:  0.4327172
Encoder Loss:  0.016204642  || Decoder Loss:  0.0028509044 Validation Decoder Loss:  0.43223768
Encoder Loss:  0.0161191  || Decoder Loss:  0.002785347 Validation Decoder Loss:  0.43178585
Encoder Loss:  0.016046628  || Decoder Loss:  0.0027307947 Validation Decoder Loss:  0.431417
Encoder Loss:  0.01598988  || Decoder Loss:  0.002697657 Validation Decoder Loss:  0.43095076
Encoder Loss:  0.015939558  || Decoder Loss:  0.0026729936 Validation Decoder Loss:  0.43074882
Encoder Loss:  0.015882758  || Decoder Loss:  0.0026370124 Validation Decoder Loss:  0.43043697
Encoder Loss:  0.015823252  || Decoder Loss:  0.0025976591 Validation Decoder Loss:  0.43050757
Encoder Loss:  0.015756795  || Decoder Loss:  0.0025390498 Validation Decoder Loss:  0.43040842
Encoder Loss:  0.01571216  || Decoder Loss:  0.0025116396 Validation Decoder Loss:  0.43057954
Encoder Loss:  0.015669502  || Decoder Loss:  0.002484469 Validation Decoder Loss:  0.43082348
Encoder Loss:  0.015631078  || Decoder Loss:  0.0024579978 Validation Decoder Loss:  0.43172494
Encoder Loss:  0.015588602  || Decoder Loss:  0.00242504 Validation Decoder Loss:  0.43243226
Encoder Loss:  0.015549059  || Decoder Loss:  0.0023913097 Validation Decoder Loss:  0.43259257
Encoder Loss:  0.015522036  || Decoder Loss:  0.0023662671 Validation Decoder Loss:  0.432768
Encoder Loss:  0.015491949  || Decoder Loss:  0.0023407058 Validation Decoder Loss:  0.43302998
Encoder Loss:  0.015467543  || Decoder Loss:  0.0023207883 Validation Decoder Loss:  0.4332121
Encoder Loss:  0.015443893  || Decoder Loss:  0.0023009628 Validation Decoder Loss:  0.43320954
Encoder Loss:  0.015421471  || Decoder Loss:  0.002279601 Validation Decoder Loss:  0.43319547
Encoder Loss:  0.015400319  || Decoder Loss:  0.0022580728 Validation Decoder Loss:  0.4330414
Encoder Loss:  0.015375453  || Decoder Loss:  0.0022345355 Validation Decoder Loss:  0.4328251
Encoder Loss:  0.015357618  || Decoder Loss:  0.0022154613 Validation Decoder Loss:  0.43292248
Encoder Loss:  0.015336422  || Decoder Loss:  0.0021904428 Validation Decoder Loss:  0.43311453
Encoder Loss:  0.015316656  || Decoder Loss:  0.002169493 Validation Decoder Loss:  0.43313062
Encoder Loss:  0.015305835  || Decoder Loss:  0.0021504909 Validation Decoder Loss:  0.4333055
Model: bold_synthesis_net_lr_0.000514078541876414 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4333055
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 364, 5, 16, 1)     239       
_________________________________________________________________
reshape_71 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.01862713  || Decoder Loss:  0.0045007668 Validation Decoder Loss:  0.47292498
Encoder Loss:  0.016560068  || Decoder Loss:  0.0037020529 Validation Decoder Loss:  0.4717555
Encoder Loss:  0.016021444  || Decoder Loss:  0.003524738 Validation Decoder Loss:  0.47138092
Encoder Loss:  0.015592581  || Decoder Loss:  0.0033159906 Validation Decoder Loss:  0.47164792
Encoder Loss:  0.015206679  || Decoder Loss:  0.0031240797 Validation Decoder Loss:  0.4709034
Encoder Loss:  0.01467192  || Decoder Loss:  0.0028897056 Validation Decoder Loss:  0.4704591
Encoder Loss:  0.0141463  || Decoder Loss:  0.002706424 Validation Decoder Loss:  0.46782237
Encoder Loss:  0.013758994  || Decoder Loss:  0.0025536227 Validation Decoder Loss:  0.46247402
Encoder Loss:  0.01346526  || Decoder Loss:  0.0024237593 Validation Decoder Loss:  0.45683834
Encoder Loss:  0.013273949  || Decoder Loss:  0.0023604124 Validation Decoder Loss:  0.45035714
Encoder Loss:  0.013135803  || Decoder Loss:  0.0023008888 Validation Decoder Loss:  0.44781414
Encoder Loss:  0.013065577  || Decoder Loss:  0.002293343 Validation Decoder Loss:  0.44487408
Encoder Loss:  0.013000721  || Decoder Loss:  0.0022757433 Validation Decoder Loss:  0.4435322
Encoder Loss:  0.0129480725  || Decoder Loss:  0.00225256 Validation Decoder Loss:  0.44240102
Encoder Loss:  0.012897535  || Decoder Loss:  0.0022215208 Validation Decoder Loss:  0.44247335
Encoder Loss:  0.012854667  || Decoder Loss:  0.0021908025 Validation Decoder Loss:  0.44130135
Encoder Loss:  0.012833595  || Decoder Loss:  0.0021867834 Validation Decoder Loss:  0.44041428
Encoder Loss:  0.0127965985  || Decoder Loss:  0.0021600313 Validation Decoder Loss:  0.44080687
Encoder Loss:  0.01276588  || Decoder Loss:  0.0021384133 Validation Decoder Loss:  0.44051218
Encoder Loss:  0.012745857  || Decoder Loss:  0.0021189384 Validation Decoder Loss:  0.4409274
Encoder Loss:  0.012719094  || Decoder Loss:  0.0021025946 Validation Decoder Loss:  0.44096953
Encoder Loss:  0.012702786  || Decoder Loss:  0.00208838 Validation Decoder Loss:  0.4405947
Encoder Loss:  0.012686741  || Decoder Loss:  0.0020763683 Validation Decoder Loss:  0.44072932
Encoder Loss:  0.012669643  || Decoder Loss:  0.0020623768 Validation Decoder Loss:  0.44114554
Encoder Loss:  0.012659226  || Decoder Loss:  0.0020501798 Validation Decoder Loss:  0.44091558
Encoder Loss:  0.012639915  || Decoder Loss:  0.0020346257 Validation Decoder Loss:  0.44048825
Encoder Loss:  0.012625135  || Decoder Loss:  0.0020194 Validation Decoder Loss:  0.44039625
Encoder Loss:  0.012612135  || Decoder Loss:  0.0020083361 Validation Decoder Loss:  0.4403572
Encoder Loss:  0.012597114  || Decoder Loss:  0.0019960443 Validation Decoder Loss:  0.4403449
Encoder Loss:  0.0125872055  || Decoder Loss:  0.001984396 Validation Decoder Loss:  0.44000787
Encoder Loss:  0.012577068  || Decoder Loss:  0.0019784789 Validation Decoder Loss:  0.43976688
Encoder Loss:  0.01256908  || Decoder Loss:  0.0019658124 Validation Decoder Loss:  0.43963847
Encoder Loss:  0.012554404  || Decoder Loss:  0.0019539525 Validation Decoder Loss:  0.4399094
Encoder Loss:  0.012543687  || Decoder Loss:  0.0019387968 Validation Decoder Loss:  0.43994224
Encoder Loss:  0.012530825  || Decoder Loss:  0.0019270596 Validation Decoder Loss:  0.44009006
Encoder Loss:  0.0125236185  || Decoder Loss:  0.001918752 Validation Decoder Loss:  0.44060177
Encoder Loss:  0.012515346  || Decoder Loss:  0.0019121462 Validation Decoder Loss:  0.44014758
Encoder Loss:  0.012505118  || Decoder Loss:  0.0019018387 Validation Decoder Loss:  0.44027495
Encoder Loss:  0.012501948  || Decoder Loss:  0.0018979352 Validation Decoder Loss:  0.44106787
Encoder Loss:  0.012495211  || Decoder Loss:  0.0018927903 Validation Decoder Loss:  0.4410954
Model: bold_synthesis_net_lr_0.0008018841512529423 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.44109538
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 130, 14, 16, 1)    671       
_________________________________________________________________
reshape_72 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 671
Trainable params: 671
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.019756641  || Decoder Loss:  0.004852561 Validation Decoder Loss:  0.37869507
Encoder Loss:  0.018052524  || Decoder Loss:  0.00459022 Validation Decoder Loss:  0.3737569
Encoder Loss:  0.01691783  || Decoder Loss:  0.004259776 Validation Decoder Loss:  0.3699565
Encoder Loss:  0.016020983  || Decoder Loss:  0.0040457393 Validation Decoder Loss:  0.36794686
Encoder Loss:  0.015154827  || Decoder Loss:  0.003859613 Validation Decoder Loss:  0.367149
Encoder Loss:  0.014469207  || Decoder Loss:  0.0036952954 Validation Decoder Loss:  0.3672307
Encoder Loss:  0.01388968  || Decoder Loss:  0.0035143616 Validation Decoder Loss:  0.36764926
Encoder Loss:  0.013610061  || Decoder Loss:  0.0033816868 Validation Decoder Loss:  0.3683039
Encoder Loss:  0.013410346  || Decoder Loss:  0.0032387355 Validation Decoder Loss:  0.36870947
Encoder Loss:  0.013277966  || Decoder Loss:  0.0031504564 Validation Decoder Loss:  0.36910516
Encoder Loss:  0.013162544  || Decoder Loss:  0.003068403 Validation Decoder Loss:  0.36967105
Encoder Loss:  0.013086091  || Decoder Loss:  0.003013671 Validation Decoder Loss:  0.3700171
Encoder Loss:  0.013010128  || Decoder Loss:  0.002946175 Validation Decoder Loss:  0.37010992
Encoder Loss:  0.012931852  || Decoder Loss:  0.0028735236 Validation Decoder Loss:  0.3696471
Encoder Loss:  0.012835697  || Decoder Loss:  0.0027780181 Validation Decoder Loss:  0.3688907
Encoder Loss:  0.01276638  || Decoder Loss:  0.002709234 Validation Decoder Loss:  0.3688556
Encoder Loss:  0.012715159  || Decoder Loss:  0.0026626873 Validation Decoder Loss:  0.36841506
Encoder Loss:  0.012676647  || Decoder Loss:  0.0026291793 Validation Decoder Loss:  0.36833358
Encoder Loss:  0.012635691  || Decoder Loss:  0.0025991544 Validation Decoder Loss:  0.36828458
Encoder Loss:  0.012595857  || Decoder Loss:  0.0025603715 Validation Decoder Loss:  0.36795568
Encoder Loss:  0.012560751  || Decoder Loss:  0.0025267268 Validation Decoder Loss:  0.3673432
Encoder Loss:  0.012523335  || Decoder Loss:  0.0024942756 Validation Decoder Loss:  0.3668303
Encoder Loss:  0.012488491  || Decoder Loss:  0.0024587447 Validation Decoder Loss:  0.36645466
Encoder Loss:  0.012454842  || Decoder Loss:  0.0024302355 Validation Decoder Loss:  0.3662898
Encoder Loss:  0.01243297  || Decoder Loss:  0.0024086512 Validation Decoder Loss:  0.36614096
Encoder Loss:  0.012406571  || Decoder Loss:  0.002388718 Validation Decoder Loss:  0.3660918
Encoder Loss:  0.01238803  || Decoder Loss:  0.0023708902 Validation Decoder Loss:  0.3659373
Encoder Loss:  0.012365383  || Decoder Loss:  0.002353681 Validation Decoder Loss:  0.36592275
Encoder Loss:  0.012347371  || Decoder Loss:  0.0023400541 Validation Decoder Loss:  0.36592653
Encoder Loss:  0.012333949  || Decoder Loss:  0.0023305789 Validation Decoder Loss:  0.36611205
Encoder Loss:  0.012317891  || Decoder Loss:  0.0023188642 Validation Decoder Loss:  0.36604008
Encoder Loss:  0.012304685  || Decoder Loss:  0.0023099652 Validation Decoder Loss:  0.3658074
Encoder Loss:  0.012293955  || Decoder Loss:  0.0023031747 Validation Decoder Loss:  0.36575764
Encoder Loss:  0.0122809075  || Decoder Loss:  0.0022931737 Validation Decoder Loss:  0.36559504
Encoder Loss:  0.012269274  || Decoder Loss:  0.002283701 Validation Decoder Loss:  0.3655934
Encoder Loss:  0.012253882  || Decoder Loss:  0.0022685735 Validation Decoder Loss:  0.36547318
Encoder Loss:  0.012237969  || Decoder Loss:  0.0022566179 Validation Decoder Loss:  0.3653414
Encoder Loss:  0.012226923  || Decoder Loss:  0.0022446532 Validation Decoder Loss:  0.3652863
Encoder Loss:  0.012209744  || Decoder Loss:  0.0022274067 Validation Decoder Loss:  0.3650821
Encoder Loss:  0.012184956  || Decoder Loss:  0.0022048175 Validation Decoder Loss:  0.36506164
Model: bold_synthesis_net_lr_0.0008477566779899387 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.36506164
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_73 (Conv3DT (None, 65, 28, 16, 1)     49        
_________________________________________________________________
reshape_73 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.031462766  || Decoder Loss:  0.0065816706 Validation Decoder Loss:  0.38042027
Encoder Loss:  0.021448484  || Decoder Loss:  0.004753292 Validation Decoder Loss:  0.38116193
Encoder Loss:  0.020556899  || Decoder Loss:  0.0044722008 Validation Decoder Loss:  0.37893453
Encoder Loss:  0.019199064  || Decoder Loss:  0.004311946 Validation Decoder Loss:  0.3727373
Encoder Loss:  0.017898224  || Decoder Loss:  0.0042569167 Validation Decoder Loss:  0.34917486
Encoder Loss:  0.016759073  || Decoder Loss:  0.0038886638 Validation Decoder Loss:  0.32080656
Encoder Loss:  0.015590739  || Decoder Loss:  0.0033561932 Validation Decoder Loss:  0.27113882
Encoder Loss:  0.014678201  || Decoder Loss:  0.0026237764 Validation Decoder Loss:  0.24179654
Encoder Loss:  0.014158791  || Decoder Loss:  0.0020952744 Validation Decoder Loss:  0.2069858
Encoder Loss:  0.01387396  || Decoder Loss:  0.0018013227 Validation Decoder Loss:  0.1922397
Encoder Loss:  0.013644667  || Decoder Loss:  0.0015359301 Validation Decoder Loss:  0.17571743
Encoder Loss:  0.013455429  || Decoder Loss:  0.0013103969 Validation Decoder Loss:  0.15026148
Encoder Loss:  0.013318739  || Decoder Loss:  0.0011457002 Validation Decoder Loss:  0.13837707
Encoder Loss:  0.013254075  || Decoder Loss:  0.0010767166 Validation Decoder Loss:  0.12493497
Encoder Loss:  0.013183038  || Decoder Loss:  0.0009883849 Validation Decoder Loss:  0.11514759
Encoder Loss:  0.013125115  || Decoder Loss:  0.00091446255 Validation Decoder Loss:  0.103073865
Encoder Loss:  0.0130803725  || Decoder Loss:  0.0008604326 Validation Decoder Loss:  0.100666225
Encoder Loss:  0.01304507  || Decoder Loss:  0.0008167732 Validation Decoder Loss:  0.09459348
Encoder Loss:  0.0130152805  || Decoder Loss:  0.00077934377 Validation Decoder Loss:  0.09180098
Encoder Loss:  0.012990508  || Decoder Loss:  0.0007476872 Validation Decoder Loss:  0.08954823
Encoder Loss:  0.012966247  || Decoder Loss:  0.00071379065 Validation Decoder Loss:  0.08655079
Encoder Loss:  0.0129473815  || Decoder Loss:  0.0006918374 Validation Decoder Loss:  0.08440235
Encoder Loss:  0.012927208  || Decoder Loss:  0.0006657632 Validation Decoder Loss:  0.081708565
Encoder Loss:  0.012912452  || Decoder Loss:  0.00064842484 Validation Decoder Loss:  0.07897855
Encoder Loss:  0.012903212  || Decoder Loss:  0.00063612877 Validation Decoder Loss:  0.07644949
Encoder Loss:  0.012883679  || Decoder Loss:  0.00061168533 Validation Decoder Loss:  0.07652725
Encoder Loss:  0.012875954  || Decoder Loss:  0.00060137414 Validation Decoder Loss:  0.07467383
Encoder Loss:  0.012858878  || Decoder Loss:  0.0005801741 Validation Decoder Loss:  0.07173984
Encoder Loss:  0.012846684  || Decoder Loss:  0.0005651139 Validation Decoder Loss:  0.06916522
Encoder Loss:  0.012835516  || Decoder Loss:  0.00055111357 Validation Decoder Loss:  0.06739767
Encoder Loss:  0.012827163  || Decoder Loss:  0.0005408992 Validation Decoder Loss:  0.06783604
Encoder Loss:  0.012818108  || Decoder Loss:  0.0005275721 Validation Decoder Loss:  0.06374346
Encoder Loss:  0.012812091  || Decoder Loss:  0.00051981944 Validation Decoder Loss:  0.06305687
Encoder Loss:  0.012802378  || Decoder Loss:  0.0005080592 Validation Decoder Loss:  0.061663255
Encoder Loss:  0.0127906585  || Decoder Loss:  0.00049214665 Validation Decoder Loss:  0.058651
Encoder Loss:  0.012783213  || Decoder Loss:  0.0004834345 Validation Decoder Loss:  0.058160104
Encoder Loss:  0.012773865  || Decoder Loss:  0.00047205947 Validation Decoder Loss:  0.05748853
Encoder Loss:  0.012766624  || Decoder Loss:  0.00046327614 Validation Decoder Loss:  0.054991856
Encoder Loss:  0.012759201  || Decoder Loss:  0.00045240557 Validation Decoder Loss:  0.05568339
Encoder Loss:  0.01275639  || Decoder Loss:  0.00044986466 Validation Decoder Loss:  0.0543673
Model: bold_synthesis_net_lr_0.000686585923485254 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.0543673
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 130, 14, 16, 1)    403       
_________________________________________________________________
reshape_74 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 403
Trainable params: 403
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02188985  || Decoder Loss:  0.005063025 Validation Decoder Loss:  0.42439675
Encoder Loss:  0.019815031  || Decoder Loss:  0.004513247 Validation Decoder Loss:  0.42568156
Encoder Loss:  0.018879151  || Decoder Loss:  0.0042409236 Validation Decoder Loss:  0.42814988
Encoder Loss:  0.01827807  || Decoder Loss:  0.0040625944 Validation Decoder Loss:  0.4282654
Encoder Loss:  0.01772408  || Decoder Loss:  0.0039329333 Validation Decoder Loss:  0.42924613
Encoder Loss:  0.017187161  || Decoder Loss:  0.0038215413 Validation Decoder Loss:  0.4298232
Encoder Loss:  0.016634589  || Decoder Loss:  0.003722354 Validation Decoder Loss:  0.43165493
Encoder Loss:  0.015993206  || Decoder Loss:  0.0035694337 Validation Decoder Loss:  0.43169552
Encoder Loss:  0.0154806655  || Decoder Loss:  0.0033640945 Validation Decoder Loss:  0.43371588
Encoder Loss:  0.0151778795  || Decoder Loss:  0.0032460848 Validation Decoder Loss:  0.43526688
Encoder Loss:  0.015024681  || Decoder Loss:  0.003168659 Validation Decoder Loss:  0.43583432
Encoder Loss:  0.014911081  || Decoder Loss:  0.0030980632 Validation Decoder Loss:  0.43636513
Encoder Loss:  0.014786118  || Decoder Loss:  0.0029888572 Validation Decoder Loss:  0.43618098
Encoder Loss:  0.0146815805  || Decoder Loss:  0.0028977355 Validation Decoder Loss:  0.4364802
Encoder Loss:  0.014604288  || Decoder Loss:  0.0028352523 Validation Decoder Loss:  0.43550485
Encoder Loss:  0.014519179  || Decoder Loss:  0.0027683221 Validation Decoder Loss:  0.43509144
Encoder Loss:  0.014423167  || Decoder Loss:  0.002678657 Validation Decoder Loss:  0.43494636
Encoder Loss:  0.014341795  || Decoder Loss:  0.0026135526 Validation Decoder Loss:  0.43326008
Encoder Loss:  0.014284348  || Decoder Loss:  0.0025681457 Validation Decoder Loss:  0.43258747
Encoder Loss:  0.014229588  || Decoder Loss:  0.0025222362 Validation Decoder Loss:  0.43308356
Encoder Loss:  0.014172145  || Decoder Loss:  0.0024625314 Validation Decoder Loss:  0.43316776
Encoder Loss:  0.014129258  || Decoder Loss:  0.0024183833 Validation Decoder Loss:  0.4334752
Encoder Loss:  0.0140880905  || Decoder Loss:  0.0023768991 Validation Decoder Loss:  0.4342627
Encoder Loss:  0.0140511915  || Decoder Loss:  0.002339188 Validation Decoder Loss:  0.4341197
Encoder Loss:  0.014021506  || Decoder Loss:  0.002312028 Validation Decoder Loss:  0.43373895
Encoder Loss:  0.0139957415  || Decoder Loss:  0.0022900007 Validation Decoder Loss:  0.4333968
Encoder Loss:  0.013971339  || Decoder Loss:  0.0022645576 Validation Decoder Loss:  0.4333376
Encoder Loss:  0.013946485  || Decoder Loss:  0.0022401907 Validation Decoder Loss:  0.4331016
Encoder Loss:  0.013924246  || Decoder Loss:  0.0022195333 Validation Decoder Loss:  0.4331339
Encoder Loss:  0.01390416  || Decoder Loss:  0.00220126 Validation Decoder Loss:  0.43325794
Encoder Loss:  0.013886951  || Decoder Loss:  0.0021847636 Validation Decoder Loss:  0.43321085
Encoder Loss:  0.013873439  || Decoder Loss:  0.0021738678 Validation Decoder Loss:  0.43316853
Encoder Loss:  0.0138617335  || Decoder Loss:  0.0021628211 Validation Decoder Loss:  0.43331528
Encoder Loss:  0.013846543  || Decoder Loss:  0.0021509565 Validation Decoder Loss:  0.433307
Encoder Loss:  0.0138352765  || Decoder Loss:  0.0021425474 Validation Decoder Loss:  0.43304035
Encoder Loss:  0.0138249295  || Decoder Loss:  0.0021297995 Validation Decoder Loss:  0.43302757
Encoder Loss:  0.013810991  || Decoder Loss:  0.002116668 Validation Decoder Loss:  0.43285763
Encoder Loss:  0.013800641  || Decoder Loss:  0.0021051848 Validation Decoder Loss:  0.4327579
Encoder Loss:  0.013789865  || Decoder Loss:  0.0020935251 Validation Decoder Loss:  0.43266642
Encoder Loss:  0.01377861  || Decoder Loss:  0.00208083 Validation Decoder Loss:  0.4324848
Model: bold_synthesis_net_lr_0.0007004919521774042 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4324848
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 140, 13, 16, 1)    386       
_________________________________________________________________
reshape_75 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 386
Trainable params: 386
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02151521  || Decoder Loss:  0.0051717362 Validation Decoder Loss:  0.44900614
Encoder Loss:  0.019473722  || Decoder Loss:  0.0043772785 Validation Decoder Loss:  0.44562384
Encoder Loss:  0.018536927  || Decoder Loss:  0.004261764 Validation Decoder Loss:  0.44207853
Encoder Loss:  0.017868686  || Decoder Loss:  0.0041160895 Validation Decoder Loss:  0.44679558
Encoder Loss:  0.017369878  || Decoder Loss:  0.003965842 Validation Decoder Loss:  0.4470372
Encoder Loss:  0.016854849  || Decoder Loss:  0.003772332 Validation Decoder Loss:  0.44017664
Encoder Loss:  0.016349971  || Decoder Loss:  0.0035718987 Validation Decoder Loss:  0.4384102
Encoder Loss:  0.015949901  || Decoder Loss:  0.003483525 Validation Decoder Loss:  0.4389295
Encoder Loss:  0.015560816  || Decoder Loss:  0.0034094246 Validation Decoder Loss:  0.43817914
Encoder Loss:  0.015160788  || Decoder Loss:  0.0033064375 Validation Decoder Loss:  0.43786854
Encoder Loss:  0.014873948  || Decoder Loss:  0.003211027 Validation Decoder Loss:  0.4370134
Encoder Loss:  0.014726108  || Decoder Loss:  0.0031202894 Validation Decoder Loss:  0.43475628
Encoder Loss:  0.014618459  || Decoder Loss:  0.0030343733 Validation Decoder Loss:  0.43350744
Encoder Loss:  0.014555055  || Decoder Loss:  0.0029853783 Validation Decoder Loss:  0.43305027
Encoder Loss:  0.014492503  || Decoder Loss:  0.002942183 Validation Decoder Loss:  0.43223113
Encoder Loss:  0.014457631  || Decoder Loss:  0.0029188455 Validation Decoder Loss:  0.43214285
Encoder Loss:  0.014416426  || Decoder Loss:  0.002885682 Validation Decoder Loss:  0.43215266
Encoder Loss:  0.0143767195  || Decoder Loss:  0.0028510997 Validation Decoder Loss:  0.43229362
Encoder Loss:  0.014336909  || Decoder Loss:  0.0028105972 Validation Decoder Loss:  0.43194744
Encoder Loss:  0.0142982425  || Decoder Loss:  0.0027775166 Validation Decoder Loss:  0.4321666
Encoder Loss:  0.01426803  || Decoder Loss:  0.0027509762 Validation Decoder Loss:  0.43139014
Encoder Loss:  0.01424505  || Decoder Loss:  0.0027326131 Validation Decoder Loss:  0.43132222
Encoder Loss:  0.014224249  || Decoder Loss:  0.002714115 Validation Decoder Loss:  0.43078774
Encoder Loss:  0.014208029  || Decoder Loss:  0.0027019635 Validation Decoder Loss:  0.43061498
Encoder Loss:  0.01418718  || Decoder Loss:  0.0026870964 Validation Decoder Loss:  0.43056482
Encoder Loss:  0.01417052  || Decoder Loss:  0.0026719056 Validation Decoder Loss:  0.43028736
Encoder Loss:  0.014144604  || Decoder Loss:  0.002648908 Validation Decoder Loss:  0.43015975
Encoder Loss:  0.014130124  || Decoder Loss:  0.002628156 Validation Decoder Loss:  0.42998105
Encoder Loss:  0.014104476  || Decoder Loss:  0.002604975 Validation Decoder Loss:  0.42961758
Encoder Loss:  0.014086871  || Decoder Loss:  0.0025840164 Validation Decoder Loss:  0.42980713
Encoder Loss:  0.014068283  || Decoder Loss:  0.002567959 Validation Decoder Loss:  0.4294614
Encoder Loss:  0.014055343  || Decoder Loss:  0.0025524122 Validation Decoder Loss:  0.42939836
Encoder Loss:  0.014036253  || Decoder Loss:  0.0025321797 Validation Decoder Loss:  0.4292326
Encoder Loss:  0.014023902  || Decoder Loss:  0.0025149942 Validation Decoder Loss:  0.42881924
Encoder Loss:  0.014009212  || Decoder Loss:  0.0025005017 Validation Decoder Loss:  0.4287929
Encoder Loss:  0.013996422  || Decoder Loss:  0.002489258 Validation Decoder Loss:  0.42833775
Encoder Loss:  0.013988371  || Decoder Loss:  0.002476143 Validation Decoder Loss:  0.42847878
Encoder Loss:  0.0139771355  || Decoder Loss:  0.0024660926 Validation Decoder Loss:  0.4280252
Encoder Loss:  0.0139693385  || Decoder Loss:  0.0024591025 Validation Decoder Loss:  0.42773372
Encoder Loss:  0.013961669  || Decoder Loss:  0.002450896 Validation Decoder Loss:  0.42785805
Model: bold_synthesis_net_lr_0.0007128689139345808 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.42785805
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_76 (Conv3DT (None, 130, 14, 16, 1)    671       
_________________________________________________________________
reshape_76 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 671
Trainable params: 671
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.023105321  || Decoder Loss:  0.0048864703 Validation Decoder Loss:  0.38025773
Encoder Loss:  0.021256838  || Decoder Loss:  0.0046525477 Validation Decoder Loss:  0.37640494
Encoder Loss:  0.020135527  || Decoder Loss:  0.004376427 Validation Decoder Loss:  0.37286776
Encoder Loss:  0.019200638  || Decoder Loss:  0.004165338 Validation Decoder Loss:  0.37028724
Encoder Loss:  0.01847283  || Decoder Loss:  0.0040512816 Validation Decoder Loss:  0.36774415
Encoder Loss:  0.017799294  || Decoder Loss:  0.003923718 Validation Decoder Loss:  0.36683524
Encoder Loss:  0.016956795  || Decoder Loss:  0.003703833 Validation Decoder Loss:  0.36688185
Encoder Loss:  0.016216729  || Decoder Loss:  0.0034869642 Validation Decoder Loss:  0.3666123
Encoder Loss:  0.015823122  || Decoder Loss:  0.0033523168 Validation Decoder Loss:  0.3662937
Encoder Loss:  0.015600032  || Decoder Loss:  0.0032422598 Validation Decoder Loss:  0.36663723
Encoder Loss:  0.01545467  || Decoder Loss:  0.0031634748 Validation Decoder Loss:  0.36698037
Encoder Loss:  0.015349209  || Decoder Loss:  0.0031073291 Validation Decoder Loss:  0.36721957
Encoder Loss:  0.015274323  || Decoder Loss:  0.003074067 Validation Decoder Loss:  0.36792442
Encoder Loss:  0.015207581  || Decoder Loss:  0.0030457953 Validation Decoder Loss:  0.36811012
Encoder Loss:  0.0151401665  || Decoder Loss:  0.0030015842 Validation Decoder Loss:  0.36838192
Encoder Loss:  0.015080002  || Decoder Loss:  0.0029631935 Validation Decoder Loss:  0.3687452
Encoder Loss:  0.01502757  || Decoder Loss:  0.0029229529 Validation Decoder Loss:  0.36901602
Encoder Loss:  0.014984109  || Decoder Loss:  0.0028867538 Validation Decoder Loss:  0.36925808
Encoder Loss:  0.014942086  || Decoder Loss:  0.0028545293 Validation Decoder Loss:  0.369504
Encoder Loss:  0.014905086  || Decoder Loss:  0.002826289 Validation Decoder Loss:  0.36976463
Encoder Loss:  0.01487329  || Decoder Loss:  0.0028076516 Validation Decoder Loss:  0.36985904
Encoder Loss:  0.014844369  || Decoder Loss:  0.0027896978 Validation Decoder Loss:  0.36991468
Encoder Loss:  0.0148211345  || Decoder Loss:  0.0027750852 Validation Decoder Loss:  0.36996385
Encoder Loss:  0.014800538  || Decoder Loss:  0.002761988 Validation Decoder Loss:  0.36998817
Encoder Loss:  0.014780776  || Decoder Loss:  0.002751305 Validation Decoder Loss:  0.369784
Encoder Loss:  0.01476141  || Decoder Loss:  0.0027357866 Validation Decoder Loss:  0.3694724
Encoder Loss:  0.014728233  || Decoder Loss:  0.0027122775 Validation Decoder Loss:  0.36938763
Encoder Loss:  0.014703481  || Decoder Loss:  0.0026914715 Validation Decoder Loss:  0.36922657
Encoder Loss:  0.014679816  || Decoder Loss:  0.0026709375 Validation Decoder Loss:  0.3690697
Encoder Loss:  0.014650441  || Decoder Loss:  0.0026510921 Validation Decoder Loss:  0.36899427
Encoder Loss:  0.014631997  || Decoder Loss:  0.002636677 Validation Decoder Loss:  0.36899248
Encoder Loss:  0.014610234  || Decoder Loss:  0.0026190153 Validation Decoder Loss:  0.36901546
Encoder Loss:  0.014589274  || Decoder Loss:  0.0026059381 Validation Decoder Loss:  0.36908367
Encoder Loss:  0.01456897  || Decoder Loss:  0.0025915818 Validation Decoder Loss:  0.36901003
Encoder Loss:  0.014549278  || Decoder Loss:  0.0025741272 Validation Decoder Loss:  0.3690021
Encoder Loss:  0.014531271  || Decoder Loss:  0.0025576318 Validation Decoder Loss:  0.36903664
Encoder Loss:  0.014510947  || Decoder Loss:  0.002541836 Validation Decoder Loss:  0.369017
Encoder Loss:  0.014494252  || Decoder Loss:  0.0025294225 Validation Decoder Loss:  0.3688266
Encoder Loss:  0.014476199  || Decoder Loss:  0.002514637 Validation Decoder Loss:  0.36869615
Encoder Loss:  0.014459596  || Decoder Loss:  0.00250089 Validation Decoder Loss:  0.36842382
Model: bold_synthesis_net_lr_0.0006668904763546956 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.36842382
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 130, 14, 16, 1)    41        
_________________________________________________________________
reshape_77 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02829361  || Decoder Loss:  0.006807658 Validation Decoder Loss:  0.38985187
Encoder Loss:  0.01948418  || Decoder Loss:  0.004773917 Validation Decoder Loss:  0.39233112
Encoder Loss:  0.018421838  || Decoder Loss:  0.0043599186 Validation Decoder Loss:  0.39105532
Encoder Loss:  0.017232476  || Decoder Loss:  0.00389092 Validation Decoder Loss:  0.39231378
Encoder Loss:  0.016133275  || Decoder Loss:  0.0036506504 Validation Decoder Loss:  0.38227624
Encoder Loss:  0.015345058  || Decoder Loss:  0.0036717611 Validation Decoder Loss:  0.34872437
Encoder Loss:  0.014266036  || Decoder Loss:  0.0030554184 Validation Decoder Loss:  0.25255245
Encoder Loss:  0.013629242  || Decoder Loss:  0.0026341681 Validation Decoder Loss:  0.22503287
Encoder Loss:  0.0130869225  || Decoder Loss:  0.002085267 Validation Decoder Loss:  0.20358759
Encoder Loss:  0.012708523  || Decoder Loss:  0.0016149773 Validation Decoder Loss:  0.19640233
Encoder Loss:  0.01254692  || Decoder Loss:  0.0014146534 Validation Decoder Loss:  0.18803842
Encoder Loss:  0.012439842  || Decoder Loss:  0.0012866925 Validation Decoder Loss:  0.18888673
Encoder Loss:  0.012375387  || Decoder Loss:  0.0012097327 Validation Decoder Loss:  0.18317842
Encoder Loss:  0.01233501  || Decoder Loss:  0.0011641014 Validation Decoder Loss:  0.17516781
Encoder Loss:  0.012290887  || Decoder Loss:  0.0011086585 Validation Decoder Loss:  0.1699437
Encoder Loss:  0.012256031  || Decoder Loss:  0.001066799 Validation Decoder Loss:  0.15938017
Encoder Loss:  0.012213312  || Decoder Loss:  0.0010131176 Validation Decoder Loss:  0.15462758
Encoder Loss:  0.0121801365  || Decoder Loss:  0.0009737343 Validation Decoder Loss:  0.15003765
Encoder Loss:  0.01214462  || Decoder Loss:  0.0009301447 Validation Decoder Loss:  0.13601509
Encoder Loss:  0.012111804  || Decoder Loss:  0.000889007 Validation Decoder Loss:  0.1310112
Encoder Loss:  0.012083202  || Decoder Loss:  0.0008530972 Validation Decoder Loss:  0.12583575
Encoder Loss:  0.0120608965  || Decoder Loss:  0.000823449 Validation Decoder Loss:  0.121045254
Encoder Loss:  0.0120287705  || Decoder Loss:  0.00078486867 Validation Decoder Loss:  0.11476672
Encoder Loss:  0.012009483  || Decoder Loss:  0.00075970555 Validation Decoder Loss:  0.11255123
Encoder Loss:  0.011992854  || Decoder Loss:  0.0007391271 Validation Decoder Loss:  0.1086415
Encoder Loss:  0.011975226  || Decoder Loss:  0.00071596086 Validation Decoder Loss:  0.10934524
Encoder Loss:  0.011954485  || Decoder Loss:  0.0006912753 Validation Decoder Loss:  0.10731547
Encoder Loss:  0.011943147  || Decoder Loss:  0.00067576923 Validation Decoder Loss:  0.106537096
Encoder Loss:  0.011925736  || Decoder Loss:  0.00065549073 Validation Decoder Loss:  0.10499266
Encoder Loss:  0.011915194  || Decoder Loss:  0.0006418934 Validation Decoder Loss:  0.10326454
Encoder Loss:  0.011898406  || Decoder Loss:  0.0006201909 Validation Decoder Loss:  0.10371298
Encoder Loss:  0.011886833  || Decoder Loss:  0.00060595927 Validation Decoder Loss:  0.1021328
Encoder Loss:  0.011878504  || Decoder Loss:  0.00059585087 Validation Decoder Loss:  0.10025068
Encoder Loss:  0.011870566  || Decoder Loss:  0.00058447954 Validation Decoder Loss:  0.101574294
Encoder Loss:  0.011858023  || Decoder Loss:  0.0005698623 Validation Decoder Loss:  0.09895044
Encoder Loss:  0.0118480325  || Decoder Loss:  0.00055698823 Validation Decoder Loss:  0.09904046
Encoder Loss:  0.011842245  || Decoder Loss:  0.00055067707 Validation Decoder Loss:  0.09825042
Encoder Loss:  0.011829769  || Decoder Loss:  0.00053458486 Validation Decoder Loss:  0.097526416
Encoder Loss:  0.011823335  || Decoder Loss:  0.0005271643 Validation Decoder Loss:  0.09412566
Encoder Loss:  0.0118131  || Decoder Loss:  0.0005155476 Validation Decoder Loss:  0.09313671
Model: bold_synthesis_net_lr_0.0007312444300732377 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.09313671
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 65, 28, 16, 1)     17        
_________________________________________________________________
reshape_78 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.031531576  || Decoder Loss:  0.0072951424 Validation Decoder Loss:  0.32181507
Encoder Loss:  0.022599142  || Decoder Loss:  0.0063417135 Validation Decoder Loss:  0.38891166
Encoder Loss:  0.018690748  || Decoder Loss:  0.004514276 Validation Decoder Loss:  0.39773917
Encoder Loss:  0.01775535  || Decoder Loss:  0.003993454 Validation Decoder Loss:  0.39024687
Encoder Loss:  0.01677005  || Decoder Loss:  0.0035945773 Validation Decoder Loss:  0.3663993
Encoder Loss:  0.015823556  || Decoder Loss:  0.0031853803 Validation Decoder Loss:  0.3609749
Encoder Loss:  0.0151609415  || Decoder Loss:  0.0027962613 Validation Decoder Loss:  0.35414094
Encoder Loss:  0.014690048  || Decoder Loss:  0.0025456354 Validation Decoder Loss:  0.3468961
Encoder Loss:  0.014245518  || Decoder Loss:  0.0023448966 Validation Decoder Loss:  0.34737417
Encoder Loss:  0.013997166  || Decoder Loss:  0.002308981 Validation Decoder Loss:  0.30755386
Encoder Loss:  0.013744168  || Decoder Loss:  0.0022008016 Validation Decoder Loss:  0.27963424
Encoder Loss:  0.013526864  || Decoder Loss:  0.0020398102 Validation Decoder Loss:  0.24918146
Encoder Loss:  0.0133303525  || Decoder Loss:  0.001824465 Validation Decoder Loss:  0.22380182
Encoder Loss:  0.013166781  || Decoder Loss:  0.0016335471 Validation Decoder Loss:  0.20575586
Encoder Loss:  0.013033976  || Decoder Loss:  0.0014630067 Validation Decoder Loss:  0.18308069
Encoder Loss:  0.012947357  || Decoder Loss:  0.0013610239 Validation Decoder Loss:  0.17199804
Encoder Loss:  0.012867708  || Decoder Loss:  0.0012642505 Validation Decoder Loss:  0.17642386
Encoder Loss:  0.012775501  || Decoder Loss:  0.0011468347 Validation Decoder Loss:  0.1717838
Encoder Loss:  0.012723194  || Decoder Loss:  0.0010802353 Validation Decoder Loss:  0.16557708
Encoder Loss:  0.012675137  || Decoder Loss:  0.0010257295 Validation Decoder Loss:  0.1582557
Encoder Loss:  0.012631496  || Decoder Loss:  0.0009692736 Validation Decoder Loss:  0.15264341
Encoder Loss:  0.012591647  || Decoder Loss:  0.0009175234 Validation Decoder Loss:  0.14531694
Encoder Loss:  0.012549255  || Decoder Loss:  0.00086263486 Validation Decoder Loss:  0.13949205
Encoder Loss:  0.012515517  || Decoder Loss:  0.0008186975 Validation Decoder Loss:  0.13737895
Encoder Loss:  0.012488881  || Decoder Loss:  0.0007846001 Validation Decoder Loss:  0.13061978
Encoder Loss:  0.012464361  || Decoder Loss:  0.0007519758 Validation Decoder Loss:  0.12808266
Encoder Loss:  0.012441974  || Decoder Loss:  0.00072496396 Validation Decoder Loss:  0.12502097
Encoder Loss:  0.012418528  || Decoder Loss:  0.000693213 Validation Decoder Loss:  0.12020973
Encoder Loss:  0.012397276  || Decoder Loss:  0.00066669314 Validation Decoder Loss:  0.11907334
Encoder Loss:  0.01238481  || Decoder Loss:  0.0006483067 Validation Decoder Loss:  0.11528583
Encoder Loss:  0.012368484  || Decoder Loss:  0.00062578433 Validation Decoder Loss:  0.1130825
Encoder Loss:  0.012348803  || Decoder Loss:  0.000603321 Validation Decoder Loss:  0.11124737
Encoder Loss:  0.0123359775  || Decoder Loss:  0.0005843467 Validation Decoder Loss:  0.10915706
Encoder Loss:  0.012319924  || Decoder Loss:  0.00056437094 Validation Decoder Loss:  0.104732916
Encoder Loss:  0.012303502  || Decoder Loss:  0.0005427215 Validation Decoder Loss:  0.10140926
Encoder Loss:  0.012290854  || Decoder Loss:  0.00052359025 Validation Decoder Loss:  0.09979647
Encoder Loss:  0.012279973  || Decoder Loss:  0.00051004963 Validation Decoder Loss:  0.09908421
Encoder Loss:  0.0122692995  || Decoder Loss:  0.0004956051 Validation Decoder Loss:  0.09740746
Encoder Loss:  0.012260837  || Decoder Loss:  0.00048471722 Validation Decoder Loss:  0.09436333
Encoder Loss:  0.0122500695  || Decoder Loss:  0.0004697323 Validation Decoder Loss:  0.094017625
Model: bold_synthesis_net_lr_0.000712646849982321 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.094017625
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_79 (Conv3DT (None, 140, 13, 16, 1)    386       
_________________________________________________________________
reshape_79 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 386
Trainable params: 386
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0075478773  || Decoder Loss:  0.0050623743 Validation Decoder Loss:  0.44806474
Encoder Loss:  0.0065710736  || Decoder Loss:  0.004299665 Validation Decoder Loss:  0.44199926
Encoder Loss:  0.006306872  || Decoder Loss:  0.004169784 Validation Decoder Loss:  0.4455825
Encoder Loss:  0.0059395945  || Decoder Loss:  0.0038813704 Validation Decoder Loss:  0.44343197
Encoder Loss:  0.005615937  || Decoder Loss:  0.003624994 Validation Decoder Loss:  0.43986523
Encoder Loss:  0.005320594  || Decoder Loss:  0.0033966494 Validation Decoder Loss:  0.43961924
Encoder Loss:  0.005098429  || Decoder Loss:  0.003247307 Validation Decoder Loss:  0.43941298
Encoder Loss:  0.004911796  || Decoder Loss:  0.0030992725 Validation Decoder Loss:  0.43722254
Encoder Loss:  0.0048275962  || Decoder Loss:  0.003027007 Validation Decoder Loss:  0.43655324
Encoder Loss:  0.004745804  || Decoder Loss:  0.002950956 Validation Decoder Loss:  0.43578243
Encoder Loss:  0.0046841973  || Decoder Loss:  0.0028929256 Validation Decoder Loss:  0.43514466
Encoder Loss:  0.004632325  || Decoder Loss:  0.0028433308 Validation Decoder Loss:  0.43410242
Encoder Loss:  0.0045854207  || Decoder Loss:  0.0027977247 Validation Decoder Loss:  0.43286425
Encoder Loss:  0.0045409184  || Decoder Loss:  0.0027548042 Validation Decoder Loss:  0.43213737
Encoder Loss:  0.0045098444  || Decoder Loss:  0.0027239115 Validation Decoder Loss:  0.43145198
Encoder Loss:  0.0044825305  || Decoder Loss:  0.0026979567 Validation Decoder Loss:  0.4309631
Encoder Loss:  0.0044456394  || Decoder Loss:  0.0026608505 Validation Decoder Loss:  0.4300473
Encoder Loss:  0.0044084415  || Decoder Loss:  0.0026240018 Validation Decoder Loss:  0.42932975
Encoder Loss:  0.004377671  || Decoder Loss:  0.0025936097 Validation Decoder Loss:  0.428053
Encoder Loss:  0.004338643  || Decoder Loss:  0.0025529766 Validation Decoder Loss:  0.42804432
Encoder Loss:  0.0043079024  || Decoder Loss:  0.0025216334 Validation Decoder Loss:  0.42789286
Encoder Loss:  0.0042774277  || Decoder Loss:  0.0024913067 Validation Decoder Loss:  0.42771274
Encoder Loss:  0.00425443  || Decoder Loss:  0.002467915 Validation Decoder Loss:  0.42701712
Encoder Loss:  0.0042258087  || Decoder Loss:  0.0024388384 Validation Decoder Loss:  0.42646003
Encoder Loss:  0.004202176  || Decoder Loss:  0.002414804 Validation Decoder Loss:  0.42645255
Encoder Loss:  0.0041899458  || Decoder Loss:  0.0024011342 Validation Decoder Loss:  0.4262712
Encoder Loss:  0.004170383  || Decoder Loss:  0.0023810342 Validation Decoder Loss:  0.4257834
Encoder Loss:  0.0041544675  || Decoder Loss:  0.0023657833 Validation Decoder Loss:  0.42550564
Encoder Loss:  0.004143551  || Decoder Loss:  0.0023545637 Validation Decoder Loss:  0.4253057
Encoder Loss:  0.0041297586  || Decoder Loss:  0.0023404744 Validation Decoder Loss:  0.42488968
Encoder Loss:  0.0041099386  || Decoder Loss:  0.0023197252 Validation Decoder Loss:  0.4251052
Encoder Loss:  0.0040976093  || Decoder Loss:  0.0023071924 Validation Decoder Loss:  0.4253831
Encoder Loss:  0.004081598  || Decoder Loss:  0.0022901294 Validation Decoder Loss:  0.4245047
Encoder Loss:  0.004072642  || Decoder Loss:  0.00228106 Validation Decoder Loss:  0.4241103
Encoder Loss:  0.0040629515  || Decoder Loss:  0.002271119 Validation Decoder Loss:  0.42498606
Encoder Loss:  0.004045128  || Decoder Loss:  0.0022525399 Validation Decoder Loss:  0.42427665
Encoder Loss:  0.0040276647  || Decoder Loss:  0.002235064 Validation Decoder Loss:  0.422754
Encoder Loss:  0.0040143034  || Decoder Loss:  0.0022208437 Validation Decoder Loss:  0.4227205
Encoder Loss:  0.0039999536  || Decoder Loss:  0.0022069872 Validation Decoder Loss:  0.4218508
Encoder Loss:  0.0039821086  || Decoder Loss:  0.0021884204 Validation Decoder Loss:  0.4215124
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4215124
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 91, 20, 16, 1)     449       
_________________________________________________________________
reshape_80 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 449
Trainable params: 449
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.026758293  || Decoder Loss:  0.006279712 Validation Decoder Loss:  0.38234556
Encoder Loss:  0.023996824  || Decoder Loss:  0.005236559 Validation Decoder Loss:  0.381377
Encoder Loss:  0.022853069  || Decoder Loss:  0.0048682606 Validation Decoder Loss:  0.37930077
Encoder Loss:  0.021893544  || Decoder Loss:  0.004587459 Validation Decoder Loss:  0.37842953
Encoder Loss:  0.020656962  || Decoder Loss:  0.0042660935 Validation Decoder Loss:  0.37483397
Encoder Loss:  0.019382898  || Decoder Loss:  0.003965082 Validation Decoder Loss:  0.3735859
Encoder Loss:  0.018461153  || Decoder Loss:  0.0037806279 Validation Decoder Loss:  0.3739159
Encoder Loss:  0.017671635  || Decoder Loss:  0.0036846139 Validation Decoder Loss:  0.3704431
Encoder Loss:  0.016990332  || Decoder Loss:  0.003454625 Validation Decoder Loss:  0.3676174
Encoder Loss:  0.016529318  || Decoder Loss:  0.0032611059 Validation Decoder Loss:  0.3671723
Encoder Loss:  0.016212903  || Decoder Loss:  0.0030871357 Validation Decoder Loss:  0.3672076
Encoder Loss:  0.015994051  || Decoder Loss:  0.0030030245 Validation Decoder Loss:  0.36427218
Encoder Loss:  0.015834799  || Decoder Loss:  0.0029692403 Validation Decoder Loss:  0.36399457
Encoder Loss:  0.01568205  || Decoder Loss:  0.0028676111 Validation Decoder Loss:  0.3621126
Encoder Loss:  0.0155362645  || Decoder Loss:  0.0027527313 Validation Decoder Loss:  0.35992712
Encoder Loss:  0.015418614  || Decoder Loss:  0.0026583108 Validation Decoder Loss:  0.35752943
Encoder Loss:  0.015307435  || Decoder Loss:  0.002553653 Validation Decoder Loss:  0.3545797
Encoder Loss:  0.015226206  || Decoder Loss:  0.0024996283 Validation Decoder Loss:  0.35210726
Encoder Loss:  0.015164182  || Decoder Loss:  0.0024514613 Validation Decoder Loss:  0.34999853
Encoder Loss:  0.015116862  || Decoder Loss:  0.0024114638 Validation Decoder Loss:  0.34928948
Encoder Loss:  0.015084727  || Decoder Loss:  0.0023856973 Validation Decoder Loss:  0.3486123
Encoder Loss:  0.015050398  || Decoder Loss:  0.0023627256 Validation Decoder Loss:  0.34762394
Encoder Loss:  0.015015564  || Decoder Loss:  0.00233359 Validation Decoder Loss:  0.34699976
Encoder Loss:  0.0149874985  || Decoder Loss:  0.002309021 Validation Decoder Loss:  0.34656262
Encoder Loss:  0.014955044  || Decoder Loss:  0.0022834784 Validation Decoder Loss:  0.34554037
Encoder Loss:  0.014927045  || Decoder Loss:  0.0022625863 Validation Decoder Loss:  0.34432223
Encoder Loss:  0.014897437  || Decoder Loss:  0.00223621 Validation Decoder Loss:  0.34336704
Encoder Loss:  0.014871901  || Decoder Loss:  0.002208599 Validation Decoder Loss:  0.3426336
Encoder Loss:  0.014851226  || Decoder Loss:  0.0021875352 Validation Decoder Loss:  0.3421926
Encoder Loss:  0.014824956  || Decoder Loss:  0.0021674584 Validation Decoder Loss:  0.34227374
Encoder Loss:  0.014814476  || Decoder Loss:  0.00215423 Validation Decoder Loss:  0.34213477
Encoder Loss:  0.014786611  || Decoder Loss:  0.0021381169 Validation Decoder Loss:  0.3418665
Encoder Loss:  0.014766081  || Decoder Loss:  0.0021215912 Validation Decoder Loss:  0.3417235
Encoder Loss:  0.014756286  || Decoder Loss:  0.002105815 Validation Decoder Loss:  0.34119925
Encoder Loss:  0.014736592  || Decoder Loss:  0.0020897775 Validation Decoder Loss:  0.34086397
Encoder Loss:  0.014719354  || Decoder Loss:  0.0020717902 Validation Decoder Loss:  0.34026784
Encoder Loss:  0.014707189  || Decoder Loss:  0.0020538105 Validation Decoder Loss:  0.33986083
Encoder Loss:  0.01469548  || Decoder Loss:  0.0020391406 Validation Decoder Loss:  0.33924478
Encoder Loss:  0.014680591  || Decoder Loss:  0.002026512 Validation Decoder Loss:  0.33899793
Encoder Loss:  0.014673227  || Decoder Loss:  0.0020143099 Validation Decoder Loss:  0.33853188
Model: bold_synthesis_net_lr_0.0006659380235416534 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.33853188
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 364, 5, 16, 1)     50        
_________________________________________________________________
reshape_81 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02581889  || Decoder Loss:  0.0059743486 Validation Decoder Loss:  0.3900623
Encoder Loss:  0.023456221  || Decoder Loss:  0.0050343387 Validation Decoder Loss:  0.394432
Encoder Loss:  0.022645313  || Decoder Loss:  0.0050142007 Validation Decoder Loss:  0.3934909
Encoder Loss:  0.021937082  || Decoder Loss:  0.004913084 Validation Decoder Loss:  0.39237535
Encoder Loss:  0.021161405  || Decoder Loss:  0.004792858 Validation Decoder Loss:  0.38864076
Encoder Loss:  0.020343881  || Decoder Loss:  0.0044670333 Validation Decoder Loss:  0.38175315
Encoder Loss:  0.01943595  || Decoder Loss:  0.004047264 Validation Decoder Loss:  0.37422782
Encoder Loss:  0.018722557  || Decoder Loss:  0.0038634771 Validation Decoder Loss:  0.37132013
Encoder Loss:  0.01810461  || Decoder Loss:  0.0036741076 Validation Decoder Loss:  0.36730605
Encoder Loss:  0.017597169  || Decoder Loss:  0.00345328 Validation Decoder Loss:  0.3523116
Encoder Loss:  0.017123625  || Decoder Loss:  0.00327097 Validation Decoder Loss:  0.32508302
Encoder Loss:  0.016688576  || Decoder Loss:  0.0031314504 Validation Decoder Loss:  0.29055852
Encoder Loss:  0.016202634  || Decoder Loss:  0.0027955174 Validation Decoder Loss:  0.2600804
Encoder Loss:  0.015780874  || Decoder Loss:  0.002467511 Validation Decoder Loss:  0.22754383
Encoder Loss:  0.015403313  || Decoder Loss:  0.0020483371 Validation Decoder Loss:  0.22265145
Encoder Loss:  0.015148174  || Decoder Loss:  0.0017560166 Validation Decoder Loss:  0.21685368
Encoder Loss:  0.014987666  || Decoder Loss:  0.0015930063 Validation Decoder Loss:  0.21689135
Encoder Loss:  0.014869127  || Decoder Loss:  0.0014826929 Validation Decoder Loss:  0.21166176
Encoder Loss:  0.014774251  || Decoder Loss:  0.0013965594 Validation Decoder Loss:  0.2102277
Encoder Loss:  0.01469986  || Decoder Loss:  0.0013231961 Validation Decoder Loss:  0.2075848
Encoder Loss:  0.014634911  || Decoder Loss:  0.0012507376 Validation Decoder Loss:  0.202402
Encoder Loss:  0.014591035  || Decoder Loss:  0.0012019468 Validation Decoder Loss:  0.20085561
Encoder Loss:  0.01454763  || Decoder Loss:  0.0011562819 Validation Decoder Loss:  0.20010883
Encoder Loss:  0.014522124  || Decoder Loss:  0.0011283775 Validation Decoder Loss:  0.19978964
Encoder Loss:  0.014495795  || Decoder Loss:  0.0011030342 Validation Decoder Loss:  0.19915298
Encoder Loss:  0.014474258  || Decoder Loss:  0.0010820372 Validation Decoder Loss:  0.19889562
Encoder Loss:  0.014456453  || Decoder Loss:  0.001058631 Validation Decoder Loss:  0.19574246
Encoder Loss:  0.014444272  || Decoder Loss:  0.0010443894 Validation Decoder Loss:  0.19626382
Encoder Loss:  0.014425285  || Decoder Loss:  0.0010244675 Validation Decoder Loss:  0.19505294
Encoder Loss:  0.0144086955  || Decoder Loss:  0.0010049948 Validation Decoder Loss:  0.19142443
Encoder Loss:  0.014399134  || Decoder Loss:  0.0009892777 Validation Decoder Loss:  0.19129829
Encoder Loss:  0.014382442  || Decoder Loss:  0.00097311795 Validation Decoder Loss:  0.19331205
Encoder Loss:  0.014368583  || Decoder Loss:  0.0009577377 Validation Decoder Loss:  0.19175787
Encoder Loss:  0.0143548325  || Decoder Loss:  0.0009389784 Validation Decoder Loss:  0.18662968
Encoder Loss:  0.0143449  || Decoder Loss:  0.00092287944 Validation Decoder Loss:  0.18977821
Encoder Loss:  0.014326589  || Decoder Loss:  0.000903207 Validation Decoder Loss:  0.18671949
Encoder Loss:  0.014315051  || Decoder Loss:  0.00088427565 Validation Decoder Loss:  0.18489382
Encoder Loss:  0.014302924  || Decoder Loss:  0.00086800224 Validation Decoder Loss:  0.18704432
Encoder Loss:  0.014290777  || Decoder Loss:  0.000852085 Validation Decoder Loss:  0.18370563
Encoder Loss:  0.0142797595  || Decoder Loss:  0.000836166 Validation Decoder Loss:  0.18114743
Model: bold_synthesis_net_lr_0.0006538926211234285 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.18114743
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_82 (Conv3DT (None, 182, 10, 16, 1)    239       
_________________________________________________________________
reshape_82 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.020480275  || Decoder Loss:  0.0046884124 Validation Decoder Loss:  0.46721452
Encoder Loss:  0.01790255  || Decoder Loss:  0.0035567163 Validation Decoder Loss:  0.46693867
Encoder Loss:  0.017259702  || Decoder Loss:  0.003198829 Validation Decoder Loss:  0.46724582
Encoder Loss:  0.016783379  || Decoder Loss:  0.0029691025 Validation Decoder Loss:  0.4674014
Encoder Loss:  0.01642376  || Decoder Loss:  0.0028325173 Validation Decoder Loss:  0.46785808
Encoder Loss:  0.016087847  || Decoder Loss:  0.0027622124 Validation Decoder Loss:  0.4683385
Encoder Loss:  0.015697422  || Decoder Loss:  0.0026697519 Validation Decoder Loss:  0.4690917
Encoder Loss:  0.015325992  || Decoder Loss:  0.0026127745 Validation Decoder Loss:  0.46886265
Encoder Loss:  0.015045651  || Decoder Loss:  0.0025330572 Validation Decoder Loss:  0.46386996
Encoder Loss:  0.014811565  || Decoder Loss:  0.0024476505 Validation Decoder Loss:  0.45732373
Encoder Loss:  0.0146457115  || Decoder Loss:  0.0024150845 Validation Decoder Loss:  0.45288926
Encoder Loss:  0.014485137  || Decoder Loss:  0.0023844703 Validation Decoder Loss:  0.44972754
Encoder Loss:  0.014339118  || Decoder Loss:  0.0023308094 Validation Decoder Loss:  0.44831717
Encoder Loss:  0.014248565  || Decoder Loss:  0.002320613 Validation Decoder Loss:  0.44521034
Encoder Loss:  0.014156347  || Decoder Loss:  0.0022755144 Validation Decoder Loss:  0.44490677
Encoder Loss:  0.014086966  || Decoder Loss:  0.0022520628 Validation Decoder Loss:  0.44344944
Encoder Loss:  0.01401003  || Decoder Loss:  0.0022048743 Validation Decoder Loss:  0.44222656
Encoder Loss:  0.01397097  || Decoder Loss:  0.0021850732 Validation Decoder Loss:  0.44158632
Encoder Loss:  0.01394773  || Decoder Loss:  0.0021923713 Validation Decoder Loss:  0.44060406
Encoder Loss:  0.013921867  || Decoder Loss:  0.0021842173 Validation Decoder Loss:  0.43972725
Encoder Loss:  0.013885744  || Decoder Loss:  0.0021639585 Validation Decoder Loss:  0.43903702
Encoder Loss:  0.013863325  || Decoder Loss:  0.0021552942 Validation Decoder Loss:  0.43901896
Encoder Loss:  0.013823753  || Decoder Loss:  0.0021188527 Validation Decoder Loss:  0.438721
Encoder Loss:  0.013804189  || Decoder Loss:  0.0021070132 Validation Decoder Loss:  0.4382577
Encoder Loss:  0.013785151  || Decoder Loss:  0.0020876331 Validation Decoder Loss:  0.43780252
Encoder Loss:  0.013761949  || Decoder Loss:  0.0020675666 Validation Decoder Loss:  0.43801624
Encoder Loss:  0.013747506  || Decoder Loss:  0.0020592164 Validation Decoder Loss:  0.43767715
Encoder Loss:  0.0137314135  || Decoder Loss:  0.0020455075 Validation Decoder Loss:  0.437513
Encoder Loss:  0.013714182  || Decoder Loss:  0.0020281642 Validation Decoder Loss:  0.43754983
Encoder Loss:  0.013705057  || Decoder Loss:  0.002025038 Validation Decoder Loss:  0.43686935
Encoder Loss:  0.01369466  || Decoder Loss:  0.002013101 Validation Decoder Loss:  0.43723643
Encoder Loss:  0.013678147  || Decoder Loss:  0.0019999326 Validation Decoder Loss:  0.4370809
Encoder Loss:  0.013670129  || Decoder Loss:  0.0019929807 Validation Decoder Loss:  0.43681794
Encoder Loss:  0.013660387  || Decoder Loss:  0.0019845865 Validation Decoder Loss:  0.4364019
Encoder Loss:  0.01365091  || Decoder Loss:  0.0019773617 Validation Decoder Loss:  0.43631107
Encoder Loss:  0.01364503  || Decoder Loss:  0.0019679153 Validation Decoder Loss:  0.43596607
Encoder Loss:  0.013635373  || Decoder Loss:  0.001961437 Validation Decoder Loss:  0.43569458
Encoder Loss:  0.013628011  || Decoder Loss:  0.001954096 Validation Decoder Loss:  0.4356646
Encoder Loss:  0.013620432  || Decoder Loss:  0.0019499777 Validation Decoder Loss:  0.43590587
Encoder Loss:  0.013611468  || Decoder Loss:  0.0019412173 Validation Decoder Loss:  0.4356576
Model: bold_synthesis_net_lr_0.0007008584156628553 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.43565756
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 140, 13, 16, 1)    386       
_________________________________________________________________
reshape_83 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 386
Trainable params: 386
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.021644684  || Decoder Loss:  0.0051852576 Validation Decoder Loss:  0.44895205
Encoder Loss:  0.019580025  || Decoder Loss:  0.004362949 Validation Decoder Loss:  0.44458255
Encoder Loss:  0.018655526  || Decoder Loss:  0.004255512 Validation Decoder Loss:  0.44028312
Encoder Loss:  0.017993437  || Decoder Loss:  0.004105539 Validation Decoder Loss:  0.445117
Encoder Loss:  0.017485619  || Decoder Loss:  0.0039624376 Validation Decoder Loss:  0.4449793
Encoder Loss:  0.017011276  || Decoder Loss:  0.0038411913 Validation Decoder Loss:  0.438307
Encoder Loss:  0.016518062  || Decoder Loss:  0.003691669 Validation Decoder Loss:  0.43631333
Encoder Loss:  0.01601975  || Decoder Loss:  0.003496472 Validation Decoder Loss:  0.43682352
Encoder Loss:  0.015564258  || Decoder Loss:  0.0033404212 Validation Decoder Loss:  0.43817738
Encoder Loss:  0.015177559  || Decoder Loss:  0.0032207507 Validation Decoder Loss:  0.43783653
Encoder Loss:  0.014922939  || Decoder Loss:  0.0031395527 Validation Decoder Loss:  0.43830726
Encoder Loss:  0.014779392  || Decoder Loss:  0.0030683486 Validation Decoder Loss:  0.4378172
Encoder Loss:  0.014669271  || Decoder Loss:  0.002983833 Validation Decoder Loss:  0.43853915
Encoder Loss:  0.014594478  || Decoder Loss:  0.0029353916 Validation Decoder Loss:  0.43788782
Encoder Loss:  0.014540691  || Decoder Loss:  0.0028996025 Validation Decoder Loss:  0.43742085
Encoder Loss:  0.0144968135  || Decoder Loss:  0.0028670013 Validation Decoder Loss:  0.4372392
Encoder Loss:  0.01445819  || Decoder Loss:  0.002832251 Validation Decoder Loss:  0.43688244
Encoder Loss:  0.014413984  || Decoder Loss:  0.0027977787 Validation Decoder Loss:  0.43622178
Encoder Loss:  0.014382409  || Decoder Loss:  0.0027685962 Validation Decoder Loss:  0.43604267
Encoder Loss:  0.014351969  || Decoder Loss:  0.0027451185 Validation Decoder Loss:  0.43561774
Encoder Loss:  0.014322475  || Decoder Loss:  0.0027149206 Validation Decoder Loss:  0.4350544
Encoder Loss:  0.0142795155  || Decoder Loss:  0.0026717642 Validation Decoder Loss:  0.43509948
Encoder Loss:  0.0142494915  || Decoder Loss:  0.0026444858 Validation Decoder Loss:  0.43482366
Encoder Loss:  0.014230794  || Decoder Loss:  0.002624383 Validation Decoder Loss:  0.4345394
Encoder Loss:  0.014215781  || Decoder Loss:  0.0026128031 Validation Decoder Loss:  0.43486965
Encoder Loss:  0.0142016215  || Decoder Loss:  0.002601259 Validation Decoder Loss:  0.4341452
Encoder Loss:  0.014186327  || Decoder Loss:  0.0025872495 Validation Decoder Loss:  0.43433923
Encoder Loss:  0.01416966  || Decoder Loss:  0.002566646 Validation Decoder Loss:  0.4339128
Encoder Loss:  0.014148504  || Decoder Loss:  0.002545557 Validation Decoder Loss:  0.43317184
Encoder Loss:  0.014134171  || Decoder Loss:  0.0025269443 Validation Decoder Loss:  0.4326421
Encoder Loss:  0.014117192  || Decoder Loss:  0.00250664 Validation Decoder Loss:  0.43220133
Encoder Loss:  0.014099031  || Decoder Loss:  0.0024888157 Validation Decoder Loss:  0.43199188
Encoder Loss:  0.014084496  || Decoder Loss:  0.0024696703 Validation Decoder Loss:  0.4313551
Encoder Loss:  0.01406087  || Decoder Loss:  0.00244316 Validation Decoder Loss:  0.4313479
Encoder Loss:  0.014044153  || Decoder Loss:  0.002420932 Validation Decoder Loss:  0.4313458
Encoder Loss:  0.014030547  || Decoder Loss:  0.0024032951 Validation Decoder Loss:  0.43108574
Encoder Loss:  0.014015601  || Decoder Loss:  0.0023859895 Validation Decoder Loss:  0.4310583
Encoder Loss:  0.014005589  || Decoder Loss:  0.0023714385 Validation Decoder Loss:  0.43064916
Encoder Loss:  0.013988804  || Decoder Loss:  0.0023555956 Validation Decoder Loss:  0.4304423
Encoder Loss:  0.0139810415  || Decoder Loss:  0.002342412 Validation Decoder Loss:  0.4302649
Model: bold_synthesis_net_lr_0.0007062788997875169 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4302649
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 260, 7, 16, 1)     403       
_________________________________________________________________
reshape_84 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 403
Trainable params: 403
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.019322246  || Decoder Loss:  0.0049916594 Validation Decoder Loss:  0.42502946
Encoder Loss:  0.017333945  || Decoder Loss:  0.004398394 Validation Decoder Loss:  0.42415395
Encoder Loss:  0.016448539  || Decoder Loss:  0.004067964 Validation Decoder Loss:  0.42271936
Encoder Loss:  0.015800426  || Decoder Loss:  0.003948761 Validation Decoder Loss:  0.42280564
Encoder Loss:  0.015122197  || Decoder Loss:  0.0038072355 Validation Decoder Loss:  0.4133888
Encoder Loss:  0.014388775  || Decoder Loss:  0.0035917985 Validation Decoder Loss:  0.41590658
Encoder Loss:  0.013818373  || Decoder Loss:  0.0033605604 Validation Decoder Loss:  0.41659802
Encoder Loss:  0.013632166  || Decoder Loss:  0.0033150488 Validation Decoder Loss:  0.4100566
Encoder Loss:  0.013458797  || Decoder Loss:  0.00321419 Validation Decoder Loss:  0.40797096
Encoder Loss:  0.013257093  || Decoder Loss:  0.0030297444 Validation Decoder Loss:  0.40792996
Encoder Loss:  0.013101149  || Decoder Loss:  0.0028795858 Validation Decoder Loss:  0.40863284
Encoder Loss:  0.012991603  || Decoder Loss:  0.0027705636 Validation Decoder Loss:  0.40961504
Encoder Loss:  0.012914052  || Decoder Loss:  0.0026985006 Validation Decoder Loss:  0.40997437
Encoder Loss:  0.012861915  || Decoder Loss:  0.0026511757 Validation Decoder Loss:  0.41110432
Encoder Loss:  0.012793502  || Decoder Loss:  0.002588745 Validation Decoder Loss:  0.4114126
Encoder Loss:  0.012742137  || Decoder Loss:  0.0025308025 Validation Decoder Loss:  0.41161186
Encoder Loss:  0.012695098  || Decoder Loss:  0.0024862732 Validation Decoder Loss:  0.41121453
Encoder Loss:  0.012657725  || Decoder Loss:  0.002446537 Validation Decoder Loss:  0.40990835
Encoder Loss:  0.012611805  || Decoder Loss:  0.0023973742 Validation Decoder Loss:  0.40979707
Encoder Loss:  0.012555774  || Decoder Loss:  0.002330787 Validation Decoder Loss:  0.4095145
Encoder Loss:  0.0125102475  || Decoder Loss:  0.0022776197 Validation Decoder Loss:  0.40930152
Encoder Loss:  0.0124726165  || Decoder Loss:  0.0022328089 Validation Decoder Loss:  0.4096636
Encoder Loss:  0.012427268  || Decoder Loss:  0.002181709 Validation Decoder Loss:  0.41051656
Encoder Loss:  0.012394784  || Decoder Loss:  0.0021450138 Validation Decoder Loss:  0.41041136
Encoder Loss:  0.012357341  || Decoder Loss:  0.002105639 Validation Decoder Loss:  0.41127226
Encoder Loss:  0.012320042  || Decoder Loss:  0.002058845 Validation Decoder Loss:  0.41155785
Encoder Loss:  0.012298512  || Decoder Loss:  0.002030307 Validation Decoder Loss:  0.41259372
Encoder Loss:  0.012274717  || Decoder Loss:  0.0020079813 Validation Decoder Loss:  0.4133148
Encoder Loss:  0.0122579755  || Decoder Loss:  0.0019865464 Validation Decoder Loss:  0.4135964
Encoder Loss:  0.012241613  || Decoder Loss:  0.0019710176 Validation Decoder Loss:  0.41418642
Encoder Loss:  0.012228077  || Decoder Loss:  0.0019562736 Validation Decoder Loss:  0.4148574
Encoder Loss:  0.012210248  || Decoder Loss:  0.0019370622 Validation Decoder Loss:  0.41457814
Encoder Loss:  0.012197321  || Decoder Loss:  0.0019206923 Validation Decoder Loss:  0.4143847
Encoder Loss:  0.012187596  || Decoder Loss:  0.001906138 Validation Decoder Loss:  0.41408026
Encoder Loss:  0.012173122  || Decoder Loss:  0.0018923859 Validation Decoder Loss:  0.41421083
Encoder Loss:  0.012157007  || Decoder Loss:  0.0018736045 Validation Decoder Loss:  0.41396177
Encoder Loss:  0.012142482  || Decoder Loss:  0.0018571753 Validation Decoder Loss:  0.41373122
Encoder Loss:  0.012134935  || Decoder Loss:  0.001846455 Validation Decoder Loss:  0.41326603
Encoder Loss:  0.012124884  || Decoder Loss:  0.0018370264 Validation Decoder Loss:  0.4137329
Encoder Loss:  0.012114749  || Decoder Loss:  0.0018233466 Validation Decoder Loss:  0.4140383
Model: bold_synthesis_net_lr_0.001 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4140383
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_85 (Conv3DT (None, 130, 14, 16, 1)    25        
_________________________________________________________________
reshape_85 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.029054806  || Decoder Loss:  0.0075876545 Validation Decoder Loss:  0.3825897
Encoder Loss:  0.019364487  || Decoder Loss:  0.0052825767 Validation Decoder Loss:  0.4050107
Encoder Loss:  0.018060073  || Decoder Loss:  0.0045193457 Validation Decoder Loss:  0.38826245
Encoder Loss:  0.017151069  || Decoder Loss:  0.0040881946 Validation Decoder Loss:  0.3894097
Encoder Loss:  0.01639063  || Decoder Loss:  0.0037128776 Validation Decoder Loss:  0.38713127
Encoder Loss:  0.015758794  || Decoder Loss:  0.0036811368 Validation Decoder Loss:  0.33136204
Encoder Loss:  0.014671652  || Decoder Loss:  0.0031884683 Validation Decoder Loss:  0.23324305
Encoder Loss:  0.013433469  || Decoder Loss:  0.0020189874 Validation Decoder Loss:  0.2538827
Encoder Loss:  0.012993605  || Decoder Loss:  0.0016688581 Validation Decoder Loss:  0.24937153
Encoder Loss:  0.012808019  || Decoder Loss:  0.0014977739 Validation Decoder Loss:  0.25111476
Encoder Loss:  0.012663079  || Decoder Loss:  0.0013350731 Validation Decoder Loss:  0.23101072
Encoder Loss:  0.012559556  || Decoder Loss:  0.0012150815 Validation Decoder Loss:  0.22538021
Encoder Loss:  0.012493833  || Decoder Loss:  0.0011479415 Validation Decoder Loss:  0.2206387
Encoder Loss:  0.012433574  || Decoder Loss:  0.0010846804 Validation Decoder Loss:  0.21447513
Encoder Loss:  0.012384998  || Decoder Loss:  0.0010306762 Validation Decoder Loss:  0.2033872
Encoder Loss:  0.01234495  || Decoder Loss:  0.0009861675 Validation Decoder Loss:  0.19593948
Encoder Loss:  0.0123087345  || Decoder Loss:  0.00094391254 Validation Decoder Loss:  0.18993852
Encoder Loss:  0.012276699  || Decoder Loss:  0.00090531324 Validation Decoder Loss:  0.18235213
Encoder Loss:  0.012241283  || Decoder Loss:  0.0008620695 Validation Decoder Loss:  0.17415601
Encoder Loss:  0.012205708  || Decoder Loss:  0.0008207735 Validation Decoder Loss:  0.1659483
Encoder Loss:  0.012176511  || Decoder Loss:  0.00078703754 Validation Decoder Loss:  0.15941213
Encoder Loss:  0.012141652  || Decoder Loss:  0.0007460451 Validation Decoder Loss:  0.15095252
Encoder Loss:  0.012114852  || Decoder Loss:  0.0007142961 Validation Decoder Loss:  0.14653875
Encoder Loss:  0.012090126  || Decoder Loss:  0.0006855932 Validation Decoder Loss:  0.14118662
Encoder Loss:  0.012065402  || Decoder Loss:  0.00065373874 Validation Decoder Loss:  0.1330334
Encoder Loss:  0.01204438  || Decoder Loss:  0.00062855566 Validation Decoder Loss:  0.1279284
Encoder Loss:  0.012025307  || Decoder Loss:  0.00060438627 Validation Decoder Loss:  0.12523377
Encoder Loss:  0.012009243  || Decoder Loss:  0.00058378704 Validation Decoder Loss:  0.12091357
Encoder Loss:  0.011995384  || Decoder Loss:  0.00056590745 Validation Decoder Loss:  0.11583533
Encoder Loss:  0.011981036  || Decoder Loss:  0.0005497106 Validation Decoder Loss:  0.109735176
Encoder Loss:  0.011967834  || Decoder Loss:  0.0005329849 Validation Decoder Loss:  0.11105185
Encoder Loss:  0.011957761  || Decoder Loss:  0.00052313734 Validation Decoder Loss:  0.106323674
Encoder Loss:  0.011946259  || Decoder Loss:  0.000507924 Validation Decoder Loss:  0.10021979
Encoder Loss:  0.011937346  || Decoder Loss:  0.000496604 Validation Decoder Loss:  0.09721434
Encoder Loss:  0.011928241  || Decoder Loss:  0.00048444755 Validation Decoder Loss:  0.090692565
Encoder Loss:  0.011917419  || Decoder Loss:  0.00047231963 Validation Decoder Loss:  0.08934274
Encoder Loss:  0.011908767  || Decoder Loss:  0.00046018805 Validation Decoder Loss:  0.08567709
Encoder Loss:  0.011899759  || Decoder Loss:  0.00044887565 Validation Decoder Loss:  0.08327001
Encoder Loss:  0.011890866  || Decoder Loss:  0.00043651188 Validation Decoder Loss:  0.079253
Encoder Loss:  0.011883765  || Decoder Loss:  0.00042624114 Validation Decoder Loss:  0.07617756
Model: bold_synthesis_net_lr_0.0007472204304443894 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.07617757
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 65, 28, 16, 1)     17        
_________________________________________________________________
reshape_86 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037788805  || Decoder Loss:  0.0074411756 Validation Decoder Loss:  0.35508704
Encoder Loss:  0.029167598  || Decoder Loss:  0.0069702575 Validation Decoder Loss:  0.34733024
Encoder Loss:  0.023071501  || Decoder Loss:  0.005509766 Validation Decoder Loss:  0.39343283
Encoder Loss:  0.021189978  || Decoder Loss:  0.0042270515 Validation Decoder Loss:  0.38884187
Encoder Loss:  0.020483883  || Decoder Loss:  0.00391792 Validation Decoder Loss:  0.37335238
Encoder Loss:  0.020067032  || Decoder Loss:  0.00385989 Validation Decoder Loss:  0.35730302
Encoder Loss:  0.019414883  || Decoder Loss:  0.0035223456 Validation Decoder Loss:  0.33709475
Encoder Loss:  0.018786214  || Decoder Loss:  0.003304646 Validation Decoder Loss:  0.3083715
Encoder Loss:  0.018163223  || Decoder Loss:  0.0031012713 Validation Decoder Loss:  0.28447676
Encoder Loss:  0.017626805  || Decoder Loss:  0.0029707714 Validation Decoder Loss:  0.2662164
Encoder Loss:  0.017327474  || Decoder Loss:  0.002911797 Validation Decoder Loss:  0.26251245
Encoder Loss:  0.017033933  || Decoder Loss:  0.0028069322 Validation Decoder Loss:  0.25979257
Encoder Loss:  0.016781773  || Decoder Loss:  0.0027260836 Validation Decoder Loss:  0.25446317
Encoder Loss:  0.01658333  || Decoder Loss:  0.002628833 Validation Decoder Loss:  0.24583212
Encoder Loss:  0.016413195  || Decoder Loss:  0.0024980672 Validation Decoder Loss:  0.23059714
Encoder Loss:  0.016263705  || Decoder Loss:  0.0023607865 Validation Decoder Loss:  0.21761063
Encoder Loss:  0.01611108  || Decoder Loss:  0.0021902155 Validation Decoder Loss:  0.2057175
Encoder Loss:  0.015979504  || Decoder Loss:  0.0020331591 Validation Decoder Loss:  0.2015521
Encoder Loss:  0.015894279  || Decoder Loss:  0.0019311474 Validation Decoder Loss:  0.1937451
Encoder Loss:  0.015813202  || Decoder Loss:  0.0018351563 Validation Decoder Loss:  0.18548541
Encoder Loss:  0.015726581  || Decoder Loss:  0.0017269383 Validation Decoder Loss:  0.17790884
Encoder Loss:  0.015637338  || Decoder Loss:  0.0016084246 Validation Decoder Loss:  0.16987637
Encoder Loss:  0.015569952  || Decoder Loss:  0.001520905 Validation Decoder Loss:  0.16250478
Encoder Loss:  0.015501409  || Decoder Loss:  0.0014357948 Validation Decoder Loss:  0.15334053
Encoder Loss:  0.015426518  || Decoder Loss:  0.0013375666 Validation Decoder Loss:  0.14377281
Encoder Loss:  0.01536257  || Decoder Loss:  0.0012492004 Validation Decoder Loss:  0.12438153
Encoder Loss:  0.0152952615  || Decoder Loss:  0.0011539996 Validation Decoder Loss:  0.11509471
Encoder Loss:  0.015217696  || Decoder Loss:  0.001044231 Validation Decoder Loss:  0.106598645
Encoder Loss:  0.015156282  || Decoder Loss:  0.0009545847 Validation Decoder Loss:  0.09862057
Encoder Loss:  0.015100108  || Decoder Loss:  0.00087863137 Validation Decoder Loss:  0.09319913
Encoder Loss:  0.015055273  || Decoder Loss:  0.00081712316 Validation Decoder Loss:  0.088697314
Encoder Loss:  0.015020235  || Decoder Loss:  0.0007671327 Validation Decoder Loss:  0.08167113
Encoder Loss:  0.014987223  || Decoder Loss:  0.00072395673 Validation Decoder Loss:  0.07557281
Encoder Loss:  0.014956519  || Decoder Loss:  0.000681483 Validation Decoder Loss:  0.07080926
Encoder Loss:  0.014929668  || Decoder Loss:  0.00064463203 Validation Decoder Loss:  0.06666295
Encoder Loss:  0.014901632  || Decoder Loss:  0.0006080558 Validation Decoder Loss:  0.062214464
Encoder Loss:  0.014884245  || Decoder Loss:  0.0005884048 Validation Decoder Loss:  0.05918692
Encoder Loss:  0.014866982  || Decoder Loss:  0.0005628307 Validation Decoder Loss:  0.05565868
Encoder Loss:  0.014849331  || Decoder Loss:  0.00054341805 Validation Decoder Loss:  0.052321315
Encoder Loss:  0.014834305  || Decoder Loss:  0.0005234513 Validation Decoder Loss:  0.048645142
Model: bold_synthesis_net_lr_0.0005453059566937522 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.048645146
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 130, 14, 16, 1)    41        
_________________________________________________________________
reshape_87 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04062018  || Decoder Loss:  0.007403801 Validation Decoder Loss:  0.37085938
Encoder Loss:  0.026295723  || Decoder Loss:  0.0053526694 Validation Decoder Loss:  0.38880557
Encoder Loss:  0.024905551  || Decoder Loss:  0.0047170497 Validation Decoder Loss:  0.3881086
Encoder Loss:  0.02405445  || Decoder Loss:  0.004445074 Validation Decoder Loss:  0.3873512
Encoder Loss:  0.023289049  || Decoder Loss:  0.0042192033 Validation Decoder Loss:  0.3866788
Encoder Loss:  0.022447338  || Decoder Loss:  0.004020104 Validation Decoder Loss:  0.38513464
Encoder Loss:  0.021555774  || Decoder Loss:  0.003979926 Validation Decoder Loss:  0.3779511
Encoder Loss:  0.02053562  || Decoder Loss:  0.004013428 Validation Decoder Loss:  0.3550449
Encoder Loss:  0.01939681  || Decoder Loss:  0.0036668752 Validation Decoder Loss:  0.32751828
Encoder Loss:  0.018340666  || Decoder Loss:  0.0030363495 Validation Decoder Loss:  0.2797253
Encoder Loss:  0.017582102  || Decoder Loss:  0.0024062872 Validation Decoder Loss:  0.23305929
Encoder Loss:  0.017117403  || Decoder Loss:  0.0019347476 Validation Decoder Loss:  0.19684276
Encoder Loss:  0.016879426  || Decoder Loss:  0.0017501804 Validation Decoder Loss:  0.18188715
Encoder Loss:  0.01669487  || Decoder Loss:  0.0015427676 Validation Decoder Loss:  0.1602403
Encoder Loss:  0.016546506  || Decoder Loss:  0.001357973 Validation Decoder Loss:  0.15555087
Encoder Loss:  0.016444325  || Decoder Loss:  0.0012282174 Validation Decoder Loss:  0.14997846
Encoder Loss:  0.016378477  || Decoder Loss:  0.0011497025 Validation Decoder Loss:  0.14455527
Encoder Loss:  0.016322132  || Decoder Loss:  0.0010817406 Validation Decoder Loss:  0.13929391
Encoder Loss:  0.016267465  || Decoder Loss:  0.0010142912 Validation Decoder Loss:  0.13498469
Encoder Loss:  0.01621656  || Decoder Loss:  0.0009506346 Validation Decoder Loss:  0.13150579
Encoder Loss:  0.01618014  || Decoder Loss:  0.0009123124 Validation Decoder Loss:  0.1292243
Encoder Loss:  0.016147016  || Decoder Loss:  0.0008778015 Validation Decoder Loss:  0.12448129
Encoder Loss:  0.01611306  || Decoder Loss:  0.00084043713 Validation Decoder Loss:  0.1235257
Encoder Loss:  0.016087933  || Decoder Loss:  0.0008126706 Validation Decoder Loss:  0.11885263
Encoder Loss:  0.016064225  || Decoder Loss:  0.0007860325 Validation Decoder Loss:  0.11654656
Encoder Loss:  0.016044483  || Decoder Loss:  0.0007643535 Validation Decoder Loss:  0.112355724
Encoder Loss:  0.016024714  || Decoder Loss:  0.0007457276 Validation Decoder Loss:  0.11076464
Encoder Loss:  0.016006604  || Decoder Loss:  0.00072445936 Validation Decoder Loss:  0.10624032
Encoder Loss:  0.015989998  || Decoder Loss:  0.00070721476 Validation Decoder Loss:  0.10471916
Encoder Loss:  0.015974186  || Decoder Loss:  0.00069210946 Validation Decoder Loss:  0.10399303
Encoder Loss:  0.01595833  || Decoder Loss:  0.000672234 Validation Decoder Loss:  0.100076884
Encoder Loss:  0.015949802  || Decoder Loss:  0.0006676718 Validation Decoder Loss:  0.09701259
Encoder Loss:  0.015932055  || Decoder Loss:  0.00064791314 Validation Decoder Loss:  0.097172216
Encoder Loss:  0.015921967  || Decoder Loss:  0.0006367953 Validation Decoder Loss:  0.0991172
Encoder Loss:  0.015911324  || Decoder Loss:  0.00062647345 Validation Decoder Loss:  0.095504045
Encoder Loss:  0.015899934  || Decoder Loss:  0.0006131834 Validation Decoder Loss:  0.095755205
Encoder Loss:  0.015890041  || Decoder Loss:  0.00060254394 Validation Decoder Loss:  0.09560716
Encoder Loss:  0.015880523  || Decoder Loss:  0.00059174444 Validation Decoder Loss:  0.093524784
Encoder Loss:  0.015870368  || Decoder Loss:  0.0005803333 Validation Decoder Loss:  0.09328737
Encoder Loss:  0.015864432  || Decoder Loss:  0.0005765949 Validation Decoder Loss:  0.09522022
Model: bold_synthesis_net_lr_0.00044487642811434484 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.09522022
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_88 (Conv3DT (None, 182, 10, 16, 1)    337       
_________________________________________________________________
reshape_88 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.030568693  || Decoder Loss:  0.0068047964 Validation Decoder Loss:  0.38296527
Encoder Loss:  0.027947009  || Decoder Loss:  0.005461725 Validation Decoder Loss:  0.38599765
Encoder Loss:  0.027028529  || Decoder Loss:  0.005020218 Validation Decoder Loss:  0.38725448
Encoder Loss:  0.026398866  || Decoder Loss:  0.0047496054 Validation Decoder Loss:  0.3873241
Encoder Loss:  0.025922155  || Decoder Loss:  0.004612915 Validation Decoder Loss:  0.3870807
Encoder Loss:  0.025416248  || Decoder Loss:  0.004445013 Validation Decoder Loss:  0.38839722
Encoder Loss:  0.02490356  || Decoder Loss:  0.004335964 Validation Decoder Loss:  0.38997295
Encoder Loss:  0.024302188  || Decoder Loss:  0.0041862866 Validation Decoder Loss:  0.3924634
Encoder Loss:  0.02367549  || Decoder Loss:  0.0040787472 Validation Decoder Loss:  0.39702728
Encoder Loss:  0.023026036  || Decoder Loss:  0.0039844373 Validation Decoder Loss:  0.39916667
Encoder Loss:  0.022474859  || Decoder Loss:  0.0039355704 Validation Decoder Loss:  0.39873773
Encoder Loss:  0.02189419  || Decoder Loss:  0.0038958823 Validation Decoder Loss:  0.39905906
Encoder Loss:  0.021320365  || Decoder Loss:  0.0037229378 Validation Decoder Loss:  0.3990421
Encoder Loss:  0.02090314  || Decoder Loss:  0.003635061 Validation Decoder Loss:  0.39961296
Encoder Loss:  0.020552842  || Decoder Loss:  0.0035801036 Validation Decoder Loss:  0.39998785
Encoder Loss:  0.020248702  || Decoder Loss:  0.0035426628 Validation Decoder Loss:  0.4002484
Encoder Loss:  0.01995979  || Decoder Loss:  0.003501848 Validation Decoder Loss:  0.40068874
Encoder Loss:  0.019733008  || Decoder Loss:  0.0034989489 Validation Decoder Loss:  0.40145954
Encoder Loss:  0.019578278  || Decoder Loss:  0.0034960671 Validation Decoder Loss:  0.40202525
Encoder Loss:  0.019460548  || Decoder Loss:  0.0034937644 Validation Decoder Loss:  0.40253577
Encoder Loss:  0.01932833  || Decoder Loss:  0.0034377547 Validation Decoder Loss:  0.4030127
Encoder Loss:  0.019183401  || Decoder Loss:  0.0033811973 Validation Decoder Loss:  0.40361264
Encoder Loss:  0.01905231  || Decoder Loss:  0.0033196814 Validation Decoder Loss:  0.40420172
Encoder Loss:  0.018955387  || Decoder Loss:  0.0032845407 Validation Decoder Loss:  0.40461516
Encoder Loss:  0.01886189  || Decoder Loss:  0.0032483127 Validation Decoder Loss:  0.40435258
Encoder Loss:  0.01877285  || Decoder Loss:  0.0032136976 Validation Decoder Loss:  0.40490732
Encoder Loss:  0.018703798  || Decoder Loss:  0.003200731 Validation Decoder Loss:  0.4051004
Encoder Loss:  0.018636858  || Decoder Loss:  0.003183089 Validation Decoder Loss:  0.40533793
Encoder Loss:  0.01857055  || Decoder Loss:  0.0031538652 Validation Decoder Loss:  0.40567526
Encoder Loss:  0.018493293  || Decoder Loss:  0.003105422 Validation Decoder Loss:  0.4057064
Encoder Loss:  0.018415231  || Decoder Loss:  0.0030544605 Validation Decoder Loss:  0.40590668
Encoder Loss:  0.01835079  || Decoder Loss:  0.0030014475 Validation Decoder Loss:  0.4055086
Encoder Loss:  0.018294327  || Decoder Loss:  0.002955259 Validation Decoder Loss:  0.40529034
Encoder Loss:  0.018246328  || Decoder Loss:  0.0029206746 Validation Decoder Loss:  0.40549874
Encoder Loss:  0.018197957  || Decoder Loss:  0.0028763695 Validation Decoder Loss:  0.40555325
Encoder Loss:  0.018152667  || Decoder Loss:  0.0028341264 Validation Decoder Loss:  0.40560728
Encoder Loss:  0.018100735  || Decoder Loss:  0.0027799793 Validation Decoder Loss:  0.40548784
Encoder Loss:  0.01806239  || Decoder Loss:  0.0027494757 Validation Decoder Loss:  0.40534705
Encoder Loss:  0.018028501  || Decoder Loss:  0.0027218855 Validation Decoder Loss:  0.4053947
Encoder Loss:  0.017988978  || Decoder Loss:  0.0026832859 Validation Decoder Loss:  0.40503567
Model: bold_synthesis_net_lr_0.0003979955229629674 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.40503567
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 70, 26, 16, 1)     43        
_________________________________________________________________
reshape_89 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 43
Trainable params: 43
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.027700627  || Decoder Loss:  0.0071577327 Validation Decoder Loss:  0.37593424
Encoder Loss:  0.024455898  || Decoder Loss:  0.005609494 Validation Decoder Loss:  0.39954463
Encoder Loss:  0.022769773  || Decoder Loss:  0.0054939 Validation Decoder Loss:  0.41337368
Encoder Loss:  0.021743532  || Decoder Loss:  0.0049567753 Validation Decoder Loss:  0.4153065
Encoder Loss:  0.02068554  || Decoder Loss:  0.0042759357 Validation Decoder Loss:  0.40830275
Encoder Loss:  0.019753577  || Decoder Loss:  0.0037815415 Validation Decoder Loss:  0.3955413
Encoder Loss:  0.018893495  || Decoder Loss:  0.0036085064 Validation Decoder Loss:  0.38461798
Encoder Loss:  0.018065711  || Decoder Loss:  0.003467407 Validation Decoder Loss:  0.37329042
Encoder Loss:  0.017437737  || Decoder Loss:  0.0032266434 Validation Decoder Loss:  0.35816768
Encoder Loss:  0.017012762  || Decoder Loss:  0.0031944495 Validation Decoder Loss:  0.35140818
Encoder Loss:  0.01671428  || Decoder Loss:  0.0031386858 Validation Decoder Loss:  0.34467888
Encoder Loss:  0.016426625  || Decoder Loss:  0.00297108 Validation Decoder Loss:  0.33673203
Encoder Loss:  0.016131157  || Decoder Loss:  0.0027497844 Validation Decoder Loss:  0.32691044
Encoder Loss:  0.01594427  || Decoder Loss:  0.0026581686 Validation Decoder Loss:  0.31335065
Encoder Loss:  0.015691485  || Decoder Loss:  0.0024300031 Validation Decoder Loss:  0.30886886
Encoder Loss:  0.015494351  || Decoder Loss:  0.0022639858 Validation Decoder Loss:  0.30972847
Encoder Loss:  0.015317069  || Decoder Loss:  0.0020912169 Validation Decoder Loss:  0.30735856
Encoder Loss:  0.01515503  || Decoder Loss:  0.0019604147 Validation Decoder Loss:  0.30899936
Encoder Loss:  0.015041533  || Decoder Loss:  0.0018735217 Validation Decoder Loss:  0.31130186
Encoder Loss:  0.01492822  || Decoder Loss:  0.0017685969 Validation Decoder Loss:  0.311755
Encoder Loss:  0.014839617  || Decoder Loss:  0.0016971744 Validation Decoder Loss:  0.3104455
Encoder Loss:  0.01476808  || Decoder Loss:  0.0016377455 Validation Decoder Loss:  0.31079775
Encoder Loss:  0.014712652  || Decoder Loss:  0.0015940772 Validation Decoder Loss:  0.31053993
Encoder Loss:  0.014666681  || Decoder Loss:  0.0015571802 Validation Decoder Loss:  0.31002754
Encoder Loss:  0.014629485  || Decoder Loss:  0.0015241377 Validation Decoder Loss:  0.31066552
Encoder Loss:  0.014597941  || Decoder Loss:  0.0014976043 Validation Decoder Loss:  0.31044924
Encoder Loss:  0.014570014  || Decoder Loss:  0.0014749207 Validation Decoder Loss:  0.3093843
Encoder Loss:  0.014546121  || Decoder Loss:  0.0014549023 Validation Decoder Loss:  0.309635
Encoder Loss:  0.014520034  || Decoder Loss:  0.0014357633 Validation Decoder Loss:  0.30616498
Encoder Loss:  0.014490853  || Decoder Loss:  0.0014120182 Validation Decoder Loss:  0.30462652
Encoder Loss:  0.014465565  || Decoder Loss:  0.0013901527 Validation Decoder Loss:  0.3028471
Encoder Loss:  0.014435726  || Decoder Loss:  0.0013619103 Validation Decoder Loss:  0.29996365
Encoder Loss:  0.0144050075  || Decoder Loss:  0.0013316419 Validation Decoder Loss:  0.2967248
Encoder Loss:  0.014380912  || Decoder Loss:  0.001305725 Validation Decoder Loss:  0.2968729
Encoder Loss:  0.014361991  || Decoder Loss:  0.0012867068 Validation Decoder Loss:  0.2936895
Encoder Loss:  0.014342656  || Decoder Loss:  0.001264739 Validation Decoder Loss:  0.29570764
Encoder Loss:  0.014328834  || Decoder Loss:  0.0012508178 Validation Decoder Loss:  0.29394802
Encoder Loss:  0.014316165  || Decoder Loss:  0.0012380248 Validation Decoder Loss:  0.29147786
Encoder Loss:  0.014301924  || Decoder Loss:  0.0012214251 Validation Decoder Loss:  0.29236954
Encoder Loss:  0.014290703  || Decoder Loss:  0.0012071307 Validation Decoder Loss:  0.29100174
Model: bold_synthesis_net_lr_0.0006110251820650581 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.29100174
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 364, 5, 16, 1)     50        
_________________________________________________________________
reshape_90 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.025249427  || Decoder Loss:  0.006173071 Validation Decoder Loss:  0.39010686
Encoder Loss:  0.02287658  || Decoder Loss:  0.005089663 Validation Decoder Loss:  0.39404956
Encoder Loss:  0.022048218  || Decoder Loss:  0.005053796 Validation Decoder Loss:  0.3963294
Encoder Loss:  0.021424858  || Decoder Loss:  0.004979628 Validation Decoder Loss:  0.39629453
Encoder Loss:  0.020665932  || Decoder Loss:  0.0047999336 Validation Decoder Loss:  0.39394134
Encoder Loss:  0.019993505  || Decoder Loss:  0.0046065985 Validation Decoder Loss:  0.3896224
Encoder Loss:  0.019248566  || Decoder Loss:  0.0043781986 Validation Decoder Loss:  0.37890154
Encoder Loss:  0.018538948  || Decoder Loss:  0.004103846 Validation Decoder Loss:  0.36966783
Encoder Loss:  0.017910304  || Decoder Loss:  0.0039231186 Validation Decoder Loss:  0.36344323
Encoder Loss:  0.01730426  || Decoder Loss:  0.0036479754 Validation Decoder Loss:  0.34870815
Encoder Loss:  0.016673852  || Decoder Loss:  0.0032785637 Validation Decoder Loss:  0.3040744
Encoder Loss:  0.016234381  || Decoder Loss:  0.0031361715 Validation Decoder Loss:  0.24693067
Encoder Loss:  0.015827559  || Decoder Loss:  0.0029682347 Validation Decoder Loss:  0.20603704
Encoder Loss:  0.015262203  || Decoder Loss:  0.0024408642 Validation Decoder Loss:  0.1950225
Encoder Loss:  0.014966186  || Decoder Loss:  0.0021723022 Validation Decoder Loss:  0.1843565
Encoder Loss:  0.014742056  || Decoder Loss:  0.0019475255 Validation Decoder Loss:  0.17662704
Encoder Loss:  0.014577795  || Decoder Loss:  0.0017848067 Validation Decoder Loss:  0.17208281
Encoder Loss:  0.014461295  || Decoder Loss:  0.0016790879 Validation Decoder Loss:  0.16244355
Encoder Loss:  0.014376258  || Decoder Loss:  0.0015948983 Validation Decoder Loss:  0.1571982
Encoder Loss:  0.014286746  || Decoder Loss:  0.0014850532 Validation Decoder Loss:  0.15565333
Encoder Loss:  0.014220647  || Decoder Loss:  0.0014098558 Validation Decoder Loss:  0.15710454
Encoder Loss:  0.0141732525  || Decoder Loss:  0.0013516021 Validation Decoder Loss:  0.15983576
Encoder Loss:  0.014126906  || Decoder Loss:  0.0013016403 Validation Decoder Loss:  0.16069964
Encoder Loss:  0.014099305  || Decoder Loss:  0.0012710392 Validation Decoder Loss:  0.16023442
Encoder Loss:  0.014068203  || Decoder Loss:  0.0012293702 Validation Decoder Loss:  0.16089374
Encoder Loss:  0.014038532  || Decoder Loss:  0.0011997608 Validation Decoder Loss:  0.16077903
Encoder Loss:  0.014014405  || Decoder Loss:  0.0011686423 Validation Decoder Loss:  0.16194892
Encoder Loss:  0.013999665  || Decoder Loss:  0.0011544989 Validation Decoder Loss:  0.1605968
Encoder Loss:  0.013976196  || Decoder Loss:  0.0011305436 Validation Decoder Loss:  0.15919617
Encoder Loss:  0.01396152  || Decoder Loss:  0.0011129738 Validation Decoder Loss:  0.16133213
Encoder Loss:  0.01394236  || Decoder Loss:  0.001090473 Validation Decoder Loss:  0.16019453
Encoder Loss:  0.01392926  || Decoder Loss:  0.0010728859 Validation Decoder Loss:  0.15950876
Encoder Loss:  0.013914289  || Decoder Loss:  0.0010571913 Validation Decoder Loss:  0.1597025
Encoder Loss:  0.0139038125  || Decoder Loss:  0.0010431693 Validation Decoder Loss:  0.16268474
Encoder Loss:  0.013890781  || Decoder Loss:  0.0010270978 Validation Decoder Loss:  0.15922724
Encoder Loss:  0.013877099  || Decoder Loss:  0.001011199 Validation Decoder Loss:  0.16048837
Encoder Loss:  0.013862128  || Decoder Loss:  0.0009915591 Validation Decoder Loss:  0.1583412
Encoder Loss:  0.0138522955  || Decoder Loss:  0.0009763227 Validation Decoder Loss:  0.16014743
Encoder Loss:  0.013832281  || Decoder Loss:  0.00095165055 Validation Decoder Loss:  0.16076544
Encoder Loss:  0.013819629  || Decoder Loss:  0.0009341948 Validation Decoder Loss:  0.15875266
Model: bold_synthesis_net_lr_0.0006181561724405465 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.15875265
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_91 (Conv3DT (None, 91, 20, 16, 1)     113       
_________________________________________________________________
reshape_91 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 113
Trainable params: 113
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.026757477  || Decoder Loss:  0.006299349 Validation Decoder Loss:  0.4349488
Encoder Loss:  0.024238948  || Decoder Loss:  0.0055861995 Validation Decoder Loss:  0.43991864
Encoder Loss:  0.023013275  || Decoder Loss:  0.004823316 Validation Decoder Loss:  0.44298953
Encoder Loss:  0.02222491  || Decoder Loss:  0.004365853 Validation Decoder Loss:  0.44492528
Encoder Loss:  0.021504126  || Decoder Loss:  0.0039252862 Validation Decoder Loss:  0.44360885
Encoder Loss:  0.020872407  || Decoder Loss:  0.00366302 Validation Decoder Loss:  0.44229513
Encoder Loss:  0.020357843  || Decoder Loss:  0.0035848645 Validation Decoder Loss:  0.44407624
Encoder Loss:  0.019846873  || Decoder Loss:  0.0035045345 Validation Decoder Loss:  0.44336635
Encoder Loss:  0.019356651  || Decoder Loss:  0.0035489015 Validation Decoder Loss:  0.44185075
Encoder Loss:  0.018831968  || Decoder Loss:  0.0034594473 Validation Decoder Loss:  0.4426123
Encoder Loss:  0.018407173  || Decoder Loss:  0.0033764977 Validation Decoder Loss:  0.44225755
Encoder Loss:  0.018077465  || Decoder Loss:  0.0033636943 Validation Decoder Loss:  0.44065124
Encoder Loss:  0.017787227  || Decoder Loss:  0.0032975907 Validation Decoder Loss:  0.4387983
Encoder Loss:  0.01751653  || Decoder Loss:  0.003208647 Validation Decoder Loss:  0.43862128
Encoder Loss:  0.017312072  || Decoder Loss:  0.0031543204 Validation Decoder Loss:  0.4386042
Encoder Loss:  0.017141167  || Decoder Loss:  0.0030760334 Validation Decoder Loss:  0.43956488
Encoder Loss:  0.016991904  || Decoder Loss:  0.002979992 Validation Decoder Loss:  0.4404654
Encoder Loss:  0.01687371  || Decoder Loss:  0.002899775 Validation Decoder Loss:  0.43982935
Encoder Loss:  0.016764857  || Decoder Loss:  0.0028248483 Validation Decoder Loss:  0.43963805
Encoder Loss:  0.016669188  || Decoder Loss:  0.002752375 Validation Decoder Loss:  0.439268
Encoder Loss:  0.016578928  || Decoder Loss:  0.0026711542 Validation Decoder Loss:  0.43865597
Encoder Loss:  0.016508203  || Decoder Loss:  0.0026108234 Validation Decoder Loss:  0.43802357
Encoder Loss:  0.01644704  || Decoder Loss:  0.0025574584 Validation Decoder Loss:  0.43776196
Encoder Loss:  0.016390882  || Decoder Loss:  0.0025187165 Validation Decoder Loss:  0.4363151
Encoder Loss:  0.016342219  || Decoder Loss:  0.0024867642 Validation Decoder Loss:  0.43471348
Encoder Loss:  0.016291652  || Decoder Loss:  0.0024487406 Validation Decoder Loss:  0.43263447
Encoder Loss:  0.01624644  || Decoder Loss:  0.00241713 Validation Decoder Loss:  0.431739
Encoder Loss:  0.016207783  || Decoder Loss:  0.0023855234 Validation Decoder Loss:  0.43087366
Encoder Loss:  0.01617628  || Decoder Loss:  0.0023619472 Validation Decoder Loss:  0.43061194
Encoder Loss:  0.016139733  || Decoder Loss:  0.0023323302 Validation Decoder Loss:  0.42890218
Encoder Loss:  0.016101781  || Decoder Loss:  0.0022914845 Validation Decoder Loss:  0.42694724
Encoder Loss:  0.016058803  || Decoder Loss:  0.0022411337 Validation Decoder Loss:  0.42515677
Encoder Loss:  0.016015628  || Decoder Loss:  0.0021911946 Validation Decoder Loss:  0.422638
Encoder Loss:  0.015971905  || Decoder Loss:  0.0021362267 Validation Decoder Loss:  0.42008933
Encoder Loss:  0.015929952  || Decoder Loss:  0.002091939 Validation Decoder Loss:  0.41793162
Encoder Loss:  0.015899774  || Decoder Loss:  0.0020558105 Validation Decoder Loss:  0.41581374
Encoder Loss:  0.015862022  || Decoder Loss:  0.0020113427 Validation Decoder Loss:  0.41440654
Encoder Loss:  0.01582665  || Decoder Loss:  0.0019706178 Validation Decoder Loss:  0.41219145
Encoder Loss:  0.015789015  || Decoder Loss:  0.0019284042 Validation Decoder Loss:  0.41087103
Encoder Loss:  0.015759714  || Decoder Loss:  0.0018963186 Validation Decoder Loss:  0.4088313
Model: bold_synthesis_net_lr_0.0005374461605644238 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4088313
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 91, 20, 16, 1)     337       
_________________________________________________________________
reshape_92 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.020712214  || Decoder Loss:  0.005987448 Validation Decoder Loss:  0.3889023
Encoder Loss:  0.018503848  || Decoder Loss:  0.004721096 Validation Decoder Loss:  0.39500424
Encoder Loss:  0.017461244  || Decoder Loss:  0.0043355366 Validation Decoder Loss:  0.39742047
Encoder Loss:  0.016361764  || Decoder Loss:  0.0040753107 Validation Decoder Loss:  0.40008697
Encoder Loss:  0.015121945  || Decoder Loss:  0.0037079616 Validation Decoder Loss:  0.40062666
Encoder Loss:  0.014052637  || Decoder Loss:  0.0034532268 Validation Decoder Loss:  0.3975375
Encoder Loss:  0.013383381  || Decoder Loss:  0.0031820394 Validation Decoder Loss:  0.39817968
Encoder Loss:  0.013091495  || Decoder Loss:  0.003078867 Validation Decoder Loss:  0.39793104
Encoder Loss:  0.0129036745  || Decoder Loss:  0.002999405 Validation Decoder Loss:  0.39131653
Encoder Loss:  0.012709475  || Decoder Loss:  0.0028531486 Validation Decoder Loss:  0.39158875
Encoder Loss:  0.012591017  || Decoder Loss:  0.002786348 Validation Decoder Loss:  0.39023244
Encoder Loss:  0.012493471  || Decoder Loss:  0.00271463 Validation Decoder Loss:  0.38833898
Encoder Loss:  0.012415937  || Decoder Loss:  0.0026512658 Validation Decoder Loss:  0.38799736
Encoder Loss:  0.0123535115  || Decoder Loss:  0.0025919694 Validation Decoder Loss:  0.3868237
Encoder Loss:  0.0123034455  || Decoder Loss:  0.0025480345 Validation Decoder Loss:  0.3861816
Encoder Loss:  0.012257048  || Decoder Loss:  0.0025086028 Validation Decoder Loss:  0.38481224
Encoder Loss:  0.012220597  || Decoder Loss:  0.0024695352 Validation Decoder Loss:  0.38276097
Encoder Loss:  0.012180839  || Decoder Loss:  0.0024248466 Validation Decoder Loss:  0.38125524
Encoder Loss:  0.012143609  || Decoder Loss:  0.002394032 Validation Decoder Loss:  0.3795451
Encoder Loss:  0.012108189  || Decoder Loss:  0.0023647675 Validation Decoder Loss:  0.3789143
Encoder Loss:  0.012081656  || Decoder Loss:  0.002337809 Validation Decoder Loss:  0.37934136
Encoder Loss:  0.012054253  || Decoder Loss:  0.0023099969 Validation Decoder Loss:  0.37951323
Encoder Loss:  0.012019996  || Decoder Loss:  0.0022763656 Validation Decoder Loss:  0.37913084
Encoder Loss:  0.012002386  || Decoder Loss:  0.0022559657 Validation Decoder Loss:  0.3789543
Encoder Loss:  0.011971925  || Decoder Loss:  0.002230652 Validation Decoder Loss:  0.3787471
Encoder Loss:  0.01195257  || Decoder Loss:  0.0022145766 Validation Decoder Loss:  0.37800288
Encoder Loss:  0.011936202  || Decoder Loss:  0.0021951431 Validation Decoder Loss:  0.3775142
Encoder Loss:  0.011920088  || Decoder Loss:  0.0021751367 Validation Decoder Loss:  0.37659228
Encoder Loss:  0.011895486  || Decoder Loss:  0.0021481013 Validation Decoder Loss:  0.37621173
Encoder Loss:  0.011877235  || Decoder Loss:  0.0021271138 Validation Decoder Loss:  0.37490064
Encoder Loss:  0.011855766  || Decoder Loss:  0.0021089541 Validation Decoder Loss:  0.37408948
Encoder Loss:  0.0118358545  || Decoder Loss:  0.002084486 Validation Decoder Loss:  0.37404448
Encoder Loss:  0.011822091  || Decoder Loss:  0.0020645524 Validation Decoder Loss:  0.37380314
Encoder Loss:  0.011807896  || Decoder Loss:  0.00205005 Validation Decoder Loss:  0.37355387
Encoder Loss:  0.011786383  || Decoder Loss:  0.0020323691 Validation Decoder Loss:  0.3732111
Encoder Loss:  0.011775603  || Decoder Loss:  0.0020177593 Validation Decoder Loss:  0.3724563
Encoder Loss:  0.011758015  || Decoder Loss:  0.0019993791 Validation Decoder Loss:  0.37278837
Encoder Loss:  0.011744467  || Decoder Loss:  0.001985743 Validation Decoder Loss:  0.3727929
Encoder Loss:  0.011736762  || Decoder Loss:  0.0019731715 Validation Decoder Loss:  0.37228924
Encoder Loss:  0.011726536  || Decoder Loss:  0.001962276 Validation Decoder Loss:  0.3724525
Model: bold_synthesis_net_lr_0.0009520772368486601 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3724525
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 91, 20, 16, 1)     337       
_________________________________________________________________
reshape_93 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02534776  || Decoder Loss:  0.0065010893 Validation Decoder Loss:  0.3852057
Encoder Loss:  0.0228642  || Decoder Loss:  0.005033456 Validation Decoder Loss:  0.38697183
Encoder Loss:  0.022012627  || Decoder Loss:  0.004690232 Validation Decoder Loss:  0.38842115
Encoder Loss:  0.021182818  || Decoder Loss:  0.004359499 Validation Decoder Loss:  0.39209825
Encoder Loss:  0.02026411  || Decoder Loss:  0.004112744 Validation Decoder Loss:  0.39366397
Encoder Loss:  0.01934588  || Decoder Loss:  0.003904907 Validation Decoder Loss:  0.39748895
Encoder Loss:  0.018435407  || Decoder Loss:  0.0036406612 Validation Decoder Loss:  0.3982908
Encoder Loss:  0.017827915  || Decoder Loss:  0.0035155641 Validation Decoder Loss:  0.3981256
Encoder Loss:  0.017285805  || Decoder Loss:  0.0034513455 Validation Decoder Loss:  0.3986338
Encoder Loss:  0.016731754  || Decoder Loss:  0.003342864 Validation Decoder Loss:  0.40171683
Encoder Loss:  0.016219977  || Decoder Loss:  0.0031583952 Validation Decoder Loss:  0.4049222
Encoder Loss:  0.015902193  || Decoder Loss:  0.0030034473 Validation Decoder Loss:  0.4066553
Encoder Loss:  0.015705582  || Decoder Loss:  0.0029375954 Validation Decoder Loss:  0.40946501
Encoder Loss:  0.015571515  || Decoder Loss:  0.002941858 Validation Decoder Loss:  0.40895993
Encoder Loss:  0.015402097  || Decoder Loss:  0.0028452552 Validation Decoder Loss:  0.40823573
Encoder Loss:  0.015290454  || Decoder Loss:  0.0027845833 Validation Decoder Loss:  0.40701327
Encoder Loss:  0.015218567  || Decoder Loss:  0.002752434 Validation Decoder Loss:  0.40613145
Encoder Loss:  0.015159809  || Decoder Loss:  0.002735984 Validation Decoder Loss:  0.40512717
Encoder Loss:  0.01511627  || Decoder Loss:  0.0027419522 Validation Decoder Loss:  0.40306082
Encoder Loss:  0.015033432  || Decoder Loss:  0.0026731766 Validation Decoder Loss:  0.39921176
Encoder Loss:  0.014940886  || Decoder Loss:  0.0025838388 Validation Decoder Loss:  0.39691836
Encoder Loss:  0.014854832  || Decoder Loss:  0.0024994586 Validation Decoder Loss:  0.39526105
Encoder Loss:  0.014784256  || Decoder Loss:  0.0024371003 Validation Decoder Loss:  0.3933043
Encoder Loss:  0.01470129  || Decoder Loss:  0.0023544522 Validation Decoder Loss:  0.39136118
Encoder Loss:  0.014640166  || Decoder Loss:  0.0022953276 Validation Decoder Loss:  0.3903188
Encoder Loss:  0.01460333  || Decoder Loss:  0.0022673365 Validation Decoder Loss:  0.38997632
Encoder Loss:  0.014565731  || Decoder Loss:  0.0022488222 Validation Decoder Loss:  0.38870305
Encoder Loss:  0.014544241  || Decoder Loss:  0.0022241361 Validation Decoder Loss:  0.3889332
Encoder Loss:  0.014504313  || Decoder Loss:  0.0021861962 Validation Decoder Loss:  0.38869452
Encoder Loss:  0.0144721335  || Decoder Loss:  0.002151036 Validation Decoder Loss:  0.38841063
Encoder Loss:  0.014435451  || Decoder Loss:  0.0021145116 Validation Decoder Loss:  0.38735875
Encoder Loss:  0.014409683  || Decoder Loss:  0.002084547 Validation Decoder Loss:  0.38627034
Encoder Loss:  0.014385083  || Decoder Loss:  0.00205632 Validation Decoder Loss:  0.38508126
Encoder Loss:  0.014366219  || Decoder Loss:  0.0020369152 Validation Decoder Loss:  0.38424653
Encoder Loss:  0.014350082  || Decoder Loss:  0.0020178014 Validation Decoder Loss:  0.38359445
Encoder Loss:  0.014331371  || Decoder Loss:  0.0020007298 Validation Decoder Loss:  0.383533
Encoder Loss:  0.014319299  || Decoder Loss:  0.0019874359 Validation Decoder Loss:  0.3826298
Encoder Loss:  0.0143125225  || Decoder Loss:  0.0019754726 Validation Decoder Loss:  0.38175836
Encoder Loss:  0.01429793  || Decoder Loss:  0.001963689 Validation Decoder Loss:  0.38158917
Encoder Loss:  0.014288074  || Decoder Loss:  0.0019485047 Validation Decoder Loss:  0.38060296
Model: bold_synthesis_net_lr_0.0006268898156711036 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.38060296
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_94 (Conv3DT (None, 182, 10, 16, 1)    715       
_________________________________________________________________
reshape_94 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 715
Trainable params: 715
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.027283773  || Decoder Loss:  0.0045394218 Validation Decoder Loss:  0.3738766
Encoder Loss:  0.02509869  || Decoder Loss:  0.0041287607 Validation Decoder Loss:  0.36953187
Encoder Loss:  0.024167165  || Decoder Loss:  0.0038995892 Validation Decoder Loss:  0.36638737
Encoder Loss:  0.023546798  || Decoder Loss:  0.003903189 Validation Decoder Loss:  0.3647985
Encoder Loss:  0.022966044  || Decoder Loss:  0.0038237807 Validation Decoder Loss:  0.3637061
Encoder Loss:  0.022608142  || Decoder Loss:  0.0037952985 Validation Decoder Loss:  0.3631309
Encoder Loss:  0.02229714  || Decoder Loss:  0.0036891964 Validation Decoder Loss:  0.3621087
Encoder Loss:  0.021990638  || Decoder Loss:  0.0035735357 Validation Decoder Loss:  0.36178094
Encoder Loss:  0.021694332  || Decoder Loss:  0.003500098 Validation Decoder Loss:  0.36174828
Encoder Loss:  0.021358108  || Decoder Loss:  0.0034125845 Validation Decoder Loss:  0.36147887
Encoder Loss:  0.021021685  || Decoder Loss:  0.003308863 Validation Decoder Loss:  0.36128467
Encoder Loss:  0.020675298  || Decoder Loss:  0.0031624658 Validation Decoder Loss:  0.36078084
Encoder Loss:  0.02031426  || Decoder Loss:  0.0030452274 Validation Decoder Loss:  0.36053962
Encoder Loss:  0.01994199  || Decoder Loss:  0.0029684284 Validation Decoder Loss:  0.36032438
Encoder Loss:  0.019621933  || Decoder Loss:  0.00291578 Validation Decoder Loss:  0.36024722
Encoder Loss:  0.01932314  || Decoder Loss:  0.0028713928 Validation Decoder Loss:  0.36000112
Encoder Loss:  0.01902459  || Decoder Loss:  0.0028377553 Validation Decoder Loss:  0.3598777
Encoder Loss:  0.018790225  || Decoder Loss:  0.0028099762 Validation Decoder Loss:  0.35937375
Encoder Loss:  0.018627038  || Decoder Loss:  0.0027788866 Validation Decoder Loss:  0.3590489
Encoder Loss:  0.018504309  || Decoder Loss:  0.002746897 Validation Decoder Loss:  0.358773
Encoder Loss:  0.018413361  || Decoder Loss:  0.0027062593 Validation Decoder Loss:  0.35860413
Encoder Loss:  0.018344415  || Decoder Loss:  0.002679416 Validation Decoder Loss:  0.35850102
Encoder Loss:  0.018287044  || Decoder Loss:  0.002652154 Validation Decoder Loss:  0.35827833
Encoder Loss:  0.018231802  || Decoder Loss:  0.0026163019 Validation Decoder Loss:  0.3577321
Encoder Loss:  0.018177155  || Decoder Loss:  0.00257346 Validation Decoder Loss:  0.35703474
Encoder Loss:  0.018136224  || Decoder Loss:  0.0025452045 Validation Decoder Loss:  0.35666475
Encoder Loss:  0.01810044  || Decoder Loss:  0.0025234022 Validation Decoder Loss:  0.35661933
Encoder Loss:  0.018072054  || Decoder Loss:  0.0025115788 Validation Decoder Loss:  0.35640055
Encoder Loss:  0.018040972  || Decoder Loss:  0.0024897046 Validation Decoder Loss:  0.3560349
Encoder Loss:  0.018007543  || Decoder Loss:  0.002468647 Validation Decoder Loss:  0.35549834
Encoder Loss:  0.017978363  || Decoder Loss:  0.002447437 Validation Decoder Loss:  0.35517317
Encoder Loss:  0.017953377  || Decoder Loss:  0.0024320285 Validation Decoder Loss:  0.35484287
Encoder Loss:  0.01792648  || Decoder Loss:  0.0024144617 Validation Decoder Loss:  0.35461125
Encoder Loss:  0.017901916  || Decoder Loss:  0.0023958497 Validation Decoder Loss:  0.35440204
Encoder Loss:  0.017882422  || Decoder Loss:  0.0023824177 Validation Decoder Loss:  0.35419333
Encoder Loss:  0.017862171  || Decoder Loss:  0.002368125 Validation Decoder Loss:  0.35395062
Encoder Loss:  0.017843597  || Decoder Loss:  0.002353406 Validation Decoder Loss:  0.3536886
Encoder Loss:  0.017829617  || Decoder Loss:  0.0023444393 Validation Decoder Loss:  0.3535679
Encoder Loss:  0.017814249  || Decoder Loss:  0.0023331777 Validation Decoder Loss:  0.35341492
Encoder Loss:  0.01780114  || Decoder Loss:  0.002321001 Validation Decoder Loss:  0.35328913
Model: bold_synthesis_net_lr_0.0003802855578658356 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.3532891
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 260, 7, 16, 1)     25        
_________________________________________________________________
reshape_95 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.032667115  || Decoder Loss:  0.007742856 Validation Decoder Loss:  0.37532702
Encoder Loss:  0.021820512  || Decoder Loss:  0.0052468167 Validation Decoder Loss:  0.4012517
Encoder Loss:  0.01990018  || Decoder Loss:  0.004312064 Validation Decoder Loss:  0.39777952
Encoder Loss:  0.01887877  || Decoder Loss:  0.003819023 Validation Decoder Loss:  0.39522114
Encoder Loss:  0.018149342  || Decoder Loss:  0.0034317619 Validation Decoder Loss:  0.399058
Encoder Loss:  0.017586967  || Decoder Loss:  0.0032270555 Validation Decoder Loss:  0.40121105
Encoder Loss:  0.017068718  || Decoder Loss:  0.0030388592 Validation Decoder Loss:  0.3987323
Encoder Loss:  0.0165884  || Decoder Loss:  0.002935575 Validation Decoder Loss:  0.3774702
Encoder Loss:  0.016108718  || Decoder Loss:  0.0028599228 Validation Decoder Loss:  0.33026916
Encoder Loss:  0.015621382  || Decoder Loss:  0.0026838635 Validation Decoder Loss:  0.26069283
Encoder Loss:  0.014931752  || Decoder Loss:  0.002093228 Validation Decoder Loss:  0.20248252
Encoder Loss:  0.01446901  || Decoder Loss:  0.0016516729 Validation Decoder Loss:  0.16646913
Encoder Loss:  0.01423681  || Decoder Loss:  0.0014282744 Validation Decoder Loss:  0.15077779
Encoder Loss:  0.014063322  || Decoder Loss:  0.0012282578 Validation Decoder Loss:  0.14188749
Encoder Loss:  0.01395416  || Decoder Loss:  0.0010961524 Validation Decoder Loss:  0.13122097
Encoder Loss:  0.013863989  || Decoder Loss:  0.0009843936 Validation Decoder Loss:  0.12501568
Encoder Loss:  0.0138036385  || Decoder Loss:  0.00090723886 Validation Decoder Loss:  0.11926868
Encoder Loss:  0.013745544  || Decoder Loss:  0.00083400955 Validation Decoder Loss:  0.111909986
Encoder Loss:  0.0137011465  || Decoder Loss:  0.00078094006 Validation Decoder Loss:  0.105960935
Encoder Loss:  0.013658694  || Decoder Loss:  0.0007297141 Validation Decoder Loss:  0.10157969
Encoder Loss:  0.013622807  || Decoder Loss:  0.0006862666 Validation Decoder Loss:  0.09571797
Encoder Loss:  0.013591402  || Decoder Loss:  0.00064578495 Validation Decoder Loss:  0.09145207
Encoder Loss:  0.013566873  || Decoder Loss:  0.0006153955 Validation Decoder Loss:  0.08912344
Encoder Loss:  0.013548478  || Decoder Loss:  0.00059437525 Validation Decoder Loss:  0.08643137
Encoder Loss:  0.013531304  || Decoder Loss:  0.0005745945 Validation Decoder Loss:  0.08310054
Encoder Loss:  0.013511226  || Decoder Loss:  0.0005492925 Validation Decoder Loss:  0.08000708
Encoder Loss:  0.013493722  || Decoder Loss:  0.00052856375 Validation Decoder Loss:  0.07759444
Encoder Loss:  0.013480246  || Decoder Loss:  0.00051346736 Validation Decoder Loss:  0.075755484
Encoder Loss:  0.013466828  || Decoder Loss:  0.00049722166 Validation Decoder Loss:  0.073561214
Encoder Loss:  0.013456424  || Decoder Loss:  0.00048355816 Validation Decoder Loss:  0.07100342
Encoder Loss:  0.013445125  || Decoder Loss:  0.00046977444 Validation Decoder Loss:  0.06899965
Encoder Loss:  0.01343606  || Decoder Loss:  0.00045755453 Validation Decoder Loss:  0.06793839
Encoder Loss:  0.013424879  || Decoder Loss:  0.00044550942 Validation Decoder Loss:  0.066005066
Encoder Loss:  0.013416231  || Decoder Loss:  0.00043311782 Validation Decoder Loss:  0.06403579
Encoder Loss:  0.013405336  || Decoder Loss:  0.00042123775 Validation Decoder Loss:  0.06253452
Encoder Loss:  0.01339706  || Decoder Loss:  0.00040872395 Validation Decoder Loss:  0.060114235
Encoder Loss:  0.013390668  || Decoder Loss:  0.00039981812 Validation Decoder Loss:  0.058087
Encoder Loss:  0.013384109  || Decoder Loss:  0.00039067888 Validation Decoder Loss:  0.05673279
Encoder Loss:  0.013375557  || Decoder Loss:  0.00038104315 Validation Decoder Loss:  0.0554459
Encoder Loss:  0.013369185  || Decoder Loss:  0.0003746629 Validation Decoder Loss:  0.0533322
Model: bold_synthesis_net_lr_0.000631575638147972 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.053332195
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 70, 26, 16, 1)     155       
_________________________________________________________________
reshape_96 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 155
Trainable params: 155
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.040659465  || Decoder Loss:  0.008080842 Validation Decoder Loss:  0.3622568
Encoder Loss:  0.030346755  || Decoder Loss:  0.006669916 Validation Decoder Loss:  0.36325982
Encoder Loss:  0.028089967  || Decoder Loss:  0.0059935413 Validation Decoder Loss:  0.36879528
Encoder Loss:  0.027298905  || Decoder Loss:  0.0056243245 Validation Decoder Loss:  0.37101927
Encoder Loss:  0.026516963  || Decoder Loss:  0.0052840514 Validation Decoder Loss:  0.36782962
Encoder Loss:  0.025338484  || Decoder Loss:  0.0051768105 Validation Decoder Loss:  0.35172802
Encoder Loss:  0.02392046  || Decoder Loss:  0.005095417 Validation Decoder Loss:  0.34433097
Encoder Loss:  0.022714525  || Decoder Loss:  0.0048875436 Validation Decoder Loss:  0.3392291
Encoder Loss:  0.021820132  || Decoder Loss:  0.004650097 Validation Decoder Loss:  0.32691735
Encoder Loss:  0.021010641  || Decoder Loss:  0.0043953783 Validation Decoder Loss:  0.30795017
Encoder Loss:  0.020086389  || Decoder Loss:  0.0038210421 Validation Decoder Loss:  0.28259873
Encoder Loss:  0.019325914  || Decoder Loss:  0.0033625253 Validation Decoder Loss:  0.2552656
Encoder Loss:  0.018765751  || Decoder Loss:  0.0031399068 Validation Decoder Loss:  0.22289054
Encoder Loss:  0.018323386  || Decoder Loss:  0.0028914579 Validation Decoder Loss:  0.21169087
Encoder Loss:  0.018021466  || Decoder Loss:  0.0025729986 Validation Decoder Loss:  0.21333721
Encoder Loss:  0.017845454  || Decoder Loss:  0.0024131685 Validation Decoder Loss:  0.21238798
Encoder Loss:  0.0177067  || Decoder Loss:  0.0022962056 Validation Decoder Loss:  0.2102403
Encoder Loss:  0.017604537  || Decoder Loss:  0.0022251145 Validation Decoder Loss:  0.20834315
Encoder Loss:  0.01751057  || Decoder Loss:  0.002140127 Validation Decoder Loss:  0.20758355
Encoder Loss:  0.017427338  || Decoder Loss:  0.0020600583 Validation Decoder Loss:  0.20631075
Encoder Loss:  0.017358957  || Decoder Loss:  0.0019930976 Validation Decoder Loss:  0.20540226
Encoder Loss:  0.017295795  || Decoder Loss:  0.0019281695 Validation Decoder Loss:  0.20434165
Encoder Loss:  0.01724302  || Decoder Loss:  0.0018773874 Validation Decoder Loss:  0.2034439
Encoder Loss:  0.017191825  || Decoder Loss:  0.0018269015 Validation Decoder Loss:  0.20188513
Encoder Loss:  0.01713145  || Decoder Loss:  0.001766635 Validation Decoder Loss:  0.20109358
Encoder Loss:  0.01707931  || Decoder Loss:  0.0017188763 Validation Decoder Loss:  0.19953594
Encoder Loss:  0.01702919  || Decoder Loss:  0.0016720943 Validation Decoder Loss:  0.19965464
Encoder Loss:  0.016989462  || Decoder Loss:  0.0016369135 Validation Decoder Loss:  0.19975013
Encoder Loss:  0.016953738  || Decoder Loss:  0.0016068153 Validation Decoder Loss:  0.20044345
Encoder Loss:  0.016927103  || Decoder Loss:  0.0015854033 Validation Decoder Loss:  0.20008835
Encoder Loss:  0.016899113  || Decoder Loss:  0.0015615366 Validation Decoder Loss:  0.19911537
Encoder Loss:  0.016869197  || Decoder Loss:  0.0015317098 Validation Decoder Loss:  0.19874325
Encoder Loss:  0.01684668  || Decoder Loss:  0.0015110308 Validation Decoder Loss:  0.19943681
Encoder Loss:  0.016822891  || Decoder Loss:  0.0014857841 Validation Decoder Loss:  0.19720897
Encoder Loss:  0.016799482  || Decoder Loss:  0.0014619696 Validation Decoder Loss:  0.1972186
Encoder Loss:  0.016781967  || Decoder Loss:  0.0014423953 Validation Decoder Loss:  0.19723244
Encoder Loss:  0.01676494  || Decoder Loss:  0.0014229822 Validation Decoder Loss:  0.19509661
Encoder Loss:  0.01674776  || Decoder Loss:  0.0014050656 Validation Decoder Loss:  0.19444071
Encoder Loss:  0.016736772  || Decoder Loss:  0.0013911629 Validation Decoder Loss:  0.19344836
Encoder Loss:  0.016720347  || Decoder Loss:  0.0013727065 Validation Decoder Loss:  0.19417748
Model: bold_synthesis_net_lr_0.0003770521751228501 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.19417746
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_97 (Conv3DT (None, 70, 26, 16, 1)     71        
_________________________________________________________________
reshape_97 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 71
Trainable params: 71
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02916594  || Decoder Loss:  0.008223944 Validation Decoder Loss:  0.3707928
Encoder Loss:  0.02461047  || Decoder Loss:  0.0063223457 Validation Decoder Loss:  0.39250377
Encoder Loss:  0.022916282  || Decoder Loss:  0.0060829744 Validation Decoder Loss:  0.40458655
Encoder Loss:  0.02195087  || Decoder Loss:  0.0055747516 Validation Decoder Loss:  0.4036205
Encoder Loss:  0.021161607  || Decoder Loss:  0.005269998 Validation Decoder Loss:  0.40049323
Encoder Loss:  0.020671826  || Decoder Loss:  0.0052297795 Validation Decoder Loss:  0.39454308
Encoder Loss:  0.020174459  || Decoder Loss:  0.0051634945 Validation Decoder Loss:  0.38576162
Encoder Loss:  0.019612687  || Decoder Loss:  0.0049750097 Validation Decoder Loss:  0.37633377
Encoder Loss:  0.01891218  || Decoder Loss:  0.0046254406 Validation Decoder Loss:  0.35203624
Encoder Loss:  0.01785353  || Decoder Loss:  0.0039614667 Validation Decoder Loss:  0.31838328
Encoder Loss:  0.016861148  || Decoder Loss:  0.0034261243 Validation Decoder Loss:  0.25523394
Encoder Loss:  0.01609314  || Decoder Loss:  0.0028993324 Validation Decoder Loss:  0.1966054
Encoder Loss:  0.015633656  || Decoder Loss:  0.0025203056 Validation Decoder Loss:  0.180002
Encoder Loss:  0.015227479  || Decoder Loss:  0.0021061758 Validation Decoder Loss:  0.16219553
Encoder Loss:  0.015013728  || Decoder Loss:  0.0019296055 Validation Decoder Loss:  0.15190783
Encoder Loss:  0.014865469  || Decoder Loss:  0.0018187527 Validation Decoder Loss:  0.14451079
Encoder Loss:  0.014738959  || Decoder Loss:  0.0017050275 Validation Decoder Loss:  0.1402277
Encoder Loss:  0.014635376  || Decoder Loss:  0.0016009979 Validation Decoder Loss:  0.13448088
Encoder Loss:  0.014552888  || Decoder Loss:  0.0015264859 Validation Decoder Loss:  0.13137037
Encoder Loss:  0.0144802015  || Decoder Loss:  0.0014570706 Validation Decoder Loss:  0.12764081
Encoder Loss:  0.014425285  || Decoder Loss:  0.0014092288 Validation Decoder Loss:  0.1244321
Encoder Loss:  0.014372765  || Decoder Loss:  0.001361806 Validation Decoder Loss:  0.1205848
Encoder Loss:  0.014317507  || Decoder Loss:  0.0013027607 Validation Decoder Loss:  0.11868055
Encoder Loss:  0.01427568  || Decoder Loss:  0.0012642265 Validation Decoder Loss:  0.117300615
Encoder Loss:  0.014224532  || Decoder Loss:  0.0012161246 Validation Decoder Loss:  0.11097552
Encoder Loss:  0.014182734  || Decoder Loss:  0.0011824502 Validation Decoder Loss:  0.10980655
Encoder Loss:  0.014144413  || Decoder Loss:  0.0011475972 Validation Decoder Loss:  0.10804323
Encoder Loss:  0.014116251  || Decoder Loss:  0.0011229423 Validation Decoder Loss:  0.10418211
Encoder Loss:  0.014090298  || Decoder Loss:  0.0010990171 Validation Decoder Loss:  0.10359183
Encoder Loss:  0.014060338  || Decoder Loss:  0.0010709747 Validation Decoder Loss:  0.10282211
Encoder Loss:  0.014037058  || Decoder Loss:  0.0010477176 Validation Decoder Loss:  0.10026726
Encoder Loss:  0.014007366  || Decoder Loss:  0.0010171675 Validation Decoder Loss:  0.0965797
Encoder Loss:  0.013979882  || Decoder Loss:  0.0009867226 Validation Decoder Loss:  0.092827216
Encoder Loss:  0.013960452  || Decoder Loss:  0.0009637602 Validation Decoder Loss:  0.089658424
Encoder Loss:  0.013931099  || Decoder Loss:  0.0009289077 Validation Decoder Loss:  0.08741117
Encoder Loss:  0.013912307  || Decoder Loss:  0.0009059207 Validation Decoder Loss:  0.08456425
Encoder Loss:  0.013890884  || Decoder Loss:  0.0008804144 Validation Decoder Loss:  0.08175531
Encoder Loss:  0.013870672  || Decoder Loss:  0.00085754937 Validation Decoder Loss:  0.0798928
Encoder Loss:  0.013851163  || Decoder Loss:  0.00083227246 Validation Decoder Loss:  0.077703886
Encoder Loss:  0.013833826  || Decoder Loss:  0.00080750365 Validation Decoder Loss:  0.07606033
Model: bold_synthesis_net_lr_0.0005601947240939318 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.07606034
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 65, 28, 16, 1)     33        
_________________________________________________________________
reshape_98 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035318673  || Decoder Loss:  0.0074489648 Validation Decoder Loss:  0.37559628
Encoder Loss:  0.025085613  || Decoder Loss:  0.0053416737 Validation Decoder Loss:  0.40598643
Encoder Loss:  0.021793172  || Decoder Loss:  0.0044442597 Validation Decoder Loss:  0.41118956
Encoder Loss:  0.020536017  || Decoder Loss:  0.0040764143 Validation Decoder Loss:  0.41016352
Encoder Loss:  0.019153813  || Decoder Loss:  0.003807966 Validation Decoder Loss:  0.4110318
Encoder Loss:  0.018056832  || Decoder Loss:  0.0035472843 Validation Decoder Loss:  0.4147501
Encoder Loss:  0.017333588  || Decoder Loss:  0.003442931 Validation Decoder Loss:  0.4162653
Encoder Loss:  0.016813973  || Decoder Loss:  0.003358031 Validation Decoder Loss:  0.4162542
Encoder Loss:  0.016463248  || Decoder Loss:  0.003242505 Validation Decoder Loss:  0.41283172
Encoder Loss:  0.016219376  || Decoder Loss:  0.0031658807 Validation Decoder Loss:  0.40333223
Encoder Loss:  0.016002297  || Decoder Loss:  0.003068747 Validation Decoder Loss:  0.39500043
Encoder Loss:  0.015762145  || Decoder Loss:  0.002921176 Validation Decoder Loss:  0.37613624
Encoder Loss:  0.015536599  || Decoder Loss:  0.0027877756 Validation Decoder Loss:  0.35658216
Encoder Loss:  0.01535471  || Decoder Loss:  0.002673002 Validation Decoder Loss:  0.34022588
Encoder Loss:  0.015101493  || Decoder Loss:  0.0024229875 Validation Decoder Loss:  0.32577312
Encoder Loss:  0.014903063  || Decoder Loss:  0.0022168867 Validation Decoder Loss:  0.3153426
Encoder Loss:  0.014766865  || Decoder Loss:  0.0020688304 Validation Decoder Loss:  0.30060962
Encoder Loss:  0.0146379685  || Decoder Loss:  0.0019193606 Validation Decoder Loss:  0.2951162
Encoder Loss:  0.014548265  || Decoder Loss:  0.0018147003 Validation Decoder Loss:  0.28711402
Encoder Loss:  0.014483605  || Decoder Loss:  0.0017401222 Validation Decoder Loss:  0.27799785
Encoder Loss:  0.014417749  || Decoder Loss:  0.0016623485 Validation Decoder Loss:  0.2683617
Encoder Loss:  0.01435472  || Decoder Loss:  0.0015849845 Validation Decoder Loss:  0.2571988
Encoder Loss:  0.014294805  || Decoder Loss:  0.0015134115 Validation Decoder Loss:  0.24538752
Encoder Loss:  0.014224745  || Decoder Loss:  0.0014309387 Validation Decoder Loss:  0.22530966
Encoder Loss:  0.014163652  || Decoder Loss:  0.0013561574 Validation Decoder Loss:  0.21299878
Encoder Loss:  0.014112199  || Decoder Loss:  0.0012933835 Validation Decoder Loss:  0.19705826
Encoder Loss:  0.014066535  || Decoder Loss:  0.0012445241 Validation Decoder Loss:  0.18663728
Encoder Loss:  0.014018757  || Decoder Loss:  0.001187776 Validation Decoder Loss:  0.1713981
Encoder Loss:  0.013985836  || Decoder Loss:  0.0011535872 Validation Decoder Loss:  0.16388886
Encoder Loss:  0.013945316  || Decoder Loss:  0.0011084541 Validation Decoder Loss:  0.15863395
Encoder Loss:  0.013908603  || Decoder Loss:  0.001065173 Validation Decoder Loss:  0.15281111
Encoder Loss:  0.013873473  || Decoder Loss:  0.0010230965 Validation Decoder Loss:  0.1477536
Encoder Loss:  0.013846396  || Decoder Loss:  0.000989293 Validation Decoder Loss:  0.14199218
Encoder Loss:  0.01381867  || Decoder Loss:  0.00095828215 Validation Decoder Loss:  0.13850026
Encoder Loss:  0.013798006  || Decoder Loss:  0.0009310651 Validation Decoder Loss:  0.13729678
Encoder Loss:  0.013772454  || Decoder Loss:  0.0009001555 Validation Decoder Loss:  0.13335514
Encoder Loss:  0.013749471  || Decoder Loss:  0.00087245717 Validation Decoder Loss:  0.1344546
Encoder Loss:  0.013729774  || Decoder Loss:  0.0008489454 Validation Decoder Loss:  0.13288754
Encoder Loss:  0.013716676  || Decoder Loss:  0.0008348235 Validation Decoder Loss:  0.132022
Encoder Loss:  0.013701699  || Decoder Loss:  0.00081905274 Validation Decoder Loss:  0.12820375
Model: bold_synthesis_net_lr_0.0005123800505702274 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.12820375
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 182, 10, 16, 1)    239       
_________________________________________________________________
reshape_99 (Reshape)         (None, 1820, 16, 1)       0         
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.023315886  || Decoder Loss:  0.0050025545 Validation Decoder Loss:  0.467968
Encoder Loss:  0.02026135  || Decoder Loss:  0.004153065 Validation Decoder Loss:  0.46606338
Encoder Loss:  0.019296074  || Decoder Loss:  0.0035401084 Validation Decoder Loss:  0.46608567
Encoder Loss:  0.018912291  || Decoder Loss:  0.0033392592 Validation Decoder Loss:  0.46645695
Encoder Loss:  0.01863182  || Decoder Loss:  0.0032419336 Validation Decoder Loss:  0.46678954
Encoder Loss:  0.018362606  || Decoder Loss:  0.0031485453 Validation Decoder Loss:  0.46721858
Encoder Loss:  0.01811474  || Decoder Loss:  0.003069794 Validation Decoder Loss:  0.46734
Encoder Loss:  0.01787371  || Decoder Loss:  0.0030056445 Validation Decoder Loss:  0.46780595
Encoder Loss:  0.01764272  || Decoder Loss:  0.0029490313 Validation Decoder Loss:  0.4679478
Encoder Loss:  0.01737605  || Decoder Loss:  0.0028529924 Validation Decoder Loss:  0.46768188
Encoder Loss:  0.017101977  || Decoder Loss:  0.0027309433 Validation Decoder Loss:  0.46766812
Encoder Loss:  0.016876392  || Decoder Loss:  0.0026524286 Validation Decoder Loss:  0.4679727
Encoder Loss:  0.016687788  || Decoder Loss:  0.0026297846 Validation Decoder Loss:  0.46850392
Encoder Loss:  0.016504407  || Decoder Loss:  0.0026029781 Validation Decoder Loss:  0.46803254
Encoder Loss:  0.01632144  || Decoder Loss:  0.002556511 Validation Decoder Loss:  0.4665984
Encoder Loss:  0.016144374  || Decoder Loss:  0.0024991115 Validation Decoder Loss:  0.4627737
Encoder Loss:  0.015984258  || Decoder Loss:  0.0024496226 Validation Decoder Loss:  0.4580442
Encoder Loss:  0.015869558  || Decoder Loss:  0.0024602604 Validation Decoder Loss:  0.45310783
Encoder Loss:  0.015752241  || Decoder Loss:  0.0024612776 Validation Decoder Loss:  0.4478451
Encoder Loss:  0.015689708  || Decoder Loss:  0.002533366 Validation Decoder Loss:  0.44391066
Encoder Loss:  0.015606063  || Decoder Loss:  0.0025498304 Validation Decoder Loss:  0.44167608
Encoder Loss:  0.015523688  || Decoder Loss:  0.0025457721 Validation Decoder Loss:  0.43834698
Encoder Loss:  0.0154534215  || Decoder Loss:  0.002525951 Validation Decoder Loss:  0.436046
Encoder Loss:  0.015414747  || Decoder Loss:  0.0025367166 Validation Decoder Loss:  0.43433815
Encoder Loss:  0.015362567  || Decoder Loss:  0.0025126955 Validation Decoder Loss:  0.43307686
Encoder Loss:  0.015308961  || Decoder Loss:  0.0024704062 Validation Decoder Loss:  0.43263495
Encoder Loss:  0.015259397  || Decoder Loss:  0.0024241211 Validation Decoder Loss:  0.43204412
Encoder Loss:  0.015217169  || Decoder Loss:  0.0023829504 Validation Decoder Loss:  0.4321064
Encoder Loss:  0.015187908  || Decoder Loss:  0.0023589588 Validation Decoder Loss:  0.43264365
Encoder Loss:  0.015155331  || Decoder Loss:  0.0023283614 Validation Decoder Loss:  0.43288654
Encoder Loss:  0.01512702  || Decoder Loss:  0.0023037903 Validation Decoder Loss:  0.4330088
Encoder Loss:  0.015101379  || Decoder Loss:  0.0022796215 Validation Decoder Loss:  0.43320364
Encoder Loss:  0.01508117  || Decoder Loss:  0.0022618375 Validation Decoder Loss:  0.43361682
Encoder Loss:  0.015058625  || Decoder Loss:  0.0022394017 Validation Decoder Loss:  0.43340212
Encoder Loss:  0.015042473  || Decoder Loss:  0.002225451 Validation Decoder Loss:  0.43365294
Encoder Loss:  0.015025363  || Decoder Loss:  0.0022116203 Validation Decoder Loss:  0.43344063
Encoder Loss:  0.015008667  || Decoder Loss:  0.0021989404 Validation Decoder Loss:  0.4338361
Encoder Loss:  0.014990856  || Decoder Loss:  0.0021811372 Validation Decoder Loss:  0.43383628
Encoder Loss:  0.014976044  || Decoder Loss:  0.0021654132 Validation Decoder Loss:  0.433909
Encoder Loss:  0.014959042  || Decoder Loss:  0.0021511242 Validation Decoder Loss:  0.4342799
Model: bold_synthesis_net_lr_0.0003928096444920143 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4342799
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_100 (Conv3D (None, 91, 20, 16, 1)     113       
_________________________________________________________________
reshape_100 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 113
Trainable params: 113
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.027509855  || Decoder Loss:  0.0063667996 Validation Decoder Loss:  0.43567926
Encoder Loss:  0.024846928  || Decoder Loss:  0.0055046612 Validation Decoder Loss:  0.44169408
Encoder Loss:  0.023609584  || Decoder Loss:  0.0047554877 Validation Decoder Loss:  0.44623864
Encoder Loss:  0.022773158  || Decoder Loss:  0.004266719 Validation Decoder Loss:  0.4499588
Encoder Loss:  0.022099555  || Decoder Loss:  0.0039363024 Validation Decoder Loss:  0.4492732
Encoder Loss:  0.021460736  || Decoder Loss:  0.003738968 Validation Decoder Loss:  0.44713104
Encoder Loss:  0.020858992  || Decoder Loss:  0.0035614823 Validation Decoder Loss:  0.4472602
Encoder Loss:  0.020283181  || Decoder Loss:  0.0034688835 Validation Decoder Loss:  0.4433291
Encoder Loss:  0.01966303  || Decoder Loss:  0.0033657872 Validation Decoder Loss:  0.44312415
Encoder Loss:  0.01911259  || Decoder Loss:  0.003210073 Validation Decoder Loss:  0.44330704
Encoder Loss:  0.018656781  || Decoder Loss:  0.0031490917 Validation Decoder Loss:  0.4419761
Encoder Loss:  0.018288452  || Decoder Loss:  0.0030510144 Validation Decoder Loss:  0.441853
Encoder Loss:  0.01799698  || Decoder Loss:  0.0029491752 Validation Decoder Loss:  0.4414443
Encoder Loss:  0.017738888  || Decoder Loss:  0.002878061 Validation Decoder Loss:  0.44154096
Encoder Loss:  0.017538723  || Decoder Loss:  0.0027913952 Validation Decoder Loss:  0.44226086
Encoder Loss:  0.017374367  || Decoder Loss:  0.0026900691 Validation Decoder Loss:  0.4422721
Encoder Loss:  0.01721494  || Decoder Loss:  0.0025651008 Validation Decoder Loss:  0.4424891
Encoder Loss:  0.017086482  || Decoder Loss:  0.0024679604 Validation Decoder Loss:  0.44302326
Encoder Loss:  0.017001789  || Decoder Loss:  0.0024180112 Validation Decoder Loss:  0.44374698
Encoder Loss:  0.016929545  || Decoder Loss:  0.0023768337 Validation Decoder Loss:  0.44391066
Encoder Loss:  0.016859462  || Decoder Loss:  0.0023273285 Validation Decoder Loss:  0.44407272
Encoder Loss:  0.01678742  || Decoder Loss:  0.002276837 Validation Decoder Loss:  0.44423157
Encoder Loss:  0.016730921  || Decoder Loss:  0.002229704 Validation Decoder Loss:  0.4439401
Encoder Loss:  0.016665833  || Decoder Loss:  0.0021837458 Validation Decoder Loss:  0.44366962
Encoder Loss:  0.01660952  || Decoder Loss:  0.0021428885 Validation Decoder Loss:  0.44282162
Encoder Loss:  0.016560366  || Decoder Loss:  0.0021025268 Validation Decoder Loss:  0.44123513
Encoder Loss:  0.01650705  || Decoder Loss:  0.0020496696 Validation Decoder Loss:  0.43976024
Encoder Loss:  0.016451297  || Decoder Loss:  0.0019919886 Validation Decoder Loss:  0.43945646
Encoder Loss:  0.016401857  || Decoder Loss:  0.0019458655 Validation Decoder Loss:  0.4390138
Encoder Loss:  0.016356818  || Decoder Loss:  0.0018988512 Validation Decoder Loss:  0.43672583
Encoder Loss:  0.016307138  || Decoder Loss:  0.0018483356 Validation Decoder Loss:  0.43463153
Encoder Loss:  0.016264496  || Decoder Loss:  0.00179677 Validation Decoder Loss:  0.43417096
Encoder Loss:  0.016225073  || Decoder Loss:  0.0017528218 Validation Decoder Loss:  0.43210387
Encoder Loss:  0.016195389  || Decoder Loss:  0.0017231514 Validation Decoder Loss:  0.43246573
Encoder Loss:  0.016172508  || Decoder Loss:  0.0017026399 Validation Decoder Loss:  0.4325144
Encoder Loss:  0.016148625  || Decoder Loss:  0.00168234 Validation Decoder Loss:  0.4327598
Encoder Loss:  0.016136603  || Decoder Loss:  0.0016725893 Validation Decoder Loss:  0.43313426
Encoder Loss:  0.01611648  || Decoder Loss:  0.0016579923 Validation Decoder Loss:  0.43383765
Encoder Loss:  0.016104165  || Decoder Loss:  0.0016480857 Validation Decoder Loss:  0.4337421
Encoder Loss:  0.016092766  || Decoder Loss:  0.0016351427 Validation Decoder Loss:  0.433329
Model: bold_synthesis_net_lr_0.0005817970292836495 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.433329
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 65, 28, 16, 1)     33        
_________________________________________________________________
reshape_101 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.032163776  || Decoder Loss:  0.007008937 Validation Decoder Loss:  0.39187446
Encoder Loss:  0.02208918  || Decoder Loss:  0.0048859464 Validation Decoder Loss:  0.4128838
Encoder Loss:  0.019707857  || Decoder Loss:  0.0041658143 Validation Decoder Loss:  0.41256565
Encoder Loss:  0.018089272  || Decoder Loss:  0.0038183576 Validation Decoder Loss:  0.41253465
Encoder Loss:  0.016967824  || Decoder Loss:  0.0035495274 Validation Decoder Loss:  0.40637177
Encoder Loss:  0.01614778  || Decoder Loss:  0.0033495077 Validation Decoder Loss:  0.39469412
Encoder Loss:  0.015605686  || Decoder Loss:  0.0031163914 Validation Decoder Loss:  0.37771067
Encoder Loss:  0.015293718  || Decoder Loss:  0.0029798278 Validation Decoder Loss:  0.35734898
Encoder Loss:  0.014991195  || Decoder Loss:  0.0027562862 Validation Decoder Loss:  0.34004033
Encoder Loss:  0.014685913  || Decoder Loss:  0.002467299 Validation Decoder Loss:  0.3319478
Encoder Loss:  0.014501901  || Decoder Loss:  0.00227805 Validation Decoder Loss:  0.3283769
Encoder Loss:  0.0143144075  || Decoder Loss:  0.002058547 Validation Decoder Loss:  0.32242712
Encoder Loss:  0.014148199  || Decoder Loss:  0.0018682196 Validation Decoder Loss:  0.32335544
Encoder Loss:  0.014048568  || Decoder Loss:  0.0017668469 Validation Decoder Loss:  0.3245476
Encoder Loss:  0.013975354  || Decoder Loss:  0.0017024782 Validation Decoder Loss:  0.3184623
Encoder Loss:  0.013915674  || Decoder Loss:  0.0016635996 Validation Decoder Loss:  0.30688864
Encoder Loss:  0.013841991  || Decoder Loss:  0.0015978628 Validation Decoder Loss:  0.29302886
Encoder Loss:  0.0137635125  || Decoder Loss:  0.0015241568 Validation Decoder Loss:  0.28450137
Encoder Loss:  0.013690572  || Decoder Loss:  0.0014444144 Validation Decoder Loss:  0.27601945
Encoder Loss:  0.013627635  || Decoder Loss:  0.0013731346 Validation Decoder Loss:  0.2729234
Encoder Loss:  0.013581923  || Decoder Loss:  0.001324849 Validation Decoder Loss:  0.2656457
Encoder Loss:  0.013539121  || Decoder Loss:  0.0012822581 Validation Decoder Loss:  0.2548755
Encoder Loss:  0.013497024  || Decoder Loss:  0.001242476 Validation Decoder Loss:  0.24582867
Encoder Loss:  0.013444577  || Decoder Loss:  0.0011867959 Validation Decoder Loss:  0.24216932
Encoder Loss:  0.013398303  || Decoder Loss:  0.0011341141 Validation Decoder Loss:  0.23613432
Encoder Loss:  0.013358988  || Decoder Loss:  0.0010863203 Validation Decoder Loss:  0.23037487
Encoder Loss:  0.013313216  || Decoder Loss:  0.0010307066 Validation Decoder Loss:  0.2216571
Encoder Loss:  0.013276479  || Decoder Loss:  0.0009883333 Validation Decoder Loss:  0.2182939
Encoder Loss:  0.013252765  || Decoder Loss:  0.0009611098 Validation Decoder Loss:  0.21119604
Encoder Loss:  0.013226435  || Decoder Loss:  0.00093139074 Validation Decoder Loss:  0.20477968
Encoder Loss:  0.013201182  || Decoder Loss:  0.0009011236 Validation Decoder Loss:  0.20161727
Encoder Loss:  0.013178214  || Decoder Loss:  0.0008740139 Validation Decoder Loss:  0.19507542
Encoder Loss:  0.013152515  || Decoder Loss:  0.0008416858 Validation Decoder Loss:  0.1959686
Encoder Loss:  0.013129161  || Decoder Loss:  0.0008120885 Validation Decoder Loss:  0.19088462
Encoder Loss:  0.013107743  || Decoder Loss:  0.0007880925 Validation Decoder Loss:  0.18559502
Encoder Loss:  0.013085886  || Decoder Loss:  0.000764947 Validation Decoder Loss:  0.18333232
Encoder Loss:  0.013062141  || Decoder Loss:  0.0007392261 Validation Decoder Loss:  0.17954297
Encoder Loss:  0.013042817  || Decoder Loss:  0.00071813446 Validation Decoder Loss:  0.17694716
Encoder Loss:  0.013024999  || Decoder Loss:  0.00069970626 Validation Decoder Loss:  0.17344588
Encoder Loss:  0.013009995  || Decoder Loss:  0.0006833266 Validation Decoder Loss:  0.17094408
Model: bold_synthesis_net_lr_0.0006634147362698415 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.17094406
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 182, 10, 16, 1)    113       
_________________________________________________________________
reshape_102 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 113
Trainable params: 113
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.028233571  || Decoder Loss:  0.006106357 Validation Decoder Loss:  0.4319377
Encoder Loss:  0.025707155  || Decoder Loss:  0.005577539 Validation Decoder Loss:  0.4367603
Encoder Loss:  0.024445444  || Decoder Loss:  0.0048724962 Validation Decoder Loss:  0.4371667
Encoder Loss:  0.023696262  || Decoder Loss:  0.0044771926 Validation Decoder Loss:  0.44242364
Encoder Loss:  0.023037106  || Decoder Loss:  0.0041141766 Validation Decoder Loss:  0.44488397
Encoder Loss:  0.022479787  || Decoder Loss:  0.0038814235 Validation Decoder Loss:  0.44499996
Encoder Loss:  0.02192856  || Decoder Loss:  0.003821943 Validation Decoder Loss:  0.44351736
Encoder Loss:  0.021379756  || Decoder Loss:  0.0038056886 Validation Decoder Loss:  0.44423583
Encoder Loss:  0.020797474  || Decoder Loss:  0.0037903027 Validation Decoder Loss:  0.44388187
Encoder Loss:  0.020129703  || Decoder Loss:  0.0037542596 Validation Decoder Loss:  0.44404882
Encoder Loss:  0.019583207  || Decoder Loss:  0.003534498 Validation Decoder Loss:  0.44428644
Encoder Loss:  0.019238027  || Decoder Loss:  0.0034619165 Validation Decoder Loss:  0.44291562
Encoder Loss:  0.018960955  || Decoder Loss:  0.0034018469 Validation Decoder Loss:  0.441928
Encoder Loss:  0.018696796  || Decoder Loss:  0.003350283 Validation Decoder Loss:  0.44107324
Encoder Loss:  0.018457351  || Decoder Loss:  0.0032771477 Validation Decoder Loss:  0.4401565
Encoder Loss:  0.018295392  || Decoder Loss:  0.0032230245 Validation Decoder Loss:  0.44040674
Encoder Loss:  0.018171573  || Decoder Loss:  0.0031594448 Validation Decoder Loss:  0.4405452
Encoder Loss:  0.018052336  || Decoder Loss:  0.0030670667 Validation Decoder Loss:  0.44119
Encoder Loss:  0.017944315  || Decoder Loss:  0.0029846376 Validation Decoder Loss:  0.44098398
Encoder Loss:  0.017842822  || Decoder Loss:  0.0028992726 Validation Decoder Loss:  0.44219917
Encoder Loss:  0.01775114  || Decoder Loss:  0.0028183507 Validation Decoder Loss:  0.44254857
Encoder Loss:  0.017662885  || Decoder Loss:  0.002735199 Validation Decoder Loss:  0.44240192
Encoder Loss:  0.017583592  || Decoder Loss:  0.0026552314 Validation Decoder Loss:  0.4426921
Encoder Loss:  0.01749995  || Decoder Loss:  0.0025757493 Validation Decoder Loss:  0.44311342
Encoder Loss:  0.017425697  || Decoder Loss:  0.0025100238 Validation Decoder Loss:  0.4433478
Encoder Loss:  0.017368995  || Decoder Loss:  0.002471494 Validation Decoder Loss:  0.44313598
Encoder Loss:  0.01731985  || Decoder Loss:  0.0024378437 Validation Decoder Loss:  0.44272214
Encoder Loss:  0.017275203  || Decoder Loss:  0.0024100274 Validation Decoder Loss:  0.44288203
Encoder Loss:  0.017239654  || Decoder Loss:  0.0023882128 Validation Decoder Loss:  0.44279233
Encoder Loss:  0.017202403  || Decoder Loss:  0.002368303 Validation Decoder Loss:  0.44265684
Encoder Loss:  0.017174216  || Decoder Loss:  0.0023535967 Validation Decoder Loss:  0.44238028
Encoder Loss:  0.01714892  || Decoder Loss:  0.0023440563 Validation Decoder Loss:  0.44102985
Encoder Loss:  0.017124845  || Decoder Loss:  0.0023326278 Validation Decoder Loss:  0.44147477
Encoder Loss:  0.017098146  || Decoder Loss:  0.0023161909 Validation Decoder Loss:  0.4416582
Encoder Loss:  0.017068345  || Decoder Loss:  0.0022984382 Validation Decoder Loss:  0.44096473
Encoder Loss:  0.017046275  || Decoder Loss:  0.00228353 Validation Decoder Loss:  0.44105425
Encoder Loss:  0.01702856  || Decoder Loss:  0.002273186 Validation Decoder Loss:  0.44035447
Encoder Loss:  0.017011305  || Decoder Loss:  0.002262073 Validation Decoder Loss:  0.44004005
Encoder Loss:  0.016992807  || Decoder Loss:  0.0022478744 Validation Decoder Loss:  0.4394654
Encoder Loss:  0.016974151  || Decoder Loss:  0.0022293485 Validation Decoder Loss:  0.43901634
Model: bold_synthesis_net_lr_0.0005030358589777189 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.43901634
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_103 (Conv3D (None, 182, 10, 16, 1)    715       
_________________________________________________________________
reshape_103 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 715
Trainable params: 715
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.01934527  || Decoder Loss:  0.0042892713 Validation Decoder Loss:  0.37150413
Encoder Loss:  0.017579317  || Decoder Loss:  0.0038123745 Validation Decoder Loss:  0.36659703
Encoder Loss:  0.016842442  || Decoder Loss:  0.0037130406 Validation Decoder Loss:  0.36325812
Encoder Loss:  0.0163348  || Decoder Loss:  0.0035936648 Validation Decoder Loss:  0.36346567
Encoder Loss:  0.015811061  || Decoder Loss:  0.00342069 Validation Decoder Loss:  0.36447972
Encoder Loss:  0.015335516  || Decoder Loss:  0.003273263 Validation Decoder Loss:  0.364101
Encoder Loss:  0.014803801  || Decoder Loss:  0.0031231088 Validation Decoder Loss:  0.3635291
Encoder Loss:  0.014229709  || Decoder Loss:  0.0030333805 Validation Decoder Loss:  0.36281317
Encoder Loss:  0.013767558  || Decoder Loss:  0.0029236292 Validation Decoder Loss:  0.36307603
Encoder Loss:  0.013555683  || Decoder Loss:  0.0028417618 Validation Decoder Loss:  0.3637217
Encoder Loss:  0.013435763  || Decoder Loss:  0.0027950658 Validation Decoder Loss:  0.36395264
Encoder Loss:  0.013341805  || Decoder Loss:  0.0027451853 Validation Decoder Loss:  0.36404878
Encoder Loss:  0.013277232  || Decoder Loss:  0.0027083105 Validation Decoder Loss:  0.3641132
Encoder Loss:  0.013228419  || Decoder Loss:  0.0026879844 Validation Decoder Loss:  0.36440435
Encoder Loss:  0.013186606  || Decoder Loss:  0.002662281 Validation Decoder Loss:  0.3643739
Encoder Loss:  0.013146038  || Decoder Loss:  0.0026359013 Validation Decoder Loss:  0.36429694
Encoder Loss:  0.013104518  || Decoder Loss:  0.0025952295 Validation Decoder Loss:  0.36405873
Encoder Loss:  0.013069067  || Decoder Loss:  0.0025626249 Validation Decoder Loss:  0.36381212
Encoder Loss:  0.0130321495  || Decoder Loss:  0.002524813 Validation Decoder Loss:  0.3633026
Encoder Loss:  0.013010192  || Decoder Loss:  0.002500686 Validation Decoder Loss:  0.36343658
Encoder Loss:  0.012985231  || Decoder Loss:  0.0024819279 Validation Decoder Loss:  0.3633277
Encoder Loss:  0.0129701  || Decoder Loss:  0.002467289 Validation Decoder Loss:  0.36347276
Encoder Loss:  0.012960455  || Decoder Loss:  0.0024588464 Validation Decoder Loss:  0.3635077
Encoder Loss:  0.012950607  || Decoder Loss:  0.0024482883 Validation Decoder Loss:  0.3635311
Encoder Loss:  0.012935323  || Decoder Loss:  0.0024360928 Validation Decoder Loss:  0.36349827
Encoder Loss:  0.012921044  || Decoder Loss:  0.0024208967 Validation Decoder Loss:  0.3637432
Encoder Loss:  0.01290956  || Decoder Loss:  0.0024128451 Validation Decoder Loss:  0.36382532
Encoder Loss:  0.012900252  || Decoder Loss:  0.0024019445 Validation Decoder Loss:  0.3638879
Encoder Loss:  0.012893337  || Decoder Loss:  0.0023984099 Validation Decoder Loss:  0.36402202
Encoder Loss:  0.012888997  || Decoder Loss:  0.00239215 Validation Decoder Loss:  0.36401325
Encoder Loss:  0.012884096  || Decoder Loss:  0.0023908105 Validation Decoder Loss:  0.36402762
Encoder Loss:  0.01287816  || Decoder Loss:  0.0023881223 Validation Decoder Loss:  0.3640968
Encoder Loss:  0.012871217  || Decoder Loss:  0.0023794773 Validation Decoder Loss:  0.36394912
Encoder Loss:  0.012864321  || Decoder Loss:  0.0023743308 Validation Decoder Loss:  0.36391956
Encoder Loss:  0.012856828  || Decoder Loss:  0.0023662401 Validation Decoder Loss:  0.3640195
Encoder Loss:  0.012849987  || Decoder Loss:  0.0023622317 Validation Decoder Loss:  0.364142
Encoder Loss:  0.012846653  || Decoder Loss:  0.0023607886 Validation Decoder Loss:  0.3642708
Encoder Loss:  0.012841087  || Decoder Loss:  0.002355343 Validation Decoder Loss:  0.36442697
Encoder Loss:  0.012836353  || Decoder Loss:  0.0023521646 Validation Decoder Loss:  0.36453843
Encoder Loss:  0.0128251845  || Decoder Loss:  0.0023427748 Validation Decoder Loss:  0.36466855
Model: bold_synthesis_net_lr_0.0007538327471887115 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.36466855
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 130, 14, 16, 1)    671       
_________________________________________________________________
reshape_104 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 671
Trainable params: 671
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.023518592  || Decoder Loss:  0.0048884302 Validation Decoder Loss:  0.38022566
Encoder Loss:  0.021661805  || Decoder Loss:  0.0046775606 Validation Decoder Loss:  0.37692082
Encoder Loss:  0.020520382  || Decoder Loss:  0.0043446776 Validation Decoder Loss:  0.37322593
Encoder Loss:  0.019594355  || Decoder Loss:  0.0041077496 Validation Decoder Loss:  0.37038243
Encoder Loss:  0.018854033  || Decoder Loss:  0.0039852634 Validation Decoder Loss:  0.3688432
Encoder Loss:  0.01820854  || Decoder Loss:  0.0038670453 Validation Decoder Loss:  0.36803284
Encoder Loss:  0.017505936  || Decoder Loss:  0.0037188558 Validation Decoder Loss:  0.36769775
Encoder Loss:  0.016790982  || Decoder Loss:  0.0035868164 Validation Decoder Loss:  0.36678895
Encoder Loss:  0.01623168  || Decoder Loss:  0.0034309453 Validation Decoder Loss:  0.36638743
Encoder Loss:  0.015961366  || Decoder Loss:  0.0033187962 Validation Decoder Loss:  0.36644
Encoder Loss:  0.015801333  || Decoder Loss:  0.0032432382 Validation Decoder Loss:  0.3667154
Encoder Loss:  0.015656067  || Decoder Loss:  0.0031531218 Validation Decoder Loss:  0.36683318
Encoder Loss:  0.015544451  || Decoder Loss:  0.0030832982 Validation Decoder Loss:  0.36688513
Encoder Loss:  0.015444771  || Decoder Loss:  0.0030135869 Validation Decoder Loss:  0.36680877
Encoder Loss:  0.015371563  || Decoder Loss:  0.002964979 Validation Decoder Loss:  0.36669606
Encoder Loss:  0.015301916  || Decoder Loss:  0.002908816 Validation Decoder Loss:  0.36637974
Encoder Loss:  0.01523905  || Decoder Loss:  0.002854397 Validation Decoder Loss:  0.36629313
Encoder Loss:  0.015188355  || Decoder Loss:  0.0028185227 Validation Decoder Loss:  0.36632696
Encoder Loss:  0.015144794  || Decoder Loss:  0.0027841048 Validation Decoder Loss:  0.3659771
Encoder Loss:  0.015099923  || Decoder Loss:  0.0027490105 Validation Decoder Loss:  0.36585534
Encoder Loss:  0.015062379  || Decoder Loss:  0.002720956 Validation Decoder Loss:  0.36576068
Encoder Loss:  0.015024393  || Decoder Loss:  0.0026920624 Validation Decoder Loss:  0.36564815
Encoder Loss:  0.01499142  || Decoder Loss:  0.0026675009 Validation Decoder Loss:  0.36553046
Encoder Loss:  0.014963725  || Decoder Loss:  0.0026463761 Validation Decoder Loss:  0.36528903
Encoder Loss:  0.014939015  || Decoder Loss:  0.002630261 Validation Decoder Loss:  0.36506027
Encoder Loss:  0.014914209  || Decoder Loss:  0.0026129887 Validation Decoder Loss:  0.36479568
Encoder Loss:  0.014890297  || Decoder Loss:  0.002595763 Validation Decoder Loss:  0.36476117
Encoder Loss:  0.014865064  || Decoder Loss:  0.0025720284 Validation Decoder Loss:  0.36479127
Encoder Loss:  0.01482983  || Decoder Loss:  0.0025434196 Validation Decoder Loss:  0.36452478
Encoder Loss:  0.014806813  || Decoder Loss:  0.0025217962 Validation Decoder Loss:  0.36420548
Encoder Loss:  0.014785378  || Decoder Loss:  0.0025030444 Validation Decoder Loss:  0.36410922
Encoder Loss:  0.0147601785  || Decoder Loss:  0.0024816166 Validation Decoder Loss:  0.36418852
Encoder Loss:  0.014736242  || Decoder Loss:  0.002458755 Validation Decoder Loss:  0.36416432
Encoder Loss:  0.014716089  || Decoder Loss:  0.0024377997 Validation Decoder Loss:  0.36417332
Encoder Loss:  0.014697291  || Decoder Loss:  0.002419059 Validation Decoder Loss:  0.36414963
Encoder Loss:  0.014676299  || Decoder Loss:  0.00240184 Validation Decoder Loss:  0.36394298
Encoder Loss:  0.01465938  || Decoder Loss:  0.002388719 Validation Decoder Loss:  0.36389816
Encoder Loss:  0.014647863  || Decoder Loss:  0.002378507 Validation Decoder Loss:  0.36382192
Encoder Loss:  0.014630037  || Decoder Loss:  0.002366629 Validation Decoder Loss:  0.363696
Encoder Loss:  0.0146161625  || Decoder Loss:  0.0023570429 Validation Decoder Loss:  0.36364046
Model: bold_synthesis_net_lr_0.0006217922372840347 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.36364046
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 65, 28, 16, 1)     41        
_________________________________________________________________
reshape_105 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 1820, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [6.70771985e-04 3.71587509e-01 6.03183109e-01 8.71381868e-01
 3.22005780e-01 2.00000000e+00 1.82000000e+03]
Optimized Validation Decoder Loss: 0.04061190038919449











Optimizing at level  2
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 65, 16, 16, 1)     25        
_________________________________________________________________
dropout_318 (Dropout)        (None, 65, 16, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 65, 28, 16, 1)     14        
_________________________________________________________________
reshape_106 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 1870, 16, 1)       739       
_________________________________________________________________
dropout_320 (Dropout)        (None, 1870, 16, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 1820, 16, 1)       52        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 2420, 16, 1)       602       
_________________________________________________________________
dropout_322 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 2607, 16, 1)       189       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07012733  || Decoder Loss:  0.012078587 Validation Decoder Loss:  0.389202
Encoder Loss:  0.051819436  || Decoder Loss:  0.0077168765 Validation Decoder Loss:  0.29781604
Encoder Loss:  0.04269858  || Decoder Loss:  0.004599868 Validation Decoder Loss:  0.31977677
Encoder Loss:  0.037211876  || Decoder Loss:  0.0035503707 Validation Decoder Loss:  0.3218308
Encoder Loss:  0.03503753  || Decoder Loss:  0.003365017 Validation Decoder Loss:  0.30999547
Encoder Loss:  0.033914898  || Decoder Loss:  0.0038423976 Validation Decoder Loss:  0.28419182
Encoder Loss:  0.032621864  || Decoder Loss:  0.004360438 Validation Decoder Loss:  0.3062546
Encoder Loss:  0.03087171  || Decoder Loss:  0.0037716893 Validation Decoder Loss:  0.4099129
Encoder Loss:  0.02997104  || Decoder Loss:  0.003968946 Validation Decoder Loss:  0.5106193
Encoder Loss:  0.02973237  || Decoder Loss:  0.004048312 Validation Decoder Loss:  0.52160156
Encoder Loss:  0.029535169  || Decoder Loss:  0.0036091332 Validation Decoder Loss:  0.51507807
Encoder Loss:  0.029431881  || Decoder Loss:  0.00344399 Validation Decoder Loss:  0.50766677
Encoder Loss:  0.02935695  || Decoder Loss:  0.0033029434 Validation Decoder Loss:  0.50602496
Encoder Loss:  0.029304845  || Decoder Loss:  0.0031956963 Validation Decoder Loss:  0.49619198
Encoder Loss:  0.029251762  || Decoder Loss:  0.0030625456 Validation Decoder Loss:  0.48716465
Encoder Loss:  0.029204  || Decoder Loss:  0.002957383 Validation Decoder Loss:  0.47525704
Encoder Loss:  0.02918097  || Decoder Loss:  0.002907582 Validation Decoder Loss:  0.47039592
Encoder Loss:  0.02915555  || Decoder Loss:  0.0028721225 Validation Decoder Loss:  0.47059467
Encoder Loss:  0.029137341  || Decoder Loss:  0.00285234 Validation Decoder Loss:  0.4679927
Encoder Loss:  0.029108014  || Decoder Loss:  0.0027795683 Validation Decoder Loss:  0.45434222
Encoder Loss:  0.029081423  || Decoder Loss:  0.0027222338 Validation Decoder Loss:  0.45265657
Encoder Loss:  0.029060993  || Decoder Loss:  0.0026775734 Validation Decoder Loss:  0.4491009
Encoder Loss:  0.029038653  || Decoder Loss:  0.0026334124 Validation Decoder Loss:  0.43996006
Encoder Loss:  0.029018512  || Decoder Loss:  0.002590106 Validation Decoder Loss:  0.44089377
Encoder Loss:  0.029002292  || Decoder Loss:  0.0025626235 Validation Decoder Loss:  0.43097222
Encoder Loss:  0.028991673  || Decoder Loss:  0.002554139 Validation Decoder Loss:  0.42500684
Encoder Loss:  0.028973557  || Decoder Loss:  0.0025056582 Validation Decoder Loss:  0.42896855
Encoder Loss:  0.02896116  || Decoder Loss:  0.0024785157 Validation Decoder Loss:  0.42870003
Encoder Loss:  0.028952159  || Decoder Loss:  0.0024664337 Validation Decoder Loss:  0.42570463
Encoder Loss:  0.028941637  || Decoder Loss:  0.0024412416 Validation Decoder Loss:  0.4137401
Encoder Loss:  0.028930422  || Decoder Loss:  0.0024119695 Validation Decoder Loss:  0.41198996
Encoder Loss:  0.028922025  || Decoder Loss:  0.0023883404 Validation Decoder Loss:  0.4071461
Encoder Loss:  0.028912028  || Decoder Loss:  0.0023596217 Validation Decoder Loss:  0.4022612
Encoder Loss:  0.028905468  || Decoder Loss:  0.0023485168 Validation Decoder Loss:  0.4033914
Encoder Loss:  0.028901396  || Decoder Loss:  0.0023413321 Validation Decoder Loss:  0.3935454
Encoder Loss:  0.028895948  || Decoder Loss:  0.0023254168 Validation Decoder Loss:  0.39516363
Encoder Loss:  0.028887535  || Decoder Loss:  0.0023078297 Validation Decoder Loss:  0.38615835
Encoder Loss:  0.028881555  || Decoder Loss:  0.0022944103 Validation Decoder Loss:  0.38427553
Encoder Loss:  0.028877633  || Decoder Loss:  0.002284146 Validation Decoder Loss:  0.38540497
Encoder Loss:  0.028874513  || Decoder Loss:  0.0022809603 Validation Decoder Loss:  0.38059574
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: bold_synthesis_net_lr_0.0005016464840024781 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.38059574
Model: "sequential_323"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 2580, 16, 1)       29        
_________________________________________________________________
dropout_324 (Dropout)        (None, 2580, 16, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 1820, 16, 1)       762       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 2450, 16, 1)       632       
_________________________________________________________________
dropout_326 (Dropout)        (None, 2450, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 2607, 16, 1)       159       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 2200, 16, 1)       409       
_________________________________________________________________
dropout_328 (Dropout)        (None, 2200, 16, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 1820, 16, 1)       382       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_327"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 1820, 16, 1)       2         
_________________________________________________________________
dropout_330 (Dropout)        (None, 1820, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 2607, 16, 1)       789       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 1920, 16, 1)       689       
_________________________________________________________________
dropout_332 (Dropout)        (None, 1920, 16, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 1820, 16, 1)       102       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 2570, 16, 1)       752       
_________________________________________________________________
dropout_334 (Dropout)        (None, 2570, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 2607, 16, 1)       39        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 1970, 16, 1)       639       
_________________________________________________________________
dropout_336 (Dropout)        (None, 1970, 16, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 1820, 16, 1)       152       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 2160, 16, 1)       342       
_________________________________________________________________
dropout_338 (Dropout)        (None, 2160, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 2607, 16, 1)       449       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Started Optimization Process
Model: "sequential_335"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 1850, 16, 1)       759       
_________________________________________________________________
dropout_340 (Dropout)        (None, 1850, 16, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 1820, 16, 1)       32        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 2430, 16, 1)       612       
_________________________________________________________________
dropout_342 (Dropout)        (None, 2430, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 2607, 16, 1)       179       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 2220, 16, 1)       389       
_________________________________________________________________
dropout_344 (Dropout)        (None, 2220, 16, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 1820, 16, 1)       402       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_339"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 2500, 16, 1)       682       
_________________________________________________________________
dropout_346 (Dropout)        (None, 2500, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 2607, 16, 1)       109       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 2460, 16, 1)       149       
_________________________________________________________________
dropout_348 (Dropout)        (None, 2460, 16, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 1820, 16, 1)       642       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 2070, 16, 1)       252       
_________________________________________________________________
dropout_350 (Dropout)        (None, 2070, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 2607, 16, 1)       539       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_344"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 1920, 16, 1)       689       
_________________________________________________________________
dropout_352 (Dropout)        (None, 1920, 16, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 1820, 16, 1)       102       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 1910, 16, 1)       92        
_________________________________________________________________
dropout_354 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 2607, 16, 1)       699       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_347"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 2020, 16, 1)       589       
_________________________________________________________________
dropout_356 (Dropout)        (None, 2020, 16, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 1820, 16, 1)       202       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 1860, 16, 1)       42        
_________________________________________________________________
dropout_358 (Dropout)        (None, 1860, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 2607, 16, 1)       749       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 2560, 16, 1)       49        
_________________________________________________________________
dropout_360 (Dropout)        (None, 2560, 16, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 1820, 16, 1)       742       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_351"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 2030, 16, 1)       212       
_________________________________________________________________
dropout_362 (Dropout)        (None, 2030, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 2607, 16, 1)       579       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 2320, 16, 1)       289       
_________________________________________________________________
dropout_364 (Dropout)        (None, 2320, 16, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 1820, 16, 1)       502       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 2600, 16, 1)       782       
_________________________________________________________________
dropout_366 (Dropout)        (None, 2600, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 2607, 16, 1)       9         
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 2600, 16, 1)       9         
_________________________________________________________________
dropout_368 (Dropout)        (None, 2600, 16, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 1820, 16, 1)       782       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 2060, 16, 1)       242       
_________________________________________________________________
dropout_370 (Dropout)        (None, 2060, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 2607, 16, 1)       549       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_359"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 1840, 16, 1)       769       
_________________________________________________________________
dropout_372 (Dropout)        (None, 1840, 16, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 1820, 16, 1)       22        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 2400, 16, 1)       582       
_________________________________________________________________
dropout_374 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 2607, 16, 1)       209       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 2300, 16, 1)       309       
_________________________________________________________________
dropout_376 (Dropout)        (None, 2300, 16, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 1820, 16, 1)       482       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_363"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 1840, 16, 1)       22        
_________________________________________________________________
dropout_378 (Dropout)        (None, 1840, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 2607, 16, 1)       769       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 2010, 16, 1)       599       
_________________________________________________________________
dropout_380 (Dropout)        (None, 2010, 16, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 1820, 16, 1)       192       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 2220, 16, 1)       402       
_________________________________________________________________
dropout_382 (Dropout)        (None, 2220, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 2607, 16, 1)       389       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 1930, 16, 1)       679       
_________________________________________________________________
dropout_384 (Dropout)        (None, 1930, 16, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 1820, 16, 1)       112       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 2420, 16, 1)       602       
_________________________________________________________________
dropout_386 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 2607, 16, 1)       189       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_371"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 1910, 16, 1)       699       
_________________________________________________________________
dropout_388 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 1820, 16, 1)       92        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 2460, 16, 1)       642       
_________________________________________________________________
dropout_390 (Dropout)        (None, 2460, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 2607, 16, 1)       149       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 2570, 16, 1)       39        
_________________________________________________________________
dropout_392 (Dropout)        (None, 2570, 16, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 1820, 16, 1)       752       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_375"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 2010, 16, 1)       192       
_________________________________________________________________
dropout_394 (Dropout)        (None, 2010, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 2607, 16, 1)       599       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 1840, 16, 1)       769       
_________________________________________________________________
dropout_396 (Dropout)        (None, 1840, 16, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 1820, 16, 1)       22        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 2440, 16, 1)       622       
_________________________________________________________________
dropout_398 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 2607, 16, 1)       169       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 1880, 16, 1)       729       
_________________________________________________________________
dropout_400 (Dropout)        (None, 1880, 16, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 1820, 16, 1)       62        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 2370, 16, 1)       552       
_________________________________________________________________
dropout_402 (Dropout)        (None, 2370, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 2607, 16, 1)       239       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_383"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 2370, 16, 1)       239       
_________________________________________________________________
dropout_404 (Dropout)        (None, 2370, 16, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 1820, 16, 1)       552       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 1830, 16, 1)       12        
_________________________________________________________________
dropout_406 (Dropout)        (None, 1830, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 2607, 16, 1)       779       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 65, 8, 16, 1)      9         
_________________________________________________________________
dropout_408 (Dropout)        (None, 65, 8, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 65, 28, 16, 1)     15        
_________________________________________________________________
reshape_107 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_387"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 2360, 16, 1)       249       
_________________________________________________________________
dropout_410 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 1820, 16, 1)       542       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 2490, 16, 1)       672       
_________________________________________________________________
dropout_412 (Dropout)        (None, 2490, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 2607, 16, 1)       119       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.026020905  || Decoder Loss:  0.007358582 Validation Decoder Loss:  0.45538992
Encoder Loss:  0.024676427  || Decoder Loss:  0.00779848 Validation Decoder Loss:  0.34803277
Encoder Loss:  0.020881383  || Decoder Loss:  0.0052872845 Validation Decoder Loss:  0.3124765
Encoder Loss:  0.018961573  || Decoder Loss:  0.0038144533 Validation Decoder Loss:  0.3214553
Encoder Loss:  0.017799253  || Decoder Loss:  0.0034564591 Validation Decoder Loss:  0.32729858
Encoder Loss:  0.016213264  || Decoder Loss:  0.0032902784 Validation Decoder Loss:  0.3160889
Encoder Loss:  0.0141027365  || Decoder Loss:  0.002986259 Validation Decoder Loss:  0.09431288
Encoder Loss:  0.012373771  || Decoder Loss:  0.002162186 Validation Decoder Loss:  0.11651325
Encoder Loss:  0.011852916  || Decoder Loss:  0.0015348583 Validation Decoder Loss:  0.12622127
Encoder Loss:  0.0116461385  || Decoder Loss:  0.0013129339 Validation Decoder Loss:  0.1042541
Encoder Loss:  0.011540311  || Decoder Loss:  0.0012108489 Validation Decoder Loss:  0.0835328
Encoder Loss:  0.011467923  || Decoder Loss:  0.0011418436 Validation Decoder Loss:  0.085374735
Encoder Loss:  0.011401862  || Decoder Loss:  0.0010772975 Validation Decoder Loss:  0.08192033
Encoder Loss:  0.011339517  || Decoder Loss:  0.0010112722 Validation Decoder Loss:  0.06579402
Encoder Loss:  0.011334233  || Decoder Loss:  0.0010141733 Validation Decoder Loss:  0.054313604
Encoder Loss:  0.011289623  || Decoder Loss:  0.0009692207 Validation Decoder Loss:  0.04225429
Encoder Loss:  0.0112827625  || Decoder Loss:  0.0009691369 Validation Decoder Loss:  0.043740943
Encoder Loss:  0.01125293  || Decoder Loss:  0.0009310744 Validation Decoder Loss:  0.04319714
Encoder Loss:  0.011237807  || Decoder Loss:  0.00091248524 Validation Decoder Loss:  0.043739915
Encoder Loss:  0.011221945  || Decoder Loss:  0.0008929825 Validation Decoder Loss:  0.042075943
Encoder Loss:  0.011190321  || Decoder Loss:  0.00085051276 Validation Decoder Loss:  0.043637216
Encoder Loss:  0.011174542  || Decoder Loss:  0.00082931796 Validation Decoder Loss:  0.041560553
Encoder Loss:  0.011148951  || Decoder Loss:  0.000797715 Validation Decoder Loss:  0.040813945
Encoder Loss:  0.011106909  || Decoder Loss:  0.00074422715 Validation Decoder Loss:  0.03881402
Encoder Loss:  0.01107885  || Decoder Loss:  0.00070668315 Validation Decoder Loss:  0.040000148
Encoder Loss:  0.011056692  || Decoder Loss:  0.00068154593 Validation Decoder Loss:  0.03905275
Encoder Loss:  0.011057225  || Decoder Loss:  0.0006812514 Validation Decoder Loss:  0.035637923
Encoder Loss:  0.011040763  || Decoder Loss:  0.0006580343 Validation Decoder Loss:  0.036232863
Encoder Loss:  0.011034979  || Decoder Loss:  0.00065281213 Validation Decoder Loss:  0.034758568
Encoder Loss:  0.011016777  || Decoder Loss:  0.0006272669 Validation Decoder Loss:  0.033760898
Encoder Loss:  0.011008736  || Decoder Loss:  0.00061702874 Validation Decoder Loss:  0.033269294
Encoder Loss:  0.010976582  || Decoder Loss:  0.000580919 Validation Decoder Loss:  0.03441755
Encoder Loss:  0.010990529  || Decoder Loss:  0.00059739046 Validation Decoder Loss:  0.03383832
Encoder Loss:  0.010995087  || Decoder Loss:  0.00060143374 Validation Decoder Loss:  0.033333104
Encoder Loss:  0.010968794  || Decoder Loss:  0.0005725898 Validation Decoder Loss:  0.03402254
Encoder Loss:  0.010978015  || Decoder Loss:  0.0005832802 Validation Decoder Loss:  0.03432034
Encoder Loss:  0.01098075  || Decoder Loss:  0.0005840488 Validation Decoder Loss:  0.031707708
Encoder Loss:  0.010953036  || Decoder Loss:  0.0005559456 Validation Decoder Loss:  0.031548448
Encoder Loss:  0.010940026  || Decoder Loss:  0.00053830835 Validation Decoder Loss:  0.03068012
Encoder Loss:  0.010948818  || Decoder Loss:  0.00054679543 Validation Decoder Loss:  0.029415622
Model: bold_synthesis_net_lr_0.0007516802280515725 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.029415622
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 1950, 16, 1)       659       
_________________________________________________________________
dropout_414 (Dropout)        (None, 1950, 16, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 1820, 16, 1)       132       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_391"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 2440, 16, 1)       622       
_________________________________________________________________
dropout_416 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 2607, 16, 1)       169       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 2110, 16, 1)       499       
_________________________________________________________________
dropout_418 (Dropout)        (None, 2110, 16, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 1820, 16, 1)       292       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 2140, 16, 1)       322       
_________________________________________________________________
dropout_420 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 2607, 16, 1)       469       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 2370, 16, 1)       239       
_________________________________________________________________
dropout_422 (Dropout)        (None, 2370, 16, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 1820, 16, 1)       552       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 2510, 16, 1)       692       
_________________________________________________________________
dropout_424 (Dropout)        (None, 2510, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 2607, 16, 1)       99        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_399"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 1880, 16, 1)       729       
_________________________________________________________________
dropout_426 (Dropout)        (None, 1880, 16, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 1820, 16, 1)       62        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 2110, 16, 1)       292       
_________________________________________________________________
dropout_428 (Dropout)        (None, 2110, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 2607, 16, 1)       499       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 2270, 16, 1)       339       
_________________________________________________________________
dropout_430 (Dropout)        (None, 2270, 16, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 1820, 16, 1)       452       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_403"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 1860, 16, 1)       42        
_________________________________________________________________
dropout_432 (Dropout)        (None, 1860, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 2607, 16, 1)       749       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 2060, 16, 1)       549       
_________________________________________________________________
dropout_434 (Dropout)        (None, 2060, 16, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 1820, 16, 1)       242       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 2440, 16, 1)       622       
_________________________________________________________________
dropout_436 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 2607, 16, 1)       169       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 1840, 16, 1)       769       
_________________________________________________________________
dropout_438 (Dropout)        (None, 1840, 16, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 1820, 16, 1)       22        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 2440, 16, 1)       622       
_________________________________________________________________
dropout_440 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 2607, 16, 1)       169       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_411"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 2330, 16, 1)       279       
_________________________________________________________________
dropout_442 (Dropout)        (None, 2330, 16, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 1820, 16, 1)       512       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_412"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 2500, 16, 1)       682       
_________________________________________________________________
dropout_444 (Dropout)        (None, 2500, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 2607, 16, 1)       109       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 1870, 16, 1)       739       
_________________________________________________________________
dropout_446 (Dropout)        (None, 1870, 16, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 1820, 16, 1)       52        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_415"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 2400, 16, 1)       582       
_________________________________________________________________
dropout_448 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 2607, 16, 1)       209       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 2360, 16, 1)       249       
_________________________________________________________________
dropout_450 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 1820, 16, 1)       542       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 2470, 16, 1)       652       
_________________________________________________________________
dropout_452 (Dropout)        (None, 2470, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 2607, 16, 1)       139       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 2480, 16, 1)       129       
_________________________________________________________________
dropout_454 (Dropout)        (None, 2480, 16, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 1820, 16, 1)       662       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 2450, 16, 1)       632       
_________________________________________________________________
dropout_456 (Dropout)        (None, 2450, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 2607, 16, 1)       159       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_423"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 2320, 16, 1)       289       
_________________________________________________________________
dropout_458 (Dropout)        (None, 2320, 16, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 1820, 16, 1)       502       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 2490, 16, 1)       672       
_________________________________________________________________
dropout_460 (Dropout)        (None, 2490, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 2607, 16, 1)       119       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 2290, 16, 1)       319       
_________________________________________________________________
dropout_462 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 1820, 16, 1)       472       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_427"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 2440, 16, 1)       622       
_________________________________________________________________
dropout_464 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 2607, 16, 1)       169       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 2130, 16, 1)       479       
_________________________________________________________________
dropout_466 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 1820, 16, 1)       312       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 2600, 16, 1)       782       
_________________________________________________________________
dropout_468 (Dropout)        (None, 2600, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 2607, 16, 1)       9         
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 2430, 16, 1)       179       
_________________________________________________________________
dropout_470 (Dropout)        (None, 2430, 16, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 1820, 16, 1)       612       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 2410, 16, 1)       592       
_________________________________________________________________
dropout_472 (Dropout)        (None, 2410, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 2607, 16, 1)       199       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_435"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 1850, 16, 1)       759       
_________________________________________________________________
dropout_474 (Dropout)        (None, 1850, 16, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 1820, 16, 1)       32        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 2520, 16, 1)       702       
_________________________________________________________________
dropout_476 (Dropout)        (None, 2520, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 2607, 16, 1)       89        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 64, 25, 16, 1)     6         
_________________________________________________________________
dropout_478 (Dropout)        (None, 64, 25, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 65, 28, 16, 1)     9         
_________________________________________________________________
reshape_108 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_439"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 2400, 16, 1)       209       
_________________________________________________________________
dropout_480 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 1820, 16, 1)       582       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 2060, 16, 1)       242       
_________________________________________________________________
dropout_482 (Dropout)        (None, 2060, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 2607, 16, 1)       549       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06824128  || Decoder Loss:  0.008526224 Validation Decoder Loss:  0.67807543
Encoder Loss:  0.054917563  || Decoder Loss:  0.004127442 Validation Decoder Loss:  0.6542375
Encoder Loss:  0.041950922  || Decoder Loss:  0.0043523987 Validation Decoder Loss:  0.6773881
Encoder Loss:  0.036256917  || Decoder Loss:  0.0045021256 Validation Decoder Loss:  0.65656406
Encoder Loss:  0.036045656  || Decoder Loss:  0.0038083221 Validation Decoder Loss:  0.6385698
Encoder Loss:  0.035882987  || Decoder Loss:  0.0035410516 Validation Decoder Loss:  0.6168109
Encoder Loss:  0.035798255  || Decoder Loss:  0.0033061123 Validation Decoder Loss:  0.61054456
Encoder Loss:  0.03564733  || Decoder Loss:  0.003116874 Validation Decoder Loss:  0.59951025
Encoder Loss:  0.035614036  || Decoder Loss:  0.0030233252 Validation Decoder Loss:  0.59376943
Encoder Loss:  0.03553477  || Decoder Loss:  0.0030789066 Validation Decoder Loss:  0.56901675
Encoder Loss:  0.0355018  || Decoder Loss:  0.0029878141 Validation Decoder Loss:  0.5818809
Encoder Loss:  0.035498943  || Decoder Loss:  0.0030153245 Validation Decoder Loss:  0.5889988
Encoder Loss:  0.035428442  || Decoder Loss:  0.0028093024 Validation Decoder Loss:  0.56452286
Encoder Loss:  0.03534463  || Decoder Loss:  0.0026325833 Validation Decoder Loss:  0.5536039
Encoder Loss:  0.035360865  || Decoder Loss:  0.00263682 Validation Decoder Loss:  0.5493102
Encoder Loss:  0.03527835  || Decoder Loss:  0.002585511 Validation Decoder Loss:  0.552727
Encoder Loss:  0.035303675  || Decoder Loss:  0.0026146474 Validation Decoder Loss:  0.5397863
Encoder Loss:  0.035271753  || Decoder Loss:  0.0026471745 Validation Decoder Loss:  0.532776
Encoder Loss:  0.035210717  || Decoder Loss:  0.002571798 Validation Decoder Loss:  0.5482702
Encoder Loss:  0.035085667  || Decoder Loss:  0.002477696 Validation Decoder Loss:  0.53164726
Encoder Loss:  0.035054468  || Decoder Loss:  0.0024729078 Validation Decoder Loss:  0.53127074
Encoder Loss:  0.035034798  || Decoder Loss:  0.002463584 Validation Decoder Loss:  0.5370127
Encoder Loss:  0.035064407  || Decoder Loss:  0.0025470278 Validation Decoder Loss:  0.50818247
Encoder Loss:  0.03497217  || Decoder Loss:  0.0025188974 Validation Decoder Loss:  0.5220693
Encoder Loss:  0.035019547  || Decoder Loss:  0.0024688216 Validation Decoder Loss:  0.51256454
Encoder Loss:  0.03494959  || Decoder Loss:  0.002435538 Validation Decoder Loss:  0.48161772
Encoder Loss:  0.034918103  || Decoder Loss:  0.0023805317 Validation Decoder Loss:  0.48624372
Encoder Loss:  0.034868177  || Decoder Loss:  0.002321428 Validation Decoder Loss:  0.46459848
Encoder Loss:  0.034856174  || Decoder Loss:  0.002275367 Validation Decoder Loss:  0.4606485
Encoder Loss:  0.034815118  || Decoder Loss:  0.0022204148 Validation Decoder Loss:  0.45461065
Encoder Loss:  0.034833856  || Decoder Loss:  0.0022802064 Validation Decoder Loss:  0.43574604
Encoder Loss:  0.034763124  || Decoder Loss:  0.0021626372 Validation Decoder Loss:  0.43683702
Encoder Loss:  0.034763075  || Decoder Loss:  0.0022104008 Validation Decoder Loss:  0.43127644
Encoder Loss:  0.034742266  || Decoder Loss:  0.0021534697 Validation Decoder Loss:  0.45385733
Encoder Loss:  0.034737185  || Decoder Loss:  0.0022435512 Validation Decoder Loss:  0.40922222
Encoder Loss:  0.03471548  || Decoder Loss:  0.0021006435 Validation Decoder Loss:  0.43343717
Encoder Loss:  0.03471906  || Decoder Loss:  0.0020859714 Validation Decoder Loss:  0.430273
Encoder Loss:  0.03468415  || Decoder Loss:  0.0020138337 Validation Decoder Loss:  0.4268349
Encoder Loss:  0.034673933  || Decoder Loss:  0.0019652653 Validation Decoder Loss:  0.42503417
Encoder Loss:  0.034645364  || Decoder Loss:  0.0018900328 Validation Decoder Loss:  0.39053208
Model: bold_synthesis_net_lr_0.0009567453897836338 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.39053208
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 2420, 16, 1)       189       
_________________________________________________________________
dropout_484 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 1820, 16, 1)       602       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_443"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 1910, 16, 1)       92        
_________________________________________________________________
dropout_486 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 2607, 16, 1)       699       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 2540, 16, 1)       69        
_________________________________________________________________
dropout_488 (Dropout)        (None, 2540, 16, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 1820, 16, 1)       722       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 2510, 16, 1)       692       
_________________________________________________________________
dropout_490 (Dropout)        (None, 2510, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 2607, 16, 1)       99        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 2140, 16, 1)       469       
_________________________________________________________________
dropout_492 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 1820, 16, 1)       322       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 1950, 16, 1)       132       
_________________________________________________________________
dropout_494 (Dropout)        (None, 1950, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 2607, 16, 1)       659       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_451"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 2290, 16, 1)       319       
_________________________________________________________________
dropout_496 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 1820, 16, 1)       472       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 2360, 16, 1)       542       
_________________________________________________________________
dropout_498 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 2607, 16, 1)       249       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 65, 24, 16, 1)     33        
_________________________________________________________________
dropout_500 (Dropout)        (None, 65, 24, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 65, 28, 16, 1)     6         
_________________________________________________________________
reshape_109 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_455"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 2350, 16, 1)       259       
_________________________________________________________________
dropout_502 (Dropout)        (None, 2350, 16, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 1820, 16, 1)       532       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 2290, 16, 1)       472       
_________________________________________________________________
dropout_504 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 2607, 16, 1)       319       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058757596  || Decoder Loss:  0.012020311 Validation Decoder Loss:  0.42757604
Encoder Loss:  0.05561478  || Decoder Loss:  0.010643148 Validation Decoder Loss:  0.4102611
Encoder Loss:  0.05244277  || Decoder Loss:  0.0092333965 Validation Decoder Loss:  0.37792903
Encoder Loss:  0.049825184  || Decoder Loss:  0.008676019 Validation Decoder Loss:  0.32393974
Encoder Loss:  0.047376294  || Decoder Loss:  0.007975777 Validation Decoder Loss:  0.29886323
Encoder Loss:  0.04595129  || Decoder Loss:  0.0069985483 Validation Decoder Loss:  0.29253435
Encoder Loss:  0.045350242  || Decoder Loss:  0.006563696 Validation Decoder Loss:  0.29368553
Encoder Loss:  0.044702936  || Decoder Loss:  0.0057652853 Validation Decoder Loss:  0.2957432
Encoder Loss:  0.043745205  || Decoder Loss:  0.0038729284 Validation Decoder Loss:  0.29204535
Encoder Loss:  0.043214347  || Decoder Loss:  0.003577425 Validation Decoder Loss:  0.2945866
Encoder Loss:  0.042679347  || Decoder Loss:  0.0036239808 Validation Decoder Loss:  0.29838884
Encoder Loss:  0.041951414  || Decoder Loss:  0.0035702374 Validation Decoder Loss:  0.30532402
Encoder Loss:  0.040900715  || Decoder Loss:  0.00334776 Validation Decoder Loss:  0.31014556
Encoder Loss:  0.039492883  || Decoder Loss:  0.0032028444 Validation Decoder Loss:  0.31918073
Encoder Loss:  0.037981555  || Decoder Loss:  0.0034764772 Validation Decoder Loss:  0.32556337
Encoder Loss:  0.0365817  || Decoder Loss:  0.0035986628 Validation Decoder Loss:  0.33251497
Encoder Loss:  0.03513303  || Decoder Loss:  0.00350055 Validation Decoder Loss:  0.3390553
Encoder Loss:  0.03380193  || Decoder Loss:  0.0033032862 Validation Decoder Loss:  0.33056933
Encoder Loss:  0.032647602  || Decoder Loss:  0.0031423597 Validation Decoder Loss:  0.31393206
Encoder Loss:  0.03157251  || Decoder Loss:  0.002964476 Validation Decoder Loss:  0.2885845
Encoder Loss:  0.030750621  || Decoder Loss:  0.0029404112 Validation Decoder Loss:  0.26298612
Encoder Loss:  0.030382382  || Decoder Loss:  0.0033234216 Validation Decoder Loss:  0.18381426
Encoder Loss:  0.03016035  || Decoder Loss:  0.0032954777 Validation Decoder Loss:  0.14182512
Encoder Loss:  0.029974176  || Decoder Loss:  0.003060745 Validation Decoder Loss:  0.13136601
Encoder Loss:  0.029871732  || Decoder Loss:  0.0029572248 Validation Decoder Loss:  0.1268962
Encoder Loss:  0.02982134  || Decoder Loss:  0.0030295285 Validation Decoder Loss:  0.13063043
Encoder Loss:  0.029760735  || Decoder Loss:  0.0030691794 Validation Decoder Loss:  0.13408288
Encoder Loss:  0.029661275  || Decoder Loss:  0.002952374 Validation Decoder Loss:  0.1401589
Encoder Loss:  0.029556021  || Decoder Loss:  0.002798038 Validation Decoder Loss:  0.14285651
Encoder Loss:  0.02942292  || Decoder Loss:  0.0025238683 Validation Decoder Loss:  0.1544297
Encoder Loss:  0.02931967  || Decoder Loss:  0.0023260242 Validation Decoder Loss:  0.15966262
Encoder Loss:  0.029250037  || Decoder Loss:  0.002218199 Validation Decoder Loss:  0.16043392
Encoder Loss:  0.029191596  || Decoder Loss:  0.0021384987 Validation Decoder Loss:  0.1594194
Encoder Loss:  0.029146831  || Decoder Loss:  0.002096992 Validation Decoder Loss:  0.15869239
Encoder Loss:  0.029095639  || Decoder Loss:  0.0020245542 Validation Decoder Loss:  0.15262413
Encoder Loss:  0.029041054  || Decoder Loss:  0.0019308887 Validation Decoder Loss:  0.15267321
Encoder Loss:  0.028997948  || Decoder Loss:  0.0018491094 Validation Decoder Loss:  0.14861746
Encoder Loss:  0.028949764  || Decoder Loss:  0.0017409188 Validation Decoder Loss:  0.14638132
Encoder Loss:  0.02891602  || Decoder Loss:  0.0016791077 Validation Decoder Loss:  0.14144373
Encoder Loss:  0.028866582  || Decoder Loss:  0.0016028922 Validation Decoder Loss:  0.13817146
Model: bold_synthesis_net_lr_0.0007989793730603181 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.13817146
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 2000, 16, 1)       609       
_________________________________________________________________
dropout_506 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 1820, 16, 1)       182       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_459"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 2130, 16, 1)       312       
_________________________________________________________________
dropout_508 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 2607, 16, 1)       479       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 1850, 16, 1)       759       
_________________________________________________________________
dropout_510 (Dropout)        (None, 1850, 16, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 1820, 16, 1)       32        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 2600, 16, 1)       782       
_________________________________________________________________
dropout_512 (Dropout)        (None, 2600, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 2607, 16, 1)       9         
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 2000, 16, 1)       609       
_________________________________________________________________
dropout_514 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 1820, 16, 1)       182       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 2140, 16, 1)       322       
_________________________________________________________________
dropout_516 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 2607, 16, 1)       469       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_467"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 1900, 16, 1)       709       
_________________________________________________________________
dropout_518 (Dropout)        (None, 1900, 16, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 1820, 16, 1)       82        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 2210, 16, 1)       392       
_________________________________________________________________
dropout_520 (Dropout)        (None, 2210, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 2607, 16, 1)       399       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 2560, 16, 1)       49        
_________________________________________________________________
dropout_522 (Dropout)        (None, 2560, 16, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 1820, 16, 1)       742       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_471"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 2380, 16, 1)       562       
_________________________________________________________________
dropout_524 (Dropout)        (None, 2380, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 2607, 16, 1)       229       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 65, 8, 16, 1)      9         
_________________________________________________________________
dropout_526 (Dropout)        (None, 65, 8, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 65, 28, 16, 1)     8         
_________________________________________________________________
reshape_110 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 2340, 16, 1)       269       
_________________________________________________________________
dropout_528 (Dropout)        (None, 2340, 16, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 1820, 16, 1)       522       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_475"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 2510, 16, 1)       692       
_________________________________________________________________
dropout_530 (Dropout)        (None, 2510, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 2607, 16, 1)       99        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06538267  || Decoder Loss:  0.0065351585 Validation Decoder Loss:  0.5464712
Encoder Loss:  0.061081216  || Decoder Loss:  0.006080751 Validation Decoder Loss:  0.5491351
Encoder Loss:  0.059228383  || Decoder Loss:  0.0060565406 Validation Decoder Loss:  0.5544896
Encoder Loss:  0.05708511  || Decoder Loss:  0.005925481 Validation Decoder Loss:  0.5658633
Encoder Loss:  0.05437984  || Decoder Loss:  0.005154116 Validation Decoder Loss:  0.5934665
Encoder Loss:  0.05182268  || Decoder Loss:  0.0044311066 Validation Decoder Loss:  0.62915415
Encoder Loss:  0.046611555  || Decoder Loss:  0.0046713287 Validation Decoder Loss:  0.7212815
Encoder Loss:  0.0391485  || Decoder Loss:  0.004811504 Validation Decoder Loss:  0.7611078
Encoder Loss:  0.03752185  || Decoder Loss:  0.0047557624 Validation Decoder Loss:  0.76101065
Encoder Loss:  0.036674526  || Decoder Loss:  0.0047067124 Validation Decoder Loss:  0.7609538
Encoder Loss:  0.035881434  || Decoder Loss:  0.004659975 Validation Decoder Loss:  0.7609051
Encoder Loss:  0.03533729  || Decoder Loss:  0.004616235 Validation Decoder Loss:  0.760854
Encoder Loss:  0.034950975  || Decoder Loss:  0.0045776702 Validation Decoder Loss:  0.7608015
Encoder Loss:  0.03462091  || Decoder Loss:  0.0045462586 Validation Decoder Loss:  0.7607515
Encoder Loss:  0.034354627  || Decoder Loss:  0.0045219725 Validation Decoder Loss:  0.7607046
Encoder Loss:  0.03414042  || Decoder Loss:  0.0045027216 Validation Decoder Loss:  0.7606572
Encoder Loss:  0.034007933  || Decoder Loss:  0.0044848705 Validation Decoder Loss:  0.76060426
Encoder Loss:  0.033956166  || Decoder Loss:  0.004471024 Validation Decoder Loss:  0.7605939
Encoder Loss:  0.033870872  || Decoder Loss:  0.004119522 Validation Decoder Loss:  0.75636905
Encoder Loss:  0.03379478  || Decoder Loss:  0.0037377435 Validation Decoder Loss:  0.7559896
Encoder Loss:  0.033764675  || Decoder Loss:  0.0037075179 Validation Decoder Loss:  0.75591975
Encoder Loss:  0.033744853  || Decoder Loss:  0.0036909066 Validation Decoder Loss:  0.7558185
Encoder Loss:  0.033703588  || Decoder Loss:  0.0035275137 Validation Decoder Loss:  0.715712
Encoder Loss:  0.033634055  || Decoder Loss:  0.0031371145 Validation Decoder Loss:  0.6381085
Encoder Loss:  0.033607893  || Decoder Loss:  0.0030119487 Validation Decoder Loss:  0.58311766
Encoder Loss:  0.033571642  || Decoder Loss:  0.0027999643 Validation Decoder Loss:  0.50675255
Encoder Loss:  0.03352458  || Decoder Loss:  0.0025409893 Validation Decoder Loss:  0.44204807
Encoder Loss:  0.033500012  || Decoder Loss:  0.002433187 Validation Decoder Loss:  0.4425786
Encoder Loss:  0.03347972  || Decoder Loss:  0.0023488721 Validation Decoder Loss:  0.4073378
Encoder Loss:  0.033460584  || Decoder Loss:  0.0022208446 Validation Decoder Loss:  0.40502918
Encoder Loss:  0.03343999  || Decoder Loss:  0.0021251298 Validation Decoder Loss:  0.37148118
Encoder Loss:  0.03341967  || Decoder Loss:  0.0020066523 Validation Decoder Loss:  0.37050363
Encoder Loss:  0.033405762  || Decoder Loss:  0.00194253 Validation Decoder Loss:  0.3411159
Encoder Loss:  0.033390664  || Decoder Loss:  0.0018741434 Validation Decoder Loss:  0.31319362
Encoder Loss:  0.0333702  || Decoder Loss:  0.0017761964 Validation Decoder Loss:  0.30707812
Encoder Loss:  0.033357643  || Decoder Loss:  0.001720621 Validation Decoder Loss:  0.2867939
Encoder Loss:  0.03335019  || Decoder Loss:  0.0016737597 Validation Decoder Loss:  0.2881616
Encoder Loss:  0.033341084  || Decoder Loss:  0.0016237004 Validation Decoder Loss:  0.27021223
Encoder Loss:  0.03333689  || Decoder Loss:  0.0016037958 Validation Decoder Loss:  0.24777544
Encoder Loss:  0.033327986  || Decoder Loss:  0.0015608198 Validation Decoder Loss:  0.26753682
Model: bold_synthesis_net_lr_0.0006425612395167177 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.26753682
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 2290, 16, 1)       319       
_________________________________________________________________
dropout_532 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 1820, 16, 1)       472       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 2320, 16, 1)       502       
_________________________________________________________________
dropout_534 (Dropout)        (None, 2320, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 2607, 16, 1)       289       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 2290, 16, 1)       319       
_________________________________________________________________
dropout_536 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 1820, 16, 1)       472       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 2290, 16, 1)       472       
_________________________________________________________________
dropout_538 (Dropout)        (None, 2290, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 2607, 16, 1)       319       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_483"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 1950, 16, 1)       659       
_________________________________________________________________
dropout_540 (Dropout)        (None, 1950, 16, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 1820, 16, 1)       132       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 2420, 16, 1)       602       
_________________________________________________________________
dropout_542 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 2607, 16, 1)       189       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 2360, 16, 1)       249       
_________________________________________________________________
dropout_544 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 1820, 16, 1)       542       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_487"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 2280, 16, 1)       462       
_________________________________________________________________
dropout_546 (Dropout)        (None, 2280, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 2607, 16, 1)       329       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 1890, 16, 1)       719       
_________________________________________________________________
dropout_548 (Dropout)        (None, 1890, 16, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 1820, 16, 1)       72        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 2400, 16, 1)       582       
_________________________________________________________________
dropout_550 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 2607, 16, 1)       209       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 2080, 16, 1)       529       
_________________________________________________________________
dropout_552 (Dropout)        (None, 2080, 16, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 1820, 16, 1)       262       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 2540, 16, 1)       722       
_________________________________________________________________
dropout_554 (Dropout)        (None, 2540, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 2607, 16, 1)       69        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_495"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 1940, 16, 1)       669       
_________________________________________________________________
dropout_556 (Dropout)        (None, 1940, 16, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 1820, 16, 1)       122       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 2020, 16, 1)       202       
_________________________________________________________________
dropout_558 (Dropout)        (None, 2020, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 2607, 16, 1)       589       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 1850, 16, 1)       759       
_________________________________________________________________
dropout_560 (Dropout)        (None, 1850, 16, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 1820, 16, 1)       32        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_499"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 2420, 16, 1)       602       
_________________________________________________________________
dropout_562 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 2607, 16, 1)       189       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 2390, 16, 1)       219       
_________________________________________________________________
dropout_564 (Dropout)        (None, 2390, 16, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 1820, 16, 1)       572       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 2060, 16, 1)       242       
_________________________________________________________________
dropout_566 (Dropout)        (None, 2060, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 2607, 16, 1)       549       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 2460, 16, 1)       149       
_________________________________________________________________
dropout_568 (Dropout)        (None, 2460, 16, 1)       0         
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 1820, 16, 1)       642       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 2150, 16, 1)       332       
_________________________________________________________________
dropout_570 (Dropout)        (None, 2150, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 2607, 16, 1)       459       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_507"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 2380, 16, 1)       229       
_________________________________________________________________
dropout_572 (Dropout)        (None, 2380, 16, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 1820, 16, 1)       562       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 2480, 16, 1)       662       
_________________________________________________________________
dropout_574 (Dropout)        (None, 2480, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 2607, 16, 1)       129       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 2380, 16, 1)       229       
_________________________________________________________________
dropout_576 (Dropout)        (None, 2380, 16, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 1820, 16, 1)       562       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_511"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 2050, 16, 1)       232       
_________________________________________________________________
dropout_578 (Dropout)        (None, 2050, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 2607, 16, 1)       559       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 2400, 16, 1)       209       
_________________________________________________________________
dropout_580 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 1820, 16, 1)       582       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 2500, 16, 1)       682       
_________________________________________________________________
dropout_582 (Dropout)        (None, 2500, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 2607, 16, 1)       109       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 2160, 16, 1)       449       
_________________________________________________________________
dropout_584 (Dropout)        (None, 2160, 16, 1)       0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 1820, 16, 1)       342       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 2090, 16, 1)       272       
_________________________________________________________________
dropout_586 (Dropout)        (None, 2090, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 2607, 16, 1)       519       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_519"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 2380, 16, 1)       229       
_________________________________________________________________
dropout_588 (Dropout)        (None, 2380, 16, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 1820, 16, 1)       562       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 2530, 16, 1)       712       
_________________________________________________________________
dropout_590 (Dropout)        (None, 2530, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 2607, 16, 1)       79        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 65, 16, 16, 1)     17        
_________________________________________________________________
dropout_592 (Dropout)        (None, 65, 16, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 65, 28, 16, 1)     14        
_________________________________________________________________
reshape_111 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_523"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 2440, 16, 1)       169       
_________________________________________________________________
dropout_594 (Dropout)        (None, 2440, 16, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 1820, 16, 1)       622       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 1910, 16, 1)       92        
_________________________________________________________________
dropout_596 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 2607, 16, 1)       699       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.026750661  || Decoder Loss:  0.009718179 Validation Decoder Loss:  0.45777184
Encoder Loss:  0.026679821  || Decoder Loss:  0.009793012 Validation Decoder Loss:  0.4553644
Encoder Loss:  0.02658493  || Decoder Loss:  0.009783824 Validation Decoder Loss:  0.4553773
Encoder Loss:  0.026351782  || Decoder Loss:  0.009598121 Validation Decoder Loss:  0.45614696
Encoder Loss:  0.026116665  || Decoder Loss:  0.009412179 Validation Decoder Loss:  0.4570376
Encoder Loss:  0.025882619  || Decoder Loss:  0.00921657 Validation Decoder Loss:  0.45797545
Encoder Loss:  0.025654657  || Decoder Loss:  0.00901195 Validation Decoder Loss:  0.45902884
Encoder Loss:  0.025441665  || Decoder Loss:  0.00881814 Validation Decoder Loss:  0.4600131
Encoder Loss:  0.025236761  || Decoder Loss:  0.008631375 Validation Decoder Loss:  0.4608059
Encoder Loss:  0.025049953  || Decoder Loss:  0.0084694475 Validation Decoder Loss:  0.4615365
Encoder Loss:  0.024831992  || Decoder Loss:  0.008268019 Validation Decoder Loss:  0.46231696
Encoder Loss:  0.024568664  || Decoder Loss:  0.008003745 Validation Decoder Loss:  0.4631667
Encoder Loss:  0.024323504  || Decoder Loss:  0.007765883 Validation Decoder Loss:  0.4636355
Encoder Loss:  0.024106868  || Decoder Loss:  0.007574734 Validation Decoder Loss:  0.4643934
Encoder Loss:  0.0239189  || Decoder Loss:  0.0074144024 Validation Decoder Loss:  0.4655481
Encoder Loss:  0.023759384  || Decoder Loss:  0.0072802575 Validation Decoder Loss:  0.46624237
Encoder Loss:  0.023620099  || Decoder Loss:  0.0071737114 Validation Decoder Loss:  0.46660036
Encoder Loss:  0.023499064  || Decoder Loss:  0.0071026837 Validation Decoder Loss:  0.46685505
Encoder Loss:  0.023398707  || Decoder Loss:  0.0070622405 Validation Decoder Loss:  0.46755064
Encoder Loss:  0.023300165  || Decoder Loss:  0.0070176534 Validation Decoder Loss:  0.46869642
Encoder Loss:  0.023180773  || Decoder Loss:  0.006955723 Validation Decoder Loss:  0.46985132
Encoder Loss:  0.023052547  || Decoder Loss:  0.0069118743 Validation Decoder Loss:  0.47023442
Encoder Loss:  0.022926172  || Decoder Loss:  0.0068814857 Validation Decoder Loss:  0.4717096
Encoder Loss:  0.022823019  || Decoder Loss:  0.006842546 Validation Decoder Loss:  0.47413707
Encoder Loss:  0.022668777  || Decoder Loss:  0.0067293094 Validation Decoder Loss:  0.47673175
Encoder Loss:  0.022514235  || Decoder Loss:  0.0066366647 Validation Decoder Loss:  0.47853357
Encoder Loss:  0.022392925  || Decoder Loss:  0.0065815295 Validation Decoder Loss:  0.48104727
Encoder Loss:  0.02229704  || Decoder Loss:  0.0065609985 Validation Decoder Loss:  0.48383826
Encoder Loss:  0.022224559  || Decoder Loss:  0.0065719937 Validation Decoder Loss:  0.48639023
Encoder Loss:  0.022130938  || Decoder Loss:  0.0065673543 Validation Decoder Loss:  0.48850095
Encoder Loss:  0.022035668  || Decoder Loss:  0.0065722936 Validation Decoder Loss:  0.4905562
Encoder Loss:  0.021906557  || Decoder Loss:  0.006544447 Validation Decoder Loss:  0.49209496
Encoder Loss:  0.021807697  || Decoder Loss:  0.0065303342 Validation Decoder Loss:  0.4936251
Encoder Loss:  0.021713156  || Decoder Loss:  0.0065272637 Validation Decoder Loss:  0.49500677
Encoder Loss:  0.021623958  || Decoder Loss:  0.0065204967 Validation Decoder Loss:  0.49638996
Encoder Loss:  0.021540709  || Decoder Loss:  0.0065133455 Validation Decoder Loss:  0.49809778
Encoder Loss:  0.02143956  || Decoder Loss:  0.0064806 Validation Decoder Loss:  0.49995667
Encoder Loss:  0.021354234  || Decoder Loss:  0.0064538373 Validation Decoder Loss:  0.5016494
Encoder Loss:  0.02127623  || Decoder Loss:  0.006431834 Validation Decoder Loss:  0.5033065
Encoder Loss:  0.021199679  || Decoder Loss:  0.0064128325 Validation Decoder Loss:  0.5051426
Model: bold_synthesis_net_lr_0.00029883631907402395 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.5051427
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 2140, 16, 1)       469       
_________________________________________________________________
dropout_598 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 1820, 16, 1)       322       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_527"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 2160, 16, 1)       342       
_________________________________________________________________
dropout_600 (Dropout)        (None, 2160, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 2607, 16, 1)       449       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 65, 8, 16, 1)      9         
_________________________________________________________________
dropout_602 (Dropout)        (None, 65, 8, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 65, 28, 16, 1)     8         
_________________________________________________________________
reshape_112 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 2330, 16, 1)       279       
_________________________________________________________________
dropout_604 (Dropout)        (None, 2330, 16, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 1820, 16, 1)       512       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_531"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 2530, 16, 1)       712       
_________________________________________________________________
dropout_606 (Dropout)        (None, 2530, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 2607, 16, 1)       79        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02884613  || Decoder Loss:  0.008134342 Validation Decoder Loss:  0.5692373
Encoder Loss:  0.025551487  || Decoder Loss:  0.006537227 Validation Decoder Loss:  0.5522692
Encoder Loss:  0.025150428  || Decoder Loss:  0.0063874 Validation Decoder Loss:  0.5513502
Encoder Loss:  0.024834722  || Decoder Loss:  0.0063199806 Validation Decoder Loss:  0.5521922
Encoder Loss:  0.024516273  || Decoder Loss:  0.006256852 Validation Decoder Loss:  0.55400264
Encoder Loss:  0.024259064  || Decoder Loss:  0.006211311 Validation Decoder Loss:  0.5550306
Encoder Loss:  0.024010032  || Decoder Loss:  0.006161837 Validation Decoder Loss:  0.5563963
Encoder Loss:  0.023780867  || Decoder Loss:  0.0061511565 Validation Decoder Loss:  0.5589436
Encoder Loss:  0.02353843  || Decoder Loss:  0.0061329897 Validation Decoder Loss:  0.5626012
Encoder Loss:  0.023246773  || Decoder Loss:  0.0060940916 Validation Decoder Loss:  0.56717026
Encoder Loss:  0.022997543  || Decoder Loss:  0.006056468 Validation Decoder Loss:  0.5716228
Encoder Loss:  0.022711536  || Decoder Loss:  0.005941694 Validation Decoder Loss:  0.5743487
Encoder Loss:  0.022389418  || Decoder Loss:  0.005755274 Validation Decoder Loss:  0.5758636
Encoder Loss:  0.022151582  || Decoder Loss:  0.005672214 Validation Decoder Loss:  0.57824093
Encoder Loss:  0.021901354  || Decoder Loss:  0.005590934 Validation Decoder Loss:  0.58173764
Encoder Loss:  0.021494051  || Decoder Loss:  0.0053511113 Validation Decoder Loss:  0.58597946
Encoder Loss:  0.020854061  || Decoder Loss:  0.004990953 Validation Decoder Loss:  0.593572
Encoder Loss:  0.02026937  || Decoder Loss:  0.004753815 Validation Decoder Loss:  0.60100996
Encoder Loss:  0.019499367  || Decoder Loss:  0.0044498835 Validation Decoder Loss:  0.6051222
Encoder Loss:  0.018834159  || Decoder Loss:  0.0042302026 Validation Decoder Loss:  0.6083858
Encoder Loss:  0.018388478  || Decoder Loss:  0.0041481233 Validation Decoder Loss:  0.6098309
Encoder Loss:  0.01799273  || Decoder Loss:  0.004160088 Validation Decoder Loss:  0.61115307
Encoder Loss:  0.017637756  || Decoder Loss:  0.0041855243 Validation Decoder Loss:  0.620867
Encoder Loss:  0.016995605  || Decoder Loss:  0.004220608 Validation Decoder Loss:  0.62431836
Encoder Loss:  0.016715854  || Decoder Loss:  0.0043351324 Validation Decoder Loss:  0.6385915
Encoder Loss:  0.016565884  || Decoder Loss:  0.004481626 Validation Decoder Loss:  0.6511129
Encoder Loss:  0.016497165  || Decoder Loss:  0.004665441 Validation Decoder Loss:  0.69064975
Encoder Loss:  0.016414044  || Decoder Loss:  0.0047593927 Validation Decoder Loss:  0.746635
Encoder Loss:  0.016285803  || Decoder Loss:  0.004747156 Validation Decoder Loss:  0.76106846
Encoder Loss:  0.016159628  || Decoder Loss:  0.0047278265 Validation Decoder Loss:  0.7610761
Encoder Loss:  0.016047684  || Decoder Loss:  0.0047113146 Validation Decoder Loss:  0.7610475
Encoder Loss:  0.015939463  || Decoder Loss:  0.004696836 Validation Decoder Loss:  0.7610261
Encoder Loss:  0.015831877  || Decoder Loss:  0.0046837605 Validation Decoder Loss:  0.7610089
Encoder Loss:  0.015727654  || Decoder Loss:  0.004671838 Validation Decoder Loss:  0.7609953
Encoder Loss:  0.015621806  || Decoder Loss:  0.004660979 Validation Decoder Loss:  0.76098394
Encoder Loss:  0.015511568  || Decoder Loss:  0.0046510785 Validation Decoder Loss:  0.7609741
Encoder Loss:  0.015401016  || Decoder Loss:  0.004642128 Validation Decoder Loss:  0.76096636
Encoder Loss:  0.015295009  || Decoder Loss:  0.0046340865 Validation Decoder Loss:  0.7609601
Encoder Loss:  0.015194587  || Decoder Loss:  0.004626881 Validation Decoder Loss:  0.76095545
Encoder Loss:  0.01510136  || Decoder Loss:  0.004620364 Validation Decoder Loss:  0.76095176
Model: bold_synthesis_net_lr_0.0007085613371884913 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.76095176
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 2450, 16, 1)       159       
_________________________________________________________________
dropout_608 (Dropout)        (None, 2450, 16, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 1820, 16, 1)       632       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 2030, 16, 1)       212       
_________________________________________________________________
dropout_610 (Dropout)        (None, 2030, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 2607, 16, 1)       579       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 2340, 16, 1)       269       
_________________________________________________________________
dropout_612 (Dropout)        (None, 2340, 16, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 1820, 16, 1)       522       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 2320, 16, 1)       502       
_________________________________________________________________
dropout_614 (Dropout)        (None, 2320, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 2607, 16, 1)       289       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_539"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 2310, 16, 1)       299       
_________________________________________________________________
dropout_616 (Dropout)        (None, 2310, 16, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 1820, 16, 1)       492       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 2340, 16, 1)       522       
_________________________________________________________________
dropout_618 (Dropout)        (None, 2340, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 2607, 16, 1)       269       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 2420, 16, 1)       189       
_________________________________________________________________
dropout_620 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 1820, 16, 1)       602       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_543"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 1930, 16, 1)       112       
_________________________________________________________________
dropout_622 (Dropout)        (None, 1930, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 2607, 16, 1)       679       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 2360, 16, 1)       249       
_________________________________________________________________
dropout_624 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 1820, 16, 1)       542       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 2250, 16, 1)       432       
_________________________________________________________________
dropout_626 (Dropout)        (None, 2250, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 2607, 16, 1)       359       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_547"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 65, 10, 16, 1)     5         
_________________________________________________________________
dropout_628 (Dropout)        (None, 65, 10, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 65, 28, 16, 1)     20        
_________________________________________________________________
reshape_113 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 25
Trainable params: 25
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 2140, 16, 1)       469       
_________________________________________________________________
dropout_630 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 1820, 16, 1)       322       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 2000, 16, 1)       182       
_________________________________________________________________
dropout_632 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 2607, 16, 1)       609       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.061235067  || Decoder Loss:  0.008803498 Validation Decoder Loss:  0.7186203
Encoder Loss:  0.061069272  || Decoder Loss:  0.008802998 Validation Decoder Loss:  0.71557975
Encoder Loss:  0.0609044  || Decoder Loss:  0.008802507 Validation Decoder Loss:  0.7122624
Encoder Loss:  0.060734168  || Decoder Loss:  0.008802019 Validation Decoder Loss:  0.7111034
Encoder Loss:  0.060535897  || Decoder Loss:  0.008801538 Validation Decoder Loss:  0.7089481
Encoder Loss:  0.06036782  || Decoder Loss:  0.00880106 Validation Decoder Loss:  0.7077277
Encoder Loss:  0.06020287  || Decoder Loss:  0.008800587 Validation Decoder Loss:  0.70626456
Encoder Loss:  0.060035266  || Decoder Loss:  0.008800117 Validation Decoder Loss:  0.7030426
Encoder Loss:  0.05986099  || Decoder Loss:  0.008799655 Validation Decoder Loss:  0.7019801
Encoder Loss:  0.059680335  || Decoder Loss:  0.008799196 Validation Decoder Loss:  0.6997254
Encoder Loss:  0.059495166  || Decoder Loss:  0.008798742 Validation Decoder Loss:  0.6971119
Encoder Loss:  0.059305836  || Decoder Loss:  0.008798293 Validation Decoder Loss:  0.69556093
Encoder Loss:  0.059119847  || Decoder Loss:  0.008797846 Validation Decoder Loss:  0.6938455
Encoder Loss:  0.058929283  || Decoder Loss:  0.008797406 Validation Decoder Loss:  0.6919666
Encoder Loss:  0.058732804  || Decoder Loss:  0.008796967 Validation Decoder Loss:  0.69097084
Encoder Loss:  0.05853065  || Decoder Loss:  0.008796531 Validation Decoder Loss:  0.6893583
Encoder Loss:  0.05831953  || Decoder Loss:  0.008796102 Validation Decoder Loss:  0.6869315
Encoder Loss:  0.058101162  || Decoder Loss:  0.008795678 Validation Decoder Loss:  0.6856509
Encoder Loss:  0.05787448  || Decoder Loss:  0.008795254 Validation Decoder Loss:  0.68414867
Encoder Loss:  0.05764356  || Decoder Loss:  0.008794839 Validation Decoder Loss:  0.682978
Encoder Loss:  0.05740759  || Decoder Loss:  0.008794424 Validation Decoder Loss:  0.6806619
Encoder Loss:  0.057169992  || Decoder Loss:  0.0087940125 Validation Decoder Loss:  0.6787605
Encoder Loss:  0.056933086  || Decoder Loss:  0.008793594 Validation Decoder Loss:  0.6767601
Encoder Loss:  0.05669643  || Decoder Loss:  0.008793914 Validation Decoder Loss:  0.6747246
Encoder Loss:  0.05645561  || Decoder Loss:  0.008792792 Validation Decoder Loss:  0.67106557
Encoder Loss:  0.056210462  || Decoder Loss:  0.008793021 Validation Decoder Loss:  0.6681515
Encoder Loss:  0.05596156  || Decoder Loss:  0.008792806 Validation Decoder Loss:  0.66873235
Encoder Loss:  0.055711247  || Decoder Loss:  0.008792234 Validation Decoder Loss:  0.6667206
Encoder Loss:  0.055466484  || Decoder Loss:  0.008791927 Validation Decoder Loss:  0.6660101
Encoder Loss:  0.055229664  || Decoder Loss:  0.008791587 Validation Decoder Loss:  0.6649802
Encoder Loss:  0.054996423  || Decoder Loss:  0.008791041 Validation Decoder Loss:  0.6620577
Encoder Loss:  0.054760855  || Decoder Loss:  0.008788953 Validation Decoder Loss:  0.6605772
Encoder Loss:  0.05452867  || Decoder Loss:  0.00878707 Validation Decoder Loss:  0.65980613
Encoder Loss:  0.054307576  || Decoder Loss:  0.008785575 Validation Decoder Loss:  0.657671
Encoder Loss:  0.054096315  || Decoder Loss:  0.008785374 Validation Decoder Loss:  0.6569887
Encoder Loss:  0.05389368  || Decoder Loss:  0.008783721 Validation Decoder Loss:  0.6558438
Encoder Loss:  0.053701136  || Decoder Loss:  0.008783592 Validation Decoder Loss:  0.6532599
Encoder Loss:  0.053521812  || Decoder Loss:  0.008784168 Validation Decoder Loss:  0.6516633
Encoder Loss:  0.05335852  || Decoder Loss:  0.008783246 Validation Decoder Loss:  0.65045804
Encoder Loss:  0.053213153  || Decoder Loss:  0.008781974 Validation Decoder Loss:  0.6494061
Model: bold_synthesis_net_lr_4.162807777527938e-05 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.6494061
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 2570, 16, 1)       39        
_________________________________________________________________
dropout_634 (Dropout)        (None, 2570, 16, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 1820, 16, 1)       752       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 2150, 16, 1)       332       
_________________________________________________________________
dropout_636 (Dropout)        (None, 2150, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 2607, 16, 1)       459       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 65, 6, 16, 1)      5         
_________________________________________________________________
dropout_638 (Dropout)        (None, 65, 6, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 65, 28, 16, 1)     24        
_________________________________________________________________
reshape_114 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 2130, 16, 1)       479       
_________________________________________________________________
dropout_640 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 1820, 16, 1)       312       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 2410, 16, 1)       592       
_________________________________________________________________
dropout_642 (Dropout)        (None, 2410, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 2607, 16, 1)       199       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.043804385  || Decoder Loss:  0.007620503 Validation Decoder Loss:  0.5702105
Encoder Loss:  0.0425318  || Decoder Loss:  0.0081583075 Validation Decoder Loss:  0.63342434
Encoder Loss:  0.041347966  || Decoder Loss:  0.008730836 Validation Decoder Loss:  0.7014785
Encoder Loss:  0.040223315  || Decoder Loss:  0.008718119 Validation Decoder Loss:  0.76473475
Encoder Loss:  0.03914355  || Decoder Loss:  0.00811499 Validation Decoder Loss:  0.76348305
Encoder Loss:  0.035143383  || Decoder Loss:  0.0042419937 Validation Decoder Loss:  0.7586451
Encoder Loss:  0.026504274  || Decoder Loss:  0.0043085567 Validation Decoder Loss:  0.73777795
Encoder Loss:  0.021954054  || Decoder Loss:  0.0038703838 Validation Decoder Loss:  0.64227265
Encoder Loss:  0.021205114  || Decoder Loss:  0.0027324872 Validation Decoder Loss:  0.56837803
Encoder Loss:  0.021070424  || Decoder Loss:  0.0024268448 Validation Decoder Loss:  0.41100097
Encoder Loss:  0.020692466  || Decoder Loss:  0.0017831093 Validation Decoder Loss:  0.29190606
Encoder Loss:  0.020497428  || Decoder Loss:  0.0014223941 Validation Decoder Loss:  0.2645436
Encoder Loss:  0.020481918  || Decoder Loss:  0.0012975875 Validation Decoder Loss:  0.2391887
Encoder Loss:  0.02040265  || Decoder Loss:  0.0011732026 Validation Decoder Loss:  0.22348368
Encoder Loss:  0.02033359  || Decoder Loss:  0.0011101748 Validation Decoder Loss:  0.21920519
Encoder Loss:  0.020308875  || Decoder Loss:  0.0010732607 Validation Decoder Loss:  0.20604122
Encoder Loss:  0.020298446  || Decoder Loss:  0.0010297948 Validation Decoder Loss:  0.21305878
Encoder Loss:  0.020295499  || Decoder Loss:  0.0009920468 Validation Decoder Loss:  0.19693285
Encoder Loss:  0.020280678  || Decoder Loss:  0.0009911575 Validation Decoder Loss:  0.20345159
Encoder Loss:  0.020270204  || Decoder Loss:  0.00095396786 Validation Decoder Loss:  0.1991526
Encoder Loss:  0.020248871  || Decoder Loss:  0.00094140775 Validation Decoder Loss:  0.18339029
Encoder Loss:  0.020176886  || Decoder Loss:  0.00092483504 Validation Decoder Loss:  0.19813603
Encoder Loss:  0.02023592  || Decoder Loss:  0.00088909524 Validation Decoder Loss:  0.17547214
Encoder Loss:  0.020219086  || Decoder Loss:  0.00089983764 Validation Decoder Loss:  0.17569605
Encoder Loss:  0.02022785  || Decoder Loss:  0.0008725554 Validation Decoder Loss:  0.16445553
Encoder Loss:  0.020144906  || Decoder Loss:  0.00084657065 Validation Decoder Loss:  0.16297364
Encoder Loss:  0.020214155  || Decoder Loss:  0.00084411 Validation Decoder Loss:  0.14721212
Encoder Loss:  0.02016473  || Decoder Loss:  0.00079114217 Validation Decoder Loss:  0.16098806
Encoder Loss:  0.020166453  || Decoder Loss:  0.0007617549 Validation Decoder Loss:  0.13506663
Encoder Loss:  0.020138714  || Decoder Loss:  0.0008055503 Validation Decoder Loss:  0.13132787
Encoder Loss:  0.020140618  || Decoder Loss:  0.00072435354 Validation Decoder Loss:  0.11920656
Encoder Loss:  0.020124253  || Decoder Loss:  0.0007756729 Validation Decoder Loss:  0.11434348
Encoder Loss:  0.02011994  || Decoder Loss:  0.00071745104 Validation Decoder Loss:  0.12015724
Encoder Loss:  0.020112617  || Decoder Loss:  0.0006725282 Validation Decoder Loss:  0.09357049
Encoder Loss:  0.020071553  || Decoder Loss:  0.0007059963 Validation Decoder Loss:  0.08784604
Encoder Loss:  0.020095794  || Decoder Loss:  0.00066707603 Validation Decoder Loss:  0.10357918
Encoder Loss:  0.020079827  || Decoder Loss:  0.00062231184 Validation Decoder Loss:  0.074241534
Encoder Loss:  0.02007187  || Decoder Loss:  0.0006314554 Validation Decoder Loss:  0.08074657
Encoder Loss:  0.020060154  || Decoder Loss:  0.00059763645 Validation Decoder Loss:  0.06614365
Encoder Loss:  0.020066347  || Decoder Loss:  0.00062318426 Validation Decoder Loss:  0.06861323
Model: bold_synthesis_net_lr_0.0009402965845054339 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.06861323
Model: "sequential_559"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 2320, 16, 1)       289       
_________________________________________________________________
dropout_644 (Dropout)        (None, 2320, 16, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 1820, 16, 1)       502       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 2550, 16, 1)       732       
_________________________________________________________________
dropout_646 (Dropout)        (None, 2550, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 2607, 16, 1)       59        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 65, 24, 16, 1)     33        
_________________________________________________________________
dropout_648 (Dropout)        (None, 65, 24, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 65, 28, 16, 1)     6         
_________________________________________________________________
reshape_115 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_563"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 1910, 16, 1)       699       
_________________________________________________________________
dropout_650 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 1820, 16, 1)       92        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 2020, 16, 1)       202       
_________________________________________________________________
dropout_652 (Dropout)        (None, 2020, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 2607, 16, 1)       589       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.061683416  || Decoder Loss:  0.009204731 Validation Decoder Loss:  0.52951807
Encoder Loss:  0.0519169  || Decoder Loss:  0.006164174 Validation Decoder Loss:  0.5406661
Encoder Loss:  0.045701616  || Decoder Loss:  0.005929567 Validation Decoder Loss:  0.48397195
Encoder Loss:  0.03767926  || Decoder Loss:  0.0055477195 Validation Decoder Loss:  0.5074158
Encoder Loss:  0.032017242  || Decoder Loss:  0.0041009965 Validation Decoder Loss:  0.49623573
Encoder Loss:  0.030051444  || Decoder Loss:  0.0033487412 Validation Decoder Loss:  0.5433843
Encoder Loss:  0.029597683  || Decoder Loss:  0.003285651 Validation Decoder Loss:  0.58175635
Encoder Loss:  0.029225167  || Decoder Loss:  0.0032389981 Validation Decoder Loss:  0.5848001
Encoder Loss:  0.028999608  || Decoder Loss:  0.0032011825 Validation Decoder Loss:  0.5781735
Encoder Loss:  0.02891973  || Decoder Loss:  0.0032382696 Validation Decoder Loss:  0.5834907
Encoder Loss:  0.02885061  || Decoder Loss:  0.0032039229 Validation Decoder Loss:  0.58942175
Encoder Loss:  0.028781168  || Decoder Loss:  0.0031468826 Validation Decoder Loss:  0.59507656
Encoder Loss:  0.028734896  || Decoder Loss:  0.003137136 Validation Decoder Loss:  0.59870917
Encoder Loss:  0.028681474  || Decoder Loss:  0.0030913064 Validation Decoder Loss:  0.596626
Encoder Loss:  0.028645065  || Decoder Loss:  0.0030499503 Validation Decoder Loss:  0.59637177
Encoder Loss:  0.028598862  || Decoder Loss:  0.00296838 Validation Decoder Loss:  0.5916858
Encoder Loss:  0.028552925  || Decoder Loss:  0.0028972556 Validation Decoder Loss:  0.5925729
Encoder Loss:  0.02851141  || Decoder Loss:  0.002826534 Validation Decoder Loss:  0.5890129
Encoder Loss:  0.028466992  || Decoder Loss:  0.0027611062 Validation Decoder Loss:  0.5764315
Encoder Loss:  0.028433723  || Decoder Loss:  0.002730109 Validation Decoder Loss:  0.56529135
Encoder Loss:  0.028402593  || Decoder Loss:  0.002683407 Validation Decoder Loss:  0.5641819
Encoder Loss:  0.028378222  || Decoder Loss:  0.0026493554 Validation Decoder Loss:  0.57106924
Encoder Loss:  0.028365733  || Decoder Loss:  0.0026330694 Validation Decoder Loss:  0.5660564
Encoder Loss:  0.028343786  || Decoder Loss:  0.002598484 Validation Decoder Loss:  0.5565353
Encoder Loss:  0.028321676  || Decoder Loss:  0.002566754 Validation Decoder Loss:  0.5462374
Encoder Loss:  0.02830583  || Decoder Loss:  0.0025469423 Validation Decoder Loss:  0.5524547
Encoder Loss:  0.028297143  || Decoder Loss:  0.0025326493 Validation Decoder Loss:  0.5483377
Encoder Loss:  0.028284658  || Decoder Loss:  0.002500533 Validation Decoder Loss:  0.5529576
Encoder Loss:  0.028274832  || Decoder Loss:  0.0024917943 Validation Decoder Loss:  0.54491746
Encoder Loss:  0.028264472  || Decoder Loss:  0.0024770834 Validation Decoder Loss:  0.54504603
Encoder Loss:  0.02825293  || Decoder Loss:  0.0024584215 Validation Decoder Loss:  0.53653765
Encoder Loss:  0.02824846  || Decoder Loss:  0.0024488417 Validation Decoder Loss:  0.5396291
Encoder Loss:  0.0282394  || Decoder Loss:  0.002435345 Validation Decoder Loss:  0.530751
Encoder Loss:  0.028233508  || Decoder Loss:  0.0024327312 Validation Decoder Loss:  0.5283216
Encoder Loss:  0.028222784  || Decoder Loss:  0.002414612 Validation Decoder Loss:  0.52453375
Encoder Loss:  0.028216656  || Decoder Loss:  0.002410031 Validation Decoder Loss:  0.5298318
Encoder Loss:  0.02820746  || Decoder Loss:  0.0023953505 Validation Decoder Loss:  0.5226613
Encoder Loss:  0.0282  || Decoder Loss:  0.002383792 Validation Decoder Loss:  0.5221356
Encoder Loss:  0.028193567  || Decoder Loss:  0.0023734681 Validation Decoder Loss:  0.51815665
Encoder Loss:  0.028182039  || Decoder Loss:  0.0023476186 Validation Decoder Loss:  0.51965266
Model: bold_synthesis_net_lr_0.0006312088075035166 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.51965266
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 65, 8, 16, 1)      9         
_________________________________________________________________
dropout_654 (Dropout)        (None, 65, 8, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 65, 28, 16, 1)     15        
_________________________________________________________________
reshape_116 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_567"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 2340, 16, 1)       269       
_________________________________________________________________
dropout_656 (Dropout)        (None, 2340, 16, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 1820, 16, 1)       522       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 2490, 16, 1)       672       
_________________________________________________________________
dropout_658 (Dropout)        (None, 2490, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 2607, 16, 1)       119       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.02638436  || Decoder Loss:  0.0067218323 Validation Decoder Loss:  0.49171203
Encoder Loss:  0.026078047  || Decoder Loss:  0.0070931334 Validation Decoder Loss:  0.48723602
Encoder Loss:  0.02542612  || Decoder Loss:  0.0068234685 Validation Decoder Loss:  0.4935419
Encoder Loss:  0.024920091  || Decoder Loss:  0.0065937964 Validation Decoder Loss:  0.4990541
Encoder Loss:  0.024573507  || Decoder Loss:  0.0065065934 Validation Decoder Loss:  0.5019195
Encoder Loss:  0.02423247  || Decoder Loss:  0.006385488 Validation Decoder Loss:  0.50354016
Encoder Loss:  0.023967868  || Decoder Loss:  0.00627981 Validation Decoder Loss:  0.50651336
Encoder Loss:  0.023724495  || Decoder Loss:  0.006204637 Validation Decoder Loss:  0.5094756
Encoder Loss:  0.02347739  || Decoder Loss:  0.0061060437 Validation Decoder Loss:  0.51211894
Encoder Loss:  0.023258671  || Decoder Loss:  0.006035153 Validation Decoder Loss:  0.5139051
Encoder Loss:  0.023017813  || Decoder Loss:  0.005933005 Validation Decoder Loss:  0.5151026
Encoder Loss:  0.022652581  || Decoder Loss:  0.0057124333 Validation Decoder Loss:  0.51634884
Encoder Loss:  0.022246016  || Decoder Loss:  0.0054278355 Validation Decoder Loss:  0.517059
Encoder Loss:  0.021866033  || Decoder Loss:  0.0052674403 Validation Decoder Loss:  0.5189946
Encoder Loss:  0.02145433  || Decoder Loss:  0.0050951717 Validation Decoder Loss:  0.5219768
Encoder Loss:  0.020941839  || Decoder Loss:  0.0048312205 Validation Decoder Loss:  0.5266723
Encoder Loss:  0.020372804  || Decoder Loss:  0.0044990005 Validation Decoder Loss:  0.5309233
Encoder Loss:  0.019864755  || Decoder Loss:  0.0042164284 Validation Decoder Loss:  0.5352473
Encoder Loss:  0.019455628  || Decoder Loss:  0.004069497 Validation Decoder Loss:  0.53903455
Encoder Loss:  0.01900995  || Decoder Loss:  0.0039058607 Validation Decoder Loss:  0.5445753
Encoder Loss:  0.018516291  || Decoder Loss:  0.0037153885 Validation Decoder Loss:  0.54872847
Encoder Loss:  0.018109784  || Decoder Loss:  0.0036318444 Validation Decoder Loss:  0.55217814
Encoder Loss:  0.017725322  || Decoder Loss:  0.0036091132 Validation Decoder Loss:  0.5558789
Encoder Loss:  0.017299015  || Decoder Loss:  0.003585098 Validation Decoder Loss:  0.5600953
Encoder Loss:  0.016834367  || Decoder Loss:  0.0035628753 Validation Decoder Loss:  0.5592593
Encoder Loss:  0.01633186  || Decoder Loss:  0.0035169253 Validation Decoder Loss:  0.5565281
Encoder Loss:  0.015848849  || Decoder Loss:  0.0034832181 Validation Decoder Loss:  0.5537205
Encoder Loss:  0.015396189  || Decoder Loss:  0.0034791369 Validation Decoder Loss:  0.5550745
Encoder Loss:  0.014949083  || Decoder Loss:  0.003463736 Validation Decoder Loss:  0.5561936
Encoder Loss:  0.014523161  || Decoder Loss:  0.0034556554 Validation Decoder Loss:  0.5642954
Encoder Loss:  0.014055162  || Decoder Loss:  0.0033706517 Validation Decoder Loss:  0.5349961
Encoder Loss:  0.013636244  || Decoder Loss:  0.003318744 Validation Decoder Loss:  0.48954722
Encoder Loss:  0.0133349355  || Decoder Loss:  0.0033997868 Validation Decoder Loss:  0.24395064
Encoder Loss:  0.013179717  || Decoder Loss:  0.0034653642 Validation Decoder Loss:  0.18212327
Encoder Loss:  0.012898346  || Decoder Loss:  0.003149229 Validation Decoder Loss:  0.2607304
Encoder Loss:  0.012842277  || Decoder Loss:  0.0031160247 Validation Decoder Loss:  0.29474038
Encoder Loss:  0.012515501  || Decoder Loss:  0.0026949733 Validation Decoder Loss:  0.2913111
Encoder Loss:  0.012271615  || Decoder Loss:  0.002380539 Validation Decoder Loss:  0.30094743
Encoder Loss:  0.012144462  || Decoder Loss:  0.0022216982 Validation Decoder Loss:  0.3018903
Encoder Loss:  0.012041494  || Decoder Loss:  0.0020949387 Validation Decoder Loss:  0.28846586
Model: bold_synthesis_net_lr_0.0002175561522989398 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.28846586
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 2350, 16, 1)       259       
_________________________________________________________________
dropout_660 (Dropout)        (None, 2350, 16, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 1820, 16, 1)       532       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_571"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 2510, 16, 1)       692       
_________________________________________________________________
dropout_662 (Dropout)        (None, 2510, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 2607, 16, 1)       99        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 2370, 16, 1)       239       
_________________________________________________________________
dropout_664 (Dropout)        (None, 2370, 16, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 1820, 16, 1)       552       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 2520, 16, 1)       702       
_________________________________________________________________
dropout_666 (Dropout)        (None, 2520, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 2607, 16, 1)       89        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 2130, 16, 1)       479       
_________________________________________________________________
dropout_668 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 1820, 16, 1)       312       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 2030, 16, 1)       212       
_________________________________________________________________
dropout_670 (Dropout)        (None, 2030, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 2607, 16, 1)       579       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_579"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_272 (Conv2D)          (None, 2310, 16, 1)       299       
_________________________________________________________________
dropout_672 (Dropout)        (None, 2310, 16, 1)       0         
_________________________________________________________________
conv2d_273 (Conv2D)          (None, 1820, 16, 1)       492       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_272 (Conv2D (None, 2500, 16, 1)       682       
_________________________________________________________________
dropout_674 (Dropout)        (None, 2500, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_273 (Conv2D (None, 2607, 16, 1)       109       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 65, 8, 16, 1)      9         
_________________________________________________________________
dropout_676 (Dropout)        (None, 65, 8, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 65, 28, 16, 1)     15        
_________________________________________________________________
reshape_117 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_583"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_274 (Conv2D)          (None, 2350, 16, 1)       259       
_________________________________________________________________
dropout_678 (Dropout)        (None, 2350, 16, 1)       0         
_________________________________________________________________
conv2d_275 (Conv2D)          (None, 1820, 16, 1)       532       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_274 (Conv2D (None, 2480, 16, 1)       662       
_________________________________________________________________
dropout_680 (Dropout)        (None, 2480, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_275 (Conv2D (None, 2607, 16, 1)       129       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.018081777  || Decoder Loss:  0.0067101475 Validation Decoder Loss:  0.52894026
Encoder Loss:  0.018014228  || Decoder Loss:  0.006749556 Validation Decoder Loss:  0.52338445
Encoder Loss:  0.018003076  || Decoder Loss:  0.0068329447 Validation Decoder Loss:  0.5182565
Encoder Loss:  0.018035071  || Decoder Loss:  0.0069382982 Validation Decoder Loss:  0.5127901
Encoder Loss:  0.01807507  || Decoder Loss:  0.0070368215 Validation Decoder Loss:  0.5095649
Encoder Loss:  0.018072264  || Decoder Loss:  0.007081151 Validation Decoder Loss:  0.50680643
Encoder Loss:  0.018135794  || Decoder Loss:  0.007198941 Validation Decoder Loss:  0.5035584
Encoder Loss:  0.01815656  || Decoder Loss:  0.0072619654 Validation Decoder Loss:  0.50118256
Encoder Loss:  0.018172715  || Decoder Loss:  0.0073245 Validation Decoder Loss:  0.49866116
Encoder Loss:  0.018362433  || Decoder Loss:  0.007582819 Validation Decoder Loss:  0.4958877
Encoder Loss:  0.018408475  || Decoder Loss:  0.0076673618 Validation Decoder Loss:  0.4932273
Encoder Loss:  0.018405827  || Decoder Loss:  0.0076957066 Validation Decoder Loss:  0.49080998
Encoder Loss:  0.018357024  || Decoder Loss:  0.0076668705 Validation Decoder Loss:  0.48912933
Encoder Loss:  0.018358216  || Decoder Loss:  0.007696582 Validation Decoder Loss:  0.48768425
Encoder Loss:  0.018366555  || Decoder Loss:  0.007733818 Validation Decoder Loss:  0.4861123
Encoder Loss:  0.018354705  || Decoder Loss:  0.007749083 Validation Decoder Loss:  0.48482642
Encoder Loss:  0.018313335  || Decoder Loss:  0.007730103 Validation Decoder Loss:  0.4841762
Encoder Loss:  0.018257285  || Decoder Loss:  0.0076917014 Validation Decoder Loss:  0.48356175
Encoder Loss:  0.018220618  || Decoder Loss:  0.0076750102 Validation Decoder Loss:  0.4830687
Encoder Loss:  0.018189276  || Decoder Loss:  0.0076661166 Validation Decoder Loss:  0.48255327
Encoder Loss:  0.018142125  || Decoder Loss:  0.007640359 Validation Decoder Loss:  0.48207927
Encoder Loss:  0.01808111  || Decoder Loss:  0.007599566 Validation Decoder Loss:  0.4815284
Encoder Loss:  0.018035837  || Decoder Loss:  0.0075797033 Validation Decoder Loss:  0.4809546
Encoder Loss:  0.018020755  || Decoder Loss:  0.007595731 Validation Decoder Loss:  0.48000586
Encoder Loss:  0.017990064  || Decoder Loss:  0.007594105 Validation Decoder Loss:  0.47914654
Encoder Loss:  0.017956061  || Decoder Loss:  0.007583544 Validation Decoder Loss:  0.47828293
Encoder Loss:  0.017953858  || Decoder Loss:  0.0076089986 Validation Decoder Loss:  0.4775251
Encoder Loss:  0.017950354  || Decoder Loss:  0.007632383 Validation Decoder Loss:  0.47693253
Encoder Loss:  0.01792778  || Decoder Loss:  0.0076333284 Validation Decoder Loss:  0.47617257
Encoder Loss:  0.017907793  || Decoder Loss:  0.0076370332 Validation Decoder Loss:  0.47567493
Encoder Loss:  0.017870773  || Decoder Loss:  0.0076193586 Validation Decoder Loss:  0.47533906
Encoder Loss:  0.017827285  || Decoder Loss:  0.0075938273 Validation Decoder Loss:  0.47506276
Encoder Loss:  0.01778161  || Decoder Loss:  0.00756402 Validation Decoder Loss:  0.47495556
Encoder Loss:  0.017729092  || Decoder Loss:  0.0075236354 Validation Decoder Loss:  0.474967
Encoder Loss:  0.017674219  || Decoder Loss:  0.007480898 Validation Decoder Loss:  0.4749421
Encoder Loss:  0.01762074  || Decoder Loss:  0.007440111 Validation Decoder Loss:  0.4749189
Encoder Loss:  0.017572524  || Decoder Loss:  0.00740504 Validation Decoder Loss:  0.47493616
Encoder Loss:  0.017525973  || Decoder Loss:  0.0073750755 Validation Decoder Loss:  0.474991
Encoder Loss:  0.01748032  || Decoder Loss:  0.007348144 Validation Decoder Loss:  0.47502252
Encoder Loss:  0.017439276  || Decoder Loss:  0.007322916 Validation Decoder Loss:  0.4750085
Model: bold_synthesis_net_lr_3.004710402327799e-05 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.47500852
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_276 (Conv2D)          (None, 2360, 16, 1)       249       
_________________________________________________________________
dropout_682 (Dropout)        (None, 2360, 16, 1)       0         
_________________________________________________________________
conv2d_277 (Conv2D)          (None, 1820, 16, 1)       542       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_587"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_276 (Conv2D (None, 2060, 16, 1)       242       
_________________________________________________________________
dropout_684 (Dropout)        (None, 2060, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_277 (Conv2D (None, 2607, 16, 1)       549       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_278 (Conv2D)          (None, 2370, 16, 1)       239       
_________________________________________________________________
dropout_686 (Dropout)        (None, 2370, 16, 1)       0         
_________________________________________________________________
conv2d_279 (Conv2D)          (None, 1820, 16, 1)       552       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_278 (Conv2D (None, 2300, 16, 1)       482       
_________________________________________________________________
dropout_688 (Dropout)        (None, 2300, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_279 (Conv2D (None, 2607, 16, 1)       309       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_280 (Conv2D)          (None, 2140, 16, 1)       469       
_________________________________________________________________
dropout_690 (Dropout)        (None, 2140, 16, 1)       0         
_________________________________________________________________
conv2d_281 (Conv2D)          (None, 1820, 16, 1)       322       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_280 (Conv2D (None, 2400, 16, 1)       582       
_________________________________________________________________
dropout_692 (Dropout)        (None, 2400, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_281 (Conv2D (None, 2607, 16, 1)       209       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_595"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_282 (Conv2D)          (None, 2170, 16, 1)       439       
_________________________________________________________________
dropout_694 (Dropout)        (None, 2170, 16, 1)       0         
_________________________________________________________________
conv2d_283 (Conv2D)          (None, 1820, 16, 1)       352       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_282 (Conv2D (None, 2260, 16, 1)       442       
_________________________________________________________________
dropout_696 (Dropout)        (None, 2260, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_283 (Conv2D (None, 2607, 16, 1)       349       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_284 (Conv2D)          (None, 2570, 16, 1)       39        
_________________________________________________________________
dropout_698 (Dropout)        (None, 2570, 16, 1)       0         
_________________________________________________________________
conv2d_285 (Conv2D)          (None, 1820, 16, 1)       752       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_599"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_284 (Conv2D (None, 2410, 16, 1)       592       
_________________________________________________________________
dropout_700 (Dropout)        (None, 2410, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_285 (Conv2D (None, 2607, 16, 1)       199       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_286 (Conv2D)          (None, 2130, 16, 1)       479       
_________________________________________________________________
dropout_702 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_287 (Conv2D)          (None, 1820, 16, 1)       312       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_286 (Conv2D (None, 2000, 16, 1)       182       
_________________________________________________________________
dropout_704 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_287 (Conv2D (None, 2607, 16, 1)       609       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_288 (Conv2D)          (None, 1950, 16, 1)       659       
_________________________________________________________________
dropout_706 (Dropout)        (None, 1950, 16, 1)       0         
_________________________________________________________________
conv2d_289 (Conv2D)          (None, 1820, 16, 1)       132       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_288 (Conv2D (None, 2200, 16, 1)       382       
_________________________________________________________________
dropout_708 (Dropout)        (None, 2200, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_289 (Conv2D (None, 2607, 16, 1)       409       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 64, 10, 16, 1)     3         
_________________________________________________________________
dropout_710 (Dropout)        (None, 64, 10, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 65, 28, 16, 1)     39        
_________________________________________________________________
reshape_118 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 42
Trainable params: 42
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_608"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_290 (Conv2D)          (None, 2160, 16, 1)       449       
_________________________________________________________________
dropout_712 (Dropout)        (None, 2160, 16, 1)       0         
_________________________________________________________________
conv2d_291 (Conv2D)          (None, 1820, 16, 1)       342       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_290 (Conv2D (None, 2020, 16, 1)       202       
_________________________________________________________________
dropout_714 (Dropout)        (None, 2020, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_291 (Conv2D (None, 2607, 16, 1)       589       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.018235203  || Decoder Loss:  0.008783536 Validation Decoder Loss:  0.76474124
Encoder Loss:  0.01793084  || Decoder Loss:  0.008779814 Validation Decoder Loss:  0.7647312
Encoder Loss:  0.01754441  || Decoder Loss:  0.008776385 Validation Decoder Loss:  0.76472217
Encoder Loss:  0.017160617  || Decoder Loss:  0.008773223 Validation Decoder Loss:  0.7647139
Encoder Loss:  0.016815094  || Decoder Loss:  0.008770302 Validation Decoder Loss:  0.76470625
Encoder Loss:  0.016553218  || Decoder Loss:  0.008767572 Validation Decoder Loss:  0.76470196
Encoder Loss:  0.016377185  || Decoder Loss:  0.008765011 Validation Decoder Loss:  0.7646701
Encoder Loss:  0.016244598  || Decoder Loss:  0.008762596 Validation Decoder Loss:  0.7637329
Encoder Loss:  0.016146839  || Decoder Loss:  0.008760312 Validation Decoder Loss:  0.7629906
Encoder Loss:  0.016078666  || Decoder Loss:  0.008758111 Validation Decoder Loss:  0.7627032
Encoder Loss:  0.016037134  || Decoder Loss:  0.008755979 Validation Decoder Loss:  0.7627839
Encoder Loss:  0.016000677  || Decoder Loss:  0.008753949 Validation Decoder Loss:  0.7629852
Encoder Loss:  0.015965814  || Decoder Loss:  0.008752018 Validation Decoder Loss:  0.76317763
Encoder Loss:  0.015932925  || Decoder Loss:  0.008750176 Validation Decoder Loss:  0.76369274
Encoder Loss:  0.01590025  || Decoder Loss:  0.008748415 Validation Decoder Loss:  0.76465017
Encoder Loss:  0.015868839  || Decoder Loss:  0.008746736 Validation Decoder Loss:  0.76464427
Encoder Loss:  0.015838308  || Decoder Loss:  0.008745125 Validation Decoder Loss:  0.7646404
Encoder Loss:  0.015806539  || Decoder Loss:  0.008743571 Validation Decoder Loss:  0.7646371
Encoder Loss:  0.015774034  || Decoder Loss:  0.00874206 Validation Decoder Loss:  0.7646344
Encoder Loss:  0.015742425  || Decoder Loss:  0.008740571 Validation Decoder Loss:  0.7646322
Encoder Loss:  0.01571252  || Decoder Loss:  0.008739091 Validation Decoder Loss:  0.76463044
Encoder Loss:  0.015684564  || Decoder Loss:  0.0087375855 Validation Decoder Loss:  0.7646294
Encoder Loss:  0.015657099  || Decoder Loss:  0.008736034 Validation Decoder Loss:  0.7646291
Encoder Loss:  0.015629314  || Decoder Loss:  0.008734384 Validation Decoder Loss:  0.76462966
Encoder Loss:  0.015601901  || Decoder Loss:  0.008732579 Validation Decoder Loss:  0.7646313
Encoder Loss:  0.015573881  || Decoder Loss:  0.008730533 Validation Decoder Loss:  0.7646345
Encoder Loss:  0.015544575  || Decoder Loss:  0.0087281065 Validation Decoder Loss:  0.76463985
Encoder Loss:  0.0155140795  || Decoder Loss:  0.008725101 Validation Decoder Loss:  0.76464814
Encoder Loss:  0.015481425  || Decoder Loss:  0.0087211775 Validation Decoder Loss:  0.7646608
Encoder Loss:  0.015446252  || Decoder Loss:  0.008715752 Validation Decoder Loss:  0.76468074
Encoder Loss:  0.015406798  || Decoder Loss:  0.008707733 Validation Decoder Loss:  0.76471263
Encoder Loss:  0.015358009  || Decoder Loss:  0.008694908 Validation Decoder Loss:  0.76476616
Encoder Loss:  0.015291579  || Decoder Loss:  0.008672676 Validation Decoder Loss:  0.76485723
Encoder Loss:  0.015198416  || Decoder Loss:  0.008632118 Validation Decoder Loss:  0.76500595
Encoder Loss:  0.015063876  || Decoder Loss:  0.008559923 Validation Decoder Loss:  0.7652128
Encoder Loss:  0.014873779  || Decoder Loss:  0.008448052 Validation Decoder Loss:  0.7654291
Encoder Loss:  0.014632079  || Decoder Loss:  0.008309494 Validation Decoder Loss:  0.76561034
Encoder Loss:  0.014329645  || Decoder Loss:  0.008147321 Validation Decoder Loss:  0.7658169
Encoder Loss:  0.013833611  || Decoder Loss:  0.007828413 Validation Decoder Loss:  0.7660966
Encoder Loss:  0.012790638  || Decoder Loss:  0.006977992 Validation Decoder Loss:  0.76567197
Model: bold_synthesis_net_lr_0.00017293322475265456 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.76567197
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 65, 20, 16, 1)     17        
_________________________________________________________________
dropout_716 (Dropout)        (None, 65, 20, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 65, 28, 16, 1)     10        
_________________________________________________________________
reshape_119 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_612"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_292 (Conv2D)          (None, 2350, 16, 1)       259       
_________________________________________________________________
dropout_718 (Dropout)        (None, 2350, 16, 1)       0         
_________________________________________________________________
conv2d_293 (Conv2D)          (None, 1820, 16, 1)       532       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_292 (Conv2D (None, 2130, 16, 1)       312       
_________________________________________________________________
dropout_720 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_293 (Conv2D (None, 2607, 16, 1)       479       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06569987  || Decoder Loss:  0.0066566993 Validation Decoder Loss:  0.5254846
Encoder Loss:  0.06356888  || Decoder Loss:  0.0068810275 Validation Decoder Loss:  0.514946
Encoder Loss:  0.062362008  || Decoder Loss:  0.007354916 Validation Decoder Loss:  0.50674266
Encoder Loss:  0.061540984  || Decoder Loss:  0.007734993 Validation Decoder Loss:  0.49644846
Encoder Loss:  0.06102061  || Decoder Loss:  0.008090958 Validation Decoder Loss:  0.48929426
Encoder Loss:  0.060688537  || Decoder Loss:  0.00845656 Validation Decoder Loss:  0.4812664
Encoder Loss:  0.060403682  || Decoder Loss:  0.00851016 Validation Decoder Loss:  0.4748578
Encoder Loss:  0.060248554  || Decoder Loss:  0.0087015955 Validation Decoder Loss:  0.47020048
Encoder Loss:  0.060064584  || Decoder Loss:  0.008719184 Validation Decoder Loss:  0.46624005
Encoder Loss:  0.059907723  || Decoder Loss:  0.008737819 Validation Decoder Loss:  0.46401823
Encoder Loss:  0.05971213  || Decoder Loss:  0.008690349 Validation Decoder Loss:  0.46296364
Encoder Loss:  0.0594869  || Decoder Loss:  0.008570704 Validation Decoder Loss:  0.46310192
Encoder Loss:  0.059209965  || Decoder Loss:  0.0084365085 Validation Decoder Loss:  0.46326852
Encoder Loss:  0.058950413  || Decoder Loss:  0.008339347 Validation Decoder Loss:  0.46411276
Encoder Loss:  0.058695063  || Decoder Loss:  0.008245286 Validation Decoder Loss:  0.46510917
Encoder Loss:  0.058431406  || Decoder Loss:  0.008120492 Validation Decoder Loss:  0.46697903
Encoder Loss:  0.058166448  || Decoder Loss:  0.007983136 Validation Decoder Loss:  0.46883127
Encoder Loss:  0.057874516  || Decoder Loss:  0.0077912197 Validation Decoder Loss:  0.47080815
Encoder Loss:  0.057597857  || Decoder Loss:  0.0075948304 Validation Decoder Loss:  0.47257835
Encoder Loss:  0.057362743  || Decoder Loss:  0.007433322 Validation Decoder Loss:  0.4751542
Encoder Loss:  0.057142634  || Decoder Loss:  0.0072955047 Validation Decoder Loss:  0.47769955
Encoder Loss:  0.056950882  || Decoder Loss:  0.0072282124 Validation Decoder Loss:  0.47955972
Encoder Loss:  0.056783922  || Decoder Loss:  0.0071743615 Validation Decoder Loss:  0.48115483
Encoder Loss:  0.056608852  || Decoder Loss:  0.0070916438 Validation Decoder Loss:  0.4823867
Encoder Loss:  0.056428358  || Decoder Loss:  0.007005892 Validation Decoder Loss:  0.48299298
Encoder Loss:  0.05627175  || Decoder Loss:  0.0069681313 Validation Decoder Loss:  0.48360592
Encoder Loss:  0.056124706  || Decoder Loss:  0.006946834 Validation Decoder Loss:  0.48460805
Encoder Loss:  0.055987623  || Decoder Loss:  0.006932084 Validation Decoder Loss:  0.48554462
Encoder Loss:  0.055853333  || Decoder Loss:  0.0068933466 Validation Decoder Loss:  0.4865287
Encoder Loss:  0.055713464  || Decoder Loss:  0.0068427543 Validation Decoder Loss:  0.4877614
Encoder Loss:  0.05556438  || Decoder Loss:  0.0067864805 Validation Decoder Loss:  0.48882475
Encoder Loss:  0.055414274  || Decoder Loss:  0.006746022 Validation Decoder Loss:  0.4901211
Encoder Loss:  0.05523503  || Decoder Loss:  0.0067003393 Validation Decoder Loss:  0.49146944
Encoder Loss:  0.05503789  || Decoder Loss:  0.0066555236 Validation Decoder Loss:  0.4923429
Encoder Loss:  0.054862574  || Decoder Loss:  0.0066200355 Validation Decoder Loss:  0.49281496
Encoder Loss:  0.054719258  || Decoder Loss:  0.006596329 Validation Decoder Loss:  0.4933501
Encoder Loss:  0.05458364  || Decoder Loss:  0.0065842504 Validation Decoder Loss:  0.49384242
Encoder Loss:  0.05444869  || Decoder Loss:  0.006572041 Validation Decoder Loss:  0.49428707
Encoder Loss:  0.054331627  || Decoder Loss:  0.0065633575 Validation Decoder Loss:  0.49465984
Encoder Loss:  0.054221574  || Decoder Loss:  0.006547583 Validation Decoder Loss:  0.4950348
Model: bold_synthesis_net_lr_0.00012126314682431134 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.4950348
Model: "sequential_615"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_294 (Conv2D)          (None, 1910, 16, 1)       699       
_________________________________________________________________
dropout_722 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_295 (Conv2D)          (None, 1820, 16, 1)       92        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_294 (Conv2D (None, 2000, 16, 1)       182       
_________________________________________________________________
dropout_724 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_295 (Conv2D (None, 2607, 16, 1)       609       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 65, 16, 16, 1)     17        
_________________________________________________________________
dropout_726 (Dropout)        (None, 65, 16, 16, 1)     0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 65, 28, 16, 1)     14        
_________________________________________________________________
reshape_120 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_619"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_296 (Conv2D)          (None, 2420, 16, 1)       189       
_________________________________________________________________
dropout_728 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_297 (Conv2D)          (None, 1820, 16, 1)       602       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_296 (Conv2D (None, 1920, 16, 1)       102       
_________________________________________________________________
dropout_730 (Dropout)        (None, 1920, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_297 (Conv2D (None, 2607, 16, 1)       689       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03731193  || Decoder Loss:  0.009412273 Validation Decoder Loss:  0.44233888
Encoder Loss:  0.036247015  || Decoder Loss:  0.008912003 Validation Decoder Loss:  0.45817333
Encoder Loss:  0.034557063  || Decoder Loss:  0.0078493 Validation Decoder Loss:  0.45703024
Encoder Loss:  0.03334909  || Decoder Loss:  0.007133287 Validation Decoder Loss:  0.4595006
Encoder Loss:  0.032549698  || Decoder Loss:  0.0068098586 Validation Decoder Loss:  0.4693454
Encoder Loss:  0.031906784  || Decoder Loss:  0.0066825757 Validation Decoder Loss:  0.48133427
Encoder Loss:  0.03122597  || Decoder Loss:  0.006474642 Validation Decoder Loss:  0.49549142
Encoder Loss:  0.030673757  || Decoder Loss:  0.006413655 Validation Decoder Loss:  0.5061814
Encoder Loss:  0.030131418  || Decoder Loss:  0.0063663414 Validation Decoder Loss:  0.5172646
Encoder Loss:  0.029542323  || Decoder Loss:  0.006396168 Validation Decoder Loss:  0.52748597
Encoder Loss:  0.028767457  || Decoder Loss:  0.0064065293 Validation Decoder Loss:  0.5379882
Encoder Loss:  0.027831167  || Decoder Loss:  0.0064786905 Validation Decoder Loss:  0.55189943
Encoder Loss:  0.02657017  || Decoder Loss:  0.006452602 Validation Decoder Loss:  0.5713755
Encoder Loss:  0.025162324  || Decoder Loss:  0.0064343773 Validation Decoder Loss:  0.5905578
Encoder Loss:  0.023813331  || Decoder Loss:  0.0064674155 Validation Decoder Loss:  0.61663055
Encoder Loss:  0.022191452  || Decoder Loss:  0.0057565426 Validation Decoder Loss:  0.65716124
Encoder Loss:  0.020551762  || Decoder Loss:  0.0044395514 Validation Decoder Loss:  0.6420021
Encoder Loss:  0.019756457  || Decoder Loss:  0.0041357684 Validation Decoder Loss:  0.5513668
Encoder Loss:  0.019221876  || Decoder Loss:  0.0035718023 Validation Decoder Loss:  0.46787578
Encoder Loss:  0.019041738  || Decoder Loss:  0.003330266 Validation Decoder Loss:  0.42999452
Encoder Loss:  0.01894101  || Decoder Loss:  0.0031986258 Validation Decoder Loss:  0.4280607
Encoder Loss:  0.018865405  || Decoder Loss:  0.0030958997 Validation Decoder Loss:  0.41734445
Encoder Loss:  0.018831983  || Decoder Loss:  0.0030643488 Validation Decoder Loss:  0.40942493
Encoder Loss:  0.018797072  || Decoder Loss:  0.0030307188 Validation Decoder Loss:  0.38770506
Encoder Loss:  0.01874843  || Decoder Loss:  0.0029671225 Validation Decoder Loss:  0.38361764
Encoder Loss:  0.018692097  || Decoder Loss:  0.0028922032 Validation Decoder Loss:  0.3927549
Encoder Loss:  0.0186338  || Decoder Loss:  0.0028109564 Validation Decoder Loss:  0.35903746
Encoder Loss:  0.018564852  || Decoder Loss:  0.0027136945 Validation Decoder Loss:  0.35348383
Encoder Loss:  0.018502185  || Decoder Loss:  0.0026222016 Validation Decoder Loss:  0.35286373
Encoder Loss:  0.018443696  || Decoder Loss:  0.0025424862 Validation Decoder Loss:  0.34602916
Encoder Loss:  0.01842098  || Decoder Loss:  0.0025190474 Validation Decoder Loss:  0.3444182
Encoder Loss:  0.018392913  || Decoder Loss:  0.002485561 Validation Decoder Loss:  0.3385644
Encoder Loss:  0.018350746  || Decoder Loss:  0.002428456 Validation Decoder Loss:  0.3347385
Encoder Loss:  0.01831412  || Decoder Loss:  0.002377112 Validation Decoder Loss:  0.31823793
Encoder Loss:  0.018272828  || Decoder Loss:  0.0023169403 Validation Decoder Loss:  0.30756518
Encoder Loss:  0.018236745  || Decoder Loss:  0.0022634815 Validation Decoder Loss:  0.29643938
Encoder Loss:  0.018218206  || Decoder Loss:  0.0022405677 Validation Decoder Loss:  0.29521006
Encoder Loss:  0.018184943  || Decoder Loss:  0.0021932188 Validation Decoder Loss:  0.2936639
Encoder Loss:  0.018164592  || Decoder Loss:  0.002165615 Validation Decoder Loss:  0.28959146
Encoder Loss:  0.018141478  || Decoder Loss:  0.0021342393 Validation Decoder Loss:  0.2834897
Model: bold_synthesis_net_lr_0.0008701250216798988 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.2834897
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 2190, 16, 1)       419       
_________________________________________________________________
dropout_732 (Dropout)        (None, 2190, 16, 1)       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 1820, 16, 1)       372       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_623"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_298 (Conv2D (None, 2460, 16, 1)       642       
_________________________________________________________________
dropout_734 (Dropout)        (None, 2460, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_299 (Conv2D (None, 2607, 16, 1)       149       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_300 (Conv2D)          (None, 2420, 16, 1)       189       
_________________________________________________________________
dropout_736 (Dropout)        (None, 2420, 16, 1)       0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 1820, 16, 1)       602       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_626"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_300 (Conv2D (None, 2080, 16, 1)       262       
_________________________________________________________________
dropout_738 (Dropout)        (None, 2080, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_301 (Conv2D (None, 2607, 16, 1)       529       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_302 (Conv2D)          (None, 2430, 16, 1)       179       
_________________________________________________________________
dropout_740 (Dropout)        (None, 2430, 16, 1)       0         
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 1820, 16, 1)       612       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_302 (Conv2D (None, 1920, 16, 1)       102       
_________________________________________________________________
dropout_742 (Dropout)        (None, 1920, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_303 (Conv2D (None, 2607, 16, 1)       689       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_631"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_304 (Conv2D)          (None, 2390, 16, 1)       219       
_________________________________________________________________
dropout_744 (Dropout)        (None, 2390, 16, 1)       0         
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 1820, 16, 1)       572       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_304 (Conv2D (None, 1910, 16, 1)       92        
_________________________________________________________________
dropout_746 (Dropout)        (None, 1910, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_305 (Conv2D (None, 2607, 16, 1)       699       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_634"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_306 (Conv2D)          (None, 2170, 16, 1)       439       
_________________________________________________________________
dropout_748 (Dropout)        (None, 2170, 16, 1)       0         
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 1820, 16, 1)       352       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_635"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_306 (Conv2D (None, 2000, 16, 1)       182       
_________________________________________________________________
dropout_750 (Dropout)        (None, 2000, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_307 (Conv2D (None, 2607, 16, 1)       609       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_308 (Conv2D)          (None, 2330, 16, 1)       279       
_________________________________________________________________
dropout_752 (Dropout)        (None, 2330, 16, 1)       0         
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 1820, 16, 1)       512       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_638"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_308 (Conv2D (None, 2130, 16, 1)       312       
_________________________________________________________________
dropout_754 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_309 (Conv2D (None, 2607, 16, 1)       479       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_639"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 65, 6, 16, 1)      5         
_________________________________________________________________
dropout_756 (Dropout)        (None, 65, 6, 16, 1)      0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 65, 28, 16, 1)     14        
_________________________________________________________________
reshape_121 (Reshape)        (None, 1820, 16, 1)       0         
=================================================================
Total params: 19
Trainable params: 19
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_310 (Conv2D)          (None, 2130, 16, 1)       479       
_________________________________________________________________
dropout_758 (Dropout)        (None, 2130, 16, 1)       0         
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 1820, 16, 1)       312       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_642"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_310 (Conv2D (None, 2410, 16, 1)       592       
_________________________________________________________________
dropout_760 (Dropout)        (None, 2410, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_311 (Conv2D (None, 2607, 16, 1)       199       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.043685336  || Decoder Loss:  0.008595097 Validation Decoder Loss:  0.60036236
Encoder Loss:  0.041940458  || Decoder Loss:  0.008234944 Validation Decoder Loss:  0.6083205
Encoder Loss:  0.040931758  || Decoder Loss:  0.008133754 Validation Decoder Loss:  0.6115807
Encoder Loss:  0.040032603  || Decoder Loss:  0.007994979 Validation Decoder Loss:  0.6103064
Encoder Loss:  0.03896828  || Decoder Loss:  0.007528582 Validation Decoder Loss:  0.60984993
Encoder Loss:  0.036924437  || Decoder Loss:  0.0057820133 Validation Decoder Loss:  0.6089515
Encoder Loss:  0.03374662  || Decoder Loss:  0.0038138197 Validation Decoder Loss:  0.6338301
Encoder Loss:  0.027569026  || Decoder Loss:  0.0036916141 Validation Decoder Loss:  0.31301692
Encoder Loss:  0.021531705  || Decoder Loss:  0.0031721771 Validation Decoder Loss:  0.15246701
Encoder Loss:  0.020917919  || Decoder Loss:  0.001934358 Validation Decoder Loss:  0.15208606
Encoder Loss:  0.020554673  || Decoder Loss:  0.0012482202 Validation Decoder Loss:  0.10252856
Encoder Loss:  0.020505251  || Decoder Loss:  0.001139647 Validation Decoder Loss:  0.10287486
Encoder Loss:  0.020310884  || Decoder Loss:  0.0008636562 Validation Decoder Loss:  0.08285068
Encoder Loss:  0.020361658  || Decoder Loss:  0.0008873994 Validation Decoder Loss:  0.06892
Encoder Loss:  0.020306313  || Decoder Loss:  0.0007999678 Validation Decoder Loss:  0.0741466
Encoder Loss:  0.020292085  || Decoder Loss:  0.0007635608 Validation Decoder Loss:  0.060011208
Encoder Loss:  0.02023953  || Decoder Loss:  0.00070022 Validation Decoder Loss:  0.05011403
Encoder Loss:  0.02023157  || Decoder Loss:  0.00068274676 Validation Decoder Loss:  0.054982968
Encoder Loss:  0.020187804  || Decoder Loss:  0.00062091555 Validation Decoder Loss:  0.053217847
Encoder Loss:  0.020192515  || Decoder Loss:  0.00062756415 Validation Decoder Loss:  0.052492373
Encoder Loss:  0.020185836  || Decoder Loss:  0.0006268661 Validation Decoder Loss:  0.05161141
Encoder Loss:  0.02019585  || Decoder Loss:  0.00064016395 Validation Decoder Loss:  0.04540727
Encoder Loss:  0.020204483  || Decoder Loss:  0.0006692421 Validation Decoder Loss:  0.051748414
Encoder Loss:  0.02016301  || Decoder Loss:  0.00060238317 Validation Decoder Loss:  0.045959063
Encoder Loss:  0.020184748  || Decoder Loss:  0.0006517702 Validation Decoder Loss:  0.04178969
Encoder Loss:  0.020156752  || Decoder Loss:  0.0006071148 Validation Decoder Loss:  0.043399848
Encoder Loss:  0.020156937  || Decoder Loss:  0.0006007841 Validation Decoder Loss:  0.043397922
Encoder Loss:  0.020088889  || Decoder Loss:  0.000534498 Validation Decoder Loss:  0.045592606
Encoder Loss:  0.020117383  || Decoder Loss:  0.0005718365 Validation Decoder Loss:  0.03898514
Encoder Loss:  0.020127628  || Decoder Loss:  0.0005917583 Validation Decoder Loss:  0.040820383
Encoder Loss:  0.020088864  || Decoder Loss:  0.0005312487 Validation Decoder Loss:  0.04243224
Encoder Loss:  0.020078057  || Decoder Loss:  0.0005052258 Validation Decoder Loss:  0.04285093
Encoder Loss:  0.020034367  || Decoder Loss:  0.00046624703 Validation Decoder Loss:  0.039790124
Encoder Loss:  0.020060107  || Decoder Loss:  0.00049423025 Validation Decoder Loss:  0.036433347
Encoder Loss:  0.020107774  || Decoder Loss:  0.0005558992 Validation Decoder Loss:  0.043023344
Encoder Loss:  0.020066183  || Decoder Loss:  0.0004918965 Validation Decoder Loss:  0.03882336
Encoder Loss:  0.020015936  || Decoder Loss:  0.00044375917 Validation Decoder Loss:  0.0364578
Encoder Loss:  0.02005884  || Decoder Loss:  0.00049672596 Validation Decoder Loss:  0.035696037
Encoder Loss:  0.020072766  || Decoder Loss:  0.0005142357 Validation Decoder Loss:  0.04057978
Encoder Loss:  0.02003583  || Decoder Loss:  0.00047328247 Validation Decoder Loss:  0.033648588
Model: bold_synthesis_net_lr_0.0009402966384863515 Train Intances: 2704 | Validation Instances: 64 | Validation Loss: 0.03364859
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_312 (Conv2D)          (None, 2120, 16, 1)       489       
_________________________________________________________________
dropout_762 (Dropout)        (None, 2120, 16, 1)       0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 1820, 16, 1)       302       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_312 (Conv2D (None, 2390, 16, 1)       572       
_________________________________________________________________
dropout_764 (Dropout)        (None, 2390, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_313 (Conv2D (None, 2607, 16, 1)       219       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_647"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_314 (Conv2D)          (None, 1900, 16, 1)       709       
_________________________________________________________________
dropout_766 (Dropout)        (None, 1900, 16, 1)       0         
_________________________________________________________________
conv2d_315 (Conv2D)          (None, 1820, 16, 1)       82        
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_314 (Conv2D (None, 2040, 16, 1)       222       
_________________________________________________________________
dropout_768 (Dropout)        (None, 2040, 16, 1)       0         
_________________________________________________________________
conv2d_transpose_315 (Conv2D (None, 2607, 16, 1)       569       
=================================================================
Total params: 791
Trainable params: 791
Non-trainable params: 0
_________________________________________________________________
None
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.04061190038919449 2
[(65, 28, 16, 1)] [(1820, 16, 1)]
[(1820, 16, 1)] [(1820, 16, 1)]
[(2607, 16, 1)] [(1820, 16, 1)]
