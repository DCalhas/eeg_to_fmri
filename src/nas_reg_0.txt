Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-18 10:11:33.020144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-18 10:11:33.038736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-18 10:11:33.038906: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-18 10:11:33.040028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-18 10:11:33.041169: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-18 10:11:33.041380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-18 10:11:33.042335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-18 10:11:33.042842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-18 10:11:33.044880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-18 10:11:33.046017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-18 10:11:33.046232: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-18 10:11:33.067875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-18 10:11:33.068943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56293a032a30 executing computations on platform Host. Devices:
2019-11-18 10:11:33.068985: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-18 10:11:33.071000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-18 10:11:33.071055: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-18 10:11:33.071080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-18 10:11:33.071103: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-18 10:11:33.071126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-18 10:11:33.071149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-18 10:11:33.071171: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-18 10:11:33.071194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-18 10:11:33.074877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-18 10:11:33.074938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-18 10:11:33.285501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-18 10:11:33.285528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-18 10:11:33.285533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-18 10:11:33.287254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-18 10:11:33.288653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562940988bd0 executing computations on platform CUDA. Devices:
2019-11-18 10:11:33.288672: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-18 10:11:33.662223: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 3245, 20)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 340, 8, 20, 1)     101       
_________________________________________________________________
reshape (Reshape)            (None, 2720, 20, 1)       0         
=================================================================
Total params: 101
Trainable params: 101
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 2720, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 3245, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5572828  || Decoder Loss:  0.945562 Validation Decoder Loss:  1.6431391
Encoder Loss:  0.56194353  || Decoder Loss:  0.9537684 Validation Decoder Loss:  1.6431894
Encoder Loss:  0.54982954  || Decoder Loss:  0.95392334 Validation Decoder Loss:  1.6431991
Encoder Loss:  0.55033565  || Decoder Loss:  0.95410746 Validation Decoder Loss:  1.6431305
Encoder Loss:  0.5301299  || Decoder Loss:  0.95369804 Validation Decoder Loss:  1.6427019
Encoder Loss:  0.422233  || Decoder Loss:  0.9087715 Validation Decoder Loss:  0.6942539
Encoder Loss:  0.14797324  || Decoder Loss:  0.3709884 Validation Decoder Loss:  1.3103664
Encoder Loss:  0.15923567  || Decoder Loss:  0.46734902 Validation Decoder Loss:  1.3148057
Encoder Loss:  0.1549925  || Decoder Loss:  0.45778367 Validation Decoder Loss:  1.2869606
Encoder Loss:  0.1455977  || Decoder Loss:  0.43031216 Validation Decoder Loss:  1.0062318
Encoder Loss:  0.12921335  || Decoder Loss:  0.3677928 Validation Decoder Loss:  1.0887709
Encoder Loss:  0.08597969  || Decoder Loss:  0.17396946 Validation Decoder Loss:  0.44587386
Encoder Loss:  0.06326015  || Decoder Loss:  0.07598847 Validation Decoder Loss:  0.37090883
Encoder Loss:  0.05868474  || Decoder Loss:  0.05663749 Validation Decoder Loss:  0.39184192
Encoder Loss:  0.056953665  || Decoder Loss:  0.051815394 Validation Decoder Loss:  0.35072795
Encoder Loss:  0.05251893  || Decoder Loss:  0.04121688 Validation Decoder Loss:  0.35328954
Encoder Loss:  0.054283664  || Decoder Loss:  0.042981196 Validation Decoder Loss:  0.3749389
Encoder Loss:  0.055959657  || Decoder Loss:  0.04664534 Validation Decoder Loss:  0.36746454
Encoder Loss:  0.05231873  || Decoder Loss:  0.044187278 Validation Decoder Loss:  0.358437
Encoder Loss:  0.050528675  || Decoder Loss:  0.040703095 Validation Decoder Loss:  0.3719759
Encoder Loss:  0.050749768  || Decoder Loss:  0.041208528 Validation Decoder Loss:  0.37496626
Encoder Loss:  0.053855125  || Decoder Loss:  0.043517638 Validation Decoder Loss:  0.37453896
Encoder Loss:  0.059199516  || Decoder Loss:  0.047357306 Validation Decoder Loss:  0.3581856
Encoder Loss:  0.053464986  || Decoder Loss:  0.042823963 Validation Decoder Loss:  0.3585497
Encoder Loss:  0.05712795  || Decoder Loss:  0.04466096 Validation Decoder Loss:  0.3581013
Encoder Loss:  0.06518177  || Decoder Loss:  0.095065154 Validation Decoder Loss:  0.3551048
Encoder Loss:  0.06677603  || Decoder Loss:  0.0832324 Validation Decoder Loss:  0.3597048
Encoder Loss:  0.05708728  || Decoder Loss:  0.040681366 Validation Decoder Loss:  0.35504898
Encoder Loss:  0.05073186  || Decoder Loss:  0.033571552 Validation Decoder Loss:  0.35451537
Encoder Loss:  0.051670242  || Decoder Loss:  0.035665154 Validation Decoder Loss:  0.35602564
Encoder Loss:  0.050086945  || Decoder Loss:  0.03512354 Validation Decoder Loss:  0.36756003
Encoder Loss:  0.051762685  || Decoder Loss:  0.04197885 Validation Decoder Loss:  0.36828604
Encoder Loss:  0.053324126  || Decoder Loss:  0.03790324 Validation Decoder Loss:  0.38254
Encoder Loss:  0.054877438  || Decoder Loss:  0.04500644 Validation Decoder Loss:  0.37419373
Encoder Loss:  0.054764032  || Decoder Loss:  0.04469156 Validation Decoder Loss:  0.36798096
Encoder Loss:  0.053828295  || Decoder Loss:  0.040726136 Validation Decoder Loss:  0.35289788
Encoder Loss:  0.055133834  || Decoder Loss:  0.033902284 Validation Decoder Loss:  0.35918468
Encoder Loss:  0.055078316  || Decoder Loss:  0.036967494 Validation Decoder Loss:  0.3636778
Encoder Loss:  0.052554287  || Decoder Loss:  0.039353576 Validation Decoder Loss:  0.36535496
Encoder Loss:  0.050680064  || Decoder Loss:  0.038492467 Validation Decoder Loss:  0.3509196
Model: siamese_net_lr_0.07395834850501057 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3509196
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 187, 10, 20, 1)    123       
_________________________________________________________________
reshape_1 (Reshape)          (None, 1870, 20, 1)       0         
=================================================================
Total params: 123
Trainable params: 123
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 1870, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 3245, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22454724  || Decoder Loss:  0.16809082 Validation Decoder Loss:  0.3633011
Encoder Loss:  0.08003416  || Decoder Loss:  0.040583488 Validation Decoder Loss:  0.34762168
Encoder Loss:  0.06981848  || Decoder Loss:  0.03472479 Validation Decoder Loss:  0.3541121
Encoder Loss:  0.06688809  || Decoder Loss:  0.033690616 Validation Decoder Loss:  0.34575322
Encoder Loss:  0.07096829  || Decoder Loss:  0.033354852 Validation Decoder Loss:  0.34787542
Encoder Loss:  0.058617827  || Decoder Loss:  0.033134066 Validation Decoder Loss:  0.35133028
Encoder Loss:  0.05979166  || Decoder Loss:  0.034100223 Validation Decoder Loss:  0.35050327
Encoder Loss:  0.061602842  || Decoder Loss:  0.032804716 Validation Decoder Loss:  0.36047375
Encoder Loss:  0.059295963  || Decoder Loss:  0.03723369 Validation Decoder Loss:  0.35124475
Encoder Loss:  0.067391664  || Decoder Loss:  0.03528555 Validation Decoder Loss:  0.34645295
Encoder Loss:  0.057131186  || Decoder Loss:  0.032843385 Validation Decoder Loss:  0.34807807
Encoder Loss:  0.060570076  || Decoder Loss:  0.03433115 Validation Decoder Loss:  0.34998992
Encoder Loss:  0.0601867  || Decoder Loss:  0.036543787 Validation Decoder Loss:  0.3445444
Encoder Loss:  0.057522487  || Decoder Loss:  0.03361568 Validation Decoder Loss:  0.3509264
Encoder Loss:  0.0563087  || Decoder Loss:  0.033530843 Validation Decoder Loss:  0.3525653
Encoder Loss:  0.055019893  || Decoder Loss:  0.03344201 Validation Decoder Loss:  0.34848377
Encoder Loss:  0.056415558  || Decoder Loss:  0.03239185 Validation Decoder Loss:  0.34030834
Encoder Loss:  0.061975244  || Decoder Loss:  0.03282532 Validation Decoder Loss:  0.34154177
Encoder Loss:  0.07404667  || Decoder Loss:  0.034617107 Validation Decoder Loss:  0.35289633
Encoder Loss:  0.058715235  || Decoder Loss:  0.034891874 Validation Decoder Loss:  0.3533401
Encoder Loss:  0.055449568  || Decoder Loss:  0.03367906 Validation Decoder Loss:  0.3501833
Encoder Loss:  0.056589793  || Decoder Loss:  0.032301985 Validation Decoder Loss:  0.347788
Encoder Loss:  0.05248155  || Decoder Loss:  0.03401985 Validation Decoder Loss:  0.35440144
Encoder Loss:  0.053678814  || Decoder Loss:  0.03445312 Validation Decoder Loss:  0.3479479
Encoder Loss:  0.05473788  || Decoder Loss:  0.033095136 Validation Decoder Loss:  0.35210848
Encoder Loss:  0.057130456  || Decoder Loss:  0.03217978 Validation Decoder Loss:  0.34630662
Encoder Loss:  0.05482678  || Decoder Loss:  0.032717876 Validation Decoder Loss:  0.35164374
Encoder Loss:  0.055267703  || Decoder Loss:  0.034067396 Validation Decoder Loss:  0.35286456
Encoder Loss:  0.056747187  || Decoder Loss:  0.033802 Validation Decoder Loss:  0.34302193
Encoder Loss:  0.06741167  || Decoder Loss:  0.0344607 Validation Decoder Loss:  0.34426343
Encoder Loss:  0.054738022  || Decoder Loss:  0.032842483 Validation Decoder Loss:  0.3481702
Encoder Loss:  0.053818528  || Decoder Loss:  0.03378916 Validation Decoder Loss:  0.34443247
Encoder Loss:  0.055393506  || Decoder Loss:  0.032346826 Validation Decoder Loss:  0.3495323
Encoder Loss:  0.05260592  || Decoder Loss:  0.032409146 Validation Decoder Loss:  0.35077283
Encoder Loss:  0.05777623  || Decoder Loss:  0.032537773 Validation Decoder Loss:  0.353661
Encoder Loss:  0.058602482  || Decoder Loss:  0.03307446 Validation Decoder Loss:  0.3541879
Encoder Loss:  0.055011235  || Decoder Loss:  0.033908762 Validation Decoder Loss:  0.34745088
Encoder Loss:  0.053485416  || Decoder Loss:  0.033855636 Validation Decoder Loss:  0.34471387
Encoder Loss:  0.054154035  || Decoder Loss:  0.033486594 Validation Decoder Loss:  0.34328413
Encoder Loss:  0.05820062  || Decoder Loss:  0.03289254 Validation Decoder Loss:  0.35433003
Model: siamese_net_lr_0.005148801460182516 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35433003
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_2 (Reshape)          (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3779464  || Decoder Loss:  0.17738211 Validation Decoder Loss:  0.36415982
Encoder Loss:  0.39006653  || Decoder Loss:  0.05800298 Validation Decoder Loss:  0.36036
Encoder Loss:  0.28294995  || Decoder Loss:  0.357346 Validation Decoder Loss:  0.88967365
Encoder Loss:  0.101778835  || Decoder Loss:  0.33479115 Validation Decoder Loss:  0.5106143
Encoder Loss:  0.103670426  || Decoder Loss:  0.42241055 Validation Decoder Loss:  0.7646748
Encoder Loss:  0.10400226  || Decoder Loss:  0.44866902 Validation Decoder Loss:  0.96624506
Encoder Loss:  0.10214111  || Decoder Loss:  0.4045895 Validation Decoder Loss:  0.9602219
Encoder Loss:  0.084681235  || Decoder Loss:  0.32541886 Validation Decoder Loss:  0.38508892
Encoder Loss:  0.0640815  || Decoder Loss:  0.09364823 Validation Decoder Loss:  0.41764218
Encoder Loss:  0.059304923  || Decoder Loss:  0.06351718 Validation Decoder Loss:  0.39929152
Encoder Loss:  0.07304049  || Decoder Loss:  0.07220263 Validation Decoder Loss:  0.40375704
Encoder Loss:  0.07069549  || Decoder Loss:  0.052283965 Validation Decoder Loss:  0.35298532
Encoder Loss:  0.059016466  || Decoder Loss:  0.035620283 Validation Decoder Loss:  0.34788346
Encoder Loss:  0.057692558  || Decoder Loss:  0.03336047 Validation Decoder Loss:  0.34756446
Encoder Loss:  0.053604227  || Decoder Loss:  0.033048097 Validation Decoder Loss:  0.34972894
Encoder Loss:  0.06177206  || Decoder Loss:  0.03314262 Validation Decoder Loss:  0.34952646
Encoder Loss:  0.053652417  || Decoder Loss:  0.033015948 Validation Decoder Loss:  0.3479798
Encoder Loss:  0.054600313  || Decoder Loss:  0.032906894 Validation Decoder Loss:  0.34781957
Encoder Loss:  0.05548251  || Decoder Loss:  0.033100337 Validation Decoder Loss:  0.34813195
Encoder Loss:  0.055074774  || Decoder Loss:  0.03396947 Validation Decoder Loss:  0.3486615
Encoder Loss:  0.055566687  || Decoder Loss:  0.033912413 Validation Decoder Loss:  0.35611156
Encoder Loss:  0.059169818  || Decoder Loss:  0.037051853 Validation Decoder Loss:  0.36017138
Encoder Loss:  0.055579018  || Decoder Loss:  0.039393194 Validation Decoder Loss:  0.35026395
Encoder Loss:  0.053203117  || Decoder Loss:  0.03413152 Validation Decoder Loss:  0.3534336
Encoder Loss:  0.058237053  || Decoder Loss:  0.03667064 Validation Decoder Loss:  0.35176307
Encoder Loss:  0.06616307  || Decoder Loss:  0.035717655 Validation Decoder Loss:  0.35634273
Encoder Loss:  0.06291636  || Decoder Loss:  0.038871583 Validation Decoder Loss:  0.35436666
Encoder Loss:  0.06486473  || Decoder Loss:  0.035866585 Validation Decoder Loss:  0.35175854
Encoder Loss:  0.057912722  || Decoder Loss:  0.034851626 Validation Decoder Loss:  0.3513733
Encoder Loss:  0.05598884  || Decoder Loss:  0.037999615 Validation Decoder Loss:  0.35480195
Encoder Loss:  0.05468258  || Decoder Loss:  0.040078763 Validation Decoder Loss:  0.35368246
Encoder Loss:  0.054492928  || Decoder Loss:  0.038279355 Validation Decoder Loss:  0.35451078
Encoder Loss:  0.056533404  || Decoder Loss:  0.037233945 Validation Decoder Loss:  0.35008344
Encoder Loss:  0.05625427  || Decoder Loss:  0.03577389 Validation Decoder Loss:  0.3588272
Encoder Loss:  0.055360314  || Decoder Loss:  0.035712816 Validation Decoder Loss:  0.35534078
Encoder Loss:  0.054897055  || Decoder Loss:  0.03629071 Validation Decoder Loss:  0.36287975
Encoder Loss:  0.05208012  || Decoder Loss:  0.038152214 Validation Decoder Loss:  0.35254765
Encoder Loss:  0.05818737  || Decoder Loss:  0.036010288 Validation Decoder Loss:  0.35646388
Encoder Loss:  0.05177505  || Decoder Loss:  0.03684756 Validation Decoder Loss:  0.35804117
Encoder Loss:  0.053212103  || Decoder Loss:  0.03526358 Validation Decoder Loss:  0.36271077
Model: siamese_net_lr_0.019688933935955718 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3627108
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 224, 5, 20, 1)     99        
_________________________________________________________________
reshape_3 (Reshape)          (None, 1120, 20, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 1120, 20, 1)       2127      
=================================================================
Total params: 2,127
Trainable params: 2,127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 3245, 20, 1)       1008      
=================================================================
Total params: 1,008
Trainable params: 1,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47390354  || Decoder Loss:  0.8063996 Validation Decoder Loss:  1.0192361
Encoder Loss:  0.40810138  || Decoder Loss:  0.22970802 Validation Decoder Loss:  0.4194571
Encoder Loss:  0.21749549  || Decoder Loss:  0.3859844 Validation Decoder Loss:  1.5650866
Encoder Loss:  0.12925912  || Decoder Loss:  0.5266771 Validation Decoder Loss:  0.9407153
Encoder Loss:  0.09867491  || Decoder Loss:  0.41110152 Validation Decoder Loss:  1.6197306
Encoder Loss:  0.10241192  || Decoder Loss:  0.44291076 Validation Decoder Loss:  0.86069936
Encoder Loss:  0.08166582  || Decoder Loss:  0.2774617 Validation Decoder Loss:  0.60311675
Encoder Loss:  0.058777932  || Decoder Loss:  0.055170264 Validation Decoder Loss:  0.3504829
Encoder Loss:  0.06790848  || Decoder Loss:  0.041359987 Validation Decoder Loss:  0.35757786
Encoder Loss:  0.055238474  || Decoder Loss:  0.036159564 Validation Decoder Loss:  0.35530382
Encoder Loss:  0.060887314  || Decoder Loss:  0.036017574 Validation Decoder Loss:  0.35284877
Encoder Loss:  0.054532386  || Decoder Loss:  0.036214326 Validation Decoder Loss:  0.34564364
Encoder Loss:  0.055001035  || Decoder Loss:  0.035256434 Validation Decoder Loss:  0.35289
Encoder Loss:  0.058952235  || Decoder Loss:  0.036684245 Validation Decoder Loss:  0.3495167
Encoder Loss:  0.06544432  || Decoder Loss:  0.03589971 Validation Decoder Loss:  0.34693623
Encoder Loss:  0.055631623  || Decoder Loss:  0.035323776 Validation Decoder Loss:  0.34749842
Encoder Loss:  0.05318346  || Decoder Loss:  0.035089232 Validation Decoder Loss:  0.34611714
Encoder Loss:  0.053999268  || Decoder Loss:  0.035357412 Validation Decoder Loss:  0.34684086
Encoder Loss:  0.05420313  || Decoder Loss:  0.035120573 Validation Decoder Loss:  0.3531933
Encoder Loss:  0.06332388  || Decoder Loss:  0.034685537 Validation Decoder Loss:  0.3558366
Encoder Loss:  0.058575682  || Decoder Loss:  0.035901397 Validation Decoder Loss:  0.35044688
Encoder Loss:  0.055206362  || Decoder Loss:  0.03513225 Validation Decoder Loss:  0.3516873
Encoder Loss:  0.05485353  || Decoder Loss:  0.036518726 Validation Decoder Loss:  0.34416926
Encoder Loss:  0.05332533  || Decoder Loss:  0.03428949 Validation Decoder Loss:  0.3496434
Encoder Loss:  0.053994026  || Decoder Loss:  0.035896827 Validation Decoder Loss:  0.34488338
Encoder Loss:  0.056527644  || Decoder Loss:  0.03359115 Validation Decoder Loss:  0.34827346
Encoder Loss:  0.052812386  || Decoder Loss:  0.035327822 Validation Decoder Loss:  0.34645665
Encoder Loss:  0.05626764  || Decoder Loss:  0.03504173 Validation Decoder Loss:  0.34078884
Encoder Loss:  0.054396715  || Decoder Loss:  0.03391077 Validation Decoder Loss:  0.35165358
Encoder Loss:  0.052416768  || Decoder Loss:  0.035326663 Validation Decoder Loss:  0.34261298
Encoder Loss:  0.050864547  || Decoder Loss:  0.033359382 Validation Decoder Loss:  0.34569368
Encoder Loss:  0.0537965  || Decoder Loss:  0.0340803 Validation Decoder Loss:  0.34557968
Encoder Loss:  0.053007886  || Decoder Loss:  0.035126675 Validation Decoder Loss:  0.34717715
Encoder Loss:  0.0603855  || Decoder Loss:  0.034740154 Validation Decoder Loss:  0.34882784
Encoder Loss:  0.054115515  || Decoder Loss:  0.034979288 Validation Decoder Loss:  0.34444946
Encoder Loss:  0.055133194  || Decoder Loss:  0.033985868 Validation Decoder Loss:  0.34526056
Encoder Loss:  0.052138153  || Decoder Loss:  0.03437825 Validation Decoder Loss:  0.34569743
Encoder Loss:  0.05841019  || Decoder Loss:  0.035596926 Validation Decoder Loss:  0.34921694
Encoder Loss:  0.05385222  || Decoder Loss:  0.035233185 Validation Decoder Loss:  0.3475815
Encoder Loss:  0.0513111  || Decoder Loss:  0.034176838 Validation Decoder Loss:  0.34564117
Model: siamese_net_lr_0.01648289643536012 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34564117
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 340, 8, 20, 1)     353       
_________________________________________________________________
reshape_4 (Reshape)          (None, 2720, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2720, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 3245, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.66492236  || Decoder Loss:  0.9320738 Validation Decoder Loss:  1.6481886
Encoder Loss:  0.6554103  || Decoder Loss:  0.9485991 Validation Decoder Loss:  1.6624339
Encoder Loss:  0.2947273  || Decoder Loss:  0.49038237 Validation Decoder Loss:  0.59748375
Encoder Loss:  0.25061107  || Decoder Loss:  0.47083527 Validation Decoder Loss:  1.0143543
Encoder Loss:  0.25066468  || Decoder Loss:  0.47741744 Validation Decoder Loss:  1.0735332
Encoder Loss:  0.2503503  || Decoder Loss:  0.47454327 Validation Decoder Loss:  1.1131904
Encoder Loss:  0.2670473  || Decoder Loss:  0.5096262 Validation Decoder Loss:  0.95954674
Encoder Loss:  0.24789469  || Decoder Loss:  0.46654645 Validation Decoder Loss:  1.3206894
Encoder Loss:  0.2663747  || Decoder Loss:  0.49231273 Validation Decoder Loss:  1.181083
Encoder Loss:  0.23279443  || Decoder Loss:  0.43516797 Validation Decoder Loss:  0.8985989
Encoder Loss:  0.22285283  || Decoder Loss:  0.41634548 Validation Decoder Loss:  0.9542963
Encoder Loss:  0.25372612  || Decoder Loss:  0.47646812 Validation Decoder Loss:  0.91643244
Encoder Loss:  0.2175573  || Decoder Loss:  0.3975827 Validation Decoder Loss:  0.91946125
Encoder Loss:  0.2516392  || Decoder Loss:  0.48013774 Validation Decoder Loss:  0.9415623
Encoder Loss:  0.24602017  || Decoder Loss:  0.46710834 Validation Decoder Loss:  0.8667146
Encoder Loss:  0.21568003  || Decoder Loss:  0.4031781 Validation Decoder Loss:  0.84155667
Encoder Loss:  0.22817314  || Decoder Loss:  0.4242671 Validation Decoder Loss:  0.95012367
Encoder Loss:  0.19113809  || Decoder Loss:  0.34911567 Validation Decoder Loss:  0.734956
Encoder Loss:  0.191024  || Decoder Loss:  0.34867015 Validation Decoder Loss:  0.87389743
Encoder Loss:  0.22979888  || Decoder Loss:  0.43319497 Validation Decoder Loss:  0.95139354
Encoder Loss:  0.2503268  || Decoder Loss:  0.47733748 Validation Decoder Loss:  0.9557416
Encoder Loss:  0.25501475  || Decoder Loss:  0.477841 Validation Decoder Loss:  0.9435997
Encoder Loss:  0.24640717  || Decoder Loss:  0.46811008 Validation Decoder Loss:  0.9510062
Encoder Loss:  0.22475038  || Decoder Loss:  0.41991505 Validation Decoder Loss:  0.86101913
Encoder Loss:  0.19462703  || Decoder Loss:  0.35677406 Validation Decoder Loss:  0.9567708
Encoder Loss:  0.23851329  || Decoder Loss:  0.45329133 Validation Decoder Loss:  0.6945065
Encoder Loss:  0.23553622  || Decoder Loss:  0.44580293 Validation Decoder Loss:  0.97357726
Encoder Loss:  0.24492268  || Decoder Loss:  0.46412683 Validation Decoder Loss:  0.93067646
Encoder Loss:  0.19372721  || Decoder Loss:  0.3513712 Validation Decoder Loss:  0.6741431
Encoder Loss:  0.18132651  || Decoder Loss:  0.32533228 Validation Decoder Loss:  0.9145744
Encoder Loss:  0.23736362  || Decoder Loss:  0.44847083 Validation Decoder Loss:  0.9052193
Encoder Loss:  0.17691004  || Decoder Loss:  0.31894892 Validation Decoder Loss:  0.6829931
Encoder Loss:  0.13703962  || Decoder Loss:  0.23316729 Validation Decoder Loss:  0.52919775
Encoder Loss:  0.14889531  || Decoder Loss:  0.25445473 Validation Decoder Loss:  0.9490451
Encoder Loss:  0.22615328  || Decoder Loss:  0.4232881 Validation Decoder Loss:  0.9309615
Encoder Loss:  0.25366622  || Decoder Loss:  0.47694796 Validation Decoder Loss:  0.96749395
Encoder Loss:  0.2529061  || Decoder Loss:  0.48010018 Validation Decoder Loss:  0.96476805
Encoder Loss:  0.24833508  || Decoder Loss:  0.4767891 Validation Decoder Loss:  0.9569479
Encoder Loss:  0.24599448  || Decoder Loss:  0.46782824 Validation Decoder Loss:  0.9309499
Encoder Loss:  0.21196155  || Decoder Loss:  0.39514884 Validation Decoder Loss:  0.84273446
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.03850070451391265 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.84273446
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 160, 7, 20, 1)     103       
_________________________________________________________________
reshape_5 (Reshape)          (None, 1120, 20, 1)       0         
=================================================================
Total params: 103
Trainable params: 103
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 1120, 20, 1)       1008      
=================================================================
Total params: 1,008
Trainable params: 1,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 3245, 20, 1)       2127      
=================================================================
Total params: 2,127
Trainable params: 2,127
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.892253  || Decoder Loss:  0.90827507 Validation Decoder Loss:  1.6331737
Encoder Loss:  0.900696  || Decoder Loss:  0.9167199 Validation Decoder Loss:  1.6279761
Encoder Loss:  0.892062  || Decoder Loss:  0.9077848 Validation Decoder Loss:  1.6185827
Encoder Loss:  0.87909716  || Decoder Loss:  0.8943669 Validation Decoder Loss:  1.6019452
Encoder Loss:  0.8591494  || Decoder Loss:  0.8737205 Validation Decoder Loss:  1.5717379
Encoder Loss:  0.8255015  || Decoder Loss:  0.83889055 Validation Decoder Loss:  1.5101935
Encoder Loss:  0.7533248  || Decoder Loss:  0.7641703 Validation Decoder Loss:  1.3362644
Encoder Loss:  0.4919177  || Decoder Loss:  0.4935239 Validation Decoder Loss:  0.61080754
Encoder Loss:  0.11235999  || Decoder Loss:  0.100547984 Validation Decoder Loss:  0.3894961
Encoder Loss:  0.06864979  || Decoder Loss:  0.05531134 Validation Decoder Loss:  0.38469642
Encoder Loss:  0.065405756  || Decoder Loss:  0.051979188 Validation Decoder Loss:  0.3859014
Encoder Loss:  0.06449992  || Decoder Loss:  0.05107737 Validation Decoder Loss:  0.3863173
Encoder Loss:  0.06399997  || Decoder Loss:  0.050612126 Validation Decoder Loss:  0.38613313
Encoder Loss:  0.06362556  || Decoder Loss:  0.050310377 Validation Decoder Loss:  0.38579667
Encoder Loss:  0.0633157  || Decoder Loss:  0.050164364 Validation Decoder Loss:  0.385874
Encoder Loss:  0.063141115  || Decoder Loss:  0.05056908 Validation Decoder Loss:  0.38979167
Encoder Loss:  0.3299675  || Decoder Loss:  0.333876 Validation Decoder Loss:  0.7207627
Encoder Loss:  0.4348938  || Decoder Loss:  0.44765317 Validation Decoder Loss:  1.3091407
Encoder Loss:  0.43037742  || Decoder Loss:  0.44316915 Validation Decoder Loss:  1.3286481
Encoder Loss:  0.40546346  || Decoder Loss:  0.4174182 Validation Decoder Loss:  1.4173155
Encoder Loss:  0.4042865  || Decoder Loss:  0.41636258 Validation Decoder Loss:  1.16203
Encoder Loss:  0.43164745  || Decoder Loss:  0.4447141 Validation Decoder Loss:  0.9268527
Encoder Loss:  0.34805542  || Decoder Loss:  0.3583933 Validation Decoder Loss:  1.2679119
Encoder Loss:  0.4752726  || Decoder Loss:  0.48996636 Validation Decoder Loss:  0.9872044
Encoder Loss:  0.46961173  || Decoder Loss:  0.48422596 Validation Decoder Loss:  0.991733
Encoder Loss:  0.4727038  || Decoder Loss:  0.48744267 Validation Decoder Loss:  0.993907
Encoder Loss:  0.46836528  || Decoder Loss:  0.4829354 Validation Decoder Loss:  1.0336584
Encoder Loss:  0.42430642  || Decoder Loss:  0.4373977 Validation Decoder Loss:  1.0198756
Encoder Loss:  0.46814072  || Decoder Loss:  0.4826166 Validation Decoder Loss:  1.0209239
Encoder Loss:  0.4870726  || Decoder Loss:  0.50214815 Validation Decoder Loss:  1.00089
Encoder Loss:  0.47713172  || Decoder Loss:  0.49171868 Validation Decoder Loss:  0.98203886
Encoder Loss:  0.47696304  || Decoder Loss:  0.4916824 Validation Decoder Loss:  0.99162745
Encoder Loss:  0.48174262  || Decoder Loss:  0.49671477 Validation Decoder Loss:  1.0089779
Encoder Loss:  0.47487935  || Decoder Loss:  0.4895565 Validation Decoder Loss:  0.9695949
Encoder Loss:  0.47764522  || Decoder Loss:  0.4924845 Validation Decoder Loss:  1.0324872
Encoder Loss:  0.47566566  || Decoder Loss:  0.48997766 Validation Decoder Loss:  1.0384704
Encoder Loss:  0.48135692  || Decoder Loss:  0.49587983 Validation Decoder Loss:  1.018345
Encoder Loss:  0.48150367  || Decoder Loss:  0.49642152 Validation Decoder Loss:  1.0025208
Encoder Loss:  0.47614244  || Decoder Loss:  0.4910134 Validation Decoder Loss:  0.9810529
Encoder Loss:  0.47780323  || Decoder Loss:  0.49285886 Validation Decoder Loss:  0.94776475
Model: siamese_net_lr_0.06057766598615917 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.94776475
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 170, 11, 20, 1)    133       
_________________________________________________________________
reshape_6 (Reshape)          (None, 1870, 20, 1)       0         
=================================================================
Total params: 133
Trainable params: 133
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 1870, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 3245, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.48435864  || Decoder Loss:  0.89565885 Validation Decoder Loss:  1.6319377
Encoder Loss:  0.4869547  || Decoder Loss:  0.9058835 Validation Decoder Loss:  1.6173692
Encoder Loss:  0.3075549  || Decoder Loss:  0.6824027 Validation Decoder Loss:  0.41382653
Encoder Loss:  0.12452087  || Decoder Loss:  0.3077218 Validation Decoder Loss:  0.48704538
Encoder Loss:  0.069261335  || Decoder Loss:  0.06991116 Validation Decoder Loss:  0.3752684
Encoder Loss:  0.0639257  || Decoder Loss:  0.039386682 Validation Decoder Loss:  0.3552971
Encoder Loss:  0.05809099  || Decoder Loss:  0.033970054 Validation Decoder Loss:  0.3631642
Encoder Loss:  0.05979252  || Decoder Loss:  0.035148468 Validation Decoder Loss:  0.35807863
Encoder Loss:  0.058089443  || Decoder Loss:  0.03494235 Validation Decoder Loss:  0.3546482
Encoder Loss:  0.063868396  || Decoder Loss:  0.03924994 Validation Decoder Loss:  0.35564548
Encoder Loss:  0.056263205  || Decoder Loss:  0.03823071 Validation Decoder Loss:  0.3584526
Encoder Loss:  0.058870114  || Decoder Loss:  0.03688195 Validation Decoder Loss:  0.35804975
Encoder Loss:  0.05823426  || Decoder Loss:  0.03502437 Validation Decoder Loss:  0.34970713
Encoder Loss:  0.056716908  || Decoder Loss:  0.035263646 Validation Decoder Loss:  0.36713055
Encoder Loss:  0.06595264  || Decoder Loss:  0.03624858 Validation Decoder Loss:  0.3991903
Encoder Loss:  0.075213365  || Decoder Loss:  0.046776146 Validation Decoder Loss:  0.38247228
Encoder Loss:  0.065057434  || Decoder Loss:  0.043151088 Validation Decoder Loss:  0.3539437
Encoder Loss:  0.0707373  || Decoder Loss:  0.033612896 Validation Decoder Loss:  0.35739163
Encoder Loss:  0.06980978  || Decoder Loss:  0.03534564 Validation Decoder Loss:  0.38160247
Encoder Loss:  0.058347143  || Decoder Loss:  0.03756985 Validation Decoder Loss:  0.34941864
Encoder Loss:  0.06847675  || Decoder Loss:  0.035363834 Validation Decoder Loss:  0.34601054
Encoder Loss:  0.053388663  || Decoder Loss:  0.034814067 Validation Decoder Loss:  0.36174786
Encoder Loss:  0.05989952  || Decoder Loss:  0.03852324 Validation Decoder Loss:  0.3431217
Encoder Loss:  0.05699844  || Decoder Loss:  0.034790255 Validation Decoder Loss:  0.35635188
Encoder Loss:  0.05636234  || Decoder Loss:  0.035084773 Validation Decoder Loss:  0.354635
Encoder Loss:  0.059543457  || Decoder Loss:  0.03374808 Validation Decoder Loss:  0.35621983
Encoder Loss:  0.053002585  || Decoder Loss:  0.036220714 Validation Decoder Loss:  0.34812057
Encoder Loss:  0.062007237  || Decoder Loss:  0.036113523 Validation Decoder Loss:  0.3670619
Encoder Loss:  0.055995908  || Decoder Loss:  0.03708651 Validation Decoder Loss:  0.34933043
Encoder Loss:  0.05513891  || Decoder Loss:  0.034920916 Validation Decoder Loss:  0.34818506
Encoder Loss:  0.053719435  || Decoder Loss:  0.034003768 Validation Decoder Loss:  0.35111576
Encoder Loss:  0.0572962  || Decoder Loss:  0.035560094 Validation Decoder Loss:  0.34486085
Encoder Loss:  0.05783796  || Decoder Loss:  0.032713868 Validation Decoder Loss:  0.35107553
Encoder Loss:  0.05418771  || Decoder Loss:  0.033667397 Validation Decoder Loss:  0.3655526
Encoder Loss:  0.05351739  || Decoder Loss:  0.036871746 Validation Decoder Loss:  0.35721874
Encoder Loss:  0.055355534  || Decoder Loss:  0.03531449 Validation Decoder Loss:  0.34980953
Encoder Loss:  0.05600767  || Decoder Loss:  0.034195233 Validation Decoder Loss:  0.35568738
Encoder Loss:  0.05738487  || Decoder Loss:  0.03449251 Validation Decoder Loss:  0.34824872
Encoder Loss:  0.055344313  || Decoder Loss:  0.034584686 Validation Decoder Loss:  0.36042526
Encoder Loss:  0.06392065  || Decoder Loss:  0.03546653 Validation Decoder Loss:  0.353018
Model: siamese_net_lr_0.011833170359945721 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35301796
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 374, 5, 20, 1)     312       
_________________________________________________________________
reshape_7 (Reshape)          (None, 1870, 20, 1)       0         
=================================================================
Total params: 312
Trainable params: 312
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 1870, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 3245, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43933076  || Decoder Loss:  0.8970367 Validation Decoder Loss:  1.640816
Encoder Loss:  0.4464472  || Decoder Loss:  0.91246736 Validation Decoder Loss:  1.6392978
Encoder Loss:  0.44602913  || Decoder Loss:  0.91142607 Validation Decoder Loss:  1.6372682
Encoder Loss:  0.44542882  || Decoder Loss:  0.9100461 Validation Decoder Loss:  1.634697
Encoder Loss:  0.44456145  || Decoder Loss:  0.908271 Validation Decoder Loss:  1.6315163
Encoder Loss:  0.44328222  || Decoder Loss:  0.90600085 Validation Decoder Loss:  1.6276073
Encoder Loss:  0.44132233  || Decoder Loss:  0.90306467 Validation Decoder Loss:  1.6227661
Encoder Loss:  0.43814674  || Decoder Loss:  0.8991587 Validation Decoder Loss:  1.6166062
Encoder Loss:  0.43255243  || Decoder Loss:  0.8936636 Validation Decoder Loss:  1.608232
Encoder Loss:  0.42117158  || Decoder Loss:  0.8849601 Validation Decoder Loss:  1.5946898
Encoder Loss:  0.3887824  || Decoder Loss:  0.86570907 Validation Decoder Loss:  1.5536189
Encoder Loss:  0.19777784  || Decoder Loss:  0.6101275 Validation Decoder Loss:  0.83826935
Encoder Loss:  0.07816413  || Decoder Loss:  0.5013861 Validation Decoder Loss:  0.96142894
Encoder Loss:  0.068147644  || Decoder Loss:  0.49798283 Validation Decoder Loss:  0.9393089
Encoder Loss:  0.06675687  || Decoder Loss:  0.4961215 Validation Decoder Loss:  0.957324
Encoder Loss:  0.063854285  || Decoder Loss:  0.49452773 Validation Decoder Loss:  1.0019681
Encoder Loss:  0.06030195  || Decoder Loss:  0.49889508 Validation Decoder Loss:  0.97898126
Encoder Loss:  0.058362916  || Decoder Loss:  0.49452955 Validation Decoder Loss:  1.0065813
Encoder Loss:  0.0572373  || Decoder Loss:  0.4917808 Validation Decoder Loss:  1.021642
Encoder Loss:  0.053697173  || Decoder Loss:  0.4923522 Validation Decoder Loss:  1.0054365
Encoder Loss:  0.059621442  || Decoder Loss:  0.48968413 Validation Decoder Loss:  0.95166516
Encoder Loss:  0.058982782  || Decoder Loss:  0.48348194 Validation Decoder Loss:  1.0141301
Encoder Loss:  0.052296776  || Decoder Loss:  0.48984456 Validation Decoder Loss:  1.0408866
Encoder Loss:  0.05542282  || Decoder Loss:  0.49036244 Validation Decoder Loss:  1.020753
Encoder Loss:  0.056914404  || Decoder Loss:  0.48888797 Validation Decoder Loss:  0.99892956
Encoder Loss:  0.05550519  || Decoder Loss:  0.49015695 Validation Decoder Loss:  1.0294495
Encoder Loss:  0.05956311  || Decoder Loss:  0.48655048 Validation Decoder Loss:  1.0264248
Encoder Loss:  0.0528567  || Decoder Loss:  0.49061513 Validation Decoder Loss:  1.0236733
Encoder Loss:  0.055115018  || Decoder Loss:  0.4897296 Validation Decoder Loss:  1.0087957
Encoder Loss:  0.056696285  || Decoder Loss:  0.4863635 Validation Decoder Loss:  0.98678505
Encoder Loss:  0.054717597  || Decoder Loss:  0.48904213 Validation Decoder Loss:  0.99243057
Encoder Loss:  0.059723638  || Decoder Loss:  0.4838755 Validation Decoder Loss:  1.0280324
Encoder Loss:  0.056756105  || Decoder Loss:  0.49128434 Validation Decoder Loss:  0.96453786
Encoder Loss:  0.055868767  || Decoder Loss:  0.48597318 Validation Decoder Loss:  0.9581629
Encoder Loss:  0.055636864  || Decoder Loss:  0.48480397 Validation Decoder Loss:  0.9733728
Encoder Loss:  0.054897305  || Decoder Loss:  0.48620522 Validation Decoder Loss:  0.96660554
Encoder Loss:  0.05291598  || Decoder Loss:  0.48636574 Validation Decoder Loss:  0.95738727
Encoder Loss:  0.058424458  || Decoder Loss:  0.48322552 Validation Decoder Loss:  0.93245393
Encoder Loss:  0.05778834  || Decoder Loss:  0.48199555 Validation Decoder Loss:  0.96809053
Encoder Loss:  0.05381073  || Decoder Loss:  0.48463875 Validation Decoder Loss:  0.9731399
Model: siamese_net_lr_0.07478997685225355 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9731399
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_8 (Reshape)          (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26473942  || Decoder Loss:  0.22786213 Validation Decoder Loss:  0.33006674
Encoder Loss:  0.21337433  || Decoder Loss:  0.23286764 Validation Decoder Loss:  0.35280484
Encoder Loss:  0.05246599  || Decoder Loss:  0.036745235 Validation Decoder Loss:  0.35158128
Encoder Loss:  0.047204703  || Decoder Loss:  0.034497913 Validation Decoder Loss:  0.3538216
Encoder Loss:  0.042247772  || Decoder Loss:  0.033388432 Validation Decoder Loss:  0.3520596
Encoder Loss:  0.041588575  || Decoder Loss:  0.033261824 Validation Decoder Loss:  0.3529719
Encoder Loss:  0.04461176  || Decoder Loss:  0.033360533 Validation Decoder Loss:  0.35200128
Encoder Loss:  0.041666184  || Decoder Loss:  0.033210743 Validation Decoder Loss:  0.3507223
Encoder Loss:  0.0406552  || Decoder Loss:  0.03302444 Validation Decoder Loss:  0.3483852
Encoder Loss:  0.04078516  || Decoder Loss:  0.032997258 Validation Decoder Loss:  0.34356323
Encoder Loss:  0.041440476  || Decoder Loss:  0.032797504 Validation Decoder Loss:  0.3492216
Encoder Loss:  0.04031824  || Decoder Loss:  0.03276757 Validation Decoder Loss:  0.34730035
Encoder Loss:  0.040277142  || Decoder Loss:  0.032720152 Validation Decoder Loss:  0.34744555
Encoder Loss:  0.040132806  || Decoder Loss:  0.03260628 Validation Decoder Loss:  0.34775433
Encoder Loss:  0.042073775  || Decoder Loss:  0.03256308 Validation Decoder Loss:  0.3475824
Encoder Loss:  0.040187083  || Decoder Loss:  0.032460906 Validation Decoder Loss:  0.34761995
Encoder Loss:  0.04073184  || Decoder Loss:  0.03239373 Validation Decoder Loss:  0.3502606
Encoder Loss:  0.044416357  || Decoder Loss:  0.032433804 Validation Decoder Loss:  0.34921622
Encoder Loss:  0.03981854  || Decoder Loss:  0.032281492 Validation Decoder Loss:  0.3488829
Encoder Loss:  0.039745536  || Decoder Loss:  0.032234877 Validation Decoder Loss:  0.34926793
Encoder Loss:  0.04179251  || Decoder Loss:  0.03221844 Validation Decoder Loss:  0.3497951
Encoder Loss:  0.040871292  || Decoder Loss:  0.032173418 Validation Decoder Loss:  0.34986538
Encoder Loss:  0.03934217  || Decoder Loss:  0.03210472 Validation Decoder Loss:  0.3495981
Encoder Loss:  0.038923595  || Decoder Loss:  0.03207128 Validation Decoder Loss:  0.3495087
Encoder Loss:  0.03887538  || Decoder Loss:  0.032048278 Validation Decoder Loss:  0.34804848
Encoder Loss:  0.041256398  || Decoder Loss:  0.0320758 Validation Decoder Loss:  0.34797826
Encoder Loss:  0.041115314  || Decoder Loss:  0.03201845 Validation Decoder Loss:  0.34809282
Encoder Loss:  0.04027801  || Decoder Loss:  0.03196539 Validation Decoder Loss:  0.34744292
Encoder Loss:  0.038943548  || Decoder Loss:  0.031907 Validation Decoder Loss:  0.3477787
Encoder Loss:  0.039628845  || Decoder Loss:  0.03193474 Validation Decoder Loss:  0.3506977
Encoder Loss:  0.039975416  || Decoder Loss:  0.031858943 Validation Decoder Loss:  0.34630558
Encoder Loss:  0.04066631  || Decoder Loss:  0.031893257 Validation Decoder Loss:  0.35015488
Encoder Loss:  0.040966205  || Decoder Loss:  0.031872172 Validation Decoder Loss:  0.347075
Encoder Loss:  0.038939558  || Decoder Loss:  0.031759672 Validation Decoder Loss:  0.34998062
Encoder Loss:  0.039329764  || Decoder Loss:  0.031769518 Validation Decoder Loss:  0.3422662
Encoder Loss:  0.042301077  || Decoder Loss:  0.031836327 Validation Decoder Loss:  0.34403735
Encoder Loss:  0.04026917  || Decoder Loss:  0.031726986 Validation Decoder Loss:  0.34919333
Encoder Loss:  0.039536938  || Decoder Loss:  0.031659283 Validation Decoder Loss:  0.3491022
Encoder Loss:  0.037772685  || Decoder Loss:  0.031563424 Validation Decoder Loss:  0.35037234
Encoder Loss:  0.03854611  || Decoder Loss:  0.03159997 Validation Decoder Loss:  0.34862
Model: siamese_net_lr_0.006546958706544396 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34862
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_9 (Reshape)          (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.54679704  || Decoder Loss:  0.7009636 Validation Decoder Loss:  0.7022102
Encoder Loss:  0.31653008  || Decoder Loss:  0.14939083 Validation Decoder Loss:  0.3542732
Encoder Loss:  0.2827509  || Decoder Loss:  0.080402106 Validation Decoder Loss:  0.34224385
Encoder Loss:  0.34590518  || Decoder Loss:  0.38122118 Validation Decoder Loss:  1.64344
Encoder Loss:  0.22642592  || Decoder Loss:  0.40126565 Validation Decoder Loss:  0.6450118
Encoder Loss:  0.17574102  || Decoder Loss:  0.3280671 Validation Decoder Loss:  0.97205335
Encoder Loss:  0.20931916  || Decoder Loss:  0.40376845 Validation Decoder Loss:  0.54962075
Encoder Loss:  0.093131304  || Decoder Loss:  0.13838601 Validation Decoder Loss:  0.6455139
Encoder Loss:  0.0789108  || Decoder Loss:  0.10411856 Validation Decoder Loss:  0.3232808
Encoder Loss:  0.058939252  || Decoder Loss:  0.05279063 Validation Decoder Loss:  0.3206993
Encoder Loss:  0.07426753  || Decoder Loss:  0.06495312 Validation Decoder Loss:  0.40802288
Encoder Loss:  0.052634217  || Decoder Loss:  0.03798635 Validation Decoder Loss:  0.35948396
Encoder Loss:  0.05858501  || Decoder Loss:  0.03690923 Validation Decoder Loss:  0.35376808
Encoder Loss:  0.050236635  || Decoder Loss:  0.033811823 Validation Decoder Loss:  0.3478241
Encoder Loss:  0.05094267  || Decoder Loss:  0.03355523 Validation Decoder Loss:  0.34967765
Encoder Loss:  0.050699353  || Decoder Loss:  0.03355476 Validation Decoder Loss:  0.34523278
Encoder Loss:  0.048048638  || Decoder Loss:  0.033290114 Validation Decoder Loss:  0.3425392
Encoder Loss:  0.047581173  || Decoder Loss:  0.03311718 Validation Decoder Loss:  0.34523502
Encoder Loss:  0.047442008  || Decoder Loss:  0.033123747 Validation Decoder Loss:  0.3448609
Encoder Loss:  0.04731301  || Decoder Loss:  0.033025935 Validation Decoder Loss:  0.34386894
Encoder Loss:  0.046968006  || Decoder Loss:  0.032941394 Validation Decoder Loss:  0.35132572
Encoder Loss:  0.047988366  || Decoder Loss:  0.033686608 Validation Decoder Loss:  0.3513184
Encoder Loss:  0.04837113  || Decoder Loss:  0.032955796 Validation Decoder Loss:  0.35185182
Encoder Loss:  0.055043653  || Decoder Loss:  0.03621524 Validation Decoder Loss:  0.34137866
Encoder Loss:  0.056931015  || Decoder Loss:  0.036500502 Validation Decoder Loss:  0.34975383
Encoder Loss:  0.052147217  || Decoder Loss:  0.03493255 Validation Decoder Loss:  0.35009155
Encoder Loss:  0.047622476  || Decoder Loss:  0.033008814 Validation Decoder Loss:  0.37050775
Encoder Loss:  0.04805282  || Decoder Loss:  0.038234655 Validation Decoder Loss:  0.36189038
Encoder Loss:  0.047118597  || Decoder Loss:  0.0380183 Validation Decoder Loss:  0.35605514
Encoder Loss:  0.045596495  || Decoder Loss:  0.035062786 Validation Decoder Loss:  0.35077998
Encoder Loss:  0.04594715  || Decoder Loss:  0.034221876 Validation Decoder Loss:  0.35126305
Encoder Loss:  0.047835276  || Decoder Loss:  0.033552602 Validation Decoder Loss:  0.34640896
Encoder Loss:  0.04885214  || Decoder Loss:  0.034666006 Validation Decoder Loss:  0.3534359
Encoder Loss:  0.04726695  || Decoder Loss:  0.034747835 Validation Decoder Loss:  0.34835562
Encoder Loss:  0.046910163  || Decoder Loss:  0.0346128 Validation Decoder Loss:  0.347155
Encoder Loss:  0.047728643  || Decoder Loss:  0.033402883 Validation Decoder Loss:  0.36371922
Encoder Loss:  0.047671128  || Decoder Loss:  0.0351974 Validation Decoder Loss:  0.35066932
Encoder Loss:  0.047970638  || Decoder Loss:  0.036539234 Validation Decoder Loss:  0.36979926
Encoder Loss:  0.049928006  || Decoder Loss:  0.03652141 Validation Decoder Loss:  0.35081232
Encoder Loss:  0.047533106  || Decoder Loss:  0.033676513 Validation Decoder Loss:  0.35476744
Model: siamese_net_lr_0.012543235857719043 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35476744
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_10 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47342923  || Decoder Loss:  0.522426 Validation Decoder Loss:  0.41556388
Encoder Loss:  0.28094557  || Decoder Loss:  0.092677966 Validation Decoder Loss:  0.35428944
Encoder Loss:  0.27164426  || Decoder Loss:  0.088200636 Validation Decoder Loss:  0.36678466
Encoder Loss:  0.28470185  || Decoder Loss:  0.30806035 Validation Decoder Loss:  0.8335655
Encoder Loss:  0.23328535  || Decoder Loss:  0.40885392 Validation Decoder Loss:  1.1741688
Encoder Loss:  0.2354277  || Decoder Loss:  0.4189478 Validation Decoder Loss:  1.2005714
Encoder Loss:  0.23156631  || Decoder Loss:  0.41260198 Validation Decoder Loss:  1.181004
Encoder Loss:  0.19826278  || Decoder Loss:  0.34339637 Validation Decoder Loss:  0.73556036
Encoder Loss:  0.101383954  || Decoder Loss:  0.13209581 Validation Decoder Loss:  0.36871183
Encoder Loss:  0.05299977  || Decoder Loss:  0.039776262 Validation Decoder Loss:  0.3550269
Encoder Loss:  0.052006733  || Decoder Loss:  0.03298557 Validation Decoder Loss:  0.3570126
Encoder Loss:  0.047592975  || Decoder Loss:  0.033428904 Validation Decoder Loss:  0.3587314
Encoder Loss:  0.052575283  || Decoder Loss:  0.033319235 Validation Decoder Loss:  0.34114185
Encoder Loss:  0.055484578  || Decoder Loss:  0.034016803 Validation Decoder Loss:  0.3476662
Encoder Loss:  0.051063586  || Decoder Loss:  0.03369797 Validation Decoder Loss:  0.34225
Encoder Loss:  0.048632897  || Decoder Loss:  0.034557197 Validation Decoder Loss:  0.35220465
Encoder Loss:  0.05145443  || Decoder Loss:  0.034264542 Validation Decoder Loss:  0.34492338
Encoder Loss:  0.051693864  || Decoder Loss:  0.03401104 Validation Decoder Loss:  0.3566488
Encoder Loss:  0.05414598  || Decoder Loss:  0.034488726 Validation Decoder Loss:  0.3454394
Encoder Loss:  0.050035346  || Decoder Loss:  0.034199324 Validation Decoder Loss:  0.33897817
Encoder Loss:  0.046979584  || Decoder Loss:  0.034656882 Validation Decoder Loss:  0.35437447
Encoder Loss:  0.047339182  || Decoder Loss:  0.03343643 Validation Decoder Loss:  0.35215428
Encoder Loss:  0.046588577  || Decoder Loss:  0.03344768 Validation Decoder Loss:  0.34759307
Encoder Loss:  0.051462054  || Decoder Loss:  0.03316509 Validation Decoder Loss:  0.36050603
Encoder Loss:  0.046056546  || Decoder Loss:  0.03338599 Validation Decoder Loss:  0.3545531
Encoder Loss:  0.04640477  || Decoder Loss:  0.033121053 Validation Decoder Loss:  0.3662651
Encoder Loss:  0.049951304  || Decoder Loss:  0.033031076 Validation Decoder Loss:  0.3599981
Encoder Loss:  0.049659744  || Decoder Loss:  0.03373735 Validation Decoder Loss:  0.36547005
Encoder Loss:  0.04905718  || Decoder Loss:  0.03417342 Validation Decoder Loss:  0.35665095
Encoder Loss:  0.04603918  || Decoder Loss:  0.033146914 Validation Decoder Loss:  0.35404655
Encoder Loss:  0.04896878  || Decoder Loss:  0.032594524 Validation Decoder Loss:  0.34260476
Encoder Loss:  0.04936167  || Decoder Loss:  0.03477824 Validation Decoder Loss:  0.36358306
Encoder Loss:  0.04618829  || Decoder Loss:  0.033706464 Validation Decoder Loss:  0.35299343
Encoder Loss:  0.044140644  || Decoder Loss:  0.033374943 Validation Decoder Loss:  0.3630936
Encoder Loss:  0.048202265  || Decoder Loss:  0.03314151 Validation Decoder Loss:  0.35659698
Encoder Loss:  0.048147302  || Decoder Loss:  0.03313851 Validation Decoder Loss:  0.35473007
Encoder Loss:  0.04554222  || Decoder Loss:  0.032647047 Validation Decoder Loss:  0.34269726
Encoder Loss:  0.044922005  || Decoder Loss:  0.032833494 Validation Decoder Loss:  0.33568674
Encoder Loss:  0.04556829  || Decoder Loss:  0.033160668 Validation Decoder Loss:  0.36014616
Encoder Loss:  0.048586473  || Decoder Loss:  0.032601103 Validation Decoder Loss:  0.36414203
Model: siamese_net_lr_0.01193884983070543 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36414206
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 374, 5, 20, 1)     249       
_________________________________________________________________
reshape_11 (Reshape)         (None, 1870, 20, 1)       0         
=================================================================
Total params: 249
Trainable params: 249
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 1870, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 3245, 20, 1)       1377      
=================================================================
Total params: 1,377
Trainable params: 1,377
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2508174  || Decoder Loss:  0.34498677 Validation Decoder Loss:  0.75175124
Encoder Loss:  0.20481418  || Decoder Loss:  0.27906483 Validation Decoder Loss:  0.67381746
Encoder Loss:  0.13379355  || Decoder Loss:  0.2504367 Validation Decoder Loss:  0.63982517
Encoder Loss:  0.09358233  || Decoder Loss:  0.22717637 Validation Decoder Loss:  0.59488505
Encoder Loss:  0.08550325  || Decoder Loss:  0.197612 Validation Decoder Loss:  0.5511441
Encoder Loss:  0.079873286  || Decoder Loss:  0.1725564 Validation Decoder Loss:  0.5183466
Encoder Loss:  0.07561359  || Decoder Loss:  0.15397638 Validation Decoder Loss:  0.4943285
Encoder Loss:  0.072363205  || Decoder Loss:  0.14010185 Validation Decoder Loss:  0.47618368
Encoder Loss:  0.069885656  || Decoder Loss:  0.1293905 Validation Decoder Loss:  0.46200216
Encoder Loss:  0.0678992  || Decoder Loss:  0.12089376 Validation Decoder Loss:  0.450612
Encoder Loss:  0.06628109  || Decoder Loss:  0.113996476 Validation Decoder Loss:  0.44126365
Encoder Loss:  0.06493146  || Decoder Loss:  0.108289614 Validation Decoder Loss:  0.43349597
Encoder Loss:  0.063737005  || Decoder Loss:  0.103501536 Validation Decoder Loss:  0.42686027
Encoder Loss:  0.06279616  || Decoder Loss:  0.09935722 Validation Decoder Loss:  0.4211341
Encoder Loss:  0.061877433  || Decoder Loss:  0.09578 Validation Decoder Loss:  0.4160859
Encoder Loss:  0.061122898  || Decoder Loss:  0.092603505 Validation Decoder Loss:  0.4116324
Encoder Loss:  0.06048381  || Decoder Loss:  0.08981835 Validation Decoder Loss:  0.40776595
Encoder Loss:  0.059860617  || Decoder Loss:  0.08737069 Validation Decoder Loss:  0.40429956
Encoder Loss:  0.059358224  || Decoder Loss:  0.08516684 Validation Decoder Loss:  0.4012292
Encoder Loss:  0.058829755  || Decoder Loss:  0.08316295 Validation Decoder Loss:  0.39837396
Encoder Loss:  0.05840603  || Decoder Loss:  0.08132115 Validation Decoder Loss:  0.39579916
Encoder Loss:  0.057999983  || Decoder Loss:  0.07963544 Validation Decoder Loss:  0.39342356
Encoder Loss:  0.057618663  || Decoder Loss:  0.07806947 Validation Decoder Loss:  0.3912287
Encoder Loss:  0.057281006  || Decoder Loss:  0.076619275 Validation Decoder Loss:  0.3892085
Encoder Loss:  0.05698184  || Decoder Loss:  0.075269684 Validation Decoder Loss:  0.38733274
Encoder Loss:  0.056687854  || Decoder Loss:  0.07400949 Validation Decoder Loss:  0.3855909
Encoder Loss:  0.056442186  || Decoder Loss:  0.072830446 Validation Decoder Loss:  0.38398117
Encoder Loss:  0.05618225  || Decoder Loss:  0.07172461 Validation Decoder Loss:  0.3824642
Encoder Loss:  0.05594516  || Decoder Loss:  0.070674 Validation Decoder Loss:  0.38103488
Encoder Loss:  0.05570608  || Decoder Loss:  0.06967949 Validation Decoder Loss:  0.37967962
Encoder Loss:  0.05549283  || Decoder Loss:  0.06873345 Validation Decoder Loss:  0.37839678
Encoder Loss:  0.05529122  || Decoder Loss:  0.06783274 Validation Decoder Loss:  0.37718356
Encoder Loss:  0.05509703  || Decoder Loss:  0.066975795 Validation Decoder Loss:  0.37603354
Encoder Loss:  0.05492795  || Decoder Loss:  0.066162325 Validation Decoder Loss:  0.37496406
Encoder Loss:  0.054741245  || Decoder Loss:  0.06538477 Validation Decoder Loss:  0.37392586
Encoder Loss:  0.05457526  || Decoder Loss:  0.06463645 Validation Decoder Loss:  0.3729322
Encoder Loss:  0.054432344  || Decoder Loss:  0.06392471 Validation Decoder Loss:  0.3720188
Encoder Loss:  0.054264165  || Decoder Loss:  0.06324304 Validation Decoder Loss:  0.37112796
Encoder Loss:  0.054101825  || Decoder Loss:  0.06258306 Validation Decoder Loss:  0.37025028
Encoder Loss:  0.053970136  || Decoder Loss:  0.061946925 Validation Decoder Loss:  0.36943197
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36943197
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_12 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.74764746  || Decoder Loss:  0.9258221 Validation Decoder Loss:  1.6493443
Encoder Loss:  0.76509094  || Decoder Loss:  0.943673 Validation Decoder Loss:  1.6483442
Encoder Loss:  0.7638811  || Decoder Loss:  0.94124293 Validation Decoder Loss:  1.643354
Encoder Loss:  0.75620496  || Decoder Loss:  0.93228066 Validation Decoder Loss:  1.618866
Encoder Loss:  0.71505004  || Decoder Loss:  0.8921086 Validation Decoder Loss:  1.5025828
Encoder Loss:  0.5374539  || Decoder Loss:  0.7378471 Validation Decoder Loss:  1.1321417
Encoder Loss:  0.3645815  || Decoder Loss:  0.4282609 Validation Decoder Loss:  0.6583084
Encoder Loss:  0.16933766  || Decoder Loss:  0.18304223 Validation Decoder Loss:  0.43269062
Encoder Loss:  0.118143275  || Decoder Loss:  0.09228775 Validation Decoder Loss:  0.368548
Encoder Loss:  0.09041995  || Decoder Loss:  0.068630174 Validation Decoder Loss:  0.3529101
Encoder Loss:  0.09021061  || Decoder Loss:  0.06336267 Validation Decoder Loss:  0.3494234
Encoder Loss:  0.09300369  || Decoder Loss:  0.06278871 Validation Decoder Loss:  0.3487243
Encoder Loss:  0.09324003  || Decoder Loss:  0.06321845 Validation Decoder Loss:  0.34874594
Encoder Loss:  0.07904047  || Decoder Loss:  0.06397294 Validation Decoder Loss:  0.34889454
Encoder Loss:  0.07581914  || Decoder Loss:  0.064568445 Validation Decoder Loss:  0.34904328
Encoder Loss:  0.08065956  || Decoder Loss:  0.065157846 Validation Decoder Loss:  0.34915864
Encoder Loss:  0.07284584  || Decoder Loss:  0.06569732 Validation Decoder Loss:  0.34919798
Encoder Loss:  0.07278332  || Decoder Loss:  0.06619732 Validation Decoder Loss:  0.3492542
Encoder Loss:  0.07410747  || Decoder Loss:  0.06659141 Validation Decoder Loss:  0.34929967
Encoder Loss:  0.07995224  || Decoder Loss:  0.06718611 Validation Decoder Loss:  0.34948432
Encoder Loss:  0.07341313  || Decoder Loss:  0.06790106 Validation Decoder Loss:  0.34962377
Encoder Loss:  0.078419454  || Decoder Loss:  0.068440475 Validation Decoder Loss:  0.34976643
Encoder Loss:  0.069966435  || Decoder Loss:  0.06913506 Validation Decoder Loss:  0.34992304
Encoder Loss:  0.0730358  || Decoder Loss:  0.06961067 Validation Decoder Loss:  0.34993944
Encoder Loss:  0.07357401  || Decoder Loss:  0.07018385 Validation Decoder Loss:  0.3500626
Encoder Loss:  0.078414  || Decoder Loss:  0.07094758 Validation Decoder Loss:  0.35033596
Encoder Loss:  0.080206364  || Decoder Loss:  0.071782626 Validation Decoder Loss:  0.35062212
Encoder Loss:  0.098426126  || Decoder Loss:  0.07312006 Validation Decoder Loss:  0.35133275
Encoder Loss:  0.087570086  || Decoder Loss:  0.075751245 Validation Decoder Loss:  0.35227454
Encoder Loss:  0.0789464  || Decoder Loss:  0.077689864 Validation Decoder Loss:  0.35293198
Encoder Loss:  0.081468195  || Decoder Loss:  0.079278626 Validation Decoder Loss:  0.35357958
Encoder Loss:  0.08673769  || Decoder Loss:  0.08113121 Validation Decoder Loss:  0.35465705
Encoder Loss:  0.08690587  || Decoder Loss:  0.083669275 Validation Decoder Loss:  0.35605
Encoder Loss:  0.08893182  || Decoder Loss:  0.086728856 Validation Decoder Loss:  0.35783124
Encoder Loss:  0.08333924  || Decoder Loss:  0.090068646 Validation Decoder Loss:  0.35952294
Encoder Loss:  0.08553645  || Decoder Loss:  0.09226183 Validation Decoder Loss:  0.36091664
Encoder Loss:  0.09293154  || Decoder Loss:  0.0964364 Validation Decoder Loss:  0.36476445
Encoder Loss:  0.08816457  || Decoder Loss:  0.10141675 Validation Decoder Loss:  0.3675303
Encoder Loss:  0.09639831  || Decoder Loss:  0.104955345 Validation Decoder Loss:  0.3714853
Encoder Loss:  0.09360261  || Decoder Loss:  0.112129234 Validation Decoder Loss:  0.37624255
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37624255
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 272, 10, 20, 1)    121       
_________________________________________________________________
reshape_13 (Reshape)         (None, 2720, 20, 1)       0         
=================================================================
Total params: 121
Trainable params: 121
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 2720, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 3245, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43842176  || Decoder Loss:  0.06485296 Validation Decoder Loss:  0.3569329
Encoder Loss:  0.4466214  || Decoder Loss:  0.04554878 Validation Decoder Loss:  0.35698158
Encoder Loss:  0.44016418  || Decoder Loss:  0.045306295 Validation Decoder Loss:  0.35697335
Encoder Loss:  0.356243  || Decoder Loss:  0.16664396 Validation Decoder Loss:  1.6416461
Encoder Loss:  0.18664975  || Decoder Loss:  0.636188 Validation Decoder Loss:  0.36705852
Encoder Loss:  0.099999845  || Decoder Loss:  0.4289204 Validation Decoder Loss:  0.6611108
Encoder Loss:  0.07413511  || Decoder Loss:  0.5077425 Validation Decoder Loss:  0.70710516
Encoder Loss:  0.06338345  || Decoder Loss:  0.49087507 Validation Decoder Loss:  0.9915688
Encoder Loss:  0.06473139  || Decoder Loss:  0.5040663 Validation Decoder Loss:  0.9489715
Encoder Loss:  0.07009271  || Decoder Loss:  0.5003581 Validation Decoder Loss:  0.9215546
Encoder Loss:  0.06396187  || Decoder Loss:  0.49839282 Validation Decoder Loss:  0.9360784
Encoder Loss:  0.06705658  || Decoder Loss:  0.49908066 Validation Decoder Loss:  0.92034525
Encoder Loss:  0.06489132  || Decoder Loss:  0.49699065 Validation Decoder Loss:  1.0130732
Encoder Loss:  0.061444975  || Decoder Loss:  0.49921903 Validation Decoder Loss:  0.94719
Encoder Loss:  0.062254004  || Decoder Loss:  0.50164956 Validation Decoder Loss:  0.9733239
Encoder Loss:  0.06397458  || Decoder Loss:  0.49621192 Validation Decoder Loss:  1.0097344
Encoder Loss:  0.05893607  || Decoder Loss:  0.4931593 Validation Decoder Loss:  0.96880245
Encoder Loss:  0.054957937  || Decoder Loss:  0.4963568 Validation Decoder Loss:  1.0255238
Encoder Loss:  0.065524384  || Decoder Loss:  0.4956368 Validation Decoder Loss:  1.011482
Encoder Loss:  0.06546215  || Decoder Loss:  0.4922265 Validation Decoder Loss:  1.0221559
Encoder Loss:  0.05677469  || Decoder Loss:  0.486862 Validation Decoder Loss:  0.97385925
Encoder Loss:  0.061685424  || Decoder Loss:  0.50282544 Validation Decoder Loss:  0.85938424
Encoder Loss:  0.06653458  || Decoder Loss:  0.49091157 Validation Decoder Loss:  1.0290761
Encoder Loss:  0.06713112  || Decoder Loss:  0.49017894 Validation Decoder Loss:  0.965666
Encoder Loss:  0.062024117  || Decoder Loss:  0.49407318 Validation Decoder Loss:  0.9950774
Encoder Loss:  0.060166597  || Decoder Loss:  0.48700008 Validation Decoder Loss:  0.99660087
Encoder Loss:  0.06003307  || Decoder Loss:  0.48770905 Validation Decoder Loss:  0.97374433
Encoder Loss:  0.057191726  || Decoder Loss:  0.48795372 Validation Decoder Loss:  0.98881257
Encoder Loss:  0.060092308  || Decoder Loss:  0.48851806 Validation Decoder Loss:  0.9626123
Encoder Loss:  0.06949668  || Decoder Loss:  0.47100273 Validation Decoder Loss:  0.91337514
Encoder Loss:  0.061247863  || Decoder Loss:  0.47518045 Validation Decoder Loss:  1.0543344
Encoder Loss:  0.058302805  || Decoder Loss:  0.4826356 Validation Decoder Loss:  0.9815729
Encoder Loss:  0.056154743  || Decoder Loss:  0.48540515 Validation Decoder Loss:  0.96937144
Encoder Loss:  0.05273306  || Decoder Loss:  0.46283966 Validation Decoder Loss:  0.9963751
Encoder Loss:  0.054180298  || Decoder Loss:  0.4389529 Validation Decoder Loss:  0.94926643
Encoder Loss:  0.05737513  || Decoder Loss:  0.479031 Validation Decoder Loss:  0.98950654
Encoder Loss:  0.05545008  || Decoder Loss:  0.48545724 Validation Decoder Loss:  0.9810741
Encoder Loss:  0.061989345  || Decoder Loss:  0.48610008 Validation Decoder Loss:  0.97367173
Encoder Loss:  0.057723306  || Decoder Loss:  0.46456558 Validation Decoder Loss:  1.043025
Encoder Loss:  0.05677155  || Decoder Loss:  0.45727673 Validation Decoder Loss:  0.9112333
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9112333
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_14 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.74770075  || Decoder Loss:  0.89045584 Validation Decoder Loss:  1.5775752
Encoder Loss:  0.66451377  || Decoder Loss:  0.76424295 Validation Decoder Loss:  1.1196338
Encoder Loss:  0.29158828  || Decoder Loss:  0.21920614 Validation Decoder Loss:  0.38277543
Encoder Loss:  0.17893267  || Decoder Loss:  0.05474918 Validation Decoder Loss:  0.36988798
Encoder Loss:  0.17478867  || Decoder Loss:  0.049090043 Validation Decoder Loss:  0.37232804
Encoder Loss:  0.17303364  || Decoder Loss:  0.047324967 Validation Decoder Loss:  0.37109616
Encoder Loss:  0.17049496  || Decoder Loss:  0.045987625 Validation Decoder Loss:  0.36825386
Encoder Loss:  0.23831888  || Decoder Loss:  0.19133884 Validation Decoder Loss:  1.4986948
Encoder Loss:  0.36376137  || Decoder Loss:  0.49543107 Validation Decoder Loss:  1.3898411
Encoder Loss:  0.35384712  || Decoder Loss:  0.4821506 Validation Decoder Loss:  0.93654966
Encoder Loss:  0.34686816  || Decoder Loss:  0.47434396 Validation Decoder Loss:  1.3370831
Encoder Loss:  0.33313885  || Decoder Loss:  0.45549157 Validation Decoder Loss:  1.0001773
Encoder Loss:  0.34335637  || Decoder Loss:  0.47423497 Validation Decoder Loss:  1.0485444
Encoder Loss:  0.35809684  || Decoder Loss:  0.49356082 Validation Decoder Loss:  0.9999274
Encoder Loss:  0.35846284  || Decoder Loss:  0.49636063 Validation Decoder Loss:  1.018454
Encoder Loss:  0.3574955  || Decoder Loss:  0.49657384 Validation Decoder Loss:  0.9618118
Encoder Loss:  0.35229933  || Decoder Loss:  0.48781765 Validation Decoder Loss:  0.89757806
Encoder Loss:  0.35662147  || Decoder Loss:  0.4932222 Validation Decoder Loss:  0.93534994
Encoder Loss:  0.3242335  || Decoder Loss:  0.44581512 Validation Decoder Loss:  1.1013007
Encoder Loss:  0.3472799  || Decoder Loss:  0.47939372 Validation Decoder Loss:  1.0716875
Encoder Loss:  0.35744324  || Decoder Loss:  0.49568215 Validation Decoder Loss:  1.012364
Encoder Loss:  0.36809754  || Decoder Loss:  0.5105799 Validation Decoder Loss:  0.94822943
Encoder Loss:  0.35574096  || Decoder Loss:  0.4916934 Validation Decoder Loss:  1.1835988
Encoder Loss:  0.37255508  || Decoder Loss:  0.509748 Validation Decoder Loss:  1.1919749
Encoder Loss:  0.36300573  || Decoder Loss:  0.49873096 Validation Decoder Loss:  0.86223954
Encoder Loss:  0.35498378  || Decoder Loss:  0.48655343 Validation Decoder Loss:  1.0287421
Encoder Loss:  0.35135722  || Decoder Loss:  0.48734567 Validation Decoder Loss:  1.0536441
Encoder Loss:  0.35821748  || Decoder Loss:  0.49687737 Validation Decoder Loss:  0.98900115
Encoder Loss:  0.33418855  || Decoder Loss:  0.46256897 Validation Decoder Loss:  0.9743653
Encoder Loss:  0.36252323  || Decoder Loss:  0.50351566 Validation Decoder Loss:  1.016543
Encoder Loss:  0.3600749  || Decoder Loss:  0.4979221 Validation Decoder Loss:  1.0127997
Encoder Loss:  0.3601705  || Decoder Loss:  0.50044507 Validation Decoder Loss:  1.0180593
Encoder Loss:  0.35944453  || Decoder Loss:  0.4996922 Validation Decoder Loss:  0.9789606
Encoder Loss:  0.35871705  || Decoder Loss:  0.49841347 Validation Decoder Loss:  0.9922059
Encoder Loss:  0.3605057  || Decoder Loss:  0.49693403 Validation Decoder Loss:  1.0320673
Encoder Loss:  0.36037868  || Decoder Loss:  0.49995983 Validation Decoder Loss:  0.97840804
Encoder Loss:  0.36241964  || Decoder Loss:  0.5012798 Validation Decoder Loss:  0.9365256
Encoder Loss:  0.36239898  || Decoder Loss:  0.49834958 Validation Decoder Loss:  0.9384189
Encoder Loss:  0.36506107  || Decoder Loss:  0.50245404 Validation Decoder Loss:  0.95065737
Encoder Loss:  0.3580672  || Decoder Loss:  0.49666727 Validation Decoder Loss:  1.0365539
Model: siamese_net_lr_0.03785381884224736 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0365539
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_15 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6131719  || Decoder Loss:  0.7688932 Validation Decoder Loss:  0.8745708
Encoder Loss:  0.27354103  || Decoder Loss:  0.13468497 Validation Decoder Loss:  0.3681596
Encoder Loss:  0.2366367  || Decoder Loss:  0.05081471 Validation Decoder Loss:  0.3745594
Encoder Loss:  0.23508328  || Decoder Loss:  0.048552975 Validation Decoder Loss:  0.37195164
Encoder Loss:  0.23295307  || Decoder Loss:  0.046339206 Validation Decoder Loss:  0.3673119
Encoder Loss:  0.22904055  || Decoder Loss:  0.044280954 Validation Decoder Loss:  0.3633753
Encoder Loss:  0.20511398  || Decoder Loss:  0.043749474 Validation Decoder Loss:  0.4599513
Encoder Loss:  0.2989569  || Decoder Loss:  0.49486512 Validation Decoder Loss:  1.4421861
Encoder Loss:  0.2776481  || Decoder Loss:  0.46504062 Validation Decoder Loss:  1.266875
Encoder Loss:  0.27207747  || Decoder Loss:  0.45408466 Validation Decoder Loss:  0.89900446
Encoder Loss:  0.29332408  || Decoder Loss:  0.4954917 Validation Decoder Loss:  0.9120518
Encoder Loss:  0.29109842  || Decoder Loss:  0.49411088 Validation Decoder Loss:  0.9640062
Encoder Loss:  0.28213128  || Decoder Loss:  0.4788489 Validation Decoder Loss:  1.1019715
Encoder Loss:  0.28652924  || Decoder Loss:  0.47574592 Validation Decoder Loss:  1.1711655
Encoder Loss:  0.29794744  || Decoder Loss:  0.48902908 Validation Decoder Loss:  1.0920506
Encoder Loss:  0.2911089  || Decoder Loss:  0.47892377 Validation Decoder Loss:  1.0463104
Encoder Loss:  0.2754386  || Decoder Loss:  0.45152432 Validation Decoder Loss:  1.163163
Encoder Loss:  0.25660646  || Decoder Loss:  0.4249566 Validation Decoder Loss:  0.9925622
Encoder Loss:  0.2091238  || Decoder Loss:  0.33991775 Validation Decoder Loss:  0.494059
Encoder Loss:  0.13357832  || Decoder Loss:  0.19890699 Validation Decoder Loss:  0.6927403
Encoder Loss:  0.16049173  || Decoder Loss:  0.2390483 Validation Decoder Loss:  0.60513556
Encoder Loss:  0.07805082  || Decoder Loss:  0.09752738 Validation Decoder Loss:  0.5452601
Encoder Loss:  0.084361725  || Decoder Loss:  0.1089627 Validation Decoder Loss:  0.4801547
Encoder Loss:  0.064610235  || Decoder Loss:  0.07175542 Validation Decoder Loss:  0.462394
Encoder Loss:  0.06704057  || Decoder Loss:  0.06859493 Validation Decoder Loss:  0.38371876
Encoder Loss:  0.04721207  || Decoder Loss:  0.038107537 Validation Decoder Loss:  0.35473123
Encoder Loss:  0.04437395  || Decoder Loss:  0.032917246 Validation Decoder Loss:  0.35624665
Encoder Loss:  0.043882485  || Decoder Loss:  0.032073777 Validation Decoder Loss:  0.35671028
Encoder Loss:  0.043597512  || Decoder Loss:  0.031611398 Validation Decoder Loss:  0.3563915
Encoder Loss:  0.043400615  || Decoder Loss:  0.03131285 Validation Decoder Loss:  0.3560108
Encoder Loss:  0.04323724  || Decoder Loss:  0.031075906 Validation Decoder Loss:  0.3542732
Encoder Loss:  0.044900164  || Decoder Loss:  0.031065354 Validation Decoder Loss:  0.35519457
Encoder Loss:  0.043316465  || Decoder Loss:  0.03230625 Validation Decoder Loss:  0.37107873
Encoder Loss:  0.046778444  || Decoder Loss:  0.03523116 Validation Decoder Loss:  0.36022204
Encoder Loss:  0.047212742  || Decoder Loss:  0.03484901 Validation Decoder Loss:  0.37297982
Encoder Loss:  0.045777597  || Decoder Loss:  0.03614972 Validation Decoder Loss:  0.36161685
Encoder Loss:  0.044708043  || Decoder Loss:  0.034295656 Validation Decoder Loss:  0.35385948
Encoder Loss:  0.04283282  || Decoder Loss:  0.032013305 Validation Decoder Loss:  0.36402303
Encoder Loss:  0.04604713  || Decoder Loss:  0.03492358 Validation Decoder Loss:  0.36240047
Encoder Loss:  0.04391267  || Decoder Loss:  0.03200543 Validation Decoder Loss:  0.3565512
Model: siamese_net_lr_0.0258208059852448 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3565512
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_16 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6062703  || Decoder Loss:  0.8926964 Validation Decoder Loss:  1.6414609
Encoder Loss:  0.61811674  || Decoder Loss:  0.9123726 Validation Decoder Loss:  1.6397837
Encoder Loss:  0.61754245  || Decoder Loss:  0.91110003 Validation Decoder Loss:  1.6375048
Encoder Loss:  0.6167486  || Decoder Loss:  0.90940934 Validation Decoder Loss:  1.6346228
Encoder Loss:  0.6156797  || Decoder Loss:  0.90723914 Validation Decoder Loss:  1.6309664
Encoder Loss:  0.6141436  || Decoder Loss:  0.90434337 Validation Decoder Loss:  1.6259608
Encoder Loss:  0.61151284  || Decoder Loss:  0.89993644 Validation Decoder Loss:  1.6176071
Encoder Loss:  0.60517716  || Decoder Loss:  0.8912422 Validation Decoder Loss:  1.5984433
Encoder Loss:  0.57090455  || Decoder Loss:  0.8671027 Validation Decoder Loss:  1.5395854
Encoder Loss:  0.19781165  || Decoder Loss:  0.34500518 Validation Decoder Loss:  1.1541091
Encoder Loss:  0.15060395  || Decoder Loss:  0.30059794 Validation Decoder Loss:  1.2773571
Encoder Loss:  0.19039701  || Decoder Loss:  0.41073462 Validation Decoder Loss:  0.8645979
Encoder Loss:  0.13542588  || Decoder Loss:  0.26659188 Validation Decoder Loss:  0.47846997
Encoder Loss:  0.08206213  || Decoder Loss:  0.12035803 Validation Decoder Loss:  0.40597382
Encoder Loss:  0.085582405  || Decoder Loss:  0.11535502 Validation Decoder Loss:  0.43540987
Encoder Loss:  0.07109316  || Decoder Loss:  0.06623221 Validation Decoder Loss:  0.38994694
Encoder Loss:  0.056314446  || Decoder Loss:  0.045416612 Validation Decoder Loss:  0.36096364
Encoder Loss:  0.049941093  || Decoder Loss:  0.039074365 Validation Decoder Loss:  0.35942873
Encoder Loss:  0.054985117  || Decoder Loss:  0.039223634 Validation Decoder Loss:  0.37105456
Encoder Loss:  0.050942663  || Decoder Loss:  0.039475303 Validation Decoder Loss:  0.35286856
Encoder Loss:  0.049685497  || Decoder Loss:  0.03857548 Validation Decoder Loss:  0.35123152
Encoder Loss:  0.05324558  || Decoder Loss:  0.037778463 Validation Decoder Loss:  0.3552488
Encoder Loss:  0.054444358  || Decoder Loss:  0.03953894 Validation Decoder Loss:  0.35535106
Encoder Loss:  0.050656483  || Decoder Loss:  0.03762752 Validation Decoder Loss:  0.36135426
Encoder Loss:  0.05120925  || Decoder Loss:  0.041354448 Validation Decoder Loss:  0.35799015
Encoder Loss:  0.047858592  || Decoder Loss:  0.038624886 Validation Decoder Loss:  0.36485773
Encoder Loss:  0.050486222  || Decoder Loss:  0.038934495 Validation Decoder Loss:  0.36595786
Encoder Loss:  0.050448813  || Decoder Loss:  0.039600734 Validation Decoder Loss:  0.3659172
Encoder Loss:  0.049887225  || Decoder Loss:  0.03938793 Validation Decoder Loss:  0.37085575
Encoder Loss:  0.051009048  || Decoder Loss:  0.039879728 Validation Decoder Loss:  0.3532492
Encoder Loss:  0.049578547  || Decoder Loss:  0.036270946 Validation Decoder Loss:  0.36625746
Encoder Loss:  0.050288595  || Decoder Loss:  0.038401898 Validation Decoder Loss:  0.37223697
Encoder Loss:  0.051210523  || Decoder Loss:  0.04109539 Validation Decoder Loss:  0.361613
Encoder Loss:  0.04921073  || Decoder Loss:  0.035780396 Validation Decoder Loss:  0.3674898
Encoder Loss:  0.049893875  || Decoder Loss:  0.037806176 Validation Decoder Loss:  0.37339306
Encoder Loss:  0.052514922  || Decoder Loss:  0.042141143 Validation Decoder Loss:  0.3689685
Encoder Loss:  0.051793553  || Decoder Loss:  0.03926079 Validation Decoder Loss:  0.35925323
Encoder Loss:  0.04992485  || Decoder Loss:  0.037404966 Validation Decoder Loss:  0.34910077
Encoder Loss:  0.05312463  || Decoder Loss:  0.037797123 Validation Decoder Loss:  0.3598723
Encoder Loss:  0.051853925  || Decoder Loss:  0.04044895 Validation Decoder Loss:  0.35960063
Model: siamese_net_lr_0.03644262787812829 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35960063
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_17 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.69867563  || Decoder Loss:  0.9160404 Validation Decoder Loss:  1.633002
Encoder Loss:  0.7098961  || Decoder Loss:  0.92979056 Validation Decoder Loss:  1.6300446
Encoder Loss:  0.70691186  || Decoder Loss:  0.9244363 Validation Decoder Loss:  1.6248246
Encoder Loss:  0.7024597  || Decoder Loss:  0.91643053 Validation Decoder Loss:  1.6158974
Encoder Loss:  0.6958368  || Decoder Loss:  0.9044918 Validation Decoder Loss:  1.6008096
Encoder Loss:  0.6858271  || Decoder Loss:  0.88639885 Validation Decoder Loss:  1.575125
Encoder Loss:  0.67007166  || Decoder Loss:  0.8578375 Validation Decoder Loss:  1.5297744
Encoder Loss:  0.64322275  || Decoder Loss:  0.80900866 Validation Decoder Loss:  1.4423785
Encoder Loss:  0.590348  || Decoder Loss:  0.7125057 Validation Decoder Loss:  1.2440147
Encoder Loss:  0.46987045  || Decoder Loss:  0.49195668 Validation Decoder Loss:  0.79316443
Encoder Loss:  0.30608606  || Decoder Loss:  0.1923827 Validation Decoder Loss:  0.47591168
Encoder Loss:  0.24393919  || Decoder Loss:  0.08145985 Validation Decoder Loss:  0.4114292
Encoder Loss:  0.22683626  || Decoder Loss:  0.06121916 Validation Decoder Loss:  0.40375042
Encoder Loss:  0.35861152  || Decoder Loss:  0.44013992 Validation Decoder Loss:  1.1047075
Encoder Loss:  0.2862427  || Decoder Loss:  0.44321233 Validation Decoder Loss:  1.3076422
Encoder Loss:  0.28208837  || Decoder Loss:  0.43735468 Validation Decoder Loss:  1.2745825
Encoder Loss:  0.28459397  || Decoder Loss:  0.4459517 Validation Decoder Loss:  1.3144917
Encoder Loss:  0.2811386  || Decoder Loss:  0.4427031 Validation Decoder Loss:  1.3190272
Encoder Loss:  0.27883676  || Decoder Loss:  0.4405267 Validation Decoder Loss:  1.2053003
Encoder Loss:  0.27056336  || Decoder Loss:  0.43042007 Validation Decoder Loss:  1.2419207
Encoder Loss:  0.27008954  || Decoder Loss:  0.43142146 Validation Decoder Loss:  1.2635788
Encoder Loss:  0.26921552  || Decoder Loss:  0.4316799 Validation Decoder Loss:  1.2532889
Encoder Loss:  0.26794145  || Decoder Loss:  0.431693 Validation Decoder Loss:  1.2486229
Encoder Loss:  0.2629447  || Decoder Loss:  0.42415553 Validation Decoder Loss:  1.2983401
Encoder Loss:  0.26404652  || Decoder Loss:  0.42836037 Validation Decoder Loss:  1.1371257
Encoder Loss:  0.2652004  || Decoder Loss:  0.4312925 Validation Decoder Loss:  1.2583945
Encoder Loss:  0.25531986  || Decoder Loss:  0.41528997 Validation Decoder Loss:  1.1305492
Encoder Loss:  0.24557494  || Decoder Loss:  0.39901885 Validation Decoder Loss:  1.1378446
Encoder Loss:  0.25513184  || Decoder Loss:  0.41715103 Validation Decoder Loss:  1.0214939
Encoder Loss:  0.22029656  || Decoder Loss:  0.35681626 Validation Decoder Loss:  1.1366559
Encoder Loss:  0.2817907  || Decoder Loss:  0.46896175 Validation Decoder Loss:  0.9967691
Encoder Loss:  0.28905505  || Decoder Loss:  0.48219317 Validation Decoder Loss:  0.99757934
Encoder Loss:  0.28560874  || Decoder Loss:  0.47760773 Validation Decoder Loss:  0.95086473
Encoder Loss:  0.2261415  || Decoder Loss:  0.37047833 Validation Decoder Loss:  0.98811966
Encoder Loss:  0.29108745  || Decoder Loss:  0.48315454 Validation Decoder Loss:  0.98284996
Encoder Loss:  0.28756234  || Decoder Loss:  0.4808333 Validation Decoder Loss:  0.97626483
Encoder Loss:  0.27850997  || Decoder Loss:  0.45880955 Validation Decoder Loss:  1.1038084
Encoder Loss:  0.2974537  || Decoder Loss:  0.4961933 Validation Decoder Loss:  0.96817374
Encoder Loss:  0.29651588  || Decoder Loss:  0.48767188 Validation Decoder Loss:  0.98314047
Encoder Loss:  0.29511207  || Decoder Loss:  0.49103096 Validation Decoder Loss:  0.9769621
Model: siamese_net_lr_0.05654206731403558 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9769621
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_18 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24503353  || Decoder Loss:  0.4004485 Validation Decoder Loss:  0.78378385
Encoder Loss:  0.20512052  || Decoder Loss:  0.34591183 Validation Decoder Loss:  0.67860377
Encoder Loss:  0.17246763  || Decoder Loss:  0.28334987 Validation Decoder Loss:  0.59435827
Encoder Loss:  0.1484442  || Decoder Loss:  0.23684284 Validation Decoder Loss:  0.535858
Encoder Loss:  0.13065642  || Decoder Loss:  0.20257187 Validation Decoder Loss:  0.49447986
Encoder Loss:  0.11729496  || Decoder Loss:  0.1769844 Validation Decoder Loss:  0.46424216
Encoder Loss:  0.10703022  || Decoder Loss:  0.15753594 Validation Decoder Loss:  0.44206256
Encoder Loss:  0.09916837  || Decoder Loss:  0.14273195 Validation Decoder Loss:  0.42551452
Encoder Loss:  0.09291752  || Decoder Loss:  0.13095063 Validation Decoder Loss:  0.4124073
Encoder Loss:  0.087745845  || Decoder Loss:  0.12123821 Validation Decoder Loss:  0.4019959
Encoder Loss:  0.08355952  || Decoder Loss:  0.113318376 Validation Decoder Loss:  0.39358574
Encoder Loss:  0.080012456  || Decoder Loss:  0.106558144 Validation Decoder Loss:  0.38658705
Encoder Loss:  0.07694741  || Decoder Loss:  0.10066087 Validation Decoder Loss:  0.3806997
Encoder Loss:  0.07428445  || Decoder Loss:  0.09556238 Validation Decoder Loss:  0.3757242
Encoder Loss:  0.07204509  || Decoder Loss:  0.0912217 Validation Decoder Loss:  0.37150282
Encoder Loss:  0.07004304  || Decoder Loss:  0.08743463 Validation Decoder Loss:  0.3677497
Encoder Loss:  0.068363555  || Decoder Loss:  0.084157504 Validation Decoder Loss:  0.36457056
Encoder Loss:  0.066886045  || Decoder Loss:  0.08130772 Validation Decoder Loss:  0.36173564
Encoder Loss:  0.065560214  || Decoder Loss:  0.07877157 Validation Decoder Loss:  0.35924125
Encoder Loss:  0.0643799  || Decoder Loss:  0.07649558 Validation Decoder Loss:  0.35702392
Encoder Loss:  0.063310705  || Decoder Loss:  0.07441973 Validation Decoder Loss:  0.35503033
Encoder Loss:  0.062352777  || Decoder Loss:  0.072556496 Validation Decoder Loss:  0.35324723
Encoder Loss:  0.061472625  || Decoder Loss:  0.070864335 Validation Decoder Loss:  0.35163206
Encoder Loss:  0.060662184  || Decoder Loss:  0.06931784 Validation Decoder Loss:  0.35020304
Encoder Loss:  0.05993175  || Decoder Loss:  0.06790926 Validation Decoder Loss:  0.34889647
Encoder Loss:  0.059246436  || Decoder Loss:  0.06659505 Validation Decoder Loss:  0.34772307
Encoder Loss:  0.058612667  || Decoder Loss:  0.065371245 Validation Decoder Loss:  0.3466495
Encoder Loss:  0.0579983  || Decoder Loss:  0.06422522 Validation Decoder Loss:  0.34565696
Encoder Loss:  0.057441827  || Decoder Loss:  0.063142665 Validation Decoder Loss:  0.34475246
Encoder Loss:  0.056912437  || Decoder Loss:  0.062130384 Validation Decoder Loss:  0.34392342
Encoder Loss:  0.056418147  || Decoder Loss:  0.061174635 Validation Decoder Loss:  0.34317148
Encoder Loss:  0.05593536  || Decoder Loss:  0.060266394 Validation Decoder Loss:  0.34245893
Encoder Loss:  0.055492144  || Decoder Loss:  0.059408892 Validation Decoder Loss:  0.34182084
Encoder Loss:  0.05507181  || Decoder Loss:  0.05860306 Validation Decoder Loss:  0.3412543
Encoder Loss:  0.05464652  || Decoder Loss:  0.057815585 Validation Decoder Loss:  0.34066916
Encoder Loss:  0.05429208  || Decoder Loss:  0.057081193 Validation Decoder Loss:  0.34023345
Encoder Loss:  0.05388798  || Decoder Loss:  0.056381866 Validation Decoder Loss:  0.3397189
Encoder Loss:  0.053583097  || Decoder Loss:  0.055713557 Validation Decoder Loss:  0.3393817
Encoder Loss:  0.053192686  || Decoder Loss:  0.05507128 Validation Decoder Loss:  0.3389296
Encoder Loss:  0.052896805  || Decoder Loss:  0.054449096 Validation Decoder Loss:  0.33858746
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33858746
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_19 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.603952  || Decoder Loss:  0.89025015 Validation Decoder Loss:  1.629308
Encoder Loss:  0.62583524  || Decoder Loss:  0.89485186 Validation Decoder Loss:  1.5732274
Encoder Loss:  0.5699544  || Decoder Loss:  0.75514954 Validation Decoder Loss:  1.0438174
Encoder Loss:  0.39119643  || Decoder Loss:  0.30855295 Validation Decoder Loss:  0.45422018
Encoder Loss:  0.31084752  || Decoder Loss:  0.109859526 Validation Decoder Loss:  0.35203654
Encoder Loss:  0.2960005  || Decoder Loss:  0.081358545 Validation Decoder Loss:  0.33987954
Encoder Loss:  0.28923428  || Decoder Loss:  0.22856098 Validation Decoder Loss:  1.4706511
Encoder Loss:  0.24109325  || Decoder Loss:  0.45078084 Validation Decoder Loss:  0.66575027
Encoder Loss:  0.20658071  || Decoder Loss:  0.41829574 Validation Decoder Loss:  0.8246803
Encoder Loss:  0.13066077  || Decoder Loss:  0.24186033 Validation Decoder Loss:  0.86878216
Encoder Loss:  0.12005162  || Decoder Loss:  0.20243973 Validation Decoder Loss:  0.53699994
Encoder Loss:  0.09687178  || Decoder Loss:  0.15039752 Validation Decoder Loss:  0.4541877
Encoder Loss:  0.058989186  || Decoder Loss:  0.06374728 Validation Decoder Loss:  0.35978144
Encoder Loss:  0.04932486  || Decoder Loss:  0.04015328 Validation Decoder Loss:  0.38824317
Encoder Loss:  0.05261838  || Decoder Loss:  0.04100755 Validation Decoder Loss:  0.34334952
Encoder Loss:  0.051692303  || Decoder Loss:  0.03999381 Validation Decoder Loss:  0.3912746
Encoder Loss:  0.05905364  || Decoder Loss:  0.047389477 Validation Decoder Loss:  0.39847225
Encoder Loss:  0.056075744  || Decoder Loss:  0.038895678 Validation Decoder Loss:  0.35656583
Encoder Loss:  0.050366983  || Decoder Loss:  0.03507651 Validation Decoder Loss:  0.34533718
Encoder Loss:  0.04812118  || Decoder Loss:  0.033730272 Validation Decoder Loss:  0.3530146
Encoder Loss:  0.049716905  || Decoder Loss:  0.03484219 Validation Decoder Loss:  0.3763941
Encoder Loss:  0.05118309  || Decoder Loss:  0.041362215 Validation Decoder Loss:  0.34612238
Encoder Loss:  0.04833074  || Decoder Loss:  0.03454922 Validation Decoder Loss:  0.3457428
Encoder Loss:  0.048027147  || Decoder Loss:  0.034336697 Validation Decoder Loss:  0.3571789
Encoder Loss:  0.049238525  || Decoder Loss:  0.035590168 Validation Decoder Loss:  0.36750203
Encoder Loss:  0.05814081  || Decoder Loss:  0.040209927 Validation Decoder Loss:  0.35277253
Encoder Loss:  0.04935016  || Decoder Loss:  0.03775516 Validation Decoder Loss:  0.34615353
Encoder Loss:  0.048530612  || Decoder Loss:  0.03411864 Validation Decoder Loss:  0.34755668
Encoder Loss:  0.049700078  || Decoder Loss:  0.03731465 Validation Decoder Loss:  0.357324
Encoder Loss:  0.053686608  || Decoder Loss:  0.041419376 Validation Decoder Loss:  0.3502559
Encoder Loss:  0.050362915  || Decoder Loss:  0.038196336 Validation Decoder Loss:  0.37313083
Encoder Loss:  0.054307375  || Decoder Loss:  0.041991282 Validation Decoder Loss:  0.3564297
Encoder Loss:  0.04778655  || Decoder Loss:  0.036335066 Validation Decoder Loss:  0.35770085
Encoder Loss:  0.04804748  || Decoder Loss:  0.035209984 Validation Decoder Loss:  0.36162493
Encoder Loss:  0.048193254  || Decoder Loss:  0.03607474 Validation Decoder Loss:  0.35128158
Encoder Loss:  0.047300383  || Decoder Loss:  0.034705967 Validation Decoder Loss:  0.3557096
Encoder Loss:  0.050649032  || Decoder Loss:  0.035625845 Validation Decoder Loss:  0.35219613
Encoder Loss:  0.04992199  || Decoder Loss:  0.034975518 Validation Decoder Loss:  0.37175184
Encoder Loss:  0.052964285  || Decoder Loss:  0.0412593 Validation Decoder Loss:  0.3535063
Encoder Loss:  0.04818871  || Decoder Loss:  0.035251737 Validation Decoder Loss:  0.35478687
Model: siamese_net_lr_0.017756109353070607 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35478687
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_20 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2119373  || Decoder Loss:  0.481299 Validation Decoder Loss:  0.9087041
Encoder Loss:  0.18411995  || Decoder Loss:  0.4180931 Validation Decoder Loss:  0.8035102
Encoder Loss:  0.16028656  || Decoder Loss:  0.35533753 Validation Decoder Loss:  0.71095335
Encoder Loss:  0.14079167  || Decoder Loss:  0.30112958 Validation Decoder Loss:  0.63817775
Encoder Loss:  0.12521607  || Decoder Loss:  0.2577318 Validation Decoder Loss:  0.58374214
Encoder Loss:  0.113137335  || Decoder Loss:  0.2240997 Validation Decoder Loss:  0.5435114
Encoder Loss:  0.10382216  || Decoder Loss:  0.19816312 Validation Decoder Loss:  0.5134952
Encoder Loss:  0.09656578  || Decoder Loss:  0.17795649 Validation Decoder Loss:  0.49066103
Encoder Loss:  0.09080774  || Decoder Loss:  0.16195242 Validation Decoder Loss:  0.47290525
Encoder Loss:  0.08615914  || Decoder Loss:  0.14904661 Validation Decoder Loss:  0.45880684
Encoder Loss:  0.08234087  || Decoder Loss:  0.1384584 Validation Decoder Loss:  0.44739753
Encoder Loss:  0.07916048  || Decoder Loss:  0.12963381 Validation Decoder Loss:  0.43800074
Encoder Loss:  0.0764704  || Decoder Loss:  0.122176 Validation Decoder Loss:  0.43015337
Encoder Loss:  0.074175246  || Decoder Loss:  0.11579525 Validation Decoder Loss:  0.4235
Encoder Loss:  0.07217473  || Decoder Loss:  0.11027603 Validation Decoder Loss:  0.41780636
Encoder Loss:  0.07043524  || Decoder Loss:  0.105455905 Validation Decoder Loss:  0.41288137
Encoder Loss:  0.0689023  || Decoder Loss:  0.101210825 Validation Decoder Loss:  0.40857697
Encoder Loss:  0.06754847  || Decoder Loss:  0.097443536 Validation Decoder Loss:  0.40479288
Encoder Loss:  0.06633478  || Decoder Loss:  0.094077446 Validation Decoder Loss:  0.4014274
Encoder Loss:  0.06523802  || Decoder Loss:  0.09105116 Validation Decoder Loss:  0.39842612
Encoder Loss:  0.06424475  || Decoder Loss:  0.08831556 Validation Decoder Loss:  0.39572948
Encoder Loss:  0.06334623  || Decoder Loss:  0.08583032 Validation Decoder Loss:  0.39330068
Encoder Loss:  0.062527515  || Decoder Loss:  0.0835623 Validation Decoder Loss:  0.3910898
Encoder Loss:  0.06177695  || Decoder Loss:  0.08148369 Validation Decoder Loss:  0.38907665
Encoder Loss:  0.061088476  || Decoder Loss:  0.079571545 Validation Decoder Loss:  0.3872427
Encoder Loss:  0.06044097  || Decoder Loss:  0.07780652 Validation Decoder Loss:  0.38554722
Encoder Loss:  0.059844647  || Decoder Loss:  0.076171786 Validation Decoder Loss:  0.38398105
Encoder Loss:  0.05928399  || Decoder Loss:  0.074653246 Validation Decoder Loss:  0.38253978
Encoder Loss:  0.05876586  || Decoder Loss:  0.0732385 Validation Decoder Loss:  0.38120311
Encoder Loss:  0.05828186  || Decoder Loss:  0.071917266 Validation Decoder Loss:  0.37996233
Encoder Loss:  0.05783159  || Decoder Loss:  0.07068044 Validation Decoder Loss:  0.37880522
Encoder Loss:  0.05740971  || Decoder Loss:  0.069519766 Validation Decoder Loss:  0.3777247
Encoder Loss:  0.057010975  || Decoder Loss:  0.06842863 Validation Decoder Loss:  0.3767115
Encoder Loss:  0.05663637  || Decoder Loss:  0.06740062 Validation Decoder Loss:  0.37576196
Encoder Loss:  0.05628293  || Decoder Loss:  0.06643032 Validation Decoder Loss:  0.3748675
Encoder Loss:  0.055946827  || Decoder Loss:  0.065512925 Validation Decoder Loss:  0.3740245
Encoder Loss:  0.055629905  || Decoder Loss:  0.064644076 Validation Decoder Loss:  0.37323138
Encoder Loss:  0.0553272  || Decoder Loss:  0.06381991 Validation Decoder Loss:  0.37248102
Encoder Loss:  0.05504411  || Decoder Loss:  0.063036926 Validation Decoder Loss:  0.3717705
Encoder Loss:  0.054770045  || Decoder Loss:  0.06229218 Validation Decoder Loss:  0.37109467
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37109464
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_21 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.088988096  || Decoder Loss:  0.271406 Validation Decoder Loss:  0.46221745
Encoder Loss:  0.0574714  || Decoder Loss:  0.08415083 Validation Decoder Loss:  0.38825667
Encoder Loss:  0.053783264  || Decoder Loss:  0.06402301 Validation Decoder Loss:  0.3731886
Encoder Loss:  0.052660313  || Decoder Loss:  0.056841522 Validation Decoder Loss:  0.3652894
Encoder Loss:  0.051931467  || Decoder Loss:  0.052469872 Validation Decoder Loss:  0.36036247
Encoder Loss:  0.051455416  || Decoder Loss:  0.04931217 Validation Decoder Loss:  0.35624275
Encoder Loss:  0.05128877  || Decoder Loss:  0.04728978 Validation Decoder Loss:  0.35584518
Encoder Loss:  0.050738383  || Decoder Loss:  0.045755986 Validation Decoder Loss:  0.35405064
Encoder Loss:  0.050718144  || Decoder Loss:  0.04468494 Validation Decoder Loss:  0.35291868
Encoder Loss:  0.050795447  || Decoder Loss:  0.043305922 Validation Decoder Loss:  0.351494
Encoder Loss:  0.0508643  || Decoder Loss:  0.04313271 Validation Decoder Loss:  0.35396513
Encoder Loss:  0.05039236  || Decoder Loss:  0.042222045 Validation Decoder Loss:  0.3537168
Encoder Loss:  0.0504351  || Decoder Loss:  0.041214075 Validation Decoder Loss:  0.3505961
Encoder Loss:  0.050328244  || Decoder Loss:  0.040525693 Validation Decoder Loss:  0.35018265
Encoder Loss:  0.050180458  || Decoder Loss:  0.039984435 Validation Decoder Loss:  0.35078686
Encoder Loss:  0.050196752  || Decoder Loss:  0.039385695 Validation Decoder Loss:  0.34931946
Encoder Loss:  0.049900565  || Decoder Loss:  0.038603846 Validation Decoder Loss:  0.34848207
Encoder Loss:  0.049927425  || Decoder Loss:  0.0383621 Validation Decoder Loss:  0.3487084
Encoder Loss:  0.05002148  || Decoder Loss:  0.038689997 Validation Decoder Loss:  0.3514018
Encoder Loss:  0.049996  || Decoder Loss:  0.038094163 Validation Decoder Loss:  0.34970507
Encoder Loss:  0.04974118  || Decoder Loss:  0.037816312 Validation Decoder Loss:  0.34902114
Encoder Loss:  0.049750578  || Decoder Loss:  0.037596043 Validation Decoder Loss:  0.35002252
Encoder Loss:  0.050110113  || Decoder Loss:  0.03728336 Validation Decoder Loss:  0.35084158
Encoder Loss:  0.049899947  || Decoder Loss:  0.037085753 Validation Decoder Loss:  0.34739354
Encoder Loss:  0.049604367  || Decoder Loss:  0.036478795 Validation Decoder Loss:  0.34801394
Encoder Loss:  0.04972192  || Decoder Loss:  0.036791097 Validation Decoder Loss:  0.3493299
Encoder Loss:  0.04972456  || Decoder Loss:  0.03623879 Validation Decoder Loss:  0.34731454
Encoder Loss:  0.049442764  || Decoder Loss:  0.0360327 Validation Decoder Loss:  0.34783837
Encoder Loss:  0.049468637  || Decoder Loss:  0.03607374 Validation Decoder Loss:  0.34818012
Encoder Loss:  0.04947867  || Decoder Loss:  0.035682715 Validation Decoder Loss:  0.3467839
Encoder Loss:  0.049413513  || Decoder Loss:  0.035528667 Validation Decoder Loss:  0.34741935
Encoder Loss:  0.049542133  || Decoder Loss:  0.035613444 Validation Decoder Loss:  0.34792125
Encoder Loss:  0.049409274  || Decoder Loss:  0.03535047 Validation Decoder Loss:  0.34664708
Encoder Loss:  0.049369756  || Decoder Loss:  0.035082046 Validation Decoder Loss:  0.34720582
Encoder Loss:  0.049513355  || Decoder Loss:  0.035033017 Validation Decoder Loss:  0.34727496
Encoder Loss:  0.049541622  || Decoder Loss:  0.034949776 Validation Decoder Loss:  0.346945
Encoder Loss:  0.04941661  || Decoder Loss:  0.034804516 Validation Decoder Loss:  0.3473301
Encoder Loss:  0.04930599  || Decoder Loss:  0.034810837 Validation Decoder Loss:  0.3473841
Encoder Loss:  0.04932538  || Decoder Loss:  0.034736328 Validation Decoder Loss:  0.34676898
Encoder Loss:  0.0493116  || Decoder Loss:  0.034447752 Validation Decoder Loss:  0.3459969
Model: siamese_net_lr_0.00013935674600354975 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34599686
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_22 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13454865  || Decoder Loss:  0.47246945 Validation Decoder Loss:  0.91215086
Encoder Loss:  0.12122269  || Decoder Loss:  0.40720555 Validation Decoder Loss:  0.7969947
Encoder Loss:  0.107184984  || Decoder Loss:  0.33702588 Validation Decoder Loss:  0.6937215
Encoder Loss:  0.09529985  || Decoder Loss:  0.2773209 Validation Decoder Loss:  0.6151781
Encoder Loss:  0.086314365  || Decoder Loss:  0.23198038 Validation Decoder Loss:  0.55958474
Encoder Loss:  0.07973117  || Decoder Loss:  0.19894505 Validation Decoder Loss:  0.5207881
Encoder Loss:  0.074909195  || Decoder Loss:  0.17464317 Validation Decoder Loss:  0.4925511
Encoder Loss:  0.071232945  || Decoder Loss:  0.15628675 Validation Decoder Loss:  0.47154176
Encoder Loss:  0.06839455  || Decoder Loss:  0.14201078 Validation Decoder Loss:  0.4555394
Encoder Loss:  0.06618607  || Decoder Loss:  0.13062465 Validation Decoder Loss:  0.44265673
Encoder Loss:  0.0643055  || Decoder Loss:  0.121345796 Validation Decoder Loss:  0.4323616
Encoder Loss:  0.062787324  || Decoder Loss:  0.11363879 Validation Decoder Loss:  0.42384255
Encoder Loss:  0.061506793  || Decoder Loss:  0.10713874 Validation Decoder Loss:  0.4167465
Encoder Loss:  0.060412012  || Decoder Loss:  0.10158365 Validation Decoder Loss:  0.41067407
Encoder Loss:  0.059440568  || Decoder Loss:  0.09678087 Validation Decoder Loss:  0.4053798
Encoder Loss:  0.058565177  || Decoder Loss:  0.09258513 Validation Decoder Loss:  0.4009366
Encoder Loss:  0.057895314  || Decoder Loss:  0.08888724 Validation Decoder Loss:  0.39693362
Encoder Loss:  0.05721077  || Decoder Loss:  0.0856046 Validation Decoder Loss:  0.39348763
Encoder Loss:  0.056602985  || Decoder Loss:  0.082668036 Validation Decoder Loss:  0.39030865
Encoder Loss:  0.05606885  || Decoder Loss:  0.08002553 Validation Decoder Loss:  0.38753995
Encoder Loss:  0.055609893  || Decoder Loss:  0.077634834 Validation Decoder Loss:  0.3851075
Encoder Loss:  0.055210587  || Decoder Loss:  0.07546132 Validation Decoder Loss:  0.38285238
Encoder Loss:  0.05480387  || Decoder Loss:  0.07347576 Validation Decoder Loss:  0.3807571
Encoder Loss:  0.054390326  || Decoder Loss:  0.07165426 Validation Decoder Loss:  0.3789036
Encoder Loss:  0.054058205  || Decoder Loss:  0.06997708 Validation Decoder Loss:  0.3771537
Encoder Loss:  0.053805523  || Decoder Loss:  0.06842742 Validation Decoder Loss:  0.3755455
Encoder Loss:  0.053532343  || Decoder Loss:  0.06699111 Validation Decoder Loss:  0.3741251
Encoder Loss:  0.053291302  || Decoder Loss:  0.0656558 Validation Decoder Loss:  0.37286127
Encoder Loss:  0.05301453  || Decoder Loss:  0.06441089 Validation Decoder Loss:  0.37157494
Encoder Loss:  0.0527317  || Decoder Loss:  0.063247465 Validation Decoder Loss:  0.3703845
Encoder Loss:  0.052529912  || Decoder Loss:  0.062157564 Validation Decoder Loss:  0.36932868
Encoder Loss:  0.052321266  || Decoder Loss:  0.061134025 Validation Decoder Loss:  0.3683232
Encoder Loss:  0.0521232  || Decoder Loss:  0.06017116 Validation Decoder Loss:  0.3673603
Encoder Loss:  0.05192774  || Decoder Loss:  0.059263367 Validation Decoder Loss:  0.36646658
Encoder Loss:  0.051814467  || Decoder Loss:  0.05840612 Validation Decoder Loss:  0.3656391
Encoder Loss:  0.05160826  || Decoder Loss:  0.057594966 Validation Decoder Loss:  0.364869
Encoder Loss:  0.051440552  || Decoder Loss:  0.056826342 Validation Decoder Loss:  0.36411387
Encoder Loss:  0.051355876  || Decoder Loss:  0.056096926 Validation Decoder Loss:  0.36342728
Encoder Loss:  0.051152788  || Decoder Loss:  0.0554035 Validation Decoder Loss:  0.36276698
Encoder Loss:  0.051098734  || Decoder Loss:  0.054743543 Validation Decoder Loss:  0.36215967
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36215967
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_23 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38936883  || Decoder Loss:  0.44663715 Validation Decoder Loss:  0.8639524
Encoder Loss:  0.33112353  || Decoder Loss:  0.3836595 Validation Decoder Loss:  0.76847756
Encoder Loss:  0.26941133  || Decoder Loss:  0.31024954 Validation Decoder Loss:  0.6576837
Encoder Loss:  0.22170624  || Decoder Loss:  0.25367615 Validation Decoder Loss:  0.5905843
Encoder Loss:  0.18887438  || Decoder Loss:  0.21454321 Validation Decoder Loss:  0.54555935
Encoder Loss:  0.16557278  || Decoder Loss:  0.18672256 Validation Decoder Loss:  0.5135859
Encoder Loss:  0.14833587  || Decoder Loss:  0.16614498 Validation Decoder Loss:  0.4899888
Encoder Loss:  0.13517801  || Decoder Loss:  0.15043758 Validation Decoder Loss:  0.4719833
Encoder Loss:  0.124798395  || Decoder Loss:  0.138055 Validation Decoder Loss:  0.45790976
Encoder Loss:  0.1164414  || Decoder Loss:  0.12808536 Validation Decoder Loss:  0.4466292
Encoder Loss:  0.109559104  || Decoder Loss:  0.119872525 Validation Decoder Loss:  0.4373064
Encoder Loss:  0.10376178  || Decoder Loss:  0.112972595 Validation Decoder Loss:  0.42955714
Encoder Loss:  0.098826066  || Decoder Loss:  0.10709537 Validation Decoder Loss:  0.42310643
Encoder Loss:  0.0945986  || Decoder Loss:  0.10204833 Validation Decoder Loss:  0.41746676
Encoder Loss:  0.09088121  || Decoder Loss:  0.09763789 Validation Decoder Loss:  0.41258004
Encoder Loss:  0.0876086  || Decoder Loss:  0.093755275 Validation Decoder Loss:  0.40839043
Encoder Loss:  0.08472467  || Decoder Loss:  0.09032194 Validation Decoder Loss:  0.40464872
Encoder Loss:  0.0821354  || Decoder Loss:  0.08725429 Validation Decoder Loss:  0.4013341
Encoder Loss:  0.07979987  || Decoder Loss:  0.084497735 Validation Decoder Loss:  0.39837092
Encoder Loss:  0.07769107  || Decoder Loss:  0.081996895 Validation Decoder Loss:  0.39574623
Encoder Loss:  0.075791106  || Decoder Loss:  0.07973518 Validation Decoder Loss:  0.39337274
Encoder Loss:  0.07405454  || Decoder Loss:  0.07766595 Validation Decoder Loss:  0.39115715
Encoder Loss:  0.07243741  || Decoder Loss:  0.075766824 Validation Decoder Loss:  0.38919318
Encoder Loss:  0.070963755  || Decoder Loss:  0.074016504 Validation Decoder Loss:  0.3873387
Encoder Loss:  0.069582045  || Decoder Loss:  0.07240528 Validation Decoder Loss:  0.38566852
Encoder Loss:  0.06830222  || Decoder Loss:  0.07090989 Validation Decoder Loss:  0.38416177
Encoder Loss:  0.06712986  || Decoder Loss:  0.06951732 Validation Decoder Loss:  0.38270736
Encoder Loss:  0.06601387  || Decoder Loss:  0.0682179 Validation Decoder Loss:  0.381396
Encoder Loss:  0.06497692  || Decoder Loss:  0.067004286 Validation Decoder Loss:  0.3802054
Encoder Loss:  0.06401387  || Decoder Loss:  0.065877646 Validation Decoder Loss:  0.37905985
Encoder Loss:  0.0630751  || Decoder Loss:  0.06481803 Validation Decoder Loss:  0.3779881
Encoder Loss:  0.06216492  || Decoder Loss:  0.063816994 Validation Decoder Loss:  0.37696743
Encoder Loss:  0.061278228  || Decoder Loss:  0.062884614 Validation Decoder Loss:  0.37584692
Encoder Loss:  0.06037943  || Decoder Loss:  0.061981905 Validation Decoder Loss:  0.37463036
Encoder Loss:  0.05958401  || Decoder Loss:  0.06112196 Validation Decoder Loss:  0.37387806
Encoder Loss:  0.058884088  || Decoder Loss:  0.06031818 Validation Decoder Loss:  0.37307256
Encoder Loss:  0.05821088  || Decoder Loss:  0.059537068 Validation Decoder Loss:  0.37223744
Encoder Loss:  0.057566557  || Decoder Loss:  0.058788203 Validation Decoder Loss:  0.3714887
Encoder Loss:  0.05696271  || Decoder Loss:  0.05808488 Validation Decoder Loss:  0.37079892
Encoder Loss:  0.056395687  || Decoder Loss:  0.05741862 Validation Decoder Loss:  0.37014747
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37014747
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_24 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23265506  || Decoder Loss:  0.0711823 Validation Decoder Loss:  0.34278
Encoder Loss:  0.18428774  || Decoder Loss:  0.08113312 Validation Decoder Loss:  0.3582099
Encoder Loss:  0.05509645  || Decoder Loss:  0.037395332 Validation Decoder Loss:  0.35253823
Encoder Loss:  0.04581201  || Decoder Loss:  0.036333654 Validation Decoder Loss:  0.35328734
Encoder Loss:  0.050733935  || Decoder Loss:  0.035800293 Validation Decoder Loss:  0.35694325
Encoder Loss:  0.048977613  || Decoder Loss:  0.03552946 Validation Decoder Loss:  0.35869586
Encoder Loss:  0.054373838  || Decoder Loss:  0.035189282 Validation Decoder Loss:  0.35251176
Encoder Loss:  0.04812996  || Decoder Loss:  0.035113595 Validation Decoder Loss:  0.3547964
Encoder Loss:  0.05009599  || Decoder Loss:  0.034615442 Validation Decoder Loss:  0.35266137
Encoder Loss:  0.04648818  || Decoder Loss:  0.03439248 Validation Decoder Loss:  0.35345703
Encoder Loss:  0.05432951  || Decoder Loss:  0.034574553 Validation Decoder Loss:  0.3496353
Encoder Loss:  0.055187237  || Decoder Loss:  0.034224063 Validation Decoder Loss:  0.35091323
Encoder Loss:  0.048215456  || Decoder Loss:  0.033808373 Validation Decoder Loss:  0.34976172
Encoder Loss:  0.04886402  || Decoder Loss:  0.033811055 Validation Decoder Loss:  0.34998822
Encoder Loss:  0.04599495  || Decoder Loss:  0.033762455 Validation Decoder Loss:  0.35035014
Encoder Loss:  0.04513707  || Decoder Loss:  0.033687852 Validation Decoder Loss:  0.3498451
Encoder Loss:  0.044672783  || Decoder Loss:  0.033635374 Validation Decoder Loss:  0.34933552
Encoder Loss:  0.047602095  || Decoder Loss:  0.03362802 Validation Decoder Loss:  0.34891742
Encoder Loss:  0.04484463  || Decoder Loss:  0.033567935 Validation Decoder Loss:  0.3491066
Encoder Loss:  0.044962138  || Decoder Loss:  0.033547968 Validation Decoder Loss:  0.34920633
Encoder Loss:  0.04578998  || Decoder Loss:  0.03352708 Validation Decoder Loss:  0.34847203
Encoder Loss:  0.044606756  || Decoder Loss:  0.033488516 Validation Decoder Loss:  0.34852007
Encoder Loss:  0.043686222  || Decoder Loss:  0.03346746 Validation Decoder Loss:  0.34862086
Encoder Loss:  0.046139564  || Decoder Loss:  0.033451673 Validation Decoder Loss:  0.34839576
Encoder Loss:  0.044132177  || Decoder Loss:  0.03343667 Validation Decoder Loss:  0.34852177
Encoder Loss:  0.049009662  || Decoder Loss:  0.033436783 Validation Decoder Loss:  0.34808227
Encoder Loss:  0.04682318  || Decoder Loss:  0.03340169 Validation Decoder Loss:  0.34818763
Encoder Loss:  0.04618231  || Decoder Loss:  0.033386473 Validation Decoder Loss:  0.34806165
Encoder Loss:  0.046604853  || Decoder Loss:  0.033375334 Validation Decoder Loss:  0.3482243
Encoder Loss:  0.04462153  || Decoder Loss:  0.03336192 Validation Decoder Loss:  0.34837368
Encoder Loss:  0.043990895  || Decoder Loss:  0.033344004 Validation Decoder Loss:  0.34831947
Encoder Loss:  0.044285856  || Decoder Loss:  0.03334456 Validation Decoder Loss:  0.34818244
Encoder Loss:  0.045612443  || Decoder Loss:  0.033324033 Validation Decoder Loss:  0.3479792
Encoder Loss:  0.04475043  || Decoder Loss:  0.033314258 Validation Decoder Loss:  0.34815833
Encoder Loss:  0.044484705  || Decoder Loss:  0.033302866 Validation Decoder Loss:  0.3483649
Encoder Loss:  0.04378622  || Decoder Loss:  0.03329594 Validation Decoder Loss:  0.3480917
Encoder Loss:  0.044217177  || Decoder Loss:  0.033284176 Validation Decoder Loss:  0.3479467
Encoder Loss:  0.044566814  || Decoder Loss:  0.03327481 Validation Decoder Loss:  0.34778804
Encoder Loss:  0.047672346  || Decoder Loss:  0.033275656 Validation Decoder Loss:  0.34775516
Encoder Loss:  0.044538822  || Decoder Loss:  0.033267807 Validation Decoder Loss:  0.34792727
Model: siamese_net_lr_0.008524841414205325 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34792727
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_25 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3256633  || Decoder Loss:  0.43302009 Validation Decoder Loss:  0.76934266
Encoder Loss:  0.21114689  || Decoder Loss:  0.27631748 Validation Decoder Loss:  0.55944073
Encoder Loss:  0.14298028  || Decoder Loss:  0.18084644 Validation Decoder Loss:  0.47774923
Encoder Loss:  0.11285526  || Decoder Loss:  0.13734363 Validation Decoder Loss:  0.4370187
Encoder Loss:  0.0963659  || Decoder Loss:  0.11386163 Validation Decoder Loss:  0.41369593
Encoder Loss:  0.08595869  || Decoder Loss:  0.09920212 Validation Decoder Loss:  0.39906496
Encoder Loss:  0.078839004  || Decoder Loss:  0.0891792 Validation Decoder Loss:  0.3893389
Encoder Loss:  0.07363757  || Decoder Loss:  0.08183708 Validation Decoder Loss:  0.38251394
Encoder Loss:  0.06961491  || Decoder Loss:  0.076204866 Validation Decoder Loss:  0.3778227
Encoder Loss:  0.06636493  || Decoder Loss:  0.07175672 Validation Decoder Loss:  0.3743742
Encoder Loss:  0.0638762  || Decoder Loss:  0.06795399 Validation Decoder Loss:  0.37161183
Encoder Loss:  0.06166562  || Decoder Loss:  0.064585015 Validation Decoder Loss:  0.36914524
Encoder Loss:  0.059941903  || Decoder Loss:  0.061748933 Validation Decoder Loss:  0.3655998
Encoder Loss:  0.05757201  || Decoder Loss:  0.059384357 Validation Decoder Loss:  0.36448577
Encoder Loss:  0.056221113  || Decoder Loss:  0.057366956 Validation Decoder Loss:  0.36279726
Encoder Loss:  0.05478415  || Decoder Loss:  0.055384766 Validation Decoder Loss:  0.36016282
Encoder Loss:  0.05340091  || Decoder Loss:  0.053664245 Validation Decoder Loss:  0.35887346
Encoder Loss:  0.052388743  || Decoder Loss:  0.0522628 Validation Decoder Loss:  0.35760793
Encoder Loss:  0.051540148  || Decoder Loss:  0.05100029 Validation Decoder Loss:  0.35670185
Encoder Loss:  0.05068679  || Decoder Loss:  0.049833454 Validation Decoder Loss:  0.35572442
Encoder Loss:  0.04991921  || Decoder Loss:  0.04875543 Validation Decoder Loss:  0.35486674
Encoder Loss:  0.049191546  || Decoder Loss:  0.047765426 Validation Decoder Loss:  0.35416067
Encoder Loss:  0.048480403  || Decoder Loss:  0.04684642 Validation Decoder Loss:  0.3534966
Encoder Loss:  0.04784284  || Decoder Loss:  0.046001397 Validation Decoder Loss:  0.3527419
Encoder Loss:  0.04728508  || Decoder Loss:  0.045218498 Validation Decoder Loss:  0.35210544
Encoder Loss:  0.04677037  || Decoder Loss:  0.044497784 Validation Decoder Loss:  0.35151947
Encoder Loss:  0.046282984  || Decoder Loss:  0.043824214 Validation Decoder Loss:  0.35101926
Encoder Loss:  0.0458123  || Decoder Loss:  0.04319264 Validation Decoder Loss:  0.35055524
Encoder Loss:  0.04538247  || Decoder Loss:  0.042602606 Validation Decoder Loss:  0.35007346
Encoder Loss:  0.044985298  || Decoder Loss:  0.042047966 Validation Decoder Loss:  0.34962875
Encoder Loss:  0.044619016  || Decoder Loss:  0.041527867 Validation Decoder Loss:  0.34922454
Encoder Loss:  0.044276427  || Decoder Loss:  0.04103972 Validation Decoder Loss:  0.34883356
Encoder Loss:  0.043952495  || Decoder Loss:  0.040578507 Validation Decoder Loss:  0.34848076
Encoder Loss:  0.043647137  || Decoder Loss:  0.04014249 Validation Decoder Loss:  0.34812605
Encoder Loss:  0.043351043  || Decoder Loss:  0.039727695 Validation Decoder Loss:  0.3478331
Encoder Loss:  0.043088745  || Decoder Loss:  0.03933774 Validation Decoder Loss:  0.34751832
Encoder Loss:  0.042816237  || Decoder Loss:  0.03896165 Validation Decoder Loss:  0.3472681
Encoder Loss:  0.042568646  || Decoder Loss:  0.03860912 Validation Decoder Loss:  0.3470122
Encoder Loss:  0.042329323  || Decoder Loss:  0.038269304 Validation Decoder Loss:  0.3467908
Encoder Loss:  0.042109683  || Decoder Loss:  0.037947882 Validation Decoder Loss:  0.346567
Model: siamese_net_lr_2.9978643423890278e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.346567
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_26 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15839723  || Decoder Loss:  0.32989287 Validation Decoder Loss:  0.7208338
Encoder Loss:  0.100968815  || Decoder Loss:  0.28574792 Validation Decoder Loss:  0.6479858
Encoder Loss:  0.085267484  || Decoder Loss:  0.24421693 Validation Decoder Loss:  0.59096766
Encoder Loss:  0.07928155  || Decoder Loss:  0.21241142 Validation Decoder Loss:  0.5500241
Encoder Loss:  0.07499328  || Decoder Loss:  0.18884616 Validation Decoder Loss:  0.5198073
Encoder Loss:  0.07337311  || Decoder Loss:  0.17105898 Validation Decoder Loss:  0.49752933
Encoder Loss:  0.07061352  || Decoder Loss:  0.15749991 Validation Decoder Loss:  0.48017284
Encoder Loss:  0.0695138  || Decoder Loss:  0.1467191 Validation Decoder Loss:  0.4666098
Encoder Loss:  0.06770401  || Decoder Loss:  0.13811539 Validation Decoder Loss:  0.45555347
Encoder Loss:  0.06674462  || Decoder Loss:  0.13098446 Validation Decoder Loss:  0.44652182
Encoder Loss:  0.06567401  || Decoder Loss:  0.12511528 Validation Decoder Loss:  0.4390759
Encoder Loss:  0.064848274  || Decoder Loss:  0.120250076 Validation Decoder Loss:  0.43294516
Encoder Loss:  0.06409153  || Decoder Loss:  0.11624771 Validation Decoder Loss:  0.42788517
Encoder Loss:  0.06370647  || Decoder Loss:  0.11301548 Validation Decoder Loss:  0.42387897
Encoder Loss:  0.0634647  || Decoder Loss:  0.11067337 Validation Decoder Loss:  0.4209404
Encoder Loss:  0.063160904  || Decoder Loss:  0.10915249 Validation Decoder Loss:  0.41908795
Encoder Loss:  0.061672248  || Decoder Loss:  0.10751112 Validation Decoder Loss:  0.41667616
Encoder Loss:  0.06068972  || Decoder Loss:  0.10574427 Validation Decoder Loss:  0.41439813
Encoder Loss:  0.059862006  || Decoder Loss:  0.103155784 Validation Decoder Loss:  0.40994948
Encoder Loss:  0.059228484  || Decoder Loss:  0.09929022 Validation Decoder Loss:  0.4056328
Encoder Loss:  0.058707464  || Decoder Loss:  0.095922984 Validation Decoder Loss:  0.40190288
Encoder Loss:  0.058247212  || Decoder Loss:  0.092952125 Validation Decoder Loss:  0.39864945
Encoder Loss:  0.05781889  || Decoder Loss:  0.09026872 Validation Decoder Loss:  0.39570063
Encoder Loss:  0.05743972  || Decoder Loss:  0.087851614 Validation Decoder Loss:  0.39306805
Encoder Loss:  0.05708618  || Decoder Loss:  0.08562079 Validation Decoder Loss:  0.39067054
Encoder Loss:  0.056763597  || Decoder Loss:  0.08356259 Validation Decoder Loss:  0.388484
Encoder Loss:  0.05646763  || Decoder Loss:  0.08166916 Validation Decoder Loss:  0.38645053
Encoder Loss:  0.056216083  || Decoder Loss:  0.07992907 Validation Decoder Loss:  0.38465825
Encoder Loss:  0.055970397  || Decoder Loss:  0.0783123 Validation Decoder Loss:  0.3830269
Encoder Loss:  0.055736646  || Decoder Loss:  0.07681312 Validation Decoder Loss:  0.3814687
Encoder Loss:  0.05554238  || Decoder Loss:  0.07541249 Validation Decoder Loss:  0.38008115
Encoder Loss:  0.055351883  || Decoder Loss:  0.074110515 Validation Decoder Loss:  0.37880257
Encoder Loss:  0.055174533  || Decoder Loss:  0.07289437 Validation Decoder Loss:  0.37761945
Encoder Loss:  0.055011135  || Decoder Loss:  0.07174836 Validation Decoder Loss:  0.37651572
Encoder Loss:  0.054855563  || Decoder Loss:  0.07067432 Validation Decoder Loss:  0.37548345
Encoder Loss:  0.054719724  || Decoder Loss:  0.06966822 Validation Decoder Loss:  0.37452722
Encoder Loss:  0.054580193  || Decoder Loss:  0.06870682 Validation Decoder Loss:  0.37362623
Encoder Loss:  0.05445617  || Decoder Loss:  0.067803785 Validation Decoder Loss:  0.3727824
Encoder Loss:  0.054334622  || Decoder Loss:  0.066949666 Validation Decoder Loss:  0.3719917
Encoder Loss:  0.054218255  || Decoder Loss:  0.0661369 Validation Decoder Loss:  0.37125042
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37125042
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_27 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10009302  || Decoder Loss:  0.44033074 Validation Decoder Loss:  0.9005544
Encoder Loss:  0.06867457  || Decoder Loss:  0.3817463 Validation Decoder Loss:  0.8127324
Encoder Loss:  0.05661474  || Decoder Loss:  0.32335538 Validation Decoder Loss:  0.71135575
Encoder Loss:  0.05534121  || Decoder Loss:  0.26820704 Validation Decoder Loss:  0.6380801
Encoder Loss:  0.055537157  || Decoder Loss:  0.22878283 Validation Decoder Loss:  0.58386207
Encoder Loss:  0.055322737  || Decoder Loss:  0.1994589 Validation Decoder Loss:  0.54482245
Encoder Loss:  0.055169716  || Decoder Loss:  0.17756836 Validation Decoder Loss:  0.51599026
Encoder Loss:  0.05517946  || Decoder Loss:  0.16080555 Validation Decoder Loss:  0.49399504
Encoder Loss:  0.055121932  || Decoder Loss:  0.14764059 Validation Decoder Loss:  0.4768519
Encoder Loss:  0.05497137  || Decoder Loss:  0.13705327 Validation Decoder Loss:  0.46322367
Encoder Loss:  0.05488455  || Decoder Loss:  0.12835039 Validation Decoder Loss:  0.4521581
Encoder Loss:  0.05478239  || Decoder Loss:  0.12108278 Validation Decoder Loss:  0.44302905
Encoder Loss:  0.054713145  || Decoder Loss:  0.11490956 Validation Decoder Loss:  0.4353724
Encoder Loss:  0.05456003  || Decoder Loss:  0.10960606 Validation Decoder Loss:  0.42887813
Encoder Loss:  0.054432083  || Decoder Loss:  0.10499334 Validation Decoder Loss:  0.42329282
Encoder Loss:  0.05429  || Decoder Loss:  0.10094036 Validation Decoder Loss:  0.41844383
Encoder Loss:  0.05413316  || Decoder Loss:  0.097349636 Validation Decoder Loss:  0.41420084
Encoder Loss:  0.054011025  || Decoder Loss:  0.09414598 Validation Decoder Loss:  0.4104498
Encoder Loss:  0.053872466  || Decoder Loss:  0.091266945 Validation Decoder Loss:  0.40711075
Encoder Loss:  0.053699683  || Decoder Loss:  0.0886646 Validation Decoder Loss:  0.40412027
Encoder Loss:  0.053508524  || Decoder Loss:  0.08629861 Validation Decoder Loss:  0.4014274
Encoder Loss:  0.053309664  || Decoder Loss:  0.08413932 Validation Decoder Loss:  0.3989917
Encoder Loss:  0.053143177  || Decoder Loss:  0.082160614 Validation Decoder Loss:  0.39677113
Encoder Loss:  0.052969962  || Decoder Loss:  0.08033773 Validation Decoder Loss:  0.394741
Encoder Loss:  0.052817885  || Decoder Loss:  0.078654334 Validation Decoder Loss:  0.39287424
Encoder Loss:  0.05265996  || Decoder Loss:  0.07709226 Validation Decoder Loss:  0.39114934
Encoder Loss:  0.052478146  || Decoder Loss:  0.07563919 Validation Decoder Loss:  0.3895518
Encoder Loss:  0.052306578  || Decoder Loss:  0.07428182 Validation Decoder Loss:  0.38807213
Encoder Loss:  0.052183677  || Decoder Loss:  0.07301483 Validation Decoder Loss:  0.3866945
Encoder Loss:  0.052075323  || Decoder Loss:  0.07182638 Validation Decoder Loss:  0.38540775
Encoder Loss:  0.051980034  || Decoder Loss:  0.07070997 Validation Decoder Loss:  0.38420296
Encoder Loss:  0.05189272  || Decoder Loss:  0.069658235 Validation Decoder Loss:  0.38307142
Encoder Loss:  0.051810842  || Decoder Loss:  0.068666875 Validation Decoder Loss:  0.38200563
Encoder Loss:  0.05173474  || Decoder Loss:  0.06772892 Validation Decoder Loss:  0.38099962
Encoder Loss:  0.051665064  || Decoder Loss:  0.06684033 Validation Decoder Loss:  0.3800489
Encoder Loss:  0.051604196  || Decoder Loss:  0.06599752 Validation Decoder Loss:  0.3791484
Encoder Loss:  0.051547933  || Decoder Loss:  0.06519652 Validation Decoder Loss:  0.378294
Encoder Loss:  0.05149655  || Decoder Loss:  0.06443482 Validation Decoder Loss:  0.37748158
Encoder Loss:  0.05144613  || Decoder Loss:  0.06370845 Validation Decoder Loss:  0.3767084
Encoder Loss:  0.05141022  || Decoder Loss:  0.06301517 Validation Decoder Loss:  0.37597197
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37597197
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_28 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11793536  || Decoder Loss:  0.4592611 Validation Decoder Loss:  0.89624906
Encoder Loss:  0.09417985  || Decoder Loss:  0.4049236 Validation Decoder Loss:  0.79623073
Encoder Loss:  0.086397  || Decoder Loss:  0.34115392 Validation Decoder Loss:  0.7068896
Encoder Loss:  0.080456525  || Decoder Loss:  0.2878924 Validation Decoder Loss:  0.6366622
Encoder Loss:  0.075615585  || Decoder Loss:  0.24610798 Validation Decoder Loss:  0.5839884
Encoder Loss:  0.07173849  || Decoder Loss:  0.21412978 Validation Decoder Loss:  0.54494
Encoder Loss:  0.06864412  || Decoder Loss:  0.18963331 Validation Decoder Loss:  0.5155202
Encoder Loss:  0.066157565  || Decoder Loss:  0.17057584 Validation Decoder Loss:  0.49292815
Encoder Loss:  0.06406643  || Decoder Loss:  0.15549059 Validation Decoder Loss:  0.47510564
Encoder Loss:  0.062358767  || Decoder Loss:  0.14330548 Validation Decoder Loss:  0.46088484
Encoder Loss:  0.061040226  || Decoder Loss:  0.1332991 Validation Decoder Loss:  0.44934553
Encoder Loss:  0.059960023  || Decoder Loss:  0.12496942 Validation Decoder Loss:  0.4397911
Encoder Loss:  0.059065495  || Decoder Loss:  0.117926046 Validation Decoder Loss:  0.43181616
Encoder Loss:  0.05832354  || Decoder Loss:  0.11189352 Validation Decoder Loss:  0.42500794
Encoder Loss:  0.057668578  || Decoder Loss:  0.10667143 Validation Decoder Loss:  0.41917104
Encoder Loss:  0.057097856  || Decoder Loss:  0.10210362 Validation Decoder Loss:  0.4141426
Encoder Loss:  0.0566191  || Decoder Loss:  0.09807904 Validation Decoder Loss:  0.4096896
Encoder Loss:  0.056171957  || Decoder Loss:  0.09450003 Validation Decoder Loss:  0.40578842
Encoder Loss:  0.055780217  || Decoder Loss:  0.0913017 Validation Decoder Loss:  0.4023172
Encoder Loss:  0.0554321  || Decoder Loss:  0.08842442 Validation Decoder Loss:  0.39919546
Encoder Loss:  0.055108383  || Decoder Loss:  0.085821025 Validation Decoder Loss:  0.3963762
Encoder Loss:  0.05479917  || Decoder Loss:  0.08345274 Validation Decoder Loss:  0.39386308
Encoder Loss:  0.054544024  || Decoder Loss:  0.08129293 Validation Decoder Loss:  0.39157173
Encoder Loss:  0.054303184  || Decoder Loss:  0.07931131 Validation Decoder Loss:  0.38949063
Encoder Loss:  0.054103293  || Decoder Loss:  0.07748775 Validation Decoder Loss:  0.3875409
Encoder Loss:  0.053860676  || Decoder Loss:  0.07580495 Validation Decoder Loss:  0.38580364
Encoder Loss:  0.053698387  || Decoder Loss:  0.074244626 Validation Decoder Loss:  0.38415444
Encoder Loss:  0.05349451  || Decoder Loss:  0.07279625 Validation Decoder Loss:  0.3826629
Encoder Loss:  0.053330168  || Decoder Loss:  0.071446456 Validation Decoder Loss:  0.38126302
Encoder Loss:  0.05315541  || Decoder Loss:  0.07018564 Validation Decoder Loss:  0.37999094
Encoder Loss:  0.053023815  || Decoder Loss:  0.069006175 Validation Decoder Loss:  0.37878644
Encoder Loss:  0.052886218  || Decoder Loss:  0.067897916 Validation Decoder Loss:  0.37764356
Encoder Loss:  0.052734103  || Decoder Loss:  0.06685852 Validation Decoder Loss:  0.37661415
Encoder Loss:  0.05264812  || Decoder Loss:  0.06587661 Validation Decoder Loss:  0.3756051
Encoder Loss:  0.052469794  || Decoder Loss:  0.06495275 Validation Decoder Loss:  0.37467086
Encoder Loss:  0.05232344  || Decoder Loss:  0.06407872 Validation Decoder Loss:  0.3737818
Encoder Loss:  0.052212954  || Decoder Loss:  0.06324976 Validation Decoder Loss:  0.37294742
Encoder Loss:  0.05210291  || Decoder Loss:  0.06246477 Validation Decoder Loss:  0.3721671
Encoder Loss:  0.0520072  || Decoder Loss:  0.061718583 Validation Decoder Loss:  0.37142867
Encoder Loss:  0.051894046  || Decoder Loss:  0.06100879 Validation Decoder Loss:  0.3707263
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3707263
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_29 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 3245, 20, 1)       2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5093887  || Decoder Loss:  0.92832625 Validation Decoder Loss:  1.6380898
Encoder Loss:  0.5179074  || Decoder Loss:  0.94763494 Validation Decoder Loss:  1.6365435
Encoder Loss:  0.5172325  || Decoder Loss:  0.9457762 Validation Decoder Loss:  1.634226
Encoder Loss:  0.5162808  || Decoder Loss:  0.9431386 Validation Decoder Loss:  1.6308403
Encoder Loss:  0.5149559  || Decoder Loss:  0.93945146 Validation Decoder Loss:  1.6259162
Encoder Loss:  0.51311266  || Decoder Loss:  0.93429697 Validation Decoder Loss:  1.6187125
Encoder Loss:  0.5105162  || Decoder Loss:  0.9270229 Validation Decoder Loss:  1.6080616
Encoder Loss:  0.506758  || Decoder Loss:  0.9166072 Validation Decoder Loss:  1.5921073
Encoder Loss:  0.5010331  || Decoder Loss:  0.90141433 Validation Decoder Loss:  1.5678217
Encoder Loss:  0.49132672  || Decoder Loss:  0.87870705 Validation Decoder Loss:  1.5299494
Encoder Loss:  0.46844587  || Decoder Loss:  0.843201 Validation Decoder Loss:  1.4660573
Encoder Loss:  0.27001545  || Decoder Loss:  0.56900597 Validation Decoder Loss:  0.97824526
Encoder Loss:  0.14454626  || Decoder Loss:  0.44193405 Validation Decoder Loss:  0.68944424
Encoder Loss:  0.14518672  || Decoder Loss:  0.42011338 Validation Decoder Loss:  0.7213308
Encoder Loss:  0.14084531  || Decoder Loss:  0.4119868 Validation Decoder Loss:  0.76318866
Encoder Loss:  0.13916673  || Decoder Loss:  0.4136267 Validation Decoder Loss:  0.7462568
Encoder Loss:  0.13763946  || Decoder Loss:  0.4048394 Validation Decoder Loss:  0.74879944
Encoder Loss:  0.13754857  || Decoder Loss:  0.40618825 Validation Decoder Loss:  0.7683566
Encoder Loss:  0.13535915  || Decoder Loss:  0.40098748 Validation Decoder Loss:  0.7344394
Encoder Loss:  0.13636212  || Decoder Loss:  0.3888848 Validation Decoder Loss:  0.75328076
Encoder Loss:  0.138519  || Decoder Loss:  0.40147614 Validation Decoder Loss:  0.77558887
Encoder Loss:  0.13677573  || Decoder Loss:  0.40742493 Validation Decoder Loss:  0.778249
Encoder Loss:  0.1333753  || Decoder Loss:  0.39900076 Validation Decoder Loss:  0.7338019
Encoder Loss:  0.13366476  || Decoder Loss:  0.3922928 Validation Decoder Loss:  0.7458066
Encoder Loss:  0.13381363  || Decoder Loss:  0.39228994 Validation Decoder Loss:  0.7668494
Encoder Loss:  0.12960581  || Decoder Loss:  0.3818226 Validation Decoder Loss:  0.72999716
Encoder Loss:  0.13237001  || Decoder Loss:  0.3776979 Validation Decoder Loss:  0.78738797
Encoder Loss:  0.12664032  || Decoder Loss:  0.36260042 Validation Decoder Loss:  0.7532425
Encoder Loss:  0.12250027  || Decoder Loss:  0.32602456 Validation Decoder Loss:  0.87493587
Encoder Loss:  0.107891046  || Decoder Loss:  0.23240906 Validation Decoder Loss:  1.0067234
Encoder Loss:  0.106290415  || Decoder Loss:  0.21682821 Validation Decoder Loss:  0.6194225
Encoder Loss:  0.097151324  || Decoder Loss:  0.16197336 Validation Decoder Loss:  0.9657079
Encoder Loss:  0.09360149  || Decoder Loss:  0.13909493 Validation Decoder Loss:  0.5176008
Encoder Loss:  0.09765757  || Decoder Loss:  0.16970749 Validation Decoder Loss:  0.52081174
Encoder Loss:  0.09028  || Decoder Loss:  0.11201331 Validation Decoder Loss:  0.71048456
Encoder Loss:  0.10369196  || Decoder Loss:  0.16779765 Validation Decoder Loss:  0.48147482
Encoder Loss:  0.08672979  || Decoder Loss:  0.110553704 Validation Decoder Loss:  0.48743612
Encoder Loss:  0.09037009  || Decoder Loss:  0.10757947 Validation Decoder Loss:  0.59641576
Encoder Loss:  0.07490754  || Decoder Loss:  0.04127666 Validation Decoder Loss:  0.3863143
Encoder Loss:  0.073167436  || Decoder Loss:  0.02468971 Validation Decoder Loss:  0.37691182
Model: siamese_net_lr_0.09436657729973026 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37691182
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 344, 5, 20, 1)     30        
_________________________________________________________________
reshape_30 (Reshape)         (None, 1720, 20, 1)       0         
=================================================================
Total params: 30
Trainable params: 30
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 1720, 20, 1)       1527      
=================================================================
Total params: 1,527
Trainable params: 1,527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 3245, 20, 1)       1527      
=================================================================
Total params: 1,527
Trainable params: 1,527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5669037  || Decoder Loss:  0.8928079 Validation Decoder Loss:  1.6324035
Encoder Loss:  0.59252256  || Decoder Loss:  0.90547806 Validation Decoder Loss:  1.6170596
Encoder Loss:  0.58975035  || Decoder Loss:  0.89624476 Validation Decoder Loss:  1.5879055
Encoder Loss:  0.58360523  || Decoder Loss:  0.87690276 Validation Decoder Loss:  1.5058781
Encoder Loss:  0.50604266  || Decoder Loss:  0.6309835 Validation Decoder Loss:  0.23180917
Encoder Loss:  0.32713658  || Decoder Loss:  0.06349539 Validation Decoder Loss:  0.2966296
Encoder Loss:  0.32673562  || Decoder Loss:  0.06266782 Validation Decoder Loss:  0.3034577
Encoder Loss:  0.32596108  || Decoder Loss:  0.060821548 Validation Decoder Loss:  0.30606014
Encoder Loss:  0.3250366  || Decoder Loss:  0.058786582 Validation Decoder Loss:  0.30798653
Encoder Loss:  0.32392892  || Decoder Loss:  0.056765243 Validation Decoder Loss:  0.3096881
Encoder Loss:  0.32227555  || Decoder Loss:  0.054871067 Validation Decoder Loss:  0.31134576
Encoder Loss:  0.30803463  || Decoder Loss:  0.053242277 Validation Decoder Loss:  0.31308442
Encoder Loss:  0.32315713  || Decoder Loss:  0.05199969 Validation Decoder Loss:  0.3148606
Encoder Loss:  0.3228425  || Decoder Loss:  0.051153917 Validation Decoder Loss:  0.3164158
Encoder Loss:  0.32235917  || Decoder Loss:  0.05057567 Validation Decoder Loss:  0.31748652
Encoder Loss:  0.321749  || Decoder Loss:  0.050111696 Validation Decoder Loss:  0.31807557
Encoder Loss:  0.32085723  || Decoder Loss:  0.049681492 Validation Decoder Loss:  0.3183868
Encoder Loss:  0.31932628  || Decoder Loss:  0.04926477 Validation Decoder Loss:  0.31862557
Encoder Loss:  0.3157717  || Decoder Loss:  0.048867006 Validation Decoder Loss:  0.31899977
Encoder Loss:  0.3050775  || Decoder Loss:  0.15134422 Validation Decoder Loss:  1.6756005
Encoder Loss:  0.2430025  || Decoder Loss:  0.49471498 Validation Decoder Loss:  0.4123787
Encoder Loss:  0.19922915  || Decoder Loss:  0.4428368 Validation Decoder Loss:  0.47439584
Encoder Loss:  0.19314753  || Decoder Loss:  0.44797766 Validation Decoder Loss:  1.1829407
Encoder Loss:  0.20121345  || Decoder Loss:  0.45819518 Validation Decoder Loss:  0.8337734
Encoder Loss:  0.22251217  || Decoder Loss:  0.4705458 Validation Decoder Loss:  0.9697447
Encoder Loss:  0.20409054  || Decoder Loss:  0.4745303 Validation Decoder Loss:  0.9530997
Encoder Loss:  0.17481676  || Decoder Loss:  0.40370682 Validation Decoder Loss:  0.800416
Encoder Loss:  0.16668601  || Decoder Loss:  0.3662799 Validation Decoder Loss:  1.0822282
Encoder Loss:  0.19789252  || Decoder Loss:  0.44033346 Validation Decoder Loss:  0.85911113
Encoder Loss:  0.16615146  || Decoder Loss:  0.35826886 Validation Decoder Loss:  0.62243557
Encoder Loss:  0.18842979  || Decoder Loss:  0.43449214 Validation Decoder Loss:  0.97834504
Encoder Loss:  0.19261688  || Decoder Loss:  0.4736663 Validation Decoder Loss:  0.9778544
Encoder Loss:  0.19379528  || Decoder Loss:  0.46669275 Validation Decoder Loss:  0.90108764
Encoder Loss:  0.1963755  || Decoder Loss:  0.45635283 Validation Decoder Loss:  0.8984702
Encoder Loss:  0.18231533  || Decoder Loss:  0.42550123 Validation Decoder Loss:  0.9204122
Encoder Loss:  0.18257643  || Decoder Loss:  0.4448019 Validation Decoder Loss:  0.7688663
Encoder Loss:  0.13611747  || Decoder Loss:  0.28057593 Validation Decoder Loss:  0.48075843
Encoder Loss:  0.083313696  || Decoder Loss:  0.1325864 Validation Decoder Loss:  0.41450644
Encoder Loss:  0.11321007  || Decoder Loss:  0.20145947 Validation Decoder Loss:  0.7694524
Encoder Loss:  0.12962042  || Decoder Loss:  0.2639856 Validation Decoder Loss:  0.99065256
Model: siamese_net_lr_0.03692866321687907 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99065256
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_31 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50759715  || Decoder Loss:  0.90216416 Validation Decoder Loss:  1.6354716
Encoder Loss:  0.51254934  || Decoder Loss:  0.91312003 Validation Decoder Loss:  1.631258
Encoder Loss:  0.50955313  || Decoder Loss:  0.9068091 Validation Decoder Loss:  1.6247802
Encoder Loss:  0.5039245  || Decoder Loss:  0.8975839 Validation Decoder Loss:  1.6146922
Encoder Loss:  0.4909047  || Decoder Loss:  0.8831545 Validation Decoder Loss:  1.5962441
Encoder Loss:  0.3401609  || Decoder Loss:  0.67094094 Validation Decoder Loss:  0.8218906
Encoder Loss:  0.14872867  || Decoder Loss:  0.43941903 Validation Decoder Loss:  0.5617135
Encoder Loss:  0.14468463  || Decoder Loss:  0.3906343 Validation Decoder Loss:  0.6024156
Encoder Loss:  0.14507388  || Decoder Loss:  0.4262466 Validation Decoder Loss:  0.7174859
Encoder Loss:  0.14291102  || Decoder Loss:  0.43067515 Validation Decoder Loss:  0.68059695
Encoder Loss:  0.13807571  || Decoder Loss:  0.41476655 Validation Decoder Loss:  0.6582207
Encoder Loss:  0.14168632  || Decoder Loss:  0.42989665 Validation Decoder Loss:  0.61644065
Encoder Loss:  0.13889097  || Decoder Loss:  0.407264 Validation Decoder Loss:  0.69055986
Encoder Loss:  0.1364188  || Decoder Loss:  0.40790272 Validation Decoder Loss:  0.5743176
Encoder Loss:  0.13166957  || Decoder Loss:  0.36806935 Validation Decoder Loss:  0.5605988
Encoder Loss:  0.09608191  || Decoder Loss:  0.12749264 Validation Decoder Loss:  0.56742924
Encoder Loss:  0.08576608  || Decoder Loss:  0.045859817 Validation Decoder Loss:  0.39614642
Encoder Loss:  0.08207516  || Decoder Loss:  0.032756373 Validation Decoder Loss:  0.35666177
Encoder Loss:  0.08142149  || Decoder Loss:  0.031126998 Validation Decoder Loss:  0.35757625
Encoder Loss:  0.08116027  || Decoder Loss:  0.030359538 Validation Decoder Loss:  0.35964656
Encoder Loss:  0.08017816  || Decoder Loss:  0.030560194 Validation Decoder Loss:  0.36480975
Encoder Loss:  0.081069514  || Decoder Loss:  0.029695569 Validation Decoder Loss:  0.3610268
Encoder Loss:  0.07935842  || Decoder Loss:  0.029394848 Validation Decoder Loss:  0.36687547
Encoder Loss:  0.07977932  || Decoder Loss:  0.02977894 Validation Decoder Loss:  0.36760098
Encoder Loss:  0.07791342  || Decoder Loss:  0.02899096 Validation Decoder Loss:  0.3631864
Encoder Loss:  0.0794473  || Decoder Loss:  0.029094143 Validation Decoder Loss:  0.37481916
Encoder Loss:  0.08372562  || Decoder Loss:  0.031816557 Validation Decoder Loss:  0.3640777
Encoder Loss:  0.07511526  || Decoder Loss:  0.029402561 Validation Decoder Loss:  0.39050472
Encoder Loss:  0.0768709  || Decoder Loss:  0.030731285 Validation Decoder Loss:  0.37722337
Encoder Loss:  0.07497969  || Decoder Loss:  0.030802848 Validation Decoder Loss:  0.35926586
Encoder Loss:  0.076224096  || Decoder Loss:  0.02929467 Validation Decoder Loss:  0.3635261
Encoder Loss:  0.07347198  || Decoder Loss:  0.030031305 Validation Decoder Loss:  0.35614592
Encoder Loss:  0.07223597  || Decoder Loss:  0.028508542 Validation Decoder Loss:  0.3641031
Encoder Loss:  0.07169864  || Decoder Loss:  0.028593821 Validation Decoder Loss:  0.3605783
Encoder Loss:  0.06988855  || Decoder Loss:  0.02850913 Validation Decoder Loss:  0.35968488
Encoder Loss:  0.06905143  || Decoder Loss:  0.02867635 Validation Decoder Loss:  0.36036465
Encoder Loss:  0.06798991  || Decoder Loss:  0.028876927 Validation Decoder Loss:  0.35972157
Encoder Loss:  0.06666698  || Decoder Loss:  0.029215932 Validation Decoder Loss:  0.35834926
Encoder Loss:  0.07026461  || Decoder Loss:  0.029542513 Validation Decoder Loss:  0.35776603
Encoder Loss:  0.06251552  || Decoder Loss:  0.029644687 Validation Decoder Loss:  0.35533494
Model: siamese_net_lr_0.0448017102037328 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35533494
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_32 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3547972  || Decoder Loss:  0.06479591 Validation Decoder Loss:  0.3360421
Encoder Loss:  0.35117626  || Decoder Loss:  0.03356355 Validation Decoder Loss:  0.33364394
Encoder Loss:  0.34942868  || Decoder Loss:  0.034645505 Validation Decoder Loss:  0.3311647
Encoder Loss:  0.34538305  || Decoder Loss:  0.03694104 Validation Decoder Loss:  0.3281402
Encoder Loss:  0.32829145  || Decoder Loss:  0.04356519 Validation Decoder Loss:  0.32645303
Encoder Loss:  0.17716558  || Decoder Loss:  0.061574116 Validation Decoder Loss:  0.3353871
Encoder Loss:  0.10808291  || Decoder Loss:  0.042853218 Validation Decoder Loss:  0.3456841
Encoder Loss:  0.08299321  || Decoder Loss:  0.03427966 Validation Decoder Loss:  0.34632748
Encoder Loss:  0.0797217  || Decoder Loss:  0.033586487 Validation Decoder Loss:  0.34435204
Encoder Loss:  0.08025194  || Decoder Loss:  0.03347732 Validation Decoder Loss:  0.34385866
Encoder Loss:  0.08016583  || Decoder Loss:  0.0334256 Validation Decoder Loss:  0.3439695
Encoder Loss:  0.07977045  || Decoder Loss:  0.03338572 Validation Decoder Loss:  0.34379074
Encoder Loss:  0.07874299  || Decoder Loss:  0.033351477 Validation Decoder Loss:  0.3437025
Encoder Loss:  0.07843835  || Decoder Loss:  0.03332336 Validation Decoder Loss:  0.34368798
Encoder Loss:  0.07906906  || Decoder Loss:  0.03330098 Validation Decoder Loss:  0.3435418
Encoder Loss:  0.0771907  || Decoder Loss:  0.03328271 Validation Decoder Loss:  0.3436023
Encoder Loss:  0.07732728  || Decoder Loss:  0.033270277 Validation Decoder Loss:  0.34361857
Encoder Loss:  0.07922954  || Decoder Loss:  0.03326172 Validation Decoder Loss:  0.34340578
Encoder Loss:  0.077369355  || Decoder Loss:  0.033257835 Validation Decoder Loss:  0.3434524
Encoder Loss:  0.08051051  || Decoder Loss:  0.03325341 Validation Decoder Loss:  0.34337544
Encoder Loss:  0.0769012  || Decoder Loss:  0.03325312 Validation Decoder Loss:  0.3432976
Encoder Loss:  0.076006696  || Decoder Loss:  0.033256717 Validation Decoder Loss:  0.34330195
Encoder Loss:  0.07432236  || Decoder Loss:  0.033267368 Validation Decoder Loss:  0.34343916
Encoder Loss:  0.07529792  || Decoder Loss:  0.033281673 Validation Decoder Loss:  0.34347826
Encoder Loss:  0.07488958  || Decoder Loss:  0.03329624 Validation Decoder Loss:  0.3434822
Encoder Loss:  0.07394089  || Decoder Loss:  0.03331307 Validation Decoder Loss:  0.34350187
Encoder Loss:  0.07498846  || Decoder Loss:  0.033336014 Validation Decoder Loss:  0.34360522
Encoder Loss:  0.073541954  || Decoder Loss:  0.03335297 Validation Decoder Loss:  0.34376216
Encoder Loss:  0.07745438  || Decoder Loss:  0.033369366 Validation Decoder Loss:  0.34351295
Encoder Loss:  0.073585995  || Decoder Loss:  0.03338815 Validation Decoder Loss:  0.34400237
Encoder Loss:  0.078355506  || Decoder Loss:  0.033398613 Validation Decoder Loss:  0.3435815
Encoder Loss:  0.07172989  || Decoder Loss:  0.03341618 Validation Decoder Loss:  0.34405196
Encoder Loss:  0.0762033  || Decoder Loss:  0.033428293 Validation Decoder Loss:  0.34371436
Encoder Loss:  0.06852251  || Decoder Loss:  0.03344759 Validation Decoder Loss:  0.34394544
Encoder Loss:  0.07273984  || Decoder Loss:  0.03346876 Validation Decoder Loss:  0.34404588
Encoder Loss:  0.06743894  || Decoder Loss:  0.033487987 Validation Decoder Loss:  0.3440438
Encoder Loss:  0.06903999  || Decoder Loss:  0.033513788 Validation Decoder Loss:  0.344374
Encoder Loss:  0.066296205  || Decoder Loss:  0.03353508 Validation Decoder Loss:  0.34430146
Encoder Loss:  0.06909868  || Decoder Loss:  0.033560842 Validation Decoder Loss:  0.3447122
Encoder Loss:  0.06565464  || Decoder Loss:  0.033571947 Validation Decoder Loss:  0.34451693
Model: siamese_net_lr_0.026221839415270703 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34451693
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_33 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29396394  || Decoder Loss:  0.47053754 Validation Decoder Loss:  0.871642
Encoder Loss:  0.24996336  || Decoder Loss:  0.40355626 Validation Decoder Loss:  0.7532819
Encoder Loss:  0.20861487  || Decoder Loss:  0.33073425 Validation Decoder Loss:  0.65387094
Encoder Loss:  0.17544276  || Decoder Loss:  0.27176785 Validation Decoder Loss:  0.5816251
Encoder Loss:  0.15043703  || Decoder Loss:  0.22743493 Validation Decoder Loss:  0.5315344
Encoder Loss:  0.1320363  || Decoder Loss:  0.19480884 Validation Decoder Loss:  0.49581134
Encoder Loss:  0.118337624  || Decoder Loss:  0.17052485 Validation Decoder Loss:  0.47014216
Encoder Loss:  0.107897274  || Decoder Loss:  0.1520352 Validation Decoder Loss:  0.45064205
Encoder Loss:  0.0997741  || Decoder Loss:  0.13761522 Validation Decoder Loss:  0.4362012
Encoder Loss:  0.09326767  || Decoder Loss:  0.12610611 Validation Decoder Loss:  0.42478284
Encoder Loss:  0.08799603  || Decoder Loss:  0.11673317 Validation Decoder Loss:  0.41574794
Encoder Loss:  0.0836357  || Decoder Loss:  0.108963564 Validation Decoder Loss:  0.40852037
Encoder Loss:  0.079947315  || Decoder Loss:  0.10242316 Validation Decoder Loss:  0.40258813
Encoder Loss:  0.07679797  || Decoder Loss:  0.0968437 Validation Decoder Loss:  0.39768142
Encoder Loss:  0.0740907  || Decoder Loss:  0.09202912 Validation Decoder Loss:  0.39346305
Encoder Loss:  0.07172057  || Decoder Loss:  0.08783014 Validation Decoder Loss:  0.38989604
Encoder Loss:  0.06964398  || Decoder Loss:  0.084136225 Validation Decoder Loss:  0.38675353
Encoder Loss:  0.06780857  || Decoder Loss:  0.08086004 Validation Decoder Loss:  0.3840428
Encoder Loss:  0.06616009  || Decoder Loss:  0.07793423 Validation Decoder Loss:  0.38162822
Encoder Loss:  0.06467956  || Decoder Loss:  0.07530443 Validation Decoder Loss:  0.37949613
Encoder Loss:  0.06334523  || Decoder Loss:  0.07292808 Validation Decoder Loss:  0.37759855
Encoder Loss:  0.062143408  || Decoder Loss:  0.070770025 Validation Decoder Loss:  0.37593275
Encoder Loss:  0.06101941  || Decoder Loss:  0.06880005 Validation Decoder Loss:  0.37436414
Encoder Loss:  0.060006313  || Decoder Loss:  0.066995196 Validation Decoder Loss:  0.37297094
Encoder Loss:  0.05906296  || Decoder Loss:  0.06533507 Validation Decoder Loss:  0.3716799
Encoder Loss:  0.058207124  || Decoder Loss:  0.06380302 Validation Decoder Loss:  0.3705141
Encoder Loss:  0.0574044  || Decoder Loss:  0.0623842 Validation Decoder Loss:  0.36943763
Encoder Loss:  0.0566582  || Decoder Loss:  0.061066452 Validation Decoder Loss:  0.36843634
Encoder Loss:  0.055967864  || Decoder Loss:  0.059839316 Validation Decoder Loss:  0.36751866
Encoder Loss:  0.055319585  || Decoder Loss:  0.058693524 Validation Decoder Loss:  0.3666597
Encoder Loss:  0.05471866  || Decoder Loss:  0.057621136 Validation Decoder Loss:  0.36587152
Encoder Loss:  0.054147556  || Decoder Loss:  0.05661522 Validation Decoder Loss:  0.36512697
Encoder Loss:  0.05361495  || Decoder Loss:  0.055669647 Validation Decoder Loss:  0.36443287
Encoder Loss:  0.05310907  || Decoder Loss:  0.05477907 Validation Decoder Loss:  0.36377504
Encoder Loss:  0.052644633  || Decoder Loss:  0.0539387 Validation Decoder Loss:  0.36317584
Encoder Loss:  0.052186865  || Decoder Loss:  0.05314442 Validation Decoder Loss:  0.3625918
Encoder Loss:  0.0517586  || Decoder Loss:  0.05239247 Validation Decoder Loss:  0.36204058
Encoder Loss:  0.05136922  || Decoder Loss:  0.051679272 Validation Decoder Loss:  0.3615374
Encoder Loss:  0.050975952  || Decoder Loss:  0.05100215 Validation Decoder Loss:  0.3610497
Encoder Loss:  0.050599903  || Decoder Loss:  0.050358377 Validation Decoder Loss:  0.36057252
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36057252
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_34 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46846244  || Decoder Loss:  0.8007123 Validation Decoder Loss:  0.9308018
Encoder Loss:  0.42644078  || Decoder Loss:  0.19141999 Validation Decoder Loss:  0.37615627
Encoder Loss:  0.41419262  || Decoder Loss:  0.045805383 Validation Decoder Loss:  0.33836645
Encoder Loss:  0.4129436  || Decoder Loss:  0.036203083 Validation Decoder Loss:  0.33513165
Encoder Loss:  0.4123076  || Decoder Loss:  0.036130086 Validation Decoder Loss:  0.33366534
Encoder Loss:  0.4115031  || Decoder Loss:  0.03676985 Validation Decoder Loss:  0.33184192
Encoder Loss:  0.4103924  || Decoder Loss:  0.037663396 Validation Decoder Loss:  0.32962185
Encoder Loss:  0.40880272  || Decoder Loss:  0.038941998 Validation Decoder Loss:  0.32690296
Encoder Loss:  0.40637618  || Decoder Loss:  0.040895596 Validation Decoder Loss:  0.32349074
Encoder Loss:  0.40218177  || Decoder Loss:  0.044285517 Validation Decoder Loss:  0.31908548
Encoder Loss:  0.3924336  || Decoder Loss:  0.0522822 Validation Decoder Loss:  0.31456083
Encoder Loss:  0.30541644  || Decoder Loss:  0.23362958 Validation Decoder Loss:  1.274689
Encoder Loss:  0.1836593  || Decoder Loss:  0.47303584 Validation Decoder Loss:  0.75409937
Encoder Loss:  0.12048686  || Decoder Loss:  0.42851803 Validation Decoder Loss:  0.84435636
Encoder Loss:  0.124749094  || Decoder Loss:  0.42755315 Validation Decoder Loss:  0.7884866
Encoder Loss:  0.120136134  || Decoder Loss:  0.40402564 Validation Decoder Loss:  0.71500146
Encoder Loss:  0.10288653  || Decoder Loss:  0.17956929 Validation Decoder Loss:  0.36236584
Encoder Loss:  0.08973694  || Decoder Loss:  0.04246156 Validation Decoder Loss:  0.32731375
Encoder Loss:  0.09015561  || Decoder Loss:  0.035901368 Validation Decoder Loss:  0.3455647
Encoder Loss:  0.09059648  || Decoder Loss:  0.03428542 Validation Decoder Loss:  0.3376422
Encoder Loss:  0.0882913  || Decoder Loss:  0.03369557 Validation Decoder Loss:  0.3381948
Encoder Loss:  0.08925588  || Decoder Loss:  0.033347756 Validation Decoder Loss:  0.3343709
Encoder Loss:  0.08686102  || Decoder Loss:  0.03372881 Validation Decoder Loss:  0.33077636
Encoder Loss:  0.09033142  || Decoder Loss:  0.03431339 Validation Decoder Loss:  0.34808826
Encoder Loss:  0.08676246  || Decoder Loss:  0.034284286 Validation Decoder Loss:  0.332241
Encoder Loss:  0.08891028  || Decoder Loss:  0.03436898 Validation Decoder Loss:  0.33084393
Encoder Loss:  0.085730135  || Decoder Loss:  0.033812467 Validation Decoder Loss:  0.33737162
Encoder Loss:  0.08817389  || Decoder Loss:  0.03373266 Validation Decoder Loss:  0.33097014
Encoder Loss:  0.08478045  || Decoder Loss:  0.03388126 Validation Decoder Loss:  0.3335525
Encoder Loss:  0.085080996  || Decoder Loss:  0.033945955 Validation Decoder Loss:  0.3314234
Encoder Loss:  0.08436138  || Decoder Loss:  0.033722185 Validation Decoder Loss:  0.3328246
Encoder Loss:  0.08601821  || Decoder Loss:  0.03374107 Validation Decoder Loss:  0.3307672
Encoder Loss:  0.081218675  || Decoder Loss:  0.033915866 Validation Decoder Loss:  0.33234546
Encoder Loss:  0.083190106  || Decoder Loss:  0.033828184 Validation Decoder Loss:  0.32857504
Encoder Loss:  0.08177042  || Decoder Loss:  0.034830675 Validation Decoder Loss:  0.3967543
Encoder Loss:  0.08137716  || Decoder Loss:  0.036297817 Validation Decoder Loss:  0.32562646
Encoder Loss:  0.08049012  || Decoder Loss:  0.034665335 Validation Decoder Loss:  0.33154225
Encoder Loss:  0.07940423  || Decoder Loss:  0.033797678 Validation Decoder Loss:  0.33962455
Encoder Loss:  0.079136565  || Decoder Loss:  0.034049734 Validation Decoder Loss:  0.32987082
Encoder Loss:  0.076757476  || Decoder Loss:  0.034343723 Validation Decoder Loss:  0.32856238
Model: siamese_net_lr_0.09931963508368509 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32856238
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_35 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.097749665  || Decoder Loss:  0.06900086 Validation Decoder Loss:  0.32527
Encoder Loss:  0.08938817  || Decoder Loss:  0.03474134 Validation Decoder Loss:  0.34089154
Encoder Loss:  0.1269937  || Decoder Loss:  0.03463297 Validation Decoder Loss:  0.3486376
Encoder Loss:  0.10782515  || Decoder Loss:  0.031791516 Validation Decoder Loss:  0.34252912
Encoder Loss:  0.076241486  || Decoder Loss:  0.030859493 Validation Decoder Loss:  0.341538
Encoder Loss:  0.06744829  || Decoder Loss:  0.030345583 Validation Decoder Loss:  0.34034002
Encoder Loss:  0.06419939  || Decoder Loss:  0.030040875 Validation Decoder Loss:  0.34190387
Encoder Loss:  0.07763268  || Decoder Loss:  0.029888384 Validation Decoder Loss:  0.3371728
Encoder Loss:  0.06132832  || Decoder Loss:  0.029696692 Validation Decoder Loss:  0.3380161
Encoder Loss:  0.06802876  || Decoder Loss:  0.029801602 Validation Decoder Loss:  0.33955675
Encoder Loss:  0.066144034  || Decoder Loss:  0.029714081 Validation Decoder Loss:  0.33828288
Encoder Loss:  0.064872354  || Decoder Loss:  0.029656274 Validation Decoder Loss:  0.338684
Encoder Loss:  0.05546769  || Decoder Loss:  0.029668348 Validation Decoder Loss:  0.3390247
Encoder Loss:  0.09135191  || Decoder Loss:  0.02984339 Validation Decoder Loss:  0.349851
Encoder Loss:  0.094016746  || Decoder Loss:  0.029545028 Validation Decoder Loss:  0.33909893
Encoder Loss:  0.073572196  || Decoder Loss:  0.029232211 Validation Decoder Loss:  0.33848804
Encoder Loss:  0.06675591  || Decoder Loss:  0.029085686 Validation Decoder Loss:  0.34301013
Encoder Loss:  0.061066236  || Decoder Loss:  0.029031573 Validation Decoder Loss:  0.34132457
Encoder Loss:  0.07155602  || Decoder Loss:  0.029040186 Validation Decoder Loss:  0.34248364
Encoder Loss:  0.063512795  || Decoder Loss:  0.028913422 Validation Decoder Loss:  0.34322402
Encoder Loss:  0.06073812  || Decoder Loss:  0.028851083 Validation Decoder Loss:  0.34537643
Encoder Loss:  0.055431243  || Decoder Loss:  0.028800823 Validation Decoder Loss:  0.34666222
Encoder Loss:  0.06362259  || Decoder Loss:  0.028841836 Validation Decoder Loss:  0.346636
Encoder Loss:  0.062390853  || Decoder Loss:  0.028792707 Validation Decoder Loss:  0.34727567
Encoder Loss:  0.054437313  || Decoder Loss:  0.028703427 Validation Decoder Loss:  0.3480764
Encoder Loss:  0.055902157  || Decoder Loss:  0.028652122 Validation Decoder Loss:  0.34739715
Encoder Loss:  0.062994726  || Decoder Loss:  0.028632753 Validation Decoder Loss:  0.34700513
Encoder Loss:  0.0609023  || Decoder Loss:  0.028547475 Validation Decoder Loss:  0.346228
Encoder Loss:  0.058077477  || Decoder Loss:  0.028494708 Validation Decoder Loss:  0.3478505
Encoder Loss:  0.068737835  || Decoder Loss:  0.028503718 Validation Decoder Loss:  0.3456989
Encoder Loss:  0.06861313  || Decoder Loss:  0.028561573 Validation Decoder Loss:  0.34335825
Encoder Loss:  0.058616176  || Decoder Loss:  0.028426854 Validation Decoder Loss:  0.35085842
Encoder Loss:  0.07038762  || Decoder Loss:  0.02842145 Validation Decoder Loss:  0.34014118
Encoder Loss:  0.06272374  || Decoder Loss:  0.028411636 Validation Decoder Loss:  0.34470248
Encoder Loss:  0.06349113  || Decoder Loss:  0.02838272 Validation Decoder Loss:  0.34505188
Encoder Loss:  0.061839003  || Decoder Loss:  0.028380238 Validation Decoder Loss:  0.35100192
Encoder Loss:  0.05286613  || Decoder Loss:  0.028337998 Validation Decoder Loss:  0.34694612
Encoder Loss:  0.054146294  || Decoder Loss:  0.028295562 Validation Decoder Loss:  0.34630233
Encoder Loss:  0.05378275  || Decoder Loss:  0.028312724 Validation Decoder Loss:  0.34601873
Encoder Loss:  0.052531317  || Decoder Loss:  0.028311362 Validation Decoder Loss:  0.34565672
Model: siamese_net_lr_0.004037798526846744 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34565672
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_36 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 620, 20, 1)        151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50095046  || Decoder Loss:  0.89861536 Validation Decoder Loss:  1.6325227
Encoder Loss:  0.524135  || Decoder Loss:  0.9125432 Validation Decoder Loss:  1.6269956
Encoder Loss:  0.5215479  || Decoder Loss:  0.9056341 Validation Decoder Loss:  1.6183975
Encoder Loss:  0.5170104  || Decoder Loss:  0.8956786 Validation Decoder Loss:  1.6052101
Encoder Loss:  0.5085936  || Decoder Loss:  0.8808786 Validation Decoder Loss:  1.5835359
Encoder Loss:  0.48531428  || Decoder Loss:  0.854666 Validation Decoder Loss:  1.5282853
Encoder Loss:  0.25390953  || Decoder Loss:  0.5033114 Validation Decoder Loss:  0.5668051
Encoder Loss:  0.17420998  || Decoder Loss:  0.4276111 Validation Decoder Loss:  0.7269143
Encoder Loss:  0.15525734  || Decoder Loss:  0.45392647 Validation Decoder Loss:  0.69393647
Encoder Loss:  0.15418017  || Decoder Loss:  0.4640788 Validation Decoder Loss:  0.60093606
Encoder Loss:  0.15430772  || Decoder Loss:  0.45866284 Validation Decoder Loss:  0.62553203
Encoder Loss:  0.15173686  || Decoder Loss:  0.45649302 Validation Decoder Loss:  0.54421335
Encoder Loss:  0.15144704  || Decoder Loss:  0.44725254 Validation Decoder Loss:  0.5634989
Encoder Loss:  0.14749011  || Decoder Loss:  0.43834773 Validation Decoder Loss:  0.5323113
Encoder Loss:  0.14273353  || Decoder Loss:  0.40942326 Validation Decoder Loss:  0.43902543
Encoder Loss:  0.08856368  || Decoder Loss:  0.09234593 Validation Decoder Loss:  0.4525628
Encoder Loss:  0.07834905  || Decoder Loss:  0.041274603 Validation Decoder Loss:  0.374091
Encoder Loss:  0.07592383  || Decoder Loss:  0.033521257 Validation Decoder Loss:  0.39444238
Encoder Loss:  0.07702102  || Decoder Loss:  0.03363905 Validation Decoder Loss:  0.38149783
Encoder Loss:  0.0745115  || Decoder Loss:  0.03399575 Validation Decoder Loss:  0.39712328
Encoder Loss:  0.07326117  || Decoder Loss:  0.03307809 Validation Decoder Loss:  0.40902752
Encoder Loss:  0.071818076  || Decoder Loss:  0.03486272 Validation Decoder Loss:  0.3875696
Encoder Loss:  0.069866836  || Decoder Loss:  0.0332322 Validation Decoder Loss:  0.402182
Encoder Loss:  0.06890718  || Decoder Loss:  0.034406666 Validation Decoder Loss:  0.39265323
Encoder Loss:  0.061201967  || Decoder Loss:  0.03418574 Validation Decoder Loss:  0.37924135
Encoder Loss:  0.05801361  || Decoder Loss:  0.03302963 Validation Decoder Loss:  0.36687508
Encoder Loss:  0.06643937  || Decoder Loss:  0.032810345 Validation Decoder Loss:  0.40246168
Encoder Loss:  0.06448926  || Decoder Loss:  0.03533255 Validation Decoder Loss:  0.3817973
Encoder Loss:  0.05966945  || Decoder Loss:  0.037526373 Validation Decoder Loss:  0.3561265
Encoder Loss:  0.062057268  || Decoder Loss:  0.035892047 Validation Decoder Loss:  0.36767057
Encoder Loss:  0.06486344  || Decoder Loss:  0.039306775 Validation Decoder Loss:  0.41124567
Encoder Loss:  0.054675832  || Decoder Loss:  0.039390575 Validation Decoder Loss:  0.39759213
Encoder Loss:  0.05352291  || Decoder Loss:  0.036103927 Validation Decoder Loss:  0.36122867
Encoder Loss:  0.052704554  || Decoder Loss:  0.034750104 Validation Decoder Loss:  0.351686
Encoder Loss:  0.057772394  || Decoder Loss:  0.03486599 Validation Decoder Loss:  0.35683095
Encoder Loss:  0.058063027  || Decoder Loss:  0.036128834 Validation Decoder Loss:  0.40751836
Encoder Loss:  0.056120463  || Decoder Loss:  0.03691974 Validation Decoder Loss:  0.3615647
Encoder Loss:  0.059749592  || Decoder Loss:  0.035456713 Validation Decoder Loss:  0.36539114
Encoder Loss:  0.05850632  || Decoder Loss:  0.035385724 Validation Decoder Loss:  0.364653
Encoder Loss:  0.058708377  || Decoder Loss:  0.037969984 Validation Decoder Loss:  0.34823918
Model: siamese_net_lr_0.041770746928286404 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34823918
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_37 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5162732  || Decoder Loss:  0.88237745 Validation Decoder Loss:  1.6244476
Encoder Loss:  0.52349615  || Decoder Loss:  0.89189523 Validation Decoder Loss:  1.5871845
Encoder Loss:  0.50398165  || Decoder Loss:  0.81767714 Validation Decoder Loss:  1.2833425
Encoder Loss:  0.3628811  || Decoder Loss:  0.518083 Validation Decoder Loss:  1.0704515
Encoder Loss:  0.17172854  || Decoder Loss:  0.4119201 Validation Decoder Loss:  0.97839856
Encoder Loss:  0.1404037  || Decoder Loss:  0.35580182 Validation Decoder Loss:  0.9133923
Encoder Loss:  0.10674075  || Decoder Loss:  0.15269762 Validation Decoder Loss:  0.43166372
Encoder Loss:  0.08748756  || Decoder Loss:  0.039995834 Validation Decoder Loss:  0.3441354
Encoder Loss:  0.086103804  || Decoder Loss:  0.03144752 Validation Decoder Loss:  0.34759644
Encoder Loss:  0.08158432  || Decoder Loss:  0.030461587 Validation Decoder Loss:  0.3520671
Encoder Loss:  0.08222565  || Decoder Loss:  0.03003421 Validation Decoder Loss:  0.3534251
Encoder Loss:  0.08141068  || Decoder Loss:  0.029758144 Validation Decoder Loss:  0.3544654
Encoder Loss:  0.081276  || Decoder Loss:  0.029563015 Validation Decoder Loss:  0.354239
Encoder Loss:  0.080151685  || Decoder Loss:  0.029413898 Validation Decoder Loss:  0.35440433
Encoder Loss:  0.08106765  || Decoder Loss:  0.029302461 Validation Decoder Loss:  0.3548379
Encoder Loss:  0.07842247  || Decoder Loss:  0.02921572 Validation Decoder Loss:  0.35486138
Encoder Loss:  0.07932749  || Decoder Loss:  0.029197797 Validation Decoder Loss:  0.35703096
Encoder Loss:  0.07808115  || Decoder Loss:  0.029182076 Validation Decoder Loss:  0.35772365
Encoder Loss:  0.0765815  || Decoder Loss:  0.029210405 Validation Decoder Loss:  0.35926068
Encoder Loss:  0.07559826  || Decoder Loss:  0.029275607 Validation Decoder Loss:  0.35918248
Encoder Loss:  0.07500598  || Decoder Loss:  0.02935923 Validation Decoder Loss:  0.36068362
Encoder Loss:  0.078896694  || Decoder Loss:  0.029359093 Validation Decoder Loss:  0.36161423
Encoder Loss:  0.073088996  || Decoder Loss:  0.02944806 Validation Decoder Loss:  0.3621126
Encoder Loss:  0.07255028  || Decoder Loss:  0.029580345 Validation Decoder Loss:  0.36141503
Encoder Loss:  0.071155585  || Decoder Loss:  0.029750146 Validation Decoder Loss:  0.36135235
Encoder Loss:  0.07081605  || Decoder Loss:  0.029948331 Validation Decoder Loss:  0.36032212
Encoder Loss:  0.07237762  || Decoder Loss:  0.030136077 Validation Decoder Loss:  0.35868368
Encoder Loss:  0.06956265  || Decoder Loss:  0.030326884 Validation Decoder Loss:  0.35733724
Encoder Loss:  0.06920468  || Decoder Loss:  0.030501561 Validation Decoder Loss:  0.35819602
Encoder Loss:  0.061933096  || Decoder Loss:  0.030740662 Validation Decoder Loss:  0.35578614
Encoder Loss:  0.06368759  || Decoder Loss:  0.030999416 Validation Decoder Loss:  0.35627222
Encoder Loss:  0.066185445  || Decoder Loss:  0.031208023 Validation Decoder Loss:  0.35665357
Encoder Loss:  0.06419989  || Decoder Loss:  0.031391058 Validation Decoder Loss:  0.34815583
Encoder Loss:  0.064475544  || Decoder Loss:  0.031446442 Validation Decoder Loss:  0.3539598
Encoder Loss:  0.053077545  || Decoder Loss:  0.03153396 Validation Decoder Loss:  0.35081905
Encoder Loss:  0.06264121  || Decoder Loss:  0.031652465 Validation Decoder Loss:  0.3550074
Encoder Loss:  0.06095001  || Decoder Loss:  0.031627882 Validation Decoder Loss:  0.3477234
Encoder Loss:  0.06444295  || Decoder Loss:  0.031571604 Validation Decoder Loss:  0.3507036
Encoder Loss:  0.06863329  || Decoder Loss:  0.031473957 Validation Decoder Loss:  0.3459375
Encoder Loss:  0.06588654  || Decoder Loss:  0.03147481 Validation Decoder Loss:  0.3520189
Model: siamese_net_lr_0.015586284581416941 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3520189
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_38 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 3245, 20, 1)       2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.54414487  || Decoder Loss:  0.9272523 Validation Decoder Loss:  1.6363761
Encoder Loss:  0.55401003  || Decoder Loss:  0.9419444 Validation Decoder Loss:  1.6301986
Encoder Loss:  0.5514281  || Decoder Loss:  0.9319183 Validation Decoder Loss:  1.6164923
Encoder Loss:  0.54645604  || Decoder Loss:  0.91170764 Validation Decoder Loss:  1.5847731
Encoder Loss:  0.53636056  || Decoder Loss:  0.86904424 Validation Decoder Loss:  1.5092888
Encoder Loss:  0.51456594  || Decoder Loss:  0.7741982 Validation Decoder Loss:  1.3234122
Encoder Loss:  0.46643364  || Decoder Loss:  0.56091714 Validation Decoder Loss:  0.907119
Encoder Loss:  0.39489773  || Decoder Loss:  0.24691723 Validation Decoder Loss:  0.5160097
Encoder Loss:  0.351494  || Decoder Loss:  0.08942124 Validation Decoder Loss:  0.40718207
Encoder Loss:  0.3062083  || Decoder Loss:  0.33814678 Validation Decoder Loss:  1.5333526
Encoder Loss:  0.20327087  || Decoder Loss:  0.45785165 Validation Decoder Loss:  1.4119633
Encoder Loss:  0.20020437  || Decoder Loss:  0.49164787 Validation Decoder Loss:  1.3155344
Encoder Loss:  0.1880626  || Decoder Loss:  0.47304833 Validation Decoder Loss:  1.277969
Encoder Loss:  0.18278638  || Decoder Loss:  0.47905433 Validation Decoder Loss:  1.2954619
Encoder Loss:  0.1813681  || Decoder Loss:  0.4678841 Validation Decoder Loss:  1.230368
Encoder Loss:  0.1774536  || Decoder Loss:  0.4610825 Validation Decoder Loss:  1.2229071
Encoder Loss:  0.17728204  || Decoder Loss:  0.45880014 Validation Decoder Loss:  1.2225254
Encoder Loss:  0.17613548  || Decoder Loss:  0.45509136 Validation Decoder Loss:  1.1727669
Encoder Loss:  0.17247705  || Decoder Loss:  0.4509502 Validation Decoder Loss:  1.123
Encoder Loss:  0.1691238  || Decoder Loss:  0.4436523 Validation Decoder Loss:  1.1378369
Encoder Loss:  0.16898061  || Decoder Loss:  0.44463116 Validation Decoder Loss:  1.1533706
Encoder Loss:  0.1686829  || Decoder Loss:  0.4414661 Validation Decoder Loss:  1.1440357
Encoder Loss:  0.16959403  || Decoder Loss:  0.44495457 Validation Decoder Loss:  1.1157072
Encoder Loss:  0.1663234  || Decoder Loss:  0.43645778 Validation Decoder Loss:  1.1620356
Encoder Loss:  0.16914347  || Decoder Loss:  0.44273734 Validation Decoder Loss:  1.1263378
Encoder Loss:  0.16517834  || Decoder Loss:  0.43201655 Validation Decoder Loss:  1.1432546
Encoder Loss:  0.16469574  || Decoder Loss:  0.43154612 Validation Decoder Loss:  1.1472958
Encoder Loss:  0.16534156  || Decoder Loss:  0.43103296 Validation Decoder Loss:  1.1090212
Encoder Loss:  0.16161472  || Decoder Loss:  0.41783303 Validation Decoder Loss:  1.150358
Encoder Loss:  0.160601  || Decoder Loss:  0.41552818 Validation Decoder Loss:  1.1534538
Encoder Loss:  0.15741597  || Decoder Loss:  0.40256423 Validation Decoder Loss:  1.1287978
Encoder Loss:  0.15072241  || Decoder Loss:  0.37739438 Validation Decoder Loss:  1.1430173
Encoder Loss:  0.1531593  || Decoder Loss:  0.364912 Validation Decoder Loss:  0.92784613
Encoder Loss:  0.13686952  || Decoder Loss:  0.2980074 Validation Decoder Loss:  0.8861208
Encoder Loss:  0.12880345  || Decoder Loss:  0.27196842 Validation Decoder Loss:  0.7098391
Encoder Loss:  0.12211259  || Decoder Loss:  0.25138372 Validation Decoder Loss:  0.8593358
Encoder Loss:  0.12369308  || Decoder Loss:  0.2510053 Validation Decoder Loss:  0.57336366
Encoder Loss:  0.09474666  || Decoder Loss:  0.12958294 Validation Decoder Loss:  0.58965117
Encoder Loss:  0.14730985  || Decoder Loss:  0.35943457 Validation Decoder Loss:  0.6863215
Encoder Loss:  0.088718385  || Decoder Loss:  0.0991085 Validation Decoder Loss:  0.48152196
Model: siamese_net_lr_0.056005480265339885 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.48152196
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_39 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44324985  || Decoder Loss:  0.87448364 Validation Decoder Loss:  1.4945513
Encoder Loss:  0.42850268  || Decoder Loss:  0.534069 Validation Decoder Loss:  0.4952621
Encoder Loss:  0.44141522  || Decoder Loss:  0.12799764 Validation Decoder Loss:  0.31718326
Encoder Loss:  0.44018605  || Decoder Loss:  0.087350644 Validation Decoder Loss:  0.31043687
Encoder Loss:  0.43882802  || Decoder Loss:  0.084102124 Validation Decoder Loss:  0.31313032
Encoder Loss:  0.4368039  || Decoder Loss:  0.0824379 Validation Decoder Loss:  0.31632763
Encoder Loss:  0.43352014  || Decoder Loss:  0.08054573 Validation Decoder Loss:  0.3200398
Encoder Loss:  0.42723203  || Decoder Loss:  0.07832891 Validation Decoder Loss:  0.32616234
Encoder Loss:  0.40684262  || Decoder Loss:  0.07739039 Validation Decoder Loss:  0.36698782
Encoder Loss:  0.22833468  || Decoder Loss:  0.44805473 Validation Decoder Loss:  1.1510806
Encoder Loss:  0.103019305  || Decoder Loss:  0.44852826 Validation Decoder Loss:  1.1863736
Encoder Loss:  0.10135519  || Decoder Loss:  0.44019783 Validation Decoder Loss:  1.2452767
Encoder Loss:  0.101750195  || Decoder Loss:  0.442677 Validation Decoder Loss:  1.2246039
Encoder Loss:  0.09966344  || Decoder Loss:  0.43853846 Validation Decoder Loss:  1.2508404
Encoder Loss:  0.1017991  || Decoder Loss:  0.44284657 Validation Decoder Loss:  1.1915756
Encoder Loss:  0.098631695  || Decoder Loss:  0.43511286 Validation Decoder Loss:  1.2439938
Encoder Loss:  0.09833277  || Decoder Loss:  0.43339816 Validation Decoder Loss:  1.2839847
Encoder Loss:  0.10400156  || Decoder Loss:  0.43834344 Validation Decoder Loss:  1.1924179
Encoder Loss:  0.099297926  || Decoder Loss:  0.40461627 Validation Decoder Loss:  0.99326557
Encoder Loss:  0.09381992  || Decoder Loss:  0.26624784 Validation Decoder Loss:  0.6047844
Encoder Loss:  0.09466091  || Decoder Loss:  0.15287302 Validation Decoder Loss:  0.3914715
Encoder Loss:  0.091314964  || Decoder Loss:  0.08236372 Validation Decoder Loss:  0.4101301
Encoder Loss:  0.08996227  || Decoder Loss:  0.04382997 Validation Decoder Loss:  0.39863974
Encoder Loss:  0.092007786  || Decoder Loss:  0.034249224 Validation Decoder Loss:  0.36977765
Encoder Loss:  0.0881798  || Decoder Loss:  0.033373762 Validation Decoder Loss:  0.3694451
Encoder Loss:  0.0902598  || Decoder Loss:  0.030383179 Validation Decoder Loss:  0.36458844
Encoder Loss:  0.0877708  || Decoder Loss:  0.028625228 Validation Decoder Loss:  0.3643831
Encoder Loss:  0.090888746  || Decoder Loss:  0.029209478 Validation Decoder Loss:  0.36266798
Encoder Loss:  0.08669386  || Decoder Loss:  0.029938798 Validation Decoder Loss:  0.36434078
Encoder Loss:  0.08758163  || Decoder Loss:  0.031217556 Validation Decoder Loss:  0.36182377
Encoder Loss:  0.08545284  || Decoder Loss:  0.030001452 Validation Decoder Loss:  0.35860103
Encoder Loss:  0.08606474  || Decoder Loss:  0.029653387 Validation Decoder Loss:  0.36663803
Encoder Loss:  0.08345413  || Decoder Loss:  0.03038124 Validation Decoder Loss:  0.35760188
Encoder Loss:  0.08555527  || Decoder Loss:  0.028672786 Validation Decoder Loss:  0.35642737
Encoder Loss:  0.08317441  || Decoder Loss:  0.02877858 Validation Decoder Loss:  0.35404125
Encoder Loss:  0.08246213  || Decoder Loss:  0.029071193 Validation Decoder Loss:  0.35283262
Encoder Loss:  0.08150379  || Decoder Loss:  0.029542813 Validation Decoder Loss:  0.35626766
Encoder Loss:  0.08484886  || Decoder Loss:  0.030091658 Validation Decoder Loss:  0.35379803
Encoder Loss:  0.07666167  || Decoder Loss:  0.030223912 Validation Decoder Loss:  0.35657793
Encoder Loss:  0.07621634  || Decoder Loss:  0.02977349 Validation Decoder Loss:  0.35809642
Model: siamese_net_lr_0.0414141579111488 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35809642
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_40 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4615029  || Decoder Loss:  0.9180865 Validation Decoder Loss:  1.6403027
Encoder Loss:  0.46930984  || Decoder Loss:  0.93482745 Validation Decoder Loss:  1.6384557
Encoder Loss:  0.45455784  || Decoder Loss:  0.92878413 Validation Decoder Loss:  1.6171546
Encoder Loss:  0.46225035  || Decoder Loss:  0.863793 Validation Decoder Loss:  1.3704985
Encoder Loss:  0.4443741  || Decoder Loss:  0.52891916 Validation Decoder Loss:  0.7123692
Encoder Loss:  0.40557292  || Decoder Loss:  0.18939516 Validation Decoder Loss:  0.43365943
Encoder Loss:  0.42265642  || Decoder Loss:  0.09170706 Validation Decoder Loss:  0.3758014
Encoder Loss:  0.4202038  || Decoder Loss:  0.07477964 Validation Decoder Loss:  0.3667663
Encoder Loss:  0.41625595  || Decoder Loss:  0.0751036 Validation Decoder Loss:  0.36819154
Encoder Loss:  0.40918568  || Decoder Loss:  0.080779016 Validation Decoder Loss:  0.37501037
Encoder Loss:  0.38810676  || Decoder Loss:  0.09751827 Validation Decoder Loss:  0.416237
Encoder Loss:  0.19702297  || Decoder Loss:  0.39895135 Validation Decoder Loss:  1.2305497
Encoder Loss:  0.14414905  || Decoder Loss:  0.48423636 Validation Decoder Loss:  1.0582448
Encoder Loss:  0.11823477  || Decoder Loss:  0.4704823 Validation Decoder Loss:  1.0874239
Encoder Loss:  0.11774097  || Decoder Loss:  0.4696238 Validation Decoder Loss:  1.094184
Encoder Loss:  0.11810636  || Decoder Loss:  0.4712084 Validation Decoder Loss:  1.1091243
Encoder Loss:  0.118302085  || Decoder Loss:  0.46650505 Validation Decoder Loss:  1.0923182
Encoder Loss:  0.116384074  || Decoder Loss:  0.46424407 Validation Decoder Loss:  1.0971674
Encoder Loss:  0.11642616  || Decoder Loss:  0.46308517 Validation Decoder Loss:  1.0995352
Encoder Loss:  0.11485843  || Decoder Loss:  0.4603268 Validation Decoder Loss:  1.0585228
Encoder Loss:  0.111533545  || Decoder Loss:  0.45469216 Validation Decoder Loss:  1.0456511
Encoder Loss:  0.10926658  || Decoder Loss:  0.44856825 Validation Decoder Loss:  0.99594355
Encoder Loss:  0.106252976  || Decoder Loss:  0.43389693 Validation Decoder Loss:  1.0154107
Encoder Loss:  0.107240364  || Decoder Loss:  0.40994132 Validation Decoder Loss:  0.94268787
Encoder Loss:  0.10108343  || Decoder Loss:  0.32542625 Validation Decoder Loss:  0.7596349
Encoder Loss:  0.093880236  || Decoder Loss:  0.19004898 Validation Decoder Loss:  0.7649159
Encoder Loss:  0.09717165  || Decoder Loss:  0.30204585 Validation Decoder Loss:  0.6035327
Encoder Loss:  0.08783058  || Decoder Loss:  0.09428134 Validation Decoder Loss:  0.38118634
Encoder Loss:  0.08465709  || Decoder Loss:  0.0654419 Validation Decoder Loss:  0.4289314
Encoder Loss:  0.084371135  || Decoder Loss:  0.051622577 Validation Decoder Loss:  0.39890558
Encoder Loss:  0.08238135  || Decoder Loss:  0.040656563 Validation Decoder Loss:  0.36203173
Encoder Loss:  0.0810481  || Decoder Loss:  0.034836598 Validation Decoder Loss:  0.3594307
Encoder Loss:  0.08013968  || Decoder Loss:  0.032584466 Validation Decoder Loss:  0.3573674
Encoder Loss:  0.07948874  || Decoder Loss:  0.031459704 Validation Decoder Loss:  0.3657928
Encoder Loss:  0.07798215  || Decoder Loss:  0.03289168 Validation Decoder Loss:  0.3610952
Encoder Loss:  0.07716153  || Decoder Loss:  0.032411292 Validation Decoder Loss:  0.35695183
Encoder Loss:  0.07577859  || Decoder Loss:  0.031911183 Validation Decoder Loss:  0.3550701
Encoder Loss:  0.074423574  || Decoder Loss:  0.03196439 Validation Decoder Loss:  0.35145688
Encoder Loss:  0.075735524  || Decoder Loss:  0.0323441 Validation Decoder Loss:  0.34992826
Encoder Loss:  0.07219211  || Decoder Loss:  0.03286373 Validation Decoder Loss:  0.35476395
Model: siamese_net_lr_0.06726595903343728 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35476398
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_41 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44987282  || Decoder Loss:  0.91737056 Validation Decoder Loss:  1.6384159
Encoder Loss:  0.48742875  || Decoder Loss:  0.93524337 Validation Decoder Loss:  1.6366774
Encoder Loss:  0.48693997  || Decoder Loss:  0.93084353 Validation Decoder Loss:  1.6235039
Encoder Loss:  0.4839444  || Decoder Loss:  0.90007406 Validation Decoder Loss:  1.5185286
Encoder Loss:  0.46820718  || Decoder Loss:  0.7214723 Validation Decoder Loss:  1.0570844
Encoder Loss:  0.43662778  || Decoder Loss:  0.35896203 Validation Decoder Loss:  0.57943404
Encoder Loss:  0.4175363  || Decoder Loss:  0.14509314 Validation Decoder Loss:  0.41289663
Encoder Loss:  0.41113442  || Decoder Loss:  0.083649196 Validation Decoder Loss:  0.37198412
Encoder Loss:  0.40815377  || Decoder Loss:  0.07037366 Validation Decoder Loss:  0.36354512
Encoder Loss:  0.4013673  || Decoder Loss:  0.068727925 Validation Decoder Loss:  0.36254585
Encoder Loss:  0.37833256  || Decoder Loss:  0.069622695 Validation Decoder Loss:  0.3631779
Encoder Loss:  0.4065899  || Decoder Loss:  0.07124137 Validation Decoder Loss:  0.3645131
Encoder Loss:  0.4044699  || Decoder Loss:  0.07348374 Validation Decoder Loss:  0.3664956
Encoder Loss:  0.40129304  || Decoder Loss:  0.07663146 Validation Decoder Loss:  0.36959964
Encoder Loss:  0.39598802  || Decoder Loss:  0.08159042 Validation Decoder Loss:  0.3754059
Encoder Loss:  0.38427186  || Decoder Loss:  0.091835774 Validation Decoder Loss:  0.3928221
Encoder Loss:  0.2964806  || Decoder Loss:  0.22480753 Validation Decoder Loss:  1.4386721
Encoder Loss:  0.19665386  || Decoder Loss:  0.5454473 Validation Decoder Loss:  1.1625242
Encoder Loss:  0.13553555  || Decoder Loss:  0.4718257 Validation Decoder Loss:  1.1472778
Encoder Loss:  0.13893849  || Decoder Loss:  0.4753651 Validation Decoder Loss:  1.0618446
Encoder Loss:  0.1290358  || Decoder Loss:  0.4695433 Validation Decoder Loss:  1.1256175
Encoder Loss:  0.13322267  || Decoder Loss:  0.47028485 Validation Decoder Loss:  1.0949898
Encoder Loss:  0.12920788  || Decoder Loss:  0.46888757 Validation Decoder Loss:  1.1258032
Encoder Loss:  0.1320846  || Decoder Loss:  0.4669101 Validation Decoder Loss:  1.1021812
Encoder Loss:  0.13077632  || Decoder Loss:  0.46612132 Validation Decoder Loss:  1.1091766
Encoder Loss:  0.13116688  || Decoder Loss:  0.46233475 Validation Decoder Loss:  1.1038077
Encoder Loss:  0.12950133  || Decoder Loss:  0.46147346 Validation Decoder Loss:  1.1088967
Encoder Loss:  0.12915057  || Decoder Loss:  0.45904952 Validation Decoder Loss:  1.1134508
Encoder Loss:  0.13295467  || Decoder Loss:  0.4581427 Validation Decoder Loss:  1.0148313
Encoder Loss:  0.122814655  || Decoder Loss:  0.43781102 Validation Decoder Loss:  1.0157152
Encoder Loss:  0.1211816  || Decoder Loss:  0.41355523 Validation Decoder Loss:  1.1035118
Encoder Loss:  0.122087985  || Decoder Loss:  0.38934425 Validation Decoder Loss:  1.0428872
Encoder Loss:  0.117505245  || Decoder Loss:  0.35343575 Validation Decoder Loss:  0.7550578
Encoder Loss:  0.10918365  || Decoder Loss:  0.2647968 Validation Decoder Loss:  0.62566555
Encoder Loss:  0.106845066  || Decoder Loss:  0.23742798 Validation Decoder Loss:  0.62137026
Encoder Loss:  0.10444346  || Decoder Loss:  0.20867752 Validation Decoder Loss:  0.87535393
Encoder Loss:  0.10949113  || Decoder Loss:  0.27084613 Validation Decoder Loss:  0.67648196
Encoder Loss:  0.1021038  || Decoder Loss:  0.20303182 Validation Decoder Loss:  0.530409
Encoder Loss:  0.09743748  || Decoder Loss:  0.15118998 Validation Decoder Loss:  0.4369099
Encoder Loss:  0.09040775  || Decoder Loss:  0.07021525 Validation Decoder Loss:  0.40813124
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.40813124
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_42 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46072942  || Decoder Loss:  0.81084687 Validation Decoder Loss:  1.1575649
Encoder Loss:  0.44067284  || Decoder Loss:  0.34080818 Validation Decoder Loss:  0.46631148
Encoder Loss:  0.42564628  || Decoder Loss:  0.06716312 Validation Decoder Loss:  0.3472367
Encoder Loss:  0.42213818  || Decoder Loss:  0.038857695 Validation Decoder Loss:  0.34138432
Encoder Loss:  0.41879573  || Decoder Loss:  0.040138546 Validation Decoder Loss:  0.34244326
Encoder Loss:  0.41299212  || Decoder Loss:  0.044388685 Validation Decoder Loss:  0.34594926
Encoder Loss:  0.39982867  || Decoder Loss:  0.054187194 Validation Decoder Loss:  0.36144635
Encoder Loss:  0.2967778  || Decoder Loss:  0.22924417 Validation Decoder Loss:  1.3261297
Encoder Loss:  0.16304289  || Decoder Loss:  0.4356991 Validation Decoder Loss:  0.8919741
Encoder Loss:  0.10870596  || Decoder Loss:  0.39776117 Validation Decoder Loss:  0.9231283
Encoder Loss:  0.10815035  || Decoder Loss:  0.37618858 Validation Decoder Loss:  0.7854825
Encoder Loss:  0.09432884  || Decoder Loss:  0.13698688 Validation Decoder Loss:  0.36231405
Encoder Loss:  0.09045094  || Decoder Loss:  0.04328127 Validation Decoder Loss:  0.34841096
Encoder Loss:  0.08749168  || Decoder Loss:  0.033959378 Validation Decoder Loss:  0.34535885
Encoder Loss:  0.088964395  || Decoder Loss:  0.033376724 Validation Decoder Loss:  0.34563386
Encoder Loss:  0.085469425  || Decoder Loss:  0.033274714 Validation Decoder Loss:  0.3460209
Encoder Loss:  0.086585805  || Decoder Loss:  0.0332357 Validation Decoder Loss:  0.3462035
Encoder Loss:  0.08568848  || Decoder Loss:  0.03321497 Validation Decoder Loss:  0.34637752
Encoder Loss:  0.08568195  || Decoder Loss:  0.033207275 Validation Decoder Loss:  0.34655634
Encoder Loss:  0.08455929  || Decoder Loss:  0.033207033 Validation Decoder Loss:  0.34676313
Encoder Loss:  0.08454632  || Decoder Loss:  0.033214975 Validation Decoder Loss:  0.34689397
Encoder Loss:  0.08193443  || Decoder Loss:  0.033227168 Validation Decoder Loss:  0.34708798
Encoder Loss:  0.08120999  || Decoder Loss:  0.033253334 Validation Decoder Loss:  0.34725273
Encoder Loss:  0.07975868  || Decoder Loss:  0.033287656 Validation Decoder Loss:  0.3474166
Encoder Loss:  0.07854877  || Decoder Loss:  0.033330556 Validation Decoder Loss:  0.3474669
Encoder Loss:  0.07701146  || Decoder Loss:  0.0333651 Validation Decoder Loss:  0.34734917
Encoder Loss:  0.07831276  || Decoder Loss:  0.03338518 Validation Decoder Loss:  0.34742337
Encoder Loss:  0.076324284  || Decoder Loss:  0.033410538 Validation Decoder Loss:  0.3475905
Encoder Loss:  0.07065487  || Decoder Loss:  0.033469528 Validation Decoder Loss:  0.3474445
Encoder Loss:  0.07399313  || Decoder Loss:  0.033515178 Validation Decoder Loss:  0.34727228
Encoder Loss:  0.064664796  || Decoder Loss:  0.033563823 Validation Decoder Loss:  0.34682977
Encoder Loss:  0.069319986  || Decoder Loss:  0.03359579 Validation Decoder Loss:  0.34622648
Encoder Loss:  0.06458858  || Decoder Loss:  0.03361687 Validation Decoder Loss:  0.34572995
Encoder Loss:  0.0705083  || Decoder Loss:  0.033641137 Validation Decoder Loss:  0.34472483
Encoder Loss:  0.06077305  || Decoder Loss:  0.033643913 Validation Decoder Loss:  0.34492218
Encoder Loss:  0.06771326  || Decoder Loss:  0.033665527 Validation Decoder Loss:  0.34373373
Encoder Loss:  0.066847086  || Decoder Loss:  0.033665694 Validation Decoder Loss:  0.3433137
Encoder Loss:  0.07138932  || Decoder Loss:  0.03369245 Validation Decoder Loss:  0.339919
Encoder Loss:  0.061441317  || Decoder Loss:  0.033774033 Validation Decoder Loss:  0.33995828
Encoder Loss:  0.059335236  || Decoder Loss:  0.033835743 Validation Decoder Loss:  0.33730304
Model: siamese_net_lr_0.06616964480306742 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33730304
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_43 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13085584  || Decoder Loss:  0.421311 Validation Decoder Loss:  0.88837886
Encoder Loss:  0.118917376  || Decoder Loss:  0.37205902 Validation Decoder Loss:  0.80740297
Encoder Loss:  0.108621165  || Decoder Loss:  0.323682 Validation Decoder Loss:  0.7390233
Encoder Loss:  0.10025011  || Decoder Loss:  0.28373328 Validation Decoder Loss:  0.684746
Encoder Loss:  0.093695104  || Decoder Loss:  0.25201616 Validation Decoder Loss:  0.6424719
Encoder Loss:  0.088535644  || Decoder Loss:  0.22699477 Validation Decoder Loss:  0.60947275
Encoder Loss:  0.0851746  || Decoder Loss:  0.20726356 Validation Decoder Loss:  0.5840014
Encoder Loss:  0.0819742  || Decoder Loss:  0.19126673 Validation Decoder Loss:  0.5627003
Encoder Loss:  0.07912338  || Decoder Loss:  0.17791562 Validation Decoder Loss:  0.5449902
Encoder Loss:  0.07638496  || Decoder Loss:  0.16651493 Validation Decoder Loss:  0.5297399
Encoder Loss:  0.0741111  || Decoder Loss:  0.1565994 Validation Decoder Loss:  0.51642776
Encoder Loss:  0.0729387  || Decoder Loss:  0.14813462 Validation Decoder Loss:  0.50536025
Encoder Loss:  0.07087287  || Decoder Loss:  0.14080334 Validation Decoder Loss:  0.49539077
Encoder Loss:  0.06999325  || Decoder Loss:  0.1343182 Validation Decoder Loss:  0.4868104
Encoder Loss:  0.06876044  || Decoder Loss:  0.12859969 Validation Decoder Loss:  0.4790848
Encoder Loss:  0.067575976  || Decoder Loss:  0.12350155 Validation Decoder Loss:  0.47219262
Encoder Loss:  0.066714846  || Decoder Loss:  0.118882544 Validation Decoder Loss:  0.4659717
Encoder Loss:  0.06530871  || Decoder Loss:  0.11474555 Validation Decoder Loss:  0.46029627
Encoder Loss:  0.064529955  || Decoder Loss:  0.11095485 Validation Decoder Loss:  0.4551262
Encoder Loss:  0.06408225  || Decoder Loss:  0.107527055 Validation Decoder Loss:  0.45047528
Encoder Loss:  0.06408301  || Decoder Loss:  0.10444851 Validation Decoder Loss:  0.44638216
Encoder Loss:  0.06333505  || Decoder Loss:  0.10165427 Validation Decoder Loss:  0.44259217
Encoder Loss:  0.06286427  || Decoder Loss:  0.099075995 Validation Decoder Loss:  0.43910426
Encoder Loss:  0.06173916  || Decoder Loss:  0.09666605 Validation Decoder Loss:  0.43571448
Encoder Loss:  0.06179333  || Decoder Loss:  0.09441103 Validation Decoder Loss:  0.43264472
Encoder Loss:  0.060730685  || Decoder Loss:  0.092309736 Validation Decoder Loss:  0.42965582
Encoder Loss:  0.06033201  || Decoder Loss:  0.09032106 Validation Decoder Loss:  0.42687154
Encoder Loss:  0.05991706  || Decoder Loss:  0.088477574 Validation Decoder Loss:  0.42429644
Encoder Loss:  0.059754934  || Decoder Loss:  0.08676505 Validation Decoder Loss:  0.42189074
Encoder Loss:  0.059414238  || Decoder Loss:  0.08515391 Validation Decoder Loss:  0.419636
Encoder Loss:  0.05896847  || Decoder Loss:  0.08365444 Validation Decoder Loss:  0.41752136
Encoder Loss:  0.05872282  || Decoder Loss:  0.08223377 Validation Decoder Loss:  0.41552022
Encoder Loss:  0.058422584  || Decoder Loss:  0.080900155 Validation Decoder Loss:  0.4136327
Encoder Loss:  0.058260895  || Decoder Loss:  0.07963085 Validation Decoder Loss:  0.41182303
Encoder Loss:  0.058148738  || Decoder Loss:  0.078432605 Validation Decoder Loss:  0.4101311
Encoder Loss:  0.057748392  || Decoder Loss:  0.0773049 Validation Decoder Loss:  0.40852565
Encoder Loss:  0.057616577  || Decoder Loss:  0.076226875 Validation Decoder Loss:  0.4069901
Encoder Loss:  0.05723636  || Decoder Loss:  0.075211346 Validation Decoder Loss:  0.40553585
Encoder Loss:  0.05704728  || Decoder Loss:  0.074233614 Validation Decoder Loss:  0.4041155
Encoder Loss:  0.057633113  || Decoder Loss:  0.07330935 Validation Decoder Loss:  0.4028373
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.4028373
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_44 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3926857  || Decoder Loss:  0.30071765 Validation Decoder Loss:  0.34996378
Encoder Loss:  0.44186923  || Decoder Loss:  0.03668991 Validation Decoder Loss:  0.33693838
Encoder Loss:  0.43192306  || Decoder Loss:  0.03506266 Validation Decoder Loss:  0.33588487
Encoder Loss:  0.39551795  || Decoder Loss:  0.035155974 Validation Decoder Loss:  0.33541
Encoder Loss:  0.44417435  || Decoder Loss:  0.035331585 Validation Decoder Loss:  0.3354211
Encoder Loss:  0.44352517  || Decoder Loss:  0.035579044 Validation Decoder Loss:  0.33544147
Encoder Loss:  0.442311  || Decoder Loss:  0.035880353 Validation Decoder Loss:  0.33553076
Encoder Loss:  0.44000107  || Decoder Loss:  0.036245238 Validation Decoder Loss:  0.33574632
Encoder Loss:  0.42392686  || Decoder Loss:  0.036687046 Validation Decoder Loss:  0.33633047
Encoder Loss:  0.40445805  || Decoder Loss:  0.037190717 Validation Decoder Loss:  0.33561474
Encoder Loss:  0.4065714  || Decoder Loss:  0.037760608 Validation Decoder Loss:  0.33534116
Encoder Loss:  0.3416879  || Decoder Loss:  0.03850818 Validation Decoder Loss:  0.33610183
Encoder Loss:  0.13335362  || Decoder Loss:  0.03909342 Validation Decoder Loss:  0.33612025
Encoder Loss:  0.15983592  || Decoder Loss:  0.03939078 Validation Decoder Loss:  0.33600345
Encoder Loss:  0.21780244  || Decoder Loss:  0.03975498 Validation Decoder Loss:  0.33597785
Encoder Loss:  0.19870953  || Decoder Loss:  0.040348433 Validation Decoder Loss:  0.33560157
Encoder Loss:  0.14984287  || Decoder Loss:  0.04097554 Validation Decoder Loss:  0.33567667
Encoder Loss:  0.11353467  || Decoder Loss:  0.04138882 Validation Decoder Loss:  0.33573863
Encoder Loss:  0.14917989  || Decoder Loss:  0.041801713 Validation Decoder Loss:  0.33548036
Encoder Loss:  0.1254922  || Decoder Loss:  0.04241328 Validation Decoder Loss:  0.3355372
Encoder Loss:  0.11238417  || Decoder Loss:  0.04288397 Validation Decoder Loss:  0.3356716
Encoder Loss:  0.06773085  || Decoder Loss:  0.043288503 Validation Decoder Loss:  0.33589453
Encoder Loss:  0.0904082  || Decoder Loss:  0.043537874 Validation Decoder Loss:  0.33611682
Encoder Loss:  0.084173545  || Decoder Loss:  0.04387014 Validation Decoder Loss:  0.33621952
Encoder Loss:  0.11690709  || Decoder Loss:  0.044298008 Validation Decoder Loss:  0.33645594
Encoder Loss:  0.123680964  || Decoder Loss:  0.044988584 Validation Decoder Loss:  0.3364285
Encoder Loss:  0.105767615  || Decoder Loss:  0.045922384 Validation Decoder Loss:  0.33683038
Encoder Loss:  0.10781138  || Decoder Loss:  0.04674005 Validation Decoder Loss:  0.3370195
Encoder Loss:  0.08276547  || Decoder Loss:  0.047626834 Validation Decoder Loss:  0.33749932
Encoder Loss:  0.061918996  || Decoder Loss:  0.04821488 Validation Decoder Loss:  0.33801022
Encoder Loss:  0.08292158  || Decoder Loss:  0.048586715 Validation Decoder Loss:  0.33867756
Encoder Loss:  0.117746696  || Decoder Loss:  0.04973389 Validation Decoder Loss:  0.33961636
Encoder Loss:  0.08794168  || Decoder Loss:  0.051181197 Validation Decoder Loss:  0.3399817
Encoder Loss:  0.11001651  || Decoder Loss:  0.052966546 Validation Decoder Loss:  0.34110796
Encoder Loss:  0.07166209  || Decoder Loss:  0.05488934 Validation Decoder Loss:  0.3420115
Encoder Loss:  0.08136118  || Decoder Loss:  0.056631144 Validation Decoder Loss:  0.34322774
Encoder Loss:  0.07266184  || Decoder Loss:  0.058359317 Validation Decoder Loss:  0.3445959
Encoder Loss:  0.07159361  || Decoder Loss:  0.060147334 Validation Decoder Loss:  0.34634566
Encoder Loss:  0.10680707  || Decoder Loss:  0.06288988 Validation Decoder Loss:  0.3503719
Encoder Loss:  0.075079925  || Decoder Loss:  0.070464164 Validation Decoder Loss:  0.35697207
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35697204
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_45 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 3245, 20, 1)       2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24394721  || Decoder Loss:  0.18855077 Validation Decoder Loss:  0.35741913
Encoder Loss:  0.150607  || Decoder Loss:  0.033530176 Validation Decoder Loss:  0.34886652
Encoder Loss:  0.11510253  || Decoder Loss:  0.03185144 Validation Decoder Loss:  0.34755582
Encoder Loss:  0.09083026  || Decoder Loss:  0.030784683 Validation Decoder Loss:  0.3501344
Encoder Loss:  0.09898659  || Decoder Loss:  0.030213665 Validation Decoder Loss:  0.35146683
Encoder Loss:  0.09805087  || Decoder Loss:  0.029515358 Validation Decoder Loss:  0.35173726
Encoder Loss:  0.098802134  || Decoder Loss:  0.029015498 Validation Decoder Loss:  0.35331511
Encoder Loss:  0.098213635  || Decoder Loss:  0.028475747 Validation Decoder Loss:  0.35414922
Encoder Loss:  0.097579986  || Decoder Loss:  0.028015174 Validation Decoder Loss:  0.3557434
Encoder Loss:  0.098513916  || Decoder Loss:  0.027548706 Validation Decoder Loss:  0.35924304
Encoder Loss:  0.094684795  || Decoder Loss:  0.02718342 Validation Decoder Loss:  0.35572436
Encoder Loss:  0.09336605  || Decoder Loss:  0.02671377 Validation Decoder Loss:  0.35526717
Encoder Loss:  0.09253938  || Decoder Loss:  0.026401937 Validation Decoder Loss:  0.3550033
Encoder Loss:  0.09354066  || Decoder Loss:  0.026131876 Validation Decoder Loss:  0.35631126
Encoder Loss:  0.09218901  || Decoder Loss:  0.025880657 Validation Decoder Loss:  0.35807574
Encoder Loss:  0.093959935  || Decoder Loss:  0.02557804 Validation Decoder Loss:  0.3582186
Encoder Loss:  0.089977235  || Decoder Loss:  0.025317073 Validation Decoder Loss:  0.35625708
Encoder Loss:  0.08941398  || Decoder Loss:  0.025135433 Validation Decoder Loss:  0.35589108
Encoder Loss:  0.09059536  || Decoder Loss:  0.025081983 Validation Decoder Loss:  0.35683292
Encoder Loss:  0.08851471  || Decoder Loss:  0.024914958 Validation Decoder Loss:  0.35524067
Encoder Loss:  0.08779693  || Decoder Loss:  0.02487809 Validation Decoder Loss:  0.35657173
Encoder Loss:  0.08699207  || Decoder Loss:  0.02474127 Validation Decoder Loss:  0.35453635
Encoder Loss:  0.09218458  || Decoder Loss:  0.024855493 Validation Decoder Loss:  0.36435732
Encoder Loss:  0.08419245  || Decoder Loss:  0.024637036 Validation Decoder Loss:  0.3546057
Encoder Loss:  0.08408401  || Decoder Loss:  0.024581712 Validation Decoder Loss:  0.350424
Encoder Loss:  0.07603277  || Decoder Loss:  0.024446558 Validation Decoder Loss:  0.35653916
Encoder Loss:  0.08479809  || Decoder Loss:  0.024804048 Validation Decoder Loss:  0.34418428
Encoder Loss:  0.07932195  || Decoder Loss:  0.02464642 Validation Decoder Loss:  0.3523884
Encoder Loss:  0.07832821  || Decoder Loss:  0.02470938 Validation Decoder Loss:  0.35054705
Encoder Loss:  0.076996624  || Decoder Loss:  0.025075555 Validation Decoder Loss:  0.3485089
Encoder Loss:  0.083315514  || Decoder Loss:  0.02540699 Validation Decoder Loss:  0.34256268
Encoder Loss:  0.06429123  || Decoder Loss:  0.025326846 Validation Decoder Loss:  0.34777695
Encoder Loss:  0.07472658  || Decoder Loss:  0.025908632 Validation Decoder Loss:  0.3441072
Encoder Loss:  0.062011  || Decoder Loss:  0.02590268 Validation Decoder Loss:  0.34711948
Encoder Loss:  0.07656844  || Decoder Loss:  0.026287936 Validation Decoder Loss:  0.3488648
Encoder Loss:  0.09337769  || Decoder Loss:  0.026011754 Validation Decoder Loss:  0.3556878
Encoder Loss:  0.07875153  || Decoder Loss:  0.025669241 Validation Decoder Loss:  0.3459546
Encoder Loss:  0.063021995  || Decoder Loss:  0.02529463 Validation Decoder Loss:  0.34417218
Encoder Loss:  0.06879943  || Decoder Loss:  0.025476532 Validation Decoder Loss:  0.34973854
Encoder Loss:  0.0695371  || Decoder Loss:  0.02533334 Validation Decoder Loss:  0.35004276
Model: siamese_net_lr_0.004589019988070981 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35004276
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_46 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4388537  || Decoder Loss:  0.91783935 Validation Decoder Loss:  1.6381738
Encoder Loss:  0.44689065  || Decoder Loss:  0.93559945 Validation Decoder Loss:  1.6373265
Encoder Loss:  0.44634598  || Decoder Loss:  0.93368804 Validation Decoder Loss:  1.6320649
Encoder Loss:  0.44502777  || Decoder Loss:  0.9229682 Validation Decoder Loss:  1.5959151
Encoder Loss:  0.3844846  || Decoder Loss:  0.85302645 Validation Decoder Loss:  1.3739697
Encoder Loss:  0.44657895  || Decoder Loss:  0.5848492 Validation Decoder Loss:  0.8290141
Encoder Loss:  0.44629884  || Decoder Loss:  0.2519915 Validation Decoder Loss:  0.47993273
Encoder Loss:  0.44583833  || Decoder Loss:  0.1100583 Validation Decoder Loss:  0.38194066
Encoder Loss:  0.44527164  || Decoder Loss:  0.0752276 Validation Decoder Loss:  0.36043087
Encoder Loss:  0.44456717  || Decoder Loss:  0.06861667 Validation Decoder Loss:  0.3561338
Encoder Loss:  0.44367903  || Decoder Loss:  0.06822129 Validation Decoder Loss:  0.35528237
Encoder Loss:  0.442536  || Decoder Loss:  0.069214486 Validation Decoder Loss:  0.3550511
Encoder Loss:  0.4410195  || Decoder Loss:  0.070722856 Validation Decoder Loss:  0.35495216
Encoder Loss:  0.4389131  || Decoder Loss:  0.07274487 Validation Decoder Loss:  0.35497248
Encoder Loss:  0.43576536  || Decoder Loss:  0.07559378 Validation Decoder Loss:  0.35528153
Encoder Loss:  0.43040776  || Decoder Loss:  0.0801169 Validation Decoder Loss:  0.3565205
Encoder Loss:  0.4182037  || Decoder Loss:  0.08958384 Validation Decoder Loss:  0.3631991
Encoder Loss:  0.30797955  || Decoder Loss:  0.23566186 Validation Decoder Loss:  1.3866775
Encoder Loss:  0.16243587  || Decoder Loss:  0.558087 Validation Decoder Loss:  1.0476663
Encoder Loss:  0.10871713  || Decoder Loss:  0.48520058 Validation Decoder Loss:  1.10474
Encoder Loss:  0.11405399  || Decoder Loss:  0.49447933 Validation Decoder Loss:  0.97702336
Encoder Loss:  0.09856675  || Decoder Loss:  0.4841047 Validation Decoder Loss:  1.0296912
Encoder Loss:  0.10098538  || Decoder Loss:  0.48928493 Validation Decoder Loss:  1.0597382
Encoder Loss:  0.104021646  || Decoder Loss:  0.48202252 Validation Decoder Loss:  1.0076592
Encoder Loss:  0.09934622  || Decoder Loss:  0.48630628 Validation Decoder Loss:  1.0443642
Encoder Loss:  0.10294904  || Decoder Loss:  0.47807512 Validation Decoder Loss:  1.0000134
Encoder Loss:  0.097681224  || Decoder Loss:  0.47612202 Validation Decoder Loss:  0.96801233
Encoder Loss:  0.096662134  || Decoder Loss:  0.47303456 Validation Decoder Loss:  1.0116343
Encoder Loss:  0.0986058  || Decoder Loss:  0.47057915 Validation Decoder Loss:  0.99789995
Encoder Loss:  0.10053017  || Decoder Loss:  0.46135408 Validation Decoder Loss:  0.9860705
Encoder Loss:  0.1021652  || Decoder Loss:  0.4506322 Validation Decoder Loss:  0.96160734
Encoder Loss:  0.10008821  || Decoder Loss:  0.4382435 Validation Decoder Loss:  0.9716255
Encoder Loss:  0.099359676  || Decoder Loss:  0.41034397 Validation Decoder Loss:  1.0144526
Encoder Loss:  0.09751272  || Decoder Loss:  0.37951496 Validation Decoder Loss:  0.90181565
Encoder Loss:  0.101219386  || Decoder Loss:  0.2734456 Validation Decoder Loss:  0.9531241
Encoder Loss:  0.09777474  || Decoder Loss:  0.473918 Validation Decoder Loss:  0.9738538
Encoder Loss:  0.09561498  || Decoder Loss:  0.47620082 Validation Decoder Loss:  0.9860344
Encoder Loss:  0.09841241  || Decoder Loss:  0.47245085 Validation Decoder Loss:  0.98043036
Encoder Loss:  0.10135988  || Decoder Loss:  0.4624582 Validation Decoder Loss:  0.8952562
Encoder Loss:  0.09375039  || Decoder Loss:  0.3929762 Validation Decoder Loss:  0.72000885
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.72000885
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_47 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44100586  || Decoder Loss:  0.8990906 Validation Decoder Loss:  1.6372182
Encoder Loss:  0.44667935  || Decoder Loss:  0.9088146 Validation Decoder Loss:  1.633611
Encoder Loss:  0.44572383  || Decoder Loss:  0.9060468 Validation Decoder Loss:  1.6281959
Encoder Loss:  0.44424492  || Decoder Loss:  0.90188897 Validation Decoder Loss:  1.6196427
Encoder Loss:  0.4419245  || Decoder Loss:  0.8947253 Validation Decoder Loss:  1.6027038
Encoder Loss:  0.4380929  || Decoder Loss:  0.8776375 Validation Decoder Loss:  1.5549914
Encoder Loss:  0.4308177  || Decoder Loss:  0.8205303 Validation Decoder Loss:  1.3886712
Encoder Loss:  0.40889063  || Decoder Loss:  0.64194435 Validation Decoder Loss:  0.98354316
Encoder Loss:  0.19234426  || Decoder Loss:  0.47594714 Validation Decoder Loss:  1.2057898
Encoder Loss:  0.1282413  || Decoder Loss:  0.4783646 Validation Decoder Loss:  1.1168516
Encoder Loss:  0.101234704  || Decoder Loss:  0.4674401 Validation Decoder Loss:  1.1407554
Encoder Loss:  0.100578755  || Decoder Loss:  0.46545073 Validation Decoder Loss:  1.1532445
Encoder Loss:  0.09971758  || Decoder Loss:  0.46104783 Validation Decoder Loss:  1.1555891
Encoder Loss:  0.09827324  || Decoder Loss:  0.4548046 Validation Decoder Loss:  1.1368511
Encoder Loss:  0.0941769  || Decoder Loss:  0.44713986 Validation Decoder Loss:  1.1261647
Encoder Loss:  0.0932728  || Decoder Loss:  0.44005704 Validation Decoder Loss:  1.136544
Encoder Loss:  0.09157865  || Decoder Loss:  0.42427894 Validation Decoder Loss:  1.1873701
Encoder Loss:  0.091528885  || Decoder Loss:  0.4141066 Validation Decoder Loss:  1.2107695
Encoder Loss:  0.091769055  || Decoder Loss:  0.38458234 Validation Decoder Loss:  1.0780187
Encoder Loss:  0.090582095  || Decoder Loss:  0.16757818 Validation Decoder Loss:  0.41132855
Encoder Loss:  0.09052124  || Decoder Loss:  0.061151896 Validation Decoder Loss:  0.3906821
Encoder Loss:  0.08961688  || Decoder Loss:  0.05256627 Validation Decoder Loss:  0.47088993
Encoder Loss:  0.088045016  || Decoder Loss:  0.067881964 Validation Decoder Loss:  0.35848802
Encoder Loss:  0.08917893  || Decoder Loss:  0.03730381 Validation Decoder Loss:  0.35381007
Encoder Loss:  0.086829774  || Decoder Loss:  0.03371101 Validation Decoder Loss:  0.36810243
Encoder Loss:  0.0869566  || Decoder Loss:  0.030407526 Validation Decoder Loss:  0.39363986
Encoder Loss:  0.08644054  || Decoder Loss:  0.033718053 Validation Decoder Loss:  0.3682807
Encoder Loss:  0.087622434  || Decoder Loss:  0.030666497 Validation Decoder Loss:  0.365416
Encoder Loss:  0.08390251  || Decoder Loss:  0.03106941 Validation Decoder Loss:  0.36614847
Encoder Loss:  0.08507545  || Decoder Loss:  0.02977894 Validation Decoder Loss:  0.36114526
Encoder Loss:  0.084002435  || Decoder Loss:  0.03291343 Validation Decoder Loss:  0.35862392
Encoder Loss:  0.08185917  || Decoder Loss:  0.030318446 Validation Decoder Loss:  0.36712116
Encoder Loss:  0.0819886  || Decoder Loss:  0.03046149 Validation Decoder Loss:  0.3568563
Encoder Loss:  0.07993903  || Decoder Loss:  0.030426798 Validation Decoder Loss:  0.36321676
Encoder Loss:  0.07980406  || Decoder Loss:  0.030525869 Validation Decoder Loss:  0.3511755
Encoder Loss:  0.075878344  || Decoder Loss:  0.0310469 Validation Decoder Loss:  0.35503003
Encoder Loss:  0.07612629  || Decoder Loss:  0.032081403 Validation Decoder Loss:  0.35025385
Encoder Loss:  0.06725989  || Decoder Loss:  0.031430434 Validation Decoder Loss:  0.3656565
Encoder Loss:  0.074345395  || Decoder Loss:  0.031639863 Validation Decoder Loss:  0.36050305
Encoder Loss:  0.07530375  || Decoder Loss:  0.032170158 Validation Decoder Loss:  0.3497599
Model: siamese_net_lr_0.04992063880762942 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34975988
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 164, 5, 20, 1)     39        
_________________________________________________________________
reshape_48 (Reshape)         (None, 820, 20, 1)        0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 820, 20, 1)        2427      
=================================================================
Total params: 2,427
Trainable params: 2,427
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 3245, 20, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7349669  || Decoder Loss:  0.83508825 Validation Decoder Loss:  1.1404648
Encoder Loss:  0.33825168  || Decoder Loss:  0.30091524 Validation Decoder Loss:  0.45573837
Encoder Loss:  0.17630343  || Decoder Loss:  0.08440266 Validation Decoder Loss:  0.37087685
Encoder Loss:  0.15879782  || Decoder Loss:  0.06133092 Validation Decoder Loss:  0.36322516
Encoder Loss:  0.15688613  || Decoder Loss:  0.05985861 Validation Decoder Loss:  0.3632432
Encoder Loss:  0.15165001  || Decoder Loss:  0.060057092 Validation Decoder Loss:  0.36597824
Encoder Loss:  0.53194916  || Decoder Loss:  0.6265993 Validation Decoder Loss:  0.37852955
Encoder Loss:  0.4039714  || Decoder Loss:  0.50036234 Validation Decoder Loss:  1.6334821
Encoder Loss:  0.36995766  || Decoder Loss:  0.4682042 Validation Decoder Loss:  0.72457623
Encoder Loss:  0.35352063  || Decoder Loss:  0.45205325 Validation Decoder Loss:  0.8678374
Encoder Loss:  0.38053843  || Decoder Loss:  0.48904938 Validation Decoder Loss:  0.9821519
Encoder Loss:  0.3728285  || Decoder Loss:  0.477065 Validation Decoder Loss:  0.8951735
Encoder Loss:  0.35560712  || Decoder Loss:  0.45580596 Validation Decoder Loss:  0.9161865
Encoder Loss:  0.24145001  || Decoder Loss:  0.30383876 Validation Decoder Loss:  0.47293514
Encoder Loss:  0.12973638  || Decoder Loss:  0.15398416 Validation Decoder Loss:  0.410166
Encoder Loss:  0.07373662  || Decoder Loss:  0.076568194 Validation Decoder Loss:  0.34584612
Encoder Loss:  0.043907847  || Decoder Loss:  0.037115697 Validation Decoder Loss:  0.3439418
Encoder Loss:  0.040076748  || Decoder Loss:  0.03425229 Validation Decoder Loss:  0.3452987
Encoder Loss:  0.041375566  || Decoder Loss:  0.033960436 Validation Decoder Loss:  0.34678298
Encoder Loss:  0.04017601  || Decoder Loss:  0.034030706 Validation Decoder Loss:  0.34389448
Encoder Loss:  0.043927092  || Decoder Loss:  0.034561347 Validation Decoder Loss:  0.35324866
Encoder Loss:  0.040702876  || Decoder Loss:  0.034380563 Validation Decoder Loss:  0.34959358
Encoder Loss:  0.041219503  || Decoder Loss:  0.034478188 Validation Decoder Loss:  0.35762227
Encoder Loss:  0.042486135  || Decoder Loss:  0.035293043 Validation Decoder Loss:  0.35205454
Encoder Loss:  0.043092657  || Decoder Loss:  0.03430741 Validation Decoder Loss:  0.3491596
Encoder Loss:  0.040045995  || Decoder Loss:  0.034124926 Validation Decoder Loss:  0.34685546
Encoder Loss:  0.038962506  || Decoder Loss:  0.033957653 Validation Decoder Loss:  0.3463685
Encoder Loss:  0.040998936  || Decoder Loss:  0.034440856 Validation Decoder Loss:  0.34712002
Encoder Loss:  0.041144818  || Decoder Loss:  0.034538705 Validation Decoder Loss:  0.35093623
Encoder Loss:  0.040699806  || Decoder Loss:  0.034981713 Validation Decoder Loss:  0.34922615
Encoder Loss:  0.041554436  || Decoder Loss:  0.03545149 Validation Decoder Loss:  0.34863207
Encoder Loss:  0.039215047  || Decoder Loss:  0.03398181 Validation Decoder Loss:  0.34826055
Encoder Loss:  0.039064717  || Decoder Loss:  0.03384096 Validation Decoder Loss:  0.34778857
Encoder Loss:  0.039547134  || Decoder Loss:  0.034074944 Validation Decoder Loss:  0.3485449
Encoder Loss:  0.04080936  || Decoder Loss:  0.034025256 Validation Decoder Loss:  0.3453094
Encoder Loss:  0.039197132  || Decoder Loss:  0.0342492 Validation Decoder Loss:  0.34895313
Encoder Loss:  0.0412998  || Decoder Loss:  0.034869708 Validation Decoder Loss:  0.35243666
Encoder Loss:  0.040387847  || Decoder Loss:  0.034585398 Validation Decoder Loss:  0.34993505
Encoder Loss:  0.041235868  || Decoder Loss:  0.035144016 Validation Decoder Loss:  0.34830648
Encoder Loss:  0.040478192  || Decoder Loss:  0.03488854 Validation Decoder Loss:  0.3493181
Model: siamese_net_lr_0.029593373236370884 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34931806
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_49 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.052951183  || Decoder Loss:  0.4667899 Validation Decoder Loss:  0.9689356
Encoder Loss:  0.05118677  || Decoder Loss:  0.39452332 Validation Decoder Loss:  0.8372109
Encoder Loss:  0.050912447  || Decoder Loss:  0.3226476 Validation Decoder Loss:  0.7221005
Encoder Loss:  0.050682865  || Decoder Loss:  0.26513758 Validation Decoder Loss:  0.63809323
Encoder Loss:  0.05061216  || Decoder Loss:  0.22305223 Validation Decoder Loss:  0.5797364
Encoder Loss:  0.050581075  || Decoder Loss:  0.19273597 Validation Decoder Loss:  0.5387702
Encoder Loss:  0.05056744  || Decoder Loss:  0.17045933 Validation Decoder Loss:  0.50915307
Encoder Loss:  0.0505538  || Decoder Loss:  0.15359083 Validation Decoder Loss:  0.48705667
Encoder Loss:  0.050543547  || Decoder Loss:  0.14043878 Validation Decoder Loss:  0.47004884
Encoder Loss:  0.05053364  || Decoder Loss:  0.12991697 Validation Decoder Loss:  0.45659035
Encoder Loss:  0.050521974  || Decoder Loss:  0.12131239 Validation Decoder Loss:  0.44568676
Encoder Loss:  0.050512057  || Decoder Loss:  0.114144705 Validation Decoder Loss:  0.4366785
Encoder Loss:  0.050503053  || Decoder Loss:  0.10807973 Validation Decoder Loss:  0.42911038
Encoder Loss:  0.050494365  || Decoder Loss:  0.1028789 Validation Decoder Loss:  0.42265585
Encoder Loss:  0.050485715  || Decoder Loss:  0.098367475 Validation Decoder Loss:  0.417099
Encoder Loss:  0.050482336  || Decoder Loss:  0.09441511 Validation Decoder Loss:  0.41225252
Encoder Loss:  0.050469004  || Decoder Loss:  0.09092226 Validation Decoder Loss:  0.40799397
Encoder Loss:  0.05046237  || Decoder Loss:  0.087811805 Validation Decoder Loss:  0.40421903
Encoder Loss:  0.050456505  || Decoder Loss:  0.085023016 Validation Decoder Loss:  0.40085247
Encoder Loss:  0.050449032  || Decoder Loss:  0.08250744 Validation Decoder Loss:  0.3978302
Encoder Loss:  0.05044326  || Decoder Loss:  0.080225945 Validation Decoder Loss:  0.3950972
Encoder Loss:  0.050436158  || Decoder Loss:  0.07814652 Validation Decoder Loss:  0.39261568
Encoder Loss:  0.05042909  || Decoder Loss:  0.076242924 Validation Decoder Loss:  0.39035615
Encoder Loss:  0.050428897  || Decoder Loss:  0.07449317 Validation Decoder Loss:  0.3882831
Encoder Loss:  0.050417162  || Decoder Loss:  0.072878934 Validation Decoder Loss:  0.38637844
Encoder Loss:  0.050411448  || Decoder Loss:  0.07138462 Validation Decoder Loss:  0.3846215
Encoder Loss:  0.050410252  || Decoder Loss:  0.06999693 Validation Decoder Loss:  0.3829906
Encoder Loss:  0.050400224  || Decoder Loss:  0.0687046 Validation Decoder Loss:  0.3814776
Encoder Loss:  0.05039637  || Decoder Loss:  0.067497775 Validation Decoder Loss:  0.3800693
Encoder Loss:  0.05039371  || Decoder Loss:  0.066368006 Validation Decoder Loss:  0.378753
Encoder Loss:  0.050390374  || Decoder Loss:  0.06530797 Validation Decoder Loss:  0.3775239
Encoder Loss:  0.05038783  || Decoder Loss:  0.064311095 Validation Decoder Loss:  0.3763681
Encoder Loss:  0.05038984  || Decoder Loss:  0.063371755 Validation Decoder Loss:  0.37527955
Encoder Loss:  0.05037606  || Decoder Loss:  0.062485024 Validation Decoder Loss:  0.3742577
Encoder Loss:  0.050373826  || Decoder Loss:  0.061646394 Validation Decoder Loss:  0.37329292
Encoder Loss:  0.050368614  || Decoder Loss:  0.06085183 Validation Decoder Loss:  0.372382
Encoder Loss:  0.050389364  || Decoder Loss:  0.060097955 Validation Decoder Loss:  0.37151387
Encoder Loss:  0.050358806  || Decoder Loss:  0.059381537 Validation Decoder Loss:  0.37069607
Encoder Loss:  0.05035962  || Decoder Loss:  0.05869973 Validation Decoder Loss:  0.36992174
Encoder Loss:  0.050379418  || Decoder Loss:  0.058050126 Validation Decoder Loss:  0.3691734
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3691734
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 164, 5, 20, 1)     102       
_________________________________________________________________
reshape_50 (Reshape)         (None, 820, 20, 1)        0         
=================================================================
Total params: 102
Trainable params: 102
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 820, 20, 1)        2427      
=================================================================
Total params: 2,427
Trainable params: 2,427
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 3245, 20, 1)       2427      
=================================================================
Total params: 2,427
Trainable params: 2,427
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46914876  || Decoder Loss:  0.9158511 Validation Decoder Loss:  1.6231093
Encoder Loss:  0.47719306  || Decoder Loss:  0.9129984 Validation Decoder Loss:  1.5903343
Encoder Loss:  0.4733932  || Decoder Loss:  0.8671486 Validation Decoder Loss:  1.4952443
Encoder Loss:  0.46315384  || Decoder Loss:  0.74025285 Validation Decoder Loss:  1.1736023
Encoder Loss:  0.41146868  || Decoder Loss:  0.35657606 Validation Decoder Loss:  0.4695106
Encoder Loss:  0.41774955  || Decoder Loss:  0.074368 Validation Decoder Loss:  0.36576825
Encoder Loss:  0.41447094  || Decoder Loss:  0.0485263 Validation Decoder Loss:  0.36074638
Encoder Loss:  0.41183704  || Decoder Loss:  0.04595143 Validation Decoder Loss:  0.3595553
Encoder Loss:  0.40802944  || Decoder Loss:  0.04531066 Validation Decoder Loss:  0.3587064
Encoder Loss:  0.40162566  || Decoder Loss:  0.04540782 Validation Decoder Loss:  0.35895923
Encoder Loss:  0.38760012  || Decoder Loss:  0.046860605 Validation Decoder Loss:  0.3632202
Encoder Loss:  0.2934142  || Decoder Loss:  0.14396335 Validation Decoder Loss:  1.5838337
Encoder Loss:  0.19211638  || Decoder Loss:  0.5607354 Validation Decoder Loss:  1.4874461
Encoder Loss:  0.14002635  || Decoder Loss:  0.5006669 Validation Decoder Loss:  1.1099907
Encoder Loss:  0.108859256  || Decoder Loss:  0.444129 Validation Decoder Loss:  1.1420403
Encoder Loss:  0.10882947  || Decoder Loss:  0.45087898 Validation Decoder Loss:  1.180865
Encoder Loss:  0.110020526  || Decoder Loss:  0.45393527 Validation Decoder Loss:  1.2041706
Encoder Loss:  0.11134754  || Decoder Loss:  0.45807427 Validation Decoder Loss:  1.2183604
Encoder Loss:  0.112238914  || Decoder Loss:  0.46357423 Validation Decoder Loss:  1.2444091
Encoder Loss:  0.118997306  || Decoder Loss:  0.46427155 Validation Decoder Loss:  1.0988655
Encoder Loss:  0.10541055  || Decoder Loss:  0.45291707 Validation Decoder Loss:  1.1336324
Encoder Loss:  0.10436886  || Decoder Loss:  0.44753894 Validation Decoder Loss:  1.1088037
Encoder Loss:  0.10196417  || Decoder Loss:  0.44315097 Validation Decoder Loss:  1.140006
Encoder Loss:  0.101454526  || Decoder Loss:  0.44406787 Validation Decoder Loss:  1.1363888
Encoder Loss:  0.10150711  || Decoder Loss:  0.4453022 Validation Decoder Loss:  1.1045392
Encoder Loss:  0.09825648  || Decoder Loss:  0.4382304 Validation Decoder Loss:  1.1841245
Encoder Loss:  0.09831072  || Decoder Loss:  0.4431805 Validation Decoder Loss:  1.1307395
Encoder Loss:  0.095480636  || Decoder Loss:  0.4347003 Validation Decoder Loss:  1.1962392
Encoder Loss:  0.095455214  || Decoder Loss:  0.4396819 Validation Decoder Loss:  1.3098128
Encoder Loss:  0.09694576  || Decoder Loss:  0.4518589 Validation Decoder Loss:  1.144397
Encoder Loss:  0.09136112  || Decoder Loss:  0.43827164 Validation Decoder Loss:  1.1683164
Encoder Loss:  0.090969734  || Decoder Loss:  0.4237958 Validation Decoder Loss:  1.2034404
Encoder Loss:  0.087766826  || Decoder Loss:  0.4338391 Validation Decoder Loss:  1.1051508
Encoder Loss:  0.07553622  || Decoder Loss:  0.3329509 Validation Decoder Loss:  1.0890393
Encoder Loss:  0.08268622  || Decoder Loss:  0.5029893 Validation Decoder Loss:  0.9576534
Encoder Loss:  0.08036735  || Decoder Loss:  0.4786185 Validation Decoder Loss:  0.89029
Encoder Loss:  0.07899185  || Decoder Loss:  0.46495685 Validation Decoder Loss:  0.97192097
Encoder Loss:  0.07832969  || Decoder Loss:  0.45905054 Validation Decoder Loss:  1.0431635
Encoder Loss:  0.07391837  || Decoder Loss:  0.3886948 Validation Decoder Loss:  0.93431866
Encoder Loss:  0.073030815  || Decoder Loss:  0.37319946 Validation Decoder Loss:  0.9934887
Model: siamese_net_lr_0.0790671506855862 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9934887
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_51 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 620, 20, 1)        151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.52941275  || Decoder Loss:  0.9371306 Validation Decoder Loss:  1.6162604
Encoder Loss:  0.51362073  || Decoder Loss:  0.82824117 Validation Decoder Loss:  1.2110856
Encoder Loss:  0.44370225  || Decoder Loss:  0.43725422 Validation Decoder Loss:  0.66975665
Encoder Loss:  0.39605847  || Decoder Loss:  0.17415754 Validation Decoder Loss:  0.44272658
Encoder Loss:  0.37682518  || Decoder Loss:  0.07466363 Validation Decoder Loss:  0.36483544
Encoder Loss:  0.3694323  || Decoder Loss:  0.046963815 Validation Decoder Loss:  0.34868035
Encoder Loss:  0.36509144  || Decoder Loss:  0.0451885 Validation Decoder Loss:  0.35095298
Encoder Loss:  0.3587651  || Decoder Loss:  0.051650062 Validation Decoder Loss:  0.36232936
Encoder Loss:  0.34085494  || Decoder Loss:  0.072419345 Validation Decoder Loss:  0.42909703
Encoder Loss:  0.22489944  || Decoder Loss:  0.3774947 Validation Decoder Loss:  1.0226173
Encoder Loss:  0.15818901  || Decoder Loss:  0.44317082 Validation Decoder Loss:  1.0324887
Encoder Loss:  0.15555243  || Decoder Loss:  0.44052604 Validation Decoder Loss:  1.027241
Encoder Loss:  0.15254815  || Decoder Loss:  0.43052548 Validation Decoder Loss:  1.0384624
Encoder Loss:  0.1515968  || Decoder Loss:  0.427453 Validation Decoder Loss:  1.0084534
Encoder Loss:  0.14512356  || Decoder Loss:  0.40059304 Validation Decoder Loss:  0.91445297
Encoder Loss:  0.1037772  || Decoder Loss:  0.16375358 Validation Decoder Loss:  0.36597207
Encoder Loss:  0.08116338  || Decoder Loss:  0.0451928 Validation Decoder Loss:  0.34743452
Encoder Loss:  0.079189815  || Decoder Loss:  0.03482639 Validation Decoder Loss:  0.34709007
Encoder Loss:  0.078254454  || Decoder Loss:  0.033707947 Validation Decoder Loss:  0.34708297
Encoder Loss:  0.07866696  || Decoder Loss:  0.033527166 Validation Decoder Loss:  0.34627694
Encoder Loss:  0.07535042  || Decoder Loss:  0.033492967 Validation Decoder Loss:  0.34666002
Encoder Loss:  0.0774426  || Decoder Loss:  0.033490527 Validation Decoder Loss:  0.34675193
Encoder Loss:  0.07456748  || Decoder Loss:  0.03350179 Validation Decoder Loss:  0.34705698
Encoder Loss:  0.07466645  || Decoder Loss:  0.033523213 Validation Decoder Loss:  0.34716755
Encoder Loss:  0.07340354  || Decoder Loss:  0.033547815 Validation Decoder Loss:  0.34711033
Encoder Loss:  0.06897234  || Decoder Loss:  0.033578653 Validation Decoder Loss:  0.3466426
Encoder Loss:  0.064875126  || Decoder Loss:  0.03358326 Validation Decoder Loss:  0.34645677
Encoder Loss:  0.059202813  || Decoder Loss:  0.033617824 Validation Decoder Loss:  0.34667933
Encoder Loss:  0.061868325  || Decoder Loss:  0.03363983 Validation Decoder Loss:  0.3462668
Encoder Loss:  0.056182653  || Decoder Loss:  0.033669986 Validation Decoder Loss:  0.34591383
Encoder Loss:  0.055442438  || Decoder Loss:  0.033703372 Validation Decoder Loss:  0.34502462
Encoder Loss:  0.0555689  || Decoder Loss:  0.03372107 Validation Decoder Loss:  0.34628323
Encoder Loss:  0.054960757  || Decoder Loss:  0.03363392 Validation Decoder Loss:  0.34551394
Encoder Loss:  0.051001824  || Decoder Loss:  0.03367644 Validation Decoder Loss:  0.34596902
Encoder Loss:  0.049400616  || Decoder Loss:  0.03373275 Validation Decoder Loss:  0.34613302
Encoder Loss:  0.048123904  || Decoder Loss:  0.033774577 Validation Decoder Loss:  0.34638652
Encoder Loss:  0.048265427  || Decoder Loss:  0.033745747 Validation Decoder Loss:  0.34526297
Encoder Loss:  0.047845785  || Decoder Loss:  0.033679947 Validation Decoder Loss:  0.34627795
Encoder Loss:  0.048158273  || Decoder Loss:  0.033731185 Validation Decoder Loss:  0.3453774
Encoder Loss:  0.047993246  || Decoder Loss:  0.033728115 Validation Decoder Loss:  0.34677362
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34677365
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_52 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 3245, 20, 1)       2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50034845  || Decoder Loss:  0.9272027 Validation Decoder Loss:  1.6381425
Encoder Loss:  0.50889117  || Decoder Loss:  0.93190074 Validation Decoder Loss:  1.6285273
Encoder Loss:  0.50456434  || Decoder Loss:  0.8998279 Validation Decoder Loss:  1.5890342
Encoder Loss:  0.49355873  || Decoder Loss:  0.81604993 Validation Decoder Loss:  1.4476418
Encoder Loss:  0.46428397  || Decoder Loss:  0.5898476 Validation Decoder Loss:  0.9871199
Encoder Loss:  0.41484085  || Decoder Loss:  0.20783731 Validation Decoder Loss:  0.50745416
Encoder Loss:  0.39284953  || Decoder Loss:  0.061682798 Validation Decoder Loss:  0.40781766
Encoder Loss:  0.33567724  || Decoder Loss:  0.04375649 Validation Decoder Loss:  0.38328618
Encoder Loss:  0.3920596  || Decoder Loss:  0.04077927 Validation Decoder Loss:  0.3731614
Encoder Loss:  0.39102852  || Decoder Loss:  0.039876457 Validation Decoder Loss:  0.36771077
Encoder Loss:  0.3896905  || Decoder Loss:  0.039462008 Validation Decoder Loss:  0.36446127
Encoder Loss:  0.3879397  || Decoder Loss:  0.039255694 Validation Decoder Loss:  0.36243844
Encoder Loss:  0.38550892  || Decoder Loss:  0.03920712 Validation Decoder Loss:  0.36117682
Encoder Loss:  0.38181576  || Decoder Loss:  0.039355233 Validation Decoder Loss:  0.36051705
Encoder Loss:  0.3751884  || Decoder Loss:  0.03989353 Validation Decoder Loss:  0.36078775
Encoder Loss:  0.35671183  || Decoder Loss:  0.042036735 Validation Decoder Loss:  0.36773413
Encoder Loss:  0.23716737  || Decoder Loss:  0.3827579 Validation Decoder Loss:  0.96957386
Encoder Loss:  0.14026532  || Decoder Loss:  0.4554257 Validation Decoder Loss:  1.2643459
Encoder Loss:  0.14347528  || Decoder Loss:  0.46100494 Validation Decoder Loss:  1.1826742
Encoder Loss:  0.14101623  || Decoder Loss:  0.4558189 Validation Decoder Loss:  1.1707442
Encoder Loss:  0.13881627  || Decoder Loss:  0.4509392 Validation Decoder Loss:  1.1769586
Encoder Loss:  0.1423127  || Decoder Loss:  0.4612872 Validation Decoder Loss:  1.1290913
Encoder Loss:  0.13812093  || Decoder Loss:  0.43911648 Validation Decoder Loss:  1.1540712
Encoder Loss:  0.13776292  || Decoder Loss:  0.44453728 Validation Decoder Loss:  1.1671715
Encoder Loss:  0.13836811  || Decoder Loss:  0.4450251 Validation Decoder Loss:  1.1441367
Encoder Loss:  0.13560764  || Decoder Loss:  0.4389301 Validation Decoder Loss:  1.2100778
Encoder Loss:  0.14351456  || Decoder Loss:  0.4578763 Validation Decoder Loss:  1.2014084
Encoder Loss:  0.13924922  || Decoder Loss:  0.44744286 Validation Decoder Loss:  1.1026862
Encoder Loss:  0.13596492  || Decoder Loss:  0.4331545 Validation Decoder Loss:  1.1004404
Encoder Loss:  0.13370553  || Decoder Loss:  0.42415679 Validation Decoder Loss:  1.1711063
Encoder Loss:  0.13281728  || Decoder Loss:  0.42434606 Validation Decoder Loss:  1.1881425
Encoder Loss:  0.13271351  || Decoder Loss:  0.4200178 Validation Decoder Loss:  1.177594
Encoder Loss:  0.13127792  || Decoder Loss:  0.41099426 Validation Decoder Loss:  1.1468654
Encoder Loss:  0.12817861  || Decoder Loss:  0.40321583 Validation Decoder Loss:  1.1868771
Encoder Loss:  0.12914295  || Decoder Loss:  0.39204368 Validation Decoder Loss:  1.0765035
Encoder Loss:  0.124245144  || Decoder Loss:  0.37002358 Validation Decoder Loss:  1.1331844
Encoder Loss:  0.1270293  || Decoder Loss:  0.3744768 Validation Decoder Loss:  0.9530337
Encoder Loss:  0.118021704  || Decoder Loss:  0.32218128 Validation Decoder Loss:  1.1121836
Encoder Loss:  0.13048184  || Decoder Loss:  0.42176613 Validation Decoder Loss:  0.7168555
Encoder Loss:  0.12231507  || Decoder Loss:  0.37388477 Validation Decoder Loss:  0.9223495
Model: siamese_net_lr_0.09847337115831187 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9223495
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_53 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08301334  || Decoder Loss:  0.46758962 Validation Decoder Loss:  0.90392137
Encoder Loss:  0.06582893  || Decoder Loss:  0.39533454 Validation Decoder Loss:  0.8089794
Encoder Loss:  0.06276489  || Decoder Loss:  0.32778186 Validation Decoder Loss:  0.7187908
Encoder Loss:  0.060893413  || Decoder Loss:  0.2715355 Validation Decoder Loss:  0.6456289
Encoder Loss:  0.059349295  || Decoder Loss:  0.22819567 Validation Decoder Loss:  0.5911886
Encoder Loss:  0.05813052  || Decoder Loss:  0.19611393 Validation Decoder Loss:  0.55166554
Encoder Loss:  0.057141293  || Decoder Loss:  0.1723393 Validation Decoder Loss:  0.52235913
Encoder Loss:  0.05639459  || Decoder Loss:  0.15423477 Validation Decoder Loss:  0.49997672
Encoder Loss:  0.055796236  || Decoder Loss:  0.14006193 Validation Decoder Loss:  0.482411
Encoder Loss:  0.055274248  || Decoder Loss:  0.12871256 Validation Decoder Loss:  0.4681724
Encoder Loss:  0.054848738  || Decoder Loss:  0.1194163 Validation Decoder Loss:  0.45648313
Encoder Loss:  0.054428596  || Decoder Loss:  0.1116758 Validation Decoder Loss:  0.4466597
Encoder Loss:  0.054075763  || Decoder Loss:  0.10513857 Validation Decoder Loss:  0.43831664
Encoder Loss:  0.05380808  || Decoder Loss:  0.099549815 Validation Decoder Loss:  0.43113232
Encoder Loss:  0.053556778  || Decoder Loss:  0.09470171 Validation Decoder Loss:  0.424886
Encoder Loss:  0.0533623  || Decoder Loss:  0.09046855 Validation Decoder Loss:  0.41941476
Encoder Loss:  0.05314878  || Decoder Loss:  0.0867284 Validation Decoder Loss:  0.41460717
Encoder Loss:  0.052921295  || Decoder Loss:  0.08341803 Validation Decoder Loss:  0.4103573
Encoder Loss:  0.052627835  || Decoder Loss:  0.08045177 Validation Decoder Loss:  0.40656695
Encoder Loss:  0.052346405  || Decoder Loss:  0.077789865 Validation Decoder Loss:  0.4031722
Encoder Loss:  0.052116882  || Decoder Loss:  0.075384356 Validation Decoder Loss:  0.40009254
Encoder Loss:  0.05192663  || Decoder Loss:  0.07319607 Validation Decoder Loss:  0.39729577
Encoder Loss:  0.051704515  || Decoder Loss:  0.071198955 Validation Decoder Loss:  0.39475602
Encoder Loss:  0.051470503  || Decoder Loss:  0.0693652 Validation Decoder Loss:  0.39238924
Encoder Loss:  0.051484656  || Decoder Loss:  0.06767655 Validation Decoder Loss:  0.39025158
Encoder Loss:  0.051283892  || Decoder Loss:  0.06611863 Validation Decoder Loss:  0.38825667
Encoder Loss:  0.05130587  || Decoder Loss:  0.06467479 Validation Decoder Loss:  0.38644457
Encoder Loss:  0.051148426  || Decoder Loss:  0.06333305 Validation Decoder Loss:  0.38475132
Encoder Loss:  0.051141948  || Decoder Loss:  0.062083017 Validation Decoder Loss:  0.3832006
Encoder Loss:  0.05100436  || Decoder Loss:  0.060916666 Validation Decoder Loss:  0.3817422
Encoder Loss:  0.05101347  || Decoder Loss:  0.059822608 Validation Decoder Loss:  0.38039744
Encoder Loss:  0.05093622  || Decoder Loss:  0.058798246 Validation Decoder Loss:  0.37913778
Encoder Loss:  0.05093442  || Decoder Loss:  0.05783338 Validation Decoder Loss:  0.37796468
Encoder Loss:  0.05082101  || Decoder Loss:  0.056925453 Validation Decoder Loss:  0.37685996
Encoder Loss:  0.05079302  || Decoder Loss:  0.05606804 Validation Decoder Loss:  0.37582612
Encoder Loss:  0.050730996  || Decoder Loss:  0.055257153 Validation Decoder Loss:  0.37485558
Encoder Loss:  0.05066654  || Decoder Loss:  0.054489374 Validation Decoder Loss:  0.3739389
Encoder Loss:  0.05064517  || Decoder Loss:  0.053761043 Validation Decoder Loss:  0.37307638
Encoder Loss:  0.050617274  || Decoder Loss:  0.05306947 Validation Decoder Loss:  0.37226307
Encoder Loss:  0.050586667  || Decoder Loss:  0.0524113 Validation Decoder Loss:  0.37149367
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37149367
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_54 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07331614  || Decoder Loss:  0.47465843 Validation Decoder Loss:  0.9502188
Encoder Loss:  0.05339593  || Decoder Loss:  0.4117944 Validation Decoder Loss:  0.84843874
Encoder Loss:  0.052018404  || Decoder Loss:  0.34647217 Validation Decoder Loss:  0.74603575
Encoder Loss:  0.05199908  || Decoder Loss:  0.28891465 Validation Decoder Loss:  0.6615798
Encoder Loss:  0.051846374  || Decoder Loss:  0.24290699 Validation Decoder Loss:  0.59805095
Encoder Loss:  0.05178962  || Decoder Loss:  0.2082019 Validation Decoder Loss:  0.5518968
Encoder Loss:  0.051724933  || Decoder Loss:  0.18237127 Validation Decoder Loss:  0.5183487
Encoder Loss:  0.05171649  || Decoder Loss:  0.16288261 Validation Decoder Loss:  0.4935012
Encoder Loss:  0.05171619  || Decoder Loss:  0.14781787 Validation Decoder Loss:  0.47461647
Encoder Loss:  0.05171607  || Decoder Loss:  0.1358687 Validation Decoder Loss:  0.45990896
Encoder Loss:  0.051702365  || Decoder Loss:  0.12617351 Validation Decoder Loss:  0.44817957
Encoder Loss:  0.051684245  || Decoder Loss:  0.11815023 Validation Decoder Loss:  0.43862945
Encoder Loss:  0.05165448  || Decoder Loss:  0.1113999 Validation Decoder Loss:  0.4307049
Encoder Loss:  0.05165333  || Decoder Loss:  0.10564003 Validation Decoder Loss:  0.42402515
Encoder Loss:  0.05158881  || Decoder Loss:  0.10066578 Validation Decoder Loss:  0.41831058
Encoder Loss:  0.05153307  || Decoder Loss:  0.096323825 Validation Decoder Loss:  0.41337317
Encoder Loss:  0.05148569  || Decoder Loss:  0.09250032 Validation Decoder Loss:  0.4090681
Encoder Loss:  0.051421184  || Decoder Loss:  0.089106016 Validation Decoder Loss:  0.40527847
Encoder Loss:  0.051377796  || Decoder Loss:  0.08607125 Validation Decoder Loss:  0.40192246
Encoder Loss:  0.05131113  || Decoder Loss:  0.0833413 Validation Decoder Loss:  0.39892352
Encoder Loss:  0.051254824  || Decoder Loss:  0.08087115 Validation Decoder Loss:  0.3962291
Encoder Loss:  0.05120604  || Decoder Loss:  0.078624934 Validation Decoder Loss:  0.39379176
Encoder Loss:  0.051174264  || Decoder Loss:  0.07657299 Validation Decoder Loss:  0.39157534
Encoder Loss:  0.051150225  || Decoder Loss:  0.074690536 Validation Decoder Loss:  0.38955107
Encoder Loss:  0.05111248  || Decoder Loss:  0.072956875 Validation Decoder Loss:  0.38769162
Encoder Loss:  0.051092517  || Decoder Loss:  0.071354784 Validation Decoder Loss:  0.38597786
Encoder Loss:  0.051086236  || Decoder Loss:  0.069869325 Validation Decoder Loss:  0.38439393
Encoder Loss:  0.051063806  || Decoder Loss:  0.068487965 Validation Decoder Loss:  0.382922
Encoder Loss:  0.051043514  || Decoder Loss:  0.06719981 Validation Decoder Loss:  0.38155025
Encoder Loss:  0.051032357  || Decoder Loss:  0.06599546 Validation Decoder Loss:  0.3802706
Encoder Loss:  0.0510214  || Decoder Loss:  0.06486683 Validation Decoder Loss:  0.37907302
Encoder Loss:  0.05099828  || Decoder Loss:  0.06380671 Validation Decoder Loss:  0.37794727
Encoder Loss:  0.050977916  || Decoder Loss:  0.06280892 Validation Decoder Loss:  0.37688982
Encoder Loss:  0.05095085  || Decoder Loss:  0.06186792 Validation Decoder Loss:  0.37589574
Encoder Loss:  0.05091662  || Decoder Loss:  0.060978845 Validation Decoder Loss:  0.37495154
Encoder Loss:  0.050917033  || Decoder Loss:  0.060137376 Validation Decoder Loss:  0.37406188
Encoder Loss:  0.050906133  || Decoder Loss:  0.059339676 Validation Decoder Loss:  0.3732173
Encoder Loss:  0.050887093  || Decoder Loss:  0.058582336 Validation Decoder Loss:  0.37241593
Encoder Loss:  0.050871324  || Decoder Loss:  0.0578622 Validation Decoder Loss:  0.37165126
Encoder Loss:  0.050865576  || Decoder Loss:  0.057176556 Validation Decoder Loss:  0.37092116
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37092116
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_55 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.093598  || Decoder Loss:  0.39681697 Validation Decoder Loss:  0.81957585
Encoder Loss:  0.079921015  || Decoder Loss:  0.34852636 Validation Decoder Loss:  0.74535275
Encoder Loss:  0.07520123  || Decoder Loss:  0.30244324 Validation Decoder Loss:  0.6850152
Encoder Loss:  0.073753044  || Decoder Loss:  0.2656955 Validation Decoder Loss:  0.638484
Encoder Loss:  0.07172016  || Decoder Loss:  0.23695791 Validation Decoder Loss:  0.60227627
Encoder Loss:  0.070511416  || Decoder Loss:  0.21406554 Validation Decoder Loss:  0.5733818
Encoder Loss:  0.06952238  || Decoder Loss:  0.19546986 Validation Decoder Loss:  0.54983425
Encoder Loss:  0.068520695  || Decoder Loss:  0.1800692 Validation Decoder Loss:  0.53023213
Encoder Loss:  0.06727666  || Decoder Loss:  0.16708383 Validation Decoder Loss:  0.5136277
Encoder Loss:  0.06723909  || Decoder Loss:  0.15598209 Validation Decoder Loss:  0.49937308
Encoder Loss:  0.06538582  || Decoder Loss:  0.1463606 Validation Decoder Loss:  0.48695362
Encoder Loss:  0.06500751  || Decoder Loss:  0.13793921 Validation Decoder Loss:  0.47602442
Encoder Loss:  0.06477678  || Decoder Loss:  0.13049345 Validation Decoder Loss:  0.46630734
Encoder Loss:  0.06407919  || Decoder Loss:  0.123851396 Validation Decoder Loss:  0.45760354
Encoder Loss:  0.06416113  || Decoder Loss:  0.11787932 Validation Decoder Loss:  0.4497612
Encoder Loss:  0.06442473  || Decoder Loss:  0.11247764 Validation Decoder Loss:  0.44262573
Encoder Loss:  0.062233698  || Decoder Loss:  0.10756946 Validation Decoder Loss:  0.43610775
Encoder Loss:  0.06260691  || Decoder Loss:  0.1030931 Validation Decoder Loss:  0.4301278
Encoder Loss:  0.062228456  || Decoder Loss:  0.09899041 Validation Decoder Loss:  0.4246211
Encoder Loss:  0.061804544  || Decoder Loss:  0.09522171 Validation Decoder Loss:  0.41953304
Encoder Loss:  0.06139909  || Decoder Loss:  0.0917515 Validation Decoder Loss:  0.41482142
Encoder Loss:  0.06106928  || Decoder Loss:  0.088551894 Validation Decoder Loss:  0.41045707
Encoder Loss:  0.060565796  || Decoder Loss:  0.08560004 Validation Decoder Loss:  0.40640616
Encoder Loss:  0.060194373  || Decoder Loss:  0.082873754 Validation Decoder Loss:  0.40263748
Encoder Loss:  0.060093418  || Decoder Loss:  0.08035788 Validation Decoder Loss:  0.3991537
Encoder Loss:  0.05965877  || Decoder Loss:  0.07804447 Validation Decoder Loss:  0.39594087
Encoder Loss:  0.05903401  || Decoder Loss:  0.07591269 Validation Decoder Loss:  0.39295354
Encoder Loss:  0.05942012  || Decoder Loss:  0.07395513 Validation Decoder Loss:  0.3902164
Encoder Loss:  0.058559418  || Decoder Loss:  0.07216709 Validation Decoder Loss:  0.38769734
Encoder Loss:  0.058296047  || Decoder Loss:  0.07052646 Validation Decoder Loss:  0.3853715
Encoder Loss:  0.05878256  || Decoder Loss:  0.069031455 Validation Decoder Loss:  0.38326555
Encoder Loss:  0.058218732  || Decoder Loss:  0.067676716 Validation Decoder Loss:  0.38134405
Encoder Loss:  0.057795297  || Decoder Loss:  0.06644201 Validation Decoder Loss:  0.37958163
Encoder Loss:  0.057292417  || Decoder Loss:  0.06531407 Validation Decoder Loss:  0.37796772
Encoder Loss:  0.05748023  || Decoder Loss:  0.06428575 Validation Decoder Loss:  0.37649894
Encoder Loss:  0.05726813  || Decoder Loss:  0.0633507 Validation Decoder Loss:  0.37516448
Encoder Loss:  0.056746945  || Decoder Loss:  0.062498905 Validation Decoder Loss:  0.37395546
Encoder Loss:  0.056583967  || Decoder Loss:  0.06171985 Validation Decoder Loss:  0.37285158
Encoder Loss:  0.05644517  || Decoder Loss:  0.06100464 Validation Decoder Loss:  0.37184373
Encoder Loss:  0.05613859  || Decoder Loss:  0.060342547 Validation Decoder Loss:  0.37091637
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37091637
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_56 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.48389253  || Decoder Loss:  0.89787847 Validation Decoder Loss:  1.6317544
Encoder Loss:  0.4824828  || Decoder Loss:  0.9094595 Validation Decoder Loss:  1.6243572
Encoder Loss:  0.49893013  || Decoder Loss:  0.8994495 Validation Decoder Loss:  1.6117682
Encoder Loss:  0.4963856  || Decoder Loss:  0.8843141 Validation Decoder Loss:  1.590151
Encoder Loss:  0.49239877  || Decoder Loss:  0.8600034 Validation Decoder Loss:  1.5495899
Encoder Loss:  0.48525947  || Decoder Loss:  0.81325567 Validation Decoder Loss:  1.4516306
Encoder Loss:  0.46499306  || Decoder Loss:  0.6620859 Validation Decoder Loss:  0.96132374
Encoder Loss:  0.40389085  || Decoder Loss:  0.17789915 Validation Decoder Loss:  0.39948598
Encoder Loss:  0.38119408  || Decoder Loss:  0.06371085 Validation Decoder Loss:  0.40584624
Encoder Loss:  0.31357425  || Decoder Loss:  0.14571643 Validation Decoder Loss:  1.6345639
Encoder Loss:  0.21991388  || Decoder Loss:  0.51644206 Validation Decoder Loss:  1.4389275
Encoder Loss:  0.14595795  || Decoder Loss:  0.44936675 Validation Decoder Loss:  1.3349679
Encoder Loss:  0.1401117  || Decoder Loss:  0.44071212 Validation Decoder Loss:  1.274649
Encoder Loss:  0.13575354  || Decoder Loss:  0.43314222 Validation Decoder Loss:  1.217384
Encoder Loss:  0.1339652  || Decoder Loss:  0.42313436 Validation Decoder Loss:  1.1681405
Encoder Loss:  0.13040255  || Decoder Loss:  0.41745612 Validation Decoder Loss:  1.2086344
Encoder Loss:  0.13111365  || Decoder Loss:  0.41797474 Validation Decoder Loss:  1.1729025
Encoder Loss:  0.13053736  || Decoder Loss:  0.41756305 Validation Decoder Loss:  1.1688282
Encoder Loss:  0.12902452  || Decoder Loss:  0.4106748 Validation Decoder Loss:  1.163265
Encoder Loss:  0.12850265  || Decoder Loss:  0.41006222 Validation Decoder Loss:  1.1858876
Encoder Loss:  0.12706089  || Decoder Loss:  0.40627742 Validation Decoder Loss:  1.2513139
Encoder Loss:  0.1319774  || Decoder Loss:  0.41605133 Validation Decoder Loss:  1.1649365
Encoder Loss:  0.12640525  || Decoder Loss:  0.4022887 Validation Decoder Loss:  1.2002106
Encoder Loss:  0.12488649  || Decoder Loss:  0.3930394 Validation Decoder Loss:  1.2292719
Encoder Loss:  0.12221129  || Decoder Loss:  0.37454063 Validation Decoder Loss:  1.1795632
Encoder Loss:  0.109984264  || Decoder Loss:  0.27541578 Validation Decoder Loss:  0.5581048
Encoder Loss:  0.088895634  || Decoder Loss:  0.08790055 Validation Decoder Loss:  0.4844082
Encoder Loss:  0.0824356  || Decoder Loss:  0.060469054 Validation Decoder Loss:  0.40467966
Encoder Loss:  0.08032774  || Decoder Loss:  0.03937892 Validation Decoder Loss:  0.4287008
Encoder Loss:  0.08657357  || Decoder Loss:  0.043575156 Validation Decoder Loss:  0.42246664
Encoder Loss:  0.07932559  || Decoder Loss:  0.039043453 Validation Decoder Loss:  0.38192463
Encoder Loss:  0.07858162  || Decoder Loss:  0.035510648 Validation Decoder Loss:  0.43423945
Encoder Loss:  0.0811486  || Decoder Loss:  0.037880413 Validation Decoder Loss:  0.37697577
Encoder Loss:  0.07298276  || Decoder Loss:  0.0319338 Validation Decoder Loss:  0.39575022
Encoder Loss:  0.076949246  || Decoder Loss:  0.03349987 Validation Decoder Loss:  0.39213032
Encoder Loss:  0.07354789  || Decoder Loss:  0.035200678 Validation Decoder Loss:  0.37830597
Encoder Loss:  0.07174876  || Decoder Loss:  0.033352774 Validation Decoder Loss:  0.39051872
Encoder Loss:  0.070485  || Decoder Loss:  0.03301156 Validation Decoder Loss:  0.37194186
Encoder Loss:  0.06906709  || Decoder Loss:  0.033015672 Validation Decoder Loss:  0.37069327
Encoder Loss:  0.06057845  || Decoder Loss:  0.032640707 Validation Decoder Loss:  0.3863303
Model: siamese_net_lr_0.04462183537650789 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3863303
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_57 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45709905  || Decoder Loss:  0.88915753 Validation Decoder Loss:  1.6393893
Encoder Loss:  0.45845437  || Decoder Loss:  0.9086724 Validation Decoder Loss:  1.6371722
Encoder Loss:  0.45413032  || Decoder Loss:  0.9050827 Validation Decoder Loss:  1.6340942
Encoder Loss:  0.44704014  || Decoder Loss:  0.9002486 Validation Decoder Loss:  1.6298573
Encoder Loss:  0.43510854  || Decoder Loss:  0.89343584 Validation Decoder Loss:  1.623287
Encoder Loss:  0.40927303  || Decoder Loss:  0.88102156 Validation Decoder Loss:  1.606097
Encoder Loss:  0.24826427  || Decoder Loss:  0.64255023 Validation Decoder Loss:  0.70547247
Encoder Loss:  0.11439222  || Decoder Loss:  0.50819474 Validation Decoder Loss:  0.8478059
Encoder Loss:  0.10773544  || Decoder Loss:  0.50568163 Validation Decoder Loss:  0.8581853
Encoder Loss:  0.106393605  || Decoder Loss:  0.50553995 Validation Decoder Loss:  0.84953165
Encoder Loss:  0.10619506  || Decoder Loss:  0.50602263 Validation Decoder Loss:  0.8692142
Encoder Loss:  0.10326492  || Decoder Loss:  0.5071253 Validation Decoder Loss:  0.8565314
Encoder Loss:  0.10335994  || Decoder Loss:  0.507262 Validation Decoder Loss:  0.8742525
Encoder Loss:  0.103101775  || Decoder Loss:  0.50113946 Validation Decoder Loss:  0.7998065
Encoder Loss:  0.1052321  || Decoder Loss:  0.500601 Validation Decoder Loss:  0.83888066
Encoder Loss:  0.10220933  || Decoder Loss:  0.5049457 Validation Decoder Loss:  0.8804034
Encoder Loss:  0.10006764  || Decoder Loss:  0.5069174 Validation Decoder Loss:  0.8711251
Encoder Loss:  0.09957125  || Decoder Loss:  0.5051712 Validation Decoder Loss:  0.86595076
Encoder Loss:  0.0986164  || Decoder Loss:  0.5068202 Validation Decoder Loss:  0.93593776
Encoder Loss:  0.09597962  || Decoder Loss:  0.51437 Validation Decoder Loss:  0.9040729
Encoder Loss:  0.09521245  || Decoder Loss:  0.5122407 Validation Decoder Loss:  0.92411697
Encoder Loss:  0.095281556  || Decoder Loss:  0.5144199 Validation Decoder Loss:  0.8835549
Encoder Loss:  0.09522296  || Decoder Loss:  0.5072063 Validation Decoder Loss:  0.9268199
Encoder Loss:  0.0924123  || Decoder Loss:  0.5100792 Validation Decoder Loss:  0.90523404
Encoder Loss:  0.09240361  || Decoder Loss:  0.5046412 Validation Decoder Loss:  0.84225696
Encoder Loss:  0.09176227  || Decoder Loss:  0.49563915 Validation Decoder Loss:  0.8085221
Encoder Loss:  0.091923915  || Decoder Loss:  0.49647042 Validation Decoder Loss:  0.86681163
Encoder Loss:  0.08974018  || Decoder Loss:  0.48941672 Validation Decoder Loss:  0.830517
Encoder Loss:  0.08894228  || Decoder Loss:  0.49089763 Validation Decoder Loss:  0.8891928
Encoder Loss:  0.08877806  || Decoder Loss:  0.47092697 Validation Decoder Loss:  0.9514487
Encoder Loss:  0.07723908  || Decoder Loss:  0.4739829 Validation Decoder Loss:  0.843531
Encoder Loss:  0.09749911  || Decoder Loss:  0.47482407 Validation Decoder Loss:  0.7838094
Encoder Loss:  0.08456001  || Decoder Loss:  0.34821755 Validation Decoder Loss:  0.5940013
Encoder Loss:  0.07533701  || Decoder Loss:  0.12666354 Validation Decoder Loss:  0.3920943
Encoder Loss:  0.0658999  || Decoder Loss:  0.09906208 Validation Decoder Loss:  0.48277187
Encoder Loss:  0.07092711  || Decoder Loss:  0.107185 Validation Decoder Loss:  0.35948026
Encoder Loss:  0.059353817  || Decoder Loss:  0.043425374 Validation Decoder Loss:  0.34744626
Encoder Loss:  0.06932929  || Decoder Loss:  0.033388104 Validation Decoder Loss:  0.35235912
Encoder Loss:  0.06566497  || Decoder Loss:  0.032569576 Validation Decoder Loss:  0.35527956
Encoder Loss:  0.06967177  || Decoder Loss:  0.03283824 Validation Decoder Loss:  0.35236484
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3523648
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_58 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5025612  || Decoder Loss:  0.9004552 Validation Decoder Loss:  1.6359698
Encoder Loss:  0.5110474  || Decoder Loss:  0.9151883 Validation Decoder Loss:  1.633034
Encoder Loss:  0.5102159  || Decoder Loss:  0.9106917 Validation Decoder Loss:  1.6286366
Encoder Loss:  0.5091014  || Decoder Loss:  0.90464246 Validation Decoder Loss:  1.6222885
Encoder Loss:  0.50763685  || Decoder Loss:  0.8966544 Validation Decoder Loss:  1.6131923
Encoder Loss:  0.5057067  || Decoder Loss:  0.88602525 Validation Decoder Loss:  1.5999427
Encoder Loss:  0.5030931  || Decoder Loss:  0.871379 Validation Decoder Loss:  1.5797569
Encoder Loss:  0.4993391  || Decoder Loss:  0.8497088 Validation Decoder Loss:  1.5461465
Encoder Loss:  0.4932756  || Decoder Loss:  0.813041 Validation Decoder Loss:  1.4796333
Encoder Loss:  0.4807035  || Decoder Loss:  0.73183775 Validation Decoder Loss:  1.291324
Encoder Loss:  0.441185  || Decoder Loss:  0.4609692 Validation Decoder Loss:  0.6372429
Encoder Loss:  0.3553713  || Decoder Loss:  0.11026738 Validation Decoder Loss:  0.4117775
Encoder Loss:  0.36413667  || Decoder Loss:  0.06191144 Validation Decoder Loss:  0.40101802
Encoder Loss:  0.28864032  || Decoder Loss:  0.060041666 Validation Decoder Loss:  0.40389243
Encoder Loss:  0.3659074  || Decoder Loss:  0.06214211 Validation Decoder Loss:  0.41469967
Encoder Loss:  0.3145647  || Decoder Loss:  0.09614971 Validation Decoder Loss:  1.3912047
Encoder Loss:  0.18639319  || Decoder Loss:  0.5071011 Validation Decoder Loss:  1.1807162
Encoder Loss:  0.13941681  || Decoder Loss:  0.43229353 Validation Decoder Loss:  1.2831697
Encoder Loss:  0.14391774  || Decoder Loss:  0.44441074 Validation Decoder Loss:  1.2230346
Encoder Loss:  0.13946758  || Decoder Loss:  0.4267244 Validation Decoder Loss:  1.2350509
Encoder Loss:  0.13853483  || Decoder Loss:  0.43181232 Validation Decoder Loss:  1.238694
Encoder Loss:  0.13766734  || Decoder Loss:  0.42292827 Validation Decoder Loss:  1.2695208
Encoder Loss:  0.1449153  || Decoder Loss:  0.44361562 Validation Decoder Loss:  1.2705796
Encoder Loss:  0.1404826  || Decoder Loss:  0.43134862 Validation Decoder Loss:  1.1700882
Encoder Loss:  0.13776709  || Decoder Loss:  0.42627144 Validation Decoder Loss:  1.1517868
Encoder Loss:  0.13443178  || Decoder Loss:  0.41876805 Validation Decoder Loss:  1.2095888
Encoder Loss:  0.13614577  || Decoder Loss:  0.42155543 Validation Decoder Loss:  1.1604968
Encoder Loss:  0.13299954  || Decoder Loss:  0.41856617 Validation Decoder Loss:  1.2377216
Encoder Loss:  0.13553737  || Decoder Loss:  0.42292225 Validation Decoder Loss:  1.1852347
Encoder Loss:  0.13228706  || Decoder Loss:  0.4174258 Validation Decoder Loss:  1.2541895
Encoder Loss:  0.13437803  || Decoder Loss:  0.41855636 Validation Decoder Loss:  1.190713
Encoder Loss:  0.13129792  || Decoder Loss:  0.41740298 Validation Decoder Loss:  1.2891486
Encoder Loss:  0.13356677  || Decoder Loss:  0.41993323 Validation Decoder Loss:  1.2183132
Encoder Loss:  0.13012855  || Decoder Loss:  0.41740268 Validation Decoder Loss:  1.2984772
Encoder Loss:  0.13016374  || Decoder Loss:  0.41116005 Validation Decoder Loss:  1.3151755
Encoder Loss:  0.1275168  || Decoder Loss:  0.41047168 Validation Decoder Loss:  1.324333
Encoder Loss:  0.12769006  || Decoder Loss:  0.41551507 Validation Decoder Loss:  1.3767992
Encoder Loss:  0.12714988  || Decoder Loss:  0.4019894 Validation Decoder Loss:  1.3986548
Encoder Loss:  0.124392346  || Decoder Loss:  0.41017753 Validation Decoder Loss:  1.3458502
Encoder Loss:  0.12146156  || Decoder Loss:  0.39610168 Validation Decoder Loss:  1.274168
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.274168
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 307, 10, 20, 1)    331       
_________________________________________________________________
reshape_59 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 331
Trainable params: 331
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.76403964  || Decoder Loss:  0.94584054 Validation Decoder Loss:  1.6543745
Encoder Loss:  0.77997863  || Decoder Loss:  0.9640801 Validation Decoder Loss:  1.6559284
Encoder Loss:  0.77881354  || Decoder Loss:  0.9623689 Validation Decoder Loss:  1.6647539
Encoder Loss:  0.23386183  || Decoder Loss:  0.116595946 Validation Decoder Loss:  0.34796253
Encoder Loss:  0.18132578  || Decoder Loss:  0.035215326 Validation Decoder Loss:  0.3475027
Encoder Loss:  0.18128763  || Decoder Loss:  0.03537081 Validation Decoder Loss:  0.3473422
Encoder Loss:  0.18122469  || Decoder Loss:  0.035547126 Validation Decoder Loss:  0.3471912
Encoder Loss:  0.18113138  || Decoder Loss:  0.035757102 Validation Decoder Loss:  0.34702983
Encoder Loss:  0.18099  || Decoder Loss:  0.036009695 Validation Decoder Loss:  0.34685734
Encoder Loss:  0.18076599  || Decoder Loss:  0.036318064 Validation Decoder Loss:  0.34667468
Encoder Loss:  0.1803853  || Decoder Loss:  0.036704324 Validation Decoder Loss:  0.34648377
Encoder Loss:  0.17965105  || Decoder Loss:  0.03721048 Validation Decoder Loss:  0.3462891
Encoder Loss:  0.17747545  || Decoder Loss:  0.03793183 Validation Decoder Loss:  0.3461054
Encoder Loss:  0.16409513  || Decoder Loss:  0.039087463 Validation Decoder Loss:  0.34607893
Encoder Loss:  0.1690235  || Decoder Loss:  0.042562667 Validation Decoder Loss:  0.34996647
Encoder Loss:  0.30066812  || Decoder Loss:  0.37774885 Validation Decoder Loss:  1.0773244
Encoder Loss:  0.31661364  || Decoder Loss:  0.45140567 Validation Decoder Loss:  1.1430829
Encoder Loss:  0.28725383  || Decoder Loss:  0.40887988 Validation Decoder Loss:  1.16401
Encoder Loss:  0.21269947  || Decoder Loss:  0.29264486 Validation Decoder Loss:  0.40836596
Encoder Loss:  0.07854776  || Decoder Loss:  0.08745279 Validation Decoder Loss:  0.3873906
Encoder Loss:  0.052962095  || Decoder Loss:  0.048212174 Validation Decoder Loss:  0.36443147
Encoder Loss:  0.048778698  || Decoder Loss:  0.043015305 Validation Decoder Loss:  0.3536119
Encoder Loss:  0.044784937  || Decoder Loss:  0.039248675 Validation Decoder Loss:  0.3589215
Encoder Loss:  0.045600057  || Decoder Loss:  0.039858386 Validation Decoder Loss:  0.34873223
Encoder Loss:  0.044299256  || Decoder Loss:  0.03782221 Validation Decoder Loss:  0.3744711
Encoder Loss:  0.047015503  || Decoder Loss:  0.043232955 Validation Decoder Loss:  0.3600189
Encoder Loss:  0.046897057  || Decoder Loss:  0.04050177 Validation Decoder Loss:  0.36193502
Encoder Loss:  0.046417423  || Decoder Loss:  0.041738704 Validation Decoder Loss:  0.3561563
Encoder Loss:  0.04734792  || Decoder Loss:  0.0396329 Validation Decoder Loss:  0.3523422
Encoder Loss:  0.044890713  || Decoder Loss:  0.03710571 Validation Decoder Loss:  0.350848
Encoder Loss:  0.043127637  || Decoder Loss:  0.03603785 Validation Decoder Loss:  0.36204898
Encoder Loss:  0.04632641  || Decoder Loss:  0.041070413 Validation Decoder Loss:  0.35130754
Encoder Loss:  0.04165094  || Decoder Loss:  0.035524655 Validation Decoder Loss:  0.35168508
Encoder Loss:  0.044739027  || Decoder Loss:  0.037288286 Validation Decoder Loss:  0.3475807
Encoder Loss:  0.048553973  || Decoder Loss:  0.037329566 Validation Decoder Loss:  0.34768242
Encoder Loss:  0.044960808  || Decoder Loss:  0.037547957 Validation Decoder Loss:  0.35808757
Encoder Loss:  0.0470631  || Decoder Loss:  0.039813302 Validation Decoder Loss:  0.35566473
Encoder Loss:  0.04403369  || Decoder Loss:  0.038192824 Validation Decoder Loss:  0.35981277
Encoder Loss:  0.046981186  || Decoder Loss:  0.040147096 Validation Decoder Loss:  0.35878897
Encoder Loss:  0.04499253  || Decoder Loss:  0.038166944 Validation Decoder Loss:  0.3567445
Model: siamese_net_lr_0.0477828639087389 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35674453
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 614, 5, 20, 1)     363       
_________________________________________________________________
reshape_60 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 363
Trainable params: 363
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7990755  || Decoder Loss:  0.9437564 Validation Decoder Loss:  1.65963
Encoder Loss:  0.808727  || Decoder Loss:  0.9632511 Validation Decoder Loss:  1.6595802
Encoder Loss:  0.814142  || Decoder Loss:  0.9630007 Validation Decoder Loss:  1.6594561
Encoder Loss:  0.81439996  || Decoder Loss:  0.9626468 Validation Decoder Loss:  1.659239
Encoder Loss:  0.81391585  || Decoder Loss:  0.9621839 Validation Decoder Loss:  1.6589055
Encoder Loss:  0.81328225  || Decoder Loss:  0.96159554 Validation Decoder Loss:  1.6584073
Encoder Loss:  0.8124702  || Decoder Loss:  0.9608501 Validation Decoder Loss:  1.6576768
Encoder Loss:  0.8114212  || Decoder Loss:  0.9599009 Validation Decoder Loss:  1.6566142
Encoder Loss:  0.81004053  || Decoder Loss:  0.95867753 Validation Decoder Loss:  1.6550679
Encoder Loss:  0.80816734  || Decoder Loss:  0.9570668 Validation Decoder Loss:  1.6527896
Encoder Loss:  0.8055047  || Decoder Loss:  0.9548706 Validation Decoder Loss:  1.6493288
Encoder Loss:  0.80142814  || Decoder Loss:  0.95169145 Validation Decoder Loss:  1.6437261
Encoder Loss:  0.79432404  || Decoder Loss:  0.9465357 Validation Decoder Loss:  1.633306
Encoder Loss:  0.77650183  || Decoder Loss:  0.9357554 Validation Decoder Loss:  1.6057551
Encoder Loss:  0.714026  || Decoder Loss:  0.8849144 Validation Decoder Loss:  1.2491395
Encoder Loss:  0.36572263  || Decoder Loss:  0.4751414 Validation Decoder Loss:  0.75144446
Encoder Loss:  0.29471147  || Decoder Loss:  0.3827833 Validation Decoder Loss:  0.6820082
Encoder Loss:  0.25068313  || Decoder Loss:  0.32491094 Validation Decoder Loss:  0.5181546
Encoder Loss:  0.10914853  || Decoder Loss:  0.12705275 Validation Decoder Loss:  0.40103346
Encoder Loss:  0.0883753  || Decoder Loss:  0.09841769 Validation Decoder Loss:  0.35988152
Encoder Loss:  0.050012313  || Decoder Loss:  0.045176968 Validation Decoder Loss:  0.37765318
Encoder Loss:  0.045337796  || Decoder Loss:  0.039069697 Validation Decoder Loss:  0.35337448
Encoder Loss:  0.043788165  || Decoder Loss:  0.037496127 Validation Decoder Loss:  0.34821522
Encoder Loss:  0.043145876  || Decoder Loss:  0.03692172 Validation Decoder Loss:  0.35338798
Encoder Loss:  0.042555645  || Decoder Loss:  0.036613412 Validation Decoder Loss:  0.35819894
Encoder Loss:  0.04248604  || Decoder Loss:  0.03677693 Validation Decoder Loss:  0.3583905
Encoder Loss:  0.042679008  || Decoder Loss:  0.03753494 Validation Decoder Loss:  0.35806823
Encoder Loss:  0.042548873  || Decoder Loss:  0.037621167 Validation Decoder Loss:  0.35489035
Encoder Loss:  0.04225652  || Decoder Loss:  0.03694673 Validation Decoder Loss:  0.34691155
Encoder Loss:  0.039835315  || Decoder Loss:  0.034456417 Validation Decoder Loss:  0.3441947
Encoder Loss:  0.04124167  || Decoder Loss:  0.034952473 Validation Decoder Loss:  0.35125947
Encoder Loss:  0.04350087  || Decoder Loss:  0.039024517 Validation Decoder Loss:  0.35150588
Encoder Loss:  0.04286997  || Decoder Loss:  0.038612083 Validation Decoder Loss:  0.3440842
Encoder Loss:  0.040858153  || Decoder Loss:  0.03428704 Validation Decoder Loss:  0.36167568
Encoder Loss:  0.044546265  || Decoder Loss:  0.039649233 Validation Decoder Loss:  0.35845262
Encoder Loss:  0.042973462  || Decoder Loss:  0.03758211 Validation Decoder Loss:  0.3457219
Encoder Loss:  0.041137666  || Decoder Loss:  0.036015525 Validation Decoder Loss:  0.35048336
Encoder Loss:  0.041955486  || Decoder Loss:  0.037499636 Validation Decoder Loss:  0.3527956
Encoder Loss:  0.042652756  || Decoder Loss:  0.038138077 Validation Decoder Loss:  0.35810146
Encoder Loss:  0.043647215  || Decoder Loss:  0.039206892 Validation Decoder Loss:  0.3488019
Model: siamese_net_lr_0.06668667805888844 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3488019
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 614, 5, 20, 1)     111       
_________________________________________________________________
reshape_61 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7941446  || Decoder Loss:  0.9439923 Validation Decoder Loss:  1.6544986
Encoder Loss:  0.8118998  || Decoder Loss:  0.9657531 Validation Decoder Loss:  1.6545807
Encoder Loss:  0.8118853  || Decoder Loss:  0.9657402 Validation Decoder Loss:  1.6546912
Encoder Loss:  0.81186163  || Decoder Loss:  0.9657171 Validation Decoder Loss:  1.6548264
Encoder Loss:  0.8118326  || Decoder Loss:  0.96568894 Validation Decoder Loss:  1.654986
Encoder Loss:  0.81179774  || Decoder Loss:  0.965656 Validation Decoder Loss:  1.6551706
Encoder Loss:  0.8117564  || Decoder Loss:  0.9656183 Validation Decoder Loss:  1.6553814
Encoder Loss:  0.8117074  || Decoder Loss:  0.9655756 Validation Decoder Loss:  1.6556201
Encoder Loss:  0.81164813  || Decoder Loss:  0.9655282 Validation Decoder Loss:  1.6558886
Encoder Loss:  0.8115739  || Decoder Loss:  0.9654763 Validation Decoder Loss:  1.6561887
Encoder Loss:  0.81147265  || Decoder Loss:  0.96542174 Validation Decoder Loss:  1.6565213
Encoder Loss:  0.811312  || Decoder Loss:  0.96536696 Validation Decoder Loss:  1.6568849
Encoder Loss:  0.810997  || Decoder Loss:  0.96531844 Validation Decoder Loss:  1.6572733
Encoder Loss:  0.8102191  || Decoder Loss:  0.96528417 Validation Decoder Loss:  1.6576724
Encoder Loss:  0.8077481  || Decoder Loss:  0.9652588 Validation Decoder Loss:  1.6580825
Encoder Loss:  0.78852814  || Decoder Loss:  0.9634982 Validation Decoder Loss:  1.626623
Encoder Loss:  0.29123345  || Decoder Loss:  0.35173938 Validation Decoder Loss:  0.4432287
Encoder Loss:  0.20881623  || Decoder Loss:  0.27082357 Validation Decoder Loss:  0.4250291
Encoder Loss:  0.06838779  || Decoder Loss:  0.07119001 Validation Decoder Loss:  0.3659705
Encoder Loss:  0.04485881  || Decoder Loss:  0.037750058 Validation Decoder Loss:  0.35099378
Encoder Loss:  0.041837312  || Decoder Loss:  0.03503858 Validation Decoder Loss:  0.35340905
Encoder Loss:  0.04256839  || Decoder Loss:  0.036017366 Validation Decoder Loss:  0.3506502
Encoder Loss:  0.043054037  || Decoder Loss:  0.035426453 Validation Decoder Loss:  0.3520192
Encoder Loss:  0.04427469  || Decoder Loss:  0.037369918 Validation Decoder Loss:  0.35266733
Encoder Loss:  0.04191548  || Decoder Loss:  0.035444442 Validation Decoder Loss:  0.35332263
Encoder Loss:  0.04460418  || Decoder Loss:  0.036870424 Validation Decoder Loss:  0.3497578
Encoder Loss:  0.047889844  || Decoder Loss:  0.036746208 Validation Decoder Loss:  0.3573395
Encoder Loss:  0.04467518  || Decoder Loss:  0.03672838 Validation Decoder Loss:  0.35199797
Encoder Loss:  0.04506482  || Decoder Loss:  0.037917465 Validation Decoder Loss:  0.35326076
Encoder Loss:  0.043404084  || Decoder Loss:  0.0373246 Validation Decoder Loss:  0.3539694
Encoder Loss:  0.043302786  || Decoder Loss:  0.03729331 Validation Decoder Loss:  0.35453033
Encoder Loss:  0.042835712  || Decoder Loss:  0.03724789 Validation Decoder Loss:  0.353333
Encoder Loss:  0.043739103  || Decoder Loss:  0.036956854 Validation Decoder Loss:  0.3534601
Encoder Loss:  0.043926455  || Decoder Loss:  0.03701277 Validation Decoder Loss:  0.35196316
Encoder Loss:  0.042147025  || Decoder Loss:  0.035861775 Validation Decoder Loss:  0.35398194
Encoder Loss:  0.044096135  || Decoder Loss:  0.03730451 Validation Decoder Loss:  0.35421294
Encoder Loss:  0.047088925  || Decoder Loss:  0.0360353 Validation Decoder Loss:  0.35781512
Encoder Loss:  0.046214905  || Decoder Loss:  0.04025873 Validation Decoder Loss:  0.35439247
Encoder Loss:  0.044438392  || Decoder Loss:  0.03697844 Validation Decoder Loss:  0.3504898
Encoder Loss:  0.04597313  || Decoder Loss:  0.03610688 Validation Decoder Loss:  0.3566177
Model: siamese_net_lr_0.06371553052501744 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3566177
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 614, 5, 20, 1)     552       
_________________________________________________________________
reshape_62 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 552
Trainable params: 552
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19968632  || Decoder Loss:  0.14650899 Validation Decoder Loss:  1.5938698
Encoder Loss:  0.43065163  || Decoder Loss:  0.52653223 Validation Decoder Loss:  1.2427075
Encoder Loss:  0.3522507  || Decoder Loss:  0.44072968 Validation Decoder Loss:  0.63783735
Encoder Loss:  0.3284986  || Decoder Loss:  0.4114849 Validation Decoder Loss:  0.6866846
Encoder Loss:  0.34902886  || Decoder Loss:  0.43755215 Validation Decoder Loss:  1.13028
Encoder Loss:  0.31551397  || Decoder Loss:  0.3936341 Validation Decoder Loss:  1.2270224
Encoder Loss:  0.384313  || Decoder Loss:  0.48404682 Validation Decoder Loss:  1.247533
Encoder Loss:  0.38733456  || Decoder Loss:  0.4880559 Validation Decoder Loss:  1.2458183
Encoder Loss:  0.38693985  || Decoder Loss:  0.48748043 Validation Decoder Loss:  1.2658395
Encoder Loss:  0.387453  || Decoder Loss:  0.4878635 Validation Decoder Loss:  1.2351853
Encoder Loss:  0.3863567  || Decoder Loss:  0.48559242 Validation Decoder Loss:  1.2115337
Encoder Loss:  0.38463247  || Decoder Loss:  0.4841114 Validation Decoder Loss:  1.2186704
Encoder Loss:  0.38398698  || Decoder Loss:  0.48248395 Validation Decoder Loss:  1.2216637
Encoder Loss:  0.37997895  || Decoder Loss:  0.47865075 Validation Decoder Loss:  1.2184407
Encoder Loss:  0.33522773  || Decoder Loss:  0.41978687 Validation Decoder Loss:  0.4005928
Encoder Loss:  0.24526492  || Decoder Loss:  0.3032505 Validation Decoder Loss:  1.132987
Encoder Loss:  0.27076092  || Decoder Loss:  0.335251 Validation Decoder Loss:  1.1798434
Encoder Loss:  0.33792165  || Decoder Loss:  0.4232603 Validation Decoder Loss:  0.5241301
Encoder Loss:  0.36580142  || Decoder Loss:  0.45923018 Validation Decoder Loss:  0.7531492
Encoder Loss:  0.3811047  || Decoder Loss:  0.47754896 Validation Decoder Loss:  0.6957664
Encoder Loss:  0.37552932  || Decoder Loss:  0.47235337 Validation Decoder Loss:  0.7106494
Encoder Loss:  0.3635405  || Decoder Loss:  0.45734212 Validation Decoder Loss:  0.65496147
Encoder Loss:  0.16248348  || Decoder Loss:  0.19559722 Validation Decoder Loss:  0.5786984
Encoder Loss:  0.101498105  || Decoder Loss:  0.116035804 Validation Decoder Loss:  0.4546447
Encoder Loss:  0.075405076  || Decoder Loss:  0.080542296 Validation Decoder Loss:  0.4985379
Encoder Loss:  0.04714065  || Decoder Loss:  0.044586714 Validation Decoder Loss:  0.32913402
Encoder Loss:  0.041192304  || Decoder Loss:  0.036366 Validation Decoder Loss:  0.33215135
Encoder Loss:  0.03942915  || Decoder Loss:  0.035181824 Validation Decoder Loss:  0.35304788
Encoder Loss:  0.03890433  || Decoder Loss:  0.0339347 Validation Decoder Loss:  0.35157308
Encoder Loss:  0.038924538  || Decoder Loss:  0.0342241 Validation Decoder Loss:  0.3664918
Encoder Loss:  0.040460125  || Decoder Loss:  0.035524834 Validation Decoder Loss:  0.36203474
Encoder Loss:  0.04006879  || Decoder Loss:  0.035500385 Validation Decoder Loss:  0.38478673
Encoder Loss:  0.04269857  || Decoder Loss:  0.038013507 Validation Decoder Loss:  0.34112293
Encoder Loss:  0.039732743  || Decoder Loss:  0.034492023 Validation Decoder Loss:  0.39679116
Encoder Loss:  0.041168228  || Decoder Loss:  0.037032265 Validation Decoder Loss:  0.32756853
Encoder Loss:  0.040920552  || Decoder Loss:  0.037195653 Validation Decoder Loss:  0.39282274
Encoder Loss:  0.0426068  || Decoder Loss:  0.038987562 Validation Decoder Loss:  0.34513167
Encoder Loss:  0.039659712  || Decoder Loss:  0.034580536 Validation Decoder Loss:  0.3282544
Encoder Loss:  0.041252278  || Decoder Loss:  0.037240487 Validation Decoder Loss:  0.38968793
Encoder Loss:  0.04295064  || Decoder Loss:  0.03921109 Validation Decoder Loss:  0.36723268
Model: siamese_net_lr_0.030297355510431733 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3672327
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 307, 10, 20, 1)    1465      
_________________________________________________________________
reshape_63 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 1,465
Trainable params: 1,465
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7874304  || Decoder Loss:  0.946455 Validation Decoder Loss:  1.6515188
Encoder Loss:  0.79850036  || Decoder Loss:  0.9582484 Validation Decoder Loss:  1.6505885
Encoder Loss:  0.7968011  || Decoder Loss:  0.9568312 Validation Decoder Loss:  1.649078
Encoder Loss:  0.79395723  || Decoder Loss:  0.95466834 Validation Decoder Loss:  1.6466067
Encoder Loss:  0.7862642  || Decoder Loss:  0.9514348 Validation Decoder Loss:  1.6426792
Encoder Loss:  0.7859018  || Decoder Loss:  0.9464117 Validation Decoder Loss:  1.6357244
Encoder Loss:  0.7773298  || Decoder Loss:  0.9380619 Validation Decoder Loss:  1.6231382
Encoder Loss:  0.7624833  || Decoder Loss:  0.92322654 Validation Decoder Loss:  1.5978342
Encoder Loss:  0.7317412  || Decoder Loss:  0.8908124 Validation Decoder Loss:  1.5228033
Encoder Loss:  0.41709363  || Decoder Loss:  0.46453285 Validation Decoder Loss:  0.6282252
Encoder Loss:  0.32201055  || Decoder Loss:  0.40193856 Validation Decoder Loss:  1.1134393
Encoder Loss:  0.37096745  || Decoder Loss:  0.49958098 Validation Decoder Loss:  1.0652357
Encoder Loss:  0.36667037  || Decoder Loss:  0.49698308 Validation Decoder Loss:  1.0388494
Encoder Loss:  0.36249366  || Decoder Loss:  0.49319485 Validation Decoder Loss:  1.0127356
Encoder Loss:  0.3586212  || Decoder Loss:  0.4891251 Validation Decoder Loss:  1.0148743
Encoder Loss:  0.35956722  || Decoder Loss:  0.49088463 Validation Decoder Loss:  1.0142083
Encoder Loss:  0.3595111  || Decoder Loss:  0.4913722 Validation Decoder Loss:  1.0168681
Encoder Loss:  0.36014107  || Decoder Loss:  0.4927251 Validation Decoder Loss:  1.0220855
Encoder Loss:  0.36164674  || Decoder Loss:  0.49511784 Validation Decoder Loss:  1.026242
Encoder Loss:  0.3621253  || Decoder Loss:  0.49623093 Validation Decoder Loss:  1.0247908
Encoder Loss:  0.36144152  || Decoder Loss:  0.49588805 Validation Decoder Loss:  1.0106337
Encoder Loss:  0.36046818  || Decoder Loss:  0.49526462 Validation Decoder Loss:  1.0094961
Encoder Loss:  0.36033136  || Decoder Loss:  0.49555004 Validation Decoder Loss:  1.0132357
Encoder Loss:  0.36123887  || Decoder Loss:  0.49659076 Validation Decoder Loss:  1.0001284
Encoder Loss:  0.36256167  || Decoder Loss:  0.4973584 Validation Decoder Loss:  1.0177883
Encoder Loss:  0.3605269  || Decoder Loss:  0.4958709 Validation Decoder Loss:  1.0221015
Encoder Loss:  0.36119792  || Decoder Loss:  0.4967595 Validation Decoder Loss:  1.018222
Encoder Loss:  0.36302784  || Decoder Loss:  0.49810174 Validation Decoder Loss:  1.031798
Encoder Loss:  0.3613766  || Decoder Loss:  0.49644786 Validation Decoder Loss:  1.013659
Encoder Loss:  0.36083004  || Decoder Loss:  0.49566975 Validation Decoder Loss:  1.0167129
Encoder Loss:  0.36062652  || Decoder Loss:  0.49562278 Validation Decoder Loss:  1.0349604
Encoder Loss:  0.3616161  || Decoder Loss:  0.4966256 Validation Decoder Loss:  1.0332263
Encoder Loss:  0.36080405  || Decoder Loss:  0.49550572 Validation Decoder Loss:  1.027259
Encoder Loss:  0.36076027  || Decoder Loss:  0.49569726 Validation Decoder Loss:  1.0444508
Encoder Loss:  0.36100414  || Decoder Loss:  0.4964702 Validation Decoder Loss:  1.0326011
Encoder Loss:  0.36089814  || Decoder Loss:  0.4960807 Validation Decoder Loss:  1.0290549
Encoder Loss:  0.36215553  || Decoder Loss:  0.49665627 Validation Decoder Loss:  1.0506939
Encoder Loss:  0.3603228  || Decoder Loss:  0.49529484 Validation Decoder Loss:  1.0514183
Encoder Loss:  0.36098468  || Decoder Loss:  0.4958999 Validation Decoder Loss:  1.0429037
Encoder Loss:  0.36018753  || Decoder Loss:  0.4952721 Validation Decoder Loss:  1.0327983
Model: siamese_net_lr_0.04973924875198488 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0327983
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_64 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_64 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054363333  || Decoder Loss:  0.4774745 Validation Decoder Loss:  0.92162263
Encoder Loss:  0.051901717  || Decoder Loss:  0.41078427 Validation Decoder Loss:  0.8105743
Encoder Loss:  0.051594257  || Decoder Loss:  0.3399303 Validation Decoder Loss:  0.7051536
Encoder Loss:  0.051284943  || Decoder Loss:  0.27693635 Validation Decoder Loss:  0.62199694
Encoder Loss:  0.051357724  || Decoder Loss:  0.22783993 Validation Decoder Loss:  0.56171024
Encoder Loss:  0.051063977  || Decoder Loss:  0.19228616 Validation Decoder Loss:  0.5209288
Encoder Loss:  0.051209945  || Decoder Loss:  0.16667576 Validation Decoder Loss:  0.49143812
Encoder Loss:  0.050999478  || Decoder Loss:  0.14778806 Validation Decoder Loss:  0.4705173
Encoder Loss:  0.051018286  || Decoder Loss:  0.13340259 Validation Decoder Loss:  0.45447832
Encoder Loss:  0.050916683  || Decoder Loss:  0.12210741 Validation Decoder Loss:  0.4420672
Encoder Loss:  0.050814856  || Decoder Loss:  0.11300878 Validation Decoder Loss:  0.4319928
Encoder Loss:  0.050680842  || Decoder Loss:  0.10552297 Validation Decoder Loss:  0.4235778
Encoder Loss:  0.050584573  || Decoder Loss:  0.099252015 Validation Decoder Loss:  0.41650188
Encoder Loss:  0.05042423  || Decoder Loss:  0.09391777 Validation Decoder Loss:  0.41113013
Encoder Loss:  0.05045322  || Decoder Loss:  0.08932252 Validation Decoder Loss:  0.40617687
Encoder Loss:  0.050401207  || Decoder Loss:  0.08532214 Validation Decoder Loss:  0.40208265
Encoder Loss:  0.05040193  || Decoder Loss:  0.08180649 Validation Decoder Loss:  0.39850134
Encoder Loss:  0.050401557  || Decoder Loss:  0.078692175 Validation Decoder Loss:  0.39529788
Encoder Loss:  0.05036381  || Decoder Loss:  0.075912744 Validation Decoder Loss:  0.39226675
Encoder Loss:  0.05033715  || Decoder Loss:  0.07341588 Validation Decoder Loss:  0.38964212
Encoder Loss:  0.050295558  || Decoder Loss:  0.071160465 Validation Decoder Loss:  0.3875463
Encoder Loss:  0.050329037  || Decoder Loss:  0.06911145 Validation Decoder Loss:  0.38538963
Encoder Loss:  0.050275892  || Decoder Loss:  0.067242146 Validation Decoder Loss:  0.3837099
Encoder Loss:  0.050333343  || Decoder Loss:  0.065528795 Validation Decoder Loss:  0.38185608
Encoder Loss:  0.050281163  || Decoder Loss:  0.06395272 Validation Decoder Loss:  0.38044026
Encoder Loss:  0.05027419  || Decoder Loss:  0.062497698 Validation Decoder Loss:  0.37915784
Encoder Loss:  0.050331265  || Decoder Loss:  0.06114994 Validation Decoder Loss:  0.37772852
Encoder Loss:  0.05025324  || Decoder Loss:  0.059897505 Validation Decoder Loss:  0.37667674
Encoder Loss:  0.05031764  || Decoder Loss:  0.058730572 Validation Decoder Loss:  0.37544382
Encoder Loss:  0.050248757  || Decoder Loss:  0.05764065 Validation Decoder Loss:  0.37448418
Encoder Loss:  0.05024557  || Decoder Loss:  0.056619905 Validation Decoder Loss:  0.37360656
Encoder Loss:  0.05026168  || Decoder Loss:  0.05566205 Validation Decoder Loss:  0.37273514
Encoder Loss:  0.050259102  || Decoder Loss:  0.054761328 Validation Decoder Loss:  0.37189835
Encoder Loss:  0.050255984  || Decoder Loss:  0.053912412 Validation Decoder Loss:  0.371147
Encoder Loss:  0.050237194  || Decoder Loss:  0.053111006 Validation Decoder Loss:  0.37040418
Encoder Loss:  0.050236646  || Decoder Loss:  0.052353207 Validation Decoder Loss:  0.36972502
Encoder Loss:  0.050262317  || Decoder Loss:  0.05163513 Validation Decoder Loss:  0.36909682
Encoder Loss:  0.05024872  || Decoder Loss:  0.050953988 Validation Decoder Loss:  0.36850742
Encoder Loss:  0.0502466  || Decoder Loss:  0.050306655 Validation Decoder Loss:  0.36793032
Encoder Loss:  0.05022669  || Decoder Loss:  0.049690872 Validation Decoder Loss:  0.36737797
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36737797
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_65 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.103799716  || Decoder Loss:  0.3380944 Validation Decoder Loss:  0.59509647
Encoder Loss:  0.08529841  || Decoder Loss:  0.28946108 Validation Decoder Loss:  0.5173645
Encoder Loss:  0.079033524  || Decoder Loss:  0.24397807 Validation Decoder Loss:  0.4604077
Encoder Loss:  0.07475695  || Decoder Loss:  0.21015242 Validation Decoder Loss:  0.42181754
Encoder Loss:  0.07147723  || Decoder Loss:  0.18524261 Validation Decoder Loss:  0.395064
Encoder Loss:  0.068963654  || Decoder Loss:  0.16624217 Validation Decoder Loss:  0.37582436
Encoder Loss:  0.06699528  || Decoder Loss:  0.15137573 Validation Decoder Loss:  0.3617716
Encoder Loss:  0.065457866  || Decoder Loss:  0.13958761 Validation Decoder Loss:  0.35127681
Encoder Loss:  0.06417941  || Decoder Loss:  0.13005014 Validation Decoder Loss:  0.34329343
Encoder Loss:  0.063092306  || Decoder Loss:  0.12217998 Validation Decoder Loss:  0.33712733
Encoder Loss:  0.062148094  || Decoder Loss:  0.115577586 Validation Decoder Loss:  0.33229223
Encoder Loss:  0.061319653  || Decoder Loss:  0.10993596 Validation Decoder Loss:  0.3284411
Encoder Loss:  0.06062902  || Decoder Loss:  0.10506381 Validation Decoder Loss:  0.32537395
Encoder Loss:  0.0600189  || Decoder Loss:  0.10083876 Validation Decoder Loss:  0.322896
Encoder Loss:  0.059466057  || Decoder Loss:  0.097132 Validation Decoder Loss:  0.32087746
Encoder Loss:  0.058998264  || Decoder Loss:  0.09385508 Validation Decoder Loss:  0.31922337
Encoder Loss:  0.05857808  || Decoder Loss:  0.09094517 Validation Decoder Loss:  0.31786197
Encoder Loss:  0.05816437  || Decoder Loss:  0.08834117 Validation Decoder Loss:  0.31672883
Encoder Loss:  0.05781508  || Decoder Loss:  0.085989 Validation Decoder Loss:  0.31578788
Encoder Loss:  0.057484955  || Decoder Loss:  0.08385972 Validation Decoder Loss:  0.315001
Encoder Loss:  0.05717528  || Decoder Loss:  0.08191419 Validation Decoder Loss:  0.31434202
Encoder Loss:  0.05689068  || Decoder Loss:  0.08013334 Validation Decoder Loss:  0.31379107
Encoder Loss:  0.056643862  || Decoder Loss:  0.078507446 Validation Decoder Loss:  0.3133372
Encoder Loss:  0.05638342  || Decoder Loss:  0.07701191 Validation Decoder Loss:  0.31295782
Encoder Loss:  0.0561627  || Decoder Loss:  0.075615734 Validation Decoder Loss:  0.31264433
Encoder Loss:  0.055945415  || Decoder Loss:  0.07432092 Validation Decoder Loss:  0.3123893
Encoder Loss:  0.05573998  || Decoder Loss:  0.07311366 Validation Decoder Loss:  0.31218377
Encoder Loss:  0.055538636  || Decoder Loss:  0.071978204 Validation Decoder Loss:  0.31202036
Encoder Loss:  0.055363063  || Decoder Loss:  0.07091103 Validation Decoder Loss:  0.31189495
Encoder Loss:  0.05519761  || Decoder Loss:  0.069920264 Validation Decoder Loss:  0.31180686
Encoder Loss:  0.05505248  || Decoder Loss:  0.06899194 Validation Decoder Loss:  0.3117476
Encoder Loss:  0.054859757  || Decoder Loss:  0.06811312 Validation Decoder Loss:  0.31171626
Encoder Loss:  0.05478326  || Decoder Loss:  0.06729209 Validation Decoder Loss:  0.3117127
Encoder Loss:  0.054556355  || Decoder Loss:  0.06651638 Validation Decoder Loss:  0.31173086
Encoder Loss:  0.05444376  || Decoder Loss:  0.065764576 Validation Decoder Loss:  0.31176952
Encoder Loss:  0.054303408  || Decoder Loss:  0.06505211 Validation Decoder Loss:  0.3118257
Encoder Loss:  0.054152165  || Decoder Loss:  0.06436836 Validation Decoder Loss:  0.31189847
Encoder Loss:  0.05406489  || Decoder Loss:  0.0637157 Validation Decoder Loss:  0.3119861
Encoder Loss:  0.05391773  || Decoder Loss:  0.06309759 Validation Decoder Loss:  0.3120873
Encoder Loss:  0.05381763  || Decoder Loss:  0.062507145 Validation Decoder Loss:  0.31220177
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31220174
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_66 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1149077  || Decoder Loss:  0.48922426 Validation Decoder Loss:  0.8878533
Encoder Loss:  0.09838546  || Decoder Loss:  0.4069958 Validation Decoder Loss:  0.7617914
Encoder Loss:  0.08868419  || Decoder Loss:  0.33114034 Validation Decoder Loss:  0.65916216
Encoder Loss:  0.08086453  || Decoder Loss:  0.27015516 Validation Decoder Loss:  0.5829486
Encoder Loss:  0.07499517  || Decoder Loss:  0.22459246 Validation Decoder Loss:  0.52850294
Encoder Loss:  0.070714906  || Decoder Loss:  0.19129172 Validation Decoder Loss:  0.49047807
Encoder Loss:  0.06753722  || Decoder Loss:  0.16695534 Validation Decoder Loss:  0.46336553
Encoder Loss:  0.06516255  || Decoder Loss:  0.14886068 Validation Decoder Loss:  0.44366845
Encoder Loss:  0.06331678  || Decoder Loss:  0.13495356 Validation Decoder Loss:  0.42848778
Encoder Loss:  0.061834536  || Decoder Loss:  0.123837024 Validation Decoder Loss:  0.41645962
Encoder Loss:  0.06059537  || Decoder Loss:  0.11477351 Validation Decoder Loss:  0.40700296
Encoder Loss:  0.059517898  || Decoder Loss:  0.10722729 Validation Decoder Loss:  0.39902544
Encoder Loss:  0.05855949  || Decoder Loss:  0.1006773 Validation Decoder Loss:  0.3919783
Encoder Loss:  0.057781544  || Decoder Loss:  0.09496354 Validation Decoder Loss:  0.3861392
Encoder Loss:  0.057054926  || Decoder Loss:  0.090106055 Validation Decoder Loss:  0.38109577
Encoder Loss:  0.05638736  || Decoder Loss:  0.08572773 Validation Decoder Loss:  0.3764339
Encoder Loss:  0.055905275  || Decoder Loss:  0.08190492 Validation Decoder Loss:  0.3727855
Encoder Loss:  0.055434674  || Decoder Loss:  0.07868182 Validation Decoder Loss:  0.3697964
Encoder Loss:  0.05507323  || Decoder Loss:  0.075872704 Validation Decoder Loss:  0.3673449
Encoder Loss:  0.054729834  || Decoder Loss:  0.073430866 Validation Decoder Loss:  0.36539376
Encoder Loss:  0.054430854  || Decoder Loss:  0.07129058 Validation Decoder Loss:  0.36373365
Encoder Loss:  0.05417891  || Decoder Loss:  0.06937561 Validation Decoder Loss:  0.3623559
Encoder Loss:  0.05394285  || Decoder Loss:  0.06767156 Validation Decoder Loss:  0.3612128
Encoder Loss:  0.05373909  || Decoder Loss:  0.06613075 Validation Decoder Loss:  0.3602485
Encoder Loss:  0.05355169  || Decoder Loss:  0.06473167 Validation Decoder Loss:  0.3594166
Encoder Loss:  0.053374387  || Decoder Loss:  0.06345324 Validation Decoder Loss:  0.35868114
Encoder Loss:  0.053198863  || Decoder Loss:  0.06223257 Validation Decoder Loss:  0.35793504
Encoder Loss:  0.053030156  || Decoder Loss:  0.06108289 Validation Decoder Loss:  0.35723084
Encoder Loss:  0.052905727  || Decoder Loss:  0.06001811 Validation Decoder Loss:  0.35674885
Encoder Loss:  0.052725505  || Decoder Loss:  0.05906309 Validation Decoder Loss:  0.35621843
Encoder Loss:  0.05263737  || Decoder Loss:  0.0581649 Validation Decoder Loss:  0.35588193
Encoder Loss:  0.05248879  || Decoder Loss:  0.057335287 Validation Decoder Loss:  0.3554482
Encoder Loss:  0.05239089  || Decoder Loss:  0.05653523 Validation Decoder Loss:  0.35512072
Encoder Loss:  0.052267145  || Decoder Loss:  0.0557823 Validation Decoder Loss:  0.35476923
Encoder Loss:  0.05218426  || Decoder Loss:  0.055077806 Validation Decoder Loss:  0.35449463
Encoder Loss:  0.05206628  || Decoder Loss:  0.05440186 Validation Decoder Loss:  0.35419315
Encoder Loss:  0.051998287  || Decoder Loss:  0.053776514 Validation Decoder Loss:  0.3539896
Encoder Loss:  0.051894307  || Decoder Loss:  0.053181972 Validation Decoder Loss:  0.35373116
Encoder Loss:  0.051805075  || Decoder Loss:  0.052586745 Validation Decoder Loss:  0.35345694
Encoder Loss:  0.0517159  || Decoder Loss:  0.052014634 Validation Decoder Loss:  0.35319388
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35319388
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_67 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_67 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13371834  || Decoder Loss:  0.43608144 Validation Decoder Loss:  0.76177114
Encoder Loss:  0.098997734  || Decoder Loss:  0.3956243 Validation Decoder Loss:  0.67020357
Encoder Loss:  0.08924303  || Decoder Loss:  0.3415555 Validation Decoder Loss:  0.59452486
Encoder Loss:  0.08267406  || Decoder Loss:  0.29105607 Validation Decoder Loss:  0.53562164
Encoder Loss:  0.077131264  || Decoder Loss:  0.24867778 Validation Decoder Loss:  0.494342
Encoder Loss:  0.07283098  || Decoder Loss:  0.21516007 Validation Decoder Loss:  0.46598262
Encoder Loss:  0.0695095  || Decoder Loss:  0.18912935 Validation Decoder Loss:  0.44626552
Encoder Loss:  0.066908635  || Decoder Loss:  0.16893263 Validation Decoder Loss:  0.43207505
Encoder Loss:  0.064873874  || Decoder Loss:  0.15312643 Validation Decoder Loss:  0.42136207
Encoder Loss:  0.063271664  || Decoder Loss:  0.14054586 Validation Decoder Loss:  0.4128648
Encoder Loss:  0.061932184  || Decoder Loss:  0.1303407 Validation Decoder Loss:  0.40589797
Encoder Loss:  0.06084141  || Decoder Loss:  0.12190049 Validation Decoder Loss:  0.40005037
Encoder Loss:  0.059923936  || Decoder Loss:  0.114818305 Validation Decoder Loss:  0.3950538
Encoder Loss:  0.05912683  || Decoder Loss:  0.10877799 Validation Decoder Loss:  0.39073327
Encoder Loss:  0.058452833  || Decoder Loss:  0.10356793 Validation Decoder Loss:  0.38699764
Encoder Loss:  0.057854205  || Decoder Loss:  0.099027656 Validation Decoder Loss:  0.3837222
Encoder Loss:  0.05731532  || Decoder Loss:  0.09502397 Validation Decoder Loss:  0.38083446
Encoder Loss:  0.05683588  || Decoder Loss:  0.09146865 Validation Decoder Loss:  0.37828574
Encoder Loss:  0.056411255  || Decoder Loss:  0.08829419 Validation Decoder Loss:  0.37602493
Encoder Loss:  0.056030557  || Decoder Loss:  0.085438184 Validation Decoder Loss:  0.37400913
Encoder Loss:  0.05567959  || Decoder Loss:  0.082859285 Validation Decoder Loss:  0.37220067
Encoder Loss:  0.055352166  || Decoder Loss:  0.080513984 Validation Decoder Loss:  0.37059677
Encoder Loss:  0.05505439  || Decoder Loss:  0.07837268 Validation Decoder Loss:  0.36914772
Encoder Loss:  0.05478352  || Decoder Loss:  0.07640785 Validation Decoder Loss:  0.36784554
Encoder Loss:  0.054532323  || Decoder Loss:  0.07460111 Validation Decoder Loss:  0.36666548
Encoder Loss:  0.05429542  || Decoder Loss:  0.072929695 Validation Decoder Loss:  0.36559266
Encoder Loss:  0.05407645  || Decoder Loss:  0.07138052 Validation Decoder Loss:  0.3646168
Encoder Loss:  0.05387219  || Decoder Loss:  0.06994199 Validation Decoder Loss:  0.363724
Encoder Loss:  0.05367266  || Decoder Loss:  0.0685996 Validation Decoder Loss:  0.3629076
Encoder Loss:  0.053496405  || Decoder Loss:  0.06734469 Validation Decoder Loss:  0.36215156
Encoder Loss:  0.053320784  || Decoder Loss:  0.06617135 Validation Decoder Loss:  0.36146593
Encoder Loss:  0.053153466  || Decoder Loss:  0.06506747 Validation Decoder Loss:  0.3608285
Encoder Loss:  0.05299436  || Decoder Loss:  0.0640279 Validation Decoder Loss:  0.3602396
Encoder Loss:  0.052833766  || Decoder Loss:  0.06304842 Validation Decoder Loss:  0.359691
Encoder Loss:  0.052691355  || Decoder Loss:  0.06212183 Validation Decoder Loss:  0.3591788
Encoder Loss:  0.052557893  || Decoder Loss:  0.061245628 Validation Decoder Loss:  0.3586951
Encoder Loss:  0.05242215  || Decoder Loss:  0.06041695 Validation Decoder Loss:  0.35825247
Encoder Loss:  0.052304655  || Decoder Loss:  0.059629813 Validation Decoder Loss:  0.3578424
Encoder Loss:  0.052199427  || Decoder Loss:  0.058880754 Validation Decoder Loss:  0.35745284
Encoder Loss:  0.052068334  || Decoder Loss:  0.058168497 Validation Decoder Loss:  0.35709226
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35709226
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_68 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10728723  || Decoder Loss:  0.4520027 Validation Decoder Loss:  0.83122015
Encoder Loss:  0.09087314  || Decoder Loss:  0.38417664 Validation Decoder Loss:  0.7145205
Encoder Loss:  0.08249209  || Decoder Loss:  0.31791326 Validation Decoder Loss:  0.6269876
Encoder Loss:  0.07657175  || Decoder Loss:  0.26666635 Validation Decoder Loss:  0.56467533
Encoder Loss:  0.07217624  || Decoder Loss:  0.22858633 Validation Decoder Loss:  0.52071667
Encoder Loss:  0.0688901  || Decoder Loss:  0.20016341 Validation Decoder Loss:  0.48910317
Encoder Loss:  0.06639432  || Decoder Loss:  0.17859875 Validation Decoder Loss:  0.4658023
Encoder Loss:  0.06444881  || Decoder Loss:  0.16182067 Validation Decoder Loss:  0.44795865
Encoder Loss:  0.06291007  || Decoder Loss:  0.14856565 Validation Decoder Loss:  0.43414307
Encoder Loss:  0.061663315  || Decoder Loss:  0.1378406 Validation Decoder Loss:  0.42305934
Encoder Loss:  0.06063833  || Decoder Loss:  0.12902735 Validation Decoder Loss:  0.4140845
Encoder Loss:  0.05977831  || Decoder Loss:  0.12164072 Validation Decoder Loss:  0.40662393
Encoder Loss:  0.059052065  || Decoder Loss:  0.115404636 Validation Decoder Loss:  0.4003263
Encoder Loss:  0.058421116  || Decoder Loss:  0.11001593 Validation Decoder Loss:  0.39502335
Encoder Loss:  0.057876166  || Decoder Loss:  0.10533966 Validation Decoder Loss:  0.39035523
Encoder Loss:  0.05739111  || Decoder Loss:  0.10120726 Validation Decoder Loss:  0.38627213
Encoder Loss:  0.05696064  || Decoder Loss:  0.097511634 Validation Decoder Loss:  0.3825778
Encoder Loss:  0.056583486  || Decoder Loss:  0.09426135 Validation Decoder Loss:  0.3794212
Encoder Loss:  0.056246366  || Decoder Loss:  0.091357194 Validation Decoder Loss:  0.37662256
Encoder Loss:  0.055937454  || Decoder Loss:  0.088730104 Validation Decoder Loss:  0.37410918
Encoder Loss:  0.05565625  || Decoder Loss:  0.08632598 Validation Decoder Loss:  0.37178516
Encoder Loss:  0.055399626  || Decoder Loss:  0.08412507 Validation Decoder Loss:  0.3697226
Encoder Loss:  0.05516248  || Decoder Loss:  0.08211224 Validation Decoder Loss:  0.36785477
Encoder Loss:  0.054942675  || Decoder Loss:  0.08025316 Validation Decoder Loss:  0.3661444
Encoder Loss:  0.05474095  || Decoder Loss:  0.07851884 Validation Decoder Loss:  0.36448544
Encoder Loss:  0.05454869  || Decoder Loss:  0.07689962 Validation Decoder Loss:  0.36304387
Encoder Loss:  0.054372944  || Decoder Loss:  0.075413644 Validation Decoder Loss:  0.3616838
Encoder Loss:  0.05420944  || Decoder Loss:  0.07403042 Validation Decoder Loss:  0.36043382
Encoder Loss:  0.054058928  || Decoder Loss:  0.07273441 Validation Decoder Loss:  0.35927254
Encoder Loss:  0.053913865  || Decoder Loss:  0.07151916 Validation Decoder Loss:  0.35819703
Encoder Loss:  0.053778548  || Decoder Loss:  0.07038194 Validation Decoder Loss:  0.35719672
Encoder Loss:  0.053650565  || Decoder Loss:  0.06930434 Validation Decoder Loss:  0.3562628
Encoder Loss:  0.05353054  || Decoder Loss:  0.06828848 Validation Decoder Loss:  0.35539076
Encoder Loss:  0.05341637  || Decoder Loss:  0.06732669 Validation Decoder Loss:  0.35459858
Encoder Loss:  0.053307578  || Decoder Loss:  0.06641535 Validation Decoder Loss:  0.35383886
Encoder Loss:  0.053203654  || Decoder Loss:  0.06554977 Validation Decoder Loss:  0.3531316
Encoder Loss:  0.0531044  || Decoder Loss:  0.06472927 Validation Decoder Loss:  0.35245368
Encoder Loss:  0.05301215  || Decoder Loss:  0.0639408 Validation Decoder Loss:  0.35181534
Encoder Loss:  0.05292211  || Decoder Loss:  0.063181125 Validation Decoder Loss:  0.35124457
Encoder Loss:  0.05283254  || Decoder Loss:  0.062449604 Validation Decoder Loss:  0.35064125
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35064125
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_69 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13504356  || Decoder Loss:  0.4854497 Validation Decoder Loss:  0.91350144
Encoder Loss:  0.10050553  || Decoder Loss:  0.4091372 Validation Decoder Loss:  0.7948216
Encoder Loss:  0.08953435  || Decoder Loss:  0.3386681 Validation Decoder Loss:  0.7020199
Encoder Loss:  0.082030274  || Decoder Loss:  0.28452843 Validation Decoder Loss:  0.635855
Encoder Loss:  0.0768471  || Decoder Loss:  0.24507229 Validation Decoder Loss:  0.5892813
Encoder Loss:  0.0726944  || Decoder Loss:  0.21626133 Validation Decoder Loss:  0.5554848
Encoder Loss:  0.06975956  || Decoder Loss:  0.19457075 Validation Decoder Loss:  0.52996635
Encoder Loss:  0.06735104  || Decoder Loss:  0.17757425 Validation Decoder Loss:  0.50979686
Encoder Loss:  0.06542071  || Decoder Loss:  0.16371033 Validation Decoder Loss:  0.49328598
Encoder Loss:  0.06391395  || Decoder Loss:  0.15212503 Validation Decoder Loss:  0.47956514
Encoder Loss:  0.06269114  || Decoder Loss:  0.14237207 Validation Decoder Loss:  0.46818024
Encoder Loss:  0.06162653  || Decoder Loss:  0.13407953 Validation Decoder Loss:  0.45850468
Encoder Loss:  0.0607306  || Decoder Loss:  0.12695402 Validation Decoder Loss:  0.4502579
Encoder Loss:  0.05996196  || Decoder Loss:  0.12080398 Validation Decoder Loss:  0.4431734
Encoder Loss:  0.059293013  || Decoder Loss:  0.11542093 Validation Decoder Loss:  0.4369636
Encoder Loss:  0.05870323  || Decoder Loss:  0.110662624 Validation Decoder Loss:  0.43151137
Encoder Loss:  0.05817864  || Decoder Loss:  0.10642504 Validation Decoder Loss:  0.42666525
Encoder Loss:  0.057708263  || Decoder Loss:  0.10263668 Validation Decoder Loss:  0.42236927
Encoder Loss:  0.05728616  || Decoder Loss:  0.09923185 Validation Decoder Loss:  0.4185081
Encoder Loss:  0.05690082  || Decoder Loss:  0.09614876 Validation Decoder Loss:  0.41503006
Encoder Loss:  0.056552563  || Decoder Loss:  0.09334513 Validation Decoder Loss:  0.41187423
Encoder Loss:  0.056229338  || Decoder Loss:  0.09078472 Validation Decoder Loss:  0.40900463
Encoder Loss:  0.055937614  || Decoder Loss:  0.088442996 Validation Decoder Loss:  0.40638876
Encoder Loss:  0.055667233  || Decoder Loss:  0.08628488 Validation Decoder Loss:  0.403979
Encoder Loss:  0.055413354  || Decoder Loss:  0.08427145 Validation Decoder Loss:  0.40174177
Encoder Loss:  0.05517394  || Decoder Loss:  0.082422845 Validation Decoder Loss:  0.3997077
Encoder Loss:  0.054956187  || Decoder Loss:  0.080712706 Validation Decoder Loss:  0.39781854
Encoder Loss:  0.054759134  || Decoder Loss:  0.07910648 Validation Decoder Loss:  0.3960412
Encoder Loss:  0.0545609  || Decoder Loss:  0.07760858 Validation Decoder Loss:  0.3944089
Encoder Loss:  0.05438771  || Decoder Loss:  0.07621007 Validation Decoder Loss:  0.3928669
Encoder Loss:  0.05421615  || Decoder Loss:  0.07488855 Validation Decoder Loss:  0.3914278
Encoder Loss:  0.054054476  || Decoder Loss:  0.07364097 Validation Decoder Loss:  0.39007396
Encoder Loss:  0.053901598  || Decoder Loss:  0.072477765 Validation Decoder Loss:  0.38881373
Encoder Loss:  0.05376092  || Decoder Loss:  0.07137954 Validation Decoder Loss:  0.38762254
Encoder Loss:  0.053626437  || Decoder Loss:  0.070338264 Validation Decoder Loss:  0.3864961
Encoder Loss:  0.053498417  || Decoder Loss:  0.069350585 Validation Decoder Loss:  0.3854328
Encoder Loss:  0.053378526  || Decoder Loss:  0.06841233 Validation Decoder Loss:  0.38442165
Encoder Loss:  0.053260393  || Decoder Loss:  0.067520455 Validation Decoder Loss:  0.38346648
Encoder Loss:  0.053149994  || Decoder Loss:  0.06667045 Validation Decoder Loss:  0.38255847
Encoder Loss:  0.05304274  || Decoder Loss:  0.065866984 Validation Decoder Loss:  0.38170278
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38170278
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_70 (Conv3DT (None, 295, 6, 20, 1)     213       
_________________________________________________________________
reshape_70 (Reshape)         (None, 1770, 20, 1)       0         
=================================================================
Total params: 213
Trainable params: 213
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 1770, 20, 1)       1477      
=================================================================
Total params: 1,477
Trainable params: 1,477
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 3245, 20, 1)       1477      
=================================================================
Total params: 1,477
Trainable params: 1,477
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.77970487  || Decoder Loss:  0.8910763 Validation Decoder Loss:  1.6400437
Encoder Loss:  0.7951098  || Decoder Loss:  0.90882623 Validation Decoder Loss:  1.6378226
Encoder Loss:  0.7933769  || Decoder Loss:  0.9070077 Validation Decoder Loss:  1.6347935
Encoder Loss:  0.7908105  || Decoder Loss:  0.9045633 Validation Decoder Loss:  1.6309509
Encoder Loss:  0.7870128  || Decoder Loss:  0.90138924 Validation Decoder Loss:  1.6261411
Encoder Loss:  0.78082186  || Decoder Loss:  0.897119 Validation Decoder Loss:  1.6195811
Encoder Loss:  0.7666877  || Decoder Loss:  0.889815 Validation Decoder Loss:  1.6050451
Encoder Loss:  0.491448  || Decoder Loss:  0.58933944 Validation Decoder Loss:  0.48874578
Encoder Loss:  0.3827223  || Decoder Loss:  0.4821784 Validation Decoder Loss:  0.7281195
Encoder Loss:  0.37234032  || Decoder Loss:  0.47130957 Validation Decoder Loss:  0.611831
Encoder Loss:  0.36951378  || Decoder Loss:  0.46741372 Validation Decoder Loss:  0.6121505
Encoder Loss:  0.36279878  || Decoder Loss:  0.45924905 Validation Decoder Loss:  0.54078853
Encoder Loss:  0.35446763  || Decoder Loss:  0.44865525 Validation Decoder Loss:  0.5301135
Encoder Loss:  0.33967164  || Decoder Loss:  0.42941663 Validation Decoder Loss:  0.49950215
Encoder Loss:  0.3510444  || Decoder Loss:  0.4452153 Validation Decoder Loss:  0.6974555
Encoder Loss:  0.36697304  || Decoder Loss:  0.467609 Validation Decoder Loss:  0.5470079
Encoder Loss:  0.36420676  || Decoder Loss:  0.46415776 Validation Decoder Loss:  0.5436282
Encoder Loss:  0.35608238  || Decoder Loss:  0.45356026 Validation Decoder Loss:  0.47306806
Encoder Loss:  0.3554638  || Decoder Loss:  0.45291087 Validation Decoder Loss:  0.5553561
Encoder Loss:  0.3599081  || Decoder Loss:  0.45984128 Validation Decoder Loss:  0.8688028
Encoder Loss:  0.3613285  || Decoder Loss:  0.46217582 Validation Decoder Loss:  0.8789186
Encoder Loss:  0.3601439  || Decoder Loss:  0.4599506 Validation Decoder Loss:  0.99175245
Encoder Loss:  0.38561165  || Decoder Loss:  0.49346197 Validation Decoder Loss:  0.92858
Encoder Loss:  0.38470104  || Decoder Loss:  0.49225798 Validation Decoder Loss:  1.0297946
Encoder Loss:  0.35735816  || Decoder Loss:  0.45465624 Validation Decoder Loss:  0.9021969
Encoder Loss:  0.35188958  || Decoder Loss:  0.44874474 Validation Decoder Loss:  0.7671167
Encoder Loss:  0.37745866  || Decoder Loss:  0.48166952 Validation Decoder Loss:  0.8885342
Encoder Loss:  0.3740942  || Decoder Loss:  0.47792953 Validation Decoder Loss:  0.951862
Encoder Loss:  0.38651696  || Decoder Loss:  0.49398762 Validation Decoder Loss:  0.9837887
Encoder Loss:  0.386329  || Decoder Loss:  0.4943263 Validation Decoder Loss:  0.9989337
Encoder Loss:  0.38282487  || Decoder Loss:  0.4896536 Validation Decoder Loss:  1.0448456
Encoder Loss:  0.38582766  || Decoder Loss:  0.49091348 Validation Decoder Loss:  1.0663865
Encoder Loss:  0.38456315  || Decoder Loss:  0.4908875 Validation Decoder Loss:  0.97842884
Encoder Loss:  0.3674196  || Decoder Loss:  0.47031045 Validation Decoder Loss:  0.9019138
Encoder Loss:  0.36513406  || Decoder Loss:  0.46561328 Validation Decoder Loss:  0.9904072
Encoder Loss:  0.3704243  || Decoder Loss:  0.4736715 Validation Decoder Loss:  1.0014548
Encoder Loss:  0.35251796  || Decoder Loss:  0.44885436 Validation Decoder Loss:  0.9746764
Encoder Loss:  0.34602734  || Decoder Loss:  0.43812945 Validation Decoder Loss:  0.8273018
Encoder Loss:  0.37995765  || Decoder Loss:  0.48530644 Validation Decoder Loss:  0.9843103
Encoder Loss:  0.3833538  || Decoder Loss:  0.4898766 Validation Decoder Loss:  0.9830646
Model: siamese_net_lr_0.09792239055683802 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9830646
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_71 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09906704  || Decoder Loss:  0.35583428 Validation Decoder Loss:  0.711981
Encoder Loss:  0.07919633  || Decoder Loss:  0.28721315 Validation Decoder Loss:  0.61436427
Encoder Loss:  0.07152126  || Decoder Loss:  0.23442309 Validation Decoder Loss:  0.55079365
Encoder Loss:  0.067588724  || Decoder Loss:  0.19942595 Validation Decoder Loss:  0.5108037
Encoder Loss:  0.06493543  || Decoder Loss:  0.17602462 Validation Decoder Loss:  0.484043
Encoder Loss:  0.06306443  || Decoder Loss:  0.15905514 Validation Decoder Loss:  0.4638576
Encoder Loss:  0.061587885  || Decoder Loss:  0.14542477 Validation Decoder Loss:  0.44762313
Encoder Loss:  0.06041842  || Decoder Loss:  0.13416466 Validation Decoder Loss:  0.43434542
Encoder Loss:  0.059463166  || Decoder Loss:  0.12487974 Validation Decoder Loss:  0.4235801
Encoder Loss:  0.058617145  || Decoder Loss:  0.11713584 Validation Decoder Loss:  0.4146152
Encoder Loss:  0.058008727  || Decoder Loss:  0.11056594 Validation Decoder Loss:  0.40728876
Encoder Loss:  0.057357192  || Decoder Loss:  0.10509196 Validation Decoder Loss:  0.4010331
Encoder Loss:  0.056908205  || Decoder Loss:  0.10022967 Validation Decoder Loss:  0.39561304
Encoder Loss:  0.056409616  || Decoder Loss:  0.09610561 Validation Decoder Loss:  0.39103937
Encoder Loss:  0.056089543  || Decoder Loss:  0.09238835 Validation Decoder Loss:  0.3869567
Encoder Loss:  0.055682536  || Decoder Loss:  0.08918548 Validation Decoder Loss:  0.38348722
Encoder Loss:  0.055457015  || Decoder Loss:  0.08629059 Validation Decoder Loss:  0.38036466
Encoder Loss:  0.055095397  || Decoder Loss:  0.08375958 Validation Decoder Loss:  0.37771565
Encoder Loss:  0.05498532  || Decoder Loss:  0.0814397 Validation Decoder Loss:  0.37535638
Encoder Loss:  0.054598507  || Decoder Loss:  0.079430416 Validation Decoder Loss:  0.37329683
Encoder Loss:  0.054552652  || Decoder Loss:  0.07752511 Validation Decoder Loss:  0.37141916
Encoder Loss:  0.05424324  || Decoder Loss:  0.07579076 Validation Decoder Loss:  0.36954948
Encoder Loss:  0.05418719  || Decoder Loss:  0.07413231 Validation Decoder Loss:  0.36798474
Encoder Loss:  0.053964168  || Decoder Loss:  0.07268095 Validation Decoder Loss:  0.36650467
Encoder Loss:  0.053779453  || Decoder Loss:  0.07127906 Validation Decoder Loss:  0.36506534
Encoder Loss:  0.05368097  || Decoder Loss:  0.069961034 Validation Decoder Loss:  0.36377478
Encoder Loss:  0.053497992  || Decoder Loss:  0.068757944 Validation Decoder Loss:  0.36261863
Encoder Loss:  0.053392116  || Decoder Loss:  0.06762812 Validation Decoder Loss:  0.36153847
Encoder Loss:  0.05334743  || Decoder Loss:  0.0665864 Validation Decoder Loss:  0.36060816
Encoder Loss:  0.05318366  || Decoder Loss:  0.065614834 Validation Decoder Loss:  0.35966986
Encoder Loss:  0.053030506  || Decoder Loss:  0.064667255 Validation Decoder Loss:  0.35878703
Encoder Loss:  0.05295679  || Decoder Loss:  0.06378769 Validation Decoder Loss:  0.358005
Encoder Loss:  0.052920375  || Decoder Loss:  0.06295671 Validation Decoder Loss:  0.35724315
Encoder Loss:  0.052748982  || Decoder Loss:  0.062155604 Validation Decoder Loss:  0.35650188
Encoder Loss:  0.052735135  || Decoder Loss:  0.06141386 Validation Decoder Loss:  0.35587192
Encoder Loss:  0.052600898  || Decoder Loss:  0.06069642 Validation Decoder Loss:  0.35523388
Encoder Loss:  0.05253841  || Decoder Loss:  0.060013838 Validation Decoder Loss:  0.354635
Encoder Loss:  0.05248343  || Decoder Loss:  0.05936148 Validation Decoder Loss:  0.35407645
Encoder Loss:  0.052390553  || Decoder Loss:  0.05873743 Validation Decoder Loss:  0.3535245
Encoder Loss:  0.05231835  || Decoder Loss:  0.058145657 Validation Decoder Loss:  0.35303843
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35303843
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_72 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22723334  || Decoder Loss:  0.49186203 Validation Decoder Loss:  0.8558476
Encoder Loss:  0.11869135  || Decoder Loss:  0.38015872 Validation Decoder Loss:  0.6903683
Encoder Loss:  0.08693047  || Decoder Loss:  0.29301572 Validation Decoder Loss:  0.58289576
Encoder Loss:  0.077864595  || Decoder Loss:  0.23611361 Validation Decoder Loss:  0.51694405
Encoder Loss:  0.07282366  || Decoder Loss:  0.19923449 Validation Decoder Loss:  0.47520202
Encoder Loss:  0.069451526  || Decoder Loss:  0.17432329 Validation Decoder Loss:  0.44736022
Encoder Loss:  0.06694023  || Decoder Loss:  0.15656175 Validation Decoder Loss:  0.4276132
Encoder Loss:  0.06529462  || Decoder Loss:  0.14334758 Validation Decoder Loss:  0.4133914
Encoder Loss:  0.06344878  || Decoder Loss:  0.13308676 Validation Decoder Loss:  0.40218902
Encoder Loss:  0.06228696  || Decoder Loss:  0.12479169 Validation Decoder Loss:  0.39344442
Encoder Loss:  0.061189465  || Decoder Loss:  0.117994756 Validation Decoder Loss:  0.3863924
Encoder Loss:  0.060491923  || Decoder Loss:  0.11232819 Validation Decoder Loss:  0.38081807
Encoder Loss:  0.05991934  || Decoder Loss:  0.10763075 Validation Decoder Loss:  0.3765229
Encoder Loss:  0.059127145  || Decoder Loss:  0.10361586 Validation Decoder Loss:  0.37287605
Encoder Loss:  0.05853026  || Decoder Loss:  0.10005476 Validation Decoder Loss:  0.3697405
Encoder Loss:  0.05803578  || Decoder Loss:  0.09690222 Validation Decoder Loss:  0.36712477
Encoder Loss:  0.057478298  || Decoder Loss:  0.09408656 Validation Decoder Loss:  0.36480224
Encoder Loss:  0.057037186  || Decoder Loss:  0.09151141 Validation Decoder Loss:  0.36271575
Encoder Loss:  0.056612838  || Decoder Loss:  0.08915269 Validation Decoder Loss:  0.36084196
Encoder Loss:  0.056308795  || Decoder Loss:  0.08697502 Validation Decoder Loss:  0.3591693
Encoder Loss:  0.055992655  || Decoder Loss:  0.08498737 Validation Decoder Loss:  0.35770366
Encoder Loss:  0.055668104  || Decoder Loss:  0.08312267 Validation Decoder Loss:  0.3562656
Encoder Loss:  0.055409923  || Decoder Loss:  0.08136767 Validation Decoder Loss:  0.35494912
Encoder Loss:  0.055182215  || Decoder Loss:  0.07972402 Validation Decoder Loss:  0.35374504
Encoder Loss:  0.05497403  || Decoder Loss:  0.078202866 Validation Decoder Loss:  0.35266972
Encoder Loss:  0.054797087  || Decoder Loss:  0.076785035 Validation Decoder Loss:  0.35173082
Encoder Loss:  0.054591134  || Decoder Loss:  0.075475685 Validation Decoder Loss:  0.3508757
Encoder Loss:  0.054399613  || Decoder Loss:  0.07419854 Validation Decoder Loss:  0.34995973
Encoder Loss:  0.054222614  || Decoder Loss:  0.07298795 Validation Decoder Loss:  0.3491232
Encoder Loss:  0.054084253  || Decoder Loss:  0.07184089 Validation Decoder Loss:  0.34835565
Encoder Loss:  0.053953003  || Decoder Loss:  0.07077651 Validation Decoder Loss:  0.34770912
Encoder Loss:  0.053810243  || Decoder Loss:  0.069771394 Validation Decoder Loss:  0.347093
Encoder Loss:  0.05367843  || Decoder Loss:  0.06881592 Validation Decoder Loss:  0.34652042
Encoder Loss:  0.053552013  || Decoder Loss:  0.06790639 Validation Decoder Loss:  0.34596902
Encoder Loss:  0.053415347  || Decoder Loss:  0.06702945 Validation Decoder Loss:  0.3454196
Encoder Loss:  0.053314827  || Decoder Loss:  0.066190064 Validation Decoder Loss:  0.34491748
Encoder Loss:  0.05321387  || Decoder Loss:  0.06539303 Validation Decoder Loss:  0.3444723
Encoder Loss:  0.053123947  || Decoder Loss:  0.06464409 Validation Decoder Loss:  0.34409976
Encoder Loss:  0.053011894  || Decoder Loss:  0.06392842 Validation Decoder Loss:  0.3437052
Encoder Loss:  0.052923523  || Decoder Loss:  0.06323311 Validation Decoder Loss:  0.3433373
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3433373
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_73 (Conv3DT (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_73 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.099988736  || Decoder Loss:  0.4628645 Validation Decoder Loss:  0.85877943
Encoder Loss:  0.082391664  || Decoder Loss:  0.3934174 Validation Decoder Loss:  0.74222904
Encoder Loss:  0.07568681  || Decoder Loss:  0.32031402 Validation Decoder Loss:  0.6498805
Encoder Loss:  0.07141003  || Decoder Loss:  0.26470166 Validation Decoder Loss:  0.58271325
Encoder Loss:  0.06797268  || Decoder Loss:  0.22274002 Validation Decoder Loss:  0.53619814
Encoder Loss:  0.06544483  || Decoder Loss:  0.19180046 Validation Decoder Loss:  0.5030775
Encoder Loss:  0.063482314  || Decoder Loss:  0.16863987 Validation Decoder Loss:  0.47892582
Encoder Loss:  0.06191197  || Decoder Loss:  0.15094388 Validation Decoder Loss:  0.4606974
Encoder Loss:  0.06059498  || Decoder Loss:  0.13704707 Validation Decoder Loss:  0.44654107
Encoder Loss:  0.059462294  || Decoder Loss:  0.12587517 Validation Decoder Loss:  0.43506068
Encoder Loss:  0.05846243  || Decoder Loss:  0.11672462 Validation Decoder Loss:  0.42577684
Encoder Loss:  0.057610523  || Decoder Loss:  0.109165505 Validation Decoder Loss:  0.4181667
Encoder Loss:  0.05685031  || Decoder Loss:  0.10276307 Validation Decoder Loss:  0.41177458
Encoder Loss:  0.056139536  || Decoder Loss:  0.097263746 Validation Decoder Loss:  0.406278
Encoder Loss:  0.05546093  || Decoder Loss:  0.09244108 Validation Decoder Loss:  0.40148678
Encoder Loss:  0.054807182  || Decoder Loss:  0.0880755 Validation Decoder Loss:  0.39705473
Encoder Loss:  0.05428294  || Decoder Loss:  0.084163524 Validation Decoder Loss:  0.39320683
Encoder Loss:  0.053884115  || Decoder Loss:  0.08075879 Validation Decoder Loss:  0.3898065
Encoder Loss:  0.053569894  || Decoder Loss:  0.07775925 Validation Decoder Loss:  0.3868351
Encoder Loss:  0.053323895  || Decoder Loss:  0.07511178 Validation Decoder Loss:  0.38424385
Encoder Loss:  0.053106632  || Decoder Loss:  0.07277663 Validation Decoder Loss:  0.3819617
Encoder Loss:  0.052935943  || Decoder Loss:  0.07070282 Validation Decoder Loss:  0.3799346
Encoder Loss:  0.052777693  || Decoder Loss:  0.06883414 Validation Decoder Loss:  0.3781075
Encoder Loss:  0.05263569  || Decoder Loss:  0.06713568 Validation Decoder Loss:  0.37644333
Encoder Loss:  0.05251292  || Decoder Loss:  0.065576695 Validation Decoder Loss:  0.3749411
Encoder Loss:  0.052392557  || Decoder Loss:  0.0641425 Validation Decoder Loss:  0.37355125
Encoder Loss:  0.05228737  || Decoder Loss:  0.06281454 Validation Decoder Loss:  0.37227148
Encoder Loss:  0.05218847  || Decoder Loss:  0.061578732 Validation Decoder Loss:  0.37109256
Encoder Loss:  0.052088708  || Decoder Loss:  0.060420774 Validation Decoder Loss:  0.3699885
Encoder Loss:  0.052003916  || Decoder Loss:  0.05934466 Validation Decoder Loss:  0.36898524
Encoder Loss:  0.051917166  || Decoder Loss:  0.058330517 Validation Decoder Loss:  0.3680309
Encoder Loss:  0.051840883  || Decoder Loss:  0.057376157 Validation Decoder Loss:  0.36714643
Encoder Loss:  0.051761508  || Decoder Loss:  0.056473438 Validation Decoder Loss:  0.36631203
Encoder Loss:  0.051691424  || Decoder Loss:  0.055624463 Validation Decoder Loss:  0.36553645
Encoder Loss:  0.05162306  || Decoder Loss:  0.054819003 Validation Decoder Loss:  0.36480138
Encoder Loss:  0.051559873  || Decoder Loss:  0.054055538 Validation Decoder Loss:  0.36411387
Encoder Loss:  0.051497154  || Decoder Loss:  0.05332957 Validation Decoder Loss:  0.3634662
Encoder Loss:  0.051437605  || Decoder Loss:  0.052638065 Validation Decoder Loss:  0.36283836
Encoder Loss:  0.051381845  || Decoder Loss:  0.051978387 Validation Decoder Loss:  0.3622611
Encoder Loss:  0.05132967  || Decoder Loss:  0.0513522 Validation Decoder Loss:  0.36170727
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36170727
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_74 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13367337  || Decoder Loss:  0.33449614 Validation Decoder Loss:  0.7533766
Encoder Loss:  0.093392685  || Decoder Loss:  0.28806248 Validation Decoder Loss:  0.6842499
Encoder Loss:  0.083739154  || Decoder Loss:  0.24197437 Validation Decoder Loss:  0.62273943
Encoder Loss:  0.07801281  || Decoder Loss:  0.20613812 Validation Decoder Loss:  0.5785444
Encoder Loss:  0.07389461  || Decoder Loss:  0.18020126 Validation Decoder Loss:  0.54660857
Encoder Loss:  0.07071235  || Decoder Loss:  0.16091298 Validation Decoder Loss:  0.5225334
Encoder Loss:  0.06837898  || Decoder Loss:  0.14609952 Validation Decoder Loss:  0.5039674
Encoder Loss:  0.06661678  || Decoder Loss:  0.1345098 Validation Decoder Loss:  0.48941737
Encoder Loss:  0.065238245  || Decoder Loss:  0.12527391 Validation Decoder Loss:  0.47789508
Encoder Loss:  0.064130366  || Decoder Loss:  0.11778138 Validation Decoder Loss:  0.46837327
Encoder Loss:  0.062973455  || Decoder Loss:  0.11148691 Validation Decoder Loss:  0.46021152
Encoder Loss:  0.06213008  || Decoder Loss:  0.10608613 Validation Decoder Loss:  0.45314193
Encoder Loss:  0.061318085  || Decoder Loss:  0.101412736 Validation Decoder Loss:  0.446952
Encoder Loss:  0.06068121  || Decoder Loss:  0.097332515 Validation Decoder Loss:  0.44151703
Encoder Loss:  0.060001556  || Decoder Loss:  0.093738034 Validation Decoder Loss:  0.43663335
Encoder Loss:  0.05953637  || Decoder Loss:  0.09054017 Validation Decoder Loss:  0.43232378
Encoder Loss:  0.058982752  || Decoder Loss:  0.08769484 Validation Decoder Loss:  0.42834926
Encoder Loss:  0.05847467  || Decoder Loss:  0.08508252 Validation Decoder Loss:  0.4246383
Encoder Loss:  0.058279842  || Decoder Loss:  0.08273194 Validation Decoder Loss:  0.42145693
Encoder Loss:  0.057744924  || Decoder Loss:  0.08063971 Validation Decoder Loss:  0.41843718
Encoder Loss:  0.057622027  || Decoder Loss:  0.07870164 Validation Decoder Loss:  0.4157988
Encoder Loss:  0.057175353  || Decoder Loss:  0.07696636 Validation Decoder Loss:  0.413288
Encoder Loss:  0.05688597  || Decoder Loss:  0.07531733 Validation Decoder Loss:  0.4108879
Encoder Loss:  0.05668041  || Decoder Loss:  0.07379324 Validation Decoder Loss:  0.4087064
Encoder Loss:  0.056423455  || Decoder Loss:  0.07239167 Validation Decoder Loss:  0.40666363
Encoder Loss:  0.05616864  || Decoder Loss:  0.071077034 Validation Decoder Loss:  0.40471417
Encoder Loss:  0.055973224  || Decoder Loss:  0.06983619 Validation Decoder Loss:  0.40286958
Encoder Loss:  0.05579906  || Decoder Loss:  0.06868406 Validation Decoder Loss:  0.40120542
Encoder Loss:  0.055630077  || Decoder Loss:  0.067619525 Validation Decoder Loss:  0.39964694
Encoder Loss:  0.055399906  || Decoder Loss:  0.06660804 Validation Decoder Loss:  0.3981249
Encoder Loss:  0.05531217  || Decoder Loss:  0.06565019 Validation Decoder Loss:  0.39673153
Encoder Loss:  0.055058736  || Decoder Loss:  0.06474942 Validation Decoder Loss:  0.3953597
Encoder Loss:  0.055043057  || Decoder Loss:  0.063893154 Validation Decoder Loss:  0.39414424
Encoder Loss:  0.0547478  || Decoder Loss:  0.063091725 Validation Decoder Loss:  0.39288956
Encoder Loss:  0.05466678  || Decoder Loss:  0.06230042 Validation Decoder Loss:  0.39168534
Encoder Loss:  0.054591015  || Decoder Loss:  0.06155874 Validation Decoder Loss:  0.39059305
Encoder Loss:  0.054406587  || Decoder Loss:  0.060861167 Validation Decoder Loss:  0.38954034
Encoder Loss:  0.054333963  || Decoder Loss:  0.060189474 Validation Decoder Loss:  0.38852936
Encoder Loss:  0.054169428  || Decoder Loss:  0.05954686 Validation Decoder Loss:  0.3875413
Encoder Loss:  0.054080114  || Decoder Loss:  0.05892742 Validation Decoder Loss:  0.38662165
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38662165
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 194, 5, 20, 1)     6         
_________________________________________________________________
reshape_75 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 6
Trainable params: 6
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 970, 20, 1)        2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 3245, 20, 1)       1308      
=================================================================
Total params: 1,308
Trainable params: 1,308
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.59116346  || Decoder Loss:  0.90111345 Validation Decoder Loss:  1.6373599
Encoder Loss:  0.60010916  || Decoder Loss:  0.9143031 Validation Decoder Loss:  1.6286802
Encoder Loss:  0.5965781  || Decoder Loss:  0.904047 Validation Decoder Loss:  1.587723
Encoder Loss:  0.5683567  || Decoder Loss:  0.81816185 Validation Decoder Loss:  1.2572696
Encoder Loss:  0.45193654  || Decoder Loss:  0.46099484 Validation Decoder Loss:  0.631217
Encoder Loss:  0.3597525  || Decoder Loss:  0.17970714 Validation Decoder Loss:  0.40967637
Encoder Loss:  0.33125275  || Decoder Loss:  0.0971821 Validation Decoder Loss:  0.35407716
Encoder Loss:  0.32026336  || Decoder Loss:  0.07713425 Validation Decoder Loss:  0.34142685
Encoder Loss:  0.3828804  || Decoder Loss:  0.38139778 Validation Decoder Loss:  1.6581153
Encoder Loss:  0.58625406  || Decoder Loss:  0.9238551 Validation Decoder Loss:  1.6559411
Encoder Loss:  0.38236874  || Decoder Loss:  0.4453912 Validation Decoder Loss:  0.34094024
Encoder Loss:  0.30100727  || Decoder Loss:  0.5046414 Validation Decoder Loss:  0.34847778
Encoder Loss:  0.23318963  || Decoder Loss:  0.3924569 Validation Decoder Loss:  0.348491
Encoder Loss:  0.27164513  || Decoder Loss:  0.50501615 Validation Decoder Loss:  0.3457452
Encoder Loss:  0.18261571  || Decoder Loss:  0.35103276 Validation Decoder Loss:  0.3473842
Encoder Loss:  0.10798687  || Decoder Loss:  0.16838658 Validation Decoder Loss:  0.36782524
Encoder Loss:  0.08802724  || Decoder Loss:  0.06337021 Validation Decoder Loss:  0.35394764
Encoder Loss:  0.0580881  || Decoder Loss:  0.03220717 Validation Decoder Loss:  0.35190833
Encoder Loss:  0.058630824  || Decoder Loss:  0.031525105 Validation Decoder Loss:  0.35413283
Encoder Loss:  0.052472934  || Decoder Loss:  0.030147197 Validation Decoder Loss:  0.35908014
Encoder Loss:  0.06468974  || Decoder Loss:  0.030477423 Validation Decoder Loss:  0.34929326
Encoder Loss:  0.06282157  || Decoder Loss:  0.030284276 Validation Decoder Loss:  0.3535567
Encoder Loss:  0.059036884  || Decoder Loss:  0.030346237 Validation Decoder Loss:  0.35426566
Encoder Loss:  0.056201745  || Decoder Loss:  0.030209906 Validation Decoder Loss:  0.35129556
Encoder Loss:  0.05187151  || Decoder Loss:  0.030004058 Validation Decoder Loss:  0.35444593
Encoder Loss:  0.053765163  || Decoder Loss:  0.030007746 Validation Decoder Loss:  0.3519697
Encoder Loss:  0.059663843  || Decoder Loss:  0.030407948 Validation Decoder Loss:  0.35010216
Encoder Loss:  0.060592312  || Decoder Loss:  0.030242143 Validation Decoder Loss:  0.35359824
Encoder Loss:  0.05502303  || Decoder Loss:  0.03014735 Validation Decoder Loss:  0.35474268
Encoder Loss:  0.056063958  || Decoder Loss:  0.030346146 Validation Decoder Loss:  0.34967607
Encoder Loss:  0.059707716  || Decoder Loss:  0.030377837 Validation Decoder Loss:  0.355125
Encoder Loss:  0.053778566  || Decoder Loss:  0.030160341 Validation Decoder Loss:  0.35408342
Encoder Loss:  0.058769684  || Decoder Loss:  0.0302611 Validation Decoder Loss:  0.35017747
Encoder Loss:  0.04933447  || Decoder Loss:  0.0299884 Validation Decoder Loss:  0.35704708
Encoder Loss:  0.05484368  || Decoder Loss:  0.030382035 Validation Decoder Loss:  0.3498804
Encoder Loss:  0.057496842  || Decoder Loss:  0.030366112 Validation Decoder Loss:  0.36381167
Encoder Loss:  0.05812718  || Decoder Loss:  0.030394603 Validation Decoder Loss:  0.3538955
Encoder Loss:  0.054540634  || Decoder Loss:  0.030233385 Validation Decoder Loss:  0.35480732
Encoder Loss:  0.057657484  || Decoder Loss:  0.03036334 Validation Decoder Loss:  0.35516375
Encoder Loss:  0.053881224  || Decoder Loss:  0.030232558 Validation Decoder Loss:  0.35110953
Model: siamese_net_lr_0.01937941823336488 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35110953
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_76 (Conv3DT (None, 194, 5, 20, 1)     69        
_________________________________________________________________
reshape_76 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 69
Trainable params: 69
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 970, 20, 1)        339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 3245, 20, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33240756  || Decoder Loss:  0.09779883 Validation Decoder Loss:  0.35435516
Encoder Loss:  0.31619596  || Decoder Loss:  0.040748592 Validation Decoder Loss:  0.35716558
Encoder Loss:  0.2858943  || Decoder Loss:  0.36795464 Validation Decoder Loss:  0.43204433
Encoder Loss:  0.10339866  || Decoder Loss:  0.1379417 Validation Decoder Loss:  0.33508822
Encoder Loss:  0.05363665  || Decoder Loss:  0.0375139 Validation Decoder Loss:  0.35421944
Encoder Loss:  0.05418076  || Decoder Loss:  0.0344495 Validation Decoder Loss:  0.3491361
Encoder Loss:  0.05342685  || Decoder Loss:  0.03392372 Validation Decoder Loss:  0.3471321
Encoder Loss:  0.04782133  || Decoder Loss:  0.03382694 Validation Decoder Loss:  0.3474935
Encoder Loss:  0.051419076  || Decoder Loss:  0.033786513 Validation Decoder Loss:  0.34730187
Encoder Loss:  0.051686052  || Decoder Loss:  0.033750027 Validation Decoder Loss:  0.346385
Encoder Loss:  0.050981402  || Decoder Loss:  0.033713676 Validation Decoder Loss:  0.34538868
Encoder Loss:  0.061417736  || Decoder Loss:  0.03373267 Validation Decoder Loss:  0.3473963
Encoder Loss:  0.057374448  || Decoder Loss:  0.033650335 Validation Decoder Loss:  0.3445832
Encoder Loss:  0.055194303  || Decoder Loss:  0.033667125 Validation Decoder Loss:  0.347481
Encoder Loss:  0.053496517  || Decoder Loss:  0.033602085 Validation Decoder Loss:  0.34700274
Encoder Loss:  0.05005394  || Decoder Loss:  0.03359706 Validation Decoder Loss:  0.3467409
Encoder Loss:  0.05135883  || Decoder Loss:  0.033549294 Validation Decoder Loss:  0.34423798
Encoder Loss:  0.05142556  || Decoder Loss:  0.03358425 Validation Decoder Loss:  0.34707758
Encoder Loss:  0.05022008  || Decoder Loss:  0.03354746 Validation Decoder Loss:  0.34642342
Encoder Loss:  0.048567485  || Decoder Loss:  0.03354415 Validation Decoder Loss:  0.3454164
Encoder Loss:  0.05460101  || Decoder Loss:  0.03356836 Validation Decoder Loss:  0.34862566
Encoder Loss:  0.048765574  || Decoder Loss:  0.0335332 Validation Decoder Loss:  0.3461645
Encoder Loss:  0.048955593  || Decoder Loss:  0.033532135 Validation Decoder Loss:  0.3477763
Encoder Loss:  0.05174439  || Decoder Loss:  0.03355214 Validation Decoder Loss:  0.34692684
Encoder Loss:  0.047127604  || Decoder Loss:  0.033572424 Validation Decoder Loss:  0.34620535
Encoder Loss:  0.047300607  || Decoder Loss:  0.0336359 Validation Decoder Loss:  0.3469754
Encoder Loss:  0.048806306  || Decoder Loss:  0.033732906 Validation Decoder Loss:  0.34685576
Encoder Loss:  0.04860139  || Decoder Loss:  0.033853922 Validation Decoder Loss:  0.34727907
Encoder Loss:  0.051866904  || Decoder Loss:  0.03388969 Validation Decoder Loss:  0.34719503
Encoder Loss:  0.04826942  || Decoder Loss:  0.033842143 Validation Decoder Loss:  0.34843457
Encoder Loss:  0.050078478  || Decoder Loss:  0.033926595 Validation Decoder Loss:  0.34566176
Encoder Loss:  0.056618705  || Decoder Loss:  0.03411298 Validation Decoder Loss:  0.34663343
Encoder Loss:  0.05517503  || Decoder Loss:  0.034525692 Validation Decoder Loss:  0.34956804
Encoder Loss:  0.049468637  || Decoder Loss:  0.03410123 Validation Decoder Loss:  0.3474928
Encoder Loss:  0.049255718  || Decoder Loss:  0.03421159 Validation Decoder Loss:  0.34575194
Encoder Loss:  0.05448471  || Decoder Loss:  0.034225978 Validation Decoder Loss:  0.34733775
Encoder Loss:  0.048563533  || Decoder Loss:  0.0341766 Validation Decoder Loss:  0.34866393
Encoder Loss:  0.0485822  || Decoder Loss:  0.034387413 Validation Decoder Loss:  0.3475945
Encoder Loss:  0.048089474  || Decoder Loss:  0.03432332 Validation Decoder Loss:  0.34714293
Encoder Loss:  0.049560767  || Decoder Loss:  0.03425053 Validation Decoder Loss:  0.34912127
Model: siamese_net_lr_0.02056312080326411 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34912127
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_77 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.094062865  || Decoder Loss:  0.086585484 Validation Decoder Loss:  0.3428015
Encoder Loss:  0.07507378  || Decoder Loss:  0.039472703 Validation Decoder Loss:  0.34354067
Encoder Loss:  0.07623113  || Decoder Loss:  0.038030434 Validation Decoder Loss:  0.3443939
Encoder Loss:  0.073005505  || Decoder Loss:  0.037218776 Validation Decoder Loss:  0.34479153
Encoder Loss:  0.072295025  || Decoder Loss:  0.036574215 Validation Decoder Loss:  0.3449654
Encoder Loss:  0.058511462  || Decoder Loss:  0.03604527 Validation Decoder Loss:  0.34491643
Encoder Loss:  0.076999806  || Decoder Loss:  0.035611704 Validation Decoder Loss:  0.3447087
Encoder Loss:  0.077412516  || Decoder Loss:  0.03525248 Validation Decoder Loss:  0.34490657
Encoder Loss:  0.0684697  || Decoder Loss:  0.03495054 Validation Decoder Loss:  0.34505373
Encoder Loss:  0.06856727  || Decoder Loss:  0.034706865 Validation Decoder Loss:  0.34552956
Encoder Loss:  0.07645633  || Decoder Loss:  0.034500714 Validation Decoder Loss:  0.34536833
Encoder Loss:  0.062162805  || Decoder Loss:  0.034334928 Validation Decoder Loss:  0.34552896
Encoder Loss:  0.05927371  || Decoder Loss:  0.034181517 Validation Decoder Loss:  0.34564286
Encoder Loss:  0.06609237  || Decoder Loss:  0.034053728 Validation Decoder Loss:  0.34607258
Encoder Loss:  0.080059566  || Decoder Loss:  0.033952337 Validation Decoder Loss:  0.34537792
Encoder Loss:  0.06264  || Decoder Loss:  0.033886217 Validation Decoder Loss:  0.3461182
Encoder Loss:  0.06924471  || Decoder Loss:  0.03379662 Validation Decoder Loss:  0.3461355
Encoder Loss:  0.059618745  || Decoder Loss:  0.033731285 Validation Decoder Loss:  0.34596732
Encoder Loss:  0.058010012  || Decoder Loss:  0.03366479 Validation Decoder Loss:  0.34641638
Encoder Loss:  0.060967598  || Decoder Loss:  0.033615842 Validation Decoder Loss:  0.34585518
Encoder Loss:  0.05979772  || Decoder Loss:  0.033567995 Validation Decoder Loss:  0.34602243
Encoder Loss:  0.059189513  || Decoder Loss:  0.033519287 Validation Decoder Loss:  0.34621802
Encoder Loss:  0.06489609  || Decoder Loss:  0.03348984 Validation Decoder Loss:  0.3460251
Encoder Loss:  0.07043748  || Decoder Loss:  0.03344703 Validation Decoder Loss:  0.34652737
Encoder Loss:  0.0802052  || Decoder Loss:  0.03339967 Validation Decoder Loss:  0.34640983
Encoder Loss:  0.06493463  || Decoder Loss:  0.033375874 Validation Decoder Loss:  0.34610495
Encoder Loss:  0.057716627  || Decoder Loss:  0.033355255 Validation Decoder Loss:  0.34621137
Encoder Loss:  0.05741246  || Decoder Loss:  0.03332945 Validation Decoder Loss:  0.34624803
Encoder Loss:  0.061773304  || Decoder Loss:  0.033305973 Validation Decoder Loss:  0.3462563
Encoder Loss:  0.061474413  || Decoder Loss:  0.033289943 Validation Decoder Loss:  0.34641352
Encoder Loss:  0.061272968  || Decoder Loss:  0.03326748 Validation Decoder Loss:  0.34634358
Encoder Loss:  0.054748107  || Decoder Loss:  0.033241462 Validation Decoder Loss:  0.34650207
Encoder Loss:  0.06222955  || Decoder Loss:  0.033231184 Validation Decoder Loss:  0.34645778
Encoder Loss:  0.05580941  || Decoder Loss:  0.03321033 Validation Decoder Loss:  0.34651324
Encoder Loss:  0.05741891  || Decoder Loss:  0.033191774 Validation Decoder Loss:  0.34614408
Encoder Loss:  0.05581488  || Decoder Loss:  0.03318336 Validation Decoder Loss:  0.3463848
Encoder Loss:  0.05328088  || Decoder Loss:  0.033166043 Validation Decoder Loss:  0.34622723
Encoder Loss:  0.05537207  || Decoder Loss:  0.03316002 Validation Decoder Loss:  0.34628147
Encoder Loss:  0.0550694  || Decoder Loss:  0.033144068 Validation Decoder Loss:  0.34635836
Encoder Loss:  0.053235408  || Decoder Loss:  0.03313709 Validation Decoder Loss:  0.34628153
Model: siamese_net_lr_0.0012268407448616109 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34628153
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 194, 5, 20, 1)     6         
_________________________________________________________________
reshape_78 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 6
Trainable params: 6
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 970, 20, 1)        339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 3245, 20, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46702203  || Decoder Loss:  0.5242929 Validation Decoder Loss:  0.48539317
Encoder Loss:  0.32377872  || Decoder Loss:  0.06874538 Validation Decoder Loss:  0.35335588
Encoder Loss:  0.31375518  || Decoder Loss:  0.03846636 Validation Decoder Loss:  0.3503378
Encoder Loss:  0.31340504  || Decoder Loss:  0.037855927 Validation Decoder Loss:  0.3504952
Encoder Loss:  0.31315944  || Decoder Loss:  0.03781351 Validation Decoder Loss:  0.3505084
Encoder Loss:  0.31275848  || Decoder Loss:  0.037774347 Validation Decoder Loss:  0.35060138
Encoder Loss:  0.31183666  || Decoder Loss:  0.03773774 Validation Decoder Loss:  0.3507227
Encoder Loss:  0.3053316  || Decoder Loss:  0.03769483 Validation Decoder Loss:  0.35085183
Encoder Loss:  0.31100142  || Decoder Loss:  0.03764386 Validation Decoder Loss:  0.35098004
Encoder Loss:  0.30947354  || Decoder Loss:  0.03758018 Validation Decoder Loss:  0.3511228
Encoder Loss:  0.30133197  || Decoder Loss:  0.03759961 Validation Decoder Loss:  0.35181507
Encoder Loss:  0.23703958  || Decoder Loss:  0.23429565 Validation Decoder Loss:  1.634394
Encoder Loss:  0.25648472  || Decoder Loss:  0.35884553 Validation Decoder Loss:  0.35523838
Encoder Loss:  0.19298589  || Decoder Loss:  0.12043394 Validation Decoder Loss:  1.3474531
Encoder Loss:  0.1686067  || Decoder Loss:  0.23983698 Validation Decoder Loss:  0.3550867
Encoder Loss:  0.1285325  || Decoder Loss:  0.09779858 Validation Decoder Loss:  0.35793322
Encoder Loss:  0.09807957  || Decoder Loss:  0.05893029 Validation Decoder Loss:  0.34714872
Encoder Loss:  0.06689321  || Decoder Loss:  0.033844016 Validation Decoder Loss:  0.34703815
Encoder Loss:  0.057584263  || Decoder Loss:  0.033573493 Validation Decoder Loss:  0.34699488
Encoder Loss:  0.07187114  || Decoder Loss:  0.033707477 Validation Decoder Loss:  0.34723875
Encoder Loss:  0.06352322  || Decoder Loss:  0.033457845 Validation Decoder Loss:  0.34744877
Encoder Loss:  0.091902226  || Decoder Loss:  0.03352672 Validation Decoder Loss:  0.347515
Encoder Loss:  0.059508957  || Decoder Loss:  0.033393856 Validation Decoder Loss:  0.34775048
Encoder Loss:  0.056112174  || Decoder Loss:  0.033373684 Validation Decoder Loss:  0.34802037
Encoder Loss:  0.057644814  || Decoder Loss:  0.033356868 Validation Decoder Loss:  0.3477933
Encoder Loss:  0.057613764  || Decoder Loss:  0.033350483 Validation Decoder Loss:  0.347804
Encoder Loss:  0.049430825  || Decoder Loss:  0.033341315 Validation Decoder Loss:  0.34784067
Encoder Loss:  0.056761228  || Decoder Loss:  0.033317238 Validation Decoder Loss:  0.34803265
Encoder Loss:  0.06387058  || Decoder Loss:  0.03337617 Validation Decoder Loss:  0.34761244
Encoder Loss:  0.05371886  || Decoder Loss:  0.033348847 Validation Decoder Loss:  0.34814993
Encoder Loss:  0.05981842  || Decoder Loss:  0.03335144 Validation Decoder Loss:  0.34756264
Encoder Loss:  0.059050888  || Decoder Loss:  0.0333405 Validation Decoder Loss:  0.3477122
Encoder Loss:  0.059600677  || Decoder Loss:  0.033370428 Validation Decoder Loss:  0.34822208
Encoder Loss:  0.06333087  || Decoder Loss:  0.033338893 Validation Decoder Loss:  0.34809226
Encoder Loss:  0.04929761  || Decoder Loss:  0.033339683 Validation Decoder Loss:  0.34792343
Encoder Loss:  0.055166278  || Decoder Loss:  0.033348702 Validation Decoder Loss:  0.3477482
Encoder Loss:  0.05384939  || Decoder Loss:  0.0333333 Validation Decoder Loss:  0.34793693
Encoder Loss:  0.05704521  || Decoder Loss:  0.03334205 Validation Decoder Loss:  0.34751278
Encoder Loss:  0.05812914  || Decoder Loss:  0.033348057 Validation Decoder Loss:  0.34776658
Encoder Loss:  0.061862484  || Decoder Loss:  0.03336544 Validation Decoder Loss:  0.34788656
Model: siamese_net_lr_0.03158369754802169 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34788656
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_79 (Conv3DT (None, 102, 10, 20, 1)    235       
_________________________________________________________________
reshape_79 (Reshape)         (None, 1020, 20, 1)       0         
=================================================================
Total params: 235
Trainable params: 235
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 1020, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 3245, 20, 1)       2227      
=================================================================
Total params: 2,227
Trainable params: 2,227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6464563  || Decoder Loss:  0.91208357 Validation Decoder Loss:  1.631272
Encoder Loss:  0.65954226  || Decoder Loss:  0.9257667 Validation Decoder Loss:  1.6295643
Encoder Loss:  0.6575927  || Decoder Loss:  0.922835 Validation Decoder Loss:  1.6269574
Encoder Loss:  0.65494746  || Decoder Loss:  0.91887605 Validation Decoder Loss:  1.6231408
Encoder Loss:  0.6514565  || Decoder Loss:  0.91365886 Validation Decoder Loss:  1.6176564
Encoder Loss:  0.64687806  || Decoder Loss:  0.906839 Validation Decoder Loss:  1.609829
Encoder Loss:  0.64081836  || Decoder Loss:  0.89787817 Validation Decoder Loss:  1.5986279
Encoder Loss:  0.63259846  || Decoder Loss:  0.88590723 Validation Decoder Loss:  1.5823851
Encoder Loss:  0.6209099  || Decoder Loss:  0.8694177 Validation Decoder Loss:  1.5581362
Encoder Loss:  0.6026457  || Decoder Loss:  0.8454419 Validation Decoder Loss:  1.5196707
Encoder Loss:  0.5654771  || Decoder Loss:  0.8059571 Validation Decoder Loss:  1.4434186
Encoder Loss:  0.32841113  || Decoder Loss:  0.5106438 Validation Decoder Loss:  0.84071136
Encoder Loss:  0.26076296  || Decoder Loss:  0.46382973 Validation Decoder Loss:  0.7210438
Encoder Loss:  0.25457385  || Decoder Loss:  0.44396445 Validation Decoder Loss:  0.81307304
Encoder Loss:  0.25526598  || Decoder Loss:  0.4593295 Validation Decoder Loss:  0.75713634
Encoder Loss:  0.24280158  || Decoder Loss:  0.45710656 Validation Decoder Loss:  0.71873665
Encoder Loss:  0.22866848  || Decoder Loss:  0.41833222 Validation Decoder Loss:  0.7739172
Encoder Loss:  0.23567794  || Decoder Loss:  0.4416283 Validation Decoder Loss:  0.72753686
Encoder Loss:  0.2372235  || Decoder Loss:  0.45593837 Validation Decoder Loss:  0.715673
Encoder Loss:  0.26406622  || Decoder Loss:  0.5136522 Validation Decoder Loss:  0.726148
Encoder Loss:  0.20617238  || Decoder Loss:  0.38670504 Validation Decoder Loss:  0.75255233
Encoder Loss:  0.20651704  || Decoder Loss:  0.39210424 Validation Decoder Loss:  0.70611644
Encoder Loss:  0.23067482  || Decoder Loss:  0.44459015 Validation Decoder Loss:  0.7019404
Encoder Loss:  0.23937172  || Decoder Loss:  0.46181962 Validation Decoder Loss:  0.67336243
Encoder Loss:  0.20607443  || Decoder Loss:  0.38808468 Validation Decoder Loss:  0.6700863
Encoder Loss:  0.22884254  || Decoder Loss:  0.43328267 Validation Decoder Loss:  0.59825516
Encoder Loss:  0.21075282  || Decoder Loss:  0.39973205 Validation Decoder Loss:  0.73890835
Encoder Loss:  0.21723132  || Decoder Loss:  0.4165525 Validation Decoder Loss:  0.68388796
Encoder Loss:  0.22058928  || Decoder Loss:  0.4236879 Validation Decoder Loss:  0.70113516
Encoder Loss:  0.21298845  || Decoder Loss:  0.40693763 Validation Decoder Loss:  0.67361224
Encoder Loss:  0.21571916  || Decoder Loss:  0.41219917 Validation Decoder Loss:  0.66772723
Encoder Loss:  0.2098959  || Decoder Loss:  0.39961216 Validation Decoder Loss:  0.69213104
Encoder Loss:  0.22269638  || Decoder Loss:  0.4293763 Validation Decoder Loss:  0.71741796
Encoder Loss:  0.2249896  || Decoder Loss:  0.43149307 Validation Decoder Loss:  0.6658319
Encoder Loss:  0.1972854  || Decoder Loss:  0.37221652 Validation Decoder Loss:  0.69406414
Encoder Loss:  0.16852327  || Decoder Loss:  0.3084605 Validation Decoder Loss:  1.0825274
Encoder Loss:  0.19640484  || Decoder Loss:  0.3702871 Validation Decoder Loss:  0.70563424
Encoder Loss:  0.13317002  || Decoder Loss:  0.23171109 Validation Decoder Loss:  0.6861634
Encoder Loss:  0.12869082  || Decoder Loss:  0.22144833 Validation Decoder Loss:  0.9077718
Encoder Loss:  0.17497997  || Decoder Loss:  0.32386318 Validation Decoder Loss:  0.60803616
Model: siamese_net_lr_0.0762513378524695 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.60803616
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_80 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45899367  || Decoder Loss:  0.8916242 Validation Decoder Loss:  1.6377187
Encoder Loss:  0.47369164  || Decoder Loss:  0.9074753 Validation Decoder Loss:  1.635031
Encoder Loss:  0.47431853  || Decoder Loss:  0.90560985 Validation Decoder Loss:  1.6314334
Encoder Loss:  0.4733609  || Decoder Loss:  0.9031769 Validation Decoder Loss:  1.6267715
Encoder Loss:  0.47211024  || Decoder Loss:  0.90002817 Validation Decoder Loss:  1.6205804
Encoder Loss:  0.47049  || Decoder Loss:  0.89564097 Validation Decoder Loss:  1.6113168
Encoder Loss:  0.46828383  || Decoder Loss:  0.88803786 Validation Decoder Loss:  1.5929502
Encoder Loss:  0.46477535  || Decoder Loss:  0.8686935 Validation Decoder Loss:  1.5387493
Encoder Loss:  0.45721745  || Decoder Loss:  0.8008712 Validation Decoder Loss:  1.3436555
Encoder Loss:  0.4390603  || Decoder Loss:  0.59536475 Validation Decoder Loss:  0.88975453
Encoder Loss:  0.41306797  || Decoder Loss:  0.30587482 Validation Decoder Loss:  0.51473296
Encoder Loss:  0.39140767  || Decoder Loss:  0.14785473 Validation Decoder Loss:  0.38594925
Encoder Loss:  0.3594668  || Decoder Loss:  0.10495964 Validation Decoder Loss:  0.3767019
Encoder Loss:  0.20432566  || Decoder Loss:  0.42092758 Validation Decoder Loss:  1.0697768
Encoder Loss:  0.11544399  || Decoder Loss:  0.4244775 Validation Decoder Loss:  1.2217367
Encoder Loss:  0.115851514  || Decoder Loss:  0.43165362 Validation Decoder Loss:  1.276279
Encoder Loss:  0.11810112  || Decoder Loss:  0.43098325 Validation Decoder Loss:  1.2939079
Encoder Loss:  0.11979103  || Decoder Loss:  0.42829838 Validation Decoder Loss:  1.2884672
Encoder Loss:  0.11948423  || Decoder Loss:  0.42548075 Validation Decoder Loss:  1.267108
Encoder Loss:  0.12005867  || Decoder Loss:  0.42655328 Validation Decoder Loss:  1.2286992
Encoder Loss:  0.11517266  || Decoder Loss:  0.42380646 Validation Decoder Loss:  1.2501477
Encoder Loss:  0.11393611  || Decoder Loss:  0.42459714 Validation Decoder Loss:  1.2787677
Encoder Loss:  0.11952808  || Decoder Loss:  0.42765614 Validation Decoder Loss:  1.2017595
Encoder Loss:  0.112072095  || Decoder Loss:  0.42162287 Validation Decoder Loss:  1.2816
Encoder Loss:  0.1161985  || Decoder Loss:  0.42211598 Validation Decoder Loss:  1.2338716
Encoder Loss:  0.11260199  || Decoder Loss:  0.41984308 Validation Decoder Loss:  1.2987018
Encoder Loss:  0.116448335  || Decoder Loss:  0.4279443 Validation Decoder Loss:  1.2116157
Encoder Loss:  0.10924792  || Decoder Loss:  0.41868493 Validation Decoder Loss:  1.2934265
Encoder Loss:  0.112344764  || Decoder Loss:  0.4192668 Validation Decoder Loss:  1.261737
Encoder Loss:  0.10933567  || Decoder Loss:  0.41441587 Validation Decoder Loss:  1.2773063
Encoder Loss:  0.107909516  || Decoder Loss:  0.41593283 Validation Decoder Loss:  1.3211473
Encoder Loss:  0.112339936  || Decoder Loss:  0.41678283 Validation Decoder Loss:  1.2249608
Encoder Loss:  0.10419703  || Decoder Loss:  0.4062117 Validation Decoder Loss:  1.3093872
Encoder Loss:  0.100294866  || Decoder Loss:  0.37890273 Validation Decoder Loss:  1.0649409
Encoder Loss:  0.0864902  || Decoder Loss:  0.33707187 Validation Decoder Loss:  1.3171003
Encoder Loss:  0.083361596  || Decoder Loss:  0.415056 Validation Decoder Loss:  1.1350954
Encoder Loss:  0.07965227  || Decoder Loss:  0.38036427 Validation Decoder Loss:  1.1705897
Encoder Loss:  0.081465416  || Decoder Loss:  0.42030898 Validation Decoder Loss:  1.2929237
Encoder Loss:  0.088921785  || Decoder Loss:  0.50865877 Validation Decoder Loss:  0.959698
Encoder Loss:  0.08348442  || Decoder Loss:  0.48310304 Validation Decoder Loss:  0.96857846
Model: siamese_net_lr_0.08311924501518449 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.96857846
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 194, 5, 20, 1)     132       
_________________________________________________________________
reshape_81 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 132
Trainable params: 132
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 970, 20, 1)        2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 3245, 20, 1)       1308      
=================================================================
Total params: 1,308
Trainable params: 1,308
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5724515  || Decoder Loss:  0.8977413 Validation Decoder Loss:  1.6313219
Encoder Loss:  0.5781435  || Decoder Loss:  0.9057385 Validation Decoder Loss:  1.6238685
Encoder Loss:  0.57268965  || Decoder Loss:  0.89870965 Validation Decoder Loss:  1.6106174
Encoder Loss:  0.5575234  || Decoder Loss:  0.8832054 Validation Decoder Loss:  1.5717877
Encoder Loss:  0.357998  || Decoder Loss:  0.6086338 Validation Decoder Loss:  1.0367134
Encoder Loss:  0.20174819  || Decoder Loss:  0.46129742 Validation Decoder Loss:  0.86021805
Encoder Loss:  0.18650028  || Decoder Loss:  0.4736373 Validation Decoder Loss:  0.7244114
Encoder Loss:  0.18129864  || Decoder Loss:  0.45465243 Validation Decoder Loss:  0.686161
Encoder Loss:  0.16048539  || Decoder Loss:  0.38104802 Validation Decoder Loss:  1.0797238
Encoder Loss:  0.08994316  || Decoder Loss:  0.13915582 Validation Decoder Loss:  0.50270855
Encoder Loss:  0.06424061  || Decoder Loss:  0.0693025 Validation Decoder Loss:  0.36262792
Encoder Loss:  0.05620113  || Decoder Loss:  0.04679326 Validation Decoder Loss:  0.33305353
Encoder Loss:  0.056004003  || Decoder Loss:  0.039574448 Validation Decoder Loss:  0.35999072
Encoder Loss:  0.05297038  || Decoder Loss:  0.037232015 Validation Decoder Loss:  0.35098597
Encoder Loss:  0.059229273  || Decoder Loss:  0.038781572 Validation Decoder Loss:  0.34921598
Encoder Loss:  0.053942867  || Decoder Loss:  0.037377402 Validation Decoder Loss:  0.3669464
Encoder Loss:  0.054564387  || Decoder Loss:  0.03703895 Validation Decoder Loss:  0.37234294
Encoder Loss:  0.06592942  || Decoder Loss:  0.039574698 Validation Decoder Loss:  0.33807686
Encoder Loss:  0.05256947  || Decoder Loss:  0.040459022 Validation Decoder Loss:  0.3408854
Encoder Loss:  0.05539979  || Decoder Loss:  0.038723525 Validation Decoder Loss:  0.37967232
Encoder Loss:  0.051836442  || Decoder Loss:  0.038299352 Validation Decoder Loss:  0.33657634
Encoder Loss:  0.048616424  || Decoder Loss:  0.0388508 Validation Decoder Loss:  0.36326307
Encoder Loss:  0.05132451  || Decoder Loss:  0.035818327 Validation Decoder Loss:  0.33492166
Encoder Loss:  0.050355386  || Decoder Loss:  0.036579505 Validation Decoder Loss:  0.35843748
Encoder Loss:  0.052752458  || Decoder Loss:  0.036025256 Validation Decoder Loss:  0.33489037
Encoder Loss:  0.05127078  || Decoder Loss:  0.037021175 Validation Decoder Loss:  0.37432197
Encoder Loss:  0.049847353  || Decoder Loss:  0.035889372 Validation Decoder Loss:  0.34748858
Encoder Loss:  0.05153137  || Decoder Loss:  0.035885062 Validation Decoder Loss:  0.33646756
Encoder Loss:  0.05507563  || Decoder Loss:  0.03799156 Validation Decoder Loss:  0.3653031
Encoder Loss:  0.049296077  || Decoder Loss:  0.03644313 Validation Decoder Loss:  0.3333364
Encoder Loss:  0.05221631  || Decoder Loss:  0.037461385 Validation Decoder Loss:  0.35977346
Encoder Loss:  0.05023336  || Decoder Loss:  0.034736495 Validation Decoder Loss:  0.33774647
Encoder Loss:  0.049694695  || Decoder Loss:  0.037568368 Validation Decoder Loss:  0.359681
Encoder Loss:  0.05055341  || Decoder Loss:  0.03456563 Validation Decoder Loss:  0.33852506
Encoder Loss:  0.051964197  || Decoder Loss:  0.037004318 Validation Decoder Loss:  0.39227933
Encoder Loss:  0.049381327  || Decoder Loss:  0.03639038 Validation Decoder Loss:  0.33508962
Encoder Loss:  0.049603533  || Decoder Loss:  0.036446072 Validation Decoder Loss:  0.35270727
Encoder Loss:  0.051163055  || Decoder Loss:  0.035215978 Validation Decoder Loss:  0.34856698
Encoder Loss:  0.057395134  || Decoder Loss:  0.036425494 Validation Decoder Loss:  0.35208476
Encoder Loss:  0.053576984  || Decoder Loss:  0.03556626 Validation Decoder Loss:  0.38273874
Model: siamese_net_lr_0.022828748422543677 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38273874
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_82 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_82 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42320758  || Decoder Loss:  0.11148984 Validation Decoder Loss:  0.34292987
Encoder Loss:  0.42341542  || Decoder Loss:  0.03470497 Validation Decoder Loss:  0.3392914
Encoder Loss:  0.42247844  || Decoder Loss:  0.034700107 Validation Decoder Loss:  0.3384679
Encoder Loss:  0.42096898  || Decoder Loss:  0.035631053 Validation Decoder Loss:  0.33780986
Encoder Loss:  0.41839132  || Decoder Loss:  0.037162837 Validation Decoder Loss:  0.33712095
Encoder Loss:  0.4136558  || Decoder Loss:  0.039874326 Validation Decoder Loss:  0.33696178
Encoder Loss:  0.4027229  || Decoder Loss:  0.045820445 Validation Decoder Loss:  0.3403842
Encoder Loss:  0.30660912  || Decoder Loss:  0.12937716 Validation Decoder Loss:  0.91230255
Encoder Loss:  0.15614875  || Decoder Loss:  0.11576827 Validation Decoder Loss:  0.36373025
Encoder Loss:  0.088682406  || Decoder Loss:  0.039648887 Validation Decoder Loss:  0.34197503
Encoder Loss:  0.09056284  || Decoder Loss:  0.034302387 Validation Decoder Loss:  0.34682336
Encoder Loss:  0.1012762  || Decoder Loss:  0.033641063 Validation Decoder Loss:  0.34512836
Encoder Loss:  0.108155385  || Decoder Loss:  0.033550438 Validation Decoder Loss:  0.34440535
Encoder Loss:  0.096457526  || Decoder Loss:  0.03347913 Validation Decoder Loss:  0.3448609
Encoder Loss:  0.09965141  || Decoder Loss:  0.033423062 Validation Decoder Loss:  0.34478357
Encoder Loss:  0.09650987  || Decoder Loss:  0.03337214 Validation Decoder Loss:  0.34463888
Encoder Loss:  0.09337204  || Decoder Loss:  0.03332764 Validation Decoder Loss:  0.34445035
Encoder Loss:  0.09329541  || Decoder Loss:  0.03328884 Validation Decoder Loss:  0.34446222
Encoder Loss:  0.09441273  || Decoder Loss:  0.033254944 Validation Decoder Loss:  0.3444522
Encoder Loss:  0.098562784  || Decoder Loss:  0.03322356 Validation Decoder Loss:  0.34428334
Encoder Loss:  0.09151152  || Decoder Loss:  0.033195816 Validation Decoder Loss:  0.34436357
Encoder Loss:  0.0959749  || Decoder Loss:  0.03317045 Validation Decoder Loss:  0.3442859
Encoder Loss:  0.09073021  || Decoder Loss:  0.033149924 Validation Decoder Loss:  0.34434557
Encoder Loss:  0.09290838  || Decoder Loss:  0.033132754 Validation Decoder Loss:  0.34413004
Encoder Loss:  0.09391195  || Decoder Loss:  0.03311971 Validation Decoder Loss:  0.34441346
Encoder Loss:  0.09528635  || Decoder Loss:  0.033103954 Validation Decoder Loss:  0.34443057
Encoder Loss:  0.089075156  || Decoder Loss:  0.033091474 Validation Decoder Loss:  0.34448725
Encoder Loss:  0.09505111  || Decoder Loss:  0.033079825 Validation Decoder Loss:  0.34441012
Encoder Loss:  0.08581643  || Decoder Loss:  0.033072993 Validation Decoder Loss:  0.34444734
Encoder Loss:  0.094341345  || Decoder Loss:  0.03306798 Validation Decoder Loss:  0.34436977
Encoder Loss:  0.08730541  || Decoder Loss:  0.03306431 Validation Decoder Loss:  0.34439155
Encoder Loss:  0.09192286  || Decoder Loss:  0.033060834 Validation Decoder Loss:  0.34433717
Encoder Loss:  0.08038035  || Decoder Loss:  0.033061147 Validation Decoder Loss:  0.34412944
Encoder Loss:  0.07977521  || Decoder Loss:  0.033058424 Validation Decoder Loss:  0.34433895
Encoder Loss:  0.084366776  || Decoder Loss:  0.033060804 Validation Decoder Loss:  0.3444407
Encoder Loss:  0.08589928  || Decoder Loss:  0.033066157 Validation Decoder Loss:  0.3445665
Encoder Loss:  0.09180505  || Decoder Loss:  0.03307095 Validation Decoder Loss:  0.34461588
Encoder Loss:  0.08116426  || Decoder Loss:  0.033077404 Validation Decoder Loss:  0.3447699
Encoder Loss:  0.083284244  || Decoder Loss:  0.033098113 Validation Decoder Loss:  0.34468305
Encoder Loss:  0.07469445  || Decoder Loss:  0.03308116 Validation Decoder Loss:  0.34464976
Model: siamese_net_lr_0.04361801227699857 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34464976
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 307, 10, 20, 1)    1465      
_________________________________________________________________
reshape_83 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 1,465
Trainable params: 1,465
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8117633  || Decoder Loss:  0.94578177 Validation Decoder Loss:  1.6518359
Encoder Loss:  0.7876575  || Decoder Loss:  0.9588076 Validation Decoder Loss:  1.6514696
Encoder Loss:  0.7701718  || Decoder Loss:  0.95831406 Validation Decoder Loss:  1.6511743
Encoder Loss:  0.7615435  || Decoder Loss:  0.9577366 Validation Decoder Loss:  1.65081
Encoder Loss:  0.7465328  || Decoder Loss:  0.95724154 Validation Decoder Loss:  1.6505647
Encoder Loss:  0.7522626  || Decoder Loss:  0.9567465 Validation Decoder Loss:  1.6502358
Encoder Loss:  0.7356742  || Decoder Loss:  0.9561707 Validation Decoder Loss:  1.6499976
Encoder Loss:  0.7296913  || Decoder Loss:  0.95583236 Validation Decoder Loss:  1.6499182
Encoder Loss:  0.73344254  || Decoder Loss:  0.95553607 Validation Decoder Loss:  1.6498154
Encoder Loss:  0.73986936  || Decoder Loss:  0.955013 Validation Decoder Loss:  1.6494288
Encoder Loss:  0.7299211  || Decoder Loss:  0.95440423 Validation Decoder Loss:  1.6491733
Encoder Loss:  0.7443216  || Decoder Loss:  0.95370895 Validation Decoder Loss:  1.6485336
Encoder Loss:  0.7398647  || Decoder Loss:  0.95233727 Validation Decoder Loss:  1.6473966
Encoder Loss:  0.7238348  || Decoder Loss:  0.95060885 Validation Decoder Loss:  1.6458771
Encoder Loss:  0.72454256  || Decoder Loss:  0.94778717 Validation Decoder Loss:  1.6410218
Encoder Loss:  0.6436275  || Decoder Loss:  0.842623 Validation Decoder Loss:  0.38521016
Encoder Loss:  0.057428736  || Decoder Loss:  0.051803883 Validation Decoder Loss:  0.3588857
Encoder Loss:  0.057909675  || Decoder Loss:  0.050132535 Validation Decoder Loss:  0.35894966
Encoder Loss:  0.05567106  || Decoder Loss:  0.050491795 Validation Decoder Loss:  0.35917544
Encoder Loss:  0.05867139  || Decoder Loss:  0.050843764 Validation Decoder Loss:  0.35953566
Encoder Loss:  0.0660316  || Decoder Loss:  0.051576212 Validation Decoder Loss:  0.36045492
Encoder Loss:  0.05522898  || Decoder Loss:  0.052396055 Validation Decoder Loss:  0.36086333
Encoder Loss:  0.06002368  || Decoder Loss:  0.052780803 Validation Decoder Loss:  0.36131257
Encoder Loss:  0.057497982  || Decoder Loss:  0.053401843 Validation Decoder Loss:  0.36179754
Encoder Loss:  0.056581117  || Decoder Loss:  0.05383868 Validation Decoder Loss:  0.36207807
Encoder Loss:  0.058421813  || Decoder Loss:  0.054293975 Validation Decoder Loss:  0.36257875
Encoder Loss:  0.05951105  || Decoder Loss:  0.054823074 Validation Decoder Loss:  0.36308944
Encoder Loss:  0.058998752  || Decoder Loss:  0.055493392 Validation Decoder Loss:  0.36367592
Encoder Loss:  0.061803494  || Decoder Loss:  0.056092616 Validation Decoder Loss:  0.36436635
Encoder Loss:  0.060061254  || Decoder Loss:  0.056991447 Validation Decoder Loss:  0.36516982
Encoder Loss:  0.06078796  || Decoder Loss:  0.057816204 Validation Decoder Loss:  0.36590347
Encoder Loss:  0.06510467  || Decoder Loss:  0.05875225 Validation Decoder Loss:  0.3671565
Encoder Loss:  0.06326968  || Decoder Loss:  0.06001243 Validation Decoder Loss:  0.36826038
Encoder Loss:  0.07137889  || Decoder Loss:  0.061653797 Validation Decoder Loss:  0.3705647
Encoder Loss:  0.07342398  || Decoder Loss:  0.06433566 Validation Decoder Loss:  0.37366575
Encoder Loss:  0.069743246  || Decoder Loss:  0.0673502 Validation Decoder Loss:  0.37627894
Encoder Loss:  0.07102242  || Decoder Loss:  0.069729716 Validation Decoder Loss:  0.37869138
Encoder Loss:  0.06957365  || Decoder Loss:  0.07128759 Validation Decoder Loss:  0.37991357
Encoder Loss:  0.076627925  || Decoder Loss:  0.073518276 Validation Decoder Loss:  0.38348392
Encoder Loss:  0.075618684  || Decoder Loss:  0.0764172 Validation Decoder Loss:  0.38629457
Model: siamese_net_lr_0.07396512341294134 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38629457
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 614, 5, 20, 1)     174       
_________________________________________________________________
reshape_84 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 174
Trainable params: 174
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16201892  || Decoder Loss:  0.05310193 Validation Decoder Loss:  0.34567356
Encoder Loss:  0.15122797  || Decoder Loss:  0.034360785 Validation Decoder Loss:  0.34639883
Encoder Loss:  0.15082362  || Decoder Loss:  0.034512594 Validation Decoder Loss:  0.3468218
Encoder Loss:  0.13709685  || Decoder Loss:  0.03481909 Validation Decoder Loss:  0.34675872
Encoder Loss:  0.09892368  || Decoder Loss:  0.035262145 Validation Decoder Loss:  0.34647754
Encoder Loss:  0.109352276  || Decoder Loss:  0.035856687 Validation Decoder Loss:  0.34678045
Encoder Loss:  0.078091  || Decoder Loss:  0.03763105 Validation Decoder Loss:  0.34819877
Encoder Loss:  0.097529195  || Decoder Loss:  0.09736498 Validation Decoder Loss:  0.37076926
Encoder Loss:  0.12725973  || Decoder Loss:  0.15517914 Validation Decoder Loss:  0.89634186
Encoder Loss:  0.38757777  || Decoder Loss:  0.52012324 Validation Decoder Loss:  1.0566487
Encoder Loss:  0.41396177  || Decoder Loss:  0.557284 Validation Decoder Loss:  1.0368166
Encoder Loss:  0.37038243  || Decoder Loss:  0.49658844 Validation Decoder Loss:  0.9925578
Encoder Loss:  0.3588176  || Decoder Loss:  0.4805682 Validation Decoder Loss:  0.99390817
Encoder Loss:  0.3518727  || Decoder Loss:  0.4709064 Validation Decoder Loss:  0.98036516
Encoder Loss:  0.33392838  || Decoder Loss:  0.44587883 Validation Decoder Loss:  0.9460434
Encoder Loss:  0.28529015  || Decoder Loss:  0.3780592 Validation Decoder Loss:  0.8272834
Encoder Loss:  0.23923056  || Decoder Loss:  0.31381315 Validation Decoder Loss:  0.83745784
Encoder Loss:  0.26262587  || Decoder Loss:  0.34644154 Validation Decoder Loss:  0.8591538
Encoder Loss:  0.25211528  || Decoder Loss:  0.3317746 Validation Decoder Loss:  0.905002
Encoder Loss:  0.2839559  || Decoder Loss:  0.37618867 Validation Decoder Loss:  0.77842087
Encoder Loss:  0.15316214  || Decoder Loss:  0.19378453 Validation Decoder Loss:  0.3810558
Encoder Loss:  0.0623726  || Decoder Loss:  0.06716012 Validation Decoder Loss:  0.37752402
Encoder Loss:  0.04471787  || Decoder Loss:  0.042527728 Validation Decoder Loss:  0.35712636
Encoder Loss:  0.042262837  || Decoder Loss:  0.039139822 Validation Decoder Loss:  0.35942072
Encoder Loss:  0.04154962  || Decoder Loss:  0.0381507 Validation Decoder Loss:  0.35257468
Encoder Loss:  0.03971904  || Decoder Loss:  0.035601076 Validation Decoder Loss:  0.35405165
Encoder Loss:  0.04057285  || Decoder Loss:  0.036789104 Validation Decoder Loss:  0.34858724
Encoder Loss:  0.03871478  || Decoder Loss:  0.03420946 Validation Decoder Loss:  0.34853718
Encoder Loss:  0.038947377  || Decoder Loss:  0.034534298 Validation Decoder Loss:  0.34943917
Encoder Loss:  0.038912777  || Decoder Loss:  0.034480773 Validation Decoder Loss:  0.3482691
Encoder Loss:  0.03905237  || Decoder Loss:  0.034673687 Validation Decoder Loss:  0.34922373
Encoder Loss:  0.039342232  || Decoder Loss:  0.035093192 Validation Decoder Loss:  0.35102338
Encoder Loss:  0.03931742  || Decoder Loss:  0.03506129 Validation Decoder Loss:  0.35420394
Encoder Loss:  0.039853424  || Decoder Loss:  0.035805322 Validation Decoder Loss:  0.34878954
Encoder Loss:  0.038752865  || Decoder Loss:  0.034264117 Validation Decoder Loss:  0.3508732
Encoder Loss:  0.039416973  || Decoder Loss:  0.03519658 Validation Decoder Loss:  0.3512708
Encoder Loss:  0.039297517  || Decoder Loss:  0.035032652 Validation Decoder Loss:  0.35293257
Encoder Loss:  0.03967576  || Decoder Loss:  0.035557084 Validation Decoder Loss:  0.34883645
Encoder Loss:  0.03854569  || Decoder Loss:  0.033981837 Validation Decoder Loss:  0.35046864
Encoder Loss:  0.03926847  || Decoder Loss:  0.034989808 Validation Decoder Loss:  0.34953725
Model: siamese_net_lr_0.0707112550469772 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34953725
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_85 (Conv3DT (None, 97, 10, 20, 1)     205       
_________________________________________________________________
reshape_85 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 205
Trainable params: 205
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 970, 20, 1)        1308      
=================================================================
Total params: 1,308
Trainable params: 1,308
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 3245, 20, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3948469  || Decoder Loss:  0.3060008 Validation Decoder Loss:  0.35433298
Encoder Loss:  0.32121673  || Decoder Loss:  0.047978032 Validation Decoder Loss:  0.34721643
Encoder Loss:  0.31783777  || Decoder Loss:  0.050909974 Validation Decoder Loss:  0.3488682
Encoder Loss:  0.31050485  || Decoder Loss:  0.05752378 Validation Decoder Loss:  0.35552317
Encoder Loss:  0.2698735  || Decoder Loss:  0.12429176 Validation Decoder Loss:  1.2855891
Encoder Loss:  0.26093015  || Decoder Loss:  0.4984346 Validation Decoder Loss:  1.0735009
Encoder Loss:  0.18954222  || Decoder Loss:  0.3985051 Validation Decoder Loss:  0.9774223
Encoder Loss:  0.14300035  || Decoder Loss:  0.24592562 Validation Decoder Loss:  0.4418319
Encoder Loss:  0.09166894  || Decoder Loss:  0.07432489 Validation Decoder Loss:  0.3488499
Encoder Loss:  0.07891036  || Decoder Loss:  0.039417207 Validation Decoder Loss:  0.3451745
Encoder Loss:  0.07516985  || Decoder Loss:  0.03346155 Validation Decoder Loss:  0.34667468
Encoder Loss:  0.07560479  || Decoder Loss:  0.032750953 Validation Decoder Loss:  0.34564984
Encoder Loss:  0.07859347  || Decoder Loss:  0.03255231 Validation Decoder Loss:  0.34535074
Encoder Loss:  0.07173249  || Decoder Loss:  0.032444254 Validation Decoder Loss:  0.34581453
Encoder Loss:  0.07611902  || Decoder Loss:  0.032378625 Validation Decoder Loss:  0.34559795
Encoder Loss:  0.070529744  || Decoder Loss:  0.032332946 Validation Decoder Loss:  0.3460797
Encoder Loss:  0.07082646  || Decoder Loss:  0.032300677 Validation Decoder Loss:  0.34631544
Encoder Loss:  0.07057559  || Decoder Loss:  0.032294765 Validation Decoder Loss:  0.34642857
Encoder Loss:  0.06982654  || Decoder Loss:  0.032308936 Validation Decoder Loss:  0.3465023
Encoder Loss:  0.069689415  || Decoder Loss:  0.032338817 Validation Decoder Loss:  0.3466484
Encoder Loss:  0.06895187  || Decoder Loss:  0.032379378 Validation Decoder Loss:  0.34691256
Encoder Loss:  0.06663504  || Decoder Loss:  0.032433532 Validation Decoder Loss:  0.34727743
Encoder Loss:  0.063414074  || Decoder Loss:  0.032510236 Validation Decoder Loss:  0.3476742
Encoder Loss:  0.061707724  || Decoder Loss:  0.03261346 Validation Decoder Loss:  0.3476467
Encoder Loss:  0.05856582  || Decoder Loss:  0.03276267 Validation Decoder Loss:  0.34758276
Encoder Loss:  0.056007758  || Decoder Loss:  0.03296318 Validation Decoder Loss:  0.34835672
Encoder Loss:  0.054696284  || Decoder Loss:  0.033200447 Validation Decoder Loss:  0.34869456
Encoder Loss:  0.05353188  || Decoder Loss:  0.03345205 Validation Decoder Loss:  0.3490433
Encoder Loss:  0.04894577  || Decoder Loss:  0.03367956 Validation Decoder Loss:  0.34975204
Encoder Loss:  0.050131455  || Decoder Loss:  0.033852905 Validation Decoder Loss:  0.3501672
Encoder Loss:  0.047545396  || Decoder Loss:  0.03388768 Validation Decoder Loss:  0.3500718
Encoder Loss:  0.05138057  || Decoder Loss:  0.033889722 Validation Decoder Loss:  0.35016462
Encoder Loss:  0.05059855  || Decoder Loss:  0.03388442 Validation Decoder Loss:  0.35016608
Encoder Loss:  0.047678985  || Decoder Loss:  0.0339123 Validation Decoder Loss:  0.3503062
Encoder Loss:  0.051339164  || Decoder Loss:  0.033981487 Validation Decoder Loss:  0.35042375
Encoder Loss:  0.049943544  || Decoder Loss:  0.03394448 Validation Decoder Loss:  0.350118
Encoder Loss:  0.049373433  || Decoder Loss:  0.033958066 Validation Decoder Loss:  0.34995797
Encoder Loss:  0.054193635  || Decoder Loss:  0.033935443 Validation Decoder Loss:  0.3496724
Encoder Loss:  0.050264616  || Decoder Loss:  0.033881262 Validation Decoder Loss:  0.34988147
Encoder Loss:  0.05036436  || Decoder Loss:  0.034036912 Validation Decoder Loss:  0.34995985
Model: siamese_net_lr_0.019924487121009724 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34995985
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_86 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 3245, 20, 1)       770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46643528  || Decoder Loss:  0.91474146 Validation Decoder Loss:  1.6588582
Encoder Loss:  0.46817425  || Decoder Loss:  0.9260353 Validation Decoder Loss:  1.6745822
Encoder Loss:  0.36096957  || Decoder Loss:  0.7677373 Validation Decoder Loss:  1.3064934
Encoder Loss:  0.14479786  || Decoder Loss:  0.47310117 Validation Decoder Loss:  1.3544974
Encoder Loss:  0.100178145  || Decoder Loss:  0.49841836 Validation Decoder Loss:  1.2482138
Encoder Loss:  0.10794223  || Decoder Loss:  0.4839437 Validation Decoder Loss:  1.3315988
Encoder Loss:  0.09609825  || Decoder Loss:  0.4869092 Validation Decoder Loss:  1.3084099
Encoder Loss:  0.08988824  || Decoder Loss:  0.4747082 Validation Decoder Loss:  1.2558525
Encoder Loss:  0.078480735  || Decoder Loss:  0.30097255 Validation Decoder Loss:  0.563498
Encoder Loss:  0.08100388  || Decoder Loss:  0.1701288 Validation Decoder Loss:  0.41440147
Encoder Loss:  0.079582065  || Decoder Loss:  0.087137416 Validation Decoder Loss:  0.34095368
Encoder Loss:  0.067064226  || Decoder Loss:  0.07078703 Validation Decoder Loss:  0.2606566
Encoder Loss:  0.06726855  || Decoder Loss:  0.05044168 Validation Decoder Loss:  0.3374569
Encoder Loss:  0.064144224  || Decoder Loss:  0.038499232 Validation Decoder Loss:  0.31966588
Encoder Loss:  0.069597  || Decoder Loss:  0.036222007 Validation Decoder Loss:  0.37560624
Encoder Loss:  0.08156139  || Decoder Loss:  0.038176745 Validation Decoder Loss:  0.33149567
Encoder Loss:  0.07114444  || Decoder Loss:  0.038059834 Validation Decoder Loss:  0.31962836
Encoder Loss:  0.059669457  || Decoder Loss:  0.03772334 Validation Decoder Loss:  0.3494624
Encoder Loss:  0.05863802  || Decoder Loss:  0.036928836 Validation Decoder Loss:  0.38342115
Encoder Loss:  0.05867164  || Decoder Loss:  0.036428593 Validation Decoder Loss:  0.3468833
Encoder Loss:  0.068469994  || Decoder Loss:  0.038209833 Validation Decoder Loss:  0.3484125
Encoder Loss:  0.070846125  || Decoder Loss:  0.039486993 Validation Decoder Loss:  0.40401113
Encoder Loss:  0.07079858  || Decoder Loss:  0.04009456 Validation Decoder Loss:  0.3846656
Encoder Loss:  0.05845802  || Decoder Loss:  0.040635616 Validation Decoder Loss:  0.3086834
Encoder Loss:  0.057697996  || Decoder Loss:  0.039969243 Validation Decoder Loss:  0.3240521
Encoder Loss:  0.059948374  || Decoder Loss:  0.03763714 Validation Decoder Loss:  0.35879934
Encoder Loss:  0.059662655  || Decoder Loss:  0.038911052 Validation Decoder Loss:  0.27900264
Encoder Loss:  0.066482164  || Decoder Loss:  0.040918607 Validation Decoder Loss:  0.38272905
Encoder Loss:  0.061045866  || Decoder Loss:  0.037139192 Validation Decoder Loss:  0.31061062
Encoder Loss:  0.06475179  || Decoder Loss:  0.041093383 Validation Decoder Loss:  0.3724125
Encoder Loss:  0.05501142  || Decoder Loss:  0.04098184 Validation Decoder Loss:  0.28982592
Encoder Loss:  0.052768108  || Decoder Loss:  0.040027257 Validation Decoder Loss:  0.40288353
Encoder Loss:  0.05313485  || Decoder Loss:  0.03788613 Validation Decoder Loss:  0.34420645
Encoder Loss:  0.05234172  || Decoder Loss:  0.03790351 Validation Decoder Loss:  0.36525607
Encoder Loss:  0.052773353  || Decoder Loss:  0.035655096 Validation Decoder Loss:  0.36668608
Encoder Loss:  0.05703846  || Decoder Loss:  0.03767273 Validation Decoder Loss:  0.38657635
Encoder Loss:  0.058245216  || Decoder Loss:  0.036852613 Validation Decoder Loss:  0.33375102
Encoder Loss:  0.06374638  || Decoder Loss:  0.038042143 Validation Decoder Loss:  0.37152046
Encoder Loss:  0.053315315  || Decoder Loss:  0.036244616 Validation Decoder Loss:  0.35279846
Encoder Loss:  0.059197217  || Decoder Loss:  0.037590295 Validation Decoder Loss:  0.35670328
Model: siamese_net_lr_0.05710244090290578 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35670328
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 97, 10, 20, 1)     69        
_________________________________________________________________
reshape_87 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 69
Trainable params: 69
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 970, 20, 1)        2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 3245, 20, 1)       2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07065943  || Decoder Loss:  0.07065943 Validation Decoder Loss:  0.3556036
Encoder Loss:  0.0549516  || Decoder Loss:  0.0549516 Validation Decoder Loss:  0.35534358
Encoder Loss:  0.054558482  || Decoder Loss:  0.054558482 Validation Decoder Loss:  0.35501066
Encoder Loss:  0.05409825  || Decoder Loss:  0.05409825 Validation Decoder Loss:  0.35463977
Encoder Loss:  0.053586822  || Decoder Loss:  0.053586822 Validation Decoder Loss:  0.35424876
Encoder Loss:  0.053038884  || Decoder Loss:  0.053038884 Validation Decoder Loss:  0.35385072
Encoder Loss:  0.052466173  || Decoder Loss:  0.052466173 Validation Decoder Loss:  0.35345578
Encoder Loss:  0.051878095  || Decoder Loss:  0.051878095 Validation Decoder Loss:  0.3530715
Encoder Loss:  0.05128218  || Decoder Loss:  0.05128218 Validation Decoder Loss:  0.35270372
Encoder Loss:  0.050684515  || Decoder Loss:  0.050684515 Validation Decoder Loss:  0.35235643
Encoder Loss:  0.050089926  || Decoder Loss:  0.050089926 Validation Decoder Loss:  0.35203218
Encoder Loss:  0.04950227  || Decoder Loss:  0.04950227 Validation Decoder Loss:  0.35173234
Encoder Loss:  0.048924476  || Decoder Loss:  0.048924476 Validation Decoder Loss:  0.35145715
Encoder Loss:  0.048358794  || Decoder Loss:  0.048358794 Validation Decoder Loss:  0.35120603
Encoder Loss:  0.047806796  || Decoder Loss:  0.047806796 Validation Decoder Loss:  0.35097766
Encoder Loss:  0.04726958  || Decoder Loss:  0.04726958 Validation Decoder Loss:  0.35077018
Encoder Loss:  0.04674778  || Decoder Loss:  0.04674778 Validation Decoder Loss:  0.35058135
Encoder Loss:  0.04624174  || Decoder Loss:  0.04624174 Validation Decoder Loss:  0.35040855
Encoder Loss:  0.04575147  || Decoder Loss:  0.04575147 Validation Decoder Loss:  0.35024908
Encoder Loss:  0.04527683  || Decoder Loss:  0.04527683 Validation Decoder Loss:  0.35010022
Encoder Loss:  0.044817466  || Decoder Loss:  0.044817466 Validation Decoder Loss:  0.34995914
Encoder Loss:  0.044372953  || Decoder Loss:  0.044372953 Validation Decoder Loss:  0.34982324
Encoder Loss:  0.043942787  || Decoder Loss:  0.043942787 Validation Decoder Loss:  0.34969002
Encoder Loss:  0.04352638  || Decoder Loss:  0.04352638 Validation Decoder Loss:  0.34955722
Encoder Loss:  0.0431232  || Decoder Loss:  0.0431232 Validation Decoder Loss:  0.34942278
Encoder Loss:  0.04273266  || Decoder Loss:  0.04273266 Validation Decoder Loss:  0.349285
Encoder Loss:  0.042354193  || Decoder Loss:  0.042354193 Validation Decoder Loss:  0.3491424
Encoder Loss:  0.041987263  || Decoder Loss:  0.041987263 Validation Decoder Loss:  0.3489938
Encoder Loss:  0.04163136  || Decoder Loss:  0.04163136 Validation Decoder Loss:  0.3488384
Encoder Loss:  0.041286003  || Decoder Loss:  0.041286003 Validation Decoder Loss:  0.34867546
Encoder Loss:  0.040950738  || Decoder Loss:  0.040950738 Validation Decoder Loss:  0.34850472
Encoder Loss:  0.040625133  || Decoder Loss:  0.040625133 Validation Decoder Loss:  0.34832606
Encoder Loss:  0.04030879  || Decoder Loss:  0.04030879 Validation Decoder Loss:  0.34813964
Encoder Loss:  0.040001348  || Decoder Loss:  0.040001348 Validation Decoder Loss:  0.3479457
Encoder Loss:  0.039702434  || Decoder Loss:  0.039702434 Validation Decoder Loss:  0.34774476
Encoder Loss:  0.039411712  || Decoder Loss:  0.039411712 Validation Decoder Loss:  0.34753743
Encoder Loss:  0.039128855  || Decoder Loss:  0.039128855 Validation Decoder Loss:  0.3473244
Encoder Loss:  0.03885355  || Decoder Loss:  0.03885355 Validation Decoder Loss:  0.34710658
Encoder Loss:  0.03858548  || Decoder Loss:  0.03858548 Validation Decoder Loss:  0.3468847
Encoder Loss:  0.038324345  || Decoder Loss:  0.038324345 Validation Decoder Loss:  0.34665975
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34665975
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_88 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_88 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43791842  || Decoder Loss:  0.4051361 Validation Decoder Loss:  0.39189222
Encoder Loss:  0.43523365  || Decoder Loss:  0.045801915 Validation Decoder Loss:  0.34138983
Encoder Loss:  0.4345671  || Decoder Loss:  0.035310254 Validation Decoder Loss:  0.34085006
Encoder Loss:  0.43409345  || Decoder Loss:  0.035584792 Validation Decoder Loss:  0.34045988
Encoder Loss:  0.43345618  || Decoder Loss:  0.036040016 Validation Decoder Loss:  0.34005377
Encoder Loss:  0.4325989  || Decoder Loss:  0.03668038 Validation Decoder Loss:  0.33972865
Encoder Loss:  0.43143067  || Decoder Loss:  0.03755034 Validation Decoder Loss:  0.33946484
Encoder Loss:  0.42979395  || Decoder Loss:  0.038760554 Validation Decoder Loss:  0.3393349
Encoder Loss:  0.4273816  || Decoder Loss:  0.040532194 Validation Decoder Loss:  0.33953923
Encoder Loss:  0.4234777  || Decoder Loss:  0.043382816 Validation Decoder Loss:  0.3406555
Encoder Loss:  0.41577852  || Decoder Loss:  0.048992883 Validation Decoder Loss:  0.34541392
Encoder Loss:  0.385415  || Decoder Loss:  0.07206932 Validation Decoder Loss:  0.44353896
Encoder Loss:  0.15755682  || Decoder Loss:  0.4208815 Validation Decoder Loss:  0.96590054
Encoder Loss:  0.111080386  || Decoder Loss:  0.37698987 Validation Decoder Loss:  0.5436304
Encoder Loss:  0.09775952  || Decoder Loss:  0.09772975 Validation Decoder Loss:  0.35304758
Encoder Loss:  0.095875934  || Decoder Loss:  0.037471212 Validation Decoder Loss:  0.3435152
Encoder Loss:  0.09119925  || Decoder Loss:  0.0338125 Validation Decoder Loss:  0.34485984
Encoder Loss:  0.0927888  || Decoder Loss:  0.033359963 Validation Decoder Loss:  0.34490487
Encoder Loss:  0.09448225  || Decoder Loss:  0.033275407 Validation Decoder Loss:  0.3447715
Encoder Loss:  0.09113492  || Decoder Loss:  0.033223473 Validation Decoder Loss:  0.34491116
Encoder Loss:  0.09113874  || Decoder Loss:  0.033188745 Validation Decoder Loss:  0.34513927
Encoder Loss:  0.09364265  || Decoder Loss:  0.033158407 Validation Decoder Loss:  0.34503782
Encoder Loss:  0.09069062  || Decoder Loss:  0.033134293 Validation Decoder Loss:  0.3451525
Encoder Loss:  0.095010646  || Decoder Loss:  0.033113204 Validation Decoder Loss:  0.3452565
Encoder Loss:  0.09118926  || Decoder Loss:  0.03311033 Validation Decoder Loss:  0.34532258
Encoder Loss:  0.08723042  || Decoder Loss:  0.03311138 Validation Decoder Loss:  0.3455798
Encoder Loss:  0.08899429  || Decoder Loss:  0.033125654 Validation Decoder Loss:  0.34572297
Encoder Loss:  0.087246485  || Decoder Loss:  0.033144094 Validation Decoder Loss:  0.34591192
Encoder Loss:  0.086580984  || Decoder Loss:  0.033167116 Validation Decoder Loss:  0.34611273
Encoder Loss:  0.08735334  || Decoder Loss:  0.03319409 Validation Decoder Loss:  0.34638157
Encoder Loss:  0.09287085  || Decoder Loss:  0.03320616 Validation Decoder Loss:  0.34655452
Encoder Loss:  0.086220674  || Decoder Loss:  0.0332507 Validation Decoder Loss:  0.34684917
Encoder Loss:  0.08743126  || Decoder Loss:  0.033316195 Validation Decoder Loss:  0.3469597
Encoder Loss:  0.08166358  || Decoder Loss:  0.033369288 Validation Decoder Loss:  0.34705526
Encoder Loss:  0.07952015  || Decoder Loss:  0.033379413 Validation Decoder Loss:  0.34716877
Encoder Loss:  0.07605814  || Decoder Loss:  0.033541214 Validation Decoder Loss:  0.34731096
Encoder Loss:  0.077831954  || Decoder Loss:  0.033460673 Validation Decoder Loss:  0.34714213
Encoder Loss:  0.07579326  || Decoder Loss:  0.033786725 Validation Decoder Loss:  0.34791344
Encoder Loss:  0.07023921  || Decoder Loss:  0.0338427 Validation Decoder Loss:  0.3485539
Encoder Loss:  0.073709145  || Decoder Loss:  0.03369257 Validation Decoder Loss:  0.34756932
Model: siamese_net_lr_0.07122530579461163 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34756932
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_89 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19188635  || Decoder Loss:  0.23195328 Validation Decoder Loss:  0.36529538
Encoder Loss:  0.07030106  || Decoder Loss:  0.045236617 Validation Decoder Loss:  0.35431075
Encoder Loss:  0.04742367  || Decoder Loss:  0.03202066 Validation Decoder Loss:  0.35192955
Encoder Loss:  0.05489212  || Decoder Loss:  0.03318383 Validation Decoder Loss:  0.35595638
Encoder Loss:  0.06468644  || Decoder Loss:  0.032249067 Validation Decoder Loss:  0.34946403
Encoder Loss:  0.048910346  || Decoder Loss:  0.031819098 Validation Decoder Loss:  0.34664464
Encoder Loss:  0.046842076  || Decoder Loss:  0.031391595 Validation Decoder Loss:  0.34856078
Encoder Loss:  0.047972634  || Decoder Loss:  0.03117189 Validation Decoder Loss:  0.35101312
Encoder Loss:  0.04704114  || Decoder Loss:  0.030890811 Validation Decoder Loss:  0.3505769
Encoder Loss:  0.048862085  || Decoder Loss:  0.030858746 Validation Decoder Loss:  0.3552063
Encoder Loss:  0.046101615  || Decoder Loss:  0.030882012 Validation Decoder Loss:  0.35353202
Encoder Loss:  0.04573256  || Decoder Loss:  0.030579058 Validation Decoder Loss:  0.35358867
Encoder Loss:  0.045637384  || Decoder Loss:  0.030797616 Validation Decoder Loss:  0.37466544
Encoder Loss:  0.047490183  || Decoder Loss:  0.034597114 Validation Decoder Loss:  0.3645841
Encoder Loss:  0.046664976  || Decoder Loss:  0.03339803 Validation Decoder Loss:  0.36819667
Encoder Loss:  0.046987206  || Decoder Loss:  0.034300994 Validation Decoder Loss:  0.35421422
Encoder Loss:  0.0443588  || Decoder Loss:  0.031215608 Validation Decoder Loss:  0.35459602
Encoder Loss:  0.047975697  || Decoder Loss:  0.03107253 Validation Decoder Loss:  0.3727159
Encoder Loss:  0.04535382  || Decoder Loss:  0.03219085 Validation Decoder Loss:  0.3538034
Encoder Loss:  0.047508568  || Decoder Loss:  0.030722147 Validation Decoder Loss:  0.34911078
Encoder Loss:  0.049985852  || Decoder Loss:  0.034213837 Validation Decoder Loss:  0.3614875
Encoder Loss:  0.05478654  || Decoder Loss:  0.035979148 Validation Decoder Loss:  0.34978914
Encoder Loss:  0.047690917  || Decoder Loss:  0.03088465 Validation Decoder Loss:  0.34703082
Encoder Loss:  0.046085663  || Decoder Loss:  0.030293532 Validation Decoder Loss:  0.34915873
Encoder Loss:  0.04213781  || Decoder Loss:  0.030008715 Validation Decoder Loss:  0.34959948
Encoder Loss:  0.04401498  || Decoder Loss:  0.031179974 Validation Decoder Loss:  0.35467365
Encoder Loss:  0.04477073  || Decoder Loss:  0.03235704 Validation Decoder Loss:  0.35542297
Encoder Loss:  0.043870922  || Decoder Loss:  0.032736298 Validation Decoder Loss:  0.35058305
Encoder Loss:  0.044104766  || Decoder Loss:  0.03204556 Validation Decoder Loss:  0.35059482
Encoder Loss:  0.041936386  || Decoder Loss:  0.031043408 Validation Decoder Loss:  0.3560664
Encoder Loss:  0.043881327  || Decoder Loss:  0.03064958 Validation Decoder Loss:  0.35111088
Encoder Loss:  0.049628492  || Decoder Loss:  0.033022553 Validation Decoder Loss:  0.35218
Encoder Loss:  0.042331327  || Decoder Loss:  0.030690594 Validation Decoder Loss:  0.3507652
Encoder Loss:  0.04491675  || Decoder Loss:  0.030668257 Validation Decoder Loss:  0.34903815
Encoder Loss:  0.043094553  || Decoder Loss:  0.030046653 Validation Decoder Loss:  0.35593158
Encoder Loss:  0.04595259  || Decoder Loss:  0.03186854 Validation Decoder Loss:  0.35189402
Encoder Loss:  0.04246191  || Decoder Loss:  0.030735979 Validation Decoder Loss:  0.35635412
Encoder Loss:  0.04192438  || Decoder Loss:  0.031266287 Validation Decoder Loss:  0.35216928
Encoder Loss:  0.042712413  || Decoder Loss:  0.03140043 Validation Decoder Loss:  0.3560177
Encoder Loss:  0.043271914  || Decoder Loss:  0.0322289 Validation Decoder Loss:  0.3620916
Model: siamese_net_lr_0.0077382947421342566 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36209163
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_90 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45500633  || Decoder Loss:  0.8918405 Validation Decoder Loss:  1.6350973
Encoder Loss:  0.46333194  || Decoder Loss:  0.9057997 Validation Decoder Loss:  1.6263285
Encoder Loss:  0.46123692  || Decoder Loss:  0.8992629 Validation Decoder Loss:  1.6091175
Encoder Loss:  0.4572766  || Decoder Loss:  0.88121814 Validation Decoder Loss:  1.5506151
Encoder Loss:  0.44717273  || Decoder Loss:  0.792426 Validation Decoder Loss:  1.2521746
Encoder Loss:  0.4109864  || Decoder Loss:  0.48526174 Validation Decoder Loss:  0.6793333
Encoder Loss:  0.18531865  || Decoder Loss:  0.47585872 Validation Decoder Loss:  1.3143352
Encoder Loss:  0.12488535  || Decoder Loss:  0.4695553 Validation Decoder Loss:  1.2522376
Encoder Loss:  0.11403596  || Decoder Loss:  0.45714897 Validation Decoder Loss:  1.1670313
Encoder Loss:  0.108879894  || Decoder Loss:  0.44394824 Validation Decoder Loss:  1.2424896
Encoder Loss:  0.108110964  || Decoder Loss:  0.44313893 Validation Decoder Loss:  1.2233534
Encoder Loss:  0.1060123  || Decoder Loss:  0.43684387 Validation Decoder Loss:  1.2413654
Encoder Loss:  0.10591166  || Decoder Loss:  0.4343416 Validation Decoder Loss:  1.2654862
Encoder Loss:  0.105210565  || Decoder Loss:  0.43104747 Validation Decoder Loss:  1.2690108
Encoder Loss:  0.10439721  || Decoder Loss:  0.43225133 Validation Decoder Loss:  1.2748989
Encoder Loss:  0.10378977  || Decoder Loss:  0.42851368 Validation Decoder Loss:  1.3226135
Encoder Loss:  0.103646815  || Decoder Loss:  0.4278445 Validation Decoder Loss:  1.2932491
Encoder Loss:  0.101444386  || Decoder Loss:  0.42199773 Validation Decoder Loss:  1.337939
Encoder Loss:  0.100634076  || Decoder Loss:  0.41795552 Validation Decoder Loss:  1.349745
Encoder Loss:  0.09934157  || Decoder Loss:  0.41001415 Validation Decoder Loss:  1.2821907
Encoder Loss:  0.09530735  || Decoder Loss:  0.31386822 Validation Decoder Loss:  0.6330744
Encoder Loss:  0.09180008  || Decoder Loss:  0.26626602 Validation Decoder Loss:  0.65118754
Encoder Loss:  0.09236887  || Decoder Loss:  0.1972452 Validation Decoder Loss:  0.50783265
Encoder Loss:  0.08560917  || Decoder Loss:  0.16120678 Validation Decoder Loss:  0.6204195
Encoder Loss:  0.090549126  || Decoder Loss:  0.1901747 Validation Decoder Loss:  0.79432964
Encoder Loss:  0.079095885  || Decoder Loss:  0.12983717 Validation Decoder Loss:  0.4899199
Encoder Loss:  0.07655363  || Decoder Loss:  0.07950725 Validation Decoder Loss:  0.39061466
Encoder Loss:  0.0742519  || Decoder Loss:  0.050460607 Validation Decoder Loss:  0.42541856
Encoder Loss:  0.064288415  || Decoder Loss:  0.039517548 Validation Decoder Loss:  0.3682698
Encoder Loss:  0.06889589  || Decoder Loss:  0.037037592 Validation Decoder Loss:  0.3698517
Encoder Loss:  0.068273924  || Decoder Loss:  0.037546996 Validation Decoder Loss:  0.38769332
Encoder Loss:  0.06786521  || Decoder Loss:  0.035793778 Validation Decoder Loss:  0.3428035
Encoder Loss:  0.06302874  || Decoder Loss:  0.036521133 Validation Decoder Loss:  0.3527708
Encoder Loss:  0.06331067  || Decoder Loss:  0.036371697 Validation Decoder Loss:  0.33164126
Encoder Loss:  0.060448065  || Decoder Loss:  0.038173784 Validation Decoder Loss:  0.37205
Encoder Loss:  0.06430092  || Decoder Loss:  0.03794078 Validation Decoder Loss:  0.32525298
Encoder Loss:  0.07350727  || Decoder Loss:  0.03813761 Validation Decoder Loss:  0.37049457
Encoder Loss:  0.07476524  || Decoder Loss:  0.040363446 Validation Decoder Loss:  0.36213478
Encoder Loss:  0.07080108  || Decoder Loss:  0.041105166 Validation Decoder Loss:  0.36442506
Encoder Loss:  0.06362685  || Decoder Loss:  0.04176913 Validation Decoder Loss:  0.34367755
Model: siamese_net_lr_0.05953495759841676 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34367752
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_91 (Conv3DT (None, 314, 5, 20, 1)     126       
_________________________________________________________________
reshape_91 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 126
Trainable params: 126
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 1570, 20, 1)       108       
=================================================================
Total params: 108
Trainable params: 108
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 3245, 20, 1)       1677      
=================================================================
Total params: 1,677
Trainable params: 1,677
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8439652  || Decoder Loss:  0.8994972 Validation Decoder Loss:  1.6389687
Encoder Loss:  0.85096383  || Decoder Loss:  0.9061637 Validation Decoder Loss:  1.6334271
Encoder Loss:  0.84672785  || Decoder Loss:  0.9013803 Validation Decoder Loss:  1.6258209
Encoder Loss:  0.8411858  || Decoder Loss:  0.89513516 Validation Decoder Loss:  1.615372
Encoder Loss:  0.833865  || Decoder Loss:  0.8869338 Validation Decoder Loss:  1.6005027
Encoder Loss:  0.82168406  || Decoder Loss:  0.8755265 Validation Decoder Loss:  1.5772625
Encoder Loss:  0.8076468  || Decoder Loss:  0.85721105 Validation Decoder Loss:  1.5325415
Encoder Loss:  0.7686106  || Decoder Loss:  0.8128608 Validation Decoder Loss:  1.3675836
Encoder Loss:  0.36460194  || Decoder Loss:  0.3538317 Validation Decoder Loss:  0.28820607
Encoder Loss:  0.09838063  || Decoder Loss:  0.05141221 Validation Decoder Loss:  0.31883508
Encoder Loss:  0.09681091  || Decoder Loss:  0.049785286 Validation Decoder Loss:  0.32663763
Encoder Loss:  0.093536235  || Decoder Loss:  0.046308435 Validation Decoder Loss:  0.33396423
Encoder Loss:  0.090714425  || Decoder Loss:  0.043549117 Validation Decoder Loss:  0.3441834
Encoder Loss:  0.08901236  || Decoder Loss:  0.042719018 Validation Decoder Loss:  0.359459
Encoder Loss:  0.09045687  || Decoder Loss:  0.0512705 Validation Decoder Loss:  0.57230663
Encoder Loss:  0.47154674  || Decoder Loss:  0.52054864 Validation Decoder Loss:  1.2934654
Encoder Loss:  0.40026683  || Decoder Loss:  0.445611 Validation Decoder Loss:  1.3229332
Encoder Loss:  0.40382907  || Decoder Loss:  0.45038474 Validation Decoder Loss:  1.2448463
Encoder Loss:  0.40203404  || Decoder Loss:  0.44857982 Validation Decoder Loss:  1.185601
Encoder Loss:  0.38061592  || Decoder Loss:  0.42494744 Validation Decoder Loss:  1.2993882
Encoder Loss:  0.37997323  || Decoder Loss:  0.4239569 Validation Decoder Loss:  1.2969155
Encoder Loss:  0.3523944  || Decoder Loss:  0.39285928 Validation Decoder Loss:  0.805467
Encoder Loss:  0.33132184  || Decoder Loss:  0.36908954 Validation Decoder Loss:  0.92951715
Encoder Loss:  0.43336272  || Decoder Loss:  0.48440307 Validation Decoder Loss:  1.0252426
Encoder Loss:  0.43795624  || Decoder Loss:  0.48988524 Validation Decoder Loss:  1.024034
Encoder Loss:  0.43214944  || Decoder Loss:  0.483288 Validation Decoder Loss:  1.0148517
Encoder Loss:  0.39283288  || Decoder Loss:  0.4377187 Validation Decoder Loss:  1.1762555
Encoder Loss:  0.4461294  || Decoder Loss:  0.49734092 Validation Decoder Loss:  1.0051453
Encoder Loss:  0.44185108  || Decoder Loss:  0.49401906 Validation Decoder Loss:  0.98729587
Encoder Loss:  0.44187084  || Decoder Loss:  0.49273038 Validation Decoder Loss:  0.991908
Encoder Loss:  0.44036275  || Decoder Loss:  0.4925126 Validation Decoder Loss:  0.98623747
Encoder Loss:  0.43921494  || Decoder Loss:  0.49075675 Validation Decoder Loss:  0.99279994
Encoder Loss:  0.43588665  || Decoder Loss:  0.4874155 Validation Decoder Loss:  0.97937584
Encoder Loss:  0.4275555  || Decoder Loss:  0.47833255 Validation Decoder Loss:  0.9336849
Encoder Loss:  0.33764434  || Decoder Loss:  0.3755375 Validation Decoder Loss:  0.77703243
Encoder Loss:  0.38972363  || Decoder Loss:  0.43556038 Validation Decoder Loss:  0.99596477
Encoder Loss:  0.4355871  || Decoder Loss:  0.48730865 Validation Decoder Loss:  0.9878918
Encoder Loss:  0.43006825  || Decoder Loss:  0.48065594 Validation Decoder Loss:  1.0335577
Encoder Loss:  0.42271808  || Decoder Loss:  0.47134307 Validation Decoder Loss:  0.9182276
Encoder Loss:  0.34980968  || Decoder Loss:  0.39003536 Validation Decoder Loss:  0.9037075
Model: siamese_net_lr_0.04848460696600828 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9037075
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 614, 5, 20, 1)     363       
_________________________________________________________________
reshape_92 (Reshape)         (None, 3070, 20, 1)       0         
=================================================================
Total params: 363
Trainable params: 363
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.85080796  || Decoder Loss:  0.9445476 Validation Decoder Loss:  1.6599638
Encoder Loss:  0.8676047  || Decoder Loss:  0.9626165 Validation Decoder Loss:  1.6600094
Encoder Loss:  0.8668885  || Decoder Loss:  0.9620399 Validation Decoder Loss:  1.660049
Encoder Loss:  0.8628385  || Decoder Loss:  0.9612027 Validation Decoder Loss:  1.6600722
Encoder Loss:  0.8603232  || Decoder Loss:  0.9601005 Validation Decoder Loss:  1.6601615
Encoder Loss:  0.8635117  || Decoder Loss:  0.95841485 Validation Decoder Loss:  1.6603463
Encoder Loss:  0.860702  || Decoder Loss:  0.95553744 Validation Decoder Loss:  1.6624091
Encoder Loss:  0.4966991  || Decoder Loss:  0.5107266 Validation Decoder Loss:  0.3537328
Encoder Loss:  0.11988904  || Decoder Loss:  0.051044952 Validation Decoder Loss:  0.3629904
Encoder Loss:  0.12828866  || Decoder Loss:  0.06622422 Validation Decoder Loss:  0.40641874
Encoder Loss:  0.33072713  || Decoder Loss:  0.35641482 Validation Decoder Loss:  0.9694255
Encoder Loss:  0.39122143  || Decoder Loss:  0.46128705 Validation Decoder Loss:  1.0868104
Encoder Loss:  0.393261  || Decoder Loss:  0.465222 Validation Decoder Loss:  1.1037219
Encoder Loss:  0.39283904  || Decoder Loss:  0.46526647 Validation Decoder Loss:  1.1102569
Encoder Loss:  0.39434066  || Decoder Loss:  0.467735 Validation Decoder Loss:  1.0960641
Encoder Loss:  0.39237443  || Decoder Loss:  0.46587995 Validation Decoder Loss:  1.128856
Encoder Loss:  0.3939501  || Decoder Loss:  0.46818027 Validation Decoder Loss:  1.112445
Encoder Loss:  0.38781083  || Decoder Loss:  0.4612126 Validation Decoder Loss:  1.0808046
Encoder Loss:  0.37630844  || Decoder Loss:  0.44784904 Validation Decoder Loss:  1.0505772
Encoder Loss:  0.16223995  || Decoder Loss:  0.18565851 Validation Decoder Loss:  0.35223582
Encoder Loss:  0.050570168  || Decoder Loss:  0.048605785 Validation Decoder Loss:  0.34848654
Encoder Loss:  0.04148067  || Decoder Loss:  0.03742032 Validation Decoder Loss:  0.36289555
Encoder Loss:  0.0439238  || Decoder Loss:  0.041022982 Validation Decoder Loss:  0.35042745
Encoder Loss:  0.042280298  || Decoder Loss:  0.03778374 Validation Decoder Loss:  0.3439771
Encoder Loss:  0.040651273  || Decoder Loss:  0.036467325 Validation Decoder Loss:  0.34841663
Encoder Loss:  0.04026845  || Decoder Loss:  0.036316555 Validation Decoder Loss:  0.34990114
Encoder Loss:  0.040199768  || Decoder Loss:  0.035727464 Validation Decoder Loss:  0.34498253
Encoder Loss:  0.039758973  || Decoder Loss:  0.035805885 Validation Decoder Loss:  0.3495245
Encoder Loss:  0.03972307  || Decoder Loss:  0.03640149 Validation Decoder Loss:  0.35460824
Encoder Loss:  0.041485637  || Decoder Loss:  0.037177406 Validation Decoder Loss:  0.34865546
Encoder Loss:  0.039091896  || Decoder Loss:  0.03567195 Validation Decoder Loss:  0.35019407
Encoder Loss:  0.040689155  || Decoder Loss:  0.03738817 Validation Decoder Loss:  0.34378546
Encoder Loss:  0.03932848  || Decoder Loss:  0.034604594 Validation Decoder Loss:  0.35177088
Encoder Loss:  0.04124382  || Decoder Loss:  0.037227582 Validation Decoder Loss:  0.34779805
Encoder Loss:  0.039101336  || Decoder Loss:  0.03509417 Validation Decoder Loss:  0.35229003
Encoder Loss:  0.04059545  || Decoder Loss:  0.037613466 Validation Decoder Loss:  0.3511549
Encoder Loss:  0.039904404  || Decoder Loss:  0.036454324 Validation Decoder Loss:  0.35053155
Encoder Loss:  0.038865518  || Decoder Loss:  0.03531539 Validation Decoder Loss:  0.3458882
Encoder Loss:  0.039579153  || Decoder Loss:  0.035417415 Validation Decoder Loss:  0.3496648
Encoder Loss:  0.03995245  || Decoder Loss:  0.036855146 Validation Decoder Loss:  0.34712684
Model: siamese_net_lr_0.034557853626196296 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34712684
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_93 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47396848  || Decoder Loss:  0.90104735 Validation Decoder Loss:  1.638046
Encoder Loss:  0.47815174  || Decoder Loss:  0.9181643 Validation Decoder Loss:  1.6356752
Encoder Loss:  0.4765274  || Decoder Loss:  0.9161726 Validation Decoder Loss:  1.6324254
Encoder Loss:  0.4738598  || Decoder Loss:  0.9135617 Validation Decoder Loss:  1.6280242
Encoder Loss:  0.46950752  || Decoder Loss:  0.9102334 Validation Decoder Loss:  1.6221097
Encoder Loss:  0.4621296  || Decoder Loss:  0.90594864 Validation Decoder Loss:  1.613756
Encoder Loss:  0.44729984  || Decoder Loss:  0.8999241 Validation Decoder Loss:  1.5989728
Encoder Loss:  0.3731737  || Decoder Loss:  0.87289864 Validation Decoder Loss:  0.4911927
Encoder Loss:  0.14366928  || Decoder Loss:  0.40948448 Validation Decoder Loss:  0.53656805
Encoder Loss:  0.11996794  || Decoder Loss:  0.46193045 Validation Decoder Loss:  0.46321303
Encoder Loss:  0.12299692  || Decoder Loss:  0.45730522 Validation Decoder Loss:  0.4648874
Encoder Loss:  0.122645676  || Decoder Loss:  0.45604226 Validation Decoder Loss:  0.48821467
Encoder Loss:  0.12307197  || Decoder Loss:  0.45802557 Validation Decoder Loss:  0.5271322
Encoder Loss:  0.11953452  || Decoder Loss:  0.46246162 Validation Decoder Loss:  0.51122844
Encoder Loss:  0.116820276  || Decoder Loss:  0.45809707 Validation Decoder Loss:  0.49525607
Encoder Loss:  0.11768682  || Decoder Loss:  0.4569352 Validation Decoder Loss:  0.4803759
Encoder Loss:  0.11909798  || Decoder Loss:  0.46213967 Validation Decoder Loss:  0.47499803
Encoder Loss:  0.12232616  || Decoder Loss:  0.4586479 Validation Decoder Loss:  0.5524111
Encoder Loss:  0.114443436  || Decoder Loss:  0.46538827 Validation Decoder Loss:  0.46882287
Encoder Loss:  0.119748585  || Decoder Loss:  0.47025734 Validation Decoder Loss:  0.48113608
Encoder Loss:  0.11968651  || Decoder Loss:  0.4689696 Validation Decoder Loss:  0.4938592
Encoder Loss:  0.11653302  || Decoder Loss:  0.46695805 Validation Decoder Loss:  0.47470954
Encoder Loss:  0.1184068  || Decoder Loss:  0.47266194 Validation Decoder Loss:  0.4966039
Encoder Loss:  0.11660902  || Decoder Loss:  0.47082072 Validation Decoder Loss:  0.4818159
Encoder Loss:  0.116445065  || Decoder Loss:  0.4712459 Validation Decoder Loss:  0.48321176
Encoder Loss:  0.116349265  || Decoder Loss:  0.4760835 Validation Decoder Loss:  0.45679665
Encoder Loss:  0.119996846  || Decoder Loss:  0.46682155 Validation Decoder Loss:  0.5358167
Encoder Loss:  0.11328669  || Decoder Loss:  0.47483528 Validation Decoder Loss:  0.46126175
Encoder Loss:  0.11906369  || Decoder Loss:  0.46953517 Validation Decoder Loss:  0.5367577
Encoder Loss:  0.112718344  || Decoder Loss:  0.4758235 Validation Decoder Loss:  0.45026246
Encoder Loss:  0.11945027  || Decoder Loss:  0.46943343 Validation Decoder Loss:  0.5796212
Encoder Loss:  0.10808931  || Decoder Loss:  0.4848129 Validation Decoder Loss:  0.5431577
Encoder Loss:  0.108024456  || Decoder Loss:  0.4832439 Validation Decoder Loss:  0.5588106
Encoder Loss:  0.10686251  || Decoder Loss:  0.4845633 Validation Decoder Loss:  0.5847385
Encoder Loss:  0.106844366  || Decoder Loss:  0.4849028 Validation Decoder Loss:  0.5698323
Encoder Loss:  0.105632916  || Decoder Loss:  0.47534207 Validation Decoder Loss:  0.53618133
Encoder Loss:  0.10560194  || Decoder Loss:  0.47810215 Validation Decoder Loss:  0.5588682
Encoder Loss:  0.10465701  || Decoder Loss:  0.48043746 Validation Decoder Loss:  0.5746753
Encoder Loss:  0.10412845  || Decoder Loss:  0.4901157 Validation Decoder Loss:  0.62914443
Encoder Loss:  0.101105995  || Decoder Loss:  0.48852828 Validation Decoder Loss:  0.5755375
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.5755375
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_94 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_94 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 620, 20, 1)        151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 3245, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.401763  || Decoder Loss:  0.24358067 Validation Decoder Loss:  0.35998014
Encoder Loss:  0.4079126  || Decoder Loss:  0.07816399 Validation Decoder Loss:  0.34915096
Encoder Loss:  0.40652505  || Decoder Loss:  0.074916594 Validation Decoder Loss:  0.3414728
Encoder Loss:  0.404198  || Decoder Loss:  0.0707593 Validation Decoder Loss:  0.33473602
Encoder Loss:  0.399754  || Decoder Loss:  0.0635666 Validation Decoder Loss:  0.32897025
Encoder Loss:  0.38823193  || Decoder Loss:  0.049586605 Validation Decoder Loss:  0.3676447
Encoder Loss:  0.26082635  || Decoder Loss:  0.25510845 Validation Decoder Loss:  1.2863774
Encoder Loss:  0.14343764  || Decoder Loss:  0.438379 Validation Decoder Loss:  1.1403544
Encoder Loss:  0.12450962  || Decoder Loss:  0.40002796 Validation Decoder Loss:  1.2250199
Encoder Loss:  0.11246631  || Decoder Loss:  0.21647948 Validation Decoder Loss:  0.4515949
Encoder Loss:  0.104819305  || Decoder Loss:  0.10106353 Validation Decoder Loss:  0.43477777
Encoder Loss:  0.088069946  || Decoder Loss:  0.040582914 Validation Decoder Loss:  0.3672639
Encoder Loss:  0.08960294  || Decoder Loss:  0.030353887 Validation Decoder Loss:  0.36430436
Encoder Loss:  0.089159854  || Decoder Loss:  0.029106662 Validation Decoder Loss:  0.35799187
Encoder Loss:  0.084775336  || Decoder Loss:  0.028790442 Validation Decoder Loss:  0.362875
Encoder Loss:  0.09266946  || Decoder Loss:  0.02946074 Validation Decoder Loss:  0.3584832
Encoder Loss:  0.08662471  || Decoder Loss:  0.029889064 Validation Decoder Loss:  0.37253517
Encoder Loss:  0.0788256  || Decoder Loss:  0.029755643 Validation Decoder Loss:  0.3643513
Encoder Loss:  0.08163109  || Decoder Loss:  0.029264007 Validation Decoder Loss:  0.36980262
Encoder Loss:  0.079880856  || Decoder Loss:  0.029686023 Validation Decoder Loss:  0.3680971
Encoder Loss:  0.07765212  || Decoder Loss:  0.030242767 Validation Decoder Loss:  0.3638504
Encoder Loss:  0.07646208  || Decoder Loss:  0.031532228 Validation Decoder Loss:  0.36385298
Encoder Loss:  0.07493444  || Decoder Loss:  0.0301123 Validation Decoder Loss:  0.36635804
Encoder Loss:  0.073406145  || Decoder Loss:  0.030206393 Validation Decoder Loss:  0.36763796
Encoder Loss:  0.07594787  || Decoder Loss:  0.03096221 Validation Decoder Loss:  0.36006156
Encoder Loss:  0.07168343  || Decoder Loss:  0.033041425 Validation Decoder Loss:  0.35265818
Encoder Loss:  0.06900435  || Decoder Loss:  0.033044003 Validation Decoder Loss:  0.37467292
Encoder Loss:  0.058104143  || Decoder Loss:  0.032425508 Validation Decoder Loss:  0.35729507
Encoder Loss:  0.06898615  || Decoder Loss:  0.032241907 Validation Decoder Loss:  0.36369097
Encoder Loss:  0.06865387  || Decoder Loss:  0.032726616 Validation Decoder Loss:  0.3741886
Encoder Loss:  0.0770223  || Decoder Loss:  0.034087554 Validation Decoder Loss:  0.37646684
Encoder Loss:  0.062192272  || Decoder Loss:  0.03579787 Validation Decoder Loss:  0.35191143
Encoder Loss:  0.058438074  || Decoder Loss:  0.034991138 Validation Decoder Loss:  0.36015385
Encoder Loss:  0.054394733  || Decoder Loss:  0.034144092 Validation Decoder Loss:  0.35297096
Encoder Loss:  0.06980719  || Decoder Loss:  0.034034394 Validation Decoder Loss:  0.3526504
Encoder Loss:  0.06606458  || Decoder Loss:  0.034589134 Validation Decoder Loss:  0.33789784
Encoder Loss:  0.06973128  || Decoder Loss:  0.03491593 Validation Decoder Loss:  0.3753096
Encoder Loss:  0.061357547  || Decoder Loss:  0.03546799 Validation Decoder Loss:  0.3362317
Encoder Loss:  0.0557323  || Decoder Loss:  0.034368567 Validation Decoder Loss:  0.3552689
Encoder Loss:  0.068175346  || Decoder Loss:  0.03412237 Validation Decoder Loss:  0.34270778
Model: siamese_net_lr_0.02437977982258857 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34270778
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 92, 10, 20, 1)     175       
_________________________________________________________________
reshape_95 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.085976906  || Decoder Loss:  0.072663315 Validation Decoder Loss:  0.34782243
Encoder Loss:  0.047136206  || Decoder Loss:  0.035279892 Validation Decoder Loss:  0.3475986
Encoder Loss:  0.047163855  || Decoder Loss:  0.034487966 Validation Decoder Loss:  0.3487463
Encoder Loss:  0.04467365  || Decoder Loss:  0.0340344 Validation Decoder Loss:  0.34871176
Encoder Loss:  0.042666003  || Decoder Loss:  0.03366299 Validation Decoder Loss:  0.34794128
Encoder Loss:  0.04275114  || Decoder Loss:  0.03335081 Validation Decoder Loss:  0.347484
Encoder Loss:  0.039536886  || Decoder Loss:  0.03308095 Validation Decoder Loss:  0.3475158
Encoder Loss:  0.044571586  || Decoder Loss:  0.03287336 Validation Decoder Loss:  0.3464307
Encoder Loss:  0.043107733  || Decoder Loss:  0.03268755 Validation Decoder Loss:  0.34675992
Encoder Loss:  0.04640665  || Decoder Loss:  0.032518614 Validation Decoder Loss:  0.34793
Encoder Loss:  0.044536125  || Decoder Loss:  0.03235693 Validation Decoder Loss:  0.34342897
Encoder Loss:  0.049234863  || Decoder Loss:  0.032397054 Validation Decoder Loss:  0.349801
Encoder Loss:  0.04030385  || Decoder Loss:  0.032108195 Validation Decoder Loss:  0.3453825
Encoder Loss:  0.038946144  || Decoder Loss:  0.03203279 Validation Decoder Loss:  0.34590682
Encoder Loss:  0.039026916  || Decoder Loss:  0.031874422 Validation Decoder Loss:  0.34580854
Encoder Loss:  0.03876445  || Decoder Loss:  0.03179669 Validation Decoder Loss:  0.34470668
Encoder Loss:  0.04030075  || Decoder Loss:  0.031734794 Validation Decoder Loss:  0.34666505
Encoder Loss:  0.038010117  || Decoder Loss:  0.03164371 Validation Decoder Loss:  0.34657234
Encoder Loss:  0.03781764  || Decoder Loss:  0.031558145 Validation Decoder Loss:  0.34536213
Encoder Loss:  0.038426686  || Decoder Loss:  0.03151586 Validation Decoder Loss:  0.34689504
Encoder Loss:  0.038310956  || Decoder Loss:  0.031452265 Validation Decoder Loss:  0.34730238
Encoder Loss:  0.03928955  || Decoder Loss:  0.031381816 Validation Decoder Loss:  0.34702188
Encoder Loss:  0.037556134  || Decoder Loss:  0.031319737 Validation Decoder Loss:  0.34749228
Encoder Loss:  0.04064575  || Decoder Loss:  0.03130398 Validation Decoder Loss:  0.35074025
Encoder Loss:  0.038536616  || Decoder Loss:  0.031207204 Validation Decoder Loss:  0.3486361
Encoder Loss:  0.040663462  || Decoder Loss:  0.031165704 Validation Decoder Loss:  0.34924325
Encoder Loss:  0.0374534  || Decoder Loss:  0.031108752 Validation Decoder Loss:  0.34824076
Encoder Loss:  0.04145597  || Decoder Loss:  0.0311588 Validation Decoder Loss:  0.34864902
Encoder Loss:  0.037196502  || Decoder Loss:  0.031046532 Validation Decoder Loss:  0.3469358
Encoder Loss:  0.03685904  || Decoder Loss:  0.031003006 Validation Decoder Loss:  0.3476581
Encoder Loss:  0.036777597  || Decoder Loss:  0.030984087 Validation Decoder Loss:  0.3489836
Encoder Loss:  0.037058163  || Decoder Loss:  0.03093768 Validation Decoder Loss:  0.34811807
Encoder Loss:  0.03688773  || Decoder Loss:  0.030919146 Validation Decoder Loss:  0.3492416
Encoder Loss:  0.036961738  || Decoder Loss:  0.030878052 Validation Decoder Loss:  0.34880114
Encoder Loss:  0.03647139  || Decoder Loss:  0.030847404 Validation Decoder Loss:  0.34929073
Encoder Loss:  0.03806907  || Decoder Loss:  0.030841975 Validation Decoder Loss:  0.34817824
Encoder Loss:  0.037390925  || Decoder Loss:  0.03079588 Validation Decoder Loss:  0.3484437
Encoder Loss:  0.036713995  || Decoder Loss:  0.030766672 Validation Decoder Loss:  0.3491018
Encoder Loss:  0.03669404  || Decoder Loss:  0.030744158 Validation Decoder Loss:  0.34995
Encoder Loss:  0.036082797  || Decoder Loss:  0.030711586 Validation Decoder Loss:  0.3500576
Model: siamese_net_lr_0.0032776752677827403 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3500576
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_96 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 620, 20, 1)        2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4665838  || Decoder Loss:  0.89991486 Validation Decoder Loss:  1.6386771
Encoder Loss:  0.471618  || Decoder Loss:  0.91538256 Validation Decoder Loss:  1.6353798
Encoder Loss:  0.46875474  || Decoder Loss:  0.91101366 Validation Decoder Loss:  1.6304339
Encoder Loss:  0.4627882  || Decoder Loss:  0.90477395 Validation Decoder Loss:  1.6228873
Encoder Loss:  0.4449656  || Decoder Loss:  0.8947161 Validation Decoder Loss:  1.6084156
Encoder Loss:  0.24333578  || Decoder Loss:  0.5745935 Validation Decoder Loss:  0.62682164
Encoder Loss:  0.12359894  || Decoder Loss:  0.4051878 Validation Decoder Loss:  0.56831425
Encoder Loss:  0.12035602  || Decoder Loss:  0.40742898 Validation Decoder Loss:  0.6359689
Encoder Loss:  0.11253233  || Decoder Loss:  0.41157848 Validation Decoder Loss:  0.7802351
Encoder Loss:  0.11194072  || Decoder Loss:  0.4328631 Validation Decoder Loss:  0.83593756
Encoder Loss:  0.107512005  || Decoder Loss:  0.44187278 Validation Decoder Loss:  0.7598854
Encoder Loss:  0.110714674  || Decoder Loss:  0.4461549 Validation Decoder Loss:  0.6949148
Encoder Loss:  0.10915304  || Decoder Loss:  0.43245 Validation Decoder Loss:  0.71766603
Encoder Loss:  0.10827999  || Decoder Loss:  0.4263273 Validation Decoder Loss:  0.6711268
Encoder Loss:  0.109978825  || Decoder Loss:  0.4183035 Validation Decoder Loss:  0.80512685
Encoder Loss:  0.105474584  || Decoder Loss:  0.41539422 Validation Decoder Loss:  0.6757723
Encoder Loss:  0.10779256  || Decoder Loss:  0.41095233 Validation Decoder Loss:  0.76452607
Encoder Loss:  0.10350545  || Decoder Loss:  0.40004405 Validation Decoder Loss:  0.69720924
Encoder Loss:  0.101782605  || Decoder Loss:  0.3583264 Validation Decoder Loss:  0.6135317
Encoder Loss:  0.08760375  || Decoder Loss:  0.09028387 Validation Decoder Loss:  0.41738728
Encoder Loss:  0.08535308  || Decoder Loss:  0.054942228 Validation Decoder Loss:  0.4265414
Encoder Loss:  0.08366972  || Decoder Loss:  0.04834616 Validation Decoder Loss:  0.35963225
Encoder Loss:  0.08163426  || Decoder Loss:  0.038946602 Validation Decoder Loss:  0.39246988
Encoder Loss:  0.0807585  || Decoder Loss:  0.0347845 Validation Decoder Loss:  0.3646493
Encoder Loss:  0.07936011  || Decoder Loss:  0.0312728 Validation Decoder Loss:  0.3780384
Encoder Loss:  0.0785556  || Decoder Loss:  0.033225775 Validation Decoder Loss:  0.3323147
Encoder Loss:  0.07778386  || Decoder Loss:  0.030569863 Validation Decoder Loss:  0.3344011
Encoder Loss:  0.07705058  || Decoder Loss:  0.030732607 Validation Decoder Loss:  0.33420205
Encoder Loss:  0.07510535  || Decoder Loss:  0.02881089 Validation Decoder Loss:  0.33920977
Encoder Loss:  0.074648045  || Decoder Loss:  0.028405346 Validation Decoder Loss:  0.33814538
Encoder Loss:  0.06392706  || Decoder Loss:  0.028122162 Validation Decoder Loss:  0.3366583
Encoder Loss:  0.06541726  || Decoder Loss:  0.027735576 Validation Decoder Loss:  0.34073085
Encoder Loss:  0.07552083  || Decoder Loss:  0.027978772 Validation Decoder Loss:  0.3380829
Encoder Loss:  0.074257344  || Decoder Loss:  0.028059931 Validation Decoder Loss:  0.33832568
Encoder Loss:  0.067279555  || Decoder Loss:  0.028434537 Validation Decoder Loss:  0.33838367
Encoder Loss:  0.068225294  || Decoder Loss:  0.028712545 Validation Decoder Loss:  0.33756113
Encoder Loss:  0.06280446  || Decoder Loss:  0.028638374 Validation Decoder Loss:  0.3412612
Encoder Loss:  0.069966  || Decoder Loss:  0.029342152 Validation Decoder Loss:  0.33758008
Encoder Loss:  0.076883025  || Decoder Loss:  0.032125108 Validation Decoder Loss:  0.35213718
Encoder Loss:  0.063082725  || Decoder Loss:  0.035722956 Validation Decoder Loss:  0.3620628
Model: siamese_net_lr_0.055623216240363614 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3620628
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_97 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_97 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 620, 20, 1)        1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 3245, 20, 1)       2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.52085227  || Decoder Loss:  0.8937105 Validation Decoder Loss:  1.6147113
Encoder Loss:  0.52575606  || Decoder Loss:  0.8897199 Validation Decoder Loss:  1.5795782
Encoder Loss:  0.51560014  || Decoder Loss:  0.84783244 Validation Decoder Loss:  1.4780239
Encoder Loss:  0.47787103  || Decoder Loss:  0.68079674 Validation Decoder Loss:  0.85688645
Encoder Loss:  0.32144776  || Decoder Loss:  0.37364206 Validation Decoder Loss:  0.993853
Encoder Loss:  0.16133131  || Decoder Loss:  0.40633515 Validation Decoder Loss:  1.3559098
Encoder Loss:  0.15382375  || Decoder Loss:  0.39966962 Validation Decoder Loss:  1.2329535
Encoder Loss:  0.14893329  || Decoder Loss:  0.39156768 Validation Decoder Loss:  1.2617636
Encoder Loss:  0.14704356  || Decoder Loss:  0.37006187 Validation Decoder Loss:  1.252003
Encoder Loss:  0.13937345  || Decoder Loss:  0.3418591 Validation Decoder Loss:  1.2088857
Encoder Loss:  0.119680226  || Decoder Loss:  0.23549116 Validation Decoder Loss:  0.7091234
Encoder Loss:  0.08648311  || Decoder Loss:  0.061203253 Validation Decoder Loss:  0.39806098
Encoder Loss:  0.0856845  || Decoder Loss:  0.033621345 Validation Decoder Loss:  0.3575104
Encoder Loss:  0.08113163  || Decoder Loss:  0.02949407 Validation Decoder Loss:  0.3570133
Encoder Loss:  0.08272756  || Decoder Loss:  0.028587604 Validation Decoder Loss:  0.35832554
Encoder Loss:  0.07944006  || Decoder Loss:  0.02827378 Validation Decoder Loss:  0.357949
Encoder Loss:  0.07896774  || Decoder Loss:  0.028176151 Validation Decoder Loss:  0.35904297
Encoder Loss:  0.079018004  || Decoder Loss:  0.028123064 Validation Decoder Loss:  0.3612965
Encoder Loss:  0.07871549  || Decoder Loss:  0.028102903 Validation Decoder Loss:  0.36076152
Encoder Loss:  0.07744142  || Decoder Loss:  0.028110959 Validation Decoder Loss:  0.3619703
Encoder Loss:  0.07838915  || Decoder Loss:  0.028153673 Validation Decoder Loss:  0.36241376
Encoder Loss:  0.077079974  || Decoder Loss:  0.028188486 Validation Decoder Loss:  0.3611391
Encoder Loss:  0.0750793  || Decoder Loss:  0.028243922 Validation Decoder Loss:  0.36061466
Encoder Loss:  0.074793175  || Decoder Loss:  0.028343534 Validation Decoder Loss:  0.36198387
Encoder Loss:  0.0747025  || Decoder Loss:  0.028465383 Validation Decoder Loss:  0.3621438
Encoder Loss:  0.073564015  || Decoder Loss:  0.0285615 Validation Decoder Loss:  0.3629863
Encoder Loss:  0.07173781  || Decoder Loss:  0.028724238 Validation Decoder Loss:  0.36303154
Encoder Loss:  0.07180956  || Decoder Loss:  0.028884513 Validation Decoder Loss:  0.3609246
Encoder Loss:  0.07100405  || Decoder Loss:  0.029020429 Validation Decoder Loss:  0.36179078
Encoder Loss:  0.06766582  || Decoder Loss:  0.02920734 Validation Decoder Loss:  0.36150557
Encoder Loss:  0.06738962  || Decoder Loss:  0.029417805 Validation Decoder Loss:  0.3593263
Encoder Loss:  0.058823142  || Decoder Loss:  0.029601207 Validation Decoder Loss:  0.3581357
Encoder Loss:  0.06358979  || Decoder Loss:  0.029846635 Validation Decoder Loss:  0.35651687
Encoder Loss:  0.054643597  || Decoder Loss:  0.030001191 Validation Decoder Loss:  0.35590744
Encoder Loss:  0.064514734  || Decoder Loss:  0.030209865 Validation Decoder Loss:  0.35279414
Encoder Loss:  0.07411481  || Decoder Loss:  0.030291297 Validation Decoder Loss:  0.3580014
Encoder Loss:  0.08885732  || Decoder Loss:  0.030314444 Validation Decoder Loss:  0.36272496
Encoder Loss:  0.05670571  || Decoder Loss:  0.030660613 Validation Decoder Loss:  0.3706615
Encoder Loss:  0.06102959  || Decoder Loss:  0.031979047 Validation Decoder Loss:  0.35006928
Encoder Loss:  0.05470151  || Decoder Loss:  0.031868853 Validation Decoder Loss:  0.3725059
Model: siamese_net_lr_0.01713219580293546 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37250587
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_98 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 620, 20, 1)        770       
=================================================================
Total params: 770
Trainable params: 770
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 3245, 20, 1)       151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14885135  || Decoder Loss:  0.056579117 Validation Decoder Loss:  0.33255383
Encoder Loss:  0.13129368  || Decoder Loss:  0.03530614 Validation Decoder Loss:  0.33407277
Encoder Loss:  0.07869721  || Decoder Loss:  0.034808476 Validation Decoder Loss:  0.33979365
Encoder Loss:  0.09153648  || Decoder Loss:  0.03453706 Validation Decoder Loss:  0.3413529
Encoder Loss:  0.083613776  || Decoder Loss:  0.034369174 Validation Decoder Loss:  0.342316
Encoder Loss:  0.095177285  || Decoder Loss:  0.03424809 Validation Decoder Loss:  0.34311116
Encoder Loss:  0.09487057  || Decoder Loss:  0.034144327 Validation Decoder Loss:  0.34374776
Encoder Loss:  0.09454919  || Decoder Loss:  0.034034766 Validation Decoder Loss:  0.34376594
Encoder Loss:  0.1023293  || Decoder Loss:  0.0339582 Validation Decoder Loss:  0.34460014
Encoder Loss:  0.07162478  || Decoder Loss:  0.03389271 Validation Decoder Loss:  0.34479338
Encoder Loss:  0.072821744  || Decoder Loss:  0.03384305 Validation Decoder Loss:  0.34464392
Encoder Loss:  0.06030817  || Decoder Loss:  0.03380941 Validation Decoder Loss:  0.34441832
Encoder Loss:  0.06923868  || Decoder Loss:  0.033786464 Validation Decoder Loss:  0.34377396
Encoder Loss:  0.06314346  || Decoder Loss:  0.033769913 Validation Decoder Loss:  0.34315103
Encoder Loss:  0.056576017  || Decoder Loss:  0.033750273 Validation Decoder Loss:  0.34285647
Encoder Loss:  0.06687221  || Decoder Loss:  0.033740547 Validation Decoder Loss:  0.3428132
Encoder Loss:  0.067880556  || Decoder Loss:  0.033731613 Validation Decoder Loss:  0.34290573
Encoder Loss:  0.08040075  || Decoder Loss:  0.0337266 Validation Decoder Loss:  0.34277087
Encoder Loss:  0.06324536  || Decoder Loss:  0.033719566 Validation Decoder Loss:  0.34302178
Encoder Loss:  0.06569203  || Decoder Loss:  0.033719245 Validation Decoder Loss:  0.34327066
Encoder Loss:  0.06546106  || Decoder Loss:  0.033720296 Validation Decoder Loss:  0.34344894
Encoder Loss:  0.061794993  || Decoder Loss:  0.03371828 Validation Decoder Loss:  0.3434384
Encoder Loss:  0.065195024  || Decoder Loss:  0.033718538 Validation Decoder Loss:  0.3435682
Encoder Loss:  0.06389455  || Decoder Loss:  0.03372181 Validation Decoder Loss:  0.34471494
Encoder Loss:  0.06451528  || Decoder Loss:  0.033726253 Validation Decoder Loss:  0.34477997
Encoder Loss:  0.055405978  || Decoder Loss:  0.033726312 Validation Decoder Loss:  0.34512168
Encoder Loss:  0.06723044  || Decoder Loss:  0.033726886 Validation Decoder Loss:  0.34475356
Encoder Loss:  0.08426255  || Decoder Loss:  0.03373928 Validation Decoder Loss:  0.34704107
Encoder Loss:  0.06804676  || Decoder Loss:  0.033754114 Validation Decoder Loss:  0.3447392
Encoder Loss:  0.061724946  || Decoder Loss:  0.033743326 Validation Decoder Loss:  0.34365842
Encoder Loss:  0.062296674  || Decoder Loss:  0.033743802 Validation Decoder Loss:  0.3427723
Encoder Loss:  0.060002614  || Decoder Loss:  0.0337423 Validation Decoder Loss:  0.3425584
Encoder Loss:  0.060745593  || Decoder Loss:  0.03373968 Validation Decoder Loss:  0.34191024
Encoder Loss:  0.07042475  || Decoder Loss:  0.033734165 Validation Decoder Loss:  0.34226727
Encoder Loss:  0.06018969  || Decoder Loss:  0.033726104 Validation Decoder Loss:  0.3423376
Encoder Loss:  0.05962349  || Decoder Loss:  0.03373392 Validation Decoder Loss:  0.3415531
Encoder Loss:  0.066868365  || Decoder Loss:  0.033725012 Validation Decoder Loss:  0.34196153
Encoder Loss:  0.05748742  || Decoder Loss:  0.033728436 Validation Decoder Loss:  0.34241283
Encoder Loss:  0.05831649  || Decoder Loss:  0.033730503 Validation Decoder Loss:  0.3424125
Encoder Loss:  0.065430015  || Decoder Loss:  0.033731736 Validation Decoder Loss:  0.34149906
Model: siamese_net_lr_0.005569292972198569 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34149906
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 115, 8, 20, 1)     209       
_________________________________________________________________
reshape_99 (Reshape)         (None, 920, 20, 1)        0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29508483  || Decoder Loss:  0.32430595 Validation Decoder Loss:  0.73507535
Encoder Loss:  0.25027612  || Decoder Loss:  0.2719802 Validation Decoder Loss:  0.65636086
Encoder Loss:  0.21557276  || Decoder Loss:  0.24191754 Validation Decoder Loss:  0.6156353
Encoder Loss:  0.17558487  || Decoder Loss:  0.22431532 Validation Decoder Loss:  0.5803569
Encoder Loss:  0.15484661  || Decoder Loss:  0.20131308 Validation Decoder Loss:  0.5415932
Encoder Loss:  0.13831788  || Decoder Loss:  0.17785452 Validation Decoder Loss:  0.5096228
Encoder Loss:  0.12525366  || Decoder Loss:  0.15870681 Validation Decoder Loss:  0.48555428
Encoder Loss:  0.11524036  || Decoder Loss:  0.1440082 Validation Decoder Loss:  0.46744177
Encoder Loss:  0.107704856  || Decoder Loss:  0.13283558 Validation Decoder Loss:  0.45382887
Encoder Loss:  0.10166516  || Decoder Loss:  0.12414596 Validation Decoder Loss:  0.44288546
Encoder Loss:  0.09668539  || Decoder Loss:  0.116931446 Validation Decoder Loss:  0.433707
Encoder Loss:  0.09244787  || Decoder Loss:  0.11079103 Validation Decoder Loss:  0.425927
Encoder Loss:  0.08880129  || Decoder Loss:  0.10550938 Validation Decoder Loss:  0.4192464
Encoder Loss:  0.08563659  || Decoder Loss:  0.1009448 Validation Decoder Loss:  0.41347462
Encoder Loss:  0.08293516  || Decoder Loss:  0.09700017 Validation Decoder Loss:  0.40852267
Encoder Loss:  0.08063838  || Decoder Loss:  0.09360861 Validation Decoder Loss:  0.4042632
Encoder Loss:  0.07856758  || Decoder Loss:  0.09063226 Validation Decoder Loss:  0.4004588
Encoder Loss:  0.076710284  || Decoder Loss:  0.087956406 Validation Decoder Loss:  0.3970589
Encoder Loss:  0.07495523  || Decoder Loss:  0.085532404 Validation Decoder Loss:  0.3939507
Encoder Loss:  0.0734666  || Decoder Loss:  0.08334596 Validation Decoder Loss:  0.39120352
Encoder Loss:  0.07211718  || Decoder Loss:  0.08138483 Validation Decoder Loss:  0.38874188
Encoder Loss:  0.07085256  || Decoder Loss:  0.07959658 Validation Decoder Loss:  0.38648474
Encoder Loss:  0.069659114  || Decoder Loss:  0.077933535 Validation Decoder Loss:  0.38439125
Encoder Loss:  0.06852475  || Decoder Loss:  0.076373 Validation Decoder Loss:  0.3824172
Encoder Loss:  0.06753664  || Decoder Loss:  0.07492225 Validation Decoder Loss:  0.3806334
Encoder Loss:  0.066596344  || Decoder Loss:  0.07358215 Validation Decoder Loss:  0.37898648
Encoder Loss:  0.065678686  || Decoder Loss:  0.07232242 Validation Decoder Loss:  0.37741622
Encoder Loss:  0.064908564  || Decoder Loss:  0.071142904 Validation Decoder Loss:  0.37601662
Encoder Loss:  0.06412634  || Decoder Loss:  0.070057176 Validation Decoder Loss:  0.37471718
Encoder Loss:  0.06342799  || Decoder Loss:  0.06903399 Validation Decoder Loss:  0.3735156
Encoder Loss:  0.062756196  || Decoder Loss:  0.06806856 Validation Decoder Loss:  0.37238973
Encoder Loss:  0.062122393  || Decoder Loss:  0.06715097 Validation Decoder Loss:  0.37133396
Encoder Loss:  0.061531235  || Decoder Loss:  0.06628163 Validation Decoder Loss:  0.37035245
Encoder Loss:  0.06096606  || Decoder Loss:  0.06545877 Validation Decoder Loss:  0.36943728
Encoder Loss:  0.060420703  || Decoder Loss:  0.06467424 Validation Decoder Loss:  0.3685719
Encoder Loss:  0.05988497  || Decoder Loss:  0.06392187 Validation Decoder Loss:  0.36773914
Encoder Loss:  0.05938552  || Decoder Loss:  0.06319689 Validation Decoder Loss:  0.36694735
Encoder Loss:  0.058919605  || Decoder Loss:  0.06250006 Validation Decoder Loss:  0.36620614
Encoder Loss:  0.05847677  || Decoder Loss:  0.06183256 Validation Decoder Loss:  0.36551005
Encoder Loss:  0.05804494  || Decoder Loss:  0.061198667 Validation Decoder Loss:  0.36486346
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36486346
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_100 (Conv3D (None, 92, 10, 20, 1)     59        
_________________________________________________________________
reshape_100 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47241306  || Decoder Loss:  0.6372249 Validation Decoder Loss:  1.6376251
Encoder Loss:  0.36525396  || Decoder Loss:  0.5487097 Validation Decoder Loss:  1.6062926
Encoder Loss:  0.16433619  || Decoder Loss:  0.25932103 Validation Decoder Loss:  0.3568033
Encoder Loss:  0.058702003  || Decoder Loss:  0.03916191 Validation Decoder Loss:  0.35301206
Encoder Loss:  0.055217277  || Decoder Loss:  0.033549838 Validation Decoder Loss:  0.34617943
Encoder Loss:  0.054575443  || Decoder Loss:  0.03316256 Validation Decoder Loss:  0.3510041
Encoder Loss:  0.051146526  || Decoder Loss:  0.03303375 Validation Decoder Loss:  0.35401285
Encoder Loss:  0.052258905  || Decoder Loss:  0.033030942 Validation Decoder Loss:  0.3431353
Encoder Loss:  0.05518115  || Decoder Loss:  0.03312145 Validation Decoder Loss:  0.34901404
Encoder Loss:  0.059926394  || Decoder Loss:  0.033116497 Validation Decoder Loss:  0.36171198
Encoder Loss:  0.05105034  || Decoder Loss:  0.0330704 Validation Decoder Loss:  0.35285223
Encoder Loss:  0.054286066  || Decoder Loss:  0.033129327 Validation Decoder Loss:  0.3528432
Encoder Loss:  0.05536054  || Decoder Loss:  0.0347935 Validation Decoder Loss:  0.3438628
Encoder Loss:  0.051790506  || Decoder Loss:  0.0373443 Validation Decoder Loss:  0.34345424
Encoder Loss:  0.052791458  || Decoder Loss:  0.03739153 Validation Decoder Loss:  0.34478897
Encoder Loss:  0.057615228  || Decoder Loss:  0.037706506 Validation Decoder Loss:  0.36150646
Encoder Loss:  0.052305087  || Decoder Loss:  0.040337976 Validation Decoder Loss:  0.365677
Encoder Loss:  0.051941685  || Decoder Loss:  0.039886966 Validation Decoder Loss:  0.35186258
Encoder Loss:  0.04968522  || Decoder Loss:  0.03423776 Validation Decoder Loss:  0.3541244
Encoder Loss:  0.05003521  || Decoder Loss:  0.03541284 Validation Decoder Loss:  0.35810328
Encoder Loss:  0.050207287  || Decoder Loss:  0.0361122 Validation Decoder Loss:  0.3542617
Encoder Loss:  0.052271076  || Decoder Loss:  0.035454582 Validation Decoder Loss:  0.36655468
Encoder Loss:  0.053907577  || Decoder Loss:  0.03802397 Validation Decoder Loss:  0.3526097
Encoder Loss:  0.047764197  || Decoder Loss:  0.035419617 Validation Decoder Loss:  0.35535413
Encoder Loss:  0.051175002  || Decoder Loss:  0.03669151 Validation Decoder Loss:  0.34971833
Encoder Loss:  0.049617235  || Decoder Loss:  0.034523774 Validation Decoder Loss:  0.35774517
Encoder Loss:  0.04788681  || Decoder Loss:  0.036657404 Validation Decoder Loss:  0.35337022
Encoder Loss:  0.04945275  || Decoder Loss:  0.035812534 Validation Decoder Loss:  0.348764
Encoder Loss:  0.045740377  || Decoder Loss:  0.033175156 Validation Decoder Loss:  0.35344866
Encoder Loss:  0.047764678  || Decoder Loss:  0.0344019 Validation Decoder Loss:  0.35360983
Encoder Loss:  0.05093145  || Decoder Loss:  0.035588317 Validation Decoder Loss:  0.35053927
Encoder Loss:  0.051482596  || Decoder Loss:  0.0354095 Validation Decoder Loss:  0.36005282
Encoder Loss:  0.049660932  || Decoder Loss:  0.037731793 Validation Decoder Loss:  0.35577062
Encoder Loss:  0.054416277  || Decoder Loss:  0.035756096 Validation Decoder Loss:  0.351345
Encoder Loss:  0.04964706  || Decoder Loss:  0.035092875 Validation Decoder Loss:  0.35506022
Encoder Loss:  0.048133444  || Decoder Loss:  0.03600823 Validation Decoder Loss:  0.3532278
Encoder Loss:  0.053444166  || Decoder Loss:  0.034282755 Validation Decoder Loss:  0.35900193
Encoder Loss:  0.055556383  || Decoder Loss:  0.036478024 Validation Decoder Loss:  0.3559731
Encoder Loss:  0.049065482  || Decoder Loss:  0.035907153 Validation Decoder Loss:  0.35054326
Encoder Loss:  0.04838055  || Decoder Loss:  0.034486413 Validation Decoder Loss:  0.35131744
Model: siamese_net_lr_0.013819056801770717 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3513174
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 614, 5, 20, 1)     111       
_________________________________________________________________
reshape_101 (Reshape)        (None, 3070, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7722542  || Decoder Loss:  0.9487247 Validation Decoder Loss:  1.6544964
Encoder Loss:  0.78979653  || Decoder Loss:  0.9657399 Validation Decoder Loss:  1.6547245
Encoder Loss:  0.78977853  || Decoder Loss:  0.9657077 Validation Decoder Loss:  1.6550217
Encoder Loss:  0.78974116  || Decoder Loss:  0.9656587 Validation Decoder Loss:  1.6554081
Encoder Loss:  0.7896916  || Decoder Loss:  0.9655934 Validation Decoder Loss:  1.6559024
Encoder Loss:  0.78962636  || Decoder Loss:  0.9655067 Validation Decoder Loss:  1.656533
Encoder Loss:  0.7895393  || Decoder Loss:  0.96538794 Validation Decoder Loss:  1.6573453
Encoder Loss:  0.7894172  || Decoder Loss:  0.96521837 Validation Decoder Loss:  1.658416
Encoder Loss:  0.78923297  || Decoder Loss:  0.96495664 Validation Decoder Loss:  1.6598926
Encoder Loss:  0.78891504  || Decoder Loss:  0.9644949 Validation Decoder Loss:  1.6621169
Encoder Loss:  0.78818023  || Decoder Loss:  0.9634043 Validation Decoder Loss:  1.6662725
Encoder Loss:  0.69032073  || Decoder Loss:  0.8151709 Validation Decoder Loss:  0.35965845
Encoder Loss:  0.17475627  || Decoder Loss:  0.034110572 Validation Decoder Loss:  0.35054648
Encoder Loss:  0.17469653  || Decoder Loss:  0.034053188 Validation Decoder Loss:  0.3502657
Encoder Loss:  0.17467967  || Decoder Loss:  0.03406561 Validation Decoder Loss:  0.3501857
Encoder Loss:  0.17465994  || Decoder Loss:  0.034079675 Validation Decoder Loss:  0.35011697
Encoder Loss:  0.17463614  || Decoder Loss:  0.034094904 Validation Decoder Loss:  0.3500461
Encoder Loss:  0.17460716  || Decoder Loss:  0.034111366 Validation Decoder Loss:  0.34997192
Encoder Loss:  0.17457117  || Decoder Loss:  0.03412911 Validation Decoder Loss:  0.3498943
Encoder Loss:  0.1745258  || Decoder Loss:  0.03414827 Validation Decoder Loss:  0.34981298
Encoder Loss:  0.17446728  || Decoder Loss:  0.034168936 Validation Decoder Loss:  0.34972787
Encoder Loss:  0.17438929  || Decoder Loss:  0.03419122 Validation Decoder Loss:  0.3496386
Encoder Loss:  0.17428072  || Decoder Loss:  0.03421529 Validation Decoder Loss:  0.34954497
Encoder Loss:  0.1741188  || Decoder Loss:  0.0342413 Validation Decoder Loss:  0.3494465
Encoder Loss:  0.17384702  || Decoder Loss:  0.034269452 Validation Decoder Loss:  0.34934264
Encoder Loss:  0.173258  || Decoder Loss:  0.03430006 Validation Decoder Loss:  0.34923238
Encoder Loss:  0.16564062  || Decoder Loss:  0.03433365 Validation Decoder Loss:  0.34911352
Encoder Loss:  0.16175547  || Decoder Loss:  0.034367055 Validation Decoder Loss:  0.34900364
Encoder Loss:  0.17046058  || Decoder Loss:  0.034405034 Validation Decoder Loss:  0.3488716
Encoder Loss:  0.13976878  || Decoder Loss:  0.03444849 Validation Decoder Loss:  0.348741
Encoder Loss:  0.07466785  || Decoder Loss:  0.034476466 Validation Decoder Loss:  0.34867597
Encoder Loss:  0.068554215  || Decoder Loss:  0.034488387 Validation Decoder Loss:  0.34862542
Encoder Loss:  0.072307356  || Decoder Loss:  0.034498587 Validation Decoder Loss:  0.34857744
Encoder Loss:  0.0600501  || Decoder Loss:  0.03450772 Validation Decoder Loss:  0.34853023
Encoder Loss:  0.084551856  || Decoder Loss:  0.034517534 Validation Decoder Loss:  0.34846854
Encoder Loss:  0.06148992  || Decoder Loss:  0.034532364 Validation Decoder Loss:  0.34842056
Encoder Loss:  0.0466125  || Decoder Loss:  0.034536816 Validation Decoder Loss:  0.34839034
Encoder Loss:  0.05004454  || Decoder Loss:  0.034538146 Validation Decoder Loss:  0.34835827
Encoder Loss:  0.048600484  || Decoder Loss:  0.034541313 Validation Decoder Loss:  0.34832725
Encoder Loss:  0.0550529  || Decoder Loss:  0.03454493 Validation Decoder Loss:  0.34829223
Model: siamese_net_lr_0.08278002933553229 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34829223
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_102 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 920, 20, 1)        2327      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31364465  || Decoder Loss:  0.16845077 Validation Decoder Loss:  0.35943753
Encoder Loss:  0.26699498  || Decoder Loss:  0.05139722 Validation Decoder Loss:  0.3596549
Encoder Loss:  0.2665086  || Decoder Loss:  0.053447388 Validation Decoder Loss:  0.3619168
Encoder Loss:  0.26589626  || Decoder Loss:  0.058887232 Validation Decoder Loss:  0.37014258
Encoder Loss:  0.26340172  || Decoder Loss:  0.07463861 Validation Decoder Loss:  0.4131817
Encoder Loss:  0.26923093  || Decoder Loss:  0.33281752 Validation Decoder Loss:  1.085784
Encoder Loss:  0.24981089  || Decoder Loss:  0.4462357 Validation Decoder Loss:  0.9077544
Encoder Loss:  0.122040816  || Decoder Loss:  0.17821112 Validation Decoder Loss:  0.4158522
Encoder Loss:  0.061973576  || Decoder Loss:  0.046359982 Validation Decoder Loss:  0.35231483
Encoder Loss:  0.0537435  || Decoder Loss:  0.033765275 Validation Decoder Loss:  0.3511379
Encoder Loss:  0.052182365  || Decoder Loss:  0.033138383 Validation Decoder Loss:  0.3498138
Encoder Loss:  0.05063227  || Decoder Loss:  0.033108603 Validation Decoder Loss:  0.34926927
Encoder Loss:  0.05104031  || Decoder Loss:  0.03317596 Validation Decoder Loss:  0.34869847
Encoder Loss:  0.048605453  || Decoder Loss:  0.03321333 Validation Decoder Loss:  0.34832084
Encoder Loss:  0.046387814  || Decoder Loss:  0.033279575 Validation Decoder Loss:  0.34837097
Encoder Loss:  0.04878571  || Decoder Loss:  0.03332459 Validation Decoder Loss:  0.3478782
Encoder Loss:  0.04913938  || Decoder Loss:  0.033292364 Validation Decoder Loss:  0.3478027
Encoder Loss:  0.046982754  || Decoder Loss:  0.033296496 Validation Decoder Loss:  0.34723222
Encoder Loss:  0.048167583  || Decoder Loss:  0.03330972 Validation Decoder Loss:  0.3477615
Encoder Loss:  0.04842328  || Decoder Loss:  0.03331516 Validation Decoder Loss:  0.3525386
Encoder Loss:  0.044770382  || Decoder Loss:  0.033559613 Validation Decoder Loss:  0.35373765
Encoder Loss:  0.04942219  || Decoder Loss:  0.033770338 Validation Decoder Loss:  0.35581714
Encoder Loss:  0.044877984  || Decoder Loss:  0.034291953 Validation Decoder Loss:  0.34902555
Encoder Loss:  0.05167196  || Decoder Loss:  0.034174755 Validation Decoder Loss:  0.34228003
Encoder Loss:  0.048135865  || Decoder Loss:  0.03467281 Validation Decoder Loss:  0.35531354
Encoder Loss:  0.04587655  || Decoder Loss:  0.033670727 Validation Decoder Loss:  0.34807438
Encoder Loss:  0.044220123  || Decoder Loss:  0.03350996 Validation Decoder Loss:  0.34091163
Encoder Loss:  0.04690885  || Decoder Loss:  0.034448005 Validation Decoder Loss:  0.35888898
Encoder Loss:  0.051291496  || Decoder Loss:  0.03426455 Validation Decoder Loss:  0.34225023
Encoder Loss:  0.048485927  || Decoder Loss:  0.03447012 Validation Decoder Loss:  0.34309623
Encoder Loss:  0.04981066  || Decoder Loss:  0.03479742 Validation Decoder Loss:  0.35303456
Encoder Loss:  0.046768874  || Decoder Loss:  0.034101855 Validation Decoder Loss:  0.34257326
Encoder Loss:  0.051165227  || Decoder Loss:  0.03556755 Validation Decoder Loss:  0.34850672
Encoder Loss:  0.047478624  || Decoder Loss:  0.035136 Validation Decoder Loss:  0.34127712
Encoder Loss:  0.046515428  || Decoder Loss:  0.034858167 Validation Decoder Loss:  0.34915403
Encoder Loss:  0.049828302  || Decoder Loss:  0.034009513 Validation Decoder Loss:  0.36147383
Encoder Loss:  0.047723394  || Decoder Loss:  0.03488805 Validation Decoder Loss:  0.35618246
Encoder Loss:  0.04752593  || Decoder Loss:  0.034858197 Validation Decoder Loss:  0.3439342
Encoder Loss:  0.0473839  || Decoder Loss:  0.034363702 Validation Decoder Loss:  0.34833333
Encoder Loss:  0.048510607  || Decoder Loss:  0.03464909 Validation Decoder Loss:  0.3534883
Model: siamese_net_lr_0.018385452116710374 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3534883
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_103 (Conv3D (None, 194, 5, 20, 1)     6         
_________________________________________________________________
reshape_103 (Reshape)        (None, 970, 20, 1)        0         
=================================================================
Total params: 6
Trainable params: 6
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 970, 20, 1)        2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 3245, 20, 1)       2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8745311  || Decoder Loss:  0.91384804 Validation Decoder Loss:  1.6331702
Encoder Loss:  0.8840363  || Decoder Loss:  0.9233968 Validation Decoder Loss:  1.6270794
Encoder Loss:  0.87421834  || Decoder Loss:  0.9126913 Validation Decoder Loss:  1.6147735
Encoder Loss:  0.8579172  || Decoder Loss:  0.89491653 Validation Decoder Loss:  1.5903062
Encoder Loss:  0.82964706  || Decoder Loss:  0.8640917 Validation Decoder Loss:  1.5399826
Encoder Loss:  0.77406913  || Decoder Loss:  0.80349463 Validation Decoder Loss:  1.4195676
Encoder Loss:  0.62701344  || Decoder Loss:  0.64320433 Validation Decoder Loss:  1.0171268
Encoder Loss:  0.26685664  || Decoder Loss:  0.2522846 Validation Decoder Loss:  0.46514904
Encoder Loss:  0.102605924  || Decoder Loss:  0.07114281 Validation Decoder Loss:  0.3953368
Encoder Loss:  0.08513072  || Decoder Loss:  0.052082893 Validation Decoder Loss:  0.38442087
Encoder Loss:  0.08145866  || Decoder Loss:  0.048078485 Validation Decoder Loss:  0.3792998
Encoder Loss:  0.079798676  || Decoder Loss:  0.046268668 Validation Decoder Loss:  0.37543067
Encoder Loss:  0.07868459  || Decoder Loss:  0.045054287 Validation Decoder Loss:  0.37218085
Encoder Loss:  0.07776629  || Decoder Loss:  0.044053532 Validation Decoder Loss:  0.36938405
Encoder Loss:  0.07692737  || Decoder Loss:  0.0431394 Validation Decoder Loss:  0.3669462
Encoder Loss:  0.07612536  || Decoder Loss:  0.042265616 Validation Decoder Loss:  0.36478698
Encoder Loss:  0.07534617  || Decoder Loss:  0.041416798 Validation Decoder Loss:  0.36283317
Encoder Loss:  0.07458746  || Decoder Loss:  0.0405904 Validation Decoder Loss:  0.36102206
Encoder Loss:  0.07385197  || Decoder Loss:  0.039789442 Validation Decoder Loss:  0.35930437
Encoder Loss:  0.07314479  || Decoder Loss:  0.03901946 Validation Decoder Loss:  0.35764644
Encoder Loss:  0.07247212  || Decoder Loss:  0.03828723 Validation Decoder Loss:  0.35602924
Encoder Loss:  0.07184061  || Decoder Loss:  0.03760003 Validation Decoder Loss:  0.3544467
Encoder Loss:  0.07125695  || Decoder Loss:  0.036965165 Validation Decoder Loss:  0.35290307
Encoder Loss:  0.070727274  || Decoder Loss:  0.036389332 Validation Decoder Loss:  0.35140938
Encoder Loss:  0.07025645  || Decoder Loss:  0.035877857 Validation Decoder Loss:  0.34998155
Encoder Loss:  0.06984736  || Decoder Loss:  0.035433907 Validation Decoder Loss:  0.34863684
Encoder Loss:  0.06950028  || Decoder Loss:  0.035057813 Validation Decoder Loss:  0.34739232
Encoder Loss:  0.06921255  || Decoder Loss:  0.03474665 Validation Decoder Loss:  0.34626216
Encoder Loss:  0.068978645  || Decoder Loss:  0.034494463 Validation Decoder Loss:  0.34525648
Encoder Loss:  0.068790935  || Decoder Loss:  0.03429294 Validation Decoder Loss:  0.34437978
Encoder Loss:  0.06864069  || Decoder Loss:  0.034132585 Validation Decoder Loss:  0.343631
Encoder Loss:  0.06851921  || Decoder Loss:  0.034003958 Validation Decoder Loss:  0.34300354
Encoder Loss:  0.06841877  || Decoder Loss:  0.033898648 Validation Decoder Loss:  0.34248668
Encoder Loss:  0.06833309  || Decoder Loss:  0.03380988 Validation Decoder Loss:  0.342067
Encoder Loss:  0.06825748  || Decoder Loss:  0.033732582 Validation Decoder Loss:  0.34172985
Encoder Loss:  0.06818864  || Decoder Loss:  0.033663183 Validation Decoder Loss:  0.34146082
Encoder Loss:  0.06812425  || Decoder Loss:  0.033599284 Validation Decoder Loss:  0.34124675
Encoder Loss:  0.06806281  || Decoder Loss:  0.033539303 Validation Decoder Loss:  0.34107623
Encoder Loss:  0.06800327  || Decoder Loss:  0.03348218 Validation Decoder Loss:  0.3409396
Encoder Loss:  0.06794484  || Decoder Loss:  0.03342722 Validation Decoder Loss:  0.34082934
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3408293
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_104 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 920, 20, 1)        489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 3245, 20, 1)       1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18389013  || Decoder Loss:  0.26766765 Validation Decoder Loss:  0.61229527
Encoder Loss:  0.14984931  || Decoder Loss:  0.21249245 Validation Decoder Loss:  0.5404496
Encoder Loss:  0.12774476  || Decoder Loss:  0.17629296 Validation Decoder Loss:  0.497379
Encoder Loss:  0.114162266  || Decoder Loss:  0.15389496 Validation Decoder Loss:  0.47019047
Encoder Loss:  0.10509088  || Decoder Loss:  0.13893919 Validation Decoder Loss:  0.4512344
Encoder Loss:  0.09849779  || Decoder Loss:  0.12808543 Validation Decoder Loss:  0.43713683
Encoder Loss:  0.09343719  || Decoder Loss:  0.119721934 Validation Decoder Loss:  0.42609543
Encoder Loss:  0.08931158  || Decoder Loss:  0.11302053 Validation Decoder Loss:  0.4171364
Encoder Loss:  0.08596689  || Decoder Loss:  0.10743441 Validation Decoder Loss:  0.40977478
Encoder Loss:  0.08307272  || Decoder Loss:  0.10273566 Validation Decoder Loss:  0.4034512
Encoder Loss:  0.080593206  || Decoder Loss:  0.09863511 Validation Decoder Loss:  0.39802027
Encoder Loss:  0.07841024  || Decoder Loss:  0.09505326 Validation Decoder Loss:  0.39328763
Encoder Loss:  0.076479204  || Decoder Loss:  0.091869354 Validation Decoder Loss:  0.3890897
Encoder Loss:  0.074703395  || Decoder Loss:  0.089009695 Validation Decoder Loss:  0.3853503
Encoder Loss:  0.07314576  || Decoder Loss:  0.08640442 Validation Decoder Loss:  0.38201952
Encoder Loss:  0.07172347  || Decoder Loss:  0.08404005 Validation Decoder Loss:  0.37898457
Encoder Loss:  0.07032042  || Decoder Loss:  0.081865795 Validation Decoder Loss:  0.3762173
Encoder Loss:  0.06915538  || Decoder Loss:  0.07983949 Validation Decoder Loss:  0.37373176
Encoder Loss:  0.0679868  || Decoder Loss:  0.077973574 Validation Decoder Loss:  0.37142223
Encoder Loss:  0.06690581  || Decoder Loss:  0.07621968 Validation Decoder Loss:  0.3692797
Encoder Loss:  0.06590438  || Decoder Loss:  0.074572586 Validation Decoder Loss:  0.36730713
Encoder Loss:  0.06495771  || Decoder Loss:  0.07303004 Validation Decoder Loss:  0.3654898
Encoder Loss:  0.06407509  || Decoder Loss:  0.0715772 Validation Decoder Loss:  0.36381167
Encoder Loss:  0.06324023  || Decoder Loss:  0.07020912 Validation Decoder Loss:  0.3622589
Encoder Loss:  0.06243559  || Decoder Loss:  0.06891583 Validation Decoder Loss:  0.36081728
Encoder Loss:  0.06172374  || Decoder Loss:  0.06769341 Validation Decoder Loss:  0.3595281
Encoder Loss:  0.06101584  || Decoder Loss:  0.06654155 Validation Decoder Loss:  0.35831285
Encoder Loss:  0.060317434  || Decoder Loss:  0.06544018 Validation Decoder Loss:  0.35715708
Encoder Loss:  0.05966301  || Decoder Loss:  0.06438828 Validation Decoder Loss:  0.3560884
Encoder Loss:  0.059090562  || Decoder Loss:  0.06338915 Validation Decoder Loss:  0.3551259
Encoder Loss:  0.058495924  || Decoder Loss:  0.062441472 Validation Decoder Loss:  0.35422516
Encoder Loss:  0.05795116  || Decoder Loss:  0.06153606 Validation Decoder Loss:  0.35339138
Encoder Loss:  0.05740205  || Decoder Loss:  0.06067246 Validation Decoder Loss:  0.35260656
Encoder Loss:  0.05687863  || Decoder Loss:  0.05984323 Validation Decoder Loss:  0.35185075
Encoder Loss:  0.056388192  || Decoder Loss:  0.05904829 Validation Decoder Loss:  0.3511693
Encoder Loss:  0.055924736  || Decoder Loss:  0.058292273 Validation Decoder Loss:  0.35054255
Encoder Loss:  0.05549421  || Decoder Loss:  0.057570845 Validation Decoder Loss:  0.3499706
Encoder Loss:  0.055061493  || Decoder Loss:  0.056879625 Validation Decoder Loss:  0.3494202
Encoder Loss:  0.05464787  || Decoder Loss:  0.056216046 Validation Decoder Loss:  0.34891355
Encoder Loss:  0.054269515  || Decoder Loss:  0.055582654 Validation Decoder Loss:  0.34845465
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34845465
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 184, 5, 20, 1)     122       
_________________________________________________________________
reshape_105 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 920, 20, 1)        1408      
=================================================================
Total params: 1,408
Trainable params: 1,408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 3245, 20, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [1.00000000e-05 1.00000000e+00 5.16029855e-01 5.14981452e-01
 8.73502979e-01 0.00000000e+00 9.20000000e+02]
Optimized Validation Decoder Loss: 0.31220173835754395











Optimizing at level  2
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 98, 5, 20, 1)      36        
_________________________________________________________________
dropout_243 (Dropout)        (None, 98, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 184, 5, 20, 1)     88        
_________________________________________________________________
reshape_106 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 1550, 20, 1)       148       
_________________________________________________________________
dropout_245 (Dropout)        (None, 1550, 20, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 920, 20, 1)        632       
=================================================================
Total params: 780
Trainable params: 780
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 3040, 20, 1)       284       
_________________________________________________________________
dropout_247 (Dropout)        (None, 3040, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 3245, 20, 1)       207       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30206376  || Decoder Loss:  0.1898796 Validation Decoder Loss:  0.27671266
Encoder Loss:  0.25344902  || Decoder Loss:  0.37177524 Validation Decoder Loss:  0.5417987
Encoder Loss:  0.22526443  || Decoder Loss:  0.49041012 Validation Decoder Loss:  0.64872205
Encoder Loss:  0.2167129  || Decoder Loss:  0.49717999 Validation Decoder Loss:  0.6452743
Encoder Loss:  0.21667118  || Decoder Loss:  0.49649677 Validation Decoder Loss:  0.6384984
Encoder Loss:  0.21664633  || Decoder Loss:  0.49672616 Validation Decoder Loss:  0.6460185
Encoder Loss:  0.2163926  || Decoder Loss:  0.49614704 Validation Decoder Loss:  0.6653362
Encoder Loss:  0.22272764  || Decoder Loss:  0.49901986 Validation Decoder Loss:  0.66734225
Encoder Loss:  0.22006771  || Decoder Loss:  0.4967952 Validation Decoder Loss:  0.6392478
Encoder Loss:  0.21931028  || Decoder Loss:  0.4970424 Validation Decoder Loss:  0.64230967
Encoder Loss:  0.2194118  || Decoder Loss:  0.49450386 Validation Decoder Loss:  0.6720567
Encoder Loss:  0.21832308  || Decoder Loss:  0.49678418 Validation Decoder Loss:  0.66346025
Encoder Loss:  0.2230812  || Decoder Loss:  0.49781838 Validation Decoder Loss:  0.7412659
Encoder Loss:  0.21997595  || Decoder Loss:  0.49883133 Validation Decoder Loss:  0.6773542
Encoder Loss:  0.21799181  || Decoder Loss:  0.49464524 Validation Decoder Loss:  0.8366555
Encoder Loss:  0.21766171  || Decoder Loss:  0.49453515 Validation Decoder Loss:  1.0631425
Encoder Loss:  0.21458381  || Decoder Loss:  0.4932891 Validation Decoder Loss:  1.0418694
Encoder Loss:  0.2142842  || Decoder Loss:  0.49249858 Validation Decoder Loss:  1.0834923
Encoder Loss:  0.21553531  || Decoder Loss:  0.49253243 Validation Decoder Loss:  1.2291458
Encoder Loss:  0.21410875  || Decoder Loss:  0.49165177 Validation Decoder Loss:  1.2077097
Encoder Loss:  0.2148458  || Decoder Loss:  0.49197236 Validation Decoder Loss:  1.0980592
Encoder Loss:  0.21369463  || Decoder Loss:  0.49101856 Validation Decoder Loss:  1.1642168
Encoder Loss:  0.2149317  || Decoder Loss:  0.49095824 Validation Decoder Loss:  1.196584
Encoder Loss:  0.21532938  || Decoder Loss:  0.49082765 Validation Decoder Loss:  1.2851534
Encoder Loss:  0.2150605  || Decoder Loss:  0.48971978 Validation Decoder Loss:  1.0948367
Encoder Loss:  0.21458532  || Decoder Loss:  0.48962522 Validation Decoder Loss:  1.2484827
Encoder Loss:  0.21416534  || Decoder Loss:  0.48872468 Validation Decoder Loss:  1.2137065
Encoder Loss:  0.21191932  || Decoder Loss:  0.48612952 Validation Decoder Loss:  1.1176674
Encoder Loss:  0.21231292  || Decoder Loss:  0.48317844 Validation Decoder Loss:  1.0944357
Encoder Loss:  0.21172267  || Decoder Loss:  0.48235208 Validation Decoder Loss:  1.0887475
Encoder Loss:  0.210314  || Decoder Loss:  0.482131 Validation Decoder Loss:  1.0914221
Encoder Loss:  0.2131297  || Decoder Loss:  0.48222965 Validation Decoder Loss:  1.0109768
Encoder Loss:  0.21672054  || Decoder Loss:  0.4834657 Validation Decoder Loss:  1.1648498
Encoder Loss:  0.2111853  || Decoder Loss:  0.4811974 Validation Decoder Loss:  1.1024085
Encoder Loss:  0.210715  || Decoder Loss:  0.47995654 Validation Decoder Loss:  1.0670452
Encoder Loss:  0.20879963  || Decoder Loss:  0.47855067 Validation Decoder Loss:  0.9493997
Encoder Loss:  0.20865346  || Decoder Loss:  0.47815624 Validation Decoder Loss:  1.128443
Encoder Loss:  0.20871271  || Decoder Loss:  0.47630882 Validation Decoder Loss:  0.61767435
Encoder Loss:  0.21784641  || Decoder Loss:  0.49418914 Validation Decoder Loss:  1.2707751
Encoder Loss:  0.21311462  || Decoder Loss:  0.48628426 Validation Decoder Loss:  1.116865
Model: siamese_net_lr_0.06099731486586265 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.116865
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_249 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 184, 5, 20, 1)     66        
_________________________________________________________________
reshape_107 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 2370, 20, 1)       877       
_________________________________________________________________
dropout_251 (Dropout)        (None, 2370, 20, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 920, 20, 1)        533       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 2780, 20, 1)       943       
_________________________________________________________________
dropout_253 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 3245, 20, 1)       467       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7094274  || Decoder Loss:  0.77925664 Validation Decoder Loss:  1.6339403
Encoder Loss:  0.50714594  || Decoder Loss:  0.5722195 Validation Decoder Loss:  1.3787822
Encoder Loss:  0.44417164  || Decoder Loss:  0.5112799 Validation Decoder Loss:  1.3447468
Encoder Loss:  0.44094235  || Decoder Loss:  0.5059154 Validation Decoder Loss:  1.4018178
Encoder Loss:  0.4413969  || Decoder Loss:  0.50900835 Validation Decoder Loss:  1.4285972
Encoder Loss:  0.44209966  || Decoder Loss:  0.50934035 Validation Decoder Loss:  1.3517983
Encoder Loss:  0.42966557  || Decoder Loss:  0.4947222 Validation Decoder Loss:  1.2658839
Encoder Loss:  0.4207884  || Decoder Loss:  0.48518875 Validation Decoder Loss:  0.8106341
Encoder Loss:  0.4221957  || Decoder Loss:  0.48530963 Validation Decoder Loss:  0.9070462
Encoder Loss:  0.4193934  || Decoder Loss:  0.48357156 Validation Decoder Loss:  0.986354
Encoder Loss:  0.42226073  || Decoder Loss:  0.48639804 Validation Decoder Loss:  1.0590041
Encoder Loss:  0.4203427  || Decoder Loss:  0.4843329 Validation Decoder Loss:  0.9581319
Encoder Loss:  0.42113397  || Decoder Loss:  0.48465127 Validation Decoder Loss:  0.9372865
Encoder Loss:  0.42003524  || Decoder Loss:  0.48479798 Validation Decoder Loss:  0.98690706
Encoder Loss:  0.42016563  || Decoder Loss:  0.48404875 Validation Decoder Loss:  1.0118603
Encoder Loss:  0.42073643  || Decoder Loss:  0.48444498 Validation Decoder Loss:  1.0115812
Encoder Loss:  0.42085302  || Decoder Loss:  0.48510513 Validation Decoder Loss:  1.1411344
Encoder Loss:  0.42034963  || Decoder Loss:  0.4847413 Validation Decoder Loss:  1.1301527
Encoder Loss:  0.42058071  || Decoder Loss:  0.48439738 Validation Decoder Loss:  1.0452031
Encoder Loss:  0.42122266  || Decoder Loss:  0.48475143 Validation Decoder Loss:  1.0674294
Encoder Loss:  0.420026  || Decoder Loss:  0.484061 Validation Decoder Loss:  1.1017506
Encoder Loss:  0.41898945  || Decoder Loss:  0.4837722 Validation Decoder Loss:  1.0962266
Encoder Loss:  0.41895798  || Decoder Loss:  0.48365673 Validation Decoder Loss:  1.0967783
Encoder Loss:  0.4187358  || Decoder Loss:  0.48346165 Validation Decoder Loss:  1.0761971
Encoder Loss:  0.41852778  || Decoder Loss:  0.48315582 Validation Decoder Loss:  1.122315
Encoder Loss:  0.41804957  || Decoder Loss:  0.48263755 Validation Decoder Loss:  1.1394737
Encoder Loss:  0.41897133  || Decoder Loss:  0.48295283 Validation Decoder Loss:  1.1222005
Encoder Loss:  0.41805518  || Decoder Loss:  0.48243552 Validation Decoder Loss:  1.1448998
Encoder Loss:  0.41798005  || Decoder Loss:  0.4823772 Validation Decoder Loss:  1.1673992
Encoder Loss:  0.41790688  || Decoder Loss:  0.4822807 Validation Decoder Loss:  1.1358805
Encoder Loss:  0.41966277  || Decoder Loss:  0.48270896 Validation Decoder Loss:  1.2085947
Encoder Loss:  0.41908124  || Decoder Loss:  0.48250252 Validation Decoder Loss:  1.1603612
Encoder Loss:  0.4181742  || Decoder Loss:  0.48272157 Validation Decoder Loss:  1.1708467
Encoder Loss:  0.41862538  || Decoder Loss:  0.48297846 Validation Decoder Loss:  1.1425322
Encoder Loss:  0.41835687  || Decoder Loss:  0.48305357 Validation Decoder Loss:  1.1547549
Encoder Loss:  0.4180795  || Decoder Loss:  0.48241094 Validation Decoder Loss:  1.168359
Encoder Loss:  0.41774505  || Decoder Loss:  0.4823636 Validation Decoder Loss:  1.1805127
Encoder Loss:  0.41781014  || Decoder Loss:  0.4821866 Validation Decoder Loss:  1.1702797
Encoder Loss:  0.41716516  || Decoder Loss:  0.48156086 Validation Decoder Loss:  1.1965588
Encoder Loss:  0.41712153  || Decoder Loss:  0.48161352 Validation Decoder Loss:  1.1957518
Model: siamese_net_lr_0.05451346720139921 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1957518
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_255 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 184, 5, 20, 1)     66        
_________________________________________________________________
reshape_108 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_328"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 1750, 20, 1)       1497      
_________________________________________________________________
dropout_257 (Dropout)        (None, 1750, 20, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 920, 20, 1)        832       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 1290, 20, 1)       372       
_________________________________________________________________
dropout_259 (Dropout)        (None, 1290, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 3245, 20, 1)       668       
=================================================================
Total params: 1,040
Trainable params: 1,040
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2645938  || Decoder Loss:  0.18138342 Validation Decoder Loss:  0.3470494
Encoder Loss:  0.23864466  || Decoder Loss:  0.12570424 Validation Decoder Loss:  0.32564434
Encoder Loss:  0.2478846  || Decoder Loss:  0.19595614 Validation Decoder Loss:  0.9320067
Encoder Loss:  0.31308118  || Decoder Loss:  0.4895276 Validation Decoder Loss:  0.7021029
Encoder Loss:  0.30281222  || Decoder Loss:  0.48478046 Validation Decoder Loss:  0.7357135
Encoder Loss:  0.3047536  || Decoder Loss:  0.4903258 Validation Decoder Loss:  0.72419846
Encoder Loss:  0.3083901  || Decoder Loss:  0.4938104 Validation Decoder Loss:  0.7424835
Encoder Loss:  0.30363595  || Decoder Loss:  0.48462635 Validation Decoder Loss:  0.67795825
Encoder Loss:  0.30157897  || Decoder Loss:  0.4900869 Validation Decoder Loss:  0.7705099
Encoder Loss:  0.29999274  || Decoder Loss:  0.48574245 Validation Decoder Loss:  0.9273119
Encoder Loss:  0.29870364  || Decoder Loss:  0.48304328 Validation Decoder Loss:  0.949877
Encoder Loss:  0.29681844  || Decoder Loss:  0.48135552 Validation Decoder Loss:  0.92192197
Encoder Loss:  0.2997217  || Decoder Loss:  0.4822219 Validation Decoder Loss:  1.0306356
Encoder Loss:  0.29664335  || Decoder Loss:  0.48087642 Validation Decoder Loss:  0.93328726
Encoder Loss:  0.29582077  || Decoder Loss:  0.48016417 Validation Decoder Loss:  0.91439235
Encoder Loss:  0.29852465  || Decoder Loss:  0.47991413 Validation Decoder Loss:  0.8870827
Encoder Loss:  0.29874858  || Decoder Loss:  0.47910622 Validation Decoder Loss:  0.91578126
Encoder Loss:  0.3050795  || Decoder Loss:  0.4844491 Validation Decoder Loss:  0.95592403
Encoder Loss:  0.2972726  || Decoder Loss:  0.4796303 Validation Decoder Loss:  0.79323906
Encoder Loss:  0.29389602  || Decoder Loss:  0.476483 Validation Decoder Loss:  0.79485655
Encoder Loss:  0.29497397  || Decoder Loss:  0.47859806 Validation Decoder Loss:  0.68577355
Encoder Loss:  0.30000928  || Decoder Loss:  0.49026924 Validation Decoder Loss:  0.7570415
Encoder Loss:  0.3004951  || Decoder Loss:  0.4880893 Validation Decoder Loss:  0.7699594
Encoder Loss:  0.29978222  || Decoder Loss:  0.48837215 Validation Decoder Loss:  0.78952587
Encoder Loss:  0.29931644  || Decoder Loss:  0.48951757 Validation Decoder Loss:  0.7903714
Encoder Loss:  0.2999686  || Decoder Loss:  0.48868144 Validation Decoder Loss:  0.80930233
Encoder Loss:  0.3017837  || Decoder Loss:  0.48967344 Validation Decoder Loss:  0.8440426
Encoder Loss:  0.2992814  || Decoder Loss:  0.4882691 Validation Decoder Loss:  0.84795666
Encoder Loss:  0.2992518  || Decoder Loss:  0.48860943 Validation Decoder Loss:  0.85878664
Encoder Loss:  0.29863414  || Decoder Loss:  0.4887154 Validation Decoder Loss:  0.87629867
Encoder Loss:  0.30129474  || Decoder Loss:  0.49018106 Validation Decoder Loss:  0.83522964
Encoder Loss:  0.30122384  || Decoder Loss:  0.48618028 Validation Decoder Loss:  0.86959666
Encoder Loss:  0.2980661  || Decoder Loss:  0.48809963 Validation Decoder Loss:  0.8737138
Encoder Loss:  0.29901448  || Decoder Loss:  0.4889953 Validation Decoder Loss:  0.8788997
Encoder Loss:  0.2986672  || Decoder Loss:  0.48900494 Validation Decoder Loss:  0.87237847
Encoder Loss:  0.29881623  || Decoder Loss:  0.48879552 Validation Decoder Loss:  0.8878323
Encoder Loss:  0.29890144  || Decoder Loss:  0.4890958 Validation Decoder Loss:  0.9011388
Encoder Loss:  0.29854274  || Decoder Loss:  0.48886788 Validation Decoder Loss:  0.91307485
Encoder Loss:  0.2980954  || Decoder Loss:  0.4882092 Validation Decoder Loss:  0.9502548
Encoder Loss:  0.29860213  || Decoder Loss:  0.48890206 Validation Decoder Loss:  1.0459656
Model: siamese_net_lr_0.028898228881922235 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0459656
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 166, 5, 20, 1)     41        
_________________________________________________________________
dropout_261 (Dropout)        (None, 166, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 184, 5, 20, 1)     20        
_________________________________________________________________
reshape_109 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 2620, 20, 1)       627       
_________________________________________________________________
dropout_263 (Dropout)        (None, 2620, 20, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 920, 20, 1)        783       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 1090, 20, 1)       172       
_________________________________________________________________
dropout_265 (Dropout)        (None, 1090, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 3245, 20, 1)       2157      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.73734045  || Decoder Loss:  0.8302939 Validation Decoder Loss:  1.6170648
Encoder Loss:  0.8102022  || Decoder Loss:  0.91279936 Validation Decoder Loss:  1.6082859
Encoder Loss:  0.79783905  || Decoder Loss:  0.8973349 Validation Decoder Loss:  1.5862706
Encoder Loss:  0.77274966  || Decoder Loss:  0.86599076 Validation Decoder Loss:  1.5308409
Encoder Loss:  0.7148401  || Decoder Loss:  0.7935366 Validation Decoder Loss:  1.3716947
Encoder Loss:  0.5387259  || Decoder Loss:  0.586505 Validation Decoder Loss:  0.9176871
Encoder Loss:  0.5553008  || Decoder Loss:  0.5941447 Validation Decoder Loss:  0.93476343
Encoder Loss:  0.45494947  || Decoder Loss:  0.5027491 Validation Decoder Loss:  1.3007345
Encoder Loss:  0.45701098  || Decoder Loss:  0.54143405 Validation Decoder Loss:  1.2800516
Encoder Loss:  0.45329815  || Decoder Loss:  0.52253395 Validation Decoder Loss:  1.3120143
Encoder Loss:  0.4592086  || Decoder Loss:  0.5381682 Validation Decoder Loss:  1.2831175
Encoder Loss:  0.44808587  || Decoder Loss:  0.52541536 Validation Decoder Loss:  1.2086782
Encoder Loss:  0.44315815  || Decoder Loss:  0.52981305 Validation Decoder Loss:  1.1034325
Encoder Loss:  0.42358798  || Decoder Loss:  0.50926054 Validation Decoder Loss:  1.1361575
Encoder Loss:  0.41978064  || Decoder Loss:  0.5030055 Validation Decoder Loss:  1.1387904
Encoder Loss:  0.41810775  || Decoder Loss:  0.5012091 Validation Decoder Loss:  1.1326854
Encoder Loss:  0.41340482  || Decoder Loss:  0.4959745 Validation Decoder Loss:  1.1424887
Encoder Loss:  0.4081173  || Decoder Loss:  0.48850915 Validation Decoder Loss:  1.1344182
Encoder Loss:  0.4028735  || Decoder Loss:  0.48235026 Validation Decoder Loss:  1.1313317
Encoder Loss:  0.39656514  || Decoder Loss:  0.47462937 Validation Decoder Loss:  1.1199062
Encoder Loss:  0.3901307  || Decoder Loss:  0.46693122 Validation Decoder Loss:  1.141949
Encoder Loss:  0.38980773  || Decoder Loss:  0.46610937 Validation Decoder Loss:  1.1317781
Encoder Loss:  0.3824686  || Decoder Loss:  0.45696154 Validation Decoder Loss:  1.1393359
Encoder Loss:  0.38100824  || Decoder Loss:  0.45502728 Validation Decoder Loss:  1.1071746
Encoder Loss:  0.3754226  || Decoder Loss:  0.44864762 Validation Decoder Loss:  1.1390222
Encoder Loss:  0.37603197  || Decoder Loss:  0.44891354 Validation Decoder Loss:  1.1429572
Encoder Loss:  0.37395012  || Decoder Loss:  0.44578674 Validation Decoder Loss:  1.1276333
Encoder Loss:  0.37188417  || Decoder Loss:  0.44360122 Validation Decoder Loss:  1.11543
Encoder Loss:  0.3707534  || Decoder Loss:  0.44278407 Validation Decoder Loss:  1.14583
Encoder Loss:  0.36942142  || Decoder Loss:  0.43973455 Validation Decoder Loss:  1.0857608
Encoder Loss:  0.3668442  || Decoder Loss:  0.43795455 Validation Decoder Loss:  1.1373239
Encoder Loss:  0.3659683  || Decoder Loss:  0.43580282 Validation Decoder Loss:  1.1059182
Encoder Loss:  0.36775833  || Decoder Loss:  0.43902954 Validation Decoder Loss:  1.1295336
Encoder Loss:  0.36716816  || Decoder Loss:  0.4377457 Validation Decoder Loss:  1.109445
Encoder Loss:  0.3635825  || Decoder Loss:  0.4335646 Validation Decoder Loss:  1.1621358
Encoder Loss:  0.36444688  || Decoder Loss:  0.43386593 Validation Decoder Loss:  1.080746
Encoder Loss:  0.35581008  || Decoder Loss:  0.42342758 Validation Decoder Loss:  1.1808579
Encoder Loss:  0.38122845  || Decoder Loss:  0.45392308 Validation Decoder Loss:  1.0857581
Encoder Loss:  0.3634158  || Decoder Loss:  0.43315047 Validation Decoder Loss:  1.0855709
Encoder Loss:  0.3621168  || Decoder Loss:  0.43206912 Validation Decoder Loss:  1.1259918
2019-11-18 17:01:29.050405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_0.054721088384586496 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1259918
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_267 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_110 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 2620, 20, 1)       627       
_________________________________________________________________
dropout_269 (Dropout)        (None, 2620, 20, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 920, 20, 1)        783       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 2980, 20, 1)       224       
_________________________________________________________________
dropout_271 (Dropout)        (None, 2980, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 3245, 20, 1)       267       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3062764  || Decoder Loss:  0.4208523 Validation Decoder Loss:  1.3787489
Encoder Loss:  0.3031903  || Decoder Loss:  0.5394927 Validation Decoder Loss:  1.3476601
Encoder Loss:  0.27535406  || Decoder Loss:  0.4951819 Validation Decoder Loss:  1.2907646
Encoder Loss:  0.27496502  || Decoder Loss:  0.49617013 Validation Decoder Loss:  1.1915848
Encoder Loss:  0.27870426  || Decoder Loss:  0.5056247 Validation Decoder Loss:  1.2117372
Encoder Loss:  0.27894077  || Decoder Loss:  0.50515765 Validation Decoder Loss:  1.276833
Encoder Loss:  0.2932417  || Decoder Loss:  0.53020936 Validation Decoder Loss:  1.2789657
Encoder Loss:  0.28670382  || Decoder Loss:  0.5155888 Validation Decoder Loss:  1.4006466
Encoder Loss:  0.2773246  || Decoder Loss:  0.49771535 Validation Decoder Loss:  1.3293003
Encoder Loss:  0.2786206  || Decoder Loss:  0.50640464 Validation Decoder Loss:  1.1955392
Encoder Loss:  0.27746913  || Decoder Loss:  0.5032001 Validation Decoder Loss:  1.0364848
Encoder Loss:  0.27785933  || Decoder Loss:  0.50280714 Validation Decoder Loss:  1.1972585
Encoder Loss:  0.27086166  || Decoder Loss:  0.48934993 Validation Decoder Loss:  1.4341298
Encoder Loss:  0.27597153  || Decoder Loss:  0.49630517 Validation Decoder Loss:  1.3064077
Encoder Loss:  0.27342206  || Decoder Loss:  0.49525604 Validation Decoder Loss:  1.3218567
Encoder Loss:  0.2730958  || Decoder Loss:  0.49115935 Validation Decoder Loss:  1.3611426
Encoder Loss:  0.27767  || Decoder Loss:  0.5039818 Validation Decoder Loss:  1.3304545
Encoder Loss:  0.2731486  || Decoder Loss:  0.49366432 Validation Decoder Loss:  1.2868793
Encoder Loss:  0.27161866  || Decoder Loss:  0.49061775 Validation Decoder Loss:  1.2939558
Encoder Loss:  0.2752317  || Decoder Loss:  0.49792564 Validation Decoder Loss:  1.2704489
Encoder Loss:  0.27581474  || Decoder Loss:  0.49920917 Validation Decoder Loss:  1.092262
Encoder Loss:  0.27071193  || Decoder Loss:  0.48904335 Validation Decoder Loss:  1.1530818
Encoder Loss:  0.27711704  || Decoder Loss:  0.50162673 Validation Decoder Loss:  1.0863463
Encoder Loss:  0.27235445  || Decoder Loss:  0.49000204 Validation Decoder Loss:  1.1165504
Encoder Loss:  0.27864814  || Decoder Loss:  0.50229955 Validation Decoder Loss:  1.2548918
Encoder Loss:  0.27977124  || Decoder Loss:  0.50476664 Validation Decoder Loss:  0.9693438
Encoder Loss:  0.27176753  || Decoder Loss:  0.49058774 Validation Decoder Loss:  0.9780624
Encoder Loss:  0.2718295  || Decoder Loss:  0.49234745 Validation Decoder Loss:  0.954514
Encoder Loss:  0.27225325  || Decoder Loss:  0.4911341 Validation Decoder Loss:  0.972876
Encoder Loss:  0.2710573  || Decoder Loss:  0.4896759 Validation Decoder Loss:  0.949398
Encoder Loss:  0.27258575  || Decoder Loss:  0.4935788 Validation Decoder Loss:  0.96136796
Encoder Loss:  0.27209073  || Decoder Loss:  0.4929129 Validation Decoder Loss:  0.97607374
Encoder Loss:  0.27084106  || Decoder Loss:  0.4912137 Validation Decoder Loss:  0.9692359
Encoder Loss:  0.2724491  || Decoder Loss:  0.49172023 Validation Decoder Loss:  0.9912882
Encoder Loss:  0.27145138  || Decoder Loss:  0.49146882 Validation Decoder Loss:  0.99155414
Encoder Loss:  0.2717992  || Decoder Loss:  0.49128902 Validation Decoder Loss:  0.9980274
Encoder Loss:  0.27133384  || Decoder Loss:  0.49116805 Validation Decoder Loss:  0.9965428
Encoder Loss:  0.27127296  || Decoder Loss:  0.49101192 Validation Decoder Loss:  1.000104
Encoder Loss:  0.2723215  || Decoder Loss:  0.49141002 Validation Decoder Loss:  1.0009968
Encoder Loss:  0.2714995  || Decoder Loss:  0.4907297 Validation Decoder Loss:  1.0112078
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.09854937410997282 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0112078
Started Optimization Process
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_273 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_111 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_340"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 2910, 20, 1)       337       
_________________________________________________________________
dropout_275 (Dropout)        (None, 2910, 20, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 920, 20, 1)        1073      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 2490, 20, 1)       653       
_________________________________________________________________
dropout_277 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 3245, 20, 1)       757       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50984514  || Decoder Loss:  0.5168197 Validation Decoder Loss:  1.395926
Encoder Loss:  0.49218664  || Decoder Loss:  0.49969178 Validation Decoder Loss:  0.41397163
Encoder Loss:  0.45147473  || Decoder Loss:  0.45830306 Validation Decoder Loss:  0.43680662
Encoder Loss:  0.5220816  || Decoder Loss:  0.5301049 Validation Decoder Loss:  0.56564295
Encoder Loss:  0.5121134  || Decoder Loss:  0.51997113 Validation Decoder Loss:  1.0064169
Encoder Loss:  0.48917758  || Decoder Loss:  0.49662703 Validation Decoder Loss:  0.96735764
Encoder Loss:  0.49072224  || Decoder Loss:  0.49813744 Validation Decoder Loss:  0.97674537
Encoder Loss:  0.48710713  || Decoder Loss:  0.49441886 Validation Decoder Loss:  1.0065938
Encoder Loss:  0.48881763  || Decoder Loss:  0.49621853 Validation Decoder Loss:  0.9888352
Encoder Loss:  0.48646766  || Decoder Loss:  0.4938954 Validation Decoder Loss:  0.9921992
Encoder Loss:  0.4882387  || Decoder Loss:  0.49564078 Validation Decoder Loss:  0.98429364
Encoder Loss:  0.48597348  || Decoder Loss:  0.4933867 Validation Decoder Loss:  0.9673201
Encoder Loss:  0.4926232  || Decoder Loss:  0.5001015 Validation Decoder Loss:  0.9710973
Encoder Loss:  0.48812106  || Decoder Loss:  0.49548942 Validation Decoder Loss:  1.005482
Encoder Loss:  0.4886105  || Decoder Loss:  0.4960491 Validation Decoder Loss:  0.99432933
Encoder Loss:  0.48733687  || Decoder Loss:  0.4947657 Validation Decoder Loss:  1.00611
Encoder Loss:  0.48768502  || Decoder Loss:  0.49513167 Validation Decoder Loss:  1.0037775
Encoder Loss:  0.4875187  || Decoder Loss:  0.494967 Validation Decoder Loss:  1.0062869
Encoder Loss:  0.48748422  || Decoder Loss:  0.49494433 Validation Decoder Loss:  1.0041425
Encoder Loss:  0.48739347  || Decoder Loss:  0.49484324 Validation Decoder Loss:  1.0047722
Encoder Loss:  0.4873461  || Decoder Loss:  0.4947573 Validation Decoder Loss:  1.0058426
Encoder Loss:  0.4866757  || Decoder Loss:  0.49408665 Validation Decoder Loss:  1.0096909
Encoder Loss:  0.4885056  || Decoder Loss:  0.4959016 Validation Decoder Loss:  1.0048712
Encoder Loss:  0.48721787  || Decoder Loss:  0.49466157 Validation Decoder Loss:  1.0055943
Encoder Loss:  0.48744756  || Decoder Loss:  0.49490166 Validation Decoder Loss:  1.0053611
Encoder Loss:  0.4870292  || Decoder Loss:  0.49448764 Validation Decoder Loss:  1.0053535
Encoder Loss:  0.48703766  || Decoder Loss:  0.49448413 Validation Decoder Loss:  1.0063759
Encoder Loss:  0.48730528  || Decoder Loss:  0.4947368 Validation Decoder Loss:  1.0051377
Encoder Loss:  0.48699895  || Decoder Loss:  0.49445972 Validation Decoder Loss:  1.0038402
Encoder Loss:  0.4868788  || Decoder Loss:  0.4943145 Validation Decoder Loss:  1.0007614
Encoder Loss:  0.48820722  || Decoder Loss:  0.495574 Validation Decoder Loss:  0.9956243
Encoder Loss:  0.48759055  || Decoder Loss:  0.4949458 Validation Decoder Loss:  1.0027831
Encoder Loss:  0.4867165  || Decoder Loss:  0.49416646 Validation Decoder Loss:  1.0047436
Encoder Loss:  0.48670703  || Decoder Loss:  0.49414718 Validation Decoder Loss:  1.0089233
Encoder Loss:  0.4873566  || Decoder Loss:  0.4947458 Validation Decoder Loss:  1.0084268
Encoder Loss:  0.48652884  || Decoder Loss:  0.49395955 Validation Decoder Loss:  1.0032442
Encoder Loss:  0.48644164  || Decoder Loss:  0.49388236 Validation Decoder Loss:  1.0041149
Encoder Loss:  0.48661014  || Decoder Loss:  0.49405646 Validation Decoder Loss:  1.0059118
Encoder Loss:  0.4863661  || Decoder Loss:  0.49381635 Validation Decoder Loss:  1.006685
Encoder Loss:  0.48626366  || Decoder Loss:  0.49370262 Validation Decoder Loss:  1.005651
Model: siamese_net_lr_0.09694674407709318 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.005651
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 124, 5, 20, 1)     62        
_________________________________________________________________
dropout_279 (Dropout)        (None, 124, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 184, 5, 20, 1)     62        
_________________________________________________________________
reshape_112 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_344"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 1770, 20, 1)       1477      
_________________________________________________________________
dropout_281 (Dropout)        (None, 1770, 20, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 920, 20, 1)        852       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 1290, 20, 1)       372       
_________________________________________________________________
dropout_283 (Dropout)        (None, 1290, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 3245, 20, 1)       668       
=================================================================
Total params: 1,040
Trainable params: 1,040
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4778405  || Decoder Loss:  0.6114602 Validation Decoder Loss:  0.7270913
Encoder Loss:  0.37857482  || Decoder Loss:  0.53251547 Validation Decoder Loss:  0.99948364
Encoder Loss:  0.3379782  || Decoder Loss:  0.5005897 Validation Decoder Loss:  0.9854232
Encoder Loss:  0.33375072  || Decoder Loss:  0.4968597 Validation Decoder Loss:  0.99036944
Encoder Loss:  0.3282841  || Decoder Loss:  0.49560532 Validation Decoder Loss:  1.0065925
Encoder Loss:  0.32307258  || Decoder Loss:  0.49534333 Validation Decoder Loss:  0.9947102
Encoder Loss:  0.32237056  || Decoder Loss:  0.49528894 Validation Decoder Loss:  1.003996
Encoder Loss:  0.3260341  || Decoder Loss:  0.49557182 Validation Decoder Loss:  0.9811177
Encoder Loss:  0.3241213  || Decoder Loss:  0.49453542 Validation Decoder Loss:  1.0020701
Encoder Loss:  0.33153877  || Decoder Loss:  0.49562982 Validation Decoder Loss:  0.93681943
Encoder Loss:  0.3234133  || Decoder Loss:  0.49222472 Validation Decoder Loss:  0.8893026
Encoder Loss:  0.32061738  || Decoder Loss:  0.492066 Validation Decoder Loss:  0.9001012
Encoder Loss:  0.31673962  || Decoder Loss:  0.48860455 Validation Decoder Loss:  0.8911354
Encoder Loss:  0.31553409  || Decoder Loss:  0.48188606 Validation Decoder Loss:  0.98781383
Encoder Loss:  0.31626463  || Decoder Loss:  0.48079148 Validation Decoder Loss:  0.9923025
Encoder Loss:  0.32028922  || Decoder Loss:  0.47963852 Validation Decoder Loss:  1.0013291
Encoder Loss:  0.2999059  || Decoder Loss:  0.45541203 Validation Decoder Loss:  0.71400994
Encoder Loss:  0.3217814  || Decoder Loss:  0.48789966 Validation Decoder Loss:  1.31991
Encoder Loss:  0.32120973  || Decoder Loss:  0.49404144 Validation Decoder Loss:  1.2722268
Encoder Loss:  0.31397784  || Decoder Loss:  0.4826721 Validation Decoder Loss:  1.1863407
Encoder Loss:  0.3116935  || Decoder Loss:  0.47969818 Validation Decoder Loss:  0.95866287
Encoder Loss:  0.3105789  || Decoder Loss:  0.47807014 Validation Decoder Loss:  1.2625502
Encoder Loss:  0.30794534  || Decoder Loss:  0.4713126 Validation Decoder Loss:  1.3122188
Encoder Loss:  0.31194237  || Decoder Loss:  0.47756675 Validation Decoder Loss:  1.352828
Encoder Loss:  0.31284705  || Decoder Loss:  0.4809318 Validation Decoder Loss:  0.91581357
Encoder Loss:  0.3086702  || Decoder Loss:  0.47314423 Validation Decoder Loss:  1.4465624
Encoder Loss:  0.32449132  || Decoder Loss:  0.49101543 Validation Decoder Loss:  0.85206294
Encoder Loss:  0.3161272  || Decoder Loss:  0.48749927 Validation Decoder Loss:  0.98251283
Encoder Loss:  0.30549434  || Decoder Loss:  0.47227383 Validation Decoder Loss:  1.1659083
Encoder Loss:  0.3055526  || Decoder Loss:  0.46789673 Validation Decoder Loss:  1.2146888
Encoder Loss:  0.30293965  || Decoder Loss:  0.46713802 Validation Decoder Loss:  1.2300637
Encoder Loss:  0.3024944  || Decoder Loss:  0.46496433 Validation Decoder Loss:  1.2383863
Encoder Loss:  0.30338284  || Decoder Loss:  0.4657256 Validation Decoder Loss:  1.2881737
Encoder Loss:  0.29783925  || Decoder Loss:  0.45874718 Validation Decoder Loss:  1.2477272
Encoder Loss:  0.27062207  || Decoder Loss:  0.41127145 Validation Decoder Loss:  1.2823441
Encoder Loss:  0.26742306  || Decoder Loss:  0.40546215 Validation Decoder Loss:  0.63985175
Encoder Loss:  0.3125656  || Decoder Loss:  0.48049107 Validation Decoder Loss:  0.64345294
Encoder Loss:  0.31278577  || Decoder Loss:  0.4819442 Validation Decoder Loss:  0.69577444
Encoder Loss:  0.3119225  || Decoder Loss:  0.48045266 Validation Decoder Loss:  0.716041
Encoder Loss:  0.30643088  || Decoder Loss:  0.47233668 Validation Decoder Loss:  0.6745086
Model: siamese_net_lr_0.01113151506159757 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.6745086
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 168, 5, 20, 1)     43        
_________________________________________________________________
dropout_285 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_113 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 1190, 20, 1)       868       
_________________________________________________________________
dropout_287 (Dropout)        (None, 1190, 20, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 920, 20, 1)        272       
=================================================================
Total params: 1,140
Trainable params: 1,140
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 2080, 20, 1)       1162      
_________________________________________________________________
dropout_289 (Dropout)        (None, 2080, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 3245, 20, 1)       1167      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38325775  || Decoder Loss:  0.38376877 Validation Decoder Loss:  1.5895827
Encoder Loss:  0.38656524  || Decoder Loss:  0.3857478 Validation Decoder Loss:  1.6499058
Encoder Loss:  0.33339906  || Decoder Loss:  0.32299817 Validation Decoder Loss:  0.37036127
Encoder Loss:  0.25495538  || Decoder Loss:  0.23814945 Validation Decoder Loss:  0.596678
Encoder Loss:  0.39499065  || Decoder Loss:  0.4440711 Validation Decoder Loss:  0.66282797
Encoder Loss:  0.4465606  || Decoder Loss:  0.50759125 Validation Decoder Loss:  0.48706514
Encoder Loss:  0.4209164  || Decoder Loss:  0.47759384 Validation Decoder Loss:  0.5244629
Encoder Loss:  0.40284547  || Decoder Loss:  0.45668304 Validation Decoder Loss:  0.35601145
Encoder Loss:  0.4168178  || Decoder Loss:  0.4731977 Validation Decoder Loss:  0.54181135
Encoder Loss:  0.4380673  || Decoder Loss:  0.49860448 Validation Decoder Loss:  0.49817896
Encoder Loss:  0.40470877  || Decoder Loss:  0.45949975 Validation Decoder Loss:  1.0400923
Encoder Loss:  0.4023764  || Decoder Loss:  0.45712605 Validation Decoder Loss:  1.6057999
Encoder Loss:  0.39897138  || Decoder Loss:  0.45329368 Validation Decoder Loss:  1.1075919
Encoder Loss:  0.35680598  || Decoder Loss:  0.4041835 Validation Decoder Loss:  1.0424881
Encoder Loss:  0.38126552  || Decoder Loss:  0.43263587 Validation Decoder Loss:  1.0220804
Encoder Loss:  0.40643275  || Decoder Loss:  0.46193132 Validation Decoder Loss:  0.41611943
Encoder Loss:  0.33070192  || Decoder Loss:  0.37422508 Validation Decoder Loss:  0.73414296
Encoder Loss:  0.39634866  || Decoder Loss:  0.45031202 Validation Decoder Loss:  0.6678243
Encoder Loss:  0.45413756  || Decoder Loss:  0.5175569 Validation Decoder Loss:  0.38095444
Encoder Loss:  0.4202754  || Decoder Loss:  0.47808534 Validation Decoder Loss:  0.6650021
Encoder Loss:  0.4253879  || Decoder Loss:  0.4840062 Validation Decoder Loss:  0.6637224
Encoder Loss:  0.40895218  || Decoder Loss:  0.46519092 Validation Decoder Loss:  0.684728
Encoder Loss:  0.41440257  || Decoder Loss:  0.47140282 Validation Decoder Loss:  0.38470513
Encoder Loss:  0.4406206  || Decoder Loss:  0.5016758 Validation Decoder Loss:  0.56947696
Encoder Loss:  0.39808235  || Decoder Loss:  0.45246714 Validation Decoder Loss:  0.9861765
Encoder Loss:  0.41650227  || Decoder Loss:  0.4739749 Validation Decoder Loss:  0.7250304
Encoder Loss:  0.34938392  || Decoder Loss:  0.3959832 Validation Decoder Loss:  0.52371895
Encoder Loss:  0.17922157  || Decoder Loss:  0.19930023 Validation Decoder Loss:  0.32130033
Encoder Loss:  0.2764347  || Decoder Loss:  0.31158605 Validation Decoder Loss:  0.50613153
Encoder Loss:  0.21495116  || Decoder Loss:  0.24068671 Validation Decoder Loss:  0.3516847
Encoder Loss:  0.0632417  || Decoder Loss:  0.06501246 Validation Decoder Loss:  0.3550427
Encoder Loss:  0.065442674  || Decoder Loss:  0.06765144 Validation Decoder Loss:  0.28508264
Encoder Loss:  0.053635806  || Decoder Loss:  0.053829443 Validation Decoder Loss:  0.415159
Encoder Loss:  0.06211584  || Decoder Loss:  0.06346053 Validation Decoder Loss:  0.26421934
Encoder Loss:  0.09967725  || Decoder Loss:  0.10700502 Validation Decoder Loss:  0.22527438
Encoder Loss:  0.09197396  || Decoder Loss:  0.098247916 Validation Decoder Loss:  0.58507955
Encoder Loss:  0.15074445  || Decoder Loss:  0.16640164 Validation Decoder Loss:  0.29642868
Encoder Loss:  0.058074575  || Decoder Loss:  0.059149697 Validation Decoder Loss:  0.4735341
Encoder Loss:  0.06778331  || Decoder Loss:  0.070028506 Validation Decoder Loss:  0.40631402
Encoder Loss:  0.053296153  || Decoder Loss:  0.05355206 Validation Decoder Loss:  0.24994303
Model: siamese_net_lr_0.08812394695361082 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.24994305
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 152, 5, 20, 1)     90        
_________________________________________________________________
dropout_291 (Dropout)        (None, 152, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 184, 5, 20, 1)     34        
_________________________________________________________________
reshape_114 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_352"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 2070, 20, 1)       1177      
_________________________________________________________________
dropout_293 (Dropout)        (None, 2070, 20, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 920, 20, 1)        1152      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 1910, 20, 1)       992       
_________________________________________________________________
dropout_295 (Dropout)        (None, 1910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 3245, 20, 1)       1337      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31520692  || Decoder Loss:  0.48350406 Validation Decoder Loss:  1.6579442
Encoder Loss:  0.3137576  || Decoder Loss:  0.54952693 Validation Decoder Loss:  1.4085062
Encoder Loss:  0.2870899  || Decoder Loss:  0.5339885 Validation Decoder Loss:  0.8108459
Encoder Loss:  0.28332064  || Decoder Loss:  0.49111557 Validation Decoder Loss:  0.57935965
Encoder Loss:  0.27503788  || Decoder Loss:  0.50157046 Validation Decoder Loss:  0.9284401
Encoder Loss:  0.27776366  || Decoder Loss:  0.5055951 Validation Decoder Loss:  0.5279985
Encoder Loss:  0.28964648  || Decoder Loss:  0.49555632 Validation Decoder Loss:  0.5810448
Encoder Loss:  0.26840752  || Decoder Loss:  0.47116295 Validation Decoder Loss:  0.53786623
Encoder Loss:  0.25276765  || Decoder Loss:  0.46177983 Validation Decoder Loss:  0.9452585
Encoder Loss:  0.26033106  || Decoder Loss:  0.49666855 Validation Decoder Loss:  0.8127222
Encoder Loss:  0.25138626  || Decoder Loss:  0.4822683 Validation Decoder Loss:  0.7421856
Encoder Loss:  0.25586247  || Decoder Loss:  0.47697216 Validation Decoder Loss:  0.8144644
Encoder Loss:  0.24322747  || Decoder Loss:  0.46263018 Validation Decoder Loss:  0.850242
Encoder Loss:  0.23931795  || Decoder Loss:  0.45591468 Validation Decoder Loss:  0.9468131
Encoder Loss:  0.23744169  || Decoder Loss:  0.45293492 Validation Decoder Loss:  0.9449595
Encoder Loss:  0.23445213  || Decoder Loss:  0.44515967 Validation Decoder Loss:  0.86659586
Encoder Loss:  0.20737058  || Decoder Loss:  0.38698727 Validation Decoder Loss:  0.5404486
Encoder Loss:  0.23934641  || Decoder Loss:  0.46131092 Validation Decoder Loss:  1.2563181
Encoder Loss:  0.23708206  || Decoder Loss:  0.44870567 Validation Decoder Loss:  1.320879
Encoder Loss:  0.21426268  || Decoder Loss:  0.402242 Validation Decoder Loss:  0.4922658
Encoder Loss:  0.22732168  || Decoder Loss:  0.42624503 Validation Decoder Loss:  0.5456077
Encoder Loss:  0.25421906  || Decoder Loss:  0.48085576 Validation Decoder Loss:  0.4536828
Encoder Loss:  0.24529153  || Decoder Loss:  0.46826228 Validation Decoder Loss:  0.8180313
Encoder Loss:  0.21654402  || Decoder Loss:  0.40858895 Validation Decoder Loss:  1.3106626
Encoder Loss:  0.24441633  || Decoder Loss:  0.4699852 Validation Decoder Loss:  1.3490506
Encoder Loss:  0.23357949  || Decoder Loss:  0.44597843 Validation Decoder Loss:  1.191227
Encoder Loss:  0.16657673  || Decoder Loss:  0.30041635 Validation Decoder Loss:  1.3053651
Encoder Loss:  0.21550663  || Decoder Loss:  0.404747 Validation Decoder Loss:  1.2928412
Encoder Loss:  0.18717478  || Decoder Loss:  0.34776184 Validation Decoder Loss:  0.33986223
Encoder Loss:  0.20372048  || Decoder Loss:  0.3791405 Validation Decoder Loss:  0.4842348
Encoder Loss:  0.1965652  || Decoder Loss:  0.36235583 Validation Decoder Loss:  0.35343632
Encoder Loss:  0.11091283  || Decoder Loss:  0.17807367 Validation Decoder Loss:  0.32579783
Encoder Loss:  0.17809194  || Decoder Loss:  0.324339 Validation Decoder Loss:  0.5701559
Encoder Loss:  0.21099477  || Decoder Loss:  0.3920518 Validation Decoder Loss:  1.1168166
Encoder Loss:  0.112628184  || Decoder Loss:  0.18248512 Validation Decoder Loss:  0.26823893
Encoder Loss:  0.052917637  || Decoder Loss:  0.051722594 Validation Decoder Loss:  0.42579493
Encoder Loss:  0.046926707  || Decoder Loss:  0.036957353 Validation Decoder Loss:  0.3591791
Encoder Loss:  0.0454505  || Decoder Loss:  0.035433546 Validation Decoder Loss:  0.36089337
Encoder Loss:  0.046823125  || Decoder Loss:  0.035959836 Validation Decoder Loss:  0.35532865
Encoder Loss:  0.049298085  || Decoder Loss:  0.03865606 Validation Decoder Loss:  0.3589679
Model: siamese_net_lr_0.03507351029592642 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3589679
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 150, 5, 20, 1)     25        
_________________________________________________________________
dropout_297 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_115 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 2040, 20, 1)       1207      
_________________________________________________________________
dropout_299 (Dropout)        (None, 2040, 20, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 920, 20, 1)        203       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 1880, 20, 1)       43        
_________________________________________________________________
dropout_301 (Dropout)        (None, 1880, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 3245, 20, 1)       1367      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10322549  || Decoder Loss:  0.076248325 Validation Decoder Loss:  0.34245527
Encoder Loss:  0.07259889  || Decoder Loss:  0.042583674 Validation Decoder Loss:  0.34474227
Encoder Loss:  0.0753029  || Decoder Loss:  0.045278292 Validation Decoder Loss:  0.3175361
Encoder Loss:  0.06947169  || Decoder Loss:  0.05214921 Validation Decoder Loss:  0.32494223
Encoder Loss:  0.054192323  || Decoder Loss:  0.05012195 Validation Decoder Loss:  0.3197739
Encoder Loss:  0.052046638  || Decoder Loss:  0.049343273 Validation Decoder Loss:  0.33151132
Encoder Loss:  0.04996335  || Decoder Loss:  0.047504235 Validation Decoder Loss:  0.32940218
Encoder Loss:  0.048483513  || Decoder Loss:  0.046164908 Validation Decoder Loss:  0.33782047
Encoder Loss:  0.05017078  || Decoder Loss:  0.047226463 Validation Decoder Loss:  0.36403894
Encoder Loss:  0.059993688  || Decoder Loss:  0.059201714 Validation Decoder Loss:  0.36757225
Encoder Loss:  0.054626867  || Decoder Loss:  0.05419569 Validation Decoder Loss:  0.30611938
Encoder Loss:  0.050243378  || Decoder Loss:  0.048493396 Validation Decoder Loss:  0.32452488
Encoder Loss:  0.047813166  || Decoder Loss:  0.046018686 Validation Decoder Loss:  0.32178804
Encoder Loss:  0.046675477  || Decoder Loss:  0.04471905 Validation Decoder Loss:  0.3237124
Encoder Loss:  0.04553997  || Decoder Loss:  0.043563552 Validation Decoder Loss:  0.28731135
Encoder Loss:  0.056278076  || Decoder Loss:  0.054826066 Validation Decoder Loss:  0.29393077
Encoder Loss:  0.053404447  || Decoder Loss:  0.050876394 Validation Decoder Loss:  0.31810567
Encoder Loss:  0.046327725  || Decoder Loss:  0.044800896 Validation Decoder Loss:  0.33307618
Encoder Loss:  0.04824003  || Decoder Loss:  0.04449748 Validation Decoder Loss:  0.42376328
Encoder Loss:  0.05802619  || Decoder Loss:  0.05776204 Validation Decoder Loss:  0.30098918
Encoder Loss:  0.049682144  || Decoder Loss:  0.04887855 Validation Decoder Loss:  0.31325197
Encoder Loss:  0.046576038  || Decoder Loss:  0.04471356 Validation Decoder Loss:  0.32499897
Encoder Loss:  0.04554447  || Decoder Loss:  0.042815913 Validation Decoder Loss:  0.3059938
Encoder Loss:  0.052448083  || Decoder Loss:  0.050992783 Validation Decoder Loss:  0.62773013
Encoder Loss:  0.07945116  || Decoder Loss:  0.081089765 Validation Decoder Loss:  0.35496432
Encoder Loss:  0.056062836  || Decoder Loss:  0.055685874 Validation Decoder Loss:  0.30800366
Encoder Loss:  0.0541381  || Decoder Loss:  0.052253734 Validation Decoder Loss:  0.31279045
Encoder Loss:  0.052242994  || Decoder Loss:  0.05062326 Validation Decoder Loss:  0.3144276
Encoder Loss:  0.049893692  || Decoder Loss:  0.0488729 Validation Decoder Loss:  0.31688195
Encoder Loss:  0.04825817  || Decoder Loss:  0.047222644 Validation Decoder Loss:  0.32454482
Encoder Loss:  0.047506183  || Decoder Loss:  0.046141457 Validation Decoder Loss:  0.32630315
Encoder Loss:  0.047489513  || Decoder Loss:  0.045352377 Validation Decoder Loss:  0.3239079
Encoder Loss:  0.045966852  || Decoder Loss:  0.044752207 Validation Decoder Loss:  0.32261592
Encoder Loss:  0.04557559  || Decoder Loss:  0.04419237 Validation Decoder Loss:  0.32408142
Encoder Loss:  0.045126688  || Decoder Loss:  0.043668 Validation Decoder Loss:  0.3137635
Encoder Loss:  0.045136806  || Decoder Loss:  0.043408576 Validation Decoder Loss:  0.29952192
Encoder Loss:  0.048364893  || Decoder Loss:  0.04578987 Validation Decoder Loss:  0.29917482
Encoder Loss:  0.049084548  || Decoder Loss:  0.047769576 Validation Decoder Loss:  0.31202507
Encoder Loss:  0.046384227  || Decoder Loss:  0.04505089 Validation Decoder Loss:  0.3354088
Encoder Loss:  0.04543076  || Decoder Loss:  0.04344303 Validation Decoder Loss:  0.31873518
Model: siamese_net_lr_0.022210565194080933 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31873518
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 128, 5, 20, 1)     3         
_________________________________________________________________
dropout_303 (Dropout)        (None, 128, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 184, 5, 20, 1)     58        
_________________________________________________________________
reshape_116 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 2030, 20, 1)       1217      
_________________________________________________________________
dropout_305 (Dropout)        (None, 2030, 20, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 920, 20, 1)        193       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 2620, 20, 1)       783       
_________________________________________________________________
dropout_307 (Dropout)        (None, 2620, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 3245, 20, 1)       627       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38095102  || Decoder Loss:  0.47283307 Validation Decoder Loss:  0.9136151
Encoder Loss:  0.30762023  || Decoder Loss:  0.38247895 Validation Decoder Loss:  0.5607041
Encoder Loss:  0.10667883  || Decoder Loss:  0.11536956 Validation Decoder Loss:  0.51404375
Encoder Loss:  0.32998592  || Decoder Loss:  0.42289677 Validation Decoder Loss:  1.303719
Encoder Loss:  0.20453732  || Decoder Loss:  0.2565703 Validation Decoder Loss:  0.35390377
Encoder Loss:  0.2642891  || Decoder Loss:  0.3383794 Validation Decoder Loss:  0.99194384
Encoder Loss:  0.1464131  || Decoder Loss:  0.17995277 Validation Decoder Loss:  0.2590924
Encoder Loss:  0.060825873  || Decoder Loss:  0.061735567 Validation Decoder Loss:  0.37078315
Encoder Loss:  0.04854677  || Decoder Loss:  0.04046146 Validation Decoder Loss:  0.40651464
Encoder Loss:  0.054142866  || Decoder Loss:  0.049799755 Validation Decoder Loss:  0.45829105
Encoder Loss:  0.10406616  || Decoder Loss:  0.115340404 Validation Decoder Loss:  0.82141626
Encoder Loss:  0.18936008  || Decoder Loss:  0.23864105 Validation Decoder Loss:  0.4768133
Encoder Loss:  0.16316794  || Decoder Loss:  0.20163876 Validation Decoder Loss:  0.29689822
Encoder Loss:  0.12953986  || Decoder Loss:  0.15142143 Validation Decoder Loss:  0.3033077
Encoder Loss:  0.08675515  || Decoder Loss:  0.0881693 Validation Decoder Loss:  0.280958
Encoder Loss:  0.12503359  || Decoder Loss:  0.1498632 Validation Decoder Loss:  0.39295155
Encoder Loss:  0.049874052  || Decoder Loss:  0.044185355 Validation Decoder Loss:  0.348635
Encoder Loss:  0.048851963  || Decoder Loss:  0.044303097 Validation Decoder Loss:  0.30658486
Encoder Loss:  0.050033946  || Decoder Loss:  0.04637052 Validation Decoder Loss:  0.33748245
Encoder Loss:  0.05112749  || Decoder Loss:  0.048710324 Validation Decoder Loss:  0.32656807
Encoder Loss:  0.053286217  || Decoder Loss:  0.050881553 Validation Decoder Loss:  0.5064306
Encoder Loss:  0.07022052  || Decoder Loss:  0.06951531 Validation Decoder Loss:  0.35131088
Encoder Loss:  0.23037095  || Decoder Loss:  0.2923786 Validation Decoder Loss:  0.4405511
Encoder Loss:  0.32111463  || Decoder Loss:  0.42077503 Validation Decoder Loss:  1.3732609
Encoder Loss:  0.3250693  || Decoder Loss:  0.4236375 Validation Decoder Loss:  0.50422597
Encoder Loss:  0.17639168  || Decoder Loss:  0.22132716 Validation Decoder Loss:  0.4702241
Encoder Loss:  0.19592562  || Decoder Loss:  0.24776043 Validation Decoder Loss:  0.40520483
Encoder Loss:  0.22322735  || Decoder Loss:  0.28499728 Validation Decoder Loss:  0.92284137
Encoder Loss:  0.13245364  || Decoder Loss:  0.16068926 Validation Decoder Loss:  0.744493
Encoder Loss:  0.06736772  || Decoder Loss:  0.07037007 Validation Decoder Loss:  0.40016875
Encoder Loss:  0.047845107  || Decoder Loss:  0.042354874 Validation Decoder Loss:  0.37753737
Encoder Loss:  0.04680683  || Decoder Loss:  0.04113842 Validation Decoder Loss:  0.37715724
Encoder Loss:  0.049580332  || Decoder Loss:  0.044495583 Validation Decoder Loss:  0.29417127
Encoder Loss:  0.051201247  || Decoder Loss:  0.04709269 Validation Decoder Loss:  0.3353151
Encoder Loss:  0.051760066  || Decoder Loss:  0.050038632 Validation Decoder Loss:  0.49973693
Encoder Loss:  0.053962447  || Decoder Loss:  0.052171405 Validation Decoder Loss:  0.30719692
Encoder Loss:  0.056224566  || Decoder Loss:  0.052118693 Validation Decoder Loss:  0.2796862
Encoder Loss:  0.056253232  || Decoder Loss:  0.05713303 Validation Decoder Loss:  0.5183501
Encoder Loss:  0.053782344  || Decoder Loss:  0.05234955 Validation Decoder Loss:  0.2905652
Encoder Loss:  0.05280079  || Decoder Loss:  0.051380206 Validation Decoder Loss:  0.49208674
Model: siamese_net_lr_0.021628697955604 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.49208674
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 142, 5, 20, 1)     80        
_________________________________________________________________
dropout_309 (Dropout)        (None, 142, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 184, 5, 20, 1)     44        
_________________________________________________________________
reshape_117 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_364"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 2780, 20, 1)       467       
_________________________________________________________________
dropout_311 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 920, 20, 1)        943       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 950, 20, 1)        32        
_________________________________________________________________
dropout_313 (Dropout)        (None, 950, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 3245, 20, 1)       399       
=================================================================
Total params: 431
Trainable params: 431
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16692692  || Decoder Loss:  0.12991856 Validation Decoder Loss:  0.39713728
Encoder Loss:  0.14092769  || Decoder Loss:  0.09601608 Validation Decoder Loss:  0.39913183
Encoder Loss:  0.14233813  || Decoder Loss:  0.09806442 Validation Decoder Loss:  0.40337375
Encoder Loss:  0.1443515  || Decoder Loss:  0.101014376 Validation Decoder Loss:  0.4098827
Encoder Loss:  0.14728957  || Decoder Loss:  0.10532351 Validation Decoder Loss:  0.4204675
Encoder Loss:  0.15210637  || Decoder Loss:  0.11238332 Validation Decoder Loss:  0.44095722
Encoder Loss:  0.16331911  || Decoder Loss:  0.12873511 Validation Decoder Loss:  0.51176417
Encoder Loss:  0.33729008  || Decoder Loss:  0.3588543 Validation Decoder Loss:  1.0863656
Encoder Loss:  0.4261441  || Decoder Loss:  0.48389968 Validation Decoder Loss:  1.0811437
Encoder Loss:  0.41969815  || Decoder Loss:  0.4791784 Validation Decoder Loss:  1.1664901
Encoder Loss:  0.40937656  || Decoder Loss:  0.4677264 Validation Decoder Loss:  1.1209655
Encoder Loss:  0.34878457  || Decoder Loss:  0.39776888 Validation Decoder Loss:  0.6787126
Encoder Loss:  0.31177974  || Decoder Loss:  0.35493335 Validation Decoder Loss:  0.40080386
Encoder Loss:  0.14907926  || Decoder Loss:  0.16442986 Validation Decoder Loss:  0.38388675
Encoder Loss:  0.052409936  || Decoder Loss:  0.052132875 Validation Decoder Loss:  0.31427878
Encoder Loss:  0.043207914  || Decoder Loss:  0.041102715 Validation Decoder Loss:  0.35247815
Encoder Loss:  0.04122523  || Decoder Loss:  0.038617644 Validation Decoder Loss:  0.34815282
Encoder Loss:  0.040753137  || Decoder Loss:  0.038424466 Validation Decoder Loss:  0.34686702
Encoder Loss:  0.040665135  || Decoder Loss:  0.038402118 Validation Decoder Loss:  0.34715623
Encoder Loss:  0.0405652  || Decoder Loss:  0.03840024 Validation Decoder Loss:  0.34533668
Encoder Loss:  0.04057733  || Decoder Loss:  0.038423326 Validation Decoder Loss:  0.347525
Encoder Loss:  0.040307675  || Decoder Loss:  0.038356345 Validation Decoder Loss:  0.34824264
Encoder Loss:  0.04014146  || Decoder Loss:  0.03834741 Validation Decoder Loss:  0.34843224
Encoder Loss:  0.04008471  || Decoder Loss:  0.038323656 Validation Decoder Loss:  0.34688455
Encoder Loss:  0.040089834  || Decoder Loss:  0.038344458 Validation Decoder Loss:  0.3439776
Encoder Loss:  0.04028378  || Decoder Loss:  0.03856908 Validation Decoder Loss:  0.34269685
Encoder Loss:  0.040623408  || Decoder Loss:  0.038994238 Validation Decoder Loss:  0.34230658
Encoder Loss:  0.0411062  || Decoder Loss:  0.03957438 Validation Decoder Loss:  0.34398374
Encoder Loss:  0.04054568  || Decoder Loss:  0.03891215 Validation Decoder Loss:  0.3423454
Encoder Loss:  0.041158814  || Decoder Loss:  0.039626416 Validation Decoder Loss:  0.34358263
Encoder Loss:  0.040598556  || Decoder Loss:  0.038977634 Validation Decoder Loss:  0.34211186
Encoder Loss:  0.041210495  || Decoder Loss:  0.039693344 Validation Decoder Loss:  0.34386545
Encoder Loss:  0.04033549  || Decoder Loss:  0.038667373 Validation Decoder Loss:  0.34203726
Encoder Loss:  0.0409209  || Decoder Loss:  0.03935047 Validation Decoder Loss:  0.34174296
Encoder Loss:  0.04119984  || Decoder Loss:  0.03967684 Validation Decoder Loss:  0.34390885
Encoder Loss:  0.04007062  || Decoder Loss:  0.038360916 Validation Decoder Loss:  0.34235564
Encoder Loss:  0.04012826  || Decoder Loss:  0.038432267 Validation Decoder Loss:  0.3490672
Encoder Loss:  0.03975997  || Decoder Loss:  0.03799826 Validation Decoder Loss:  0.34548557
Encoder Loss:  0.03968678  || Decoder Loss:  0.03790077 Validation Decoder Loss:  0.35724163
Encoder Loss:  0.040589076  || Decoder Loss:  0.038961332 Validation Decoder Loss:  0.3412701
Model: siamese_net_lr_0.05152631333687438 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34127012
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 168, 5, 20, 1)     43        
_________________________________________________________________
dropout_315 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_118 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 1650, 20, 1)       1597      
_________________________________________________________________
dropout_317 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 920, 20, 1)        732       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 2880, 20, 1)       124       
_________________________________________________________________
dropout_319 (Dropout)        (None, 2880, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 3245, 20, 1)       367       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37455082  || Decoder Loss:  0.3504253 Validation Decoder Loss:  1.6915296
Encoder Loss:  0.31007186  || Decoder Loss:  0.50146025 Validation Decoder Loss:  0.3658783
Encoder Loss:  0.2600061  || Decoder Loss:  0.4619776 Validation Decoder Loss:  0.78494287
Encoder Loss:  0.26097324  || Decoder Loss:  0.49544692 Validation Decoder Loss:  0.9631805
Encoder Loss:  0.2506129  || Decoder Loss:  0.49453026 Validation Decoder Loss:  0.651373
Encoder Loss:  0.23912711  || Decoder Loss:  0.49256325 Validation Decoder Loss:  0.7705567
Encoder Loss:  0.24297146  || Decoder Loss:  0.4956312 Validation Decoder Loss:  0.87005544
Encoder Loss:  0.24072933  || Decoder Loss:  0.49388367 Validation Decoder Loss:  0.81583846
Encoder Loss:  0.23614508  || Decoder Loss:  0.4727039 Validation Decoder Loss:  0.8197682
Encoder Loss:  0.22953631  || Decoder Loss:  0.47342595 Validation Decoder Loss:  0.8695027
Encoder Loss:  0.14292821  || Decoder Loss:  0.26648486 Validation Decoder Loss:  0.70882285
Encoder Loss:  0.105033115  || Decoder Loss:  0.17878698 Validation Decoder Loss:  0.447843
Encoder Loss:  0.060108427  || Decoder Loss:  0.06687714 Validation Decoder Loss:  0.36137316
Encoder Loss:  0.04889187  || Decoder Loss:  0.04321645 Validation Decoder Loss:  0.35104835
Encoder Loss:  0.047286507  || Decoder Loss:  0.039646495 Validation Decoder Loss:  0.35308784
Encoder Loss:  0.047507826  || Decoder Loss:  0.040200602 Validation Decoder Loss:  0.35021144
Encoder Loss:  0.046941265  || Decoder Loss:  0.03922836 Validation Decoder Loss:  0.3497795
Encoder Loss:  0.046790913  || Decoder Loss:  0.03908448 Validation Decoder Loss:  0.35076636
Encoder Loss:  0.046267316  || Decoder Loss:  0.039062317 Validation Decoder Loss:  0.3513937
Encoder Loss:  0.04706797  || Decoder Loss:  0.041214496 Validation Decoder Loss:  0.35210943
Encoder Loss:  0.047283567  || Decoder Loss:  0.039239272 Validation Decoder Loss:  0.3513231
Encoder Loss:  0.04785931  || Decoder Loss:  0.041377787 Validation Decoder Loss:  0.35763317
Encoder Loss:  0.048662666  || Decoder Loss:  0.043165684 Validation Decoder Loss:  0.35577336
Encoder Loss:  0.0488775  || Decoder Loss:  0.042257633 Validation Decoder Loss:  0.35553503
Encoder Loss:  0.047410302  || Decoder Loss:  0.04154936 Validation Decoder Loss:  0.35007086
Encoder Loss:  0.048218578  || Decoder Loss:  0.04199076 Validation Decoder Loss:  0.35017604
Encoder Loss:  0.046356272  || Decoder Loss:  0.039545048 Validation Decoder Loss:  0.3518381
Encoder Loss:  0.046443798  || Decoder Loss:  0.039528634 Validation Decoder Loss:  0.35322827
Encoder Loss:  0.04752335  || Decoder Loss:  0.042056385 Validation Decoder Loss:  0.3525072
Encoder Loss:  0.047182683  || Decoder Loss:  0.0405591 Validation Decoder Loss:  0.35275015
Encoder Loss:  0.046887945  || Decoder Loss:  0.040363528 Validation Decoder Loss:  0.35381716
Encoder Loss:  0.04665237  || Decoder Loss:  0.04018209 Validation Decoder Loss:  0.35229003
Encoder Loss:  0.046612974  || Decoder Loss:  0.03977238 Validation Decoder Loss:  0.35984
Encoder Loss:  0.049037356  || Decoder Loss:  0.04345128 Validation Decoder Loss:  0.35932863
Encoder Loss:  0.04763792  || Decoder Loss:  0.04315036 Validation Decoder Loss:  0.35150903
Encoder Loss:  0.04685066  || Decoder Loss:  0.039457034 Validation Decoder Loss:  0.35345858
Encoder Loss:  0.046959385  || Decoder Loss:  0.039993785 Validation Decoder Loss:  0.35429707
Encoder Loss:  0.04775201  || Decoder Loss:  0.04220251 Validation Decoder Loss:  0.355801
Encoder Loss:  0.04777014  || Decoder Loss:  0.042202335 Validation Decoder Loss:  0.35766193
Encoder Loss:  0.047423758  || Decoder Loss:  0.04156894 Validation Decoder Loss:  0.35578102
Model: siamese_net_lr_0.07708282198484287 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35578102
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 98, 5, 20, 1)      36        
_________________________________________________________________
dropout_321 (Dropout)        (None, 98, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 184, 5, 20, 1)     88        
_________________________________________________________________
reshape_119 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 3020, 20, 1)       227       
_________________________________________________________________
dropout_323 (Dropout)        (None, 3020, 20, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 920, 20, 1)        264       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 2170, 20, 1)       333       
_________________________________________________________________
dropout_325 (Dropout)        (None, 2170, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 3245, 20, 1)       1077      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20199615  || Decoder Loss:  0.4278901 Validation Decoder Loss:  0.70458305
Encoder Loss:  0.13114738  || Decoder Loss:  0.48506588 Validation Decoder Loss:  0.6707076
Encoder Loss:  0.12228205  || Decoder Loss:  0.49287942 Validation Decoder Loss:  0.68068314
Encoder Loss:  0.1229141  || Decoder Loss:  0.4870551 Validation Decoder Loss:  0.65548563
Encoder Loss:  0.1134046  || Decoder Loss:  0.45194417 Validation Decoder Loss:  0.64592874
Encoder Loss:  0.122689664  || Decoder Loss:  0.48445883 Validation Decoder Loss:  0.77195394
Encoder Loss:  0.12764789  || Decoder Loss:  0.5109872 Validation Decoder Loss:  0.6923853
Encoder Loss:  0.116656974  || Decoder Loss:  0.4967025 Validation Decoder Loss:  0.702721
Encoder Loss:  0.122693785  || Decoder Loss:  0.49677482 Validation Decoder Loss:  0.7588569
Encoder Loss:  0.12287136  || Decoder Loss:  0.4863695 Validation Decoder Loss:  0.7006488
Encoder Loss:  0.11707966  || Decoder Loss:  0.49420872 Validation Decoder Loss:  0.7498306
Encoder Loss:  0.11497543  || Decoder Loss:  0.49421588 Validation Decoder Loss:  0.7698988
Encoder Loss:  0.115869276  || Decoder Loss:  0.49255577 Validation Decoder Loss:  0.7887076
Encoder Loss:  0.1135184  || Decoder Loss:  0.49449843 Validation Decoder Loss:  0.8121813
Encoder Loss:  0.11498751  || Decoder Loss:  0.4915041 Validation Decoder Loss:  0.781691
Encoder Loss:  0.114010885  || Decoder Loss:  0.49121898 Validation Decoder Loss:  0.82259107
Encoder Loss:  0.11330299  || Decoder Loss:  0.49416146 Validation Decoder Loss:  0.85223085
Encoder Loss:  0.11158474  || Decoder Loss:  0.49199525 Validation Decoder Loss:  0.88282335
Encoder Loss:  0.11423312  || Decoder Loss:  0.49326733 Validation Decoder Loss:  0.87372816
Encoder Loss:  0.111115254  || Decoder Loss:  0.49131098 Validation Decoder Loss:  0.9178833
Encoder Loss:  0.11179024  || Decoder Loss:  0.4917489 Validation Decoder Loss:  0.900372
Encoder Loss:  0.11366702  || Decoder Loss:  0.49160948 Validation Decoder Loss:  0.9065248
Encoder Loss:  0.11315929  || Decoder Loss:  0.49098372 Validation Decoder Loss:  0.93525624
Encoder Loss:  0.11333191  || Decoder Loss:  0.49058378 Validation Decoder Loss:  0.9721268
Encoder Loss:  0.11373861  || Decoder Loss:  0.49011397 Validation Decoder Loss:  0.9751804
Encoder Loss:  0.111724794  || Decoder Loss:  0.49056643 Validation Decoder Loss:  1.00664
Encoder Loss:  0.113603  || Decoder Loss:  0.4910581 Validation Decoder Loss:  1.0101397
Encoder Loss:  0.11233408  || Decoder Loss:  0.4894958 Validation Decoder Loss:  1.0382642
Encoder Loss:  0.1113597  || Decoder Loss:  0.48920497 Validation Decoder Loss:  1.0382062
Encoder Loss:  0.113011934  || Decoder Loss:  0.4898287 Validation Decoder Loss:  1.0728343
Encoder Loss:  0.112578265  || Decoder Loss:  0.48860627 Validation Decoder Loss:  1.0873268
Encoder Loss:  0.112007275  || Decoder Loss:  0.48810846 Validation Decoder Loss:  1.1067829
Encoder Loss:  0.112487644  || Decoder Loss:  0.48812807 Validation Decoder Loss:  1.1191437
Encoder Loss:  0.11152466  || Decoder Loss:  0.48738614 Validation Decoder Loss:  1.1408594
Encoder Loss:  0.11240039  || Decoder Loss:  0.48702094 Validation Decoder Loss:  1.1539669
Encoder Loss:  0.11134351  || Decoder Loss:  0.48653966 Validation Decoder Loss:  1.1706948
Encoder Loss:  0.112112425  || Decoder Loss:  0.48611802 Validation Decoder Loss:  1.1845917
Encoder Loss:  0.10932208  || Decoder Loss:  0.48547155 Validation Decoder Loss:  1.200167
Encoder Loss:  0.10938241  || Decoder Loss:  0.48486787 Validation Decoder Loss:  1.2179747
Encoder Loss:  0.11055602  || Decoder Loss:  0.4836679 Validation Decoder Loss:  1.2434301
Model: siamese_net_lr_0.056845438107475076 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2434301
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 176, 5, 20, 1)     51        
_________________________________________________________________
dropout_327 (Dropout)        (None, 176, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 184, 5, 20, 1)     10        
_________________________________________________________________
reshape_120 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_376"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 1160, 20, 1)       928       
_________________________________________________________________
dropout_329 (Dropout)        (None, 1160, 20, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 920, 20, 1)        242       
=================================================================
Total params: 1,170
Trainable params: 1,170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 2110, 20, 1)       1192      
_________________________________________________________________
dropout_331 (Dropout)        (None, 2110, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 3245, 20, 1)       1137      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.62965083  || Decoder Loss:  0.65418 Validation Decoder Loss:  0.4206918
Encoder Loss:  0.27723262  || Decoder Loss:  0.27412283 Validation Decoder Loss:  1.6036303
Encoder Loss:  0.43539226  || Decoder Loss:  0.45405078 Validation Decoder Loss:  0.4181165
Encoder Loss:  0.34600282  || Decoder Loss:  0.34774858 Validation Decoder Loss:  0.49649122
Encoder Loss:  0.42446578  || Decoder Loss:  0.4498341 Validation Decoder Loss:  0.9620147
Encoder Loss:  0.45359188  || Decoder Loss:  0.4845479 Validation Decoder Loss:  1.7156667
Encoder Loss:  0.46565846  || Decoder Loss:  0.49110943 Validation Decoder Loss:  1.749783
Encoder Loss:  0.5711567  || Decoder Loss:  0.61222214 Validation Decoder Loss:  0.6264537
Encoder Loss:  0.46303993  || Decoder Loss:  0.49379402 Validation Decoder Loss:  1.7576866
Encoder Loss:  0.52395743  || Decoder Loss:  0.5597467 Validation Decoder Loss:  1.7318518
Encoder Loss:  0.5153078  || Decoder Loss:  0.55182916 Validation Decoder Loss:  0.69497144
Encoder Loss:  0.41437805  || Decoder Loss:  0.44609678 Validation Decoder Loss:  0.7888084
Encoder Loss:  0.4369303  || Decoder Loss:  0.46915326 Validation Decoder Loss:  1.6438186
Encoder Loss:  0.43952927  || Decoder Loss:  0.4734932 Validation Decoder Loss:  1.7152431
Encoder Loss:  0.49131736  || Decoder Loss:  0.52895784 Validation Decoder Loss:  1.1258729
Encoder Loss:  0.4338902  || Decoder Loss:  0.46666786 Validation Decoder Loss:  1.1079609
Encoder Loss:  0.44566685  || Decoder Loss:  0.4810785 Validation Decoder Loss:  0.9697488
Encoder Loss:  0.44628838  || Decoder Loss:  0.4816488 Validation Decoder Loss:  0.62197924
Encoder Loss:  0.42488804  || Decoder Loss:  0.45713344 Validation Decoder Loss:  0.5038419
Encoder Loss:  0.41393378  || Decoder Loss:  0.44743472 Validation Decoder Loss:  0.8407314
Encoder Loss:  0.39244  || Decoder Loss:  0.42356673 Validation Decoder Loss:  0.86301917
Encoder Loss:  0.37667888  || Decoder Loss:  0.40629703 Validation Decoder Loss:  0.83903193
Encoder Loss:  0.26204276  || Decoder Loss:  0.28100672 Validation Decoder Loss:  0.58941895
Encoder Loss:  0.35347587  || Decoder Loss:  0.3790821 Validation Decoder Loss:  0.7463347
Encoder Loss:  0.4460004  || Decoder Loss:  0.48228538 Validation Decoder Loss:  0.45269
Encoder Loss:  0.42813668  || Decoder Loss:  0.46195027 Validation Decoder Loss:  0.45983806
Encoder Loss:  0.44429126  || Decoder Loss:  0.48048225 Validation Decoder Loss:  0.58925927
Encoder Loss:  0.43714628  || Decoder Loss:  0.47259346 Validation Decoder Loss:  0.2845622
Encoder Loss:  0.3966743  || Decoder Loss:  0.4275344 Validation Decoder Loss:  0.56399155
Encoder Loss:  0.40956113  || Decoder Loss:  0.4427269 Validation Decoder Loss:  0.8392363
Encoder Loss:  0.37071982  || Decoder Loss:  0.3986203 Validation Decoder Loss:  1.2729186
Encoder Loss:  0.44486633  || Decoder Loss:  0.4818355 Validation Decoder Loss:  1.0646875
Encoder Loss:  0.3973702  || Decoder Loss:  0.4297389 Validation Decoder Loss:  0.78415394
Encoder Loss:  0.3675442  || Decoder Loss:  0.3947992 Validation Decoder Loss:  0.6469057
Encoder Loss:  0.37980342  || Decoder Loss:  0.41015914 Validation Decoder Loss:  0.80646
Encoder Loss:  0.4589398  || Decoder Loss:  0.49555585 Validation Decoder Loss:  0.326684
Encoder Loss:  0.32310027  || Decoder Loss:  0.3466776 Validation Decoder Loss:  0.6423996
Encoder Loss:  0.26049024  || Decoder Loss:  0.27876225 Validation Decoder Loss:  0.32430577
Encoder Loss:  0.41518888  || Decoder Loss:  0.44923759 Validation Decoder Loss:  0.7509811
Encoder Loss:  0.4178445  || Decoder Loss:  0.451199 Validation Decoder Loss:  0.40979654
Model: siamese_net_lr_0.07439439680140629 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.40979654
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 156, 5, 20, 1)     94        
_________________________________________________________________
dropout_333 (Dropout)        (None, 156, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 184, 5, 20, 1)     30        
_________________________________________________________________
reshape_121 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 2040, 20, 1)       1207      
_________________________________________________________________
dropout_335 (Dropout)        (None, 2040, 20, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 920, 20, 1)        1122      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 1910, 20, 1)       992       
_________________________________________________________________
dropout_337 (Dropout)        (None, 1910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 3245, 20, 1)       1337      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32863918  || Decoder Loss:  0.17060845 Validation Decoder Loss:  0.38235432
Encoder Loss:  0.31961507  || Decoder Loss:  0.094841965 Validation Decoder Loss:  0.3663692
Encoder Loss:  0.30913267  || Decoder Loss:  0.079406984 Validation Decoder Loss:  0.36123967
Encoder Loss:  0.29296035  || Decoder Loss:  0.06695745 Validation Decoder Loss:  0.4101093
Encoder Loss:  0.26841715  || Decoder Loss:  0.2911259 Validation Decoder Loss:  1.2846625
Encoder Loss:  0.19864936  || Decoder Loss:  0.43251395 Validation Decoder Loss:  1.1829095
Encoder Loss:  0.18854801  || Decoder Loss:  0.43490914 Validation Decoder Loss:  1.3045092
Encoder Loss:  0.19847222  || Decoder Loss:  0.46437758 Validation Decoder Loss:  1.3195704
Encoder Loss:  0.19385864  || Decoder Loss:  0.45103845 Validation Decoder Loss:  1.3317752
Encoder Loss:  0.19606534  || Decoder Loss:  0.47310397 Validation Decoder Loss:  1.1733481
Encoder Loss:  0.19845335  || Decoder Loss:  0.48217106 Validation Decoder Loss:  1.0586417
Encoder Loss:  0.20220461  || Decoder Loss:  0.49120998 Validation Decoder Loss:  0.97164905
Encoder Loss:  0.1938562  || Decoder Loss:  0.47645864 Validation Decoder Loss:  1.0224885
Encoder Loss:  0.1920797  || Decoder Loss:  0.47566518 Validation Decoder Loss:  0.90525293
Encoder Loss:  0.19657543  || Decoder Loss:  0.47822675 Validation Decoder Loss:  1.1111119
Encoder Loss:  0.19132033  || Decoder Loss:  0.47139457 Validation Decoder Loss:  1.1178603
Encoder Loss:  0.19185507  || Decoder Loss:  0.47704437 Validation Decoder Loss:  1.0540831
Encoder Loss:  0.1895749  || Decoder Loss:  0.46269035 Validation Decoder Loss:  1.2979267
Encoder Loss:  0.19269325  || Decoder Loss:  0.47189537 Validation Decoder Loss:  1.0618968
Encoder Loss:  0.18698779  || Decoder Loss:  0.46286955 Validation Decoder Loss:  1.11074
Encoder Loss:  0.18646766  || Decoder Loss:  0.46285456 Validation Decoder Loss:  0.9768305
Encoder Loss:  0.18436064  || Decoder Loss:  0.45567572 Validation Decoder Loss:  1.0156698
Encoder Loss:  0.1846646  || Decoder Loss:  0.45311773 Validation Decoder Loss:  0.9838251
Encoder Loss:  0.18372767  || Decoder Loss:  0.44997463 Validation Decoder Loss:  1.0585368
Encoder Loss:  0.18319145  || Decoder Loss:  0.45220008 Validation Decoder Loss:  1.0157225
Encoder Loss:  0.18296918  || Decoder Loss:  0.45228368 Validation Decoder Loss:  0.9963941
Encoder Loss:  0.18208645  || Decoder Loss:  0.4496103 Validation Decoder Loss:  1.0020853
Encoder Loss:  0.18134506  || Decoder Loss:  0.44844005 Validation Decoder Loss:  0.9943239
Encoder Loss:  0.18106855  || Decoder Loss:  0.4478529 Validation Decoder Loss:  0.98537445
Encoder Loss:  0.18060717  || Decoder Loss:  0.44692698 Validation Decoder Loss:  0.978226
Encoder Loss:  0.18032  || Decoder Loss:  0.4463324 Validation Decoder Loss:  0.9736532
Encoder Loss:  0.17996569  || Decoder Loss:  0.44571444 Validation Decoder Loss:  0.9696115
Encoder Loss:  0.17984214  || Decoder Loss:  0.44525367 Validation Decoder Loss:  0.96217346
Encoder Loss:  0.17974839  || Decoder Loss:  0.4446331 Validation Decoder Loss:  0.9592582
Encoder Loss:  0.17952736  || Decoder Loss:  0.44410172 Validation Decoder Loss:  0.9593645
Encoder Loss:  0.17934848  || Decoder Loss:  0.4436659 Validation Decoder Loss:  0.9608152
Encoder Loss:  0.17918983  || Decoder Loss:  0.44312778 Validation Decoder Loss:  0.9602678
Encoder Loss:  0.17886089  || Decoder Loss:  0.44226834 Validation Decoder Loss:  0.9572766
Encoder Loss:  0.17855051  || Decoder Loss:  0.44138741 Validation Decoder Loss:  0.95958537
Encoder Loss:  0.17817515  || Decoder Loss:  0.4402749 Validation Decoder Loss:  0.9599864
Model: siamese_net_lr_0.08166985298434296 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.95998645
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_155 (Conv3D (None, 142, 5, 20, 1)     17        
_________________________________________________________________
dropout_339 (Dropout)        (None, 142, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_156 (Conv3D (None, 184, 5, 20, 1)     44        
_________________________________________________________________
reshape_122 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 2780, 20, 1)       467       
_________________________________________________________________
dropout_341 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 920, 20, 1)        943       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 950, 20, 1)        32        
_________________________________________________________________
dropout_343 (Dropout)        (None, 950, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 3245, 20, 1)       399       
=================================================================
Total params: 431
Trainable params: 431
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19878428  || Decoder Loss:  0.15743084 Validation Decoder Loss:  0.36671904
Encoder Loss:  0.13103303  || Decoder Loss:  0.075669475 Validation Decoder Loss:  0.3713653
Encoder Loss:  0.13325405  || Decoder Loss:  0.07891936 Validation Decoder Loss:  0.3747285
Encoder Loss:  0.13485341  || Decoder Loss:  0.081289396 Validation Decoder Loss:  0.37778753
Encoder Loss:  0.13620313  || Decoder Loss:  0.0833187 Validation Decoder Loss:  0.38079768
Encoder Loss:  0.1374546  || Decoder Loss:  0.08522995 Validation Decoder Loss:  0.3840115
Encoder Loss:  0.13873988  || Decoder Loss:  0.0872255 Validation Decoder Loss:  0.3878165
Encoder Loss:  0.1402561  || Decoder Loss:  0.08962096 Validation Decoder Loss:  0.39310092
Encoder Loss:  0.1425607  || Decoder Loss:  0.09333242 Validation Decoder Loss:  0.4034952
Encoder Loss:  0.18887497  || Decoder Loss:  0.15575607 Validation Decoder Loss:  1.6487792
Encoder Loss:  0.84205973  || Decoder Loss:  0.9204425 Validation Decoder Loss:  1.625932
Encoder Loss:  0.83989644  || Decoder Loss:  0.9180486 Validation Decoder Loss:  1.6231319
Encoder Loss:  0.8365655  || Decoder Loss:  0.9143179 Validation Decoder Loss:  1.6044908
Encoder Loss:  0.78173274  || Decoder Loss:  0.84960103 Validation Decoder Loss:  1.3097607
Encoder Loss:  0.45281395  || Decoder Loss:  0.46013466 Validation Decoder Loss:  0.59625566
Encoder Loss:  0.32621518  || Decoder Loss:  0.32151797 Validation Decoder Loss:  0.44260234
Encoder Loss:  0.4802089  || Decoder Loss:  0.50171584 Validation Decoder Loss:  1.596619
Encoder Loss:  0.8116654  || Decoder Loss:  0.8862175 Validation Decoder Loss:  1.5508621
Encoder Loss:  0.6442344  || Decoder Loss:  0.7027369 Validation Decoder Loss:  1.3686324
Encoder Loss:  0.4837411  || Decoder Loss:  0.5376852 Validation Decoder Loss:  1.3723342
Encoder Loss:  0.4627298  || Decoder Loss:  0.5169905 Validation Decoder Loss:  1.2385461
Encoder Loss:  0.42902863  || Decoder Loss:  0.48434916 Validation Decoder Loss:  0.84297097
Encoder Loss:  0.41509914  || Decoder Loss:  0.4712813 Validation Decoder Loss:  1.1715558
Encoder Loss:  0.41899833  || Decoder Loss:  0.47647458 Validation Decoder Loss:  1.1673293
Encoder Loss:  0.41249573  || Decoder Loss:  0.4692046 Validation Decoder Loss:  1.1566691
Encoder Loss:  0.40809765  || Decoder Loss:  0.4660954 Validation Decoder Loss:  1.1208258
Encoder Loss:  0.41923782  || Decoder Loss:  0.4832464 Validation Decoder Loss:  1.0818734
Encoder Loss:  0.4279414  || Decoder Loss:  0.4960954 Validation Decoder Loss:  1.0346104
Encoder Loss:  0.4228891  || Decoder Loss:  0.4914772 Validation Decoder Loss:  1.0004927
Encoder Loss:  0.4191253  || Decoder Loss:  0.48770806 Validation Decoder Loss:  0.9948232
Encoder Loss:  0.41742802  || Decoder Loss:  0.48570633 Validation Decoder Loss:  0.99136883
Encoder Loss:  0.41307288  || Decoder Loss:  0.48059365 Validation Decoder Loss:  0.9744053
Encoder Loss:  0.38618445  || Decoder Loss:  0.44870126 Validation Decoder Loss:  0.98099804
Encoder Loss:  0.4293222  || Decoder Loss:  0.49980068 Validation Decoder Loss:  0.9821507
Encoder Loss:  0.42941433  || Decoder Loss:  0.49992958 Validation Decoder Loss:  0.9824248
Encoder Loss:  0.429613  || Decoder Loss:  0.5001709 Validation Decoder Loss:  0.9824313
Encoder Loss:  0.42918095  || Decoder Loss:  0.49963802 Validation Decoder Loss:  0.9845211
Encoder Loss:  0.4289664  || Decoder Loss:  0.49941263 Validation Decoder Loss:  0.9769629
Encoder Loss:  0.4283269  || Decoder Loss:  0.49870622 Validation Decoder Loss:  0.97431755
Encoder Loss:  0.42796117  || Decoder Loss:  0.49824998 Validation Decoder Loss:  0.9699545
Model: siamese_net_lr_0.05064358898197536 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9699545
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_158 (Conv3D (None, 152, 5, 20, 1)     90        
_________________________________________________________________
dropout_345 (Dropout)        (None, 152, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_159 (Conv3D (None, 184, 5, 20, 1)     34        
_________________________________________________________________
reshape_123 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 2070, 20, 1)       1177      
_________________________________________________________________
dropout_347 (Dropout)        (None, 2070, 20, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 920, 20, 1)        1152      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 1910, 20, 1)       73        
_________________________________________________________________
dropout_349 (Dropout)        (None, 1910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 3245, 20, 1)       1337      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3008088  || Decoder Loss:  0.15775225 Validation Decoder Loss:  0.34631824
Encoder Loss:  0.28383482  || Decoder Loss:  0.094931155 Validation Decoder Loss:  0.33973196
Encoder Loss:  0.28099975  || Decoder Loss:  0.09692859 Validation Decoder Loss:  0.3295142
Encoder Loss:  0.27427825  || Decoder Loss:  0.09909108 Validation Decoder Loss:  0.31050175
Encoder Loss:  0.2997905  || Decoder Loss:  0.2842173 Validation Decoder Loss:  1.3687418
Encoder Loss:  0.29430336  || Decoder Loss:  0.47589725 Validation Decoder Loss:  0.5988337
Encoder Loss:  0.25223014  || Decoder Loss:  0.4761419 Validation Decoder Loss:  0.80066174
Encoder Loss:  0.25804973  || Decoder Loss:  0.48932168 Validation Decoder Loss:  0.6732869
Encoder Loss:  0.25392604  || Decoder Loss:  0.4818433 Validation Decoder Loss:  0.7972525
Encoder Loss:  0.25518823  || Decoder Loss:  0.4877139 Validation Decoder Loss:  0.76074016
Encoder Loss:  0.25099617  || Decoder Loss:  0.48217884 Validation Decoder Loss:  0.6618501
Encoder Loss:  0.2575184  || Decoder Loss:  0.4928347 Validation Decoder Loss:  0.7455734
Encoder Loss:  0.24975424  || Decoder Loss:  0.47727004 Validation Decoder Loss:  0.765722
Encoder Loss:  0.2541507  || Decoder Loss:  0.47978705 Validation Decoder Loss:  0.82370245
Encoder Loss:  0.2534698  || Decoder Loss:  0.47887552 Validation Decoder Loss:  0.7175961
Encoder Loss:  0.25656697  || Decoder Loss:  0.48776588 Validation Decoder Loss:  0.7611742
Encoder Loss:  0.24672905  || Decoder Loss:  0.47289425 Validation Decoder Loss:  0.74314356
Encoder Loss:  0.2484727  || Decoder Loss:  0.46868178 Validation Decoder Loss:  0.8120159
Encoder Loss:  0.24839258  || Decoder Loss:  0.47569126 Validation Decoder Loss:  0.73988956
Encoder Loss:  0.24527572  || Decoder Loss:  0.4703429 Validation Decoder Loss:  0.6007334
Encoder Loss:  0.23921217  || Decoder Loss:  0.45241478 Validation Decoder Loss:  0.71055204
Encoder Loss:  0.24069738  || Decoder Loss:  0.45819324 Validation Decoder Loss:  0.543491
Encoder Loss:  0.21712753  || Decoder Loss:  0.40909636 Validation Decoder Loss:  1.1252811
Encoder Loss:  0.2049975  || Decoder Loss:  0.383849 Validation Decoder Loss:  0.5303223
Encoder Loss:  0.09474555  || Decoder Loss:  0.1332213 Validation Decoder Loss:  0.3032174
Encoder Loss:  0.058587085  || Decoder Loss:  0.06234493 Validation Decoder Loss:  0.298266
Encoder Loss:  0.055709586  || Decoder Loss:  0.052541465 Validation Decoder Loss:  0.32764214
Encoder Loss:  0.051421095  || Decoder Loss:  0.049509082 Validation Decoder Loss:  0.3399499
Encoder Loss:  0.05231798  || Decoder Loss:  0.0484198 Validation Decoder Loss:  0.34033954
Encoder Loss:  0.05103351  || Decoder Loss:  0.048048466 Validation Decoder Loss:  0.33989307
Encoder Loss:  0.05554305  || Decoder Loss:  0.047900256 Validation Decoder Loss:  0.34331512
Encoder Loss:  0.056107193  || Decoder Loss:  0.047858678 Validation Decoder Loss:  0.33739454
Encoder Loss:  0.05933755  || Decoder Loss:  0.047783233 Validation Decoder Loss:  0.33385402
Encoder Loss:  0.053685326  || Decoder Loss:  0.0477601 Validation Decoder Loss:  0.33469296
Encoder Loss:  0.05183129  || Decoder Loss:  0.047731064 Validation Decoder Loss:  0.33605286
Encoder Loss:  0.05124048  || Decoder Loss:  0.04765687 Validation Decoder Loss:  0.33793512
Encoder Loss:  0.053945113  || Decoder Loss:  0.047584977 Validation Decoder Loss:  0.33845612
Encoder Loss:  0.051923957  || Decoder Loss:  0.047525186 Validation Decoder Loss:  0.3352675
Encoder Loss:  0.05423574  || Decoder Loss:  0.047455892 Validation Decoder Loss:  0.32990736
Encoder Loss:  0.053733163  || Decoder Loss:  0.04749559 Validation Decoder Loss:  0.33348736
Model: siamese_net_lr_0.03507343528346719 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33348736
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_161 (Conv3D (None, 122, 5, 20, 1)     60        
_________________________________________________________________
dropout_351 (Dropout)        (None, 122, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_162 (Conv3D (None, 184, 5, 20, 1)     64        
_________________________________________________________________
reshape_124 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_392"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 1540, 20, 1)       168       
_________________________________________________________________
dropout_353 (Dropout)        (None, 1540, 20, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 920, 20, 1)        622       
=================================================================
Total params: 790
Trainable params: 790
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 2510, 20, 1)       673       
_________________________________________________________________
dropout_355 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 3245, 20, 1)       737       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31284302  || Decoder Loss:  0.25707576 Validation Decoder Loss:  0.6941488
Encoder Loss:  0.28959987  || Decoder Loss:  0.47417134 Validation Decoder Loss:  1.2977581
Encoder Loss:  0.2642556  || Decoder Loss:  0.5058226 Validation Decoder Loss:  1.2893504
Encoder Loss:  0.26364815  || Decoder Loss:  0.49895135 Validation Decoder Loss:  1.4032931
Encoder Loss:  0.26032954  || Decoder Loss:  0.5035493 Validation Decoder Loss:  1.33538
Encoder Loss:  0.2576933  || Decoder Loss:  0.5030436 Validation Decoder Loss:  1.3302741
Encoder Loss:  0.25893262  || Decoder Loss:  0.50099176 Validation Decoder Loss:  1.4105427
Encoder Loss:  0.26205468  || Decoder Loss:  0.5032826 Validation Decoder Loss:  1.3524532
Encoder Loss:  0.25563154  || Decoder Loss:  0.50221354 Validation Decoder Loss:  1.3469346
Encoder Loss:  0.25688687  || Decoder Loss:  0.49806145 Validation Decoder Loss:  1.3874334
Encoder Loss:  0.25466344  || Decoder Loss:  0.4981625 Validation Decoder Loss:  1.363766
Encoder Loss:  0.25439805  || Decoder Loss:  0.4992116 Validation Decoder Loss:  1.3656543
Encoder Loss:  0.2551096  || Decoder Loss:  0.50101614 Validation Decoder Loss:  1.356552
Encoder Loss:  0.2539255  || Decoder Loss:  0.49961013 Validation Decoder Loss:  1.3555483
Encoder Loss:  0.25351962  || Decoder Loss:  0.4964416 Validation Decoder Loss:  1.3839911
Encoder Loss:  0.25348428  || Decoder Loss:  0.49688044 Validation Decoder Loss:  1.3643712
Encoder Loss:  0.25312915  || Decoder Loss:  0.49653336 Validation Decoder Loss:  1.3813498
Encoder Loss:  0.25300962  || Decoder Loss:  0.49727565 Validation Decoder Loss:  1.3916578
Encoder Loss:  0.25421447  || Decoder Loss:  0.49377888 Validation Decoder Loss:  1.4000623
Encoder Loss:  0.253597  || Decoder Loss:  0.4972364 Validation Decoder Loss:  1.3635066
Encoder Loss:  0.25226516  || Decoder Loss:  0.49643502 Validation Decoder Loss:  1.3565933
Encoder Loss:  0.25175953  || Decoder Loss:  0.49520865 Validation Decoder Loss:  1.366698
Encoder Loss:  0.25051916  || Decoder Loss:  0.495083 Validation Decoder Loss:  1.3614442
Encoder Loss:  0.2507567  || Decoder Loss:  0.49378064 Validation Decoder Loss:  1.3626955
Encoder Loss:  0.25030556  || Decoder Loss:  0.49331063 Validation Decoder Loss:  1.3547103
Encoder Loss:  0.24990451  || Decoder Loss:  0.4930375 Validation Decoder Loss:  1.3567799
Encoder Loss:  0.24996758  || Decoder Loss:  0.4926089 Validation Decoder Loss:  1.3544183
Encoder Loss:  0.24944079  || Decoder Loss:  0.4906421 Validation Decoder Loss:  1.3437245
Encoder Loss:  0.24924026  || Decoder Loss:  0.4922318 Validation Decoder Loss:  1.3360267
Encoder Loss:  0.24885757  || Decoder Loss:  0.491035 Validation Decoder Loss:  1.3321612
Encoder Loss:  0.24848066  || Decoder Loss:  0.49097255 Validation Decoder Loss:  1.3236566
Encoder Loss:  0.24816962  || Decoder Loss:  0.48959976 Validation Decoder Loss:  1.3190577
Encoder Loss:  0.24782728  || Decoder Loss:  0.48866582 Validation Decoder Loss:  1.30318
Encoder Loss:  0.24702291  || Decoder Loss:  0.48837197 Validation Decoder Loss:  1.2860186
Encoder Loss:  0.2464863  || Decoder Loss:  0.4860078 Validation Decoder Loss:  1.2552189
Encoder Loss:  0.24542163  || Decoder Loss:  0.48360452 Validation Decoder Loss:  1.189576
Encoder Loss:  0.24439158  || Decoder Loss:  0.48264518 Validation Decoder Loss:  1.1166447
Encoder Loss:  0.24411812  || Decoder Loss:  0.481214 Validation Decoder Loss:  1.131218
Encoder Loss:  0.24367012  || Decoder Loss:  0.48000768 Validation Decoder Loss:  1.1400092
Encoder Loss:  0.2433441  || Decoder Loss:  0.48052138 Validation Decoder Loss:  1.1398349
Model: siamese_net_lr_0.09977764788657288 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1398349
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_164 (Conv3D (None, 156, 5, 20, 1)     31        
_________________________________________________________________
dropout_357 (Dropout)        (None, 156, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_165 (Conv3D (None, 184, 5, 20, 1)     30        
_________________________________________________________________
reshape_125 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 3040, 20, 1)       207       
_________________________________________________________________
dropout_359 (Dropout)        (None, 3040, 20, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 920, 20, 1)        284       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 3020, 20, 1)       1183      
_________________________________________________________________
dropout_361 (Dropout)        (None, 3020, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 3245, 20, 1)       227       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37222525  || Decoder Loss:  0.18287556 Validation Decoder Loss:  0.38956666
Encoder Loss:  0.39944607  || Decoder Loss:  0.11613137 Validation Decoder Loss:  0.38818228
Encoder Loss:  0.39698926  || Decoder Loss:  0.11537572 Validation Decoder Loss:  0.39067876
Encoder Loss:  0.38660145  || Decoder Loss:  0.11771099 Validation Decoder Loss:  0.4426675
Encoder Loss:  0.30979985  || Decoder Loss:  0.51525533 Validation Decoder Loss:  0.45058948
Encoder Loss:  0.35773668  || Decoder Loss:  0.1257356 Validation Decoder Loss:  0.65140104
Encoder Loss:  0.17154378  || Decoder Loss:  0.51276183 Validation Decoder Loss:  1.7370101
Encoder Loss:  0.15932068  || Decoder Loss:  0.5334495 Validation Decoder Loss:  1.3864493
Encoder Loss:  0.11702569  || Decoder Loss:  0.48535958 Validation Decoder Loss:  1.3566439
Encoder Loss:  0.11695314  || Decoder Loss:  0.5143626 Validation Decoder Loss:  1.2920678
Encoder Loss:  0.13040996  || Decoder Loss:  0.5030659 Validation Decoder Loss:  1.035085
Encoder Loss:  0.095097065  || Decoder Loss:  0.48567837 Validation Decoder Loss:  1.1445596
Encoder Loss:  0.09115733  || Decoder Loss:  0.4868435 Validation Decoder Loss:  1.0857854
Encoder Loss:  0.09466008  || Decoder Loss:  0.48418194 Validation Decoder Loss:  1.0313094
Encoder Loss:  0.08945165  || Decoder Loss:  0.48199263 Validation Decoder Loss:  0.976624
Encoder Loss:  0.10158991  || Decoder Loss:  0.4813847 Validation Decoder Loss:  0.97985506
Encoder Loss:  0.09412274  || Decoder Loss:  0.47928283 Validation Decoder Loss:  0.9647533
Encoder Loss:  0.09009694  || Decoder Loss:  0.47793576 Validation Decoder Loss:  0.9297086
Encoder Loss:  0.08959773  || Decoder Loss:  0.4770313 Validation Decoder Loss:  0.9061879
Encoder Loss:  0.09379834  || Decoder Loss:  0.47578883 Validation Decoder Loss:  0.8752947
Encoder Loss:  0.08896357  || Decoder Loss:  0.47505927 Validation Decoder Loss:  0.86011344
Encoder Loss:  0.09521974  || Decoder Loss:  0.4747759 Validation Decoder Loss:  0.8585751
Encoder Loss:  0.09991726  || Decoder Loss:  0.47438762 Validation Decoder Loss:  0.8908632
Encoder Loss:  0.10531084  || Decoder Loss:  0.47456923 Validation Decoder Loss:  0.84664184
Encoder Loss:  0.09705227  || Decoder Loss:  0.47340626 Validation Decoder Loss:  0.8273972
Encoder Loss:  0.0924035  || Decoder Loss:  0.47136316 Validation Decoder Loss:  0.8201636
Encoder Loss:  0.10672467  || Decoder Loss:  0.47129485 Validation Decoder Loss:  0.8885691
Encoder Loss:  0.09631613  || Decoder Loss:  0.46996602 Validation Decoder Loss:  0.9353253
Encoder Loss:  0.10011508  || Decoder Loss:  0.4663098 Validation Decoder Loss:  0.9274516
Encoder Loss:  0.09037375  || Decoder Loss:  0.45463285 Validation Decoder Loss:  0.8496725
Encoder Loss:  0.093011945  || Decoder Loss:  0.44902793 Validation Decoder Loss:  0.9373124
Encoder Loss:  0.0847971  || Decoder Loss:  0.4323327 Validation Decoder Loss:  1.3085172
Encoder Loss:  0.08996588  || Decoder Loss:  0.46151173 Validation Decoder Loss:  0.561025
Encoder Loss:  0.09058112  || Decoder Loss:  0.4707124 Validation Decoder Loss:  0.6263748
Encoder Loss:  0.088658065  || Decoder Loss:  0.45377073 Validation Decoder Loss:  1.1621019
Encoder Loss:  0.09134957  || Decoder Loss:  0.47228032 Validation Decoder Loss:  0.710981
Encoder Loss:  0.086938985  || Decoder Loss:  0.43017143 Validation Decoder Loss:  0.6402998
Encoder Loss:  0.09870765  || Decoder Loss:  0.4513475 Validation Decoder Loss:  0.50237834
Encoder Loss:  0.09452626  || Decoder Loss:  0.48379734 Validation Decoder Loss:  0.6098136
Encoder Loss:  0.08897896  || Decoder Loss:  0.48124093 Validation Decoder Loss:  0.6470736
Model: siamese_net_lr_0.04689023237466067 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.6470736
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_167 (Conv3D (None, 102, 5, 20, 1)     40        
_________________________________________________________________
dropout_363 (Dropout)        (None, 102, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_168 (Conv3D (None, 184, 5, 20, 1)     84        
_________________________________________________________________
reshape_126 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 1340, 20, 1)       568       
_________________________________________________________________
dropout_365 (Dropout)        (None, 1340, 20, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 920, 20, 1)        422       
=================================================================
Total params: 990
Trainable params: 990
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 1750, 20, 1)       832       
_________________________________________________________________
dropout_367 (Dropout)        (None, 1750, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 3245, 20, 1)       1497      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32302627  || Decoder Loss:  0.14525743 Validation Decoder Loss:  0.3897118
Encoder Loss:  0.32737008  || Decoder Loss:  0.122030064 Validation Decoder Loss:  0.3908342
Encoder Loss:  0.25259086  || Decoder Loss:  0.25356272 Validation Decoder Loss:  0.5332372
Encoder Loss:  0.15557311  || Decoder Loss:  0.4878704 Validation Decoder Loss:  0.7191421
Encoder Loss:  0.13627529  || Decoder Loss:  0.49267814 Validation Decoder Loss:  0.74884844
Encoder Loss:  0.13951701  || Decoder Loss:  0.49241447 Validation Decoder Loss:  0.8341601
Encoder Loss:  0.14102171  || Decoder Loss:  0.49299008 Validation Decoder Loss:  1.2056551
Encoder Loss:  0.13333756  || Decoder Loss:  0.48857716 Validation Decoder Loss:  0.6799166
Encoder Loss:  0.13296442  || Decoder Loss:  0.4406545 Validation Decoder Loss:  1.1034707
Encoder Loss:  0.1570973  || Decoder Loss:  0.5070215 Validation Decoder Loss:  1.2549123
Encoder Loss:  0.14538926  || Decoder Loss:  0.49376306 Validation Decoder Loss:  0.56702626
Encoder Loss:  0.1337649  || Decoder Loss:  0.46641898 Validation Decoder Loss:  0.7206379
Encoder Loss:  0.12579937  || Decoder Loss:  0.47172016 Validation Decoder Loss:  0.6704445
Encoder Loss:  0.12723298  || Decoder Loss:  0.48068008 Validation Decoder Loss:  0.6569092
Encoder Loss:  0.1280244  || Decoder Loss:  0.46752635 Validation Decoder Loss:  1.077429
Encoder Loss:  0.135581  || Decoder Loss:  0.48730537 Validation Decoder Loss:  0.73535275
Encoder Loss:  0.12425178  || Decoder Loss:  0.47960922 Validation Decoder Loss:  0.7740716
Encoder Loss:  0.12938654  || Decoder Loss:  0.48689088 Validation Decoder Loss:  0.68458676
Encoder Loss:  0.12943816  || Decoder Loss:  0.48775294 Validation Decoder Loss:  0.7357424
Encoder Loss:  0.12793727  || Decoder Loss:  0.4837527 Validation Decoder Loss:  0.81966805
Encoder Loss:  0.12346493  || Decoder Loss:  0.4778396 Validation Decoder Loss:  0.8577553
Encoder Loss:  0.12721044  || Decoder Loss:  0.49050042 Validation Decoder Loss:  0.82628566
Encoder Loss:  0.12507634  || Decoder Loss:  0.48309553 Validation Decoder Loss:  0.8154441
Encoder Loss:  0.12485716  || Decoder Loss:  0.4829272 Validation Decoder Loss:  0.84532565
Encoder Loss:  0.12749672  || Decoder Loss:  0.48667395 Validation Decoder Loss:  0.8964724
Encoder Loss:  0.12520652  || Decoder Loss:  0.4856269 Validation Decoder Loss:  0.90630364
Encoder Loss:  0.12339777  || Decoder Loss:  0.4810112 Validation Decoder Loss:  0.94847095
Encoder Loss:  0.12618819  || Decoder Loss:  0.48548535 Validation Decoder Loss:  0.9445845
Encoder Loss:  0.12392596  || Decoder Loss:  0.48262239 Validation Decoder Loss:  0.9536286
Encoder Loss:  0.12447371  || Decoder Loss:  0.48213828 Validation Decoder Loss:  0.95230687
Encoder Loss:  0.12518547  || Decoder Loss:  0.48055094 Validation Decoder Loss:  1.0122106
Encoder Loss:  0.124478586  || Decoder Loss:  0.48139396 Validation Decoder Loss:  0.9944079
Encoder Loss:  0.123267755  || Decoder Loss:  0.47996858 Validation Decoder Loss:  1.0250454
Encoder Loss:  0.12199931  || Decoder Loss:  0.4791002 Validation Decoder Loss:  1.0460461
Encoder Loss:  0.12178802  || Decoder Loss:  0.47802582 Validation Decoder Loss:  1.0700288
Encoder Loss:  0.12138063  || Decoder Loss:  0.47633597 Validation Decoder Loss:  1.088821
Encoder Loss:  0.12214358  || Decoder Loss:  0.47470826 Validation Decoder Loss:  1.07112
Encoder Loss:  0.12126878  || Decoder Loss:  0.47948283 Validation Decoder Loss:  0.9103804
Encoder Loss:  0.12180863  || Decoder Loss:  0.48724517 Validation Decoder Loss:  0.8496716
Encoder Loss:  0.12204662  || Decoder Loss:  0.4884129 Validation Decoder Loss:  0.86977094
Model: siamese_net_lr_0.058567786712767446 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.86977094
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_170 (Conv3D (None, 180, 5, 20, 1)     118       
_________________________________________________________________
dropout_369 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_171 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_127 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_404"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 1150, 20, 1)       2097      
_________________________________________________________________
dropout_371 (Dropout)        (None, 1150, 20, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 920, 20, 1)        232       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 2050, 20, 1)       1132      
_________________________________________________________________
dropout_373 (Dropout)        (None, 2050, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 3245, 20, 1)       1197      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1571432  || Decoder Loss:  0.15730569 Validation Decoder Loss:  0.45485237
Encoder Loss:  0.08148762  || Decoder Loss:  0.07911842 Validation Decoder Loss:  0.33062738
Encoder Loss:  0.05441916  || Decoder Loss:  0.051338755 Validation Decoder Loss:  0.37830746
Encoder Loss:  0.04384652  || Decoder Loss:  0.04206926 Validation Decoder Loss:  0.33769366
Encoder Loss:  0.044261552  || Decoder Loss:  0.04315433 Validation Decoder Loss:  0.31647182
Encoder Loss:  0.044042565  || Decoder Loss:  0.042933587 Validation Decoder Loss:  0.31570864
Encoder Loss:  0.043107837  || Decoder Loss:  0.04150875 Validation Decoder Loss:  0.2901557
Encoder Loss:  0.041045737  || Decoder Loss:  0.03985094 Validation Decoder Loss:  0.32280585
Encoder Loss:  0.039604675  || Decoder Loss:  0.03804729 Validation Decoder Loss:  0.32748225
Encoder Loss:  0.039892033  || Decoder Loss:  0.03780789 Validation Decoder Loss:  0.30904257
Encoder Loss:  0.06904935  || Decoder Loss:  0.06834414 Validation Decoder Loss:  0.34122652
Encoder Loss:  0.058111306  || Decoder Loss:  0.05696593 Validation Decoder Loss:  0.37889773
Encoder Loss:  0.04867184  || Decoder Loss:  0.047903538 Validation Decoder Loss:  0.37752736
Encoder Loss:  0.05116875  || Decoder Loss:  0.0498528 Validation Decoder Loss:  0.33238256
Encoder Loss:  0.047996968  || Decoder Loss:  0.047148496 Validation Decoder Loss:  0.31100118
Encoder Loss:  0.042135525  || Decoder Loss:  0.041104607 Validation Decoder Loss:  0.3554188
Encoder Loss:  0.04382461  || Decoder Loss:  0.042694017 Validation Decoder Loss:  0.3183895
Encoder Loss:  0.04327867  || Decoder Loss:  0.0421949 Validation Decoder Loss:  0.312164
Encoder Loss:  0.03953516  || Decoder Loss:  0.03880352 Validation Decoder Loss:  0.3292162
Encoder Loss:  0.039946403  || Decoder Loss:  0.03903922 Validation Decoder Loss:  0.30801898
Encoder Loss:  0.039387904  || Decoder Loss:  0.038409363 Validation Decoder Loss:  0.3211522
Encoder Loss:  0.039259166  || Decoder Loss:  0.038290184 Validation Decoder Loss:  0.3326894
Encoder Loss:  0.041678287  || Decoder Loss:  0.040549655 Validation Decoder Loss:  0.36354026
Encoder Loss:  0.03996148  || Decoder Loss:  0.038896088 Validation Decoder Loss:  0.35421103
Encoder Loss:  0.04201358  || Decoder Loss:  0.04045609 Validation Decoder Loss:  0.33464348
Encoder Loss:  0.039686233  || Decoder Loss:  0.038596243 Validation Decoder Loss:  0.3316735
Encoder Loss:  0.041349135  || Decoder Loss:  0.039808515 Validation Decoder Loss:  0.33559364
Encoder Loss:  0.03955685  || Decoder Loss:  0.03793596 Validation Decoder Loss:  0.3323129
Encoder Loss:  0.039610874  || Decoder Loss:  0.038029976 Validation Decoder Loss:  0.33712828
Encoder Loss:  0.038582113  || Decoder Loss:  0.03749632 Validation Decoder Loss:  0.33086082
Encoder Loss:  0.038933605  || Decoder Loss:  0.037391927 Validation Decoder Loss:  0.32080668
Encoder Loss:  0.038144752  || Decoder Loss:  0.03705198 Validation Decoder Loss:  0.33661723
Encoder Loss:  0.039066818  || Decoder Loss:  0.037573 Validation Decoder Loss:  0.33321902
Encoder Loss:  0.0384603  || Decoder Loss:  0.037269525 Validation Decoder Loss:  0.33348858
Encoder Loss:  0.037488427  || Decoder Loss:  0.03668743 Validation Decoder Loss:  0.32541868
Encoder Loss:  0.038039636  || Decoder Loss:  0.037081137 Validation Decoder Loss:  0.3220857
Encoder Loss:  0.03800188  || Decoder Loss:  0.037069548 Validation Decoder Loss:  0.33916128
Encoder Loss:  0.039286964  || Decoder Loss:  0.037910257 Validation Decoder Loss:  0.33074632
Encoder Loss:  0.037921418  || Decoder Loss:  0.036644686 Validation Decoder Loss:  0.32696113
Encoder Loss:  0.037963852  || Decoder Loss:  0.03690927 Validation Decoder Loss:  0.30977035
Model: siamese_net_lr_0.0058289846853293685 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.30977035
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_173 (Conv3D (None, 128, 5, 20, 1)     66        
_________________________________________________________________
dropout_375 (Dropout)        (None, 128, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_174 (Conv3D (None, 184, 5, 20, 1)     58        
_________________________________________________________________
reshape_128 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 1770, 20, 1)       1477      
_________________________________________________________________
dropout_377 (Dropout)        (None, 1770, 20, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 920, 20, 1)        852       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 1310, 20, 1)       392       
_________________________________________________________________
dropout_379 (Dropout)        (None, 1310, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 3245, 20, 1)       628       
=================================================================
Total params: 1,020
Trainable params: 1,020
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14379047  || Decoder Loss:  0.5066614 Validation Decoder Loss:  0.8080412
Encoder Loss:  0.097382106  || Decoder Loss:  0.49685612 Validation Decoder Loss:  0.76583713
Encoder Loss:  0.098770216  || Decoder Loss:  0.4890039 Validation Decoder Loss:  0.8603573
Encoder Loss:  0.06736746  || Decoder Loss:  0.49002194 Validation Decoder Loss:  0.87570107
Encoder Loss:  0.077347346  || Decoder Loss:  0.48986214 Validation Decoder Loss:  0.8486527
Encoder Loss:  0.074970506  || Decoder Loss:  0.49060163 Validation Decoder Loss:  0.8720654
Encoder Loss:  0.07237664  || Decoder Loss:  0.4918461 Validation Decoder Loss:  0.8784039
Encoder Loss:  0.08372679  || Decoder Loss:  0.48916814 Validation Decoder Loss:  0.8769753
Encoder Loss:  0.082751624  || Decoder Loss:  0.4808811 Validation Decoder Loss:  0.8722333
Encoder Loss:  0.07578682  || Decoder Loss:  0.4913792 Validation Decoder Loss:  0.8235918
Encoder Loss:  0.06861569  || Decoder Loss:  0.48835036 Validation Decoder Loss:  0.84841913
Encoder Loss:  0.0672654  || Decoder Loss:  0.48393553 Validation Decoder Loss:  0.8483106
Encoder Loss:  0.06483304  || Decoder Loss:  0.48205447 Validation Decoder Loss:  0.8331971
Encoder Loss:  0.06682663  || Decoder Loss:  0.48496583 Validation Decoder Loss:  0.8617224
Encoder Loss:  0.06466598  || Decoder Loss:  0.48338833 Validation Decoder Loss:  0.8712093
Encoder Loss:  0.06354383  || Decoder Loss:  0.48350596 Validation Decoder Loss:  0.8822522
Encoder Loss:  0.06050415  || Decoder Loss:  0.48336715 Validation Decoder Loss:  0.8905091
Encoder Loss:  0.06138561  || Decoder Loss:  0.48364368 Validation Decoder Loss:  0.91172373
Encoder Loss:  0.06961481  || Decoder Loss:  0.48357946 Validation Decoder Loss:  0.9139848
Encoder Loss:  0.071927235  || Decoder Loss:  0.4868506 Validation Decoder Loss:  0.85850805
Encoder Loss:  0.059899434  || Decoder Loss:  0.4866344 Validation Decoder Loss:  0.9206667
Encoder Loss:  0.06349362  || Decoder Loss:  0.48539135 Validation Decoder Loss:  0.94613963
Encoder Loss:  0.06257815  || Decoder Loss:  0.4854262 Validation Decoder Loss:  0.95255244
Encoder Loss:  0.06220714  || Decoder Loss:  0.48568222 Validation Decoder Loss:  0.98108065
Encoder Loss:  0.060366854  || Decoder Loss:  0.48551047 Validation Decoder Loss:  0.9777802
Encoder Loss:  0.06303322  || Decoder Loss:  0.4855058 Validation Decoder Loss:  0.98774743
Encoder Loss:  0.0614046  || Decoder Loss:  0.48549628 Validation Decoder Loss:  1.0044725
Encoder Loss:  0.060947742  || Decoder Loss:  0.4850833 Validation Decoder Loss:  1.0262299
Encoder Loss:  0.05937369  || Decoder Loss:  0.48485497 Validation Decoder Loss:  1.0433792
Encoder Loss:  0.061062545  || Decoder Loss:  0.48464492 Validation Decoder Loss:  1.002491
Encoder Loss:  0.060317658  || Decoder Loss:  0.4846776 Validation Decoder Loss:  0.9947729
Encoder Loss:  0.060108732  || Decoder Loss:  0.48454705 Validation Decoder Loss:  0.97656476
Encoder Loss:  0.060644154  || Decoder Loss:  0.48456582 Validation Decoder Loss:  0.9627345
Encoder Loss:  0.060458187  || Decoder Loss:  0.4843059 Validation Decoder Loss:  0.9830841
Encoder Loss:  0.060004797  || Decoder Loss:  0.4839249 Validation Decoder Loss:  1.0024066
Encoder Loss:  0.060615234  || Decoder Loss:  0.4833967 Validation Decoder Loss:  1.0114195
Encoder Loss:  0.06013084  || Decoder Loss:  0.48291665 Validation Decoder Loss:  1.0103819
Encoder Loss:  0.059193105  || Decoder Loss:  0.48215866 Validation Decoder Loss:  1.0199785
Encoder Loss:  0.058471963  || Decoder Loss:  0.48163128 Validation Decoder Loss:  0.9670294
Encoder Loss:  0.05907234  || Decoder Loss:  0.48006225 Validation Decoder Loss:  0.95114005
Model: siamese_net_lr_0.08176340924949128 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.95114005
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_176 (Conv3D (None, 180, 5, 20, 1)     55        
_________________________________________________________________
dropout_381 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_177 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_129 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_412"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 1170, 20, 1)       908       
_________________________________________________________________
dropout_383 (Dropout)        (None, 1170, 20, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 920, 20, 1)        252       
=================================================================
Total params: 1,160
Trainable params: 1,160
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 2120, 20, 1)       1202      
_________________________________________________________________
dropout_385 (Dropout)        (None, 2120, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 3245, 20, 1)       1127      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19784097  || Decoder Loss:  0.17075054 Validation Decoder Loss:  0.32432187
Encoder Loss:  0.46972194  || Decoder Loss:  0.4878453 Validation Decoder Loss:  1.6069772
Encoder Loss:  0.8241758  || Decoder Loss:  0.87319076 Validation Decoder Loss:  1.6049776
Encoder Loss:  0.8205744  || Decoder Loss:  0.8697418 Validation Decoder Loss:  1.5935918
Encoder Loss:  0.552869  || Decoder Loss:  0.5830459 Validation Decoder Loss:  0.37054592
Encoder Loss:  0.44028905  || Decoder Loss:  0.4670981 Validation Decoder Loss:  1.2222543
Encoder Loss:  0.4043598  || Decoder Loss:  0.43196887 Validation Decoder Loss:  0.3578562
Encoder Loss:  0.43296912  || Decoder Loss:  0.47136772 Validation Decoder Loss:  0.31456915
Encoder Loss:  0.42307413  || Decoder Loss:  0.46733034 Validation Decoder Loss:  1.0173411
Encoder Loss:  0.44101596  || Decoder Loss:  0.48876107 Validation Decoder Loss:  0.54068077
Encoder Loss:  0.4272295  || Decoder Loss:  0.4734613 Validation Decoder Loss:  1.2331982
Encoder Loss:  0.44459817  || Decoder Loss:  0.49299216 Validation Decoder Loss:  0.41736156
Encoder Loss:  0.4162412  || Decoder Loss:  0.461325 Validation Decoder Loss:  1.2925088
Encoder Loss:  0.42928615  || Decoder Loss:  0.47617927 Validation Decoder Loss:  1.1453702
Encoder Loss:  0.45740595  || Decoder Loss:  0.50790113 Validation Decoder Loss:  0.77320063
Encoder Loss:  0.42344448  || Decoder Loss:  0.4695934 Validation Decoder Loss:  0.4025377
Encoder Loss:  0.39723068  || Decoder Loss:  0.4400608 Validation Decoder Loss:  1.1722317
Encoder Loss:  0.42583996  || Decoder Loss:  0.47237113 Validation Decoder Loss:  0.9084053
Encoder Loss:  0.44324237  || Decoder Loss:  0.49212515 Validation Decoder Loss:  0.70722044
Encoder Loss:  0.41085538  || Decoder Loss:  0.45566273 Validation Decoder Loss:  0.7614209
Encoder Loss:  0.4276526  || Decoder Loss:  0.47467163 Validation Decoder Loss:  0.5563675
Encoder Loss:  0.4257055  || Decoder Loss:  0.4724943 Validation Decoder Loss:  1.0739596
Encoder Loss:  0.38586608  || Decoder Loss:  0.4274609 Validation Decoder Loss:  1.0731528
Encoder Loss:  0.4236152  || Decoder Loss:  0.47008705 Validation Decoder Loss:  0.5082176
Encoder Loss:  0.3825704  || Decoder Loss:  0.42413735 Validation Decoder Loss:  1.1054788
Encoder Loss:  0.37384403  || Decoder Loss:  0.41397703 Validation Decoder Loss:  0.45485926
Encoder Loss:  0.16007663  || Decoder Loss:  0.1736928 Validation Decoder Loss:  0.48689085
Encoder Loss:  0.05324105  || Decoder Loss:  0.053484775 Validation Decoder Loss:  0.4308039
Encoder Loss:  0.050762173  || Decoder Loss:  0.050508667 Validation Decoder Loss:  0.41894513
Encoder Loss:  0.053879496  || Decoder Loss:  0.05388328 Validation Decoder Loss:  0.3706712
Encoder Loss:  0.062919274  || Decoder Loss:  0.0638515 Validation Decoder Loss:  0.33434087
Encoder Loss:  0.046795115  || Decoder Loss:  0.046109818 Validation Decoder Loss:  0.38887677
Encoder Loss:  0.04529746  || Decoder Loss:  0.044435315 Validation Decoder Loss:  0.40326995
Encoder Loss:  0.047074195  || Decoder Loss:  0.046322092 Validation Decoder Loss:  0.43240312
Encoder Loss:  0.04604909  || Decoder Loss:  0.045196682 Validation Decoder Loss:  0.32591343
Encoder Loss:  0.038512837  || Decoder Loss:  0.036894552 Validation Decoder Loss:  0.4069409
Encoder Loss:  0.040140335  || Decoder Loss:  0.038639475 Validation Decoder Loss:  0.47406667
Encoder Loss:  0.03815026  || Decoder Loss:  0.036480352 Validation Decoder Loss:  0.40362635
Encoder Loss:  0.044121515  || Decoder Loss:  0.04304204 Validation Decoder Loss:  0.33962327
Encoder Loss:  0.041615866  || Decoder Loss:  0.040307406 Validation Decoder Loss:  0.4686226
Model: siamese_net_lr_0.07654701889810957 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.4686226
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_179 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_387 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_180 (Conv3D (None, 184, 5, 20, 1)     66        
_________________________________________________________________
reshape_130 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_416"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 1780, 20, 1)       1467      
_________________________________________________________________
dropout_389 (Dropout)        (None, 1780, 20, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 920, 20, 1)        862       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 1270, 20, 1)       352       
_________________________________________________________________
dropout_391 (Dropout)        (None, 1270, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 3245, 20, 1)       708       
=================================================================
Total params: 1,060
Trainable params: 1,060
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22580488  || Decoder Loss:  0.17119665 Validation Decoder Loss:  0.41985846
Encoder Loss:  0.38018134  || Decoder Loss:  0.41993943 Validation Decoder Loss:  0.9025893
Encoder Loss:  0.36353996  || Decoder Loss:  0.45738122 Validation Decoder Loss:  1.5021498
Encoder Loss:  0.39046845  || Decoder Loss:  0.5136545 Validation Decoder Loss:  1.4161193
Encoder Loss:  0.376006  || Decoder Loss:  0.5013779 Validation Decoder Loss:  1.2999313
Encoder Loss:  0.3650085  || Decoder Loss:  0.48826858 Validation Decoder Loss:  1.083814
Encoder Loss:  0.36035156  || Decoder Loss:  0.4828903 Validation Decoder Loss:  1.0096993
Encoder Loss:  0.3593588  || Decoder Loss:  0.48183832 Validation Decoder Loss:  1.0878925
Encoder Loss:  0.35808492  || Decoder Loss:  0.48097897 Validation Decoder Loss:  1.1101882
Encoder Loss:  0.3581578  || Decoder Loss:  0.4791737 Validation Decoder Loss:  1.122003
Encoder Loss:  0.35928485  || Decoder Loss:  0.48114383 Validation Decoder Loss:  1.116246
Encoder Loss:  0.36473763  || Decoder Loss:  0.48460168 Validation Decoder Loss:  0.98487306
Encoder Loss:  0.35779232  || Decoder Loss:  0.47947857 Validation Decoder Loss:  1.2133663
Encoder Loss:  0.35575226  || Decoder Loss:  0.4783882 Validation Decoder Loss:  1.1768631
Encoder Loss:  0.35635945  || Decoder Loss:  0.47846833 Validation Decoder Loss:  1.0557961
Encoder Loss:  0.3564464  || Decoder Loss:  0.47837228 Validation Decoder Loss:  1.1178406
Encoder Loss:  0.35558692  || Decoder Loss:  0.47672978 Validation Decoder Loss:  1.0894792
Encoder Loss:  0.35554358  || Decoder Loss:  0.4770655 Validation Decoder Loss:  1.0403955
Encoder Loss:  0.35520804  || Decoder Loss:  0.47637683 Validation Decoder Loss:  1.0946445
Encoder Loss:  0.35580733  || Decoder Loss:  0.47704148 Validation Decoder Loss:  1.1734705
Encoder Loss:  0.3553875  || Decoder Loss:  0.47650927 Validation Decoder Loss:  1.2285533
Encoder Loss:  0.35733888  || Decoder Loss:  0.47734162 Validation Decoder Loss:  1.1113307
Encoder Loss:  0.35342187  || Decoder Loss:  0.47394013 Validation Decoder Loss:  1.1590903
Encoder Loss:  0.3518838  || Decoder Loss:  0.4728216 Validation Decoder Loss:  1.1593618
Encoder Loss:  0.35087526  || Decoder Loss:  0.47089332 Validation Decoder Loss:  1.1387898
Encoder Loss:  0.3448004  || Decoder Loss:  0.46301106 Validation Decoder Loss:  1.1335629
Encoder Loss:  0.35347858  || Decoder Loss:  0.47410288 Validation Decoder Loss:  1.0665714
Encoder Loss:  0.35411236  || Decoder Loss:  0.4750772 Validation Decoder Loss:  1.1873823
Encoder Loss:  0.35610405  || Decoder Loss:  0.4764327 Validation Decoder Loss:  1.0692602
Encoder Loss:  0.3489539  || Decoder Loss:  0.46777102 Validation Decoder Loss:  1.0810564
Encoder Loss:  0.34148192  || Decoder Loss:  0.45726517 Validation Decoder Loss:  1.1334958
Encoder Loss:  0.34705582  || Decoder Loss:  0.46523055 Validation Decoder Loss:  0.948803
Encoder Loss:  0.3403551  || Decoder Loss:  0.45548543 Validation Decoder Loss:  1.0404091
Encoder Loss:  0.3376368  || Decoder Loss:  0.4524059 Validation Decoder Loss:  1.0626328
Encoder Loss:  0.33184287  || Decoder Loss:  0.44457337 Validation Decoder Loss:  0.7651571
Encoder Loss:  0.3455838  || Decoder Loss:  0.46157777 Validation Decoder Loss:  1.1988997
Encoder Loss:  0.33546254  || Decoder Loss:  0.4493211 Validation Decoder Loss:  0.9418575
Encoder Loss:  0.34097618  || Decoder Loss:  0.45552966 Validation Decoder Loss:  1.1520412
Encoder Loss:  0.3326892  || Decoder Loss:  0.44583434 Validation Decoder Loss:  0.9142332
Encoder Loss:  0.33786678  || Decoder Loss:  0.45197925 Validation Decoder Loss:  1.2051556
Model: siamese_net_lr_0.05081421205485291 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2051556
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_182 (Conv3D (None, 152, 5, 20, 1)     27        
_________________________________________________________________
dropout_393 (Dropout)        (None, 152, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_183 (Conv3D (None, 184, 5, 20, 1)     34        
_________________________________________________________________
reshape_131 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 3040, 20, 1)       207       
_________________________________________________________________
dropout_395 (Dropout)        (None, 3040, 20, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 920, 20, 1)        2122      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 2980, 20, 1)       224       
_________________________________________________________________
dropout_397 (Dropout)        (None, 2980, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 3245, 20, 1)       267       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34039462  || Decoder Loss:  0.2617287 Validation Decoder Loss:  1.4851972
Encoder Loss:  0.376143  || Decoder Loss:  0.2827405 Validation Decoder Loss:  0.45278805
Encoder Loss:  0.32910997  || Decoder Loss:  0.09832947 Validation Decoder Loss:  0.50131214
Encoder Loss:  0.30639365  || Decoder Loss:  0.33031085 Validation Decoder Loss:  1.0276843
Encoder Loss:  0.1737773  || Decoder Loss:  0.46513492 Validation Decoder Loss:  1.2441325
Encoder Loss:  0.17779373  || Decoder Loss:  0.4814044 Validation Decoder Loss:  1.3061548
Encoder Loss:  0.16772456  || Decoder Loss:  0.47116676 Validation Decoder Loss:  1.2293328
Encoder Loss:  0.1765048  || Decoder Loss:  0.48645738 Validation Decoder Loss:  1.2973405
Encoder Loss:  0.16684118  || Decoder Loss:  0.46177223 Validation Decoder Loss:  0.9839042
Encoder Loss:  0.17086235  || Decoder Loss:  0.45843044 Validation Decoder Loss:  0.7212187
Encoder Loss:  0.18030915  || Decoder Loss:  0.50074446 Validation Decoder Loss:  0.5644957
Encoder Loss:  0.19232067  || Decoder Loss:  0.4861096 Validation Decoder Loss:  0.7222897
Encoder Loss:  0.17629875  || Decoder Loss:  0.5093106 Validation Decoder Loss:  0.7532251
Encoder Loss:  0.18275785  || Decoder Loss:  0.5098098 Validation Decoder Loss:  0.76203287
Encoder Loss:  0.1815744  || Decoder Loss:  0.49117866 Validation Decoder Loss:  0.6510212
Encoder Loss:  0.16750284  || Decoder Loss:  0.5049168 Validation Decoder Loss:  0.688829
Encoder Loss:  0.17034723  || Decoder Loss:  0.4999817 Validation Decoder Loss:  0.71071804
Encoder Loss:  0.1699509  || Decoder Loss:  0.5022979 Validation Decoder Loss:  0.7062394
Encoder Loss:  0.17694697  || Decoder Loss:  0.5034532 Validation Decoder Loss:  0.74366164
Encoder Loss:  0.1856994  || Decoder Loss:  0.5053909 Validation Decoder Loss:  0.62191236
Encoder Loss:  0.17255047  || Decoder Loss:  0.4998936 Validation Decoder Loss:  0.6829393
Encoder Loss:  0.16775018  || Decoder Loss:  0.5015098 Validation Decoder Loss:  0.7287709
Encoder Loss:  0.16642429  || Decoder Loss:  0.50386566 Validation Decoder Loss:  0.6982874
Encoder Loss:  0.16361143  || Decoder Loss:  0.50026846 Validation Decoder Loss:  0.6846993
Encoder Loss:  0.16391514  || Decoder Loss:  0.49690878 Validation Decoder Loss:  0.6696011
Encoder Loss:  0.16894254  || Decoder Loss:  0.498062 Validation Decoder Loss:  0.6580899
Encoder Loss:  0.16992885  || Decoder Loss:  0.49304458 Validation Decoder Loss:  0.7119546
Encoder Loss:  0.17423056  || Decoder Loss:  0.4962518 Validation Decoder Loss:  0.67887706
Encoder Loss:  0.16255474  || Decoder Loss:  0.49711114 Validation Decoder Loss:  0.7264313
Encoder Loss:  0.16302186  || Decoder Loss:  0.4963255 Validation Decoder Loss:  0.7314762
Encoder Loss:  0.16595879  || Decoder Loss:  0.49476683 Validation Decoder Loss:  0.7113832
Encoder Loss:  0.16386202  || Decoder Loss:  0.49070603 Validation Decoder Loss:  0.7086146
Encoder Loss:  0.1630464  || Decoder Loss:  0.4892431 Validation Decoder Loss:  0.7595068
Encoder Loss:  0.17098401  || Decoder Loss:  0.49333364 Validation Decoder Loss:  0.78836054
Encoder Loss:  0.16182935  || Decoder Loss:  0.48401597 Validation Decoder Loss:  0.839208
Encoder Loss:  0.16264372  || Decoder Loss:  0.48299775 Validation Decoder Loss:  0.90427357
Encoder Loss:  0.16806199  || Decoder Loss:  0.48298717 Validation Decoder Loss:  0.9404936
Encoder Loss:  0.1622057  || Decoder Loss:  0.4823682 Validation Decoder Loss:  0.9890313
Encoder Loss:  0.16031994  || Decoder Loss:  0.48175502 Validation Decoder Loss:  0.95831126
Encoder Loss:  0.1631655  || Decoder Loss:  0.4826068 Validation Decoder Loss:  0.9992676
Model: siamese_net_lr_0.03815732922235125 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9992676
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_185 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_399 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_186 (Conv3D (None, 184, 5, 20, 1)     68        
_________________________________________________________________
reshape_132 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 2110, 20, 1)       1137      
_________________________________________________________________
dropout_401 (Dropout)        (None, 2110, 20, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 920, 20, 1)        273       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 2450, 20, 1)       613       
_________________________________________________________________
dropout_403 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 3245, 20, 1)       797       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.49628925  || Decoder Loss:  0.76096755 Validation Decoder Loss:  1.5779178
Encoder Loss:  0.5458739  || Decoder Loss:  0.83656806 Validation Decoder Loss:  1.5658107
Encoder Loss:  0.5367529  || Decoder Loss:  0.8283501 Validation Decoder Loss:  1.5429022
Encoder Loss:  0.5048213  || Decoder Loss:  0.80331266 Validation Decoder Loss:  1.3789257
Encoder Loss:  0.2580615  || Decoder Loss:  0.4859116 Validation Decoder Loss:  0.86562073
Encoder Loss:  0.22489154  || Decoder Loss:  0.49284187 Validation Decoder Loss:  0.8842999
Encoder Loss:  0.2220884  || Decoder Loss:  0.5000929 Validation Decoder Loss:  0.87991023
Encoder Loss:  0.21925107  || Decoder Loss:  0.50303006 Validation Decoder Loss:  0.82549363
Encoder Loss:  0.2179817  || Decoder Loss:  0.50185347 Validation Decoder Loss:  0.77872616
Encoder Loss:  0.21886921  || Decoder Loss:  0.4983267 Validation Decoder Loss:  0.7747232
Encoder Loss:  0.21876551  || Decoder Loss:  0.4963605 Validation Decoder Loss:  0.84346354
Encoder Loss:  0.2187782  || Decoder Loss:  0.5008071 Validation Decoder Loss:  0.79901004
Encoder Loss:  0.21769996  || Decoder Loss:  0.49651954 Validation Decoder Loss:  0.82258403
Encoder Loss:  0.2163451  || Decoder Loss:  0.4999467 Validation Decoder Loss:  0.82964504
Encoder Loss:  0.21478933  || Decoder Loss:  0.49991336 Validation Decoder Loss:  0.80790305
Encoder Loss:  0.21472004  || Decoder Loss:  0.4993155 Validation Decoder Loss:  0.7841917
Encoder Loss:  0.21579847  || Decoder Loss:  0.49706402 Validation Decoder Loss:  0.7979127
Encoder Loss:  0.21588954  || Decoder Loss:  0.49658555 Validation Decoder Loss:  0.8432682
Encoder Loss:  0.2150971  || Decoder Loss:  0.49823028 Validation Decoder Loss:  0.8277974
Encoder Loss:  0.21414545  || Decoder Loss:  0.4994433 Validation Decoder Loss:  0.82373476
Encoder Loss:  0.21582727  || Decoder Loss:  0.4989123 Validation Decoder Loss:  0.84128034
Encoder Loss:  0.21368681  || Decoder Loss:  0.49753383 Validation Decoder Loss:  0.8275409
Encoder Loss:  0.21445091  || Decoder Loss:  0.4981007 Validation Decoder Loss:  0.8412163
Encoder Loss:  0.21405123  || Decoder Loss:  0.4988867 Validation Decoder Loss:  0.8360646
Encoder Loss:  0.21461278  || Decoder Loss:  0.49626932 Validation Decoder Loss:  0.87224853
Encoder Loss:  0.21385452  || Decoder Loss:  0.49690437 Validation Decoder Loss:  0.86013424
Encoder Loss:  0.21325724  || Decoder Loss:  0.49839097 Validation Decoder Loss:  0.85785294
Encoder Loss:  0.2134734  || Decoder Loss:  0.49669752 Validation Decoder Loss:  0.86337316
Encoder Loss:  0.21301562  || Decoder Loss:  0.49815547 Validation Decoder Loss:  0.8667345
Encoder Loss:  0.21378304  || Decoder Loss:  0.49758682 Validation Decoder Loss:  0.8626471
Encoder Loss:  0.21373726  || Decoder Loss:  0.4955755 Validation Decoder Loss:  0.8887072
Encoder Loss:  0.21298379  || Decoder Loss:  0.4977837 Validation Decoder Loss:  0.87480855
Encoder Loss:  0.21337105  || Decoder Loss:  0.49664634 Validation Decoder Loss:  0.87986684
Encoder Loss:  0.21358429  || Decoder Loss:  0.49612248 Validation Decoder Loss:  0.9045619
Encoder Loss:  0.21364602  || Decoder Loss:  0.49779195 Validation Decoder Loss:  0.89241207
Encoder Loss:  0.21387644  || Decoder Loss:  0.49726254 Validation Decoder Loss:  0.9006068
Encoder Loss:  0.21289368  || Decoder Loss:  0.4976093 Validation Decoder Loss:  0.89620066
Encoder Loss:  0.2129375  || Decoder Loss:  0.49752986 Validation Decoder Loss:  0.8887848
Encoder Loss:  0.21258675  || Decoder Loss:  0.49652663 Validation Decoder Loss:  0.8934478
Encoder Loss:  0.21236071  || Decoder Loss:  0.49750113 Validation Decoder Loss:  0.8870611
Model: siamese_net_lr_0.05818066996944849 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8870611
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_188 (Conv3D (None, 146, 5, 20, 1)     84        
_________________________________________________________________
dropout_405 (Dropout)        (None, 146, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_189 (Conv3D (None, 184, 5, 20, 1)     40        
_________________________________________________________________
reshape_133 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_428"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 2780, 20, 1)       467       
_________________________________________________________________
dropout_407 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 920, 20, 1)        1862      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 980, 20, 1)        62        
_________________________________________________________________
dropout_409 (Dropout)        (None, 980, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 3245, 20, 1)       1288      
=================================================================
Total params: 1,350
Trainable params: 1,350
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23181678  || Decoder Loss:  0.6916337 Validation Decoder Loss:  0.7191425
Encoder Loss:  0.075145386  || Decoder Loss:  0.48720905 Validation Decoder Loss:  0.7059625
Encoder Loss:  0.09118142  || Decoder Loss:  0.496566 Validation Decoder Loss:  0.44670144
Encoder Loss:  0.08452909  || Decoder Loss:  0.47144377 Validation Decoder Loss:  0.6399391
Encoder Loss:  0.0953446  || Decoder Loss:  0.49337727 Validation Decoder Loss:  0.8784172
Encoder Loss:  0.081635065  || Decoder Loss:  0.49309945 Validation Decoder Loss:  0.5134983
Encoder Loss:  0.089498855  || Decoder Loss:  0.4736289 Validation Decoder Loss:  0.60183537
Encoder Loss:  0.067416675  || Decoder Loss:  0.23986687 Validation Decoder Loss:  0.29340243
Encoder Loss:  0.060229387  || Decoder Loss:  0.06075088 Validation Decoder Loss:  0.3226715
Encoder Loss:  0.060110837  || Decoder Loss:  0.048036657 Validation Decoder Loss:  0.3104096
Encoder Loss:  0.06276311  || Decoder Loss:  0.04806537 Validation Decoder Loss:  0.318535
Encoder Loss:  0.064062774  || Decoder Loss:  0.051909775 Validation Decoder Loss:  0.31105497
Encoder Loss:  0.058272053  || Decoder Loss:  0.05821657 Validation Decoder Loss:  0.31359404
Encoder Loss:  0.05523323  || Decoder Loss:  0.06263693 Validation Decoder Loss:  0.29492423
Encoder Loss:  0.055298697  || Decoder Loss:  0.064268135 Validation Decoder Loss:  0.30264676
Encoder Loss:  0.0521957  || Decoder Loss:  0.06674752 Validation Decoder Loss:  0.30434304
Encoder Loss:  0.051860474  || Decoder Loss:  0.06802556 Validation Decoder Loss:  0.30465558
Encoder Loss:  0.052879654  || Decoder Loss:  0.069799215 Validation Decoder Loss:  0.3071902
Encoder Loss:  0.05384198  || Decoder Loss:  0.07141383 Validation Decoder Loss:  0.31562614
Encoder Loss:  0.054221716  || Decoder Loss:  0.07301518 Validation Decoder Loss:  0.3402428
Encoder Loss:  0.052770223  || Decoder Loss:  0.06787934 Validation Decoder Loss:  0.34030643
Encoder Loss:  0.054840535  || Decoder Loss:  0.06266815 Validation Decoder Loss:  0.31762815
Encoder Loss:  0.0525703  || Decoder Loss:  0.05999029 Validation Decoder Loss:  0.30938116
Encoder Loss:  0.052901488  || Decoder Loss:  0.06655408 Validation Decoder Loss:  0.34206602
Encoder Loss:  0.052264865  || Decoder Loss:  0.06591085 Validation Decoder Loss:  0.33930135
Encoder Loss:  0.051833455  || Decoder Loss:  0.060546912 Validation Decoder Loss:  0.31151825
Encoder Loss:  0.052080084  || Decoder Loss:  0.055700228 Validation Decoder Loss:  0.30936512
Encoder Loss:  0.051809188  || Decoder Loss:  0.05650661 Validation Decoder Loss:  0.30636382
Encoder Loss:  0.052090038  || Decoder Loss:  0.052876778 Validation Decoder Loss:  0.3196832
Encoder Loss:  0.05181162  || Decoder Loss:  0.051819313 Validation Decoder Loss:  0.3107863
Encoder Loss:  0.050974097  || Decoder Loss:  0.049617816 Validation Decoder Loss:  0.3152759
Encoder Loss:  0.051101614  || Decoder Loss:  0.049950104 Validation Decoder Loss:  0.31033596
Encoder Loss:  0.05125032  || Decoder Loss:  0.049790677 Validation Decoder Loss:  0.32363385
Encoder Loss:  0.051565427  || Decoder Loss:  0.058991436 Validation Decoder Loss:  0.31595927
Encoder Loss:  0.05102111  || Decoder Loss:  0.051847123 Validation Decoder Loss:  0.3151015
Encoder Loss:  0.051006917  || Decoder Loss:  0.051995277 Validation Decoder Loss:  0.32479686
Encoder Loss:  0.050996616  || Decoder Loss:  0.05308424 Validation Decoder Loss:  0.3618897
Encoder Loss:  0.05122897  || Decoder Loss:  0.054273482 Validation Decoder Loss:  0.30242884
Encoder Loss:  0.050643098  || Decoder Loss:  0.046665564 Validation Decoder Loss:  0.31777498
Encoder Loss:  0.051733624  || Decoder Loss:  0.05387887 Validation Decoder Loss:  0.3284696
Model: siamese_net_lr_0.014518082752913246 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3284696
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_191 (Conv3D (None, 158, 5, 20, 1)     96        
_________________________________________________________________
dropout_411 (Dropout)        (None, 158, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_192 (Conv3D (None, 184, 5, 20, 1)     28        
_________________________________________________________________
reshape_134 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 2090, 20, 1)       1157      
_________________________________________________________________
dropout_413 (Dropout)        (None, 2090, 20, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 920, 20, 1)        253       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 1900, 20, 1)       982       
_________________________________________________________________
dropout_415 (Dropout)        (None, 1900, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 3245, 20, 1)       1347      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30195224  || Decoder Loss:  0.21755561 Validation Decoder Loss:  0.36152697
Encoder Loss:  0.25753006  || Decoder Loss:  0.088473834 Validation Decoder Loss:  0.32802266
Encoder Loss:  0.24199192  || Decoder Loss:  0.059409223 Validation Decoder Loss:  0.36683542
Encoder Loss:  0.23865443  || Decoder Loss:  0.055545896 Validation Decoder Loss:  0.37457663
Encoder Loss:  0.23554324  || Decoder Loss:  0.052879132 Validation Decoder Loss:  0.37541655
Encoder Loss:  0.2318524  || Decoder Loss:  0.050402883 Validation Decoder Loss:  0.37815186
Encoder Loss:  0.22554962  || Decoder Loss:  0.049960904 Validation Decoder Loss:  0.41932854
Encoder Loss:  0.5278049  || Decoder Loss:  0.72770846 Validation Decoder Loss:  0.82166636
Encoder Loss:  0.28305128  || Decoder Loss:  0.38930497 Validation Decoder Loss:  0.66575277
Encoder Loss:  0.31016964  || Decoder Loss:  0.48841193 Validation Decoder Loss:  1.731014
Encoder Loss:  0.3302427  || Decoder Loss:  0.52991927 Validation Decoder Loss:  1.567795
Encoder Loss:  0.27271926  || Decoder Loss:  0.46379125 Validation Decoder Loss:  1.4686712
Encoder Loss:  0.27277753  || Decoder Loss:  0.4732892 Validation Decoder Loss:  1.0982125
Encoder Loss:  0.27105075  || Decoder Loss:  0.4645251 Validation Decoder Loss:  1.1279323
Encoder Loss:  0.26309237  || Decoder Loss:  0.4555446 Validation Decoder Loss:  1.0961217
Encoder Loss:  0.26077092  || Decoder Loss:  0.44830632 Validation Decoder Loss:  1.1282833
Encoder Loss:  0.25981796  || Decoder Loss:  0.44876286 Validation Decoder Loss:  1.1185963
Encoder Loss:  0.25993946  || Decoder Loss:  0.4476712 Validation Decoder Loss:  1.0305713
Encoder Loss:  0.2571237  || Decoder Loss:  0.44777036 Validation Decoder Loss:  1.0624579
Encoder Loss:  0.26173192  || Decoder Loss:  0.4510302 Validation Decoder Loss:  1.0825865
Encoder Loss:  0.25732675  || Decoder Loss:  0.44714823 Validation Decoder Loss:  1.0887594
Encoder Loss:  0.25567037  || Decoder Loss:  0.4452598 Validation Decoder Loss:  1.1019623
Encoder Loss:  0.25590184  || Decoder Loss:  0.4484961 Validation Decoder Loss:  1.0306866
Encoder Loss:  0.26658568  || Decoder Loss:  0.45022315 Validation Decoder Loss:  0.879748
Encoder Loss:  0.2838997  || Decoder Loss:  0.46789718 Validation Decoder Loss:  1.0082202
Encoder Loss:  0.26420137  || Decoder Loss:  0.45204085 Validation Decoder Loss:  1.1647478
Encoder Loss:  0.2614466  || Decoder Loss:  0.449348 Validation Decoder Loss:  1.0010749
Encoder Loss:  0.25732705  || Decoder Loss:  0.4499079 Validation Decoder Loss:  1.0155661
Encoder Loss:  0.25498194  || Decoder Loss:  0.44880828 Validation Decoder Loss:  1.0185523
Encoder Loss:  0.2547259  || Decoder Loss:  0.44844815 Validation Decoder Loss:  1.0059257
Encoder Loss:  0.25653356  || Decoder Loss:  0.44990033 Validation Decoder Loss:  1.0164821
Encoder Loss:  0.25534156  || Decoder Loss:  0.449767 Validation Decoder Loss:  0.97455037
Encoder Loss:  0.25355515  || Decoder Loss:  0.44848746 Validation Decoder Loss:  0.96011525
Encoder Loss:  0.2532386  || Decoder Loss:  0.4478622 Validation Decoder Loss:  0.9485798
Encoder Loss:  0.2535011  || Decoder Loss:  0.44723785 Validation Decoder Loss:  0.9439864
Encoder Loss:  0.25296658  || Decoder Loss:  0.44647434 Validation Decoder Loss:  0.94547385
Encoder Loss:  0.25183272  || Decoder Loss:  0.44528496 Validation Decoder Loss:  0.9399951
Encoder Loss:  0.25089732  || Decoder Loss:  0.44377682 Validation Decoder Loss:  0.92527455
Encoder Loss:  0.25018853  || Decoder Loss:  0.44185814 Validation Decoder Loss:  0.9068263
Encoder Loss:  0.24950786  || Decoder Loss:  0.44027114 Validation Decoder Loss:  0.8958205
Model: siamese_net_lr_0.0621060616004427 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.89582056
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_194 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_417 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_195 (Conv3D (None, 184, 5, 20, 1)     118       
_________________________________________________________________
reshape_135 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 2300, 20, 1)       947       
_________________________________________________________________
dropout_419 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 920, 20, 1)        1382      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 1220, 20, 1)       302       
_________________________________________________________________
dropout_421 (Dropout)        (None, 1220, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 3245, 20, 1)       808       
=================================================================
Total params: 1,110
Trainable params: 1,110
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30972677  || Decoder Loss:  0.75730276 Validation Decoder Loss:  1.2106555
Encoder Loss:  0.09958376  || Decoder Loss:  0.5082082 Validation Decoder Loss:  1.070997
Encoder Loss:  0.07722095  || Decoder Loss:  0.48588684 Validation Decoder Loss:  1.0397028
Encoder Loss:  0.07125144  || Decoder Loss:  0.49179652 Validation Decoder Loss:  1.0274382
Encoder Loss:  0.074807316  || Decoder Loss:  0.4896799 Validation Decoder Loss:  1.0142661
Encoder Loss:  0.0724467  || Decoder Loss:  0.49100673 Validation Decoder Loss:  0.9980747
Encoder Loss:  0.070504725  || Decoder Loss:  0.49052766 Validation Decoder Loss:  0.9600052
Encoder Loss:  0.07289131  || Decoder Loss:  0.48813277 Validation Decoder Loss:  0.9488907
Encoder Loss:  0.072507165  || Decoder Loss:  0.48993832 Validation Decoder Loss:  0.9495456
Encoder Loss:  0.07111046  || Decoder Loss:  0.4882125 Validation Decoder Loss:  0.9446523
Encoder Loss:  0.07221774  || Decoder Loss:  0.48860526 Validation Decoder Loss:  0.9285157
Encoder Loss:  0.070468925  || Decoder Loss:  0.48733494 Validation Decoder Loss:  0.969231
Encoder Loss:  0.075547144  || Decoder Loss:  0.48887455 Validation Decoder Loss:  0.9677023
Encoder Loss:  0.07571465  || Decoder Loss:  0.47699848 Validation Decoder Loss:  0.9999359
Encoder Loss:  0.078213796  || Decoder Loss:  0.4946636 Validation Decoder Loss:  0.8755487
Encoder Loss:  0.07727603  || Decoder Loss:  0.48287445 Validation Decoder Loss:  0.93321836
Encoder Loss:  0.069769114  || Decoder Loss:  0.48874477 Validation Decoder Loss:  0.90354085
Encoder Loss:  0.07420768  || Decoder Loss:  0.4822333 Validation Decoder Loss:  0.83674634
Encoder Loss:  0.074793905  || Decoder Loss:  0.488694 Validation Decoder Loss:  0.79134536
Encoder Loss:  0.06894609  || Decoder Loss:  0.48468673 Validation Decoder Loss:  0.8670355
Encoder Loss:  0.06802413  || Decoder Loss:  0.48556697 Validation Decoder Loss:  0.84363467
Encoder Loss:  0.07348878  || Decoder Loss:  0.4893495 Validation Decoder Loss:  0.9062544
Encoder Loss:  0.069451086  || Decoder Loss:  0.48918542 Validation Decoder Loss:  0.86971086
Encoder Loss:  0.07199253  || Decoder Loss:  0.48820895 Validation Decoder Loss:  0.87880343
Encoder Loss:  0.07036229  || Decoder Loss:  0.48214936 Validation Decoder Loss:  0.8243566
Encoder Loss:  0.06809918  || Decoder Loss:  0.48258594 Validation Decoder Loss:  0.81392336
Encoder Loss:  0.06987343  || Decoder Loss:  0.48226973 Validation Decoder Loss:  0.86865616
Encoder Loss:  0.069416  || Decoder Loss:  0.48672748 Validation Decoder Loss:  0.8606864
Encoder Loss:  0.07068958  || Decoder Loss:  0.4892496 Validation Decoder Loss:  0.82642794
Encoder Loss:  0.074540116  || Decoder Loss:  0.4805852 Validation Decoder Loss:  0.92736197
Encoder Loss:  0.07179113  || Decoder Loss:  0.49042475 Validation Decoder Loss:  0.89043975
Encoder Loss:  0.06952447  || Decoder Loss:  0.4868054 Validation Decoder Loss:  0.8014186
Encoder Loss:  0.07517955  || Decoder Loss:  0.47994214 Validation Decoder Loss:  0.7877488
Encoder Loss:  0.071515866  || Decoder Loss:  0.48183498 Validation Decoder Loss:  0.83705497
Encoder Loss:  0.069786966  || Decoder Loss:  0.48345193 Validation Decoder Loss:  0.8201821
Encoder Loss:  0.07051809  || Decoder Loss:  0.48298395 Validation Decoder Loss:  0.8270319
Encoder Loss:  0.07021728  || Decoder Loss:  0.48233292 Validation Decoder Loss:  0.87723434
Encoder Loss:  0.06797999  || Decoder Loss:  0.48304555 Validation Decoder Loss:  0.864027
Encoder Loss:  0.06820424  || Decoder Loss:  0.4830053 Validation Decoder Loss:  0.87521607
Encoder Loss:  0.067654856  || Decoder Loss:  0.48244935 Validation Decoder Loss:  0.91180754
Model: siamese_net_lr_0.024156157595604175 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.91180754
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_197 (Conv3D (None, 148, 5, 20, 1)     86        
_________________________________________________________________
dropout_423 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_198 (Conv3D (None, 184, 5, 20, 1)     38        
_________________________________________________________________
reshape_136 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 1180, 20, 1)       888       
_________________________________________________________________
dropout_425 (Dropout)        (None, 1180, 20, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 920, 20, 1)        262       
=================================================================
Total params: 1,150
Trainable params: 1,150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 1120, 20, 1)       202       
_________________________________________________________________
dropout_427 (Dropout)        (None, 1120, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 3245, 20, 1)       2127      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6095273  || Decoder Loss:  0.86471933 Validation Decoder Loss:  1.6086836
Encoder Loss:  0.6310368  || Decoder Loss:  0.90327525 Validation Decoder Loss:  1.5977424
Encoder Loss:  0.618867  || Decoder Loss:  0.8865435 Validation Decoder Loss:  1.571122
Encoder Loss:  0.5800377  || Decoder Loss:  0.8457483 Validation Decoder Loss:  0.38896254
Encoder Loss:  0.2745848  || Decoder Loss:  0.18822147 Validation Decoder Loss:  1.585644
Encoder Loss:  0.32199904  || Decoder Loss:  0.53983134 Validation Decoder Loss:  1.2820206
Encoder Loss:  0.26276752  || Decoder Loss:  0.47741538 Validation Decoder Loss:  1.3499011
Encoder Loss:  0.2591312  || Decoder Loss:  0.46956548 Validation Decoder Loss:  1.3333281
Encoder Loss:  0.25935662  || Decoder Loss:  0.46955833 Validation Decoder Loss:  1.2587993
Encoder Loss:  0.2529289  || Decoder Loss:  0.461375 Validation Decoder Loss:  1.3037572
Encoder Loss:  0.2601923  || Decoder Loss:  0.47840273 Validation Decoder Loss:  1.2947147
Encoder Loss:  0.251483  || Decoder Loss:  0.47508365 Validation Decoder Loss:  1.1886609
Encoder Loss:  0.24940604  || Decoder Loss:  0.48286784 Validation Decoder Loss:  1.2681235
Encoder Loss:  0.2562947  || Decoder Loss:  0.49214932 Validation Decoder Loss:  1.4488044
Encoder Loss:  0.24571735  || Decoder Loss:  0.46786174 Validation Decoder Loss:  1.2361845
Encoder Loss:  0.24173309  || Decoder Loss:  0.46745843 Validation Decoder Loss:  1.4089092
Encoder Loss:  0.24521643  || Decoder Loss:  0.47386655 Validation Decoder Loss:  1.301924
Encoder Loss:  0.24405566  || Decoder Loss:  0.47291595 Validation Decoder Loss:  1.4801433
Encoder Loss:  0.24294083  || Decoder Loss:  0.46975124 Validation Decoder Loss:  1.4078541
Encoder Loss:  0.23840868  || Decoder Loss:  0.46248573 Validation Decoder Loss:  1.4355727
Encoder Loss:  0.24501465  || Decoder Loss:  0.47397813 Validation Decoder Loss:  1.3348467
Encoder Loss:  0.23641497  || Decoder Loss:  0.4586831 Validation Decoder Loss:  1.3693044
Encoder Loss:  0.23759751  || Decoder Loss:  0.46172348 Validation Decoder Loss:  1.3693961
Encoder Loss:  0.23762484  || Decoder Loss:  0.4603154 Validation Decoder Loss:  1.3045793
Encoder Loss:  0.2352044  || Decoder Loss:  0.45521522 Validation Decoder Loss:  1.3453557
Encoder Loss:  0.2326375  || Decoder Loss:  0.4500538 Validation Decoder Loss:  1.3705379
Encoder Loss:  0.22746037  || Decoder Loss:  0.43837273 Validation Decoder Loss:  1.2910665
Encoder Loss:  0.2149902  || Decoder Loss:  0.41185293 Validation Decoder Loss:  1.307
Encoder Loss:  0.21085018  || Decoder Loss:  0.40252364 Validation Decoder Loss:  1.3034514
Encoder Loss:  0.20549503  || Decoder Loss:  0.3908095 Validation Decoder Loss:  1.2355722
Encoder Loss:  0.20615804  || Decoder Loss:  0.39363343 Validation Decoder Loss:  1.199357
Encoder Loss:  0.20459679  || Decoder Loss:  0.38856423 Validation Decoder Loss:  1.184803
Encoder Loss:  0.20812823  || Decoder Loss:  0.39730138 Validation Decoder Loss:  1.147888
Encoder Loss:  0.19661997  || Decoder Loss:  0.37296912 Validation Decoder Loss:  1.1672528
Encoder Loss:  0.20504625  || Decoder Loss:  0.39152622 Validation Decoder Loss:  1.1974573
Encoder Loss:  0.2079561  || Decoder Loss:  0.3977583 Validation Decoder Loss:  1.1220789
Encoder Loss:  0.20611182  || Decoder Loss:  0.39408344 Validation Decoder Loss:  1.1689916
Encoder Loss:  0.2059382  || Decoder Loss:  0.39318025 Validation Decoder Loss:  1.145838
Encoder Loss:  0.20768446  || Decoder Loss:  0.39747658 Validation Decoder Loss:  1.0769082
Encoder Loss:  0.20742579  || Decoder Loss:  0.396688 Validation Decoder Loss:  1.0629282
Model: siamese_net_lr_0.048240145402479846 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0629282
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_200 (Conv3D (None, 166, 5, 20, 1)     41        
_________________________________________________________________
dropout_429 (Dropout)        (None, 166, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_201 (Conv3D (None, 184, 5, 20, 1)     20        
_________________________________________________________________
reshape_137 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_444"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 1170, 20, 1)       908       
_________________________________________________________________
dropout_431 (Dropout)        (None, 1170, 20, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 920, 20, 1)        252       
=================================================================
Total params: 1,160
Trainable params: 1,160
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 2060, 20, 1)       223       
_________________________________________________________________
dropout_433 (Dropout)        (None, 2060, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 3245, 20, 1)       1187      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33541325  || Decoder Loss:  0.27015373 Validation Decoder Loss:  0.3380112
Encoder Loss:  0.2974782  || Decoder Loss:  0.102512494 Validation Decoder Loss:  0.34911022
Encoder Loss:  0.2968957  || Decoder Loss:  0.10189882 Validation Decoder Loss:  0.34560478
Encoder Loss:  0.29579628  || Decoder Loss:  0.10048457 Validation Decoder Loss:  0.34067726
Encoder Loss:  0.29444304  || Decoder Loss:  0.098835334 Validation Decoder Loss:  0.3347311
Encoder Loss:  0.2927125  || Decoder Loss:  0.09701695 Validation Decoder Loss:  0.32724446
Encoder Loss:  0.29014578  || Decoder Loss:  0.095119655 Validation Decoder Loss:  0.31614453
Encoder Loss:  0.2824705  || Decoder Loss:  0.094168074 Validation Decoder Loss:  0.2797562
Encoder Loss:  0.4895133  || Decoder Loss:  0.6599265 Validation Decoder Loss:  1.6088839
Encoder Loss:  0.62262684  || Decoder Loss:  0.9019017 Validation Decoder Loss:  1.5993391
Encoder Loss:  0.6174294  || Decoder Loss:  0.89692956 Validation Decoder Loss:  1.5741994
Encoder Loss:  0.5446054  || Decoder Loss:  0.81014466 Validation Decoder Loss:  0.24367814
Encoder Loss:  0.27178046  || Decoder Loss:  0.41667798 Validation Decoder Loss:  0.82460505
Encoder Loss:  0.27217495  || Decoder Loss:  0.5253905 Validation Decoder Loss:  0.32501352
Encoder Loss:  0.24158493  || Decoder Loss:  0.46917245 Validation Decoder Loss:  0.53018904
Encoder Loss:  0.25891483  || Decoder Loss:  0.50680244 Validation Decoder Loss:  0.65178096
Encoder Loss:  0.25750074  || Decoder Loss:  0.5094714 Validation Decoder Loss:  0.7139684
Encoder Loss:  0.2424863  || Decoder Loss:  0.47866347 Validation Decoder Loss:  0.6056358
Encoder Loss:  0.25098693  || Decoder Loss:  0.509824 Validation Decoder Loss:  0.6055879
Encoder Loss:  0.2465456  || Decoder Loss:  0.47989964 Validation Decoder Loss:  0.604679
Encoder Loss:  0.269321  || Decoder Loss:  0.53059244 Validation Decoder Loss:  0.39514992
Encoder Loss:  0.24804308  || Decoder Loss:  0.48214316 Validation Decoder Loss:  0.5798909
Encoder Loss:  0.24188723  || Decoder Loss:  0.4998097 Validation Decoder Loss:  0.50962627
Encoder Loss:  0.24164201  || Decoder Loss:  0.4803931 Validation Decoder Loss:  0.8235578
Encoder Loss:  0.26757115  || Decoder Loss:  0.5054938 Validation Decoder Loss:  0.7793281
Encoder Loss:  0.2674191  || Decoder Loss:  0.51243025 Validation Decoder Loss:  0.8246708
Encoder Loss:  0.25967947  || Decoder Loss:  0.51498294 Validation Decoder Loss:  0.5654839
Encoder Loss:  0.23784989  || Decoder Loss:  0.48080266 Validation Decoder Loss:  0.6893395
Encoder Loss:  0.23899053  || Decoder Loss:  0.4905817 Validation Decoder Loss:  0.68865126
Encoder Loss:  0.2393547  || Decoder Loss:  0.4908632 Validation Decoder Loss:  0.64964837
Encoder Loss:  0.24406642  || Decoder Loss:  0.49612212 Validation Decoder Loss:  0.6444951
Encoder Loss:  0.23795791  || Decoder Loss:  0.48225677 Validation Decoder Loss:  0.7337709
Encoder Loss:  0.23790327  || Decoder Loss:  0.48913774 Validation Decoder Loss:  0.7589498
Encoder Loss:  0.24314287  || Decoder Loss:  0.48978832 Validation Decoder Loss:  0.7669076
Encoder Loss:  0.24039471  || Decoder Loss:  0.48560348 Validation Decoder Loss:  0.7469613
Encoder Loss:  0.23701529  || Decoder Loss:  0.48576385 Validation Decoder Loss:  0.7792184
Encoder Loss:  0.23549704  || Decoder Loss:  0.4872028 Validation Decoder Loss:  0.7929927
Encoder Loss:  0.23856264  || Decoder Loss:  0.48721772 Validation Decoder Loss:  0.8316171
Encoder Loss:  0.23727153  || Decoder Loss:  0.48616374 Validation Decoder Loss:  0.88520503
Encoder Loss:  0.23450917  || Decoder Loss:  0.4842785 Validation Decoder Loss:  0.8867319
Model: siamese_net_lr_0.04688213236385897 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8867319
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_203 (Conv3D (None, 140, 5, 20, 1)     78        
_________________________________________________________________
dropout_435 (Dropout)        (None, 140, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_204 (Conv3D (None, 184, 5, 20, 1)     46        
_________________________________________________________________
reshape_138 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 1770, 20, 1)       1477      
_________________________________________________________________
dropout_437 (Dropout)        (None, 1770, 20, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 920, 20, 1)        852       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 1520, 20, 1)       602       
_________________________________________________________________
dropout_439 (Dropout)        (None, 1520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 3245, 20, 1)       208       
=================================================================
Total params: 810
Trainable params: 810
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4693425  || Decoder Loss:  0.47005418 Validation Decoder Loss:  0.29890138
Encoder Loss:  0.43452686  || Decoder Loss:  0.43622372 Validation Decoder Loss:  0.6935433
Encoder Loss:  0.48604748  || Decoder Loss:  0.48864764 Validation Decoder Loss:  0.5392946
Encoder Loss:  0.48725906  || Decoder Loss:  0.48988396 Validation Decoder Loss:  0.65575695
Encoder Loss:  0.49868748  || Decoder Loss:  0.5013783 Validation Decoder Loss:  0.8587098
Encoder Loss:  0.50560135  || Decoder Loss:  0.5081971 Validation Decoder Loss:  0.44360688
Encoder Loss:  0.48178568  || Decoder Loss:  0.48429492 Validation Decoder Loss:  0.7353147
Encoder Loss:  0.49187717  || Decoder Loss:  0.49456683 Validation Decoder Loss:  0.6526009
Encoder Loss:  0.48778534  || Decoder Loss:  0.49045292 Validation Decoder Loss:  0.676384
Encoder Loss:  0.4887979  || Decoder Loss:  0.49143755 Validation Decoder Loss:  0.5872241
Encoder Loss:  0.4908657  || Decoder Loss:  0.49354285 Validation Decoder Loss:  0.61432457
Encoder Loss:  0.4897116  || Decoder Loss:  0.49242055 Validation Decoder Loss:  0.6698319
Encoder Loss:  0.48823372  || Decoder Loss:  0.49094728 Validation Decoder Loss:  0.67837137
Encoder Loss:  0.4860708  || Decoder Loss:  0.4887563 Validation Decoder Loss:  0.7153604
Encoder Loss:  0.4873025  || Decoder Loss:  0.49001288 Validation Decoder Loss:  0.7228859
Encoder Loss:  0.48697746  || Decoder Loss:  0.48967656 Validation Decoder Loss:  0.7281866
Encoder Loss:  0.48360488  || Decoder Loss:  0.48627293 Validation Decoder Loss:  0.71869314
Encoder Loss:  0.48774377  || Decoder Loss:  0.4904187 Validation Decoder Loss:  0.7425364
Encoder Loss:  0.48751605  || Decoder Loss:  0.4902169 Validation Decoder Loss:  0.766083
Encoder Loss:  0.48741218  || Decoder Loss:  0.49011335 Validation Decoder Loss:  0.7806356
Encoder Loss:  0.48746914  || Decoder Loss:  0.49017528 Validation Decoder Loss:  0.7954153
Encoder Loss:  0.48659608  || Decoder Loss:  0.4892988 Validation Decoder Loss:  0.7985635
Encoder Loss:  0.4869807  || Decoder Loss:  0.48969147 Validation Decoder Loss:  0.8109796
Encoder Loss:  0.48626655  || Decoder Loss:  0.48896712 Validation Decoder Loss:  0.8272711
Encoder Loss:  0.48711205  || Decoder Loss:  0.48981312 Validation Decoder Loss:  0.8117392
Encoder Loss:  0.48736164  || Decoder Loss:  0.49006936 Validation Decoder Loss:  0.8268269
Encoder Loss:  0.48696518  || Decoder Loss:  0.4896727 Validation Decoder Loss:  0.8367256
Encoder Loss:  0.4867562  || Decoder Loss:  0.48946398 Validation Decoder Loss:  0.83542335
Encoder Loss:  0.48679736  || Decoder Loss:  0.48950318 Validation Decoder Loss:  0.84629035
Encoder Loss:  0.48684272  || Decoder Loss:  0.48955742 Validation Decoder Loss:  0.85241556
Encoder Loss:  0.48665512  || Decoder Loss:  0.4893556 Validation Decoder Loss:  0.85521924
Encoder Loss:  0.48724374  || Decoder Loss:  0.48995328 Validation Decoder Loss:  0.86205196
Encoder Loss:  0.48716986  || Decoder Loss:  0.48988515 Validation Decoder Loss:  0.86976624
Encoder Loss:  0.48700622  || Decoder Loss:  0.48972037 Validation Decoder Loss:  0.87124115
Encoder Loss:  0.48699826  || Decoder Loss:  0.48971826 Validation Decoder Loss:  0.8742464
Encoder Loss:  0.486711  || Decoder Loss:  0.48942938 Validation Decoder Loss:  0.8753617
Encoder Loss:  0.48654327  || Decoder Loss:  0.48926106 Validation Decoder Loss:  0.87650025
Encoder Loss:  0.48621038  || Decoder Loss:  0.48892692 Validation Decoder Loss:  0.8769957
Encoder Loss:  0.48568752  || Decoder Loss:  0.4884001 Validation Decoder Loss:  0.8781518
Encoder Loss:  0.48497346  || Decoder Loss:  0.48768204 Validation Decoder Loss:  0.881723
Model: siamese_net_lr_0.06696694008959073 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.881723
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_206 (Conv3D (None, 150, 5, 20, 1)     88        
_________________________________________________________________
dropout_441 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_207 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_139 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 2070, 20, 1)       1177      
_________________________________________________________________
dropout_443 (Dropout)        (None, 2070, 20, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 920, 20, 1)        1152      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 1940, 20, 1)       1022      
_________________________________________________________________
dropout_445 (Dropout)        (None, 1940, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 3245, 20, 1)       1307      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5532467  || Decoder Loss:  0.82066864 Validation Decoder Loss:  1.6006927
Encoder Loss:  0.4972004  || Decoder Loss:  0.753793 Validation Decoder Loss:  1.3866462
Encoder Loss:  0.27557832  || Decoder Loss:  0.18536499 Validation Decoder Loss:  0.3806122
Encoder Loss:  0.31793034  || Decoder Loss:  0.13440184 Validation Decoder Loss:  0.37087202
Encoder Loss:  0.31395432  || Decoder Loss:  0.12785158 Validation Decoder Loss:  0.35977608
Encoder Loss:  0.3091636  || Decoder Loss:  0.12080558 Validation Decoder Loss:  0.34780806
Encoder Loss:  0.30344307  || Decoder Loss:  0.11332178 Validation Decoder Loss:  0.33395916
Encoder Loss:  0.29591006  || Decoder Loss:  0.1056261 Validation Decoder Loss:  0.31602424
Encoder Loss:  0.27556372  || Decoder Loss:  0.1389429 Validation Decoder Loss:  1.4024024
Encoder Loss:  0.33234  || Decoder Loss:  0.54171365 Validation Decoder Loss:  1.0126376
Encoder Loss:  0.2428012  || Decoder Loss:  0.51823896 Validation Decoder Loss:  0.73498595
Encoder Loss:  0.22261518  || Decoder Loss:  0.5124911 Validation Decoder Loss:  0.805981
Encoder Loss:  0.2230988  || Decoder Loss:  0.50552434 Validation Decoder Loss:  0.73470414
Encoder Loss:  0.22813004  || Decoder Loss:  0.51338583 Validation Decoder Loss:  0.6362213
Encoder Loss:  0.22484022  || Decoder Loss:  0.5039104 Validation Decoder Loss:  0.8020545
Encoder Loss:  0.21997204  || Decoder Loss:  0.50604135 Validation Decoder Loss:  0.8190156
Encoder Loss:  0.21921115  || Decoder Loss:  0.49977216 Validation Decoder Loss:  0.836216
Encoder Loss:  0.21980256  || Decoder Loss:  0.49715233 Validation Decoder Loss:  0.8673328
Encoder Loss:  0.2156714  || Decoder Loss:  0.49431133 Validation Decoder Loss:  0.81958836
Encoder Loss:  0.21730167  || Decoder Loss:  0.4955428 Validation Decoder Loss:  0.86508095
Encoder Loss:  0.2143838  || Decoder Loss:  0.4909203 Validation Decoder Loss:  0.8859596
Encoder Loss:  0.21474491  || Decoder Loss:  0.49070227 Validation Decoder Loss:  0.91584533
Encoder Loss:  0.21410331  || Decoder Loss:  0.48679647 Validation Decoder Loss:  0.9566641
Encoder Loss:  0.21314149  || Decoder Loss:  0.48591474 Validation Decoder Loss:  0.9523578
Encoder Loss:  0.2110988  || Decoder Loss:  0.48408082 Validation Decoder Loss:  0.9935824
Encoder Loss:  0.21053678  || Decoder Loss:  0.48235992 Validation Decoder Loss:  1.0270193
Encoder Loss:  0.20999642  || Decoder Loss:  0.4809775 Validation Decoder Loss:  1.0567931
Encoder Loss:  0.21065666  || Decoder Loss:  0.48155576 Validation Decoder Loss:  1.0701154
Encoder Loss:  0.20953394  || Decoder Loss:  0.47979793 Validation Decoder Loss:  1.0651932
Encoder Loss:  0.2083939  || Decoder Loss:  0.47912621 Validation Decoder Loss:  1.0863733
Encoder Loss:  0.2081593  || Decoder Loss:  0.47874355 Validation Decoder Loss:  1.1024971
Encoder Loss:  0.2085595  || Decoder Loss:  0.47843248 Validation Decoder Loss:  1.1103249
Encoder Loss:  0.20699112  || Decoder Loss:  0.47820312 Validation Decoder Loss:  1.1160003
Encoder Loss:  0.20817687  || Decoder Loss:  0.478276 Validation Decoder Loss:  1.1150355
Encoder Loss:  0.20660807  || Decoder Loss:  0.47818878 Validation Decoder Loss:  1.1170931
Encoder Loss:  0.20773724  || Decoder Loss:  0.47913417 Validation Decoder Loss:  1.1097221
Encoder Loss:  0.20730802  || Decoder Loss:  0.47892663 Validation Decoder Loss:  1.094842
Encoder Loss:  0.20668675  || Decoder Loss:  0.47877675 Validation Decoder Loss:  1.0937229
Encoder Loss:  0.20678097  || Decoder Loss:  0.47805756 Validation Decoder Loss:  1.0890299
Encoder Loss:  0.20745903  || Decoder Loss:  0.47909558 Validation Decoder Loss:  1.069952
Model: siamese_net_lr_0.0642632708340443 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.069952
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_209 (Conv3D (None, 128, 5, 20, 1)     66        
_________________________________________________________________
dropout_447 (Dropout)        (None, 128, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_210 (Conv3D (None, 184, 5, 20, 1)     58        
_________________________________________________________________
reshape_140 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 2030, 20, 1)       1217      
_________________________________________________________________
dropout_449 (Dropout)        (None, 2030, 20, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 920, 20, 1)        193       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_457"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 2620, 20, 1)       1702      
_________________________________________________________________
dropout_451 (Dropout)        (None, 2620, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 3245, 20, 1)       627       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.48301047  || Decoder Loss:  0.5747478 Validation Decoder Loss:  0.34750158
Encoder Loss:  0.37248608  || Decoder Loss:  0.45946416 Validation Decoder Loss:  0.43234384
Encoder Loss:  0.39255044  || Decoder Loss:  0.5103727 Validation Decoder Loss:  0.40080172
Encoder Loss:  0.3985319  || Decoder Loss:  0.49748912 Validation Decoder Loss:  0.38512492
Encoder Loss:  0.3779612  || Decoder Loss:  0.4687706 Validation Decoder Loss:  1.1080098
Encoder Loss:  0.39277363  || Decoder Loss:  0.51172316 Validation Decoder Loss:  0.6065691
Encoder Loss:  0.38677245  || Decoder Loss:  0.49690986 Validation Decoder Loss:  0.5834476
Encoder Loss:  0.37850788  || Decoder Loss:  0.48502904 Validation Decoder Loss:  1.1136292
Encoder Loss:  0.3639348  || Decoder Loss:  0.46094158 Validation Decoder Loss:  1.0604761
Encoder Loss:  0.38497314  || Decoder Loss:  0.4973455 Validation Decoder Loss:  0.46495813
Encoder Loss:  0.39441663  || Decoder Loss:  0.51114976 Validation Decoder Loss:  0.59233797
Encoder Loss:  0.37714374  || Decoder Loss:  0.48582104 Validation Decoder Loss:  0.9642203
Encoder Loss:  0.3933709  || Decoder Loss:  0.5090376 Validation Decoder Loss:  0.54110587
Encoder Loss:  0.3815152  || Decoder Loss:  0.49460176 Validation Decoder Loss:  0.72471535
Encoder Loss:  0.39517966  || Decoder Loss:  0.51290727 Validation Decoder Loss:  0.73456967
Encoder Loss:  0.40272805  || Decoder Loss:  0.5263277 Validation Decoder Loss:  0.6074103
Encoder Loss:  0.3997741  || Decoder Loss:  0.521173 Validation Decoder Loss:  0.8725456
Encoder Loss:  0.40301284  || Decoder Loss:  0.53005534 Validation Decoder Loss:  0.70480776
Encoder Loss:  0.3893993  || Decoder Loss:  0.5071348 Validation Decoder Loss:  0.89274645
Encoder Loss:  0.39613953  || Decoder Loss:  0.5220073 Validation Decoder Loss:  0.8108007
Encoder Loss:  0.38841614  || Decoder Loss:  0.5110098 Validation Decoder Loss:  0.76353836
Encoder Loss:  0.3805888  || Decoder Loss:  0.498027 Validation Decoder Loss:  0.7823914
Encoder Loss:  0.3809712  || Decoder Loss:  0.49720693 Validation Decoder Loss:  0.8657485
Encoder Loss:  0.38108033  || Decoder Loss:  0.5019363 Validation Decoder Loss:  0.8054831
Encoder Loss:  0.37902147  || Decoder Loss:  0.495923 Validation Decoder Loss:  0.85157806
Encoder Loss:  0.37832487  || Decoder Loss:  0.49554622 Validation Decoder Loss:  0.8809594
Encoder Loss:  0.37387252  || Decoder Loss:  0.49275458 Validation Decoder Loss:  0.8853877
Encoder Loss:  0.3752346  || Decoder Loss:  0.49200627 Validation Decoder Loss:  0.89979637
Encoder Loss:  0.37347737  || Decoder Loss:  0.49017322 Validation Decoder Loss:  0.8521575
Encoder Loss:  0.373726  || Decoder Loss:  0.49036855 Validation Decoder Loss:  0.90566504
Encoder Loss:  0.3707455  || Decoder Loss:  0.48967785 Validation Decoder Loss:  0.89502966
Encoder Loss:  0.37119496  || Decoder Loss:  0.48778272 Validation Decoder Loss:  0.89460605
Encoder Loss:  0.37096345  || Decoder Loss:  0.4873137 Validation Decoder Loss:  0.92795926
Encoder Loss:  0.3706316  || Decoder Loss:  0.48738456 Validation Decoder Loss:  0.91029507
Encoder Loss:  0.3687604  || Decoder Loss:  0.48680946 Validation Decoder Loss:  0.920997
Encoder Loss:  0.36830148  || Decoder Loss:  0.48582703 Validation Decoder Loss:  0.9416585
Encoder Loss:  0.36839202  || Decoder Loss:  0.48577857 Validation Decoder Loss:  0.9313005
Encoder Loss:  0.36750397  || Decoder Loss:  0.4847187 Validation Decoder Loss:  0.94901854
Encoder Loss:  0.3660627  || Decoder Loss:  0.48412395 Validation Decoder Loss:  0.96025455
Encoder Loss:  0.36636856  || Decoder Loss:  0.4834847 Validation Decoder Loss:  0.9653618
Model: siamese_net_lr_0.02162869838790927 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9653618
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_212 (Conv3D (None, 174, 5, 20, 1)     49        
_________________________________________________________________
dropout_453 (Dropout)        (None, 174, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_213 (Conv3D (None, 184, 5, 20, 1)     12        
_________________________________________________________________
reshape_141 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 2170, 20, 1)       1077      
_________________________________________________________________
dropout_455 (Dropout)        (None, 2170, 20, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 920, 20, 1)        1252      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 1380, 20, 1)       462       
_________________________________________________________________
dropout_457 (Dropout)        (None, 1380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 3245, 20, 1)       1867      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6208095  || Decoder Loss:  0.6471983 Validation Decoder Loss:  0.5244772
Encoder Loss:  0.42160186  || Decoder Loss:  0.43729877 Validation Decoder Loss:  1.3078594
Encoder Loss:  0.3619167  || Decoder Loss:  0.37741756 Validation Decoder Loss:  1.6191552
Encoder Loss:  0.5660932  || Decoder Loss:  0.5962591 Validation Decoder Loss:  0.85410184
Encoder Loss:  0.1135151  || Decoder Loss:  0.11294365 Validation Decoder Loss:  0.29805002
Encoder Loss:  0.07936926  || Decoder Loss:  0.07406503 Validation Decoder Loss:  0.31039944
Encoder Loss:  0.08159375  || Decoder Loss:  0.07356634 Validation Decoder Loss:  0.43437657
Encoder Loss:  0.07356225  || Decoder Loss:  0.06860767 Validation Decoder Loss:  0.27906692
Encoder Loss:  0.059411418  || Decoder Loss:  0.057207108 Validation Decoder Loss:  0.3148159
Encoder Loss:  0.054980736  || Decoder Loss:  0.0512273 Validation Decoder Loss:  0.33847553
Encoder Loss:  0.037715558  || Decoder Loss:  0.034361914 Validation Decoder Loss:  0.35571223
Encoder Loss:  0.031926643  || Decoder Loss:  0.028598495 Validation Decoder Loss:  0.34598258
Encoder Loss:  0.032568604  || Decoder Loss:  0.028306466 Validation Decoder Loss:  0.34941852
Encoder Loss:  0.033984408  || Decoder Loss:  0.028795363 Validation Decoder Loss:  0.33222315
Encoder Loss:  0.036929127  || Decoder Loss:  0.031192487 Validation Decoder Loss:  0.34294704
Encoder Loss:  0.034338735  || Decoder Loss:  0.028998945 Validation Decoder Loss:  0.34815586
Encoder Loss:  0.03679939  || Decoder Loss:  0.029568048 Validation Decoder Loss:  0.34855208
Encoder Loss:  0.035999607  || Decoder Loss:  0.030823603 Validation Decoder Loss:  0.33041552
Encoder Loss:  0.031483985  || Decoder Loss:  0.027819786 Validation Decoder Loss:  0.35024452
Encoder Loss:  0.030141061  || Decoder Loss:  0.026965678 Validation Decoder Loss:  0.3384023
Encoder Loss:  0.032047883  || Decoder Loss:  0.028116101 Validation Decoder Loss:  0.34590062
Encoder Loss:  0.030053828  || Decoder Loss:  0.026915349 Validation Decoder Loss:  0.34167397
Encoder Loss:  0.02966218  || Decoder Loss:  0.026663084 Validation Decoder Loss:  0.35627437
Encoder Loss:  0.029754596  || Decoder Loss:  0.026581235 Validation Decoder Loss:  0.34162748
Encoder Loss:  0.028617792  || Decoder Loss:  0.026309507 Validation Decoder Loss:  0.34860328
Encoder Loss:  0.028533382  || Decoder Loss:  0.026147082 Validation Decoder Loss:  0.34595963
Encoder Loss:  0.030600267  || Decoder Loss:  0.027096666 Validation Decoder Loss:  0.35856497
Encoder Loss:  0.029779674  || Decoder Loss:  0.026987992 Validation Decoder Loss:  0.3416167
Encoder Loss:  0.0289536  || Decoder Loss:  0.026124135 Validation Decoder Loss:  0.34459612
Encoder Loss:  0.029041443  || Decoder Loss:  0.026165301 Validation Decoder Loss:  0.34255582
Encoder Loss:  0.028594904  || Decoder Loss:  0.02612871 Validation Decoder Loss:  0.34547186
Encoder Loss:  0.03048781  || Decoder Loss:  0.02735516 Validation Decoder Loss:  0.3548239
Encoder Loss:  0.030012827  || Decoder Loss:  0.026982617 Validation Decoder Loss:  0.33622292
Encoder Loss:  0.029044677  || Decoder Loss:  0.026225127 Validation Decoder Loss:  0.36538064
Encoder Loss:  0.029108884  || Decoder Loss:  0.02633155 Validation Decoder Loss:  0.35866237
Encoder Loss:  0.028174195  || Decoder Loss:  0.025859736 Validation Decoder Loss:  0.3449161
Encoder Loss:  0.028011225  || Decoder Loss:  0.025642132 Validation Decoder Loss:  0.34691393
Encoder Loss:  0.028827824  || Decoder Loss:  0.026139228 Validation Decoder Loss:  0.34640515
Encoder Loss:  0.028117223  || Decoder Loss:  0.025739485 Validation Decoder Loss:  0.34639734
Encoder Loss:  0.027898638  || Decoder Loss:  0.02551363 Validation Decoder Loss:  0.34855193
Model: siamese_net_lr_0.017130390244350542 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3485519
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_215 (Conv3D (None, 150, 5, 20, 1)     25        
_________________________________________________________________
dropout_459 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_216 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_142 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 2770, 20, 1)       477       
_________________________________________________________________
dropout_461 (Dropout)        (None, 2770, 20, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 920, 20, 1)        933       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 940, 20, 1)        22        
_________________________________________________________________
dropout_463 (Dropout)        (None, 940, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 3245, 20, 1)       1368      
=================================================================
Total params: 1,390
Trainable params: 1,390
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35081032  || Decoder Loss:  0.3351827 Validation Decoder Loss:  0.3787666
Encoder Loss:  0.24772996  || Decoder Loss:  0.109068096 Validation Decoder Loss:  0.41222796
Encoder Loss:  0.5794532  || Decoder Loss:  0.7702639 Validation Decoder Loss:  1.6491337
Encoder Loss:  0.6706006  || Decoder Loss:  0.90579605 Validation Decoder Loss:  1.6286741
Encoder Loss:  0.6231975  || Decoder Loss:  0.8140491 Validation Decoder Loss:  1.1897271
Encoder Loss:  0.39138702  || Decoder Loss:  0.35812816 Validation Decoder Loss:  0.53327143
Encoder Loss:  0.28137052  || Decoder Loss:  0.14270446 Validation Decoder Loss:  0.41221923
Encoder Loss:  0.26149213  || Decoder Loss:  0.10578063 Validation Decoder Loss:  0.38921928
Encoder Loss:  0.2565619  || Decoder Loss:  0.09850711 Validation Decoder Loss:  0.3821733
Encoder Loss:  0.25286472  || Decoder Loss:  0.09555176 Validation Decoder Loss:  0.37730524
Encoder Loss:  0.25620836  || Decoder Loss:  0.0928175 Validation Decoder Loss:  0.37333542
Encoder Loss:  0.25372502  || Decoder Loss:  0.08977964 Validation Decoder Loss:  0.37026328
Encoder Loss:  0.24825078  || Decoder Loss:  0.08637521 Validation Decoder Loss:  0.36865544
Encoder Loss:  0.3010536  || Decoder Loss:  0.3362883 Validation Decoder Loss:  0.3698138
Encoder Loss:  0.20414364  || Decoder Loss:  0.33512807 Validation Decoder Loss:  1.0576723
Encoder Loss:  0.30572814  || Decoder Loss:  0.55174494 Validation Decoder Loss:  1.010649
Encoder Loss:  0.29397762  || Decoder Loss:  0.5292138 Validation Decoder Loss:  0.88154876
Encoder Loss:  0.28825384  || Decoder Loss:  0.5185932 Validation Decoder Loss:  0.9088645
Encoder Loss:  0.27409855  || Decoder Loss:  0.49040374 Validation Decoder Loss:  0.7896726
Encoder Loss:  0.26264954  || Decoder Loss:  0.46859917 Validation Decoder Loss:  0.71795243
Encoder Loss:  0.24586166  || Decoder Loss:  0.4345645 Validation Decoder Loss:  0.7746042
Encoder Loss:  0.2074251  || Decoder Loss:  0.35908934 Validation Decoder Loss:  0.52369595
Encoder Loss:  0.1044938  || Decoder Loss:  0.15594293 Validation Decoder Loss:  0.42765698
Encoder Loss:  0.06371088  || Decoder Loss:  0.07628986 Validation Decoder Loss:  0.29518187
Encoder Loss:  0.061484076  || Decoder Loss:  0.07138143 Validation Decoder Loss:  0.28760412
Encoder Loss:  0.06085948  || Decoder Loss:  0.06995258 Validation Decoder Loss:  0.2893669
Encoder Loss:  0.060501117  || Decoder Loss:  0.06885894 Validation Decoder Loss:  0.29369318
Encoder Loss:  0.060455747  || Decoder Loss:  0.06785876 Validation Decoder Loss:  0.29468864
Encoder Loss:  0.059438944  || Decoder Loss:  0.06678517 Validation Decoder Loss:  0.2917514
Encoder Loss:  0.059286285  || Decoder Loss:  0.06601891 Validation Decoder Loss:  0.29408374
Encoder Loss:  0.05833695  || Decoder Loss:  0.06523683 Validation Decoder Loss:  0.29249263
Encoder Loss:  0.058502175  || Decoder Loss:  0.06467019 Validation Decoder Loss:  0.2934028
Encoder Loss:  0.05766119  || Decoder Loss:  0.0639353 Validation Decoder Loss:  0.29578954
Encoder Loss:  0.057174142  || Decoder Loss:  0.06327964 Validation Decoder Loss:  0.2977651
Encoder Loss:  0.05686918  || Decoder Loss:  0.062606305 Validation Decoder Loss:  0.300129
Encoder Loss:  0.05653286  || Decoder Loss:  0.06178988 Validation Decoder Loss:  0.303398
Encoder Loss:  0.05640911  || Decoder Loss:  0.060926337 Validation Decoder Loss:  0.30450857
Encoder Loss:  0.055523768  || Decoder Loss:  0.059980575 Validation Decoder Loss:  0.3071258
Encoder Loss:  0.05526977  || Decoder Loss:  0.05894263 Validation Decoder Loss:  0.30925083
Encoder Loss:  0.054506708  || Decoder Loss:  0.057840165 Validation Decoder Loss:  0.3114673
Model: siamese_net_lr_0.08489161148142395 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3114673
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_218 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_465 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_219 (Conv3D (None, 184, 5, 20, 1)     7         
_________________________________________________________________
reshape_143 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 35
Trainable params: 35
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 1710, 20, 1)       1537      
_________________________________________________________________
dropout_467 (Dropout)        (None, 1710, 20, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 920, 20, 1)        792       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_469"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 1660, 20, 1)       742       
_________________________________________________________________
dropout_469 (Dropout)        (None, 1660, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 3245, 20, 1)       1587      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3377423  || Decoder Loss:  0.6917141 Validation Decoder Loss:  0.33751228
Encoder Loss:  0.19608319  || Decoder Loss:  0.4849886 Validation Decoder Loss:  0.41310695
Encoder Loss:  0.1736787  || Decoder Loss:  0.43698677 Validation Decoder Loss:  0.77150667
Encoder Loss:  0.17027454  || Decoder Loss:  0.4303954 Validation Decoder Loss:  0.5439362
Encoder Loss:  0.17856653  || Decoder Loss:  0.45689785 Validation Decoder Loss:  1.3866427
Encoder Loss:  0.15388998  || Decoder Loss:  0.37484923 Validation Decoder Loss:  0.47035807
Encoder Loss:  0.10707878  || Decoder Loss:  0.22719242 Validation Decoder Loss:  0.97340655
Encoder Loss:  0.18799624  || Decoder Loss:  0.48977786 Validation Decoder Loss:  0.9944129
Encoder Loss:  0.18964186  || Decoder Loss:  0.4901932 Validation Decoder Loss:  1.0222063
Encoder Loss:  0.19251335  || Decoder Loss:  0.49397573 Validation Decoder Loss:  1.0216031
Encoder Loss:  0.18991631  || Decoder Loss:  0.4928752 Validation Decoder Loss:  1.0063031
Encoder Loss:  0.18800321  || Decoder Loss:  0.48915753 Validation Decoder Loss:  1.0111291
Encoder Loss:  0.18884538  || Decoder Loss:  0.48987743 Validation Decoder Loss:  0.98341227
Encoder Loss:  0.18621412  || Decoder Loss:  0.48217568 Validation Decoder Loss:  0.9795697
Encoder Loss:  0.1924485  || Decoder Loss:  0.49929357 Validation Decoder Loss:  0.95221514
Encoder Loss:  0.19019057  || Decoder Loss:  0.49463025 Validation Decoder Loss:  1.0104698
Encoder Loss:  0.19102511  || Decoder Loss:  0.49309713 Validation Decoder Loss:  1.0087664
Encoder Loss:  0.18883505  || Decoder Loss:  0.48996562 Validation Decoder Loss:  1.0025702
Encoder Loss:  0.18891391  || Decoder Loss:  0.48851857 Validation Decoder Loss:  0.99692464
Encoder Loss:  0.18648094  || Decoder Loss:  0.48285937 Validation Decoder Loss:  0.8933663
Encoder Loss:  0.18763167  || Decoder Loss:  0.4847588 Validation Decoder Loss:  1.0134956
Encoder Loss:  0.18814652  || Decoder Loss:  0.4864196 Validation Decoder Loss:  0.9862585
Encoder Loss:  0.1837343  || Decoder Loss:  0.47520742 Validation Decoder Loss:  0.6923533
Encoder Loss:  0.19016646  || Decoder Loss:  0.48943955 Validation Decoder Loss:  0.9905269
Encoder Loss:  0.19077969  || Decoder Loss:  0.49158084 Validation Decoder Loss:  1.0098454
Encoder Loss:  0.19084792  || Decoder Loss:  0.49222842 Validation Decoder Loss:  1.022877
Encoder Loss:  0.19040984  || Decoder Loss:  0.49235696 Validation Decoder Loss:  1.0137339
Encoder Loss:  0.1891123  || Decoder Loss:  0.4916014 Validation Decoder Loss:  0.9997324
Encoder Loss:  0.18988293  || Decoder Loss:  0.49143183 Validation Decoder Loss:  1.0036169
Encoder Loss:  0.18813296  || Decoder Loss:  0.48969486 Validation Decoder Loss:  0.9912935
Encoder Loss:  0.18913408  || Decoder Loss:  0.49059013 Validation Decoder Loss:  1.0085679
Encoder Loss:  0.18836191  || Decoder Loss:  0.49004686 Validation Decoder Loss:  0.9935004
Encoder Loss:  0.18811047  || Decoder Loss:  0.48988426 Validation Decoder Loss:  0.9931886
Encoder Loss:  0.18821831  || Decoder Loss:  0.4883122 Validation Decoder Loss:  0.9792941
Encoder Loss:  0.186378  || Decoder Loss:  0.4847734 Validation Decoder Loss:  0.99611473
Encoder Loss:  0.18972996  || Decoder Loss:  0.4945431 Validation Decoder Loss:  1.0045173
Encoder Loss:  0.18977776  || Decoder Loss:  0.49494186 Validation Decoder Loss:  1.0038123
Encoder Loss:  0.18958499  || Decoder Loss:  0.49484184 Validation Decoder Loss:  1.0041972
Encoder Loss:  0.19077851  || Decoder Loss:  0.4947568 Validation Decoder Loss:  1.0050809
Encoder Loss:  0.19001593  || Decoder Loss:  0.4945292 Validation Decoder Loss:  1.004583
Model: siamese_net_lr_0.09888729963431842 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.004583
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_221 (Conv3D (None, 150, 5, 20, 1)     25        
_________________________________________________________________
dropout_471 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_222 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_144 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 2040, 20, 1)       1207      
_________________________________________________________________
dropout_473 (Dropout)        (None, 2040, 20, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 920, 20, 1)        203       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_473"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 1880, 20, 1)       962       
_________________________________________________________________
dropout_475 (Dropout)        (None, 1880, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 3245, 20, 1)       1367      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5073278  || Decoder Loss:  0.5182527 Validation Decoder Loss:  0.29031602
Encoder Loss:  0.6291447  || Decoder Loss:  0.65306586 Validation Decoder Loss:  1.7171013
Encoder Loss:  0.8346372  || Decoder Loss:  0.8750026 Validation Decoder Loss:  1.7130039
Encoder Loss:  0.8205511  || Decoder Loss:  0.8598946 Validation Decoder Loss:  1.7027614
Encoder Loss:  0.79114634  || Decoder Loss:  0.82835746 Validation Decoder Loss:  1.6527804
Encoder Loss:  0.6678936  || Decoder Loss:  0.69973433 Validation Decoder Loss:  0.841107
Encoder Loss:  0.4739412  || Decoder Loss:  0.5100166 Validation Decoder Loss:  0.9238687
Encoder Loss:  0.47105515  || Decoder Loss:  0.50996435 Validation Decoder Loss:  0.936893
Encoder Loss:  0.47230574  || Decoder Loss:  0.5106623 Validation Decoder Loss:  0.8652003
Encoder Loss:  0.4723734  || Decoder Loss:  0.50883067 Validation Decoder Loss:  0.916841
Encoder Loss:  0.47076347  || Decoder Loss:  0.5093821 Validation Decoder Loss:  0.9151832
Encoder Loss:  0.4690097  || Decoder Loss:  0.50909144 Validation Decoder Loss:  0.8998046
Encoder Loss:  0.46864602  || Decoder Loss:  0.50837946 Validation Decoder Loss:  0.88874495
Encoder Loss:  0.46949238  || Decoder Loss:  0.5079467 Validation Decoder Loss:  0.8564819
Encoder Loss:  0.4691049  || Decoder Loss:  0.5074886 Validation Decoder Loss:  0.8762226
Encoder Loss:  0.4675136  || Decoder Loss:  0.5065166 Validation Decoder Loss:  0.86116326
Encoder Loss:  0.4654343  || Decoder Loss:  0.5054678 Validation Decoder Loss:  0.86009306
Encoder Loss:  0.46477893  || Decoder Loss:  0.5042959 Validation Decoder Loss:  0.8444194
Encoder Loss:  0.46347186  || Decoder Loss:  0.503001 Validation Decoder Loss:  0.83242923
Encoder Loss:  0.46344674  || Decoder Loss:  0.50177515 Validation Decoder Loss:  0.83169174
Encoder Loss:  0.46124277  || Decoder Loss:  0.50022835 Validation Decoder Loss:  0.82939816
Encoder Loss:  0.4597479  || Decoder Loss:  0.49850965 Validation Decoder Loss:  0.82680583
Encoder Loss:  0.45770895  || Decoder Loss:  0.49659184 Validation Decoder Loss:  0.8328744
Encoder Loss:  0.45580742  || Decoder Loss:  0.49451366 Validation Decoder Loss:  0.83355355
Encoder Loss:  0.45430195  || Decoder Loss:  0.4925341 Validation Decoder Loss:  0.8509282
Encoder Loss:  0.45278394  || Decoder Loss:  0.49044055 Validation Decoder Loss:  0.8592732
Encoder Loss:  0.45077845  || Decoder Loss:  0.48863012 Validation Decoder Loss:  0.90496874
Encoder Loss:  0.44857034  || Decoder Loss:  0.4868803 Validation Decoder Loss:  0.9238409
Encoder Loss:  0.44695365  || Decoder Loss:  0.4847884 Validation Decoder Loss:  0.9574883
Encoder Loss:  0.4464312  || Decoder Loss:  0.48420584 Validation Decoder Loss:  0.99714565
Encoder Loss:  0.4454317  || Decoder Loss:  0.483155 Validation Decoder Loss:  1.0183158
Encoder Loss:  0.44392246  || Decoder Loss:  0.4816325 Validation Decoder Loss:  1.0300734
Encoder Loss:  0.44251034  || Decoder Loss:  0.480204 Validation Decoder Loss:  1.0553151
Encoder Loss:  0.44200048  || Decoder Loss:  0.4797905 Validation Decoder Loss:  1.0730147
Encoder Loss:  0.44266623  || Decoder Loss:  0.4796036 Validation Decoder Loss:  1.0347667
Encoder Loss:  0.44017273  || Decoder Loss:  0.47711763 Validation Decoder Loss:  1.0201478
Encoder Loss:  0.4306545  || Decoder Loss:  0.46736148 Validation Decoder Loss:  1.0179607
Encoder Loss:  0.42024812  || Decoder Loss:  0.4560984 Validation Decoder Loss:  0.9903214
Encoder Loss:  0.41616717  || Decoder Loss:  0.45133042 Validation Decoder Loss:  0.97492576
Encoder Loss:  0.4154884  || Decoder Loss:  0.45064902 Validation Decoder Loss:  0.9683239
Model: siamese_net_lr_0.022210520234304948 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9683239
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_224 (Conv3D (None, 174, 5, 20, 1)     112       
_________________________________________________________________
dropout_477 (Dropout)        (None, 174, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_225 (Conv3D (None, 184, 5, 20, 1)     12        
_________________________________________________________________
reshape_145 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_476"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 2170, 20, 1)       1077      
_________________________________________________________________
dropout_479 (Dropout)        (None, 2170, 20, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 920, 20, 1)        1252      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 1380, 20, 1)       462       
_________________________________________________________________
dropout_481 (Dropout)        (None, 1380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 3245, 20, 1)       1867      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3211489  || Decoder Loss:  0.32005525 Validation Decoder Loss:  0.3601809
Encoder Loss:  0.46941352  || Decoder Loss:  0.5002268 Validation Decoder Loss:  0.5241315
Encoder Loss:  0.5110312  || Decoder Loss:  0.5463376 Validation Decoder Loss:  0.3738584
Encoder Loss:  0.43696472  || Decoder Loss:  0.4647198 Validation Decoder Loss:  0.38391683
Encoder Loss:  0.40879527  || Decoder Loss:  0.43688294 Validation Decoder Loss:  0.5484768
Encoder Loss:  0.42560935  || Decoder Loss:  0.45517585 Validation Decoder Loss:  0.3920411
Encoder Loss:  0.40627968  || Decoder Loss:  0.43507397 Validation Decoder Loss:  0.5670197
Encoder Loss:  0.3622049  || Decoder Loss:  0.38848045 Validation Decoder Loss:  0.5038856
Encoder Loss:  0.16852206  || Decoder Loss:  0.17599255 Validation Decoder Loss:  0.3133201
Encoder Loss:  0.098374374  || Decoder Loss:  0.10132453 Validation Decoder Loss:  0.32759395
Encoder Loss:  0.07624143  || Decoder Loss:  0.07571592 Validation Decoder Loss:  0.3298742
Encoder Loss:  0.067720704  || Decoder Loss:  0.067422226 Validation Decoder Loss:  0.31827483
Encoder Loss:  0.05575734  || Decoder Loss:  0.054235816 Validation Decoder Loss:  0.3208893
Encoder Loss:  0.04148175  || Decoder Loss:  0.038955655 Validation Decoder Loss:  0.33867803
Encoder Loss:  0.04387464  || Decoder Loss:  0.04054775 Validation Decoder Loss:  0.37269887
Encoder Loss:  0.040423956  || Decoder Loss:  0.03796777 Validation Decoder Loss:  0.3364333
Encoder Loss:  0.037896805  || Decoder Loss:  0.03582696 Validation Decoder Loss:  0.37931648
Encoder Loss:  0.04218617  || Decoder Loss:  0.03931336 Validation Decoder Loss:  0.3324157
Encoder Loss:  0.04130798  || Decoder Loss:  0.03677595 Validation Decoder Loss:  0.32971013
Encoder Loss:  0.047187533  || Decoder Loss:  0.044131808 Validation Decoder Loss:  0.3140995
Encoder Loss:  0.04452237  || Decoder Loss:  0.043215767 Validation Decoder Loss:  0.3475411
Encoder Loss:  0.03734015  || Decoder Loss:  0.03512131 Validation Decoder Loss:  0.33540088
Encoder Loss:  0.036015347  || Decoder Loss:  0.03374846 Validation Decoder Loss:  0.3429811
Encoder Loss:  0.03591733  || Decoder Loss:  0.03380379 Validation Decoder Loss:  0.32354242
Encoder Loss:  0.03655453  || Decoder Loss:  0.034606796 Validation Decoder Loss:  0.34112188
Encoder Loss:  0.03451129  || Decoder Loss:  0.032168966 Validation Decoder Loss:  0.34321922
Encoder Loss:  0.03563138  || Decoder Loss:  0.03332431 Validation Decoder Loss:  0.3238952
Encoder Loss:  0.03583486  || Decoder Loss:  0.03387196 Validation Decoder Loss:  0.336282
Encoder Loss:  0.034954835  || Decoder Loss:  0.03291029 Validation Decoder Loss:  0.328986
Encoder Loss:  0.035472855  || Decoder Loss:  0.033469018 Validation Decoder Loss:  0.3428355
Encoder Loss:  0.034385398  || Decoder Loss:  0.032513298 Validation Decoder Loss:  0.345765
Encoder Loss:  0.03456713  || Decoder Loss:  0.03276129 Validation Decoder Loss:  0.33821264
Encoder Loss:  0.035482395  || Decoder Loss:  0.032312024 Validation Decoder Loss:  0.33590275
Encoder Loss:  0.035814278  || Decoder Loss:  0.033381183 Validation Decoder Loss:  0.33781737
Encoder Loss:  0.034765795  || Decoder Loss:  0.032600652 Validation Decoder Loss:  0.34199956
Encoder Loss:  0.034500703  || Decoder Loss:  0.032435443 Validation Decoder Loss:  0.33531094
Encoder Loss:  0.034160584  || Decoder Loss:  0.032282747 Validation Decoder Loss:  0.3361587
Encoder Loss:  0.033864614  || Decoder Loss:  0.03195659 Validation Decoder Loss:  0.3368882
Encoder Loss:  0.0341856  || Decoder Loss:  0.03154743 Validation Decoder Loss:  0.33353963
Encoder Loss:  0.033817295  || Decoder Loss:  0.031716853 Validation Decoder Loss:  0.34398258
Model: siamese_net_lr_0.017130391011621855 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34398258
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_227 (Conv3D (None, 176, 5, 20, 1)     114       
_________________________________________________________________
dropout_483 (Dropout)        (None, 176, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_228 (Conv3D (None, 184, 5, 20, 1)     10        
_________________________________________________________________
reshape_146 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 1170, 20, 1)       908       
_________________________________________________________________
dropout_485 (Dropout)        (None, 1170, 20, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 920, 20, 1)        252       
=================================================================
Total params: 1,160
Trainable params: 1,160
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 2130, 20, 1)       1212      
_________________________________________________________________
dropout_487 (Dropout)        (None, 2130, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 3245, 20, 1)       1117      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2891277  || Decoder Loss:  0.14275907 Validation Decoder Loss:  0.3767171
Encoder Loss:  0.28029692  || Decoder Loss:  0.121912174 Validation Decoder Loss:  0.3697911
Encoder Loss:  0.27662545  || Decoder Loss:  0.11650954 Validation Decoder Loss:  0.36129522
Encoder Loss:  0.27223244  || Decoder Loss:  0.110152915 Validation Decoder Loss:  0.34934515
Encoder Loss:  0.34148678  || Decoder Loss:  0.33256555 Validation Decoder Loss:  0.3125975
Encoder Loss:  0.30416593  || Decoder Loss:  0.3036262 Validation Decoder Loss:  0.22905684
Encoder Loss:  0.30307147  || Decoder Loss:  0.5195887 Validation Decoder Loss:  0.77224183
Encoder Loss:  0.29603496  || Decoder Loss:  0.5168526 Validation Decoder Loss:  0.34965268
Encoder Loss:  0.2939972  || Decoder Loss:  0.514389 Validation Decoder Loss:  0.5190712
Encoder Loss:  0.30879697  || Decoder Loss:  0.52114123 Validation Decoder Loss:  0.2459096
Encoder Loss:  0.26487198  || Decoder Loss:  0.4549533 Validation Decoder Loss:  0.35757816
Encoder Loss:  0.3180975  || Decoder Loss:  0.5468796 Validation Decoder Loss:  0.86526984
Encoder Loss:  0.27695245  || Decoder Loss:  0.48900354 Validation Decoder Loss:  0.6623378
Encoder Loss:  0.30014846  || Decoder Loss:  0.52062875 Validation Decoder Loss:  0.88360536
Encoder Loss:  0.27879295  || Decoder Loss:  0.4940318 Validation Decoder Loss:  0.7873698
Encoder Loss:  0.28077388  || Decoder Loss:  0.48922864 Validation Decoder Loss:  0.5437187
Encoder Loss:  0.28266147  || Decoder Loss:  0.4971123 Validation Decoder Loss:  0.43842518
Encoder Loss:  0.2782558  || Decoder Loss:  0.4923184 Validation Decoder Loss:  0.53441703
Encoder Loss:  0.275588  || Decoder Loss:  0.48668846 Validation Decoder Loss:  0.6127858
Encoder Loss:  0.27393705  || Decoder Loss:  0.4832648 Validation Decoder Loss:  0.7558452
Encoder Loss:  0.29157066  || Decoder Loss:  0.51478124 Validation Decoder Loss:  0.7480973
Encoder Loss:  0.26409015  || Decoder Loss:  0.46497303 Validation Decoder Loss:  0.6915637
Encoder Loss:  0.26761866  || Decoder Loss:  0.47228977 Validation Decoder Loss:  0.79958427
Encoder Loss:  0.26513267  || Decoder Loss:  0.46672204 Validation Decoder Loss:  0.9211442
Encoder Loss:  0.2616892  || Decoder Loss:  0.45725608 Validation Decoder Loss:  0.9465506
Encoder Loss:  0.25785488  || Decoder Loss:  0.45390725 Validation Decoder Loss:  0.9139874
Encoder Loss:  0.25706142  || Decoder Loss:  0.45200115 Validation Decoder Loss:  0.9034021
Encoder Loss:  0.2570606  || Decoder Loss:  0.4521606 Validation Decoder Loss:  0.9431135
Encoder Loss:  0.26322103  || Decoder Loss:  0.45387346 Validation Decoder Loss:  0.9473143
Encoder Loss:  0.25493312  || Decoder Loss:  0.44745517 Validation Decoder Loss:  0.9388018
Encoder Loss:  0.25351456  || Decoder Loss:  0.44525254 Validation Decoder Loss:  1.0077672
Encoder Loss:  0.2512315  || Decoder Loss:  0.44111693 Validation Decoder Loss:  1.0128591
Encoder Loss:  0.25143686  || Decoder Loss:  0.44069844 Validation Decoder Loss:  1.0012982
Encoder Loss:  0.25170547  || Decoder Loss:  0.4392426 Validation Decoder Loss:  0.89864826
Encoder Loss:  0.25431043  || Decoder Loss:  0.4401858 Validation Decoder Loss:  1.1557255
Encoder Loss:  0.25459975  || Decoder Loss:  0.44232112 Validation Decoder Loss:  0.9978764
Encoder Loss:  0.25067508  || Decoder Loss:  0.4346957 Validation Decoder Loss:  1.0677203
Encoder Loss:  0.25170955  || Decoder Loss:  0.43565536 Validation Decoder Loss:  0.9310279
Encoder Loss:  0.25107735  || Decoder Loss:  0.43554106 Validation Decoder Loss:  1.0257456
Encoder Loss:  0.2477823  || Decoder Loss:  0.43388554 Validation Decoder Loss:  1.0034919
Model: siamese_net_lr_0.05266365035685951 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0034919
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_230 (Conv3D (None, 168, 5, 20, 1)     106       
_________________________________________________________________
dropout_489 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_231 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_147 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 1680, 20, 1)       1567      
_________________________________________________________________
dropout_491 (Dropout)        (None, 1680, 20, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 920, 20, 1)        762       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 2890, 20, 1)       1972      
_________________________________________________________________
dropout_493 (Dropout)        (None, 2890, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 3245, 20, 1)       357       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20903936  || Decoder Loss:  0.14218022 Validation Decoder Loss:  0.3986182
Encoder Loss:  0.15637104  || Decoder Loss:  0.066798955 Validation Decoder Loss:  0.3683619
Encoder Loss:  0.14857163  || Decoder Loss:  0.071406566 Validation Decoder Loss:  0.36474943
Encoder Loss:  0.3709342  || Decoder Loss:  0.45629805 Validation Decoder Loss:  1.1973937
Encoder Loss:  0.39291608  || Decoder Loss:  0.49572396 Validation Decoder Loss:  0.8488819
Encoder Loss:  0.37168634  || Decoder Loss:  0.4732058 Validation Decoder Loss:  0.91406655
Encoder Loss:  0.38069797  || Decoder Loss:  0.4842798 Validation Decoder Loss:  0.76953876
Encoder Loss:  0.37151676  || Decoder Loss:  0.47534266 Validation Decoder Loss:  0.92620015
Encoder Loss:  0.38238063  || Decoder Loss:  0.48799163 Validation Decoder Loss:  0.8646835
Encoder Loss:  0.38064504  || Decoder Loss:  0.48567817 Validation Decoder Loss:  0.77585745
Encoder Loss:  0.37344903  || Decoder Loss:  0.47763267 Validation Decoder Loss:  0.8623509
Encoder Loss:  0.37169227  || Decoder Loss:  0.4725579 Validation Decoder Loss:  0.7730189
Encoder Loss:  0.37728825  || Decoder Loss:  0.48284385 Validation Decoder Loss:  0.8777401
Encoder Loss:  0.38127458  || Decoder Loss:  0.48767728 Validation Decoder Loss:  0.83251756
Encoder Loss:  0.3761943  || Decoder Loss:  0.4818709 Validation Decoder Loss:  0.8693328
Encoder Loss:  0.3751542  || Decoder Loss:  0.48081157 Validation Decoder Loss:  0.8748026
Encoder Loss:  0.3765424  || Decoder Loss:  0.48144495 Validation Decoder Loss:  0.9241278
Encoder Loss:  0.37249562  || Decoder Loss:  0.47623038 Validation Decoder Loss:  0.90764296
Encoder Loss:  0.37215176  || Decoder Loss:  0.4747669 Validation Decoder Loss:  0.8828178
Encoder Loss:  0.37568828  || Decoder Loss:  0.48153192 Validation Decoder Loss:  0.8867717
Encoder Loss:  0.37331  || Decoder Loss:  0.47939518 Validation Decoder Loss:  0.92451686
Encoder Loss:  0.3754233  || Decoder Loss:  0.4803535 Validation Decoder Loss:  0.8439427
Encoder Loss:  0.3736564  || Decoder Loss:  0.47800004 Validation Decoder Loss:  0.95605737
Encoder Loss:  0.37489617  || Decoder Loss:  0.47927043 Validation Decoder Loss:  0.9472522
Encoder Loss:  0.37367776  || Decoder Loss:  0.477644 Validation Decoder Loss:  0.9342295
Encoder Loss:  0.37262997  || Decoder Loss:  0.47764283 Validation Decoder Loss:  0.93267405
Encoder Loss:  0.37300846  || Decoder Loss:  0.47857124 Validation Decoder Loss:  0.90376484
Encoder Loss:  0.37421182  || Decoder Loss:  0.4793099 Validation Decoder Loss:  0.9581883
Encoder Loss:  0.373  || Decoder Loss:  0.47858316 Validation Decoder Loss:  0.9260101
Encoder Loss:  0.37381962  || Decoder Loss:  0.47812983 Validation Decoder Loss:  0.9186031
Encoder Loss:  0.37138858  || Decoder Loss:  0.4773848 Validation Decoder Loss:  0.9546584
Encoder Loss:  0.37124455  || Decoder Loss:  0.47643715 Validation Decoder Loss:  0.9481629
Encoder Loss:  0.37178218  || Decoder Loss:  0.47670665 Validation Decoder Loss:  0.9569448
Encoder Loss:  0.37124863  || Decoder Loss:  0.4763955 Validation Decoder Loss:  0.9388902
Encoder Loss:  0.37270582  || Decoder Loss:  0.47792286 Validation Decoder Loss:  0.9485611
Encoder Loss:  0.37169358  || Decoder Loss:  0.47641116 Validation Decoder Loss:  0.9647408
Encoder Loss:  0.37144527  || Decoder Loss:  0.47605518 Validation Decoder Loss:  0.9672271
Encoder Loss:  0.3711443  || Decoder Loss:  0.4758621 Validation Decoder Loss:  0.945706
Encoder Loss:  0.3698239  || Decoder Loss:  0.4750686 Validation Decoder Loss:  0.9554221
Encoder Loss:  0.36935318  || Decoder Loss:  0.47465074 Validation Decoder Loss:  0.94292533
Model: siamese_net_lr_0.0064330907665687935 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.94292533
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_233 (Conv3D (None, 180, 5, 20, 1)     118       
_________________________________________________________________
dropout_495 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_234 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_148 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_488"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 1180, 20, 1)       2067      
_________________________________________________________________
dropout_497 (Dropout)        (None, 1180, 20, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 920, 20, 1)        262       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 2110, 20, 1)       273       
_________________________________________________________________
dropout_499 (Dropout)        (None, 2110, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 3245, 20, 1)       1137      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.336925  || Decoder Loss:  0.25080365 Validation Decoder Loss:  1.69649
Encoder Loss:  0.20847422  || Decoder Loss:  0.52825135 Validation Decoder Loss:  1.5355606
Encoder Loss:  0.16408642  || Decoder Loss:  0.51983225 Validation Decoder Loss:  1.4237098
Encoder Loss:  0.16068304  || Decoder Loss:  0.50572085 Validation Decoder Loss:  1.40077
Encoder Loss:  0.16321498  || Decoder Loss:  0.5135749 Validation Decoder Loss:  1.4454006
Encoder Loss:  0.1583548  || Decoder Loss:  0.49946776 Validation Decoder Loss:  1.2819638
Encoder Loss:  0.16872467  || Decoder Loss:  0.49276772 Validation Decoder Loss:  1.246037
Encoder Loss:  0.15436168  || Decoder Loss:  0.4931582 Validation Decoder Loss:  1.1957567
Encoder Loss:  0.15852726  || Decoder Loss:  0.49019295 Validation Decoder Loss:  1.1565081
Encoder Loss:  0.16022258  || Decoder Loss:  0.48945752 Validation Decoder Loss:  1.1079191
Encoder Loss:  0.15505032  || Decoder Loss:  0.48784378 Validation Decoder Loss:  1.0219071
Encoder Loss:  0.15701503  || Decoder Loss:  0.48687366 Validation Decoder Loss:  0.98924637
Encoder Loss:  0.14972879  || Decoder Loss:  0.48642284 Validation Decoder Loss:  0.9600731
Encoder Loss:  0.15435363  || Decoder Loss:  0.48352066 Validation Decoder Loss:  0.95857596
Encoder Loss:  0.15011853  || Decoder Loss:  0.48690534 Validation Decoder Loss:  0.9064604
Encoder Loss:  0.14755207  || Decoder Loss:  0.48419884 Validation Decoder Loss:  0.9292628
Encoder Loss:  0.14869538  || Decoder Loss:  0.4854807 Validation Decoder Loss:  0.89832497
Encoder Loss:  0.14865111  || Decoder Loss:  0.48352432 Validation Decoder Loss:  0.8925381
Encoder Loss:  0.14892358  || Decoder Loss:  0.48405686 Validation Decoder Loss:  0.8811281
Encoder Loss:  0.14881422  || Decoder Loss:  0.48453438 Validation Decoder Loss:  0.85147274
Encoder Loss:  0.14697708  || Decoder Loss:  0.47922024 Validation Decoder Loss:  0.8011739
Encoder Loss:  0.1467313  || Decoder Loss:  0.47050855 Validation Decoder Loss:  0.87726045
Encoder Loss:  0.15868078  || Decoder Loss:  0.4837121 Validation Decoder Loss:  0.82773805
Encoder Loss:  0.15382975  || Decoder Loss:  0.4875861 Validation Decoder Loss:  0.7835332
Encoder Loss:  0.14798242  || Decoder Loss:  0.4844607 Validation Decoder Loss:  0.7942796
Encoder Loss:  0.14624873  || Decoder Loss:  0.4853743 Validation Decoder Loss:  0.815752
Encoder Loss:  0.151465  || Decoder Loss:  0.47977948 Validation Decoder Loss:  0.8474982
Encoder Loss:  0.14997654  || Decoder Loss:  0.48560643 Validation Decoder Loss:  0.81373024
Encoder Loss:  0.14766382  || Decoder Loss:  0.48438132 Validation Decoder Loss:  0.83081865
Encoder Loss:  0.14920658  || Decoder Loss:  0.48366538 Validation Decoder Loss:  0.8653719
Encoder Loss:  0.14777717  || Decoder Loss:  0.48242435 Validation Decoder Loss:  0.8262535
Encoder Loss:  0.14873946  || Decoder Loss:  0.4830502 Validation Decoder Loss:  0.8223979
Encoder Loss:  0.14879307  || Decoder Loss:  0.48194435 Validation Decoder Loss:  0.86456347
Encoder Loss:  0.14722058  || Decoder Loss:  0.48221886 Validation Decoder Loss:  0.895985
Encoder Loss:  0.14739136  || Decoder Loss:  0.4819915 Validation Decoder Loss:  0.8225729
Encoder Loss:  0.15356131  || Decoder Loss:  0.4767679 Validation Decoder Loss:  0.7936518
Encoder Loss:  0.15009566  || Decoder Loss:  0.48375997 Validation Decoder Loss:  0.8794523
Encoder Loss:  0.14875792  || Decoder Loss:  0.48338738 Validation Decoder Loss:  0.8928338
Encoder Loss:  0.14759678  || Decoder Loss:  0.4799604 Validation Decoder Loss:  0.83922625
Encoder Loss:  0.15057981  || Decoder Loss:  0.48085994 Validation Decoder Loss:  0.7783503
Model: siamese_net_lr_0.019053971110413674 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7783503
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_236 (Conv3D (None, 170, 5, 20, 1)     108       
_________________________________________________________________
dropout_501 (Dropout)        (None, 170, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_237 (Conv3D (None, 184, 5, 20, 1)     16        
_________________________________________________________________
reshape_149 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 2200, 20, 1)       1047      
_________________________________________________________________
dropout_503 (Dropout)        (None, 2200, 20, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 920, 20, 1)        363       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 2300, 20, 1)       1382      
_________________________________________________________________
dropout_505 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 3245, 20, 1)       947       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4237547  || Decoder Loss:  0.4387557 Validation Decoder Loss:  1.6236374
Encoder Loss:  0.77597433  || Decoder Loss:  0.8729474 Validation Decoder Loss:  1.6114385
Encoder Loss:  0.7621673  || Decoder Loss:  0.8610196 Validation Decoder Loss:  1.5924675
Encoder Loss:  0.7462155  || Decoder Loss:  0.8409791 Validation Decoder Loss:  1.558632
Encoder Loss:  0.51373935  || Decoder Loss:  0.58540595 Validation Decoder Loss:  1.2962568
Encoder Loss:  0.41861558  || Decoder Loss:  0.507295 Validation Decoder Loss:  0.9802707
Encoder Loss:  0.4123934  || Decoder Loss:  0.50128895 Validation Decoder Loss:  0.8093778
Encoder Loss:  0.41838318  || Decoder Loss:  0.50825876 Validation Decoder Loss:  0.8694079
Encoder Loss:  0.41033757  || Decoder Loss:  0.49985301 Validation Decoder Loss:  0.7983464
Encoder Loss:  0.42050254  || Decoder Loss:  0.51258594 Validation Decoder Loss:  0.74433446
Encoder Loss:  0.41805026  || Decoder Loss:  0.5102729 Validation Decoder Loss:  0.9327078
Encoder Loss:  0.41912642  || Decoder Loss:  0.5120928 Validation Decoder Loss:  0.8874954
Encoder Loss:  0.43501565  || Decoder Loss:  0.5326666 Validation Decoder Loss:  0.919857
Encoder Loss:  0.42159262  || Decoder Loss:  0.5159518 Validation Decoder Loss:  0.9970612
Encoder Loss:  0.40991324  || Decoder Loss:  0.50126094 Validation Decoder Loss:  1.035814
Encoder Loss:  0.43831864  || Decoder Loss:  0.5398726 Validation Decoder Loss:  1.0118481
Encoder Loss:  0.42265233  || Decoder Loss:  0.52042246 Validation Decoder Loss:  0.9446144
Encoder Loss:  0.39760372  || Decoder Loss:  0.48758507 Validation Decoder Loss:  0.87694836
Encoder Loss:  0.38699028  || Decoder Loss:  0.47617984 Validation Decoder Loss:  0.6923014
Encoder Loss:  0.37029663  || Decoder Loss:  0.4515295 Validation Decoder Loss:  1.1427873
Encoder Loss:  0.3730553  || Decoder Loss:  0.45675677 Validation Decoder Loss:  0.8628564
Encoder Loss:  0.34493145  || Decoder Loss:  0.42167053 Validation Decoder Loss:  0.4514755
Encoder Loss:  0.35290882  || Decoder Loss:  0.42931655 Validation Decoder Loss:  0.6741337
Encoder Loss:  0.36423945  || Decoder Loss:  0.44714957 Validation Decoder Loss:  0.47793275
Encoder Loss:  0.35270488  || Decoder Loss:  0.43008277 Validation Decoder Loss:  1.475465
Encoder Loss:  0.38278034  || Decoder Loss:  0.46679252 Validation Decoder Loss:  0.9279473
Encoder Loss:  0.33083358  || Decoder Loss:  0.40405807 Validation Decoder Loss:  0.59426546
Encoder Loss:  0.31366605  || Decoder Loss:  0.38439983 Validation Decoder Loss:  0.81893766
Encoder Loss:  0.3463499  || Decoder Loss:  0.42478356 Validation Decoder Loss:  0.4381773
Encoder Loss:  0.33530945  || Decoder Loss:  0.41062516 Validation Decoder Loss:  0.67461
Encoder Loss:  0.3072404  || Decoder Loss:  0.3735135 Validation Decoder Loss:  0.65527886
Encoder Loss:  0.35017213  || Decoder Loss:  0.42872116 Validation Decoder Loss:  0.8661435
Encoder Loss:  0.3413049  || Decoder Loss:  0.4164283 Validation Decoder Loss:  0.66982114
Encoder Loss:  0.2869526  || Decoder Loss:  0.34805238 Validation Decoder Loss:  0.62086093
Encoder Loss:  0.30699405  || Decoder Loss:  0.37531227 Validation Decoder Loss:  0.4277388
Encoder Loss:  0.3210771  || Decoder Loss:  0.3920787 Validation Decoder Loss:  0.40542525
Encoder Loss:  0.3697591  || Decoder Loss:  0.45248613 Validation Decoder Loss:  0.56114703
Encoder Loss:  0.32981476  || Decoder Loss:  0.40320855 Validation Decoder Loss:  0.4712191
Encoder Loss:  0.30495626  || Decoder Loss:  0.37178668 Validation Decoder Loss:  0.57478166
Encoder Loss:  0.2830626  || Decoder Loss:  0.3450794 Validation Decoder Loss:  0.513693
Model: siamese_net_lr_0.03956159268154324 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.513693
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_239 (Conv3D (None, 154, 5, 20, 1)     29        
_________________________________________________________________
dropout_507 (Dropout)        (None, 154, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_240 (Conv3D (None, 184, 5, 20, 1)     32        
_________________________________________________________________
reshape_150 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 2760, 20, 1)       487       
_________________________________________________________________
dropout_509 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 920, 20, 1)        1842      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 950, 20, 1)        32        
_________________________________________________________________
dropout_511 (Dropout)        (None, 950, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 3245, 20, 1)       1348      
=================================================================
Total params: 1,380
Trainable params: 1,380
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36614338  || Decoder Loss:  0.33328468 Validation Decoder Loss:  0.30238447
Encoder Loss:  0.42411003  || Decoder Loss:  0.555739 Validation Decoder Loss:  1.565714
Encoder Loss:  0.53437066  || Decoder Loss:  0.88212556 Validation Decoder Loss:  1.5196846
Encoder Loss:  0.35939488  || Decoder Loss:  0.552166 Validation Decoder Loss:  0.8716697
Encoder Loss:  0.2089584  || Decoder Loss:  0.53730863 Validation Decoder Loss:  0.45892793
Encoder Loss:  0.19086617  || Decoder Loss:  0.5014558 Validation Decoder Loss:  0.8414179
Encoder Loss:  0.21069542  || Decoder Loss:  0.50869846 Validation Decoder Loss:  0.4992332
Encoder Loss:  0.20007916  || Decoder Loss:  0.50038517 Validation Decoder Loss:  0.65009475
Encoder Loss:  0.18520628  || Decoder Loss:  0.4966176 Validation Decoder Loss:  0.6817057
Encoder Loss:  0.18302493  || Decoder Loss:  0.4948246 Validation Decoder Loss:  0.651067
Encoder Loss:  0.18975395  || Decoder Loss:  0.48428237 Validation Decoder Loss:  0.6488773
Encoder Loss:  0.19214146  || Decoder Loss:  0.50135875 Validation Decoder Loss:  0.6011833
Encoder Loss:  0.17888868  || Decoder Loss:  0.4854458 Validation Decoder Loss:  0.6553364
Encoder Loss:  0.17734246  || Decoder Loss:  0.48182976 Validation Decoder Loss:  0.5770395
Encoder Loss:  0.18998623  || Decoder Loss:  0.48841536 Validation Decoder Loss:  0.6730982
Encoder Loss:  0.17718644  || Decoder Loss:  0.4840524 Validation Decoder Loss:  0.65735096
Encoder Loss:  0.1780722  || Decoder Loss:  0.48112732 Validation Decoder Loss:  0.6468262
Encoder Loss:  0.17849186  || Decoder Loss:  0.48408708 Validation Decoder Loss:  0.7097958
Encoder Loss:  0.17530109  || Decoder Loss:  0.48085785 Validation Decoder Loss:  0.74856853
Encoder Loss:  0.18013868  || Decoder Loss:  0.47991 Validation Decoder Loss:  0.7024358
Encoder Loss:  0.18630527  || Decoder Loss:  0.47737187 Validation Decoder Loss:  0.7279348
Encoder Loss:  0.17880821  || Decoder Loss:  0.48170775 Validation Decoder Loss:  0.7419284
Encoder Loss:  0.17820717  || Decoder Loss:  0.48143494 Validation Decoder Loss:  0.7826305
Encoder Loss:  0.1740185  || Decoder Loss:  0.48027697 Validation Decoder Loss:  0.8249308
Encoder Loss:  0.17368355  || Decoder Loss:  0.47931224 Validation Decoder Loss:  0.85133374
Encoder Loss:  0.17581743  || Decoder Loss:  0.47829163 Validation Decoder Loss:  0.8825386
Encoder Loss:  0.17163059  || Decoder Loss:  0.4781183 Validation Decoder Loss:  0.9258276
Encoder Loss:  0.17512082  || Decoder Loss:  0.47840536 Validation Decoder Loss:  0.91705513
Encoder Loss:  0.18169564  || Decoder Loss:  0.4787087 Validation Decoder Loss:  0.8994322
Encoder Loss:  0.18573171  || Decoder Loss:  0.4791906 Validation Decoder Loss:  0.84831417
Encoder Loss:  0.19335298  || Decoder Loss:  0.48250234 Validation Decoder Loss:  0.84906614
Encoder Loss:  0.17999206  || Decoder Loss:  0.47828197 Validation Decoder Loss:  0.86518204
Encoder Loss:  0.17521363  || Decoder Loss:  0.47798702 Validation Decoder Loss:  0.87317073
Encoder Loss:  0.17536244  || Decoder Loss:  0.4779408 Validation Decoder Loss:  0.88419545
Encoder Loss:  0.17133933  || Decoder Loss:  0.47768474 Validation Decoder Loss:  0.88584185
Encoder Loss:  0.17058735  || Decoder Loss:  0.4774005 Validation Decoder Loss:  0.90768605
Encoder Loss:  0.17541763  || Decoder Loss:  0.4771798 Validation Decoder Loss:  0.8890595
Encoder Loss:  0.17392963  || Decoder Loss:  0.47700706 Validation Decoder Loss:  0.9131374
Encoder Loss:  0.17039073  || Decoder Loss:  0.47699174 Validation Decoder Loss:  0.91962326
Encoder Loss:  0.16949198  || Decoder Loss:  0.47615397 Validation Decoder Loss:  0.9012898
Model: siamese_net_lr_0.03725077243227936 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9012898
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_242 (Conv3D (None, 80, 5, 20, 1)      18        
_________________________________________________________________
dropout_513 (Dropout)        (None, 80, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_243 (Conv3D (None, 184, 5, 20, 1)     106       
_________________________________________________________________
reshape_151 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_500"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 1950, 20, 1)       1297      
_________________________________________________________________
dropout_515 (Dropout)        (None, 1950, 20, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 920, 20, 1)        1032      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 3100, 20, 1)       344       
_________________________________________________________________
dropout_517 (Dropout)        (None, 3100, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 3245, 20, 1)       147       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07853096  || Decoder Loss:  0.05401553 Validation Decoder Loss:  0.34581143
Encoder Loss:  0.06953282  || Decoder Loss:  0.03271857 Validation Decoder Loss:  0.34495965
Encoder Loss:  0.0638083  || Decoder Loss:  0.032532815 Validation Decoder Loss:  0.34631208
Encoder Loss:  0.052606985  || Decoder Loss:  0.03241769 Validation Decoder Loss:  0.34608912
Encoder Loss:  0.053413812  || Decoder Loss:  0.03226064 Validation Decoder Loss:  0.3460995
Encoder Loss:  0.047681786  || Decoder Loss:  0.032163247 Validation Decoder Loss:  0.34601226
Encoder Loss:  0.04760314  || Decoder Loss:  0.03204982 Validation Decoder Loss:  0.34591776
Encoder Loss:  0.052016646  || Decoder Loss:  0.031979136 Validation Decoder Loss:  0.34624717
Encoder Loss:  0.046297647  || Decoder Loss:  0.03189495 Validation Decoder Loss:  0.34597325
Encoder Loss:  0.050638076  || Decoder Loss:  0.031818386 Validation Decoder Loss:  0.34597063
Encoder Loss:  0.046307024  || Decoder Loss:  0.03178887 Validation Decoder Loss:  0.34603304
Encoder Loss:  0.052464414  || Decoder Loss:  0.031700872 Validation Decoder Loss:  0.34553808
Encoder Loss:  0.04859792  || Decoder Loss:  0.031656016 Validation Decoder Loss:  0.3455809
Encoder Loss:  0.044656463  || Decoder Loss:  0.031565413 Validation Decoder Loss:  0.3456007
Encoder Loss:  0.044368397  || Decoder Loss:  0.031522322 Validation Decoder Loss:  0.3457889
Encoder Loss:  0.04416331  || Decoder Loss:  0.031472288 Validation Decoder Loss:  0.34572554
Encoder Loss:  0.044512358  || Decoder Loss:  0.031423442 Validation Decoder Loss:  0.34594887
Encoder Loss:  0.049494807  || Decoder Loss:  0.0313808 Validation Decoder Loss:  0.34618443
Encoder Loss:  0.045189604  || Decoder Loss:  0.031360123 Validation Decoder Loss:  0.34512457
Encoder Loss:  0.048271805  || Decoder Loss:  0.031309437 Validation Decoder Loss:  0.3451081
Encoder Loss:  0.04424976  || Decoder Loss:  0.031264544 Validation Decoder Loss:  0.34534258
Encoder Loss:  0.04749119  || Decoder Loss:  0.03127275 Validation Decoder Loss:  0.34594467
Encoder Loss:  0.044399943  || Decoder Loss:  0.031268183 Validation Decoder Loss:  0.34497163
Encoder Loss:  0.04642781  || Decoder Loss:  0.031198801 Validation Decoder Loss:  0.34531662
Encoder Loss:  0.04326375  || Decoder Loss:  0.031156728 Validation Decoder Loss:  0.34522218
Encoder Loss:  0.04356549  || Decoder Loss:  0.031160858 Validation Decoder Loss:  0.34535637
Encoder Loss:  0.044157963  || Decoder Loss:  0.031141259 Validation Decoder Loss:  0.3451332
Encoder Loss:  0.04350101  || Decoder Loss:  0.031124458 Validation Decoder Loss:  0.34527004
Encoder Loss:  0.043324724  || Decoder Loss:  0.03110994 Validation Decoder Loss:  0.34515983
Encoder Loss:  0.042981602  || Decoder Loss:  0.031096214 Validation Decoder Loss:  0.34539688
Encoder Loss:  0.04307514  || Decoder Loss:  0.031083105 Validation Decoder Loss:  0.34510237
Encoder Loss:  0.043502416  || Decoder Loss:  0.031073194 Validation Decoder Loss:  0.34510684
Encoder Loss:  0.043757815  || Decoder Loss:  0.031058183 Validation Decoder Loss:  0.34505442
Encoder Loss:  0.04371989  || Decoder Loss:  0.031046895 Validation Decoder Loss:  0.34501794
Encoder Loss:  0.04368005  || Decoder Loss:  0.031039672 Validation Decoder Loss:  0.34491023
Encoder Loss:  0.042221025  || Decoder Loss:  0.031021781 Validation Decoder Loss:  0.34488612
Encoder Loss:  0.04348998  || Decoder Loss:  0.031010948 Validation Decoder Loss:  0.3449412
Encoder Loss:  0.042689275  || Decoder Loss:  0.030994423 Validation Decoder Loss:  0.34480128
Encoder Loss:  0.042848814  || Decoder Loss:  0.030982735 Validation Decoder Loss:  0.34483317
Encoder Loss:  0.04314605  || Decoder Loss:  0.03097543 Validation Decoder Loss:  0.3443457
Model: siamese_net_lr_0.0016321198574880996 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3443457
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_245 (Conv3D (None, 150, 5, 20, 1)     88        
_________________________________________________________________
dropout_519 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_246 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_152 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 2770, 20, 1)       477       
_________________________________________________________________
dropout_521 (Dropout)        (None, 2770, 20, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 920, 20, 1)        14        
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 940, 20, 1)        22        
_________________________________________________________________
dropout_523 (Dropout)        (None, 940, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 3245, 20, 1)       2307      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42032355  || Decoder Loss:  0.42892155 Validation Decoder Loss:  1.6240876
Encoder Loss:  0.66569704  || Decoder Loss:  0.9252371 Validation Decoder Loss:  1.469247
Encoder Loss:  0.46968755  || Decoder Loss:  0.52473664 Validation Decoder Loss:  0.49515525
Encoder Loss:  0.2729793  || Decoder Loss:  0.1438801 Validation Decoder Loss:  0.36799225
Encoder Loss:  0.23585744  || Decoder Loss:  0.0899042 Validation Decoder Loss:  0.28486174
Encoder Loss:  0.44202808  || Decoder Loss:  0.6476886 Validation Decoder Loss:  0.9460605
Encoder Loss:  0.3151456  || Decoder Loss:  0.5491445 Validation Decoder Loss:  0.64103913
Encoder Loss:  0.30065516  || Decoder Loss:  0.5285574 Validation Decoder Loss:  0.72726786
Encoder Loss:  0.2958833  || Decoder Loss:  0.5245304 Validation Decoder Loss:  0.7631592
Encoder Loss:  0.2895531  || Decoder Loss:  0.51650596 Validation Decoder Loss:  0.824752
Encoder Loss:  0.2865578  || Decoder Loss:  0.5097906 Validation Decoder Loss:  0.8472214
Encoder Loss:  0.28295118  || Decoder Loss:  0.5028047 Validation Decoder Loss:  0.8571708
Encoder Loss:  0.28161362  || Decoder Loss:  0.5001197 Validation Decoder Loss:  0.83943945
Encoder Loss:  0.28036332  || Decoder Loss:  0.49817258 Validation Decoder Loss:  0.87311995
Encoder Loss:  0.27848494  || Decoder Loss:  0.49635276 Validation Decoder Loss:  0.8789941
Encoder Loss:  0.27707887  || Decoder Loss:  0.49289733 Validation Decoder Loss:  0.88829327
Encoder Loss:  0.27613997  || Decoder Loss:  0.49207097 Validation Decoder Loss:  0.891441
Encoder Loss:  0.27524024  || Decoder Loss:  0.48951408 Validation Decoder Loss:  0.90267545
Encoder Loss:  0.27445754  || Decoder Loss:  0.48909912 Validation Decoder Loss:  0.9003341
Encoder Loss:  0.27393493  || Decoder Loss:  0.4873126 Validation Decoder Loss:  0.91022444
Encoder Loss:  0.27333498  || Decoder Loss:  0.48648995 Validation Decoder Loss:  0.91921663
Encoder Loss:  0.27202806  || Decoder Loss:  0.48533034 Validation Decoder Loss:  0.9205377
Encoder Loss:  0.2718145  || Decoder Loss:  0.4839076 Validation Decoder Loss:  0.9238367
Encoder Loss:  0.27131554  || Decoder Loss:  0.48293713 Validation Decoder Loss:  0.93210393
Encoder Loss:  0.27044693  || Decoder Loss:  0.48189393 Validation Decoder Loss:  0.93872935
Encoder Loss:  0.2703003  || Decoder Loss:  0.48075417 Validation Decoder Loss:  0.94528985
Encoder Loss:  0.26929614  || Decoder Loss:  0.47986397 Validation Decoder Loss:  0.9483101
Encoder Loss:  0.26892215  || Decoder Loss:  0.4786888 Validation Decoder Loss:  0.95759815
Encoder Loss:  0.2684424  || Decoder Loss:  0.47786546 Validation Decoder Loss:  0.9652072
Encoder Loss:  0.26716623  || Decoder Loss:  0.47615042 Validation Decoder Loss:  0.9708861
Encoder Loss:  0.2669674  || Decoder Loss:  0.47493467 Validation Decoder Loss:  0.97991127
Encoder Loss:  0.26631823  || Decoder Loss:  0.4738843 Validation Decoder Loss:  0.9882297
Encoder Loss:  0.2655157  || Decoder Loss:  0.47242755 Validation Decoder Loss:  0.99760425
Encoder Loss:  0.26426563  || Decoder Loss:  0.47046146 Validation Decoder Loss:  1.0110544
Encoder Loss:  0.26386818  || Decoder Loss:  0.4695428 Validation Decoder Loss:  1.0231729
Encoder Loss:  0.26251602  || Decoder Loss:  0.4670123 Validation Decoder Loss:  1.0398388
Encoder Loss:  0.26128244  || Decoder Loss:  0.46454275 Validation Decoder Loss:  1.0588931
Encoder Loss:  0.25956163  || Decoder Loss:  0.46124068 Validation Decoder Loss:  1.0841867
Encoder Loss:  0.25667262  || Decoder Loss:  0.45556706 Validation Decoder Loss:  1.1250286
Encoder Loss:  0.25351876  || Decoder Loss:  0.44940364 Validation Decoder Loss:  1.1834736
Model: siamese_net_lr_0.08489172470673874 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1834736
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_248 (Conv3D (None, 168, 5, 20, 1)     106       
_________________________________________________________________
dropout_525 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_249 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_153 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 1820, 20, 1)       1427      
_________________________________________________________________
dropout_527 (Dropout)        (None, 1820, 20, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 920, 20, 1)        902       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 2520, 20, 1)       1602      
_________________________________________________________________
dropout_529 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 3245, 20, 1)       727       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.55150336  || Decoder Loss:  0.77401143 Validation Decoder Loss:  0.27985144
Encoder Loss:  0.41412094  || Decoder Loss:  0.5576327 Validation Decoder Loss:  1.5777614
Encoder Loss:  0.44778562  || Decoder Loss:  0.6596518 Validation Decoder Loss:  1.6986027
Encoder Loss:  0.28501976  || Decoder Loss:  0.42889294 Validation Decoder Loss:  1.3218293
Encoder Loss:  0.27915084  || Decoder Loss:  0.4950833 Validation Decoder Loss:  1.7103231
Encoder Loss:  0.3075209  || Decoder Loss:  0.45368522 Validation Decoder Loss:  0.79644644
Encoder Loss:  0.28212324  || Decoder Loss:  0.48022288 Validation Decoder Loss:  1.0406452
Encoder Loss:  0.2581242  || Decoder Loss:  0.46352467 Validation Decoder Loss:  1.5246265
Encoder Loss:  0.2548431  || Decoder Loss:  0.4853843 Validation Decoder Loss:  1.4864967
Encoder Loss:  0.24974264  || Decoder Loss:  0.4745944 Validation Decoder Loss:  1.412991
Encoder Loss:  0.24455056  || Decoder Loss:  0.46582055 Validation Decoder Loss:  1.2979685
Encoder Loss:  0.24591428  || Decoder Loss:  0.46816987 Validation Decoder Loss:  1.2503948
Encoder Loss:  0.24479485  || Decoder Loss:  0.45489287 Validation Decoder Loss:  1.3628912
Encoder Loss:  0.21798964  || Decoder Loss:  0.40312997 Validation Decoder Loss:  0.77941155
Encoder Loss:  0.20881373  || Decoder Loss:  0.38752088 Validation Decoder Loss:  1.1708555
Encoder Loss:  0.20090146  || Decoder Loss:  0.3641024 Validation Decoder Loss:  0.66591257
Encoder Loss:  0.24665023  || Decoder Loss:  0.46982354 Validation Decoder Loss:  0.69728553
Encoder Loss:  0.24874106  || Decoder Loss:  0.48044083 Validation Decoder Loss:  0.6286247
Encoder Loss:  0.2511359  || Decoder Loss:  0.4797472 Validation Decoder Loss:  0.76402056
Encoder Loss:  0.25098068  || Decoder Loss:  0.47513264 Validation Decoder Loss:  0.91754925
Encoder Loss:  0.2451095  || Decoder Loss:  0.4665461 Validation Decoder Loss:  0.7887211
Encoder Loss:  0.21469314  || Decoder Loss:  0.40001714 Validation Decoder Loss:  0.6870569
Encoder Loss:  0.19069724  || Decoder Loss:  0.35132867 Validation Decoder Loss:  0.6527668
Encoder Loss:  0.249896  || Decoder Loss:  0.46511775 Validation Decoder Loss:  1.1304605
Encoder Loss:  0.20401458  || Decoder Loss:  0.37361413 Validation Decoder Loss:  0.3922484
Encoder Loss:  0.17521495  || Decoder Loss:  0.31176353 Validation Decoder Loss:  0.4023981
Encoder Loss:  0.15959479  || Decoder Loss:  0.28293842 Validation Decoder Loss:  0.8994613
Encoder Loss:  0.1784559  || Decoder Loss:  0.3236871 Validation Decoder Loss:  0.6992418
Encoder Loss:  0.18041848  || Decoder Loss:  0.31576902 Validation Decoder Loss:  0.7762302
Encoder Loss:  0.13643904  || Decoder Loss:  0.22782293 Validation Decoder Loss:  0.37631327
Encoder Loss:  0.1476422  || Decoder Loss:  0.25263634 Validation Decoder Loss:  0.7878406
Encoder Loss:  0.1378241  || Decoder Loss:  0.23714241 Validation Decoder Loss:  0.62443006
Encoder Loss:  0.11581904  || Decoder Loss:  0.184484 Validation Decoder Loss:  0.26952842
Encoder Loss:  0.13813584  || Decoder Loss:  0.22978224 Validation Decoder Loss:  0.50818884
Encoder Loss:  0.079422414  || Decoder Loss:  0.10931922 Validation Decoder Loss:  0.4863132
Encoder Loss:  0.059971776  || Decoder Loss:  0.060841285 Validation Decoder Loss:  0.38028312
Encoder Loss:  0.05641587  || Decoder Loss:  0.05590822 Validation Decoder Loss:  0.34184945
Encoder Loss:  0.054564055  || Decoder Loss:  0.054190774 Validation Decoder Loss:  0.3503524
Encoder Loss:  0.05324409  || Decoder Loss:  0.051163305 Validation Decoder Loss:  0.42300278
Encoder Loss:  0.052155863  || Decoder Loss:  0.05000732 Validation Decoder Loss:  0.31663585
Model: siamese_net_lr_0.026980063038611245 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31663585
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_251 (Conv3D (None, 144, 5, 20, 1)     19        
_________________________________________________________________
dropout_531 (Dropout)        (None, 144, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_252 (Conv3D (None, 184, 5, 20, 1)     42        
_________________________________________________________________
reshape_154 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_512"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 2760, 20, 1)       487       
_________________________________________________________________
dropout_533 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 920, 20, 1)        1842      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 1010, 20, 1)       92        
_________________________________________________________________
dropout_535 (Dropout)        (None, 1010, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 3245, 20, 1)       1228      
=================================================================
Total params: 1,320
Trainable params: 1,320
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30632922  || Decoder Loss:  0.16485317 Validation Decoder Loss:  0.37610838
Encoder Loss:  0.29691026  || Decoder Loss:  0.11874914 Validation Decoder Loss:  0.37247115
Encoder Loss:  0.29532382  || Decoder Loss:  0.11706649 Validation Decoder Loss:  0.36784798
Encoder Loss:  0.29272717  || Decoder Loss:  0.11543985 Validation Decoder Loss:  0.36174005
Encoder Loss:  0.2861825  || Decoder Loss:  0.11547256 Validation Decoder Loss:  0.3465554
Encoder Loss:  0.28984722  || Decoder Loss:  0.37298012 Validation Decoder Loss:  1.3348727
Encoder Loss:  0.27998176  || Decoder Loss:  0.4923309 Validation Decoder Loss:  1.5564579
Encoder Loss:  0.2642066  || Decoder Loss:  0.51758665 Validation Decoder Loss:  1.4140348
Encoder Loss:  0.23449653  || Decoder Loss:  0.49220026 Validation Decoder Loss:  1.2927399
Encoder Loss:  0.24021105  || Decoder Loss:  0.4975032 Validation Decoder Loss:  1.3926115
Encoder Loss:  0.24078056  || Decoder Loss:  0.49714062 Validation Decoder Loss:  1.4099978
Encoder Loss:  0.23810722  || Decoder Loss:  0.4975646 Validation Decoder Loss:  1.3849812
Encoder Loss:  0.24257137  || Decoder Loss:  0.5054696 Validation Decoder Loss:  1.4298546
Encoder Loss:  0.24460378  || Decoder Loss:  0.49689072 Validation Decoder Loss:  1.366153
Encoder Loss:  0.23399659  || Decoder Loss:  0.4823245 Validation Decoder Loss:  1.2990594
Encoder Loss:  0.24791594  || Decoder Loss:  0.5077819 Validation Decoder Loss:  1.2648823
Encoder Loss:  0.24112968  || Decoder Loss:  0.49517563 Validation Decoder Loss:  1.1673338
Encoder Loss:  0.24692078  || Decoder Loss:  0.4918729 Validation Decoder Loss:  1.2697473
Encoder Loss:  0.23363575  || Decoder Loss:  0.49346247 Validation Decoder Loss:  1.242371
Encoder Loss:  0.23178883  || Decoder Loss:  0.4910021 Validation Decoder Loss:  1.1665052
Encoder Loss:  0.2316793  || Decoder Loss:  0.48575962 Validation Decoder Loss:  1.1799407
Encoder Loss:  0.23149478  || Decoder Loss:  0.4869546 Validation Decoder Loss:  1.1390564
Encoder Loss:  0.23058052  || Decoder Loss:  0.48573288 Validation Decoder Loss:  1.1020889
Encoder Loss:  0.23110588  || Decoder Loss:  0.48205993 Validation Decoder Loss:  1.087342
Encoder Loss:  0.23622933  || Decoder Loss:  0.48662317 Validation Decoder Loss:  1.0417141
Encoder Loss:  0.22773865  || Decoder Loss:  0.48224697 Validation Decoder Loss:  1.016085
Encoder Loss:  0.22986156  || Decoder Loss:  0.48243272 Validation Decoder Loss:  1.0047925
Encoder Loss:  0.23823215  || Decoder Loss:  0.48102465 Validation Decoder Loss:  1.0141273
Encoder Loss:  0.23229897  || Decoder Loss:  0.48258328 Validation Decoder Loss:  1.0037763
Encoder Loss:  0.22975518  || Decoder Loss:  0.48190823 Validation Decoder Loss:  0.9661392
Encoder Loss:  0.2280264  || Decoder Loss:  0.48117763 Validation Decoder Loss:  0.9509887
Encoder Loss:  0.22721443  || Decoder Loss:  0.4809119 Validation Decoder Loss:  0.92943394
Encoder Loss:  0.22676276  || Decoder Loss:  0.48046592 Validation Decoder Loss:  0.9080766
Encoder Loss:  0.2257715  || Decoder Loss:  0.480219 Validation Decoder Loss:  0.8939694
Encoder Loss:  0.22633053  || Decoder Loss:  0.4797274 Validation Decoder Loss:  0.88991505
Encoder Loss:  0.22719568  || Decoder Loss:  0.4807431 Validation Decoder Loss:  0.89162374
Encoder Loss:  0.22630379  || Decoder Loss:  0.48013383 Validation Decoder Loss:  0.8896766
Encoder Loss:  0.23009926  || Decoder Loss:  0.4799469 Validation Decoder Loss:  0.86943305
Encoder Loss:  0.22634518  || Decoder Loss:  0.47995046 Validation Decoder Loss:  0.8522149
Encoder Loss:  0.22790529  || Decoder Loss:  0.48064452 Validation Decoder Loss:  0.8684057
Model: siamese_net_lr_0.06154097794869376 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8684057
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_254 (Conv3D (None, 146, 5, 20, 1)     21        
_________________________________________________________________
dropout_537 (Dropout)        (None, 146, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_255 (Conv3D (None, 184, 5, 20, 1)     40        
_________________________________________________________________
reshape_155 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 2040, 20, 1)       1207      
_________________________________________________________________
dropout_539 (Dropout)        (None, 2040, 20, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 920, 20, 1)        203       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 1860, 20, 1)       942       
_________________________________________________________________
dropout_541 (Dropout)        (None, 1860, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 3245, 20, 1)       1387      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25564218  || Decoder Loss:  0.22479963 Validation Decoder Loss:  0.40595704
Encoder Loss:  0.2994682  || Decoder Loss:  0.31851602 Validation Decoder Loss:  0.65162295
Encoder Loss:  0.38872388  || Decoder Loss:  0.44533616 Validation Decoder Loss:  1.0096059
Encoder Loss:  0.41227174  || Decoder Loss:  0.47759506 Validation Decoder Loss:  1.656569
Encoder Loss:  0.45614558  || Decoder Loss:  0.5263627 Validation Decoder Loss:  1.5272958
Encoder Loss:  0.41269648  || Decoder Loss:  0.47789538 Validation Decoder Loss:  1.2963221
Encoder Loss:  0.4101142  || Decoder Loss:  0.47651416 Validation Decoder Loss:  1.3259162
Encoder Loss:  0.42228177  || Decoder Loss:  0.49048725 Validation Decoder Loss:  1.3833045
Encoder Loss:  0.41632146  || Decoder Loss:  0.48413098 Validation Decoder Loss:  1.1793902
Encoder Loss:  0.40229198  || Decoder Loss:  0.4693522 Validation Decoder Loss:  1.3370082
Encoder Loss:  0.4064857  || Decoder Loss:  0.4752016 Validation Decoder Loss:  1.2422149
Encoder Loss:  0.41293064  || Decoder Loss:  0.48236278 Validation Decoder Loss:  1.2085602
Encoder Loss:  0.40439987  || Decoder Loss:  0.47184074 Validation Decoder Loss:  1.3059491
Encoder Loss:  0.40997955  || Decoder Loss:  0.47785133 Validation Decoder Loss:  1.2565494
Encoder Loss:  0.39822978  || Decoder Loss:  0.46431214 Validation Decoder Loss:  1.3651751
Encoder Loss:  0.3834145  || Decoder Loss:  0.44761458 Validation Decoder Loss:  1.1792831
Encoder Loss:  0.3728283  || Decoder Loss:  0.43335748 Validation Decoder Loss:  1.3863411
Encoder Loss:  0.3974625  || Decoder Loss:  0.45951518 Validation Decoder Loss:  1.2376596
Encoder Loss:  0.3731176  || Decoder Loss:  0.43180874 Validation Decoder Loss:  0.9540796
Encoder Loss:  0.3798133  || Decoder Loss:  0.44107196 Validation Decoder Loss:  1.1331491
Encoder Loss:  0.3701296  || Decoder Loss:  0.43148467 Validation Decoder Loss:  1.0853934
Encoder Loss:  0.37900296  || Decoder Loss:  0.43952742 Validation Decoder Loss:  1.2397726
Encoder Loss:  0.37207097  || Decoder Loss:  0.43349376 Validation Decoder Loss:  1.1796234
Encoder Loss:  0.3707944  || Decoder Loss:  0.43210682 Validation Decoder Loss:  1.1676784
Encoder Loss:  0.3696845  || Decoder Loss:  0.43083176 Validation Decoder Loss:  0.9581448
Encoder Loss:  0.36486596  || Decoder Loss:  0.4247498 Validation Decoder Loss:  1.0483693
Encoder Loss:  0.37076837  || Decoder Loss:  0.43146136 Validation Decoder Loss:  1.2859153
Encoder Loss:  0.36978582  || Decoder Loss:  0.4312677 Validation Decoder Loss:  1.0731528
Encoder Loss:  0.37502158  || Decoder Loss:  0.43722412 Validation Decoder Loss:  1.0026864
Encoder Loss:  0.36195275  || Decoder Loss:  0.42168632 Validation Decoder Loss:  1.3348225
Encoder Loss:  0.35898307  || Decoder Loss:  0.4176751 Validation Decoder Loss:  1.1161804
Encoder Loss:  0.37481803  || Decoder Loss:  0.43633094 Validation Decoder Loss:  0.60332143
Encoder Loss:  0.417643  || Decoder Loss:  0.48823652 Validation Decoder Loss:  0.6596886
Encoder Loss:  0.42380106  || Decoder Loss:  0.49537528 Validation Decoder Loss:  0.76606125
Encoder Loss:  0.37566835  || Decoder Loss:  0.43806732 Validation Decoder Loss:  1.0774735
Encoder Loss:  0.33488378  || Decoder Loss:  0.38932884 Validation Decoder Loss:  1.2995394
Encoder Loss:  0.34589282  || Decoder Loss:  0.4028146 Validation Decoder Loss:  0.84499216
Encoder Loss:  0.346868  || Decoder Loss:  0.40274426 Validation Decoder Loss:  0.6951313
Encoder Loss:  0.34996483  || Decoder Loss:  0.4069643 Validation Decoder Loss:  1.342428
Encoder Loss:  0.31677276  || Decoder Loss:  0.36719313 Validation Decoder Loss:  1.3442683
Model: siamese_net_lr_0.05834260721119131 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.3442683
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_257 (Conv3D (None, 176, 5, 20, 1)     51        
_________________________________________________________________
dropout_543 (Dropout)        (None, 176, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_258 (Conv3D (None, 184, 5, 20, 1)     10        
_________________________________________________________________
reshape_156 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 2210, 20, 1)       1037      
_________________________________________________________________
dropout_545 (Dropout)        (None, 2210, 20, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 920, 20, 1)        373       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 2290, 20, 1)       1372      
_________________________________________________________________
dropout_547 (Dropout)        (None, 2290, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 3245, 20, 1)       957       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3508575  || Decoder Loss:  0.56120783 Validation Decoder Loss:  0.46089712
Encoder Loss:  0.17962772  || Decoder Loss:  0.4394928 Validation Decoder Loss:  1.6760769
Encoder Loss:  0.18660286  || Decoder Loss:  0.6287697 Validation Decoder Loss:  1.6604629
Encoder Loss:  0.12316907  || Decoder Loss:  0.36420414 Validation Decoder Loss:  0.41629976
Encoder Loss:  0.108573616  || Decoder Loss:  0.29812512 Validation Decoder Loss:  0.38871855
Encoder Loss:  0.054484047  || Decoder Loss:  0.059645105 Validation Decoder Loss:  0.36741048
Encoder Loss:  0.055939533  || Decoder Loss:  0.061640892 Validation Decoder Loss:  0.3728655
Encoder Loss:  0.054972757  || Decoder Loss:  0.06021672 Validation Decoder Loss:  0.3577342
Encoder Loss:  0.054812737  || Decoder Loss:  0.060484715 Validation Decoder Loss:  0.35886532
Encoder Loss:  0.054094806  || Decoder Loss:  0.05559976 Validation Decoder Loss:  0.3571128
Encoder Loss:  0.057291664  || Decoder Loss:  0.06125961 Validation Decoder Loss:  0.35149246
Encoder Loss:  0.054004706  || Decoder Loss:  0.05617928 Validation Decoder Loss:  0.34918737
Encoder Loss:  0.052635342  || Decoder Loss:  0.056574836 Validation Decoder Loss:  0.3476117
Encoder Loss:  0.05368072  || Decoder Loss:  0.057457317 Validation Decoder Loss:  0.35918516
Encoder Loss:  0.05268375  || Decoder Loss:  0.05488884 Validation Decoder Loss:  0.3491309
Encoder Loss:  0.05258524  || Decoder Loss:  0.055398684 Validation Decoder Loss:  0.34045792
Encoder Loss:  0.053406175  || Decoder Loss:  0.056363117 Validation Decoder Loss:  0.46332598
Encoder Loss:  0.05983521  || Decoder Loss:  0.067276515 Validation Decoder Loss:  0.34863067
Encoder Loss:  0.056919705  || Decoder Loss:  0.063818686 Validation Decoder Loss:  0.34682542
Encoder Loss:  0.054603454  || Decoder Loss:  0.05418033 Validation Decoder Loss:  0.34392074
Encoder Loss:  0.053311147  || Decoder Loss:  0.056280952 Validation Decoder Loss:  0.3355284
Encoder Loss:  0.051836148  || Decoder Loss:  0.053899217 Validation Decoder Loss:  0.33632946
Encoder Loss:  0.052067515  || Decoder Loss:  0.05505288 Validation Decoder Loss:  0.33814442
Encoder Loss:  0.05257061  || Decoder Loss:  0.054144192 Validation Decoder Loss:  0.32483116
Encoder Loss:  0.0522912  || Decoder Loss:  0.054299127 Validation Decoder Loss:  0.34019348
Encoder Loss:  0.052009203  || Decoder Loss:  0.05350201 Validation Decoder Loss:  0.35260367
Encoder Loss:  0.052613452  || Decoder Loss:  0.055307195 Validation Decoder Loss:  0.3196152
Encoder Loss:  0.052777126  || Decoder Loss:  0.051452294 Validation Decoder Loss:  0.3376274
Encoder Loss:  0.052603606  || Decoder Loss:  0.055408325 Validation Decoder Loss:  0.33583608
Encoder Loss:  0.05138618  || Decoder Loss:  0.053378243 Validation Decoder Loss:  0.33098057
Encoder Loss:  0.051585473  || Decoder Loss:  0.051944815 Validation Decoder Loss:  0.34760755
Encoder Loss:  0.05289592  || Decoder Loss:  0.05330477 Validation Decoder Loss:  0.34202856
Encoder Loss:  0.05169919  || Decoder Loss:  0.053426366 Validation Decoder Loss:  0.33462113
Encoder Loss:  0.051279396  || Decoder Loss:  0.051604886 Validation Decoder Loss:  0.33475938
Encoder Loss:  0.05153547  || Decoder Loss:  0.052805267 Validation Decoder Loss:  0.33666652
Encoder Loss:  0.051154017  || Decoder Loss:  0.051136743 Validation Decoder Loss:  0.33419424
Encoder Loss:  0.051142998  || Decoder Loss:  0.051995054 Validation Decoder Loss:  0.33825082
Encoder Loss:  0.050855022  || Decoder Loss:  0.051404 Validation Decoder Loss:  0.3406155
Encoder Loss:  0.050951976  || Decoder Loss:  0.050965022 Validation Decoder Loss:  0.34500808
Encoder Loss:  0.050926972  || Decoder Loss:  0.0507828 Validation Decoder Loss:  0.33369735
Model: siamese_net_lr_0.019246076227245845 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33369738
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_260 (Conv3D (None, 136, 5, 20, 1)     11        
_________________________________________________________________
dropout_549 (Dropout)        (None, 136, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_261 (Conv3D (None, 184, 5, 20, 1)     50        
_________________________________________________________________
reshape_157 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 2780, 20, 1)       467       
_________________________________________________________________
dropout_551 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 920, 20, 1)        943       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 980, 20, 1)        62        
_________________________________________________________________
dropout_553 (Dropout)        (None, 980, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 3245, 20, 1)       1288      
=================================================================
Total params: 1,350
Trainable params: 1,350
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45273384  || Decoder Loss:  0.56280696 Validation Decoder Loss:  1.0188564
Encoder Loss:  0.34860817  || Decoder Loss:  0.37935573 Validation Decoder Loss:  0.53649175
Encoder Loss:  0.40048927  || Decoder Loss:  0.49422005 Validation Decoder Loss:  1.5223026
Encoder Loss:  0.49582294  || Decoder Loss:  0.67064375 Validation Decoder Loss:  1.0202339
Encoder Loss:  0.30268154  || Decoder Loss:  0.46531817 Validation Decoder Loss:  1.3115059
Encoder Loss:  0.29859158  || Decoder Loss:  0.48491842 Validation Decoder Loss:  0.670524
Encoder Loss:  0.30014765  || Decoder Loss:  0.4881995 Validation Decoder Loss:  0.6999397
Encoder Loss:  0.30142966  || Decoder Loss:  0.49092594 Validation Decoder Loss:  0.6249607
Encoder Loss:  0.3058882  || Decoder Loss:  0.49451217 Validation Decoder Loss:  0.68968874
Encoder Loss:  0.29661644  || Decoder Loss:  0.48922956 Validation Decoder Loss:  0.6872381
Encoder Loss:  0.2965066  || Decoder Loss:  0.4889646 Validation Decoder Loss:  0.61665606
Encoder Loss:  0.30353722  || Decoder Loss:  0.48711446 Validation Decoder Loss:  0.73564535
Encoder Loss:  0.29156777  || Decoder Loss:  0.47626233 Validation Decoder Loss:  1.3126101
Encoder Loss:  0.30519715  || Decoder Loss:  0.4987625 Validation Decoder Loss:  1.3376853
Encoder Loss:  0.30648413  || Decoder Loss:  0.50231576 Validation Decoder Loss:  1.3770466
Encoder Loss:  0.30196154  || Decoder Loss:  0.4993048 Validation Decoder Loss:  1.3411438
Encoder Loss:  0.29836425  || Decoder Loss:  0.48724592 Validation Decoder Loss:  1.3129926
Encoder Loss:  0.29473603  || Decoder Loss:  0.48511353 Validation Decoder Loss:  1.264787
Encoder Loss:  0.3108358  || Decoder Loss:  0.49866197 Validation Decoder Loss:  1.458336
Encoder Loss:  0.30784225  || Decoder Loss:  0.4972183 Validation Decoder Loss:  1.3099623
Encoder Loss:  0.30050322  || Decoder Loss:  0.49494612 Validation Decoder Loss:  1.3279009
Encoder Loss:  0.296376  || Decoder Loss:  0.48792732 Validation Decoder Loss:  1.3116918
Encoder Loss:  0.29312122  || Decoder Loss:  0.48413545 Validation Decoder Loss:  1.320673
Encoder Loss:  0.2923525  || Decoder Loss:  0.48122478 Validation Decoder Loss:  1.3075807
Encoder Loss:  0.29880753  || Decoder Loss:  0.48359612 Validation Decoder Loss:  1.2386751
Encoder Loss:  0.2964949  || Decoder Loss:  0.48513785 Validation Decoder Loss:  1.2307345
Encoder Loss:  0.2916218  || Decoder Loss:  0.48080775 Validation Decoder Loss:  1.1978014
Encoder Loss:  0.29204303  || Decoder Loss:  0.4768771 Validation Decoder Loss:  1.2389528
Encoder Loss:  0.30323517  || Decoder Loss:  0.48684913 Validation Decoder Loss:  1.1559608
Encoder Loss:  0.29558596  || Decoder Loss:  0.48054364 Validation Decoder Loss:  1.134608
Encoder Loss:  0.28905377  || Decoder Loss:  0.4790867 Validation Decoder Loss:  1.1175303
Encoder Loss:  0.2935743  || Decoder Loss:  0.48015243 Validation Decoder Loss:  1.0823598
Encoder Loss:  0.29562724  || Decoder Loss:  0.47573715 Validation Decoder Loss:  1.1281252
Encoder Loss:  0.29409397  || Decoder Loss:  0.47963282 Validation Decoder Loss:  1.1234773
Encoder Loss:  0.29561388  || Decoder Loss:  0.48188454 Validation Decoder Loss:  1.0707614
Encoder Loss:  0.29072896  || Decoder Loss:  0.47889674 Validation Decoder Loss:  1.0523875
Encoder Loss:  0.2899576  || Decoder Loss:  0.47869176 Validation Decoder Loss:  1.0582974
Encoder Loss:  0.29219556  || Decoder Loss:  0.47757667 Validation Decoder Loss:  1.0500622
Encoder Loss:  0.29350373  || Decoder Loss:  0.4764634 Validation Decoder Loss:  1.0937281
Encoder Loss:  0.28924567  || Decoder Loss:  0.4779429 Validation Decoder Loss:  1.1298707
Model: siamese_net_lr_0.09448845193334741 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1298707
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_263 (Conv3D (None, 144, 5, 20, 1)     19        
_________________________________________________________________
dropout_555 (Dropout)        (None, 144, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_264 (Conv3D (None, 184, 5, 20, 1)     42        
_________________________________________________________________
reshape_158 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 2790, 20, 1)       457       
_________________________________________________________________
dropout_557 (Dropout)        (None, 2790, 20, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 920, 20, 1)        1872      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 980, 20, 1)        62        
_________________________________________________________________
dropout_559 (Dropout)        (None, 980, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 3245, 20, 1)       309       
=================================================================
Total params: 371
Trainable params: 371
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41520295  || Decoder Loss:  0.4428471 Validation Decoder Loss:  1.0155352
Encoder Loss:  0.48717004  || Decoder Loss:  0.53010446 Validation Decoder Loss:  1.3914776
Encoder Loss:  0.4341624  || Decoder Loss:  0.48142806 Validation Decoder Loss:  1.1401553
Encoder Loss:  0.42873558  || Decoder Loss:  0.47961277 Validation Decoder Loss:  1.2714707
Encoder Loss:  0.4280078  || Decoder Loss:  0.48058105 Validation Decoder Loss:  1.2403849
Encoder Loss:  0.34834367  || Decoder Loss:  0.38856682 Validation Decoder Loss:  1.0814183
Encoder Loss:  0.14335008  || Decoder Loss:  0.1534309 Validation Decoder Loss:  0.2765767
Encoder Loss:  0.056599867  || Decoder Loss:  0.055211276 Validation Decoder Loss:  0.36013764
Encoder Loss:  0.04239103  || Decoder Loss:  0.03846396 Validation Decoder Loss:  0.33202127
Encoder Loss:  0.044355683  || Decoder Loss:  0.037122086 Validation Decoder Loss:  0.34187877
Encoder Loss:  0.04106021  || Decoder Loss:  0.036873136 Validation Decoder Loss:  0.3359437
Encoder Loss:  0.04014567  || Decoder Loss:  0.03677191 Validation Decoder Loss:  0.33387738
Encoder Loss:  0.03977478  || Decoder Loss:  0.036753654 Validation Decoder Loss:  0.3292953
Encoder Loss:  0.039230667  || Decoder Loss:  0.036859587 Validation Decoder Loss:  0.3196128
Encoder Loss:  0.040471587  || Decoder Loss:  0.03741504 Validation Decoder Loss:  0.30370474
Encoder Loss:  0.040845048  || Decoder Loss:  0.038096093 Validation Decoder Loss:  0.30944398
Encoder Loss:  0.041883897  || Decoder Loss:  0.039127544 Validation Decoder Loss:  0.29983014
Encoder Loss:  0.043245815  || Decoder Loss:  0.038980857 Validation Decoder Loss:  0.29997212
Encoder Loss:  0.04435186  || Decoder Loss:  0.041225944 Validation Decoder Loss:  0.29184636
Encoder Loss:  0.04121186  || Decoder Loss:  0.038564593 Validation Decoder Loss:  0.29848838
Encoder Loss:  0.0426106  || Decoder Loss:  0.039260816 Validation Decoder Loss:  0.3043609
Encoder Loss:  0.041391503  || Decoder Loss:  0.038920227 Validation Decoder Loss:  0.30189535
Encoder Loss:  0.042567547  || Decoder Loss:  0.038633343 Validation Decoder Loss:  0.2962284
Encoder Loss:  0.044270612  || Decoder Loss:  0.039744236 Validation Decoder Loss:  0.29223797
Encoder Loss:  0.043584034  || Decoder Loss:  0.040230546 Validation Decoder Loss:  0.30122083
Encoder Loss:  0.043066785  || Decoder Loss:  0.04019085 Validation Decoder Loss:  0.30493462
Encoder Loss:  0.04391376  || Decoder Loss:  0.037976667 Validation Decoder Loss:  0.29281557
Encoder Loss:  0.046446387  || Decoder Loss:  0.041313015 Validation Decoder Loss:  0.2873059
Encoder Loss:  0.045572396  || Decoder Loss:  0.040555377 Validation Decoder Loss:  0.2885171
Encoder Loss:  0.046139568  || Decoder Loss:  0.04155211 Validation Decoder Loss:  0.28911328
Encoder Loss:  0.043538347  || Decoder Loss:  0.03981071 Validation Decoder Loss:  0.2845772
Encoder Loss:  0.041668214  || Decoder Loss:  0.038629964 Validation Decoder Loss:  0.29097462
Encoder Loss:  0.04002767  || Decoder Loss:  0.037634138 Validation Decoder Loss:  0.30456257
Encoder Loss:  0.039408296  || Decoder Loss:  0.036949825 Validation Decoder Loss:  0.30195326
Encoder Loss:  0.03981743  || Decoder Loss:  0.036840357 Validation Decoder Loss:  0.30008668
Encoder Loss:  0.039829098  || Decoder Loss:  0.03689887 Validation Decoder Loss:  0.30026177
Encoder Loss:  0.039547116  || Decoder Loss:  0.03689842 Validation Decoder Loss:  0.29878524
Encoder Loss:  0.039401025  || Decoder Loss:  0.036735702 Validation Decoder Loss:  0.30013064
Encoder Loss:  0.040829267  || Decoder Loss:  0.036737993 Validation Decoder Loss:  0.3009311
Encoder Loss:  0.040401652  || Decoder Loss:  0.03748762 Validation Decoder Loss:  0.2912686
Model: siamese_net_lr_0.027888658525452983 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.2912686
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_266 (Conv3D (None, 164, 5, 20, 1)     39        
_________________________________________________________________
dropout_561 (Dropout)        (None, 164, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_267 (Conv3D (None, 184, 5, 20, 1)     22        
_________________________________________________________________
reshape_159 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 1620, 20, 1)       1627      
_________________________________________________________________
dropout_563 (Dropout)        (None, 1620, 20, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 920, 20, 1)        702       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 2880, 20, 1)       124       
_________________________________________________________________
dropout_565 (Dropout)        (None, 2880, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 3245, 20, 1)       367       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2461528  || Decoder Loss:  0.21653007 Validation Decoder Loss:  0.2899161
Encoder Loss:  0.108836085  || Decoder Loss:  0.056478057 Validation Decoder Loss:  0.3916645
Encoder Loss:  0.08031134  || Decoder Loss:  0.039597653 Validation Decoder Loss:  0.33779848
Encoder Loss:  0.08346119  || Decoder Loss:  0.037612673 Validation Decoder Loss:  0.34965402
Encoder Loss:  0.08158572  || Decoder Loss:  0.037174743 Validation Decoder Loss:  0.34580112
Encoder Loss:  0.10161843  || Decoder Loss:  0.036857203 Validation Decoder Loss:  0.3416961
Encoder Loss:  0.14117974  || Decoder Loss:  0.036792003 Validation Decoder Loss:  0.35422388
Encoder Loss:  0.11984062  || Decoder Loss:  0.036714945 Validation Decoder Loss:  0.34536842
Encoder Loss:  0.09309313  || Decoder Loss:  0.03660576 Validation Decoder Loss:  0.34659064
Encoder Loss:  0.06191979  || Decoder Loss:  0.036494307 Validation Decoder Loss:  0.34740984
Encoder Loss:  0.07016215  || Decoder Loss:  0.036434278 Validation Decoder Loss:  0.3466929
Encoder Loss:  0.0719788  || Decoder Loss:  0.036398135 Validation Decoder Loss:  0.3460133
Encoder Loss:  0.062122885  || Decoder Loss:  0.03636363 Validation Decoder Loss:  0.34760225
Encoder Loss:  0.064129576  || Decoder Loss:  0.036331173 Validation Decoder Loss:  0.34805906
Encoder Loss:  0.055767447  || Decoder Loss:  0.036287986 Validation Decoder Loss:  0.3475228
Encoder Loss:  0.06746929  || Decoder Loss:  0.03625578 Validation Decoder Loss:  0.34841594
Encoder Loss:  0.0611832  || Decoder Loss:  0.036222804 Validation Decoder Loss:  0.34751675
Encoder Loss:  0.07072534  || Decoder Loss:  0.036204323 Validation Decoder Loss:  0.34534103
Encoder Loss:  0.05854652  || Decoder Loss:  0.036144976 Validation Decoder Loss:  0.34601516
Encoder Loss:  0.067434624  || Decoder Loss:  0.03610957 Validation Decoder Loss:  0.35149485
Encoder Loss:  0.05736647  || Decoder Loss:  0.036075007 Validation Decoder Loss:  0.3459713
Encoder Loss:  0.056658454  || Decoder Loss:  0.036009077 Validation Decoder Loss:  0.34666395
Encoder Loss:  0.06316276  || Decoder Loss:  0.03595226 Validation Decoder Loss:  0.34243906
Encoder Loss:  0.06643003  || Decoder Loss:  0.035944637 Validation Decoder Loss:  0.34947768
Encoder Loss:  0.05756852  || Decoder Loss:  0.035850182 Validation Decoder Loss:  0.3457271
Encoder Loss:  0.065639056  || Decoder Loss:  0.035804346 Validation Decoder Loss:  0.34514022
Encoder Loss:  0.05823992  || Decoder Loss:  0.03572963 Validation Decoder Loss:  0.34527773
Encoder Loss:  0.057411805  || Decoder Loss:  0.03563784 Validation Decoder Loss:  0.34614122
Encoder Loss:  0.059881292  || Decoder Loss:  0.035550326 Validation Decoder Loss:  0.34881434
Encoder Loss:  0.060320158  || Decoder Loss:  0.03548063 Validation Decoder Loss:  0.34930477
Encoder Loss:  0.059289426  || Decoder Loss:  0.03538489 Validation Decoder Loss:  0.34905827
Encoder Loss:  0.056200635  || Decoder Loss:  0.035288192 Validation Decoder Loss:  0.34609702
Encoder Loss:  0.055669643  || Decoder Loss:  0.035183072 Validation Decoder Loss:  0.344971
Encoder Loss:  0.060549684  || Decoder Loss:  0.03511435 Validation Decoder Loss:  0.34600395
Encoder Loss:  0.057270166  || Decoder Loss:  0.03501602 Validation Decoder Loss:  0.34512195
Encoder Loss:  0.056067415  || Decoder Loss:  0.034939602 Validation Decoder Loss:  0.3476055
Encoder Loss:  0.06311571  || Decoder Loss:  0.034881543 Validation Decoder Loss:  0.3473698
Encoder Loss:  0.051461726  || Decoder Loss:  0.034817163 Validation Decoder Loss:  0.34560016
Encoder Loss:  0.053132154  || Decoder Loss:  0.03476598 Validation Decoder Loss:  0.34550098
Encoder Loss:  0.057850886  || Decoder Loss:  0.034715816 Validation Decoder Loss:  0.34411728
Model: siamese_net_lr_0.01937695598609792 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34411728
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_269 (Conv3D (None, 98, 5, 20, 1)      36        
_________________________________________________________________
dropout_567 (Dropout)        (None, 98, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_270 (Conv3D (None, 184, 5, 20, 1)     88        
_________________________________________________________________
reshape_160 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 2760, 20, 1)       487       
_________________________________________________________________
dropout_569 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 920, 20, 1)        4         
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 1910, 20, 1)       73        
_________________________________________________________________
dropout_571 (Dropout)        (None, 1910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 3245, 20, 1)       1337      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3707115  || Decoder Loss:  0.37992755 Validation Decoder Loss:  1.2199066
Encoder Loss:  0.32439053  || Decoder Loss:  0.3360462 Validation Decoder Loss:  0.21630073
Encoder Loss:  0.20829009  || Decoder Loss:  0.21481453 Validation Decoder Loss:  0.19794883
Encoder Loss:  0.08285911  || Decoder Loss:  0.08397815 Validation Decoder Loss:  0.2744862
Encoder Loss:  0.05747266  || Decoder Loss:  0.05703018 Validation Decoder Loss:  0.3959914
Encoder Loss:  0.058555804  || Decoder Loss:  0.058148608 Validation Decoder Loss:  0.43852055
Encoder Loss:  0.06042477  || Decoder Loss:  0.060492653 Validation Decoder Loss:  0.53719974
Encoder Loss:  0.048558477  || Decoder Loss:  0.04823042 Validation Decoder Loss:  0.37692064
Encoder Loss:  0.047797844  || Decoder Loss:  0.047253598 Validation Decoder Loss:  0.44812644
Encoder Loss:  0.04735742  || Decoder Loss:  0.046932682 Validation Decoder Loss:  0.28391254
Encoder Loss:  0.047414877  || Decoder Loss:  0.04701657 Validation Decoder Loss:  0.24820736
Encoder Loss:  0.047400523  || Decoder Loss:  0.047022406 Validation Decoder Loss:  0.57027787
Encoder Loss:  0.050806485  || Decoder Loss:  0.050531417 Validation Decoder Loss:  0.42728782
Encoder Loss:  0.044145107  || Decoder Loss:  0.043660372 Validation Decoder Loss:  0.2979088
Encoder Loss:  0.04497929  || Decoder Loss:  0.04452193 Validation Decoder Loss:  0.3314513
Encoder Loss:  0.043955255  || Decoder Loss:  0.043457434 Validation Decoder Loss:  0.45910883
Encoder Loss:  0.045203358  || Decoder Loss:  0.044755295 Validation Decoder Loss:  0.27969426
Encoder Loss:  0.044786073  || Decoder Loss:  0.044363867 Validation Decoder Loss:  0.32646805
Encoder Loss:  0.04304756  || Decoder Loss:  0.042515785 Validation Decoder Loss:  0.25536475
Encoder Loss:  0.045671362  || Decoder Loss:  0.045253947 Validation Decoder Loss:  0.247181
Encoder Loss:  0.044416305  || Decoder Loss:  0.043899465 Validation Decoder Loss:  0.3204252
Encoder Loss:  0.038450778  || Decoder Loss:  0.037746176 Validation Decoder Loss:  0.26620317
Encoder Loss:  0.044698305  || Decoder Loss:  0.04424017 Validation Decoder Loss:  0.29423708
Encoder Loss:  0.038780455  || Decoder Loss:  0.03810343 Validation Decoder Loss:  0.2994043
Encoder Loss:  0.036770288  || Decoder Loss:  0.03597138 Validation Decoder Loss:  0.4229546
Encoder Loss:  0.038130544  || Decoder Loss:  0.037507538 Validation Decoder Loss:  0.28148198
Encoder Loss:  0.03971535  || Decoder Loss:  0.03915507 Validation Decoder Loss:  0.41633356
Encoder Loss:  0.036220983  || Decoder Loss:  0.03545915 Validation Decoder Loss:  0.25275487
Encoder Loss:  0.041754104  || Decoder Loss:  0.041054033 Validation Decoder Loss:  0.34311283
Encoder Loss:  0.049737047  || Decoder Loss:  0.04909922 Validation Decoder Loss:  0.27357382
Encoder Loss:  0.04483991  || Decoder Loss:  0.044412736 Validation Decoder Loss:  0.4189717
Encoder Loss:  0.039873246  || Decoder Loss:  0.039326355 Validation Decoder Loss:  0.49478328
Encoder Loss:  0.0553306  || Decoder Loss:  0.05537858 Validation Decoder Loss:  0.34238803
Encoder Loss:  0.056544896  || Decoder Loss:  0.056577902 Validation Decoder Loss:  0.25436258
Encoder Loss:  0.045128636  || Decoder Loss:  0.044678308 Validation Decoder Loss:  0.2920732
Encoder Loss:  0.04210074  || Decoder Loss:  0.04165799 Validation Decoder Loss:  0.27133644
Encoder Loss:  0.036701173  || Decoder Loss:  0.035953008 Validation Decoder Loss:  0.42411548
Encoder Loss:  0.041053608  || Decoder Loss:  0.04058085 Validation Decoder Loss:  0.42389113
Encoder Loss:  0.040979244  || Decoder Loss:  0.040511232 Validation Decoder Loss:  0.33769998
Encoder Loss:  0.039082628  || Decoder Loss:  0.038537815 Validation Decoder Loss:  0.27392125
Model: siamese_net_lr_0.037920890864037125 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.27392125
Model: "sequential_538"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_272 (Conv3D (None, 172, 5, 20, 1)     110       
_________________________________________________________________
dropout_573 (Dropout)        (None, 172, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_273 (Conv3D (None, 184, 5, 20, 1)     14        
_________________________________________________________________
reshape_161 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 2220, 20, 1)       1027      
_________________________________________________________________
dropout_575 (Dropout)        (None, 2220, 20, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 920, 20, 1)        383       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 2300, 20, 1)       1382      
_________________________________________________________________
dropout_577 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 3245, 20, 1)       947       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47721642  || Decoder Loss:  0.8037966 Validation Decoder Loss:  1.6222656
Encoder Loss:  0.45453647  || Decoder Loss:  0.57020587 Validation Decoder Loss:  0.34441066
Encoder Loss:  0.37525818  || Decoder Loss:  0.1151246 Validation Decoder Loss:  0.3475777
Encoder Loss:  0.37171945  || Decoder Loss:  0.10919068 Validation Decoder Loss:  0.3432256
Encoder Loss:  0.3658315  || Decoder Loss:  0.10011134 Validation Decoder Loss:  0.33718926
Encoder Loss:  0.35560706  || Decoder Loss:  0.09181043 Validation Decoder Loss:  0.33327633
Encoder Loss:  0.31635016  || Decoder Loss:  0.095126055 Validation Decoder Loss:  0.520349
Encoder Loss:  0.1804573  || Decoder Loss:  0.47166005 Validation Decoder Loss:  1.0564005
Encoder Loss:  0.14498995  || Decoder Loss:  0.43816462 Validation Decoder Loss:  1.132764
Encoder Loss:  0.14755425  || Decoder Loss:  0.44397295 Validation Decoder Loss:  1.2142384
Encoder Loss:  0.14515102  || Decoder Loss:  0.43531403 Validation Decoder Loss:  1.2867919
Encoder Loss:  0.14557706  || Decoder Loss:  0.44451565 Validation Decoder Loss:  1.3187821
Encoder Loss:  0.14203727  || Decoder Loss:  0.4396065 Validation Decoder Loss:  1.1601529
Encoder Loss:  0.14272344  || Decoder Loss:  0.45061675 Validation Decoder Loss:  1.2988437
Encoder Loss:  0.13854481  || Decoder Loss:  0.42667684 Validation Decoder Loss:  1.2871315
Encoder Loss:  0.13432173  || Decoder Loss:  0.42334133 Validation Decoder Loss:  1.3065133
Encoder Loss:  0.13580693  || Decoder Loss:  0.42851317 Validation Decoder Loss:  1.1024821
Encoder Loss:  0.122812375  || Decoder Loss:  0.39006585 Validation Decoder Loss:  1.2898533
Encoder Loss:  0.13369936  || Decoder Loss:  0.41876504 Validation Decoder Loss:  1.4794637
Encoder Loss:  0.10509116  || Decoder Loss:  0.29211152 Validation Decoder Loss:  0.43951532
Encoder Loss:  0.07137282  || Decoder Loss:  0.09369042 Validation Decoder Loss:  0.46742377
Encoder Loss:  0.06416669  || Decoder Loss:  0.069318324 Validation Decoder Loss:  0.37831342
Encoder Loss:  0.06136172  || Decoder Loss:  0.07513527 Validation Decoder Loss:  0.31583485
Encoder Loss:  0.05673468  || Decoder Loss:  0.047884636 Validation Decoder Loss:  0.34317362
Encoder Loss:  0.059864357  || Decoder Loss:  0.050267834 Validation Decoder Loss:  0.39131898
Encoder Loss:  0.05588882  || Decoder Loss:  0.047948007 Validation Decoder Loss:  0.34372717
Encoder Loss:  0.05733281  || Decoder Loss:  0.04828519 Validation Decoder Loss:  0.3146459
Encoder Loss:  0.058044907  || Decoder Loss:  0.04652478 Validation Decoder Loss:  0.297877
Encoder Loss:  0.06727221  || Decoder Loss:  0.052572537 Validation Decoder Loss:  0.29961973
Encoder Loss:  0.06407982  || Decoder Loss:  0.05212924 Validation Decoder Loss:  0.3540376
Encoder Loss:  0.05546514  || Decoder Loss:  0.04776275 Validation Decoder Loss:  0.39221466
Encoder Loss:  0.056068126  || Decoder Loss:  0.050211515 Validation Decoder Loss:  0.311116
Encoder Loss:  0.056378104  || Decoder Loss:  0.048137806 Validation Decoder Loss:  0.3352465
Encoder Loss:  0.057066426  || Decoder Loss:  0.04616876 Validation Decoder Loss:  0.31235787
Encoder Loss:  0.058288936  || Decoder Loss:  0.046788525 Validation Decoder Loss:  0.44362816
Encoder Loss:  0.05784843  || Decoder Loss:  0.048287883 Validation Decoder Loss:  0.3434255
Encoder Loss:  0.061158285  || Decoder Loss:  0.051393196 Validation Decoder Loss:  0.33830482
Encoder Loss:  0.06054486  || Decoder Loss:  0.05158055 Validation Decoder Loss:  0.28204322
Encoder Loss:  0.05752295  || Decoder Loss:  0.05079165 Validation Decoder Loss:  0.3487794
Encoder Loss:  0.054088987  || Decoder Loss:  0.047099143 Validation Decoder Loss:  0.31211203
Model: siamese_net_lr_0.045983809610349535 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31211203
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_275 (Conv3D (None, 164, 5, 20, 1)     39        
_________________________________________________________________
dropout_579 (Dropout)        (None, 164, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_276 (Conv3D (None, 184, 5, 20, 1)     22        
_________________________________________________________________
reshape_162 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 1620, 20, 1)       1627      
_________________________________________________________________
dropout_581 (Dropout)        (None, 1620, 20, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 920, 20, 1)        702       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 2880, 20, 1)       124       
_________________________________________________________________
dropout_583 (Dropout)        (None, 2880, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 3245, 20, 1)       367       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38425013  || Decoder Loss:  0.352054 Validation Decoder Loss:  0.33692342
Encoder Loss:  0.3266341  || Decoder Loss:  0.19668266 Validation Decoder Loss:  0.3231746
Encoder Loss:  0.17343149  || Decoder Loss:  0.14785251 Validation Decoder Loss:  0.32116762
Encoder Loss:  0.0672435  || Decoder Loss:  0.0470977 Validation Decoder Loss:  0.34798634
Encoder Loss:  0.10120141  || Decoder Loss:  0.037619 Validation Decoder Loss:  0.34761253
Encoder Loss:  0.06373195  || Decoder Loss:  0.03637541 Validation Decoder Loss:  0.35238063
Encoder Loss:  0.09621585  || Decoder Loss:  0.036279693 Validation Decoder Loss:  0.36132845
Encoder Loss:  0.083196074  || Decoder Loss:  0.036270596 Validation Decoder Loss:  0.34693828
Encoder Loss:  0.094948165  || Decoder Loss:  0.036337756 Validation Decoder Loss:  0.34563053
Encoder Loss:  0.07587318  || Decoder Loss:  0.036220476 Validation Decoder Loss:  0.34728658
Encoder Loss:  0.054736648  || Decoder Loss:  0.036174573 Validation Decoder Loss:  0.35436705
Encoder Loss:  0.058051553  || Decoder Loss:  0.036111113 Validation Decoder Loss:  0.35291728
Encoder Loss:  0.062625825  || Decoder Loss:  0.03607862 Validation Decoder Loss:  0.349542
Encoder Loss:  0.060146105  || Decoder Loss:  0.036059678 Validation Decoder Loss:  0.35369402
Encoder Loss:  0.07474777  || Decoder Loss:  0.03605552 Validation Decoder Loss:  0.3488955
Encoder Loss:  0.067427985  || Decoder Loss:  0.036127053 Validation Decoder Loss:  0.35506815
Encoder Loss:  0.061880995  || Decoder Loss:  0.035981875 Validation Decoder Loss:  0.35196668
Encoder Loss:  0.06627351  || Decoder Loss:  0.035952605 Validation Decoder Loss:  0.35173446
Encoder Loss:  0.082143635  || Decoder Loss:  0.035934463 Validation Decoder Loss:  0.34907538
Encoder Loss:  0.062380843  || Decoder Loss:  0.035925068 Validation Decoder Loss:  0.35025352
Encoder Loss:  0.058301378  || Decoder Loss:  0.03585029 Validation Decoder Loss:  0.3500011
Encoder Loss:  0.0620889  || Decoder Loss:  0.03581217 Validation Decoder Loss:  0.34860563
Encoder Loss:  0.06231387  || Decoder Loss:  0.035772942 Validation Decoder Loss:  0.35642567
Encoder Loss:  0.06334451  || Decoder Loss:  0.03571811 Validation Decoder Loss:  0.3464201
Encoder Loss:  0.07933318  || Decoder Loss:  0.035660394 Validation Decoder Loss:  0.34734845
Encoder Loss:  0.06213168  || Decoder Loss:  0.03564229 Validation Decoder Loss:  0.3510472
Encoder Loss:  0.06384865  || Decoder Loss:  0.03558162 Validation Decoder Loss:  0.35089982
Encoder Loss:  0.059525654  || Decoder Loss:  0.03552929 Validation Decoder Loss:  0.3471701
Encoder Loss:  0.07324975  || Decoder Loss:  0.035519432 Validation Decoder Loss:  0.34668595
Encoder Loss:  0.05692781  || Decoder Loss:  0.035498787 Validation Decoder Loss:  0.34431684
Encoder Loss:  0.058408108  || Decoder Loss:  0.035474442 Validation Decoder Loss:  0.34784395
Encoder Loss:  0.056338187  || Decoder Loss:  0.035451114 Validation Decoder Loss:  0.3452459
Encoder Loss:  0.05661985  || Decoder Loss:  0.035457768 Validation Decoder Loss:  0.3455938
Encoder Loss:  0.05569128  || Decoder Loss:  0.035408188 Validation Decoder Loss:  0.34440422
Encoder Loss:  0.053994097  || Decoder Loss:  0.03539549 Validation Decoder Loss:  0.34226024
Encoder Loss:  0.05466192  || Decoder Loss:  0.03543857 Validation Decoder Loss:  0.34051472
Encoder Loss:  0.057700872  || Decoder Loss:  0.03538494 Validation Decoder Loss:  0.34280127
Encoder Loss:  0.05558853  || Decoder Loss:  0.035389975 Validation Decoder Loss:  0.34220976
Encoder Loss:  0.05638175  || Decoder Loss:  0.035385862 Validation Decoder Loss:  0.3430164
Encoder Loss:  0.06807751  || Decoder Loss:  0.035413023 Validation Decoder Loss:  0.3424269
Model: siamese_net_lr_0.01937696584005169 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3424269
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_278 (Conv3D (None, 170, 5, 20, 1)     108       
_________________________________________________________________
dropout_585 (Dropout)        (None, 170, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_279 (Conv3D (None, 184, 5, 20, 1)     16        
_________________________________________________________________
reshape_163 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 1850, 20, 1)       1397      
_________________________________________________________________
dropout_587 (Dropout)        (None, 1850, 20, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 920, 20, 1)        13        
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 2550, 20, 1)       713       
_________________________________________________________________
dropout_589 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 3245, 20, 1)       697       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30063224  || Decoder Loss:  0.18575363 Validation Decoder Loss:  0.37038624
Encoder Loss:  0.292443  || Decoder Loss:  0.122706346 Validation Decoder Loss:  0.3589117
Encoder Loss:  0.28729123  || Decoder Loss:  0.12333451 Validation Decoder Loss:  0.32679272
Encoder Loss:  0.515979  || Decoder Loss:  0.69311035 Validation Decoder Loss:  1.6467768
Encoder Loss:  0.62524295  || Decoder Loss:  0.879704 Validation Decoder Loss:  1.6405944
Encoder Loss:  0.6099741  || Decoder Loss:  0.8631642 Validation Decoder Loss:  1.6412206
Encoder Loss:  0.48908207  || Decoder Loss:  0.73312896 Validation Decoder Loss:  1.0445197
Encoder Loss:  0.3049286  || Decoder Loss:  0.5248973 Validation Decoder Loss:  1.1129057
Encoder Loss:  0.2714299  || Decoder Loss:  0.5147391 Validation Decoder Loss:  1.0789089
Encoder Loss:  0.27022338  || Decoder Loss:  0.5109834 Validation Decoder Loss:  1.099982
Encoder Loss:  0.2669757  || Decoder Loss:  0.5059703 Validation Decoder Loss:  1.1289418
Encoder Loss:  0.263979  || Decoder Loss:  0.5006469 Validation Decoder Loss:  1.1606357
Encoder Loss:  0.2618841  || Decoder Loss:  0.49801672 Validation Decoder Loss:  1.1866691
Encoder Loss:  0.26019698  || Decoder Loss:  0.49661463 Validation Decoder Loss:  1.2036788
Encoder Loss:  0.25825995  || Decoder Loss:  0.49496526 Validation Decoder Loss:  1.2062835
Encoder Loss:  0.26010838  || Decoder Loss:  0.5000993 Validation Decoder Loss:  1.2124848
Encoder Loss:  0.25883046  || Decoder Loss:  0.50033736 Validation Decoder Loss:  1.2133116
Encoder Loss:  0.25328314  || Decoder Loss:  0.49792224 Validation Decoder Loss:  1.2512543
Encoder Loss:  0.25488406  || Decoder Loss:  0.49758914 Validation Decoder Loss:  1.2460456
Encoder Loss:  0.2508789  || Decoder Loss:  0.49870622 Validation Decoder Loss:  1.2503849
Encoder Loss:  0.25286302  || Decoder Loss:  0.4901829 Validation Decoder Loss:  1.3066384
Encoder Loss:  0.259851  || Decoder Loss:  0.5024272 Validation Decoder Loss:  1.1378579
Encoder Loss:  0.26300597  || Decoder Loss:  0.4909743 Validation Decoder Loss:  1.3828294
Encoder Loss:  0.25163114  || Decoder Loss:  0.497039 Validation Decoder Loss:  1.3148699
Encoder Loss:  0.25430715  || Decoder Loss:  0.4911184 Validation Decoder Loss:  1.0319403
Encoder Loss:  0.24236251  || Decoder Loss:  0.47788268 Validation Decoder Loss:  1.1100826
Encoder Loss:  0.24002138  || Decoder Loss:  0.47135562 Validation Decoder Loss:  1.2025381
Encoder Loss:  0.23953246  || Decoder Loss:  0.46965653 Validation Decoder Loss:  1.0183947
Encoder Loss:  0.2536075  || Decoder Loss:  0.4882594 Validation Decoder Loss:  1.1947492
Encoder Loss:  0.24697655  || Decoder Loss:  0.487345 Validation Decoder Loss:  1.1117896
Encoder Loss:  0.24806853  || Decoder Loss:  0.48150626 Validation Decoder Loss:  1.2793839
Encoder Loss:  0.24016528  || Decoder Loss:  0.47116977 Validation Decoder Loss:  1.2203696
Encoder Loss:  0.23919539  || Decoder Loss:  0.46950734 Validation Decoder Loss:  1.1579754
Encoder Loss:  0.23665047  || Decoder Loss:  0.46576366 Validation Decoder Loss:  1.1549547
Encoder Loss:  0.24086851  || Decoder Loss:  0.47470954 Validation Decoder Loss:  1.3152895
Encoder Loss:  0.24368975  || Decoder Loss:  0.47848284 Validation Decoder Loss:  1.1820376
Encoder Loss:  0.24259119  || Decoder Loss:  0.47545895 Validation Decoder Loss:  0.99114615
Encoder Loss:  0.24084349  || Decoder Loss:  0.47242126 Validation Decoder Loss:  0.95948064
Encoder Loss:  0.23930945  || Decoder Loss:  0.4738659 Validation Decoder Loss:  1.1643975
Encoder Loss:  0.2411313  || Decoder Loss:  0.4699756 Validation Decoder Loss:  1.1124071
Model: siamese_net_lr_0.059604775529834966 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1124071
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_281 (Conv3D (None, 168, 5, 20, 1)     43        
_________________________________________________________________
dropout_591 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_282 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_164 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 1830, 20, 1)       1417      
_________________________________________________________________
dropout_593 (Dropout)        (None, 1830, 20, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 920, 20, 1)        912       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 2500, 20, 1)       663       
_________________________________________________________________
dropout_595 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 3245, 20, 1)       747       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34266824  || Decoder Loss:  0.562978 Validation Decoder Loss:  0.3214981
Encoder Loss:  0.15149269  || Decoder Loss:  0.43558022 Validation Decoder Loss:  0.4456461
Encoder Loss:  0.055162553  || Decoder Loss:  0.49540725 Validation Decoder Loss:  0.8046635
Encoder Loss:  0.059585772  || Decoder Loss:  0.46984416 Validation Decoder Loss:  0.91245836
Encoder Loss:  0.060349006  || Decoder Loss:  0.55372816 Validation Decoder Loss:  0.50123847
Encoder Loss:  0.056410562  || Decoder Loss:  0.49239472 Validation Decoder Loss:  0.83518255
Encoder Loss:  0.053548247  || Decoder Loss:  0.46270874 Validation Decoder Loss:  0.6529012
Encoder Loss:  0.05260168  || Decoder Loss:  0.451786 Validation Decoder Loss:  0.5027955
Encoder Loss:  0.05444753  || Decoder Loss:  0.4749636 Validation Decoder Loss:  0.5667207
Encoder Loss:  0.051692862  || Decoder Loss:  0.1311195 Validation Decoder Loss:  0.4424909
Encoder Loss:  0.050902534  || Decoder Loss:  0.054001182 Validation Decoder Loss:  0.324776
Encoder Loss:  0.051335517  || Decoder Loss:  0.050853435 Validation Decoder Loss:  0.36017007
Encoder Loss:  0.053168308  || Decoder Loss:  0.05310037 Validation Decoder Loss:  0.33429903
Encoder Loss:  0.05423912  || Decoder Loss:  0.05389144 Validation Decoder Loss:  0.3598698
Encoder Loss:  0.053824387  || Decoder Loss:  0.05210895 Validation Decoder Loss:  0.35915977
Encoder Loss:  0.051527094  || Decoder Loss:  0.051384024 Validation Decoder Loss:  0.3592329
Encoder Loss:  0.052298103  || Decoder Loss:  0.05206781 Validation Decoder Loss:  0.3623229
Encoder Loss:  0.05123838  || Decoder Loss:  0.051016517 Validation Decoder Loss:  0.3581624
Encoder Loss:  0.051119857  || Decoder Loss:  0.050874066 Validation Decoder Loss:  0.35572848
Encoder Loss:  0.050903797  || Decoder Loss:  0.051074147 Validation Decoder Loss:  0.35730597
Encoder Loss:  0.05145439  || Decoder Loss:  0.050855864 Validation Decoder Loss:  0.35342774
Encoder Loss:  0.0511417  || Decoder Loss:  0.050758928 Validation Decoder Loss:  0.36094755
Encoder Loss:  0.05103691  || Decoder Loss:  0.05034191 Validation Decoder Loss:  0.37024882
Encoder Loss:  0.0508344  || Decoder Loss:  0.04979633 Validation Decoder Loss:  0.36261797
Encoder Loss:  0.05134388  || Decoder Loss:  0.04965295 Validation Decoder Loss:  0.3687744
Encoder Loss:  0.051477395  || Decoder Loss:  0.049456477 Validation Decoder Loss:  0.35654137
Encoder Loss:  0.05054186  || Decoder Loss:  0.04965044 Validation Decoder Loss:  0.3578236
Encoder Loss:  0.05072469  || Decoder Loss:  0.049734913 Validation Decoder Loss:  0.35585806
Encoder Loss:  0.05049317  || Decoder Loss:  0.04966136 Validation Decoder Loss:  0.36639684
Encoder Loss:  0.050764356  || Decoder Loss:  0.04948294 Validation Decoder Loss:  0.35602802
Encoder Loss:  0.05051647  || Decoder Loss:  0.0492668 Validation Decoder Loss:  0.35521492
Encoder Loss:  0.050439693  || Decoder Loss:  0.04959573 Validation Decoder Loss:  0.3630576
Encoder Loss:  0.051219124  || Decoder Loss:  0.04943276 Validation Decoder Loss:  0.3639351
Encoder Loss:  0.05088152  || Decoder Loss:  0.048911594 Validation Decoder Loss:  0.35711905
Encoder Loss:  0.050972905  || Decoder Loss:  0.048569012 Validation Decoder Loss:  0.35121
Encoder Loss:  0.050862506  || Decoder Loss:  0.04946946 Validation Decoder Loss:  0.36332992
Encoder Loss:  0.05063368  || Decoder Loss:  0.048596013 Validation Decoder Loss:  0.3540043
Encoder Loss:  0.05080404  || Decoder Loss:  0.048755888 Validation Decoder Loss:  0.35657728
Encoder Loss:  0.05069567  || Decoder Loss:  0.049114153 Validation Decoder Loss:  0.35262144
Encoder Loss:  0.050669517  || Decoder Loss:  0.04895623 Validation Decoder Loss:  0.35789347
Model: siamese_net_lr_0.045215864710910575 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35789347
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_284 (Conv3D (None, 132, 5, 20, 1)     7         
_________________________________________________________________
dropout_597 (Dropout)        (None, 132, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_285 (Conv3D (None, 184, 5, 20, 1)     54        
_________________________________________________________________
reshape_165 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 3040, 20, 1)       207       
_________________________________________________________________
dropout_599 (Dropout)        (None, 3040, 20, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 920, 20, 1)        284       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 2800, 20, 1)       44        
_________________________________________________________________
dropout_601 (Dropout)        (None, 2800, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 3245, 20, 1)       447       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14366683  || Decoder Loss:  0.12180393 Validation Decoder Loss:  0.3007881
Encoder Loss:  0.049724463  || Decoder Loss:  0.044318657 Validation Decoder Loss:  0.35309267
Encoder Loss:  0.04209079  || Decoder Loss:  0.04003741 Validation Decoder Loss:  0.33090776
Encoder Loss:  0.04203339  || Decoder Loss:  0.039054446 Validation Decoder Loss:  0.32147694
Encoder Loss:  0.04318798  || Decoder Loss:  0.03899069 Validation Decoder Loss:  0.3032056
Encoder Loss:  0.045179334  || Decoder Loss:  0.041078605 Validation Decoder Loss:  0.36173835
Encoder Loss:  0.041358333  || Decoder Loss:  0.038576525 Validation Decoder Loss:  0.29080936
Encoder Loss:  0.040012285  || Decoder Loss:  0.037577685 Validation Decoder Loss:  0.30733794
Encoder Loss:  0.04024677  || Decoder Loss:  0.03739025 Validation Decoder Loss:  0.30769354
Encoder Loss:  0.040102124  || Decoder Loss:  0.036857355 Validation Decoder Loss:  0.2892269
Encoder Loss:  0.0396467  || Decoder Loss:  0.03708662 Validation Decoder Loss:  0.31306437
Encoder Loss:  0.039145157  || Decoder Loss:  0.036394823 Validation Decoder Loss:  0.29146853
Encoder Loss:  0.03898899  || Decoder Loss:  0.0363898 Validation Decoder Loss:  0.29302058
Encoder Loss:  0.040535633  || Decoder Loss:  0.036295928 Validation Decoder Loss:  0.28318226
Encoder Loss:  0.041081104  || Decoder Loss:  0.038116686 Validation Decoder Loss:  0.3089458
Encoder Loss:  0.037804782  || Decoder Loss:  0.035448655 Validation Decoder Loss:  0.2898231
Encoder Loss:  0.038825285  || Decoder Loss:  0.035658862 Validation Decoder Loss:  0.30530092
Encoder Loss:  0.03985596  || Decoder Loss:  0.03680197 Validation Decoder Loss:  0.30416802
Encoder Loss:  0.03889035  || Decoder Loss:  0.035790704 Validation Decoder Loss:  0.28221786
Encoder Loss:  0.039134458  || Decoder Loss:  0.035641998 Validation Decoder Loss:  0.30844164
Encoder Loss:  0.038857296  || Decoder Loss:  0.036420546 Validation Decoder Loss:  0.2914116
Encoder Loss:  0.038694195  || Decoder Loss:  0.035763953 Validation Decoder Loss:  0.29765296
Encoder Loss:  0.03821428  || Decoder Loss:  0.03544426 Validation Decoder Loss:  0.306763
Encoder Loss:  0.037316453  || Decoder Loss:  0.034791227 Validation Decoder Loss:  0.29418463
Encoder Loss:  0.037290026  || Decoder Loss:  0.034711584 Validation Decoder Loss:  0.30088103
Encoder Loss:  0.03735516  || Decoder Loss:  0.03470209 Validation Decoder Loss:  0.2974057
Encoder Loss:  0.037381552  || Decoder Loss:  0.03494601 Validation Decoder Loss:  0.2959407
Encoder Loss:  0.037259378  || Decoder Loss:  0.034633685 Validation Decoder Loss:  0.29504836
Encoder Loss:  0.037565064  || Decoder Loss:  0.034623336 Validation Decoder Loss:  0.30384615
Encoder Loss:  0.037290905  || Decoder Loss:  0.034897186 Validation Decoder Loss:  0.29842716
Encoder Loss:  0.036903888  || Decoder Loss:  0.034489114 Validation Decoder Loss:  0.29960096
Encoder Loss:  0.03695284  || Decoder Loss:  0.034264993 Validation Decoder Loss:  0.29956734
Encoder Loss:  0.036755525  || Decoder Loss:  0.034265757 Validation Decoder Loss:  0.2997244
Encoder Loss:  0.03793175  || Decoder Loss:  0.03451667 Validation Decoder Loss:  0.29836953
Encoder Loss:  0.038092718  || Decoder Loss:  0.03519726 Validation Decoder Loss:  0.28880763
Encoder Loss:  0.03741083  || Decoder Loss:  0.03460813 Validation Decoder Loss:  0.29431295
Encoder Loss:  0.037053384  || Decoder Loss:  0.034588892 Validation Decoder Loss:  0.29623482
Encoder Loss:  0.03662671  || Decoder Loss:  0.03409328 Validation Decoder Loss:  0.3011366
Encoder Loss:  0.03647174  || Decoder Loss:  0.03394442 Validation Decoder Loss:  0.30014917
Encoder Loss:  0.036586493  || Decoder Loss:  0.03401762 Validation Decoder Loss:  0.29831874
Model: siamese_net_lr_0.03182775979024825 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.29831874
Model: "sequential_558"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_287 (Conv3D (None, 156, 5, 20, 1)     94        
_________________________________________________________________
dropout_603 (Dropout)        (None, 156, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_288 (Conv3D (None, 184, 5, 20, 1)     30        
_________________________________________________________________
reshape_166 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 1620, 20, 1)       1627      
_________________________________________________________________
dropout_605 (Dropout)        (None, 1620, 20, 1)       0         
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 920, 20, 1)        702       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 2870, 20, 1)       1952      
_________________________________________________________________
dropout_607 (Dropout)        (None, 2870, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 3245, 20, 1)       377       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4795493  || Decoder Loss:  0.5059164 Validation Decoder Loss:  0.42501315
Encoder Loss:  0.23324734  || Decoder Loss:  0.22606777 Validation Decoder Loss:  1.6906252
Encoder Loss:  0.39661625  || Decoder Loss:  0.43024075 Validation Decoder Loss:  1.5838761
Encoder Loss:  0.20795678  || Decoder Loss:  0.20541534 Validation Decoder Loss:  0.44909137
Encoder Loss:  0.108301096  || Decoder Loss:  0.110969916 Validation Decoder Loss:  0.39578193
Encoder Loss:  0.044095982  || Decoder Loss:  0.038999937 Validation Decoder Loss:  0.35438603
Encoder Loss:  0.040464923  || Decoder Loss:  0.03531229 Validation Decoder Loss:  0.3412672
Encoder Loss:  0.03934605  || Decoder Loss:  0.03439318 Validation Decoder Loss:  0.34680152
Encoder Loss:  0.038758114  || Decoder Loss:  0.034014355 Validation Decoder Loss:  0.34561455
Encoder Loss:  0.041451  || Decoder Loss:  0.03408605 Validation Decoder Loss:  0.35731143
Encoder Loss:  0.041998416  || Decoder Loss:  0.034396905 Validation Decoder Loss:  0.34868607
Encoder Loss:  0.03880408  || Decoder Loss:  0.03401075 Validation Decoder Loss:  0.36104006
Encoder Loss:  0.03990345  || Decoder Loss:  0.036201544 Validation Decoder Loss:  0.36249065
Encoder Loss:  0.04055136  || Decoder Loss:  0.037409298 Validation Decoder Loss:  0.3462016
Encoder Loss:  0.039595835  || Decoder Loss:  0.03473691 Validation Decoder Loss:  0.36034787
Encoder Loss:  0.041547757  || Decoder Loss:  0.037801206 Validation Decoder Loss:  0.34739572
Encoder Loss:  0.04017918  || Decoder Loss:  0.03661803 Validation Decoder Loss:  0.37461704
Encoder Loss:  0.042225648  || Decoder Loss:  0.037105154 Validation Decoder Loss:  0.36300194
Encoder Loss:  0.04332449  || Decoder Loss:  0.03863487 Validation Decoder Loss:  0.3454893
Encoder Loss:  0.042327546  || Decoder Loss:  0.03793626 Validation Decoder Loss:  0.37022024
Encoder Loss:  0.038222317  || Decoder Loss:  0.033884905 Validation Decoder Loss:  0.36211938
Encoder Loss:  0.03918733  || Decoder Loss:  0.034818407 Validation Decoder Loss:  0.3359105
Encoder Loss:  0.040619835  || Decoder Loss:  0.03735881 Validation Decoder Loss:  0.37470698
Encoder Loss:  0.03884382  || Decoder Loss:  0.035119936 Validation Decoder Loss:  0.3443854
Encoder Loss:  0.03604929  || Decoder Loss:  0.032263864 Validation Decoder Loss:  0.36433184
Encoder Loss:  0.03695944  || Decoder Loss:  0.032793447 Validation Decoder Loss:  0.3853853
Encoder Loss:  0.03970098  || Decoder Loss:  0.035912145 Validation Decoder Loss:  0.33649135
Encoder Loss:  0.0389142  || Decoder Loss:  0.034447547 Validation Decoder Loss:  0.34974107
Encoder Loss:  0.040188063  || Decoder Loss:  0.03564747 Validation Decoder Loss:  0.3447165
Encoder Loss:  0.038340088  || Decoder Loss:  0.03441552 Validation Decoder Loss:  0.35565704
Encoder Loss:  0.041028127  || Decoder Loss:  0.03583018 Validation Decoder Loss:  0.36860526
Encoder Loss:  0.04039526  || Decoder Loss:  0.036870584 Validation Decoder Loss:  0.33497083
Encoder Loss:  0.03809402  || Decoder Loss:  0.033648737 Validation Decoder Loss:  0.34389076
Encoder Loss:  0.03789295  || Decoder Loss:  0.031879984 Validation Decoder Loss:  0.33440244
Encoder Loss:  0.035039354  || Decoder Loss:  0.03130175 Validation Decoder Loss:  0.34651434
Encoder Loss:  0.035669908  || Decoder Loss:  0.032036744 Validation Decoder Loss:  0.3441733
Encoder Loss:  0.035658594  || Decoder Loss:  0.03198641 Validation Decoder Loss:  0.34886184
Encoder Loss:  0.035390273  || Decoder Loss:  0.031866185 Validation Decoder Loss:  0.35594666
Encoder Loss:  0.03738953  || Decoder Loss:  0.033402737 Validation Decoder Loss:  0.33154565
Encoder Loss:  0.037010044  || Decoder Loss:  0.032921396 Validation Decoder Loss:  0.35364667
Model: siamese_net_lr_0.00883525365258565 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35364667
Model: "sequential_562"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_290 (Conv3D (None, 180, 5, 20, 1)     55        
_________________________________________________________________
dropout_609 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_291 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_167 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 1160, 20, 1)       2087      
_________________________________________________________________
dropout_611 (Dropout)        (None, 1160, 20, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 920, 20, 1)        242       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 2080, 20, 1)       243       
_________________________________________________________________
dropout_613 (Dropout)        (None, 2080, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 3245, 20, 1)       1167      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25756568  || Decoder Loss:  0.13481414 Validation Decoder Loss:  0.3770534
Encoder Loss:  0.4967476  || Decoder Loss:  0.56702983 Validation Decoder Loss:  1.6364361
Encoder Loss:  0.42157143  || Decoder Loss:  0.5746083 Validation Decoder Loss:  1.6297815
Encoder Loss:  0.4776175  || Decoder Loss:  0.62448895 Validation Decoder Loss:  0.38423526
Encoder Loss:  0.2690252  || Decoder Loss:  0.18551041 Validation Decoder Loss:  1.5919787
Encoder Loss:  0.3786847  || Decoder Loss:  0.5276783 Validation Decoder Loss:  1.113766
Encoder Loss:  0.33226678  || Decoder Loss:  0.5175236 Validation Decoder Loss:  0.8235426
Encoder Loss:  0.3274318  || Decoder Loss:  0.49521512 Validation Decoder Loss:  0.7934921
Encoder Loss:  0.32859287  || Decoder Loss:  0.496935 Validation Decoder Loss:  0.80342805
Encoder Loss:  0.3242046  || Decoder Loss:  0.4893793 Validation Decoder Loss:  0.685108
Encoder Loss:  0.3268378  || Decoder Loss:  0.49686632 Validation Decoder Loss:  0.8173094
Encoder Loss:  0.31867167  || Decoder Loss:  0.48531073 Validation Decoder Loss:  0.7563168
Encoder Loss:  0.32001826  || Decoder Loss:  0.48717707 Validation Decoder Loss:  0.7945759
Encoder Loss:  0.32117  || Decoder Loss:  0.4888536 Validation Decoder Loss:  0.82558584
Encoder Loss:  0.31790632  || Decoder Loss:  0.48394248 Validation Decoder Loss:  0.802845
Encoder Loss:  0.32042545  || Decoder Loss:  0.4878825 Validation Decoder Loss:  0.76099795
Encoder Loss:  0.3218602  || Decoder Loss:  0.4919665 Validation Decoder Loss:  0.7171259
Encoder Loss:  0.32213295  || Decoder Loss:  0.4914569 Validation Decoder Loss:  0.7262839
Encoder Loss:  0.31852093  || Decoder Loss:  0.4871251 Validation Decoder Loss:  0.73068744
Encoder Loss:  0.32348725  || Decoder Loss:  0.49388173 Validation Decoder Loss:  0.68109167
Encoder Loss:  0.31611812  || Decoder Loss:  0.48129386 Validation Decoder Loss:  0.75992405
Encoder Loss:  0.32048115  || Decoder Loss:  0.49139747 Validation Decoder Loss:  0.7599726
Encoder Loss:  0.32601193  || Decoder Loss:  0.50009966 Validation Decoder Loss:  0.7608837
Encoder Loss:  0.3231404  || Decoder Loss:  0.49505723 Validation Decoder Loss:  0.7250385
Encoder Loss:  0.31899184  || Decoder Loss:  0.4873653 Validation Decoder Loss:  0.7801314
Encoder Loss:  0.32101455  || Decoder Loss:  0.49316865 Validation Decoder Loss:  0.7915876
Encoder Loss:  0.31927976  || Decoder Loss:  0.4899304 Validation Decoder Loss:  0.81556845
Encoder Loss:  0.3265471  || Decoder Loss:  0.5024226 Validation Decoder Loss:  0.786436
Encoder Loss:  0.3231584  || Decoder Loss:  0.49732605 Validation Decoder Loss:  0.7126899
Encoder Loss:  0.31809735  || Decoder Loss:  0.48693207 Validation Decoder Loss:  0.73775035
Encoder Loss:  0.31746864  || Decoder Loss:  0.48589334 Validation Decoder Loss:  0.7999985
Encoder Loss:  0.3180896  || Decoder Loss:  0.48940524 Validation Decoder Loss:  0.69954956
Encoder Loss:  0.30847836  || Decoder Loss:  0.46724635 Validation Decoder Loss:  0.8737747
Encoder Loss:  0.32299644  || Decoder Loss:  0.49965084 Validation Decoder Loss:  0.7422718
Encoder Loss:  0.32272568  || Decoder Loss:  0.49624383 Validation Decoder Loss:  0.8074153
Encoder Loss:  0.3194246  || Decoder Loss:  0.49266723 Validation Decoder Loss:  0.76282865
Encoder Loss:  0.3219425  || Decoder Loss:  0.4942284 Validation Decoder Loss:  0.81317514
Encoder Loss:  0.3200666  || Decoder Loss:  0.49483722 Validation Decoder Loss:  0.7545464
Encoder Loss:  0.32297912  || Decoder Loss:  0.49711394 Validation Decoder Loss:  0.7861775
Encoder Loss:  0.3204181  || Decoder Loss:  0.49420947 Validation Decoder Loss:  0.71964663
Model: siamese_net_lr_0.0766761653723908 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.71964663
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_293 (Conv3D (None, 150, 5, 20, 1)     25        
_________________________________________________________________
dropout_615 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_294 (Conv3D (None, 184, 5, 20, 1)     36        
_________________________________________________________________
reshape_168 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 1610, 20, 1)       28        
_________________________________________________________________
dropout_617 (Dropout)        (None, 1610, 20, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 920, 20, 1)        692       
=================================================================
Total params: 720
Trainable params: 720
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_569"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 2850, 20, 1)       94        
_________________________________________________________________
dropout_619 (Dropout)        (None, 2850, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 3245, 20, 1)       397       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1446465  || Decoder Loss:  0.056930084 Validation Decoder Loss:  0.3032075
Encoder Loss:  0.09682593  || Decoder Loss:  0.04714835 Validation Decoder Loss:  0.4585383
Encoder Loss:  0.065299876  || Decoder Loss:  0.036403067 Validation Decoder Loss:  0.32949847
Encoder Loss:  0.04661479  || Decoder Loss:  0.032903455 Validation Decoder Loss:  0.3281063
Encoder Loss:  0.06745808  || Decoder Loss:  0.05989969 Validation Decoder Loss:  0.6863016
Encoder Loss:  0.060691543  || Decoder Loss:  0.06266477 Validation Decoder Loss:  0.34910962
Encoder Loss:  0.045917977  || Decoder Loss:  0.035674933 Validation Decoder Loss:  0.3461337
Encoder Loss:  0.04657813  || Decoder Loss:  0.033408877 Validation Decoder Loss:  0.33732364
Encoder Loss:  0.043638147  || Decoder Loss:  0.03214094 Validation Decoder Loss:  0.3432874
Encoder Loss:  0.040824942  || Decoder Loss:  0.03130429 Validation Decoder Loss:  0.33571663
Encoder Loss:  0.04406956  || Decoder Loss:  0.032291993 Validation Decoder Loss:  0.33271134
Encoder Loss:  0.042911597  || Decoder Loss:  0.031859983 Validation Decoder Loss:  0.35226896
Encoder Loss:  0.045614053  || Decoder Loss:  0.03525332 Validation Decoder Loss:  0.29815403
Encoder Loss:  0.0516082  || Decoder Loss:  0.03820602 Validation Decoder Loss:  0.30359584
Encoder Loss:  0.043558046  || Decoder Loss:  0.032185104 Validation Decoder Loss:  0.34102494
Encoder Loss:  0.04091689  || Decoder Loss:  0.031227268 Validation Decoder Loss:  0.33822873
Encoder Loss:  0.043110188  || Decoder Loss:  0.03334586 Validation Decoder Loss:  0.3248452
Encoder Loss:  0.049528938  || Decoder Loss:  0.0435563 Validation Decoder Loss:  0.37041318
Encoder Loss:  0.045713175  || Decoder Loss:  0.031596042 Validation Decoder Loss:  0.32628894
Encoder Loss:  0.04672352  || Decoder Loss:  0.031218935 Validation Decoder Loss:  0.34817737
Encoder Loss:  0.08455725  || Decoder Loss:  0.098042704 Validation Decoder Loss:  0.63742596
Encoder Loss:  0.094614394  || Decoder Loss:  0.11430847 Validation Decoder Loss:  0.28782305
Encoder Loss:  0.07356565  || Decoder Loss:  0.08299344 Validation Decoder Loss:  0.49873638
Encoder Loss:  0.048682097  || Decoder Loss:  0.042291153 Validation Decoder Loss:  0.30531505
Encoder Loss:  0.044078313  || Decoder Loss:  0.03634347 Validation Decoder Loss:  0.3316025
Encoder Loss:  0.043881048  || Decoder Loss:  0.035686232 Validation Decoder Loss:  0.3356238
Encoder Loss:  0.04460548  || Decoder Loss:  0.035563685 Validation Decoder Loss:  0.3338489
Encoder Loss:  0.051553857  || Decoder Loss:  0.035536315 Validation Decoder Loss:  0.33345938
Encoder Loss:  0.0515262  || Decoder Loss:  0.035492793 Validation Decoder Loss:  0.3391205
Encoder Loss:  0.045787767  || Decoder Loss:  0.03541552 Validation Decoder Loss:  0.34214628
Encoder Loss:  0.048933372  || Decoder Loss:  0.03533244 Validation Decoder Loss:  0.33946165
Encoder Loss:  0.04339604  || Decoder Loss:  0.035287887 Validation Decoder Loss:  0.3402997
Encoder Loss:  0.043834955  || Decoder Loss:  0.03521861 Validation Decoder Loss:  0.33900422
Encoder Loss:  0.045266803  || Decoder Loss:  0.03515828 Validation Decoder Loss:  0.33974332
Encoder Loss:  0.04220663  || Decoder Loss:  0.03509916 Validation Decoder Loss:  0.33955896
Encoder Loss:  0.044201937  || Decoder Loss:  0.035011552 Validation Decoder Loss:  0.3392195
Encoder Loss:  0.042852405  || Decoder Loss:  0.03493788 Validation Decoder Loss:  0.33848363
Encoder Loss:  0.04409114  || Decoder Loss:  0.034855165 Validation Decoder Loss:  0.3396976
Encoder Loss:  0.04185901  || Decoder Loss:  0.034777228 Validation Decoder Loss:  0.3418458
Encoder Loss:  0.04321516  || Decoder Loss:  0.034671888 Validation Decoder Loss:  0.34146243
Model: siamese_net_lr_0.02003427397271811 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34146243
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_296 (Conv3D (None, 164, 5, 20, 1)     102       
_________________________________________________________________
dropout_621 (Dropout)        (None, 164, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_297 (Conv3D (None, 184, 5, 20, 1)     22        
_________________________________________________________________
reshape_169 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 1830, 20, 1)       1417      
_________________________________________________________________
dropout_623 (Dropout)        (None, 1830, 20, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 920, 20, 1)        912       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 2510, 20, 1)       673       
_________________________________________________________________
dropout_625 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 3245, 20, 1)       737       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.252067  || Decoder Loss:  0.14698225 Validation Decoder Loss:  0.37740776
Encoder Loss:  0.25223613  || Decoder Loss:  0.117074944 Validation Decoder Loss:  0.37483576
Encoder Loss:  0.25299543  || Decoder Loss:  0.12396663 Validation Decoder Loss:  0.37169445
Encoder Loss:  0.23282397  || Decoder Loss:  0.112461865 Validation Decoder Loss:  0.49453276
Encoder Loss:  0.3181534  || Decoder Loss:  0.47447082 Validation Decoder Loss:  1.2285743
Encoder Loss:  0.30328855  || Decoder Loss:  0.46837872 Validation Decoder Loss:  1.1791018
Encoder Loss:  0.29924193  || Decoder Loss:  0.4665223 Validation Decoder Loss:  1.1596909
Encoder Loss:  0.3010808  || Decoder Loss:  0.47048974 Validation Decoder Loss:  1.1730355
Encoder Loss:  0.3006449  || Decoder Loss:  0.4693388 Validation Decoder Loss:  1.2494736
Encoder Loss:  0.3084076  || Decoder Loss:  0.4862441 Validation Decoder Loss:  1.146536
Encoder Loss:  0.29715124  || Decoder Loss:  0.46762288 Validation Decoder Loss:  1.0754293
Encoder Loss:  0.29785267  || Decoder Loss:  0.47065964 Validation Decoder Loss:  1.1164507
Encoder Loss:  0.29774895  || Decoder Loss:  0.47043353 Validation Decoder Loss:  1.1729844
Encoder Loss:  0.29550883  || Decoder Loss:  0.4694657 Validation Decoder Loss:  0.9796985
Encoder Loss:  0.30127144  || Decoder Loss:  0.47989652 Validation Decoder Loss:  1.0389576
Encoder Loss:  0.291467  || Decoder Loss:  0.47004077 Validation Decoder Loss:  1.041306
Encoder Loss:  0.29400328  || Decoder Loss:  0.47056556 Validation Decoder Loss:  0.8847467
Encoder Loss:  0.28681415  || Decoder Loss:  0.46499664 Validation Decoder Loss:  0.94516844
Encoder Loss:  0.30145675  || Decoder Loss:  0.48444614 Validation Decoder Loss:  0.9271619
Encoder Loss:  0.292155  || Decoder Loss:  0.46927577 Validation Decoder Loss:  0.79333067
Encoder Loss:  0.2930396  || Decoder Loss:  0.4745591 Validation Decoder Loss:  0.84560394
Encoder Loss:  0.29491398  || Decoder Loss:  0.47392955 Validation Decoder Loss:  0.9081514
Encoder Loss:  0.29840794  || Decoder Loss:  0.4821154 Validation Decoder Loss:  0.9116157
Encoder Loss:  0.29275438  || Decoder Loss:  0.46330196 Validation Decoder Loss:  0.78913045
Encoder Loss:  0.28973967  || Decoder Loss:  0.4693516 Validation Decoder Loss:  0.7238122
Encoder Loss:  0.27920935  || Decoder Loss:  0.4569482 Validation Decoder Loss:  0.65163076
Encoder Loss:  0.24453956  || Decoder Loss:  0.385743 Validation Decoder Loss:  1.1308383
Encoder Loss:  0.28191352  || Decoder Loss:  0.44726995 Validation Decoder Loss:  0.8687999
Encoder Loss:  0.23016581  || Decoder Loss:  0.36553004 Validation Decoder Loss:  0.96034324
Encoder Loss:  0.27133787  || Decoder Loss:  0.4433289 Validation Decoder Loss:  0.5889556
Encoder Loss:  0.286988  || Decoder Loss:  0.4669585 Validation Decoder Loss:  0.5743039
Encoder Loss:  0.26502004  || Decoder Loss:  0.42521226 Validation Decoder Loss:  0.72778815
Encoder Loss:  0.15310146  || Decoder Loss:  0.22935164 Validation Decoder Loss:  0.6191694
Encoder Loss:  0.108461894  || Decoder Loss:  0.14469004 Validation Decoder Loss:  0.47338283
Encoder Loss:  0.07120041  || Decoder Loss:  0.08342205 Validation Decoder Loss:  0.3189878
Encoder Loss:  0.10578796  || Decoder Loss:  0.13690524 Validation Decoder Loss:  0.3425883
Encoder Loss:  0.15189716  || Decoder Loss:  0.22292279 Validation Decoder Loss:  0.32244456
Encoder Loss:  0.09472342  || Decoder Loss:  0.122605294 Validation Decoder Loss:  0.45262617
Encoder Loss:  0.05794907  || Decoder Loss:  0.053657174 Validation Decoder Loss:  0.3560152
Encoder Loss:  0.052351937  || Decoder Loss:  0.0467603 Validation Decoder Loss:  0.35444057
Model: siamese_net_lr_0.04076919475368912 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35444057
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_299 (Conv3D (None, 178, 5, 20, 1)     53        
_________________________________________________________________
dropout_627 (Dropout)        (None, 178, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_300 (Conv3D (None, 184, 5, 20, 1)     8         
_________________________________________________________________
reshape_170 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 980, 20, 1)        309       
_________________________________________________________________
dropout_629 (Dropout)        (None, 980, 20, 1)        0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 920, 20, 1)        62        
=================================================================
Total params: 371
Trainable params: 371
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 2680, 20, 1)       1762      
_________________________________________________________________
dropout_631 (Dropout)        (None, 2680, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 3245, 20, 1)       567       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23404607  || Decoder Loss:  0.36280602 Validation Decoder Loss:  1.5795571
Encoder Loss:  0.21599592  || Decoder Loss:  0.4928544 Validation Decoder Loss:  0.3545275
Encoder Loss:  0.1979086  || Decoder Loss:  0.49866712 Validation Decoder Loss:  1.5218586
Encoder Loss:  0.18606338  || Decoder Loss:  0.4640515 Validation Decoder Loss:  0.34499872
Encoder Loss:  0.18118823  || Decoder Loss:  0.43713033 Validation Decoder Loss:  0.37430507
Encoder Loss:  0.19205877  || Decoder Loss:  0.47665855 Validation Decoder Loss:  1.4782482
Encoder Loss:  0.1683484  || Decoder Loss:  0.4073535 Validation Decoder Loss:  1.4068141
Encoder Loss:  0.18066402  || Decoder Loss:  0.44110027 Validation Decoder Loss:  0.4824441
Encoder Loss:  0.19041777  || Decoder Loss:  0.4748021 Validation Decoder Loss:  0.90756124
Encoder Loss:  0.17111275  || Decoder Loss:  0.4126769 Validation Decoder Loss:  0.62570477
Encoder Loss:  0.19305295  || Decoder Loss:  0.47559634 Validation Decoder Loss:  0.4494153
Encoder Loss:  0.16395883  || Decoder Loss:  0.40007427 Validation Decoder Loss:  1.2824478
Encoder Loss:  0.16390319  || Decoder Loss:  0.40279657 Validation Decoder Loss:  1.2240658
Encoder Loss:  0.17461102  || Decoder Loss:  0.43977615 Validation Decoder Loss:  1.0316846
Encoder Loss:  0.19300726  || Decoder Loss:  0.49727648 Validation Decoder Loss:  0.97018725
Encoder Loss:  0.19257942  || Decoder Loss:  0.49607 Validation Decoder Loss:  0.97503245
Encoder Loss:  0.19081196  || Decoder Loss:  0.49021515 Validation Decoder Loss:  1.0550301
Encoder Loss:  0.19297162  || Decoder Loss:  0.4977184 Validation Decoder Loss:  1.0051131
Encoder Loss:  0.19059667  || Decoder Loss:  0.4919746 Validation Decoder Loss:  1.0078948
Encoder Loss:  0.18900682  || Decoder Loss:  0.48713163 Validation Decoder Loss:  0.97508013
Encoder Loss:  0.18359476  || Decoder Loss:  0.46820936 Validation Decoder Loss:  1.3815237
Encoder Loss:  0.20329735  || Decoder Loss:  0.53093404 Validation Decoder Loss:  0.993207
Encoder Loss:  0.17929256  || Decoder Loss:  0.45618427 Validation Decoder Loss:  0.8860823
Encoder Loss:  0.18885495  || Decoder Loss:  0.48503426 Validation Decoder Loss:  0.97897136
Encoder Loss:  0.19424376  || Decoder Loss:  0.502619 Validation Decoder Loss:  0.98231995
Encoder Loss:  0.1939824  || Decoder Loss:  0.5019142 Validation Decoder Loss:  0.97822773
Encoder Loss:  0.19316031  || Decoder Loss:  0.5006136 Validation Decoder Loss:  0.9893004
Encoder Loss:  0.19310993  || Decoder Loss:  0.50079924 Validation Decoder Loss:  0.9794884
Encoder Loss:  0.19200829  || Decoder Loss:  0.49639386 Validation Decoder Loss:  1.0270078
Encoder Loss:  0.19304684  || Decoder Loss:  0.49673513 Validation Decoder Loss:  1.0116706
Encoder Loss:  0.19089201  || Decoder Loss:  0.4935256 Validation Decoder Loss:  0.9909698
Encoder Loss:  0.18968698  || Decoder Loss:  0.48991174 Validation Decoder Loss:  0.9810743
Encoder Loss:  0.189654  || Decoder Loss:  0.4900315 Validation Decoder Loss:  1.0095026
Encoder Loss:  0.1897387  || Decoder Loss:  0.48895493 Validation Decoder Loss:  1.0444597
Encoder Loss:  0.18978657  || Decoder Loss:  0.4896154 Validation Decoder Loss:  0.9609149
Encoder Loss:  0.1835977  || Decoder Loss:  0.4706508 Validation Decoder Loss:  0.9779736
Encoder Loss:  0.19198565  || Decoder Loss:  0.4967571 Validation Decoder Loss:  0.97080827
Encoder Loss:  0.18645695  || Decoder Loss:  0.47925892 Validation Decoder Loss:  1.0370636
Encoder Loss:  0.18502851  || Decoder Loss:  0.4752169 Validation Decoder Loss:  0.9646754
Encoder Loss:  0.19315366  || Decoder Loss:  0.49975082 Validation Decoder Loss:  0.9616139
Model: siamese_net_lr_0.058863762571225116 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9616139
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_302 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_633 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_303 (Conv3D (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_171 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 2280, 20, 1)       967       
_________________________________________________________________
dropout_635 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 920, 20, 1)        1362      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 1080, 20, 1)       162       
_________________________________________________________________
dropout_637 (Dropout)        (None, 1080, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 3245, 20, 1)       9         
=================================================================
Total params: 171
Trainable params: 171
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14377269  || Decoder Loss:  0.079586074 Validation Decoder Loss:  0.37662154
Encoder Loss:  0.051373973  || Decoder Loss:  0.03882157 Validation Decoder Loss:  0.3507622
Encoder Loss:  0.045812245  || Decoder Loss:  0.034460105 Validation Decoder Loss:  0.34567344
Encoder Loss:  0.046720732  || Decoder Loss:  0.034072783 Validation Decoder Loss:  0.34781379
Encoder Loss:  0.04729905  || Decoder Loss:  0.033955246 Validation Decoder Loss:  0.34732017
Encoder Loss:  0.045978803  || Decoder Loss:  0.03386681 Validation Decoder Loss:  0.3478545
Encoder Loss:  0.04594691  || Decoder Loss:  0.033785906 Validation Decoder Loss:  0.34792683
Encoder Loss:  0.045883328  || Decoder Loss:  0.033708375 Validation Decoder Loss:  0.34800535
Encoder Loss:  0.045766372  || Decoder Loss:  0.033631638 Validation Decoder Loss:  0.34835973
Encoder Loss:  0.045832805  || Decoder Loss:  0.033557836 Validation Decoder Loss:  0.3484032
Encoder Loss:  0.045335785  || Decoder Loss:  0.03350603 Validation Decoder Loss:  0.3490175
Encoder Loss:  0.045421362  || Decoder Loss:  0.0335819 Validation Decoder Loss:  0.34867063
Encoder Loss:  0.045222048  || Decoder Loss:  0.033486493 Validation Decoder Loss:  0.3488171
Encoder Loss:  0.045858745  || Decoder Loss:  0.033538274 Validation Decoder Loss:  0.348583
Encoder Loss:  0.049227472  || Decoder Loss:  0.033418026 Validation Decoder Loss:  0.3474635
Encoder Loss:  0.049240943  || Decoder Loss:  0.033650633 Validation Decoder Loss:  0.346619
Encoder Loss:  0.048667163  || Decoder Loss:  0.03320806 Validation Decoder Loss:  0.34718648
Encoder Loss:  0.048589606  || Decoder Loss:  0.03373163 Validation Decoder Loss:  0.3465828
Encoder Loss:  0.048131835  || Decoder Loss:  0.033107217 Validation Decoder Loss:  0.34739807
Encoder Loss:  0.048111275  || Decoder Loss:  0.033564147 Validation Decoder Loss:  0.34687817
Encoder Loss:  0.04549011  || Decoder Loss:  0.033032883 Validation Decoder Loss:  0.34802046
Encoder Loss:  0.045542642  || Decoder Loss:  0.033537634 Validation Decoder Loss:  0.3473094
Encoder Loss:  0.045888446  || Decoder Loss:  0.032988407 Validation Decoder Loss:  0.34764412
Encoder Loss:  0.045245603  || Decoder Loss:  0.03416623 Validation Decoder Loss:  0.34810662
Encoder Loss:  0.045555986  || Decoder Loss:  0.033262428 Validation Decoder Loss:  0.3463083
Encoder Loss:  0.047027707  || Decoder Loss:  0.03317629 Validation Decoder Loss:  0.35135877
Encoder Loss:  0.045976542  || Decoder Loss:  0.03325583 Validation Decoder Loss:  0.34765184
Encoder Loss:  0.045718666  || Decoder Loss:  0.032957718 Validation Decoder Loss:  0.34807152
Encoder Loss:  0.04470214  || Decoder Loss:  0.033487063 Validation Decoder Loss:  0.34806383
Encoder Loss:  0.045062292  || Decoder Loss:  0.03284733 Validation Decoder Loss:  0.34829038
Encoder Loss:  0.045248546  || Decoder Loss:  0.033940326 Validation Decoder Loss:  0.3480001
Encoder Loss:  0.044806074  || Decoder Loss:  0.032979168 Validation Decoder Loss:  0.3475113
Encoder Loss:  0.044874124  || Decoder Loss:  0.03362486 Validation Decoder Loss:  0.34918088
Encoder Loss:  0.04490354  || Decoder Loss:  0.03298728 Validation Decoder Loss:  0.34736603
Encoder Loss:  0.045689333  || Decoder Loss:  0.033081435 Validation Decoder Loss:  0.34926823
Encoder Loss:  0.044584636  || Decoder Loss:  0.03277109 Validation Decoder Loss:  0.3484435
Encoder Loss:  0.044831086  || Decoder Loss:  0.033212014 Validation Decoder Loss:  0.34870905
Encoder Loss:  0.044768516  || Decoder Loss:  0.032770637 Validation Decoder Loss:  0.34806067
Encoder Loss:  0.045338262  || Decoder Loss:  0.033637468 Validation Decoder Loss:  0.34827882
Encoder Loss:  0.045304283  || Decoder Loss:  0.03297947 Validation Decoder Loss:  0.3523425
Model: siamese_net_lr_0.008718344437780516 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3523425
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_305 (Conv3D (None, 158, 5, 20, 1)     33        
_________________________________________________________________
dropout_639 (Dropout)        (None, 158, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_306 (Conv3D (None, 184, 5, 20, 1)     28        
_________________________________________________________________
reshape_172 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 3030, 20, 1)       217       
_________________________________________________________________
dropout_641 (Dropout)        (None, 3030, 20, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 920, 20, 1)        274       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_585"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 3030, 20, 1)       274       
_________________________________________________________________
dropout_643 (Dropout)        (None, 3030, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 3245, 20, 1)       217       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3832734  || Decoder Loss:  0.3843179 Validation Decoder Loss:  0.40460145
Encoder Loss:  0.2083171  || Decoder Loss:  0.09025304 Validation Decoder Loss:  0.41307074
Encoder Loss:  0.40328526  || Decoder Loss:  0.42563972 Validation Decoder Loss:  0.6938908
Encoder Loss:  0.35362995  || Decoder Loss:  0.4419406 Validation Decoder Loss:  1.3247505
Encoder Loss:  0.33758962  || Decoder Loss:  0.40139163 Validation Decoder Loss:  1.3279011
Encoder Loss:  0.3455507  || Decoder Loss:  0.4636652 Validation Decoder Loss:  1.2589957
Encoder Loss:  0.348837  || Decoder Loss:  0.480375 Validation Decoder Loss:  1.0750782
Encoder Loss:  0.35069412  || Decoder Loss:  0.48497498 Validation Decoder Loss:  1.0579643
Encoder Loss:  0.33511382  || Decoder Loss:  0.46938524 Validation Decoder Loss:  1.0971909
Encoder Loss:  0.34998986  || Decoder Loss:  0.4853221 Validation Decoder Loss:  1.0464824
Encoder Loss:  0.3286655  || Decoder Loss:  0.46316746 Validation Decoder Loss:  1.1414372
Encoder Loss:  0.34159604  || Decoder Loss:  0.473432 Validation Decoder Loss:  1.0674787
Encoder Loss:  0.33097094  || Decoder Loss:  0.46800166 Validation Decoder Loss:  1.0898883
Encoder Loss:  0.32955444  || Decoder Loss:  0.4682106 Validation Decoder Loss:  1.2631007
Encoder Loss:  0.35362875  || Decoder Loss:  0.4745688 Validation Decoder Loss:  1.0328822
Encoder Loss:  0.3332246  || Decoder Loss:  0.47259316 Validation Decoder Loss:  1.2538635
Encoder Loss:  0.3388358  || Decoder Loss:  0.48013413 Validation Decoder Loss:  1.2827052
Encoder Loss:  0.33702195  || Decoder Loss:  0.4788141 Validation Decoder Loss:  1.3168353
Encoder Loss:  0.34025806  || Decoder Loss:  0.48659295 Validation Decoder Loss:  1.3211253
Encoder Loss:  0.33899474  || Decoder Loss:  0.4830096 Validation Decoder Loss:  1.3008215
Encoder Loss:  0.3435801  || Decoder Loss:  0.49583668 Validation Decoder Loss:  1.3258531
Encoder Loss:  0.34052765  || Decoder Loss:  0.49497455 Validation Decoder Loss:  1.3181565
Encoder Loss:  0.341464  || Decoder Loss:  0.49247268 Validation Decoder Loss:  1.2468324
Encoder Loss:  0.33810523  || Decoder Loss:  0.48994502 Validation Decoder Loss:  1.3422232
Encoder Loss:  0.33666912  || Decoder Loss:  0.49085525 Validation Decoder Loss:  1.3008903
Encoder Loss:  0.33388844  || Decoder Loss:  0.4913617 Validation Decoder Loss:  1.289505
Encoder Loss:  0.33381954  || Decoder Loss:  0.49226967 Validation Decoder Loss:  1.3456253
Encoder Loss:  0.33603755  || Decoder Loss:  0.4926977 Validation Decoder Loss:  1.3521539
Encoder Loss:  0.33849013  || Decoder Loss:  0.49429488 Validation Decoder Loss:  1.3616251
Encoder Loss:  0.33710584  || Decoder Loss:  0.49145457 Validation Decoder Loss:  1.3018459
Encoder Loss:  0.33931348  || Decoder Loss:  0.4981405 Validation Decoder Loss:  1.3215013
Encoder Loss:  0.33450145  || Decoder Loss:  0.49247643 Validation Decoder Loss:  1.2967948
Encoder Loss:  0.3376756  || Decoder Loss:  0.49467784 Validation Decoder Loss:  1.2671328
Encoder Loss:  0.34248772  || Decoder Loss:  0.499882 Validation Decoder Loss:  1.3154373
Encoder Loss:  0.3352682  || Decoder Loss:  0.48855588 Validation Decoder Loss:  1.2360998
Encoder Loss:  0.33737808  || Decoder Loss:  0.49737158 Validation Decoder Loss:  1.2049978
Encoder Loss:  0.3313016  || Decoder Loss:  0.49056384 Validation Decoder Loss:  1.2428143
Encoder Loss:  0.33457005  || Decoder Loss:  0.4926912 Validation Decoder Loss:  1.2248204
Encoder Loss:  0.32046226  || Decoder Loss:  0.47232643 Validation Decoder Loss:  0.91399384
Encoder Loss:  0.3359984  || Decoder Loss:  0.49817994 Validation Decoder Loss:  0.9067769
Model: siamese_net_lr_0.07973400137245566 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9067769
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_308 (Conv3D (None, 102, 5, 20, 1)     40        
_________________________________________________________________
dropout_645 (Dropout)        (None, 102, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_309 (Conv3D (None, 184, 5, 20, 1)     84        
_________________________________________________________________
reshape_173 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 2720, 20, 1)       527       
_________________________________________________________________
dropout_647 (Dropout)        (None, 2720, 20, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 920, 20, 1)        1802      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 1910, 20, 1)       73        
_________________________________________________________________
dropout_649 (Dropout)        (None, 1910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 3245, 20, 1)       1337      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36447915  || Decoder Loss:  0.6058704 Validation Decoder Loss:  1.4404022
Encoder Loss:  0.35449108  || Decoder Loss:  0.42400628 Validation Decoder Loss:  0.48242635
Encoder Loss:  0.23305361  || Decoder Loss:  0.5476325 Validation Decoder Loss:  1.5347981
Encoder Loss:  0.12641272  || Decoder Loss:  0.5736728 Validation Decoder Loss:  1.4884841
Encoder Loss:  0.10522881  || Decoder Loss:  0.5254599 Validation Decoder Loss:  1.3421309
Encoder Loss:  0.104011  || Decoder Loss:  0.51763266 Validation Decoder Loss:  1.3214726
Encoder Loss:  0.102029935  || Decoder Loss:  0.51186675 Validation Decoder Loss:  1.2396258
Encoder Loss:  0.09799341  || Decoder Loss:  0.5098199 Validation Decoder Loss:  1.1788135
Encoder Loss:  0.09260492  || Decoder Loss:  0.5017263 Validation Decoder Loss:  1.1623356
Encoder Loss:  0.0945162  || Decoder Loss:  0.49892274 Validation Decoder Loss:  1.109421
Encoder Loss:  0.092606276  || Decoder Loss:  0.49402055 Validation Decoder Loss:  1.0771106
Encoder Loss:  0.09375905  || Decoder Loss:  0.49197835 Validation Decoder Loss:  1.0474111
Encoder Loss:  0.09311254  || Decoder Loss:  0.48992917 Validation Decoder Loss:  1.0223002
Encoder Loss:  0.09253897  || Decoder Loss:  0.48797715 Validation Decoder Loss:  1.0030632
Encoder Loss:  0.090832084  || Decoder Loss:  0.4866424 Validation Decoder Loss:  0.9896429
Encoder Loss:  0.09753251  || Decoder Loss:  0.48592144 Validation Decoder Loss:  0.98165894
Encoder Loss:  0.09281561  || Decoder Loss:  0.48546612 Validation Decoder Loss:  0.9760076
Encoder Loss:  0.090804346  || Decoder Loss:  0.48504913 Validation Decoder Loss:  0.9669777
Encoder Loss:  0.08989611  || Decoder Loss:  0.48470688 Validation Decoder Loss:  0.95504296
Encoder Loss:  0.09172425  || Decoder Loss:  0.48435888 Validation Decoder Loss:  0.95063776
Encoder Loss:  0.09212161  || Decoder Loss:  0.4841089 Validation Decoder Loss:  0.9504733
Encoder Loss:  0.092370436  || Decoder Loss:  0.48392272 Validation Decoder Loss:  0.9436336
Encoder Loss:  0.09229357  || Decoder Loss:  0.48377326 Validation Decoder Loss:  0.9460547
Encoder Loss:  0.08958393  || Decoder Loss:  0.48377272 Validation Decoder Loss:  0.93753624
Encoder Loss:  0.09216772  || Decoder Loss:  0.48352143 Validation Decoder Loss:  0.9326384
Encoder Loss:  0.08984944  || Decoder Loss:  0.48318595 Validation Decoder Loss:  0.93654156
Encoder Loss:  0.092219144  || Decoder Loss:  0.48320538 Validation Decoder Loss:  0.92004734
Encoder Loss:  0.09482844  || Decoder Loss:  0.48175883 Validation Decoder Loss:  0.939939
Encoder Loss:  0.10184914  || Decoder Loss:  0.48511288 Validation Decoder Loss:  0.93536335
Encoder Loss:  0.09174036  || Decoder Loss:  0.48358226 Validation Decoder Loss:  0.9114764
Encoder Loss:  0.09199223  || Decoder Loss:  0.4828745 Validation Decoder Loss:  0.9086447
Encoder Loss:  0.08994759  || Decoder Loss:  0.4837136 Validation Decoder Loss:  0.91265726
Encoder Loss:  0.0913141  || Decoder Loss:  0.48251122 Validation Decoder Loss:  0.9040024
Encoder Loss:  0.09218366  || Decoder Loss:  0.48342898 Validation Decoder Loss:  0.9035944
Encoder Loss:  0.09208714  || Decoder Loss:  0.48259288 Validation Decoder Loss:  0.8989921
Encoder Loss:  0.09005479  || Decoder Loss:  0.48278764 Validation Decoder Loss:  0.89149547
Encoder Loss:  0.09490204  || Decoder Loss:  0.4838626 Validation Decoder Loss:  0.9020034
Encoder Loss:  0.089555524  || Decoder Loss:  0.48328605 Validation Decoder Loss:  0.9018402
Encoder Loss:  0.08890432  || Decoder Loss:  0.482981 Validation Decoder Loss:  0.8984302
Encoder Loss:  0.09051559  || Decoder Loss:  0.4826745 Validation Decoder Loss:  0.89612496
Model: siamese_net_lr_0.036587178261087566 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.89612496
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_311 (Conv3D (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_651 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_312 (Conv3D (None, 184, 5, 20, 1)     72        
_________________________________________________________________
reshape_174 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 2190, 20, 1)       1057      
_________________________________________________________________
dropout_653 (Dropout)        (None, 2190, 20, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 920, 20, 1)        1272      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 3210, 20, 1)       2292      
_________________________________________________________________
dropout_655 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3991927  || Decoder Loss:  0.19605412 Validation Decoder Loss:  0.3836671
Encoder Loss:  0.3923472  || Decoder Loss:  0.07314883 Validation Decoder Loss:  0.38660598
Encoder Loss:  0.3764857  || Decoder Loss:  0.072797194 Validation Decoder Loss:  0.39386433
Encoder Loss:  0.3365951  || Decoder Loss:  0.074787706 Validation Decoder Loss:  0.43456775
Encoder Loss:  0.09902597  || Decoder Loss:  0.40289456 Validation Decoder Loss:  0.7884878
Encoder Loss:  0.063271165  || Decoder Loss:  0.52867407 Validation Decoder Loss:  0.7789216
Encoder Loss:  0.059661053  || Decoder Loss:  0.5216105 Validation Decoder Loss:  0.73249245
Encoder Loss:  0.059504304  || Decoder Loss:  0.5106345 Validation Decoder Loss:  0.74878854
Encoder Loss:  0.060473476  || Decoder Loss:  0.49483147 Validation Decoder Loss:  0.7506813
Encoder Loss:  0.058180228  || Decoder Loss:  0.50762236 Validation Decoder Loss:  0.77040565
Encoder Loss:  0.059371937  || Decoder Loss:  0.50386626 Validation Decoder Loss:  0.74934685
Encoder Loss:  0.06134256  || Decoder Loss:  0.48438653 Validation Decoder Loss:  0.8728546
Encoder Loss:  0.059367765  || Decoder Loss:  0.5006202 Validation Decoder Loss:  0.781401
Encoder Loss:  0.055597972  || Decoder Loss:  0.47960952 Validation Decoder Loss:  0.7802031
Encoder Loss:  0.056240477  || Decoder Loss:  0.49029297 Validation Decoder Loss:  0.77245736
Encoder Loss:  0.05632877  || Decoder Loss:  0.49317586 Validation Decoder Loss:  0.7452967
Encoder Loss:  0.05593224  || Decoder Loss:  0.4918533 Validation Decoder Loss:  0.7556441
Encoder Loss:  0.05554489  || Decoder Loss:  0.4721323 Validation Decoder Loss:  0.6686208
Encoder Loss:  0.05417388  || Decoder Loss:  0.479038 Validation Decoder Loss:  0.71134436
Encoder Loss:  0.055594847  || Decoder Loss:  0.47793254 Validation Decoder Loss:  0.69858056
Encoder Loss:  0.05507668  || Decoder Loss:  0.47297043 Validation Decoder Loss:  0.64914787
Encoder Loss:  0.054787036  || Decoder Loss:  0.47982615 Validation Decoder Loss:  0.6961285
Encoder Loss:  0.053339243  || Decoder Loss:  0.48589188 Validation Decoder Loss:  0.72469324
Encoder Loss:  0.05318277  || Decoder Loss:  0.49309808 Validation Decoder Loss:  0.76335144
Encoder Loss:  0.05320884  || Decoder Loss:  0.48646876 Validation Decoder Loss:  0.81885564
Encoder Loss:  0.053002447  || Decoder Loss:  0.4863018 Validation Decoder Loss:  0.7994424
Encoder Loss:  0.053065795  || Decoder Loss:  0.48290598 Validation Decoder Loss:  0.85342264
Encoder Loss:  0.052707627  || Decoder Loss:  0.4809497 Validation Decoder Loss:  0.84077656
Encoder Loss:  0.052663226  || Decoder Loss:  0.47873637 Validation Decoder Loss:  0.857347
Encoder Loss:  0.052615568  || Decoder Loss:  0.47709453 Validation Decoder Loss:  0.86869633
Encoder Loss:  0.05263  || Decoder Loss:  0.4749658 Validation Decoder Loss:  0.866855
Encoder Loss:  0.052687675  || Decoder Loss:  0.47058743 Validation Decoder Loss:  0.8257239
Encoder Loss:  0.052551854  || Decoder Loss:  0.4650153 Validation Decoder Loss:  0.9037508
Encoder Loss:  0.05259877  || Decoder Loss:  0.47572395 Validation Decoder Loss:  0.86733806
Encoder Loss:  0.05257371  || Decoder Loss:  0.4665134 Validation Decoder Loss:  0.8544593
Encoder Loss:  0.052506372  || Decoder Loss:  0.46140757 Validation Decoder Loss:  0.8572097
Encoder Loss:  0.052429665  || Decoder Loss:  0.4479457 Validation Decoder Loss:  0.873667
Encoder Loss:  0.052453414  || Decoder Loss:  0.44770405 Validation Decoder Loss:  0.9324701
Encoder Loss:  0.05234063  || Decoder Loss:  0.43300593 Validation Decoder Loss:  0.9404371
Encoder Loss:  0.052409016  || Decoder Loss:  0.43776298 Validation Decoder Loss:  1.0257041
Model: siamese_net_lr_0.07047179242273681 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0257041
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_314 (Conv3D (None, 112, 5, 20, 1)     50        
_________________________________________________________________
dropout_657 (Dropout)        (None, 112, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_315 (Conv3D (None, 184, 5, 20, 1)     74        
_________________________________________________________________
reshape_175 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 1880, 20, 1)       1367      
_________________________________________________________________
dropout_659 (Dropout)        (None, 1880, 20, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 920, 20, 1)        962       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_597"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 1000, 20, 1)       82        
_________________________________________________________________
dropout_661 (Dropout)        (None, 1000, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 3245, 20, 1)       249       
=================================================================
Total params: 331
Trainable params: 331
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07840302  || Decoder Loss:  0.07233531 Validation Decoder Loss:  0.35432974
Encoder Loss:  0.06766039  || Decoder Loss:  0.033904456 Validation Decoder Loss:  0.35460556
Encoder Loss:  0.06342462  || Decoder Loss:  0.033600412 Validation Decoder Loss:  0.34992993
Encoder Loss:  0.05740013  || Decoder Loss:  0.033278596 Validation Decoder Loss:  0.35179162
Encoder Loss:  0.050912693  || Decoder Loss:  0.033010207 Validation Decoder Loss:  0.3498294
Encoder Loss:  0.047020063  || Decoder Loss:  0.032763373 Validation Decoder Loss:  0.34934247
Encoder Loss:  0.046435613  || Decoder Loss:  0.03253888 Validation Decoder Loss:  0.34897798
Encoder Loss:  0.046364207  || Decoder Loss:  0.032342795 Validation Decoder Loss:  0.34837103
Encoder Loss:  0.046181515  || Decoder Loss:  0.03217019 Validation Decoder Loss:  0.3479147
Encoder Loss:  0.04614587  || Decoder Loss:  0.032023426 Validation Decoder Loss:  0.34756824
Encoder Loss:  0.046107423  || Decoder Loss:  0.031899314 Validation Decoder Loss:  0.34731737
Encoder Loss:  0.04607168  || Decoder Loss:  0.031793486 Validation Decoder Loss:  0.3470307
Encoder Loss:  0.046037465  || Decoder Loss:  0.03170134 Validation Decoder Loss:  0.3468637
Encoder Loss:  0.046026558  || Decoder Loss:  0.03161968 Validation Decoder Loss:  0.34668824
Encoder Loss:  0.045998745  || Decoder Loss:  0.03154448 Validation Decoder Loss:  0.34650016
Encoder Loss:  0.045984827  || Decoder Loss:  0.03147392 Validation Decoder Loss:  0.34631497
Encoder Loss:  0.045965724  || Decoder Loss:  0.03140645 Validation Decoder Loss:  0.34609327
Encoder Loss:  0.04595438  || Decoder Loss:  0.031341966 Validation Decoder Loss:  0.34596816
Encoder Loss:  0.045944437  || Decoder Loss:  0.03128022 Validation Decoder Loss:  0.34567904
Encoder Loss:  0.04591705  || Decoder Loss:  0.031221347 Validation Decoder Loss:  0.3454882
Encoder Loss:  0.045903977  || Decoder Loss:  0.031160973 Validation Decoder Loss:  0.34523624
Encoder Loss:  0.04587492  || Decoder Loss:  0.031097973 Validation Decoder Loss:  0.34502026
Encoder Loss:  0.045859918  || Decoder Loss:  0.031041352 Validation Decoder Loss:  0.34486073
Encoder Loss:  0.045847874  || Decoder Loss:  0.030989615 Validation Decoder Loss:  0.34478772
Encoder Loss:  0.04585743  || Decoder Loss:  0.030937776 Validation Decoder Loss:  0.34457687
Encoder Loss:  0.04583614  || Decoder Loss:  0.030885376 Validation Decoder Loss:  0.3444294
Encoder Loss:  0.04582057  || Decoder Loss:  0.030831153 Validation Decoder Loss:  0.34433705
Encoder Loss:  0.045810185  || Decoder Loss:  0.030775685 Validation Decoder Loss:  0.34429657
Encoder Loss:  0.045792628  || Decoder Loss:  0.030717067 Validation Decoder Loss:  0.34427118
Encoder Loss:  0.045781784  || Decoder Loss:  0.030653317 Validation Decoder Loss:  0.3441779
Encoder Loss:  0.045764502  || Decoder Loss:  0.0305839 Validation Decoder Loss:  0.34394595
Encoder Loss:  0.04573729  || Decoder Loss:  0.030510096 Validation Decoder Loss:  0.3437741
Encoder Loss:  0.04572902  || Decoder Loss:  0.030440597 Validation Decoder Loss:  0.34364447
Encoder Loss:  0.045705926  || Decoder Loss:  0.030377638 Validation Decoder Loss:  0.34350753
Encoder Loss:  0.04570252  || Decoder Loss:  0.030318039 Validation Decoder Loss:  0.34332168
Encoder Loss:  0.045690134  || Decoder Loss:  0.03026247 Validation Decoder Loss:  0.34315217
Encoder Loss:  0.045676537  || Decoder Loss:  0.030210411 Validation Decoder Loss:  0.34300253
Encoder Loss:  0.045665804  || Decoder Loss:  0.030161628 Validation Decoder Loss:  0.34283125
Encoder Loss:  0.045655068  || Decoder Loss:  0.03011529 Validation Decoder Loss:  0.34270173
Encoder Loss:  0.0456429  || Decoder Loss:  0.030071026 Validation Decoder Loss:  0.3425822
Model: siamese_net_lr_0.0013702020264236927 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3425822
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_317 (Conv3D (None, 180, 5, 20, 1)     55        
_________________________________________________________________
dropout_663 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_318 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_176 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 1020, 20, 1)       1208      
_________________________________________________________________
dropout_665 (Dropout)        (None, 1020, 20, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 920, 20, 1)        102       
=================================================================
Total params: 1,310
Trainable params: 1,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 1650, 20, 1)       732       
_________________________________________________________________
dropout_667 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 3245, 20, 1)       1597      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32281476  || Decoder Loss:  0.12658107 Validation Decoder Loss:  0.37502015
Encoder Loss:  0.32147408  || Decoder Loss:  0.10128683 Validation Decoder Loss:  0.36933672
Encoder Loss:  0.32557896  || Decoder Loss:  0.091153584 Validation Decoder Loss:  0.36906365
Encoder Loss:  0.3368982  || Decoder Loss:  0.34304246 Validation Decoder Loss:  0.5053165
Encoder Loss:  0.27524263  || Decoder Loss:  0.5282636 Validation Decoder Loss:  0.79937315
Encoder Loss:  0.20885588  || Decoder Loss:  0.45434543 Validation Decoder Loss:  0.73434865
Encoder Loss:  0.23175569  || Decoder Loss:  0.54697347 Validation Decoder Loss:  1.49984
Encoder Loss:  0.20754376  || Decoder Loss:  0.49782735 Validation Decoder Loss:  1.1047726
Encoder Loss:  0.20667024  || Decoder Loss:  0.49669442 Validation Decoder Loss:  1.2396193
Encoder Loss:  0.19604696  || Decoder Loss:  0.46621594 Validation Decoder Loss:  1.4010913
Encoder Loss:  0.19517468  || Decoder Loss:  0.4505607 Validation Decoder Loss:  0.73410463
Encoder Loss:  0.19665457  || Decoder Loss:  0.46959168 Validation Decoder Loss:  1.6044598
Encoder Loss:  0.2095627  || Decoder Loss:  0.50427 Validation Decoder Loss:  1.3976278
Encoder Loss:  0.20417252  || Decoder Loss:  0.49382275 Validation Decoder Loss:  0.98672676
Encoder Loss:  0.19216755  || Decoder Loss:  0.4627237 Validation Decoder Loss:  1.0445733
Encoder Loss:  0.18168032  || Decoder Loss:  0.4316085 Validation Decoder Loss:  0.7743987
Encoder Loss:  0.08283404  || Decoder Loss:  0.14132978 Validation Decoder Loss:  0.29215515
Encoder Loss:  0.05561602  || Decoder Loss:  0.060641717 Validation Decoder Loss:  0.29988903
Encoder Loss:  0.057256393  || Decoder Loss:  0.059352145 Validation Decoder Loss:  0.40216967
Encoder Loss:  0.051887285  || Decoder Loss:  0.047685195 Validation Decoder Loss:  0.2331672
Encoder Loss:  0.05794409  || Decoder Loss:  0.060689393 Validation Decoder Loss:  0.40626574
Encoder Loss:  0.045963615  || Decoder Loss:  0.035259765 Validation Decoder Loss:  0.32840407
Encoder Loss:  0.054550063  || Decoder Loss:  0.053708706 Validation Decoder Loss:  0.25118005
Encoder Loss:  0.04870612  || Decoder Loss:  0.040371552 Validation Decoder Loss:  0.33032823
Encoder Loss:  0.04972117  || Decoder Loss:  0.042617988 Validation Decoder Loss:  0.54105747
Encoder Loss:  0.049397945  || Decoder Loss:  0.043652724 Validation Decoder Loss:  0.2652925
Encoder Loss:  0.052193776  || Decoder Loss:  0.048865903 Validation Decoder Loss:  0.3361947
Encoder Loss:  0.04603361  || Decoder Loss:  0.035287943 Validation Decoder Loss:  0.2845456
Encoder Loss:  0.04748007  || Decoder Loss:  0.03728849 Validation Decoder Loss:  0.25744623
Encoder Loss:  0.04793767  || Decoder Loss:  0.03869637 Validation Decoder Loss:  0.2785875
Encoder Loss:  0.04608006  || Decoder Loss:  0.035363413 Validation Decoder Loss:  0.2990541
Encoder Loss:  0.05307784  || Decoder Loss:  0.05071786 Validation Decoder Loss:  0.2327622
Encoder Loss:  0.053320106  || Decoder Loss:  0.05142589 Validation Decoder Loss:  0.39773977
Encoder Loss:  0.04829472  || Decoder Loss:  0.04028877 Validation Decoder Loss:  0.3424187
Encoder Loss:  0.044182323  || Decoder Loss:  0.030676814 Validation Decoder Loss:  0.29849607
Encoder Loss:  0.0461772  || Decoder Loss:  0.035761897 Validation Decoder Loss:  0.5031185
Encoder Loss:  0.047323205  || Decoder Loss:  0.038156018 Validation Decoder Loss:  0.4075827
Encoder Loss:  0.04609985  || Decoder Loss:  0.03532759 Validation Decoder Loss:  0.38883057
Encoder Loss:  0.04353007  || Decoder Loss:  0.029254656 Validation Decoder Loss:  0.29841784
Encoder Loss:  0.05170591  || Decoder Loss:  0.048124876 Validation Decoder Loss:  0.24843366
Model: siamese_net_lr_0.06940933375206984 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.24843365
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_320 (Conv3D (None, 156, 5, 20, 1)     94        
_________________________________________________________________
dropout_669 (Dropout)        (None, 156, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_321 (Conv3D (None, 184, 5, 20, 1)     30        
_________________________________________________________________
reshape_177 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 1610, 20, 1)       28        
_________________________________________________________________
dropout_671 (Dropout)        (None, 1610, 20, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 920, 20, 1)        692       
=================================================================
Total params: 720
Trainable params: 720
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 2810, 20, 1)       54        
_________________________________________________________________
dropout_673 (Dropout)        (None, 2810, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 3245, 20, 1)       437       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27823767  || Decoder Loss:  0.079525694 Validation Decoder Loss:  0.34643432
Encoder Loss:  0.2914196  || Decoder Loss:  0.07239349 Validation Decoder Loss:  0.34608603
Encoder Loss:  0.28869283  || Decoder Loss:  0.08013144 Validation Decoder Loss:  0.3449414
Encoder Loss:  0.27922344  || Decoder Loss:  0.094658144 Validation Decoder Loss:  1.5516573
Encoder Loss:  0.30324838  || Decoder Loss:  0.4719349 Validation Decoder Loss:  1.0381882
Encoder Loss:  0.2613373  || Decoder Loss:  0.49680597 Validation Decoder Loss:  0.9346107
Encoder Loss:  0.23982368  || Decoder Loss:  0.4804723 Validation Decoder Loss:  0.9014341
Encoder Loss:  0.23538204  || Decoder Loss:  0.47203723 Validation Decoder Loss:  0.86146444
Encoder Loss:  0.23117046  || Decoder Loss:  0.47050014 Validation Decoder Loss:  0.9057486
Encoder Loss:  0.23188026  || Decoder Loss:  0.47078198 Validation Decoder Loss:  0.9038191
Encoder Loss:  0.23147237  || Decoder Loss:  0.47073936 Validation Decoder Loss:  0.91426563
Encoder Loss:  0.23119089  || Decoder Loss:  0.4719018 Validation Decoder Loss:  0.8929963
Encoder Loss:  0.2299069  || Decoder Loss:  0.46945938 Validation Decoder Loss:  0.92283225
Encoder Loss:  0.22919685  || Decoder Loss:  0.47099766 Validation Decoder Loss:  0.8886887
Encoder Loss:  0.2292202  || Decoder Loss:  0.47310388 Validation Decoder Loss:  0.9096377
Encoder Loss:  0.22852585  || Decoder Loss:  0.47077727 Validation Decoder Loss:  0.9297845
Encoder Loss:  0.2275259  || Decoder Loss:  0.47177842 Validation Decoder Loss:  0.9113393
Encoder Loss:  0.22664255  || Decoder Loss:  0.47288114 Validation Decoder Loss:  0.8883133
Encoder Loss:  0.22173849  || Decoder Loss:  0.47092193 Validation Decoder Loss:  0.8841334
Encoder Loss:  0.22029644  || Decoder Loss:  0.47018337 Validation Decoder Loss:  0.87739074
Encoder Loss:  0.22056326  || Decoder Loss:  0.47258732 Validation Decoder Loss:  0.88863355
Encoder Loss:  0.2304264  || Decoder Loss:  0.4675275 Validation Decoder Loss:  0.97882676
Encoder Loss:  0.23538765  || Decoder Loss:  0.4710647 Validation Decoder Loss:  0.9662026
Encoder Loss:  0.21915129  || Decoder Loss:  0.46655977 Validation Decoder Loss:  0.94765604
Encoder Loss:  0.21287708  || Decoder Loss:  0.46117514 Validation Decoder Loss:  0.92592984
Encoder Loss:  0.20770235  || Decoder Loss:  0.45613617 Validation Decoder Loss:  0.9179169
Encoder Loss:  0.20621815  || Decoder Loss:  0.44874707 Validation Decoder Loss:  0.86862725
Encoder Loss:  0.19557576  || Decoder Loss:  0.41881427 Validation Decoder Loss:  0.696229
Encoder Loss:  0.08664264  || Decoder Loss:  0.13793094 Validation Decoder Loss:  0.35657555
Encoder Loss:  0.05194465  || Decoder Loss:  0.046034675 Validation Decoder Loss:  0.35488218
Encoder Loss:  0.051151596  || Decoder Loss:  0.03994013 Validation Decoder Loss:  0.34719223
Encoder Loss:  0.04984725  || Decoder Loss:  0.039469678 Validation Decoder Loss:  0.34902254
Encoder Loss:  0.04760088  || Decoder Loss:  0.03937016 Validation Decoder Loss:  0.34884328
Encoder Loss:  0.04855869  || Decoder Loss:  0.039325863 Validation Decoder Loss:  0.3486275
Encoder Loss:  0.04786141  || Decoder Loss:  0.039288923 Validation Decoder Loss:  0.34874582
Encoder Loss:  0.047789887  || Decoder Loss:  0.03925456 Validation Decoder Loss:  0.3488903
Encoder Loss:  0.047446605  || Decoder Loss:  0.039226606 Validation Decoder Loss:  0.34909996
Encoder Loss:  0.046648957  || Decoder Loss:  0.03919983 Validation Decoder Loss:  0.34918946
Encoder Loss:  0.047115803  || Decoder Loss:  0.03917107 Validation Decoder Loss:  0.3490593
Encoder Loss:  0.048602916  || Decoder Loss:  0.039132096 Validation Decoder Loss:  0.3492265
Model: siamese_net_lr_0.059789073672184334 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34922647
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_323 (Conv3D (None, 70, 5, 20, 1)      8         
_________________________________________________________________
dropout_675 (Dropout)        (None, 70, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_324 (Conv3D (None, 184, 5, 20, 1)     116       
_________________________________________________________________
reshape_178 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_608"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 2610, 20, 1)       637       
_________________________________________________________________
dropout_677 (Dropout)        (None, 2610, 20, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 920, 20, 1)        1692      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 3190, 20, 1)       2272      
_________________________________________________________________
dropout_679 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3999421  || Decoder Loss:  0.52917403 Validation Decoder Loss:  0.5969306
Encoder Loss:  0.36233994  || Decoder Loss:  0.50320125 Validation Decoder Loss:  0.6525487
Encoder Loss:  0.36473224  || Decoder Loss:  0.5084459 Validation Decoder Loss:  0.5890561
Encoder Loss:  0.36074254  || Decoder Loss:  0.5026268 Validation Decoder Loss:  0.6668101
Encoder Loss:  0.36011705  || Decoder Loss:  0.5030942 Validation Decoder Loss:  0.6301487
Encoder Loss:  0.35392246  || Decoder Loss:  0.49137726 Validation Decoder Loss:  0.6798897
Encoder Loss:  0.35915112  || Decoder Loss:  0.50055945 Validation Decoder Loss:  0.6779331
Encoder Loss:  0.3561655  || Decoder Loss:  0.49679047 Validation Decoder Loss:  0.66844845
Encoder Loss:  0.35171342  || Decoder Loss:  0.48725113 Validation Decoder Loss:  0.7510729
Encoder Loss:  0.3534311  || Decoder Loss:  0.4910545 Validation Decoder Loss:  0.66613
Encoder Loss:  0.35072023  || Decoder Loss:  0.48475417 Validation Decoder Loss:  0.7762883
Encoder Loss:  0.34866044  || Decoder Loss:  0.485704 Validation Decoder Loss:  0.7717778
Encoder Loss:  0.34757188  || Decoder Loss:  0.48428455 Validation Decoder Loss:  0.7723037
Encoder Loss:  0.34769177  || Decoder Loss:  0.48252904 Validation Decoder Loss:  0.79711044
Encoder Loss:  0.34632313  || Decoder Loss:  0.48324695 Validation Decoder Loss:  0.7719605
Encoder Loss:  0.34642917  || Decoder Loss:  0.48237777 Validation Decoder Loss:  0.77422273
Encoder Loss:  0.34536332  || Decoder Loss:  0.48090473 Validation Decoder Loss:  0.79109395
Encoder Loss:  0.34757787  || Decoder Loss:  0.4840994 Validation Decoder Loss:  0.80102515
Encoder Loss:  0.34584907  || Decoder Loss:  0.48147136 Validation Decoder Loss:  0.80459845
Encoder Loss:  0.3453087  || Decoder Loss:  0.4811516 Validation Decoder Loss:  0.8265972
Encoder Loss:  0.34550563  || Decoder Loss:  0.48152664 Validation Decoder Loss:  0.8221937
Encoder Loss:  0.34565762  || Decoder Loss:  0.48104632 Validation Decoder Loss:  0.8688845
Encoder Loss:  0.3456665  || Decoder Loss:  0.48154327 Validation Decoder Loss:  0.8503829
Encoder Loss:  0.34445572  || Decoder Loss:  0.4802018 Validation Decoder Loss:  0.85797167
Encoder Loss:  0.34307182  || Decoder Loss:  0.47717452 Validation Decoder Loss:  0.86383104
Encoder Loss:  0.34493092  || Decoder Loss:  0.48058635 Validation Decoder Loss:  0.87202764
Encoder Loss:  0.34405804  || Decoder Loss:  0.47928956 Validation Decoder Loss:  0.8758975
Encoder Loss:  0.3444537  || Decoder Loss:  0.48008344 Validation Decoder Loss:  0.87212664
Encoder Loss:  0.3434495  || Decoder Loss:  0.47891942 Validation Decoder Loss:  0.87281823
Encoder Loss:  0.34361294  || Decoder Loss:  0.4781397 Validation Decoder Loss:  0.8915427
Encoder Loss:  0.34275898  || Decoder Loss:  0.47729146 Validation Decoder Loss:  0.90265197
Encoder Loss:  0.34380877  || Decoder Loss:  0.4786419 Validation Decoder Loss:  0.9030414
Encoder Loss:  0.34304795  || Decoder Loss:  0.4779444 Validation Decoder Loss:  0.898613
Encoder Loss:  0.34328616  || Decoder Loss:  0.47846735 Validation Decoder Loss:  0.90272415
Encoder Loss:  0.3431322  || Decoder Loss:  0.47817793 Validation Decoder Loss:  0.91820693
Encoder Loss:  0.34287417  || Decoder Loss:  0.47789297 Validation Decoder Loss:  0.9117704
Encoder Loss:  0.342455  || Decoder Loss:  0.47728783 Validation Decoder Loss:  0.920825
Encoder Loss:  0.3423629  || Decoder Loss:  0.47718766 Validation Decoder Loss:  0.91859186
Encoder Loss:  0.34273136  || Decoder Loss:  0.4771744 Validation Decoder Loss:  0.9310384
Encoder Loss:  0.34227753  || Decoder Loss:  0.47693324 Validation Decoder Loss:  0.9361683
Model: siamese_net_lr_0.041664057421579775 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9361683
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_326 (Conv3D (None, 180, 5, 20, 1)     55        
_________________________________________________________________
dropout_681 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_327 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_179 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_612"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 1020, 20, 1)       1208      
_________________________________________________________________
dropout_683 (Dropout)        (None, 1020, 20, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 920, 20, 1)        102       
=================================================================
Total params: 1,310
Trainable params: 1,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 1650, 20, 1)       732       
_________________________________________________________________
dropout_685 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 3245, 20, 1)       1597      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40280506  || Decoder Loss:  0.3938193 Validation Decoder Loss:  0.3932318
Encoder Loss:  0.32921407  || Decoder Loss:  0.11125639 Validation Decoder Loss:  0.37337044
Encoder Loss:  0.32206613  || Decoder Loss:  0.09130695 Validation Decoder Loss:  0.36801457
Encoder Loss:  0.31459662  || Decoder Loss:  0.073465884 Validation Decoder Loss:  0.37830174
Encoder Loss:  0.30745313  || Decoder Loss:  0.09097381 Validation Decoder Loss:  1.6391194
Encoder Loss:  0.4516482  || Decoder Loss:  0.45897418 Validation Decoder Loss:  0.41058254
Encoder Loss:  0.32431048  || Decoder Loss:  0.08320937 Validation Decoder Loss:  0.389489
Encoder Loss:  0.32249868  || Decoder Loss:  0.07836555 Validation Decoder Loss:  0.4061858
Encoder Loss:  0.32112092  || Decoder Loss:  0.074794605 Validation Decoder Loss:  0.40077865
Encoder Loss:  0.3195602  || Decoder Loss:  0.070763975 Validation Decoder Loss:  0.3959632
Encoder Loss:  0.317327  || Decoder Loss:  0.06484977 Validation Decoder Loss:  0.38704833
Encoder Loss:  0.31337455  || Decoder Loss:  0.053981725 Validation Decoder Loss:  0.36049488
Encoder Loss:  0.31064457  || Decoder Loss:  0.04688448 Validation Decoder Loss:  0.3574887
Encoder Loss:  0.3098638  || Decoder Loss:  0.045748867 Validation Decoder Loss:  0.3545667
Encoder Loss:  0.30916756  || Decoder Loss:  0.045127727 Validation Decoder Loss:  0.3538998
Encoder Loss:  0.30843776  || Decoder Loss:  0.04477194 Validation Decoder Loss:  0.3537986
Encoder Loss:  0.30756876  || Decoder Loss:  0.044539317 Validation Decoder Loss:  0.3536569
Encoder Loss:  0.30643004  || Decoder Loss:  0.044374444 Validation Decoder Loss:  0.35364679
Encoder Loss:  0.30473876  || Decoder Loss:  0.044255808 Validation Decoder Loss:  0.35373908
Encoder Loss:  0.30016458  || Decoder Loss:  0.044190593 Validation Decoder Loss:  0.35398662
Encoder Loss:  0.29256415  || Decoder Loss:  0.04425739 Validation Decoder Loss:  0.3546868
Encoder Loss:  0.287172  || Decoder Loss:  0.045712713 Validation Decoder Loss:  0.3691778
Encoder Loss:  0.2684937  || Decoder Loss:  0.43385193 Validation Decoder Loss:  1.0319041
Encoder Loss:  0.20814282  || Decoder Loss:  0.42007697 Validation Decoder Loss:  1.2150565
Encoder Loss:  0.21953076  || Decoder Loss:  0.4349229 Validation Decoder Loss:  1.1363151
Encoder Loss:  0.22775453  || Decoder Loss:  0.4479763 Validation Decoder Loss:  1.233133
Encoder Loss:  0.22591859  || Decoder Loss:  0.44637042 Validation Decoder Loss:  1.116296
Encoder Loss:  0.21414492  || Decoder Loss:  0.43098474 Validation Decoder Loss:  1.2323587
Encoder Loss:  0.21777877  || Decoder Loss:  0.43379536 Validation Decoder Loss:  1.1414574
Encoder Loss:  0.21548058  || Decoder Loss:  0.42732063 Validation Decoder Loss:  1.259738
Encoder Loss:  0.2317599  || Decoder Loss:  0.45962647 Validation Decoder Loss:  1.1251428
Encoder Loss:  0.21095057  || Decoder Loss:  0.41574478 Validation Decoder Loss:  1.1457248
Encoder Loss:  0.21040282  || Decoder Loss:  0.42319036 Validation Decoder Loss:  1.2143543
Encoder Loss:  0.2129065  || Decoder Loss:  0.42308292 Validation Decoder Loss:  1.1945121
Encoder Loss:  0.21232219  || Decoder Loss:  0.42257294 Validation Decoder Loss:  1.1976085
Encoder Loss:  0.21218768  || Decoder Loss:  0.42199326 Validation Decoder Loss:  1.1211218
Encoder Loss:  0.20704043  || Decoder Loss:  0.4133436 Validation Decoder Loss:  1.1740179
Encoder Loss:  0.20896894  || Decoder Loss:  0.41970894 Validation Decoder Loss:  1.210345
Encoder Loss:  0.21011385  || Decoder Loss:  0.41814438 Validation Decoder Loss:  1.1843493
Encoder Loss:  0.20939624  || Decoder Loss:  0.4189497 Validation Decoder Loss:  1.169431
Model: siamese_net_lr_0.06940933376207574 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.169431
Model: "sequential_614"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_329 (Conv3D (None, 162, 5, 20, 1)     37        
_________________________________________________________________
dropout_687 (Dropout)        (None, 162, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_330 (Conv3D (None, 184, 5, 20, 1)     24        
_________________________________________________________________
reshape_180 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 1840, 20, 1)       1407      
_________________________________________________________________
dropout_689 (Dropout)        (None, 1840, 20, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 920, 20, 1)        3         
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 2500, 20, 1)       663       
_________________________________________________________________
dropout_691 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 3245, 20, 1)       747       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30047375  || Decoder Loss:  0.26412356 Validation Decoder Loss:  0.38019416
Encoder Loss:  0.19268622  || Decoder Loss:  0.10356361 Validation Decoder Loss:  0.38287026
Encoder Loss:  0.34275082  || Decoder Loss:  0.3581468 Validation Decoder Loss:  0.44374683
Encoder Loss:  0.47688657  || Decoder Loss:  0.5609814 Validation Decoder Loss:  1.3284202
Encoder Loss:  0.38738385  || Decoder Loss:  0.4804842 Validation Decoder Loss:  0.9292756
Encoder Loss:  0.3933266  || Decoder Loss:  0.488814 Validation Decoder Loss:  1.0492022
Encoder Loss:  0.39805204  || Decoder Loss:  0.5021446 Validation Decoder Loss:  0.91924083
Encoder Loss:  0.4056892  || Decoder Loss:  0.508643 Validation Decoder Loss:  1.0653782
Encoder Loss:  0.40372902  || Decoder Loss:  0.5095207 Validation Decoder Loss:  0.9085225
Encoder Loss:  0.4001775  || Decoder Loss:  0.5027731 Validation Decoder Loss:  1.0014848
Encoder Loss:  0.39293724  || Decoder Loss:  0.49290136 Validation Decoder Loss:  1.0593015
Encoder Loss:  0.4036789  || Decoder Loss:  0.5120243 Validation Decoder Loss:  0.95333797
Encoder Loss:  0.3943001  || Decoder Loss:  0.49566373 Validation Decoder Loss:  1.1518724
Encoder Loss:  0.40072727  || Decoder Loss:  0.50928503 Validation Decoder Loss:  1.0010962
Encoder Loss:  0.38518664  || Decoder Loss:  0.48319706 Validation Decoder Loss:  1.276314
Encoder Loss:  0.39922065  || Decoder Loss:  0.50893396 Validation Decoder Loss:  1.0582707
Encoder Loss:  0.38770226  || Decoder Loss:  0.49225578 Validation Decoder Loss:  1.201659
Encoder Loss:  0.37597072  || Decoder Loss:  0.48363224 Validation Decoder Loss:  0.8644285
Encoder Loss:  0.37256858  || Decoder Loss:  0.476726 Validation Decoder Loss:  0.9032191
Encoder Loss:  0.3816365  || Decoder Loss:  0.4866938 Validation Decoder Loss:  0.90937495
Encoder Loss:  0.38125774  || Decoder Loss:  0.48782754 Validation Decoder Loss:  0.9110831
Encoder Loss:  0.37097314  || Decoder Loss:  0.4797005 Validation Decoder Loss:  0.9668632
Encoder Loss:  0.37287742  || Decoder Loss:  0.48080745 Validation Decoder Loss:  0.97853434
Encoder Loss:  0.3775918  || Decoder Loss:  0.48591554 Validation Decoder Loss:  0.97857094
Encoder Loss:  0.3721758  || Decoder Loss:  0.482275 Validation Decoder Loss:  1.0259948
Encoder Loss:  0.3708929  || Decoder Loss:  0.48295632 Validation Decoder Loss:  1.0201261
Encoder Loss:  0.37063494  || Decoder Loss:  0.48184815 Validation Decoder Loss:  1.0732489
Encoder Loss:  0.37352288  || Decoder Loss:  0.48580238 Validation Decoder Loss:  1.0557914
Encoder Loss:  0.3714136  || Decoder Loss:  0.48416004 Validation Decoder Loss:  1.0610918
Encoder Loss:  0.37093845  || Decoder Loss:  0.48341095 Validation Decoder Loss:  1.0388052
Encoder Loss:  0.3706963  || Decoder Loss:  0.48308 Validation Decoder Loss:  1.0332748
Encoder Loss:  0.37029418  || Decoder Loss:  0.48256543 Validation Decoder Loss:  1.0373017
Encoder Loss:  0.37015793  || Decoder Loss:  0.48216987 Validation Decoder Loss:  1.0347629
Encoder Loss:  0.37001568  || Decoder Loss:  0.4822728 Validation Decoder Loss:  1.0417752
Encoder Loss:  0.36953002  || Decoder Loss:  0.48148918 Validation Decoder Loss:  1.0486584
Encoder Loss:  0.36860493  || Decoder Loss:  0.48015508 Validation Decoder Loss:  1.0456767
Encoder Loss:  0.36559832  || Decoder Loss:  0.47599605 Validation Decoder Loss:  1.035727
Encoder Loss:  0.35132805  || Decoder Loss:  0.45695615 Validation Decoder Loss:  0.738382
Encoder Loss:  0.3383842  || Decoder Loss:  0.4392667 Validation Decoder Loss:  0.9350161
Encoder Loss:  0.30050045  || Decoder Loss:  0.38817245 Validation Decoder Loss:  0.64728105
Model: siamese_net_lr_0.04566336721697514 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.64728105
Model: "sequential_618"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_332 (Conv3D (None, 140, 5, 20, 1)     15        
_________________________________________________________________
dropout_693 (Dropout)        (None, 140, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_333 (Conv3D (None, 184, 5, 20, 1)     46        
_________________________________________________________________
reshape_181 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 2760, 20, 1)       487       
_________________________________________________________________
dropout_695 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 920, 20, 1)        1842      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_621"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 950, 20, 1)        32        
_________________________________________________________________
dropout_697 (Dropout)        (None, 950, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 3245, 20, 1)       2297      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24847563  || Decoder Loss:  0.12400106 Validation Decoder Loss:  0.3399732
Encoder Loss:  0.094333895  || Decoder Loss:  0.03864893 Validation Decoder Loss:  0.338738
Encoder Loss:  0.1099593  || Decoder Loss:  0.036908135 Validation Decoder Loss:  0.3400075
Encoder Loss:  0.119313575  || Decoder Loss:  0.033090115 Validation Decoder Loss:  0.33535063
Encoder Loss:  0.105922416  || Decoder Loss:  0.03135851 Validation Decoder Loss:  0.33776483
Encoder Loss:  0.06709265  || Decoder Loss:  0.030285902 Validation Decoder Loss:  0.33803874
Encoder Loss:  0.055947732  || Decoder Loss:  0.028900282 Validation Decoder Loss:  0.33977693
Encoder Loss:  0.058267813  || Decoder Loss:  0.027593937 Validation Decoder Loss:  0.34136292
Encoder Loss:  0.057332598  || Decoder Loss:  0.026560726 Validation Decoder Loss:  0.3412391
Encoder Loss:  0.06312273  || Decoder Loss:  0.025593912 Validation Decoder Loss:  0.34238458
Encoder Loss:  0.056873683  || Decoder Loss:  0.024675153 Validation Decoder Loss:  0.3427661
Encoder Loss:  0.06715384  || Decoder Loss:  0.024206288 Validation Decoder Loss:  0.35112536
Encoder Loss:  0.07391582  || Decoder Loss:  0.024045588 Validation Decoder Loss:  0.33549982
Encoder Loss:  0.06478827  || Decoder Loss:  0.024129042 Validation Decoder Loss:  0.32016045
Encoder Loss:  0.05428208  || Decoder Loss:  0.02305312 Validation Decoder Loss:  0.32280052
Encoder Loss:  0.060276408  || Decoder Loss:  0.023896651 Validation Decoder Loss:  0.37161672
Encoder Loss:  0.05931544  || Decoder Loss:  0.02267119 Validation Decoder Loss:  0.34919935
Encoder Loss:  0.06438338  || Decoder Loss:  0.022606228 Validation Decoder Loss:  0.35682055
Encoder Loss:  0.053722147  || Decoder Loss:  0.022249972 Validation Decoder Loss:  0.3511638
Encoder Loss:  0.051283516  || Decoder Loss:  0.02204978 Validation Decoder Loss:  0.348063
Encoder Loss:  0.051940594  || Decoder Loss:  0.021996556 Validation Decoder Loss:  0.34354043
Encoder Loss:  0.05219758  || Decoder Loss:  0.021686884 Validation Decoder Loss:  0.3287995
Encoder Loss:  0.0552992  || Decoder Loss:  0.02191671 Validation Decoder Loss:  0.32301962
Encoder Loss:  0.052530702  || Decoder Loss:  0.02139333 Validation Decoder Loss:  0.33591157
Encoder Loss:  0.04982878  || Decoder Loss:  0.02163241 Validation Decoder Loss:  0.32886904
Encoder Loss:  0.05287506  || Decoder Loss:  0.021137862 Validation Decoder Loss:  0.33919066
Encoder Loss:  0.05216217  || Decoder Loss:  0.02132866 Validation Decoder Loss:  0.32942247
Encoder Loss:  0.050117034  || Decoder Loss:  0.02089656 Validation Decoder Loss:  0.33950746
Encoder Loss:  0.052142248  || Decoder Loss:  0.021006046 Validation Decoder Loss:  0.34327397
Encoder Loss:  0.051910844  || Decoder Loss:  0.020788481 Validation Decoder Loss:  0.34268373
Encoder Loss:  0.048064303  || Decoder Loss:  0.020745201 Validation Decoder Loss:  0.34258783
Encoder Loss:  0.049477283  || Decoder Loss:  0.020632558 Validation Decoder Loss:  0.34494182
Encoder Loss:  0.049750246  || Decoder Loss:  0.020565595 Validation Decoder Loss:  0.34392464
Encoder Loss:  0.055578783  || Decoder Loss:  0.020459436 Validation Decoder Loss:  0.34346992
Encoder Loss:  0.054239336  || Decoder Loss:  0.020381028 Validation Decoder Loss:  0.34352112
Encoder Loss:  0.047086693  || Decoder Loss:  0.020300236 Validation Decoder Loss:  0.34328127
Encoder Loss:  0.05053477  || Decoder Loss:  0.020224944 Validation Decoder Loss:  0.3437086
Encoder Loss:  0.04707348  || Decoder Loss:  0.020176452 Validation Decoder Loss:  0.3428378
Encoder Loss:  0.05105907  || Decoder Loss:  0.020083578 Validation Decoder Loss:  0.34244087
Encoder Loss:  0.047432713  || Decoder Loss:  0.019986726 Validation Decoder Loss:  0.343388
Model: siamese_net_lr_0.006127009834589615 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.343388
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_335 (Conv3D (None, 80, 5, 20, 1)      18        
_________________________________________________________________
dropout_699 (Dropout)        (None, 80, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_336 (Conv3D (None, 184, 5, 20, 1)     27        
_________________________________________________________________
reshape_182 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 45
Trainable params: 45
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_624"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 1950, 20, 1)       1297      
_________________________________________________________________
dropout_701 (Dropout)        (None, 1950, 20, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 920, 20, 1)        1032      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 3100, 20, 1)       1263      
_________________________________________________________________
dropout_703 (Dropout)        (None, 3100, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 3245, 20, 1)       147       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.070540495  || Decoder Loss:  0.060562268 Validation Decoder Loss:  0.32144246
Encoder Loss:  0.046377424  || Decoder Loss:  0.032745264 Validation Decoder Loss:  0.3394025
Encoder Loss:  0.0454542  || Decoder Loss:  0.031723127 Validation Decoder Loss:  0.3400275
Encoder Loss:  0.044434134  || Decoder Loss:  0.031432208 Validation Decoder Loss:  0.34085223
Encoder Loss:  0.04379337  || Decoder Loss:  0.03120954 Validation Decoder Loss:  0.34215847
Encoder Loss:  0.044318203  || Decoder Loss:  0.030980386 Validation Decoder Loss:  0.33835828
Encoder Loss:  0.043043748  || Decoder Loss:  0.030713834 Validation Decoder Loss:  0.34137177
Encoder Loss:  0.04348563  || Decoder Loss:  0.03042955 Validation Decoder Loss:  0.34001863
Encoder Loss:  0.042653907  || Decoder Loss:  0.03011096 Validation Decoder Loss:  0.33896536
Encoder Loss:  0.041699067  || Decoder Loss:  0.029809231 Validation Decoder Loss:  0.3399428
Encoder Loss:  0.04178436  || Decoder Loss:  0.029578961 Validation Decoder Loss:  0.34156728
Encoder Loss:  0.042300545  || Decoder Loss:  0.029405953 Validation Decoder Loss:  0.3397122
Encoder Loss:  0.042761937  || Decoder Loss:  0.029263496 Validation Decoder Loss:  0.33762348
Encoder Loss:  0.041918673  || Decoder Loss:  0.029117728 Validation Decoder Loss:  0.3382417
Encoder Loss:  0.042448595  || Decoder Loss:  0.029005587 Validation Decoder Loss:  0.33679175
Encoder Loss:  0.041675758  || Decoder Loss:  0.028883738 Validation Decoder Loss:  0.33704257
Encoder Loss:  0.041581932  || Decoder Loss:  0.02878669 Validation Decoder Loss:  0.33774492
Encoder Loss:  0.041451406  || Decoder Loss:  0.028692033 Validation Decoder Loss:  0.3376338
Encoder Loss:  0.0416506  || Decoder Loss:  0.028611634 Validation Decoder Loss:  0.3384562
Encoder Loss:  0.041040063  || Decoder Loss:  0.028517423 Validation Decoder Loss:  0.3370343
Encoder Loss:  0.041627742  || Decoder Loss:  0.028437834 Validation Decoder Loss:  0.3373897
Encoder Loss:  0.040978946  || Decoder Loss:  0.028352985 Validation Decoder Loss:  0.33842623
Encoder Loss:  0.04164113  || Decoder Loss:  0.028280532 Validation Decoder Loss:  0.3381697
Encoder Loss:  0.041159987  || Decoder Loss:  0.028193304 Validation Decoder Loss:  0.33849892
Encoder Loss:  0.041158427  || Decoder Loss:  0.028112656 Validation Decoder Loss:  0.337574
Encoder Loss:  0.041643545  || Decoder Loss:  0.02804097 Validation Decoder Loss:  0.33941525
Encoder Loss:  0.041141164  || Decoder Loss:  0.027953634 Validation Decoder Loss:  0.3380144
Encoder Loss:  0.040500525  || Decoder Loss:  0.02788259 Validation Decoder Loss:  0.338264
Encoder Loss:  0.041800313  || Decoder Loss:  0.027836325 Validation Decoder Loss:  0.33999014
Encoder Loss:  0.040735044  || Decoder Loss:  0.02774672 Validation Decoder Loss:  0.33825266
Encoder Loss:  0.040966682  || Decoder Loss:  0.02768897 Validation Decoder Loss:  0.33923328
Encoder Loss:  0.041166082  || Decoder Loss:  0.027629623 Validation Decoder Loss:  0.33909386
Encoder Loss:  0.041211907  || Decoder Loss:  0.027573286 Validation Decoder Loss:  0.33842576
Encoder Loss:  0.04084073  || Decoder Loss:  0.027505288 Validation Decoder Loss:  0.33876795
Encoder Loss:  0.041469418  || Decoder Loss:  0.027452093 Validation Decoder Loss:  0.339877
Encoder Loss:  0.041577235  || Decoder Loss:  0.027390864 Validation Decoder Loss:  0.33852196
Encoder Loss:  0.040683154  || Decoder Loss:  0.027316716 Validation Decoder Loss:  0.33909568
Encoder Loss:  0.041424908  || Decoder Loss:  0.02727003 Validation Decoder Loss:  0.33980328
Encoder Loss:  0.04136479  || Decoder Loss:  0.027211266 Validation Decoder Loss:  0.33893454
Encoder Loss:  0.040298034  || Decoder Loss:  0.027134884 Validation Decoder Loss:  0.33947036
Model: siamese_net_lr_0.0016322502972332792 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33947036
Model: "sequential_626"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_338 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_705 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_339 (Conv3D (None, 184, 5, 20, 1)     68        
_________________________________________________________________
reshape_183 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 1390, 20, 1)       1857      
_________________________________________________________________
dropout_707 (Dropout)        (None, 1390, 20, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 920, 20, 1)        472       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 1640, 20, 1)       722       
_________________________________________________________________
dropout_709 (Dropout)        (None, 1640, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 3245, 20, 1)       1607      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43129626  || Decoder Loss:  0.5743092 Validation Decoder Loss:  0.66105413
Encoder Loss:  0.25056657  || Decoder Loss:  0.45477185 Validation Decoder Loss:  1.3548768
Encoder Loss:  0.21327582  || Decoder Loss:  0.5196874 Validation Decoder Loss:  1.3482234
Encoder Loss:  0.1963668  || Decoder Loss:  0.4901213 Validation Decoder Loss:  1.2809739
Encoder Loss:  0.19462042  || Decoder Loss:  0.4850785 Validation Decoder Loss:  1.2175725
Encoder Loss:  0.19315937  || Decoder Loss:  0.4840486 Validation Decoder Loss:  1.2569155
Encoder Loss:  0.19384459  || Decoder Loss:  0.48441646 Validation Decoder Loss:  1.268955
Encoder Loss:  0.19622736  || Decoder Loss:  0.48330376 Validation Decoder Loss:  1.1952641
Encoder Loss:  0.19684245  || Decoder Loss:  0.48530924 Validation Decoder Loss:  1.1639948
Encoder Loss:  0.19363464  || Decoder Loss:  0.48340553 Validation Decoder Loss:  1.2457044
Encoder Loss:  0.19418852  || Decoder Loss:  0.48098955 Validation Decoder Loss:  1.1394428
Encoder Loss:  0.19290572  || Decoder Loss:  0.48133868 Validation Decoder Loss:  1.1956875
Encoder Loss:  0.19301671  || Decoder Loss:  0.47888088 Validation Decoder Loss:  1.1351116
Encoder Loss:  0.1910749  || Decoder Loss:  0.47803932 Validation Decoder Loss:  1.1704302
Encoder Loss:  0.19406375  || Decoder Loss:  0.48257053 Validation Decoder Loss:  1.0629326
Encoder Loss:  0.19144005  || Decoder Loss:  0.47727364 Validation Decoder Loss:  1.097564
Encoder Loss:  0.19086778  || Decoder Loss:  0.477209 Validation Decoder Loss:  1.1115015
Encoder Loss:  0.19104153  || Decoder Loss:  0.47695926 Validation Decoder Loss:  1.1307013
Encoder Loss:  0.19085954  || Decoder Loss:  0.47620538 Validation Decoder Loss:  1.0668778
Encoder Loss:  0.18951288  || Decoder Loss:  0.47319546 Validation Decoder Loss:  1.0506378
Encoder Loss:  0.19150208  || Decoder Loss:  0.4791915 Validation Decoder Loss:  1.1759858
Encoder Loss:  0.190294  || Decoder Loss:  0.47581002 Validation Decoder Loss:  1.1220245
Encoder Loss:  0.18803951  || Decoder Loss:  0.46759883 Validation Decoder Loss:  0.95666695
Encoder Loss:  0.18242902  || Decoder Loss:  0.4527603 Validation Decoder Loss:  1.1221833
Encoder Loss:  0.18209673  || Decoder Loss:  0.45035475 Validation Decoder Loss:  1.002226
Encoder Loss:  0.17912525  || Decoder Loss:  0.44203115 Validation Decoder Loss:  1.0046105
Encoder Loss:  0.1781324  || Decoder Loss:  0.43962312 Validation Decoder Loss:  0.98838055
Encoder Loss:  0.1767139  || Decoder Loss:  0.43674022 Validation Decoder Loss:  0.9818356
Encoder Loss:  0.17748338  || Decoder Loss:  0.43773782 Validation Decoder Loss:  0.9293598
Encoder Loss:  0.18215269  || Decoder Loss:  0.4465076 Validation Decoder Loss:  1.0089511
Encoder Loss:  0.17734146  || Decoder Loss:  0.43829572 Validation Decoder Loss:  1.021076
Encoder Loss:  0.1769839  || Decoder Loss:  0.4356 Validation Decoder Loss:  1.0044391
Encoder Loss:  0.17681682  || Decoder Loss:  0.43537843 Validation Decoder Loss:  1.0039494
Encoder Loss:  0.1760788  || Decoder Loss:  0.43494457 Validation Decoder Loss:  1.0031595
Encoder Loss:  0.17649212  || Decoder Loss:  0.43453893 Validation Decoder Loss:  1.0070612
Encoder Loss:  0.17641571  || Decoder Loss:  0.43466496 Validation Decoder Loss:  1.0087712
Encoder Loss:  0.17648739  || Decoder Loss:  0.43482476 Validation Decoder Loss:  1.0068929
Encoder Loss:  0.17626427  || Decoder Loss:  0.43462506 Validation Decoder Loss:  1.0046916
Encoder Loss:  0.17608573  || Decoder Loss:  0.43434867 Validation Decoder Loss:  1.0056584
Encoder Loss:  0.17620815  || Decoder Loss:  0.43444335 Validation Decoder Loss:  1.0008185
Model: siamese_net_lr_0.09836861373266127 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0008185
Model: "sequential_630"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_341 (Conv3D (None, 156, 5, 20, 1)     31        
_________________________________________________________________
dropout_711 (Dropout)        (None, 156, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_342 (Conv3D (None, 184, 5, 20, 1)     30        
_________________________________________________________________
reshape_184 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 1620, 20, 1)       1627      
_________________________________________________________________
dropout_713 (Dropout)        (None, 1620, 20, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 920, 20, 1)        702       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_633"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 2870, 20, 1)       1952      
_________________________________________________________________
dropout_715 (Dropout)        (None, 2870, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 3245, 20, 1)       377       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20375721  || Decoder Loss:  0.17362398 Validation Decoder Loss:  0.5028488
Encoder Loss:  0.5062737  || Decoder Loss:  0.5598419 Validation Decoder Loss:  0.7085827
Encoder Loss:  0.39973882  || Decoder Loss:  0.45564678 Validation Decoder Loss:  1.6364512
Encoder Loss:  0.37404424  || Decoder Loss:  0.42839918 Validation Decoder Loss:  1.5719546
Encoder Loss:  0.3980954  || Decoder Loss:  0.45609492 Validation Decoder Loss:  0.917603
Encoder Loss:  0.35000855  || Decoder Loss:  0.39940122 Validation Decoder Loss:  1.4771165
Encoder Loss:  0.3947359  || Decoder Loss:  0.4468671 Validation Decoder Loss:  1.3080902
Encoder Loss:  0.34445104  || Decoder Loss:  0.39263737 Validation Decoder Loss:  1.1082478
Encoder Loss:  0.14903036  || Decoder Loss:  0.1616025 Validation Decoder Loss:  0.3696609
Encoder Loss:  0.05035739  || Decoder Loss:  0.047724415 Validation Decoder Loss:  0.38058576
Encoder Loss:  0.03803814  || Decoder Loss:  0.031118967 Validation Decoder Loss:  0.33281624
Encoder Loss:  0.03695347  || Decoder Loss:  0.03042042 Validation Decoder Loss:  0.3517977
Encoder Loss:  0.035128042  || Decoder Loss:  0.030036531 Validation Decoder Loss:  0.34748995
Encoder Loss:  0.03440934  || Decoder Loss:  0.029487005 Validation Decoder Loss:  0.35657027
Encoder Loss:  0.03441583  || Decoder Loss:  0.029542925 Validation Decoder Loss:  0.338421
Encoder Loss:  0.03401727  || Decoder Loss:  0.028961584 Validation Decoder Loss:  0.35848427
Encoder Loss:  0.03322824  || Decoder Loss:  0.028669743 Validation Decoder Loss:  0.35235012
Encoder Loss:  0.033598017  || Decoder Loss:  0.02841879 Validation Decoder Loss:  0.3452531
Encoder Loss:  0.039240748  || Decoder Loss:  0.030495074 Validation Decoder Loss:  0.34776753
Encoder Loss:  0.03596298  || Decoder Loss:  0.029060962 Validation Decoder Loss:  0.33045536
Encoder Loss:  0.033502683  || Decoder Loss:  0.02919122 Validation Decoder Loss:  0.34550413
Encoder Loss:  0.0335323  || Decoder Loss:  0.028968293 Validation Decoder Loss:  0.34380192
Encoder Loss:  0.033172928  || Decoder Loss:  0.029206634 Validation Decoder Loss:  0.3457351
Encoder Loss:  0.03329466  || Decoder Loss:  0.029382585 Validation Decoder Loss:  0.34990707
Encoder Loss:  0.033958014  || Decoder Loss:  0.02992572 Validation Decoder Loss:  0.37326884
Encoder Loss:  0.037217185  || Decoder Loss:  0.032383814 Validation Decoder Loss:  0.34445885
Encoder Loss:  0.03623227  || Decoder Loss:  0.033006623 Validation Decoder Loss:  0.3596981
Encoder Loss:  0.03684693  || Decoder Loss:  0.033826645 Validation Decoder Loss:  0.35277197
Encoder Loss:  0.0381916  || Decoder Loss:  0.034699317 Validation Decoder Loss:  0.3678424
Encoder Loss:  0.038066614  || Decoder Loss:  0.03517211 Validation Decoder Loss:  0.3522196
Encoder Loss:  0.03826255  || Decoder Loss:  0.035222176 Validation Decoder Loss:  0.3563195
Encoder Loss:  0.037517358  || Decoder Loss:  0.03501192 Validation Decoder Loss:  0.35636106
Encoder Loss:  0.03726368  || Decoder Loss:  0.034761876 Validation Decoder Loss:  0.3572233
Encoder Loss:  0.037138652  || Decoder Loss:  0.034398247 Validation Decoder Loss:  0.3569047
Encoder Loss:  0.036995023  || Decoder Loss:  0.034206122 Validation Decoder Loss:  0.3560336
Encoder Loss:  0.036977734  || Decoder Loss:  0.0339855 Validation Decoder Loss:  0.35634542
Encoder Loss:  0.03639047  || Decoder Loss:  0.033617496 Validation Decoder Loss:  0.3547048
Encoder Loss:  0.035957027  || Decoder Loss:  0.033195414 Validation Decoder Loss:  0.353379
Encoder Loss:  0.035710927  || Decoder Loss:  0.03278209 Validation Decoder Loss:  0.3549435
Encoder Loss:  0.03542003  || Decoder Loss:  0.032320727 Validation Decoder Loss:  0.35395646
Model: siamese_net_lr_0.008835252038376595 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35395646
Model: "sequential_634"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_344 (Conv3D (None, 132, 5, 20, 1)     70        
_________________________________________________________________
dropout_717 (Dropout)        (None, 132, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_345 (Conv3D (None, 184, 5, 20, 1)     54        
_________________________________________________________________
reshape_185 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_636"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 3050, 20, 1)       197       
_________________________________________________________________
dropout_719 (Dropout)        (None, 3050, 20, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 920, 20, 1)        294       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 2820, 20, 1)       983       
_________________________________________________________________
dropout_721 (Dropout)        (None, 2820, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 3245, 20, 1)       427       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09160403  || Decoder Loss:  0.06950338 Validation Decoder Loss:  0.2919363
Encoder Loss:  0.1359313  || Decoder Loss:  0.10385605 Validation Decoder Loss:  0.5014554
Encoder Loss:  0.088608935  || Decoder Loss:  0.08668742 Validation Decoder Loss:  0.36676103
Encoder Loss:  0.06072171  || Decoder Loss:  0.033801887 Validation Decoder Loss:  0.33590728
Encoder Loss:  0.055783413  || Decoder Loss:  0.03168506 Validation Decoder Loss:  0.34600464
Encoder Loss:  0.048949923  || Decoder Loss:  0.031354036 Validation Decoder Loss:  0.33969837
Encoder Loss:  0.04736843  || Decoder Loss:  0.03118548 Validation Decoder Loss:  0.34340417
Encoder Loss:  0.049726166  || Decoder Loss:  0.031052284 Validation Decoder Loss:  0.34359533
Encoder Loss:  0.04882195  || Decoder Loss:  0.030924454 Validation Decoder Loss:  0.34395644
Encoder Loss:  0.04561765  || Decoder Loss:  0.030764598 Validation Decoder Loss:  0.34608942
Encoder Loss:  0.042704754  || Decoder Loss:  0.030559218 Validation Decoder Loss:  0.34536904
Encoder Loss:  0.04222708  || Decoder Loss:  0.030360287 Validation Decoder Loss:  0.34600347
Encoder Loss:  0.04203313  || Decoder Loss:  0.030200854 Validation Decoder Loss:  0.3460602
Encoder Loss:  0.04185324  || Decoder Loss:  0.030059386 Validation Decoder Loss:  0.34639195
Encoder Loss:  0.041803118  || Decoder Loss:  0.029929167 Validation Decoder Loss:  0.34646466
Encoder Loss:  0.041724063  || Decoder Loss:  0.029807601 Validation Decoder Loss:  0.34653345
Encoder Loss:  0.041663073  || Decoder Loss:  0.02969246 Validation Decoder Loss:  0.3466069
Encoder Loss:  0.041609515  || Decoder Loss:  0.029585542 Validation Decoder Loss:  0.34664154
Encoder Loss:  0.04155005  || Decoder Loss:  0.029485142 Validation Decoder Loss:  0.3466614
Encoder Loss:  0.04150173  || Decoder Loss:  0.029391592 Validation Decoder Loss:  0.3466847
Encoder Loss:  0.041454487  || Decoder Loss:  0.029304089 Validation Decoder Loss:  0.34665173
Encoder Loss:  0.04140996  || Decoder Loss:  0.029222447 Validation Decoder Loss:  0.34666425
Encoder Loss:  0.04137175  || Decoder Loss:  0.029144851 Validation Decoder Loss:  0.3466169
Encoder Loss:  0.04133086  || Decoder Loss:  0.029072542 Validation Decoder Loss:  0.3465901
Encoder Loss:  0.04129423  || Decoder Loss:  0.029003061 Validation Decoder Loss:  0.34653488
Encoder Loss:  0.04126222  || Decoder Loss:  0.028935697 Validation Decoder Loss:  0.34647578
Encoder Loss:  0.041232836  || Decoder Loss:  0.028871661 Validation Decoder Loss:  0.34645098
Encoder Loss:  0.0411986  || Decoder Loss:  0.028809287 Validation Decoder Loss:  0.3463777
Encoder Loss:  0.04116815  || Decoder Loss:  0.0287484 Validation Decoder Loss:  0.34631205
Encoder Loss:  0.041144032  || Decoder Loss:  0.028689208 Validation Decoder Loss:  0.34625664
Encoder Loss:  0.041109983  || Decoder Loss:  0.028632801 Validation Decoder Loss:  0.34619683
Encoder Loss:  0.041089296  || Decoder Loss:  0.02857618 Validation Decoder Loss:  0.34610814
Encoder Loss:  0.041061535  || Decoder Loss:  0.028522108 Validation Decoder Loss:  0.34605354
Encoder Loss:  0.041038826  || Decoder Loss:  0.028469548 Validation Decoder Loss:  0.34598982
Encoder Loss:  0.041016173  || Decoder Loss:  0.028418746 Validation Decoder Loss:  0.34594578
Encoder Loss:  0.040990494  || Decoder Loss:  0.028369306 Validation Decoder Loss:  0.34591275
Encoder Loss:  0.040972892  || Decoder Loss:  0.028320707 Validation Decoder Loss:  0.34587982
Encoder Loss:  0.04094861  || Decoder Loss:  0.02827363 Validation Decoder Loss:  0.34586108
Encoder Loss:  0.04092572  || Decoder Loss:  0.02822695 Validation Decoder Loss:  0.34583992
Encoder Loss:  0.04089832  || Decoder Loss:  0.028180819 Validation Decoder Loss:  0.34581003
Model: siamese_net_lr_0.003847059135005056 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34581003
Model: "sequential_638"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_347 (Conv3D (None, 164, 5, 20, 1)     39        
_________________________________________________________________
dropout_723 (Dropout)        (None, 164, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_348 (Conv3D (None, 184, 5, 20, 1)     22        
_________________________________________________________________
reshape_186 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_640"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 1650, 20, 1)       1597      
_________________________________________________________________
dropout_725 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 920, 20, 1)        732       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 2920, 20, 1)       2002      
_________________________________________________________________
dropout_727 (Dropout)        (None, 2920, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 3245, 20, 1)       327       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2794533  || Decoder Loss:  0.12436757 Validation Decoder Loss:  0.4253386
Encoder Loss:  0.10835824  || Decoder Loss:  0.06201981 Validation Decoder Loss:  0.33972636
Encoder Loss:  0.05466884  || Decoder Loss:  0.033552967 Validation Decoder Loss:  0.34045056
Encoder Loss:  0.05292235  || Decoder Loss:  0.033115137 Validation Decoder Loss:  0.34344202
Encoder Loss:  0.052902255  || Decoder Loss:  0.032707404 Validation Decoder Loss:  0.34356743
Encoder Loss:  0.05172865  || Decoder Loss:  0.032453798 Validation Decoder Loss:  0.3454619
Encoder Loss:  0.0574575  || Decoder Loss:  0.032370202 Validation Decoder Loss:  0.34408438
Encoder Loss:  0.0594472  || Decoder Loss:  0.03215162 Validation Decoder Loss:  0.3455634
Encoder Loss:  0.057165843  || Decoder Loss:  0.031581845 Validation Decoder Loss:  0.34647623
Encoder Loss:  0.052882243  || Decoder Loss:  0.031155562 Validation Decoder Loss:  0.34811467
Encoder Loss:  0.05107026  || Decoder Loss:  0.030904762 Validation Decoder Loss:  0.34961933
Encoder Loss:  0.054731723  || Decoder Loss:  0.030770913 Validation Decoder Loss:  0.35000962
Encoder Loss:  0.05077675  || Decoder Loss:  0.030521281 Validation Decoder Loss:  0.34861282
Encoder Loss:  0.052027375  || Decoder Loss:  0.030365478 Validation Decoder Loss:  0.34918052
Encoder Loss:  0.050955053  || Decoder Loss:  0.03024093 Validation Decoder Loss:  0.34834313
Encoder Loss:  0.050172  || Decoder Loss:  0.030123737 Validation Decoder Loss:  0.34759423
Encoder Loss:  0.051760267  || Decoder Loss:  0.03004873 Validation Decoder Loss:  0.34823918
Encoder Loss:  0.050195713  || Decoder Loss:  0.029947734 Validation Decoder Loss:  0.34866643
Encoder Loss:  0.05072178  || Decoder Loss:  0.029875748 Validation Decoder Loss:  0.3473946
Encoder Loss:  0.051726148  || Decoder Loss:  0.029818295 Validation Decoder Loss:  0.34869158
Encoder Loss:  0.05074932  || Decoder Loss:  0.029737737 Validation Decoder Loss:  0.34833482
Encoder Loss:  0.050187334  || Decoder Loss:  0.029657537 Validation Decoder Loss:  0.34829104
Encoder Loss:  0.05017108  || Decoder Loss:  0.029599532 Validation Decoder Loss:  0.3489613
Encoder Loss:  0.05125557  || Decoder Loss:  0.029563077 Validation Decoder Loss:  0.34956622
Encoder Loss:  0.05116624  || Decoder Loss:  0.02950672 Validation Decoder Loss:  0.3492122
Encoder Loss:  0.050299093  || Decoder Loss:  0.029437967 Validation Decoder Loss:  0.34831738
Encoder Loss:  0.050046474  || Decoder Loss:  0.029377561 Validation Decoder Loss:  0.34872139
Encoder Loss:  0.050149046  || Decoder Loss:  0.029334636 Validation Decoder Loss:  0.34876055
Encoder Loss:  0.05067389  || Decoder Loss:  0.029292105 Validation Decoder Loss:  0.34973174
Encoder Loss:  0.050318252  || Decoder Loss:  0.029230958 Validation Decoder Loss:  0.34876487
Encoder Loss:  0.04982293  || Decoder Loss:  0.029174445 Validation Decoder Loss:  0.348561
Encoder Loss:  0.05033643  || Decoder Loss:  0.029135182 Validation Decoder Loss:  0.34989917
Encoder Loss:  0.05166468  || Decoder Loss:  0.02911308 Validation Decoder Loss:  0.34955373
Encoder Loss:  0.04999041  || Decoder Loss:  0.029032685 Validation Decoder Loss:  0.34897262
Encoder Loss:  0.049691096  || Decoder Loss:  0.028984655 Validation Decoder Loss:  0.34877205
Encoder Loss:  0.050548628  || Decoder Loss:  0.028954234 Validation Decoder Loss:  0.34911853
Encoder Loss:  0.05031977  || Decoder Loss:  0.028901158 Validation Decoder Loss:  0.34967807
Encoder Loss:  0.049948324  || Decoder Loss:  0.028844545 Validation Decoder Loss:  0.34927964
Encoder Loss:  0.049593143  || Decoder Loss:  0.028795158 Validation Decoder Loss:  0.34953272
Encoder Loss:  0.04990176  || Decoder Loss:  0.02875215 Validation Decoder Loss:  0.3492352
Model: siamese_net_lr_0.003395365369310795 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34923524
Model: "sequential_642"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_350 (Conv3D (None, 166, 5, 20, 1)     104       
_________________________________________________________________
dropout_729 (Dropout)        (None, 166, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_351 (Conv3D (None, 184, 5, 20, 1)     20        
_________________________________________________________________
reshape_187 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 1650, 20, 1)       1597      
_________________________________________________________________
dropout_731 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 920, 20, 1)        732       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 2940, 20, 1)       1103      
_________________________________________________________________
dropout_733 (Dropout)        (None, 2940, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 3245, 20, 1)       307       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.47999114  || Decoder Loss:  0.490658 Validation Decoder Loss:  1.5893724
Encoder Loss:  0.46670136  || Decoder Loss:  0.4744662 Validation Decoder Loss:  0.39174324
Encoder Loss:  0.22369532  || Decoder Loss:  0.21213368 Validation Decoder Loss:  1.6579487
Encoder Loss:  0.51937187  || Decoder Loss:  0.5603722 Validation Decoder Loss:  1.4296353
Encoder Loss:  0.47341672  || Decoder Loss:  0.5134335 Validation Decoder Loss:  1.3437848
Encoder Loss:  0.4588977  || Decoder Loss:  0.49938548 Validation Decoder Loss:  1.3178031
Encoder Loss:  0.46029517  || Decoder Loss:  0.5012958 Validation Decoder Loss:  1.241601
Encoder Loss:  0.4560179  || Decoder Loss:  0.49687278 Validation Decoder Loss:  1.1927949
Encoder Loss:  0.4625857  || Decoder Loss:  0.5038579 Validation Decoder Loss:  1.2986312
Encoder Loss:  0.4640857  || Decoder Loss:  0.50629675 Validation Decoder Loss:  1.1906059
Encoder Loss:  0.460785  || Decoder Loss:  0.50289476 Validation Decoder Loss:  1.1515064
Encoder Loss:  0.46644607  || Decoder Loss:  0.50891995 Validation Decoder Loss:  1.1039305
Encoder Loss:  0.4623673  || Decoder Loss:  0.5045299 Validation Decoder Loss:  1.1930785
Encoder Loss:  0.46495306  || Decoder Loss:  0.50738394 Validation Decoder Loss:  1.083908
Encoder Loss:  0.46451378  || Decoder Loss:  0.5066167 Validation Decoder Loss:  1.0963411
Encoder Loss:  0.46074906  || Decoder Loss:  0.50311583 Validation Decoder Loss:  1.02293
Encoder Loss:  0.45564035  || Decoder Loss:  0.49683648 Validation Decoder Loss:  1.0364563
Encoder Loss:  0.45034808  || Decoder Loss:  0.49171162 Validation Decoder Loss:  1.0198014
Encoder Loss:  0.45026448  || Decoder Loss:  0.49105644 Validation Decoder Loss:  0.99605465
Encoder Loss:  0.44986096  || Decoder Loss:  0.4911701 Validation Decoder Loss:  0.99873334
Encoder Loss:  0.44768524  || Decoder Loss:  0.48937377 Validation Decoder Loss:  0.98681176
Encoder Loss:  0.44690654  || Decoder Loss:  0.48831117 Validation Decoder Loss:  0.9852823
Encoder Loss:  0.4455611  || Decoder Loss:  0.486852 Validation Decoder Loss:  0.9752396
Encoder Loss:  0.44454625  || Decoder Loss:  0.48568657 Validation Decoder Loss:  0.93513215
Encoder Loss:  0.44672725  || Decoder Loss:  0.48788166 Validation Decoder Loss:  0.9159529
Encoder Loss:  0.44338515  || Decoder Loss:  0.48418716 Validation Decoder Loss:  0.9115276
Encoder Loss:  0.44264042  || Decoder Loss:  0.4834845 Validation Decoder Loss:  0.8768395
Encoder Loss:  0.44196388  || Decoder Loss:  0.4826833 Validation Decoder Loss:  0.8775844
Encoder Loss:  0.44179094  || Decoder Loss:  0.482571 Validation Decoder Loss:  0.87979305
Encoder Loss:  0.43968165  || Decoder Loss:  0.4805542 Validation Decoder Loss:  0.879145
Encoder Loss:  0.44172913  || Decoder Loss:  0.4819994 Validation Decoder Loss:  0.9006271
Encoder Loss:  0.44193962  || Decoder Loss:  0.48203894 Validation Decoder Loss:  0.9279094
Encoder Loss:  0.44273108  || Decoder Loss:  0.48221338 Validation Decoder Loss:  0.93659747
Encoder Loss:  0.43918374  || Decoder Loss:  0.47944486 Validation Decoder Loss:  0.97203493
Encoder Loss:  0.4398914  || Decoder Loss:  0.4793036 Validation Decoder Loss:  0.97165966
Encoder Loss:  0.4383384  || Decoder Loss:  0.47880882 Validation Decoder Loss:  0.9561493
Encoder Loss:  0.43844932  || Decoder Loss:  0.47871968 Validation Decoder Loss:  0.95219946
Encoder Loss:  0.4382997  || Decoder Loss:  0.47860467 Validation Decoder Loss:  0.95747507
Encoder Loss:  0.43799743  || Decoder Loss:  0.47853848 Validation Decoder Loss:  0.9582113
Encoder Loss:  0.4389826  || Decoder Loss:  0.47859323 Validation Decoder Loss:  0.9546299
Model: siamese_net_lr_0.05236903871705333 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9546299
Model: "sequential_646"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_353 (Conv3D (None, 142, 5, 20, 1)     17        
_________________________________________________________________
dropout_735 (Dropout)        (None, 142, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_354 (Conv3D (None, 184, 5, 20, 1)     44        
_________________________________________________________________
reshape_188 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 2730, 20, 1)       517       
_________________________________________________________________
dropout_737 (Dropout)        (None, 2730, 20, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 920, 20, 1)        893       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_649"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 920, 20, 1)        2         
_________________________________________________________________
dropout_739 (Dropout)        (None, 920, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 3245, 20, 1)       2327      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22279482  || Decoder Loss:  0.08014571 Validation Decoder Loss:  0.3701788
Encoder Loss:  0.24861874  || Decoder Loss:  0.09602257 Validation Decoder Loss:  0.3708455
Encoder Loss:  0.2251747  || Decoder Loss:  0.05324393 Validation Decoder Loss:  0.37253147
Encoder Loss:  0.21981016  || Decoder Loss:  0.050042998 Validation Decoder Loss:  0.37523663
Encoder Loss:  0.13928324  || Decoder Loss:  0.05939751 Validation Decoder Loss:  0.47204792
Encoder Loss:  0.07355049  || Decoder Loss:  0.06902465 Validation Decoder Loss:  0.45270383
Encoder Loss:  0.08533219  || Decoder Loss:  0.061629675 Validation Decoder Loss:  0.46167868
Encoder Loss:  0.0697401  || Decoder Loss:  0.055981975 Validation Decoder Loss:  0.42653605
Encoder Loss:  0.069524914  || Decoder Loss:  0.049063187 Validation Decoder Loss:  0.39034212
Encoder Loss:  0.06845552  || Decoder Loss:  0.042983986 Validation Decoder Loss:  0.37169302
Encoder Loss:  0.061684575  || Decoder Loss:  0.038703747 Validation Decoder Loss:  0.35530654
Encoder Loss:  0.04850979  || Decoder Loss:  0.0362625 Validation Decoder Loss:  0.34534732
Encoder Loss:  0.04733814  || Decoder Loss:  0.035274442 Validation Decoder Loss:  0.34220633
Encoder Loss:  0.043813024  || Decoder Loss:  0.034736887 Validation Decoder Loss:  0.3415891
Encoder Loss:  0.04886878  || Decoder Loss:  0.034317125 Validation Decoder Loss:  0.3413852
Encoder Loss:  0.04911174  || Decoder Loss:  0.033954393 Validation Decoder Loss:  0.34140825
Encoder Loss:  0.05118963  || Decoder Loss:  0.03362665 Validation Decoder Loss:  0.3413517
Encoder Loss:  0.050534636  || Decoder Loss:  0.03330568 Validation Decoder Loss:  0.34146398
Encoder Loss:  0.04577725  || Decoder Loss:  0.03298649 Validation Decoder Loss:  0.34167364
Encoder Loss:  0.044913936  || Decoder Loss:  0.032671332 Validation Decoder Loss:  0.3418149
Encoder Loss:  0.044697024  || Decoder Loss:  0.03235477 Validation Decoder Loss:  0.34199482
Encoder Loss:  0.04411382  || Decoder Loss:  0.03203534 Validation Decoder Loss:  0.34219372
Encoder Loss:  0.048100162  || Decoder Loss:  0.031716302 Validation Decoder Loss:  0.34245104
Encoder Loss:  0.044952683  || Decoder Loss:  0.03140099 Validation Decoder Loss:  0.342687
Encoder Loss:  0.04350037  || Decoder Loss:  0.031092126 Validation Decoder Loss:  0.3430125
Encoder Loss:  0.043850895  || Decoder Loss:  0.030796979 Validation Decoder Loss:  0.34338006
Encoder Loss:  0.04293574  || Decoder Loss:  0.030519364 Validation Decoder Loss:  0.34376276
Encoder Loss:  0.044271287  || Decoder Loss:  0.030259345 Validation Decoder Loss:  0.3441728
Encoder Loss:  0.043915644  || Decoder Loss:  0.030015262 Validation Decoder Loss:  0.34456986
Encoder Loss:  0.04340971  || Decoder Loss:  0.029781038 Validation Decoder Loss:  0.34492904
Encoder Loss:  0.044707224  || Decoder Loss:  0.029553084 Validation Decoder Loss:  0.34528622
Encoder Loss:  0.04105764  || Decoder Loss:  0.02932723 Validation Decoder Loss:  0.34562695
Encoder Loss:  0.04106319  || Decoder Loss:  0.029102635 Validation Decoder Loss:  0.34597963
Encoder Loss:  0.043244664  || Decoder Loss:  0.02887826 Validation Decoder Loss:  0.34635085
Encoder Loss:  0.04211237  || Decoder Loss:  0.028651321 Validation Decoder Loss:  0.34670484
Encoder Loss:  0.04319228  || Decoder Loss:  0.02842065 Validation Decoder Loss:  0.34704727
Encoder Loss:  0.042121474  || Decoder Loss:  0.028186144 Validation Decoder Loss:  0.34741768
Encoder Loss:  0.046253387  || Decoder Loss:  0.027947528 Validation Decoder Loss:  0.34776872
Encoder Loss:  0.041076545  || Decoder Loss:  0.027706021 Validation Decoder Loss:  0.3480899
Encoder Loss:  0.042850856  || Decoder Loss:  0.027461475 Validation Decoder Loss:  0.34836426
Model: siamese_net_lr_0.062291008932368185 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34836426
Model: "sequential_650"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_356 (Conv3D (None, 82, 5, 20, 1)      20        
_________________________________________________________________
dropout_741 (Dropout)        (None, 82, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_357 (Conv3D (None, 184, 5, 20, 1)     23        
_________________________________________________________________
reshape_189 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 43
Trainable params: 43
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_652"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_272 (Conv2D)          (None, 1960, 20, 1)       1287      
_________________________________________________________________
dropout_743 (Dropout)        (None, 1960, 20, 1)       0         
_________________________________________________________________
conv2d_273 (Conv2D)          (None, 920, 20, 1)        123       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_653"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_272 (Conv2D (None, 3080, 20, 1)       2162      
_________________________________________________________________
dropout_745 (Dropout)        (None, 3080, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_273 (Conv2D (None, 3245, 20, 1)       167       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3730891  || Decoder Loss:  0.5781343 Validation Decoder Loss:  1.5222673
Encoder Loss:  0.28399476  || Decoder Loss:  0.55802965 Validation Decoder Loss:  1.4995341
Encoder Loss:  0.2715609  || Decoder Loss:  0.5384164 Validation Decoder Loss:  0.36278087
Encoder Loss:  0.22967671  || Decoder Loss:  0.4504845 Validation Decoder Loss:  1.1807132
Encoder Loss:  0.25296214  || Decoder Loss:  0.50352436 Validation Decoder Loss:  0.9864106
Encoder Loss:  0.24949035  || Decoder Loss:  0.4936805 Validation Decoder Loss:  0.9978355
Encoder Loss:  0.2483162  || Decoder Loss:  0.49194297 Validation Decoder Loss:  0.96965206
Encoder Loss:  0.24865891  || Decoder Loss:  0.49224436 Validation Decoder Loss:  0.9597771
Encoder Loss:  0.24788937  || Decoder Loss:  0.49175832 Validation Decoder Loss:  1.0152199
Encoder Loss:  0.24803333  || Decoder Loss:  0.49226746 Validation Decoder Loss:  0.9965959
Encoder Loss:  0.24768762  || Decoder Loss:  0.49131507 Validation Decoder Loss:  1.0129881
Encoder Loss:  0.24582414  || Decoder Loss:  0.48823258 Validation Decoder Loss:  1.0078585
Encoder Loss:  0.24473377  || Decoder Loss:  0.48375195 Validation Decoder Loss:  0.92165035
Encoder Loss:  0.2507761  || Decoder Loss:  0.49448854 Validation Decoder Loss:  0.946388
Encoder Loss:  0.2484731  || Decoder Loss:  0.48821625 Validation Decoder Loss:  1.0369817
Encoder Loss:  0.2509582  || Decoder Loss:  0.49270436 Validation Decoder Loss:  1.0852904
Encoder Loss:  0.24687663  || Decoder Loss:  0.4863141 Validation Decoder Loss:  1.0070803
Encoder Loss:  0.2330861  || Decoder Loss:  0.45933115 Validation Decoder Loss:  0.92432654
Encoder Loss:  0.21513644  || Decoder Loss:  0.41846997 Validation Decoder Loss:  0.9586202
Encoder Loss:  0.21179569  || Decoder Loss:  0.40932977 Validation Decoder Loss:  0.4894933
Encoder Loss:  0.26715505  || Decoder Loss:  0.53285867 Validation Decoder Loss:  0.9695772
Encoder Loss:  0.25367558  || Decoder Loss:  0.50543183 Validation Decoder Loss:  0.961133
Encoder Loss:  0.25376096  || Decoder Loss:  0.5047418 Validation Decoder Loss:  0.9661361
Encoder Loss:  0.25413692  || Decoder Loss:  0.50600225 Validation Decoder Loss:  0.9765011
Encoder Loss:  0.25246504  || Decoder Loss:  0.50384676 Validation Decoder Loss:  0.9897499
Encoder Loss:  0.25179884  || Decoder Loss:  0.5006697 Validation Decoder Loss:  0.95761025
Encoder Loss:  0.2548324  || Decoder Loss:  0.5046851 Validation Decoder Loss:  0.9919422
Encoder Loss:  0.25235897  || Decoder Loss:  0.5019861 Validation Decoder Loss:  0.9979899
Encoder Loss:  0.25029263  || Decoder Loss:  0.49539113 Validation Decoder Loss:  1.0005038
Encoder Loss:  0.25109833  || Decoder Loss:  0.49763888 Validation Decoder Loss:  1.0000486
Encoder Loss:  0.24932556  || Decoder Loss:  0.4955177 Validation Decoder Loss:  0.98803157
Encoder Loss:  0.24948204  || Decoder Loss:  0.49572334 Validation Decoder Loss:  0.9988915
Encoder Loss:  0.24801426  || Decoder Loss:  0.4920975 Validation Decoder Loss:  1.0054471
Encoder Loss:  0.24660093  || Decoder Loss:  0.48796904 Validation Decoder Loss:  0.9894935
Encoder Loss:  0.24792638  || Decoder Loss:  0.49214455 Validation Decoder Loss:  1.0435156
Encoder Loss:  0.25091332  || Decoder Loss:  0.49426582 Validation Decoder Loss:  1.0697904
Encoder Loss:  0.24785933  || Decoder Loss:  0.48721957 Validation Decoder Loss:  1.0469127
Encoder Loss:  0.24911556  || Decoder Loss:  0.494074 Validation Decoder Loss:  0.94419575
Encoder Loss:  0.25125676  || Decoder Loss:  0.49439552 Validation Decoder Loss:  0.9501265
Encoder Loss:  0.24904831  || Decoder Loss:  0.48928764 Validation Decoder Loss:  0.99479604
Model: siamese_net_lr_0.034526430368980496 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9947961
Model: "sequential_654"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_359 (Conv3D (None, 174, 5, 20, 1)     112       
_________________________________________________________________
dropout_747 (Dropout)        (None, 174, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_360 (Conv3D (None, 184, 5, 20, 1)     12        
_________________________________________________________________
reshape_190 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_656"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_274 (Conv2D)          (None, 2170, 20, 1)       1077      
_________________________________________________________________
dropout_749 (Dropout)        (None, 2170, 20, 1)       0         
_________________________________________________________________
conv2d_275 (Conv2D)          (None, 920, 20, 1)        1252      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_657"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_274 (Conv2D (None, 1380, 20, 1)       462       
_________________________________________________________________
dropout_751 (Dropout)        (None, 1380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_275 (Conv2D (None, 3245, 20, 1)       1867      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.59779966  || Decoder Loss:  0.62289584 Validation Decoder Loss:  1.4833
Encoder Loss:  0.7753494  || Decoder Loss:  0.8375361 Validation Decoder Loss:  1.2022108
Encoder Loss:  0.5116502  || Decoder Loss:  0.5531953 Validation Decoder Loss:  0.33904982
Encoder Loss:  0.112754375  || Decoder Loss:  0.11833706 Validation Decoder Loss:  0.4032002
Encoder Loss:  0.09022623  || Decoder Loss:  0.09380457 Validation Decoder Loss:  0.4216923
Encoder Loss:  0.08332048  || Decoder Loss:  0.08628989 Validation Decoder Loss:  0.42325562
Encoder Loss:  0.0786968  || Decoder Loss:  0.081262134 Validation Decoder Loss:  0.4233711
Encoder Loss:  0.0758085  || Decoder Loss:  0.07813118 Validation Decoder Loss:  0.42240492
Encoder Loss:  0.07343841  || Decoder Loss:  0.07554496 Validation Decoder Loss:  0.41916272
Encoder Loss:  0.07104037  || Decoder Loss:  0.07292588 Validation Decoder Loss:  0.41431597
Encoder Loss:  0.06853149  || Decoder Loss:  0.07018556 Validation Decoder Loss:  0.40902567
Encoder Loss:  0.06587057  || Decoder Loss:  0.06729171 Validation Decoder Loss:  0.40363526
Encoder Loss:  0.0630549  || Decoder Loss:  0.064226024 Validation Decoder Loss:  0.39802748
Encoder Loss:  0.06009415  || Decoder Loss:  0.06099467 Validation Decoder Loss:  0.39214337
Encoder Loss:  0.057118665  || Decoder Loss:  0.057694055 Validation Decoder Loss:  0.38623908
Encoder Loss:  0.0543684  || Decoder Loss:  0.05461238 Validation Decoder Loss:  0.38097546
Encoder Loss:  0.05240001  || Decoder Loss:  0.052265104 Validation Decoder Loss:  0.37737465
Encoder Loss:  0.0522455  || Decoder Loss:  0.050917253 Validation Decoder Loss:  0.37568408
Encoder Loss:  0.050741687  || Decoder Loss:  0.050267104 Validation Decoder Loss:  0.37474287
Encoder Loss:  0.050388593  || Decoder Loss:  0.04973277 Validation Decoder Loss:  0.3735606
Encoder Loss:  0.04934829  || Decoder Loss:  0.049036913 Validation Decoder Loss:  0.37228587
Encoder Loss:  0.048663184  || Decoder Loss:  0.048367642 Validation Decoder Loss:  0.3709702
Encoder Loss:  0.048741285  || Decoder Loss:  0.04778031 Validation Decoder Loss:  0.36971536
Encoder Loss:  0.047940664  || Decoder Loss:  0.04714452 Validation Decoder Loss:  0.36841905
Encoder Loss:  0.047170736  || Decoder Loss:  0.046560463 Validation Decoder Loss:  0.36719358
Encoder Loss:  0.04646582  || Decoder Loss:  0.046028085 Validation Decoder Loss:  0.36593503
Encoder Loss:  0.045767527  || Decoder Loss:  0.045322213 Validation Decoder Loss:  0.36464733
Encoder Loss:  0.045010466  || Decoder Loss:  0.04453892 Validation Decoder Loss:  0.3632534
Encoder Loss:  0.04413394  || Decoder Loss:  0.043586556 Validation Decoder Loss:  0.36171216
Encoder Loss:  0.043034706  || Decoder Loss:  0.042388536 Validation Decoder Loss:  0.3601199
Encoder Loss:  0.041791078  || Decoder Loss:  0.041036945 Validation Decoder Loss:  0.3590327
Encoder Loss:  0.040749554  || Decoder Loss:  0.03990025 Validation Decoder Loss:  0.35866246
Encoder Loss:  0.040043417  || Decoder Loss:  0.03913037 Validation Decoder Loss:  0.35801575
Encoder Loss:  0.03952549  || Decoder Loss:  0.038564745 Validation Decoder Loss:  0.35710317
Encoder Loss:  0.039144155  || Decoder Loss:  0.038150012 Validation Decoder Loss:  0.35635662
Encoder Loss:  0.038860574  || Decoder Loss:  0.0378397 Validation Decoder Loss:  0.35581428
Encoder Loss:  0.03862394  || Decoder Loss:  0.037582435 Validation Decoder Loss:  0.35542744
Encoder Loss:  0.038411677  || Decoder Loss:  0.037350334 Validation Decoder Loss:  0.35511357
Encoder Loss:  0.03820428  || Decoder Loss:  0.037125226 Validation Decoder Loss:  0.3548537
Encoder Loss:  0.03799853  || Decoder Loss:  0.03689961 Validation Decoder Loss:  0.3545988
Model: siamese_net_lr_0.017130392729228814 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35459882
Model: "sequential_658"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_362 (Conv3D (None, 158, 5, 20, 1)     33        
_________________________________________________________________
dropout_753 (Dropout)        (None, 158, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_363 (Conv3D (None, 184, 5, 20, 1)     28        
_________________________________________________________________
reshape_191 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_660"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_276 (Conv2D)          (None, 1610, 20, 1)       1637      
_________________________________________________________________
dropout_755 (Dropout)        (None, 1610, 20, 1)       0         
_________________________________________________________________
conv2d_277 (Conv2D)          (None, 920, 20, 1)        692       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_661"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_276 (Conv2D (None, 2910, 20, 1)       1073      
_________________________________________________________________
dropout_757 (Dropout)        (None, 2910, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_277 (Conv2D (None, 3245, 20, 1)       337       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22334754  || Decoder Loss:  0.18869314 Validation Decoder Loss:  0.37988228
Encoder Loss:  0.1706086  || Decoder Loss:  0.12273468 Validation Decoder Loss:  0.37403977
Encoder Loss:  0.6381533  || Decoder Loss:  0.6828812 Validation Decoder Loss:  1.6217941
Encoder Loss:  0.8131464  || Decoder Loss:  0.8877478 Validation Decoder Loss:  1.6171143
Encoder Loss:  0.8103379  || Decoder Loss:  0.88458085 Validation Decoder Loss:  1.6105936
Encoder Loss:  0.807148  || Decoder Loss:  0.8809446 Validation Decoder Loss:  1.6024481
Encoder Loss:  0.80334306  || Decoder Loss:  0.8766125 Validation Decoder Loss:  1.5917878
Encoder Loss:  0.7983515  || Decoder Loss:  0.87108696 Validation Decoder Loss:  1.5763938
Encoder Loss:  0.789119  || Decoder Loss:  0.86306727 Validation Decoder Loss:  1.5495151
Encoder Loss:  0.7776231  || Decoder Loss:  0.84622854 Validation Decoder Loss:  1.4675897
Encoder Loss:  0.48691395  || Decoder Loss:  0.49830106 Validation Decoder Loss:  0.320576
Encoder Loss:  0.15626532  || Decoder Loss:  0.10259597 Validation Decoder Loss:  0.34717298
Encoder Loss:  0.15622376  || Decoder Loss:  0.10294738 Validation Decoder Loss:  0.34952962
Encoder Loss:  0.15496272  || Decoder Loss:  0.10205513 Validation Decoder Loss:  0.35060924
Encoder Loss:  0.15332991  || Decoder Loss:  0.101492 Validation Decoder Loss:  0.35377246
Encoder Loss:  0.331427  || Decoder Loss:  0.34025276 Validation Decoder Loss:  1.5613933
Encoder Loss:  0.43916276  || Decoder Loss:  0.49804756 Validation Decoder Loss:  1.2679126
Encoder Loss:  0.42102805  || Decoder Loss:  0.4794479 Validation Decoder Loss:  1.3079836
Encoder Loss:  0.39092147  || Decoder Loss:  0.44247085 Validation Decoder Loss:  1.2873069
Encoder Loss:  0.40703133  || Decoder Loss:  0.46505272 Validation Decoder Loss:  1.183917
Encoder Loss:  0.40585172  || Decoder Loss:  0.4640984 Validation Decoder Loss:  1.2790449
Encoder Loss:  0.3937427  || Decoder Loss:  0.44858438 Validation Decoder Loss:  1.2628257
Encoder Loss:  0.39707834  || Decoder Loss:  0.45364887 Validation Decoder Loss:  1.2647994
Encoder Loss:  0.39539033  || Decoder Loss:  0.45173186 Validation Decoder Loss:  1.2549403
Encoder Loss:  0.3958285  || Decoder Loss:  0.45272332 Validation Decoder Loss:  1.2535028
Encoder Loss:  0.39634448  || Decoder Loss:  0.4534808 Validation Decoder Loss:  1.2374961
Encoder Loss:  0.39385602  || Decoder Loss:  0.45049676 Validation Decoder Loss:  1.2113363
Encoder Loss:  0.39354438  || Decoder Loss:  0.45036966 Validation Decoder Loss:  1.2125272
Encoder Loss:  0.3928422  || Decoder Loss:  0.44980183 Validation Decoder Loss:  1.2053337
Encoder Loss:  0.39206004  || Decoder Loss:  0.44949418 Validation Decoder Loss:  1.1734314
Encoder Loss:  0.39988846  || Decoder Loss:  0.4593799 Validation Decoder Loss:  1.087199
Encoder Loss:  0.3946044  || Decoder Loss:  0.45647275 Validation Decoder Loss:  0.90115
Encoder Loss:  0.41243988  || Decoder Loss:  0.48250756 Validation Decoder Loss:  0.8856425
Encoder Loss:  0.42092937  || Decoder Loss:  0.4918103 Validation Decoder Loss:  0.7781903
Encoder Loss:  0.42610607  || Decoder Loss:  0.49836957 Validation Decoder Loss:  0.8577379
Encoder Loss:  0.41988397  || Decoder Loss:  0.4917529 Validation Decoder Loss:  0.86824906
Encoder Loss:  0.42105934  || Decoder Loss:  0.49367794 Validation Decoder Loss:  0.88568974
Encoder Loss:  0.4179679  || Decoder Loss:  0.49005353 Validation Decoder Loss:  0.93728685
Encoder Loss:  0.41733634  || Decoder Loss:  0.48973027 Validation Decoder Loss:  0.9606724
Encoder Loss:  0.41654953  || Decoder Loss:  0.48889688 Validation Decoder Loss:  0.96734035
Model: siamese_net_lr_0.044525992279089134 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.96734035
Model: "sequential_662"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_365 (Conv3D (None, 172, 5, 20, 1)     47        
_________________________________________________________________
dropout_759 (Dropout)        (None, 172, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_366 (Conv3D (None, 184, 5, 20, 1)     14        
_________________________________________________________________
reshape_192 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_664"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_278 (Conv2D)          (None, 2170, 20, 1)       1077      
_________________________________________________________________
dropout_761 (Dropout)        (None, 2170, 20, 1)       0         
_________________________________________________________________
conv2d_279 (Conv2D)          (None, 920, 20, 1)        1252      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_665"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_278 (Conv2D (None, 1400, 20, 1)       482       
_________________________________________________________________
dropout_763 (Dropout)        (None, 1400, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_279 (Conv2D (None, 3245, 20, 1)       1847      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20704663  || Decoder Loss:  0.14173014 Validation Decoder Loss:  0.3782395
Encoder Loss:  0.17248622  || Decoder Loss:  0.08809693 Validation Decoder Loss:  0.376445
Encoder Loss:  0.16680534  || Decoder Loss:  0.08082066 Validation Decoder Loss:  0.37902594
Encoder Loss:  0.16213323  || Decoder Loss:  0.07490375 Validation Decoder Loss:  0.38460398
Encoder Loss:  0.15825188  || Decoder Loss:  0.07007051 Validation Decoder Loss:  0.38789934
Encoder Loss:  0.15319088  || Decoder Loss:  0.06375113 Validation Decoder Loss:  0.3734902
Encoder Loss:  0.1438328  || Decoder Loss:  0.0518824 Validation Decoder Loss:  0.34560278
Encoder Loss:  0.1381864  || Decoder Loss:  0.044951115 Validation Decoder Loss:  0.34693378
Encoder Loss:  0.13445964  || Decoder Loss:  0.040672675 Validation Decoder Loss:  0.34916386
Encoder Loss:  0.132281  || Decoder Loss:  0.038723484 Validation Decoder Loss:  0.34822425
Encoder Loss:  0.13025934  || Decoder Loss:  0.03802496 Validation Decoder Loss:  0.35035205
Encoder Loss:  0.35380515  || Decoder Loss:  0.355245 Validation Decoder Loss:  1.4795859
Encoder Loss:  0.42389897  || Decoder Loss:  0.50569844 Validation Decoder Loss:  0.7179768
Encoder Loss:  0.38421002  || Decoder Loss:  0.46695277 Validation Decoder Loss:  0.59746647
Encoder Loss:  0.39477098  || Decoder Loss:  0.47761154 Validation Decoder Loss:  0.668154
Encoder Loss:  0.3972913  || Decoder Loss:  0.48554063 Validation Decoder Loss:  0.65608954
Encoder Loss:  0.40512466  || Decoder Loss:  0.495965 Validation Decoder Loss:  0.6817596
Encoder Loss:  0.4031576  || Decoder Loss:  0.49322936 Validation Decoder Loss:  0.71783984
Encoder Loss:  0.40031403  || Decoder Loss:  0.49011984 Validation Decoder Loss:  0.7300996
Encoder Loss:  0.39962876  || Decoder Loss:  0.48937374 Validation Decoder Loss:  0.7443608
Encoder Loss:  0.40177009  || Decoder Loss:  0.49169257 Validation Decoder Loss:  0.77808636
Encoder Loss:  0.39853343  || Decoder Loss:  0.4883137 Validation Decoder Loss:  0.80914557
Encoder Loss:  0.39617348  || Decoder Loss:  0.485237 Validation Decoder Loss:  0.81516814
Encoder Loss:  0.39298373  || Decoder Loss:  0.48128104 Validation Decoder Loss:  0.822717
Encoder Loss:  0.38452023  || Decoder Loss:  0.46998554 Validation Decoder Loss:  0.8076577
Encoder Loss:  0.38189727  || Decoder Loss:  0.46633866 Validation Decoder Loss:  0.80208874
Encoder Loss:  0.3759302  || Decoder Loss:  0.45901957 Validation Decoder Loss:  0.7878162
Encoder Loss:  0.37230653  || Decoder Loss:  0.45500907 Validation Decoder Loss:  0.7574836
Encoder Loss:  0.37765953  || Decoder Loss:  0.45996705 Validation Decoder Loss:  0.7675438
Encoder Loss:  0.37161213  || Decoder Loss:  0.4538975 Validation Decoder Loss:  0.7255957
Encoder Loss:  0.37086475  || Decoder Loss:  0.45198154 Validation Decoder Loss:  0.74745363
Encoder Loss:  0.36580545  || Decoder Loss:  0.44654733 Validation Decoder Loss:  0.7165443
Encoder Loss:  0.36591253  || Decoder Loss:  0.44636878 Validation Decoder Loss:  0.7139417
Encoder Loss:  0.3757202  || Decoder Loss:  0.45903325 Validation Decoder Loss:  0.7151046
Encoder Loss:  0.3683716  || Decoder Loss:  0.4497303 Validation Decoder Loss:  0.722593
Encoder Loss:  0.3663697  || Decoder Loss:  0.44765496 Validation Decoder Loss:  0.68521595
Encoder Loss:  0.37247756  || Decoder Loss:  0.4536646 Validation Decoder Loss:  0.7493534
Encoder Loss:  0.37510455  || Decoder Loss:  0.45859164 Validation Decoder Loss:  0.69845605
Encoder Loss:  0.3658228  || Decoder Loss:  0.44576672 Validation Decoder Loss:  0.7593317
Encoder Loss:  0.37022498  || Decoder Loss:  0.45268655 Validation Decoder Loss:  0.6968727
Model: siamese_net_lr_0.06933127173007368 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.6968728
Model: "sequential_666"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_368 (Conv3D (None, 158, 5, 20, 1)     33        
_________________________________________________________________
dropout_765 (Dropout)        (None, 158, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_369 (Conv3D (None, 184, 5, 20, 1)     28        
_________________________________________________________________
reshape_193 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_668"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_280 (Conv2D)          (None, 3040, 20, 1)       207       
_________________________________________________________________
dropout_767 (Dropout)        (None, 3040, 20, 1)       0         
_________________________________________________________________
conv2d_281 (Conv2D)          (None, 920, 20, 1)        284       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_669"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_280 (Conv2D (None, 3010, 20, 1)       254       
_________________________________________________________________
dropout_769 (Dropout)        (None, 3010, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_281 (Conv2D (None, 3245, 20, 1)       237       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6114803  || Decoder Loss:  0.8883055 Validation Decoder Loss:  1.6011801
Encoder Loss:  0.6400361  || Decoder Loss:  0.92194676 Validation Decoder Loss:  1.5868568
Encoder Loss:  0.58574796  || Decoder Loss:  0.86566675 Validation Decoder Loss:  0.33221486
Encoder Loss:  0.2891403  || Decoder Loss:  0.3138768 Validation Decoder Loss:  0.88414675
Encoder Loss:  0.27969185  || Decoder Loss:  0.47837934 Validation Decoder Loss:  0.6713215
Encoder Loss:  0.27424887  || Decoder Loss:  0.50093794 Validation Decoder Loss:  0.5634922
Encoder Loss:  0.2761367  || Decoder Loss:  0.49247608 Validation Decoder Loss:  0.7120931
Encoder Loss:  0.25381342  || Decoder Loss:  0.48668498 Validation Decoder Loss:  0.8826394
Encoder Loss:  0.24663967  || Decoder Loss:  0.4829644 Validation Decoder Loss:  1.1698397
Encoder Loss:  0.24231087  || Decoder Loss:  0.4830973 Validation Decoder Loss:  0.8887725
Encoder Loss:  0.24662142  || Decoder Loss:  0.48233005 Validation Decoder Loss:  0.99615145
Encoder Loss:  0.25030896  || Decoder Loss:  0.4829317 Validation Decoder Loss:  1.1637225
Encoder Loss:  0.27056164  || Decoder Loss:  0.5002874 Validation Decoder Loss:  1.198653
Encoder Loss:  0.2516771  || Decoder Loss:  0.4883179 Validation Decoder Loss:  1.0876452
Encoder Loss:  0.24535507  || Decoder Loss:  0.4807943 Validation Decoder Loss:  1.0048077
Encoder Loss:  0.24781899  || Decoder Loss:  0.48196 Validation Decoder Loss:  0.9284766
Encoder Loss:  0.25051877  || Decoder Loss:  0.4822223 Validation Decoder Loss:  0.943155
Encoder Loss:  0.25361258  || Decoder Loss:  0.4827861 Validation Decoder Loss:  1.0596223
Encoder Loss:  0.24588503  || Decoder Loss:  0.4795335 Validation Decoder Loss:  1.0116808
Encoder Loss:  0.2399738  || Decoder Loss:  0.47900435 Validation Decoder Loss:  1.0145128
Encoder Loss:  0.24734163  || Decoder Loss:  0.47915435 Validation Decoder Loss:  1.024056
Encoder Loss:  0.2442338  || Decoder Loss:  0.47737053 Validation Decoder Loss:  0.95580876
Encoder Loss:  0.24254572  || Decoder Loss:  0.47729558 Validation Decoder Loss:  1.0819597
Encoder Loss:  0.24413191  || Decoder Loss:  0.47588181 Validation Decoder Loss:  0.99009025
Encoder Loss:  0.23882306  || Decoder Loss:  0.47573388 Validation Decoder Loss:  1.0095952
Encoder Loss:  0.2395708  || Decoder Loss:  0.4749226 Validation Decoder Loss:  1.1103019
Encoder Loss:  0.23919424  || Decoder Loss:  0.47537813 Validation Decoder Loss:  1.0566216
Encoder Loss:  0.23857771  || Decoder Loss:  0.47412527 Validation Decoder Loss:  1.0716822
Encoder Loss:  0.24166992  || Decoder Loss:  0.47542304 Validation Decoder Loss:  1.1278002
Encoder Loss:  0.24069561  || Decoder Loss:  0.4745449 Validation Decoder Loss:  1.1130496
Encoder Loss:  0.2412074  || Decoder Loss:  0.47514248 Validation Decoder Loss:  1.0124018
Encoder Loss:  0.24168521  || Decoder Loss:  0.47487503 Validation Decoder Loss:  1.0894544
Encoder Loss:  0.24047336  || Decoder Loss:  0.47535026 Validation Decoder Loss:  1.0296359
Encoder Loss:  0.24121939  || Decoder Loss:  0.47495374 Validation Decoder Loss:  1.1179706
Encoder Loss:  0.24451904  || Decoder Loss:  0.4766338 Validation Decoder Loss:  1.1421483
Encoder Loss:  0.23898594  || Decoder Loss:  0.47447535 Validation Decoder Loss:  1.0579872
Encoder Loss:  0.23762831  || Decoder Loss:  0.4740106 Validation Decoder Loss:  1.0258958
Encoder Loss:  0.23990557  || Decoder Loss:  0.47327667 Validation Decoder Loss:  1.1447406
Encoder Loss:  0.2392619  || Decoder Loss:  0.47191092 Validation Decoder Loss:  1.1243225
Encoder Loss:  0.24267325  || Decoder Loss:  0.48368573 Validation Decoder Loss:  0.7458811
Model: siamese_net_lr_0.07246143039775545 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7458811
Model: "sequential_670"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_371 (Conv3D (None, 168, 5, 20, 1)     43        
_________________________________________________________________
dropout_771 (Dropout)        (None, 168, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_372 (Conv3D (None, 184, 5, 20, 1)     18        
_________________________________________________________________
reshape_194 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_672"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_282 (Conv2D)          (None, 1810, 20, 1)       1437      
_________________________________________________________________
dropout_773 (Dropout)        (None, 1810, 20, 1)       0         
_________________________________________________________________
conv2d_283 (Conv2D)          (None, 920, 20, 1)        892       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_673"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_282 (Conv2D (None, 2550, 20, 1)       1632      
_________________________________________________________________
dropout_775 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_283 (Conv2D (None, 3245, 20, 1)       697       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41177747  || Decoder Loss:  0.5437448 Validation Decoder Loss:  1.6094826
Encoder Loss:  0.34069297  || Decoder Loss:  0.5464001 Validation Decoder Loss:  0.4471612
Encoder Loss:  0.25461304  || Decoder Loss:  0.42374897 Validation Decoder Loss:  1.2767766
Encoder Loss:  0.2752565  || Decoder Loss:  0.46330872 Validation Decoder Loss:  0.7717977
Encoder Loss:  0.2983793  || Decoder Loss:  0.5580501 Validation Decoder Loss:  1.4195666
Encoder Loss:  0.27434888  || Decoder Loss:  0.48256782 Validation Decoder Loss:  0.29367244
Encoder Loss:  0.25850028  || Decoder Loss:  0.43039748 Validation Decoder Loss:  0.29216146
Encoder Loss:  0.2450866  || Decoder Loss:  0.46010756 Validation Decoder Loss:  0.40805057
Encoder Loss:  0.26423267  || Decoder Loss:  0.5278151 Validation Decoder Loss:  0.78543055
Encoder Loss:  0.24810793  || Decoder Loss:  0.50143874 Validation Decoder Loss:  0.68576247
Encoder Loss:  0.23206656  || Decoder Loss:  0.4716681 Validation Decoder Loss:  0.9429608
Encoder Loss:  0.25439233  || Decoder Loss:  0.5078666 Validation Decoder Loss:  0.74649465
Encoder Loss:  0.2431529  || Decoder Loss:  0.49080274 Validation Decoder Loss:  0.73163676
Encoder Loss:  0.23600635  || Decoder Loss:  0.47352958 Validation Decoder Loss:  0.58688915
Encoder Loss:  0.24105558  || Decoder Loss:  0.48142424 Validation Decoder Loss:  1.0591314
Encoder Loss:  0.23961298  || Decoder Loss:  0.4773455 Validation Decoder Loss:  0.830648
Encoder Loss:  0.23323673  || Decoder Loss:  0.46861935 Validation Decoder Loss:  0.8524149
Encoder Loss:  0.23899521  || Decoder Loss:  0.46708828 Validation Decoder Loss:  0.957409
Encoder Loss:  0.22593272  || Decoder Loss:  0.46138653 Validation Decoder Loss:  0.9362796
Encoder Loss:  0.23397852  || Decoder Loss:  0.4622444 Validation Decoder Loss:  0.91488993
Encoder Loss:  0.22014102  || Decoder Loss:  0.45715845 Validation Decoder Loss:  0.9464967
Encoder Loss:  0.22560889  || Decoder Loss:  0.45570287 Validation Decoder Loss:  0.925141
Encoder Loss:  0.22657894  || Decoder Loss:  0.4543242 Validation Decoder Loss:  0.9638269
Encoder Loss:  0.22130898  || Decoder Loss:  0.44988492 Validation Decoder Loss:  0.9925431
Encoder Loss:  0.2218984  || Decoder Loss:  0.44827023 Validation Decoder Loss:  1.0012786
Encoder Loss:  0.21864389  || Decoder Loss:  0.44540462 Validation Decoder Loss:  0.9533357
Encoder Loss:  0.22230591  || Decoder Loss:  0.44747013 Validation Decoder Loss:  0.9944625
Encoder Loss:  0.22930561  || Decoder Loss:  0.44769207 Validation Decoder Loss:  1.0001602
Encoder Loss:  0.21689795  || Decoder Loss:  0.4434061 Validation Decoder Loss:  0.9937997
Encoder Loss:  0.21545596  || Decoder Loss:  0.44210544 Validation Decoder Loss:  0.9843663
Encoder Loss:  0.21800463  || Decoder Loss:  0.44131267 Validation Decoder Loss:  0.9919309
Encoder Loss:  0.21251145  || Decoder Loss:  0.43966514 Validation Decoder Loss:  0.99701643
Encoder Loss:  0.21859306  || Decoder Loss:  0.43989387 Validation Decoder Loss:  0.98534805
Encoder Loss:  0.2180101  || Decoder Loss:  0.43930206 Validation Decoder Loss:  0.9966456
Encoder Loss:  0.21971717  || Decoder Loss:  0.4384229 Validation Decoder Loss:  1.0731231
Encoder Loss:  0.21889305  || Decoder Loss:  0.4393158 Validation Decoder Loss:  1.0028936
Encoder Loss:  0.21334459  || Decoder Loss:  0.43660918 Validation Decoder Loss:  1.0010185
Encoder Loss:  0.21180171  || Decoder Loss:  0.43609104 Validation Decoder Loss:  1.0018775
Encoder Loss:  0.2127339  || Decoder Loss:  0.4356339 Validation Decoder Loss:  1.0024937
Encoder Loss:  0.21265975  || Decoder Loss:  0.43535474 Validation Decoder Loss:  1.014396
Model: siamese_net_lr_0.09023109329897219 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.014396
Model: "sequential_674"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_374 (Conv3D (None, 148, 5, 20, 1)     86        
_________________________________________________________________
dropout_777 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_375 (Conv3D (None, 184, 5, 20, 1)     38        
_________________________________________________________________
reshape_195 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_676"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_284 (Conv2D)          (None, 2780, 20, 1)       467       
_________________________________________________________________
dropout_779 (Dropout)        (None, 2780, 20, 1)       0         
_________________________________________________________________
conv2d_285 (Conv2D)          (None, 920, 20, 1)        943       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_677"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_284 (Conv2D (None, 970, 20, 1)        52        
_________________________________________________________________
dropout_781 (Dropout)        (None, 970, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_285 (Conv2D (None, 3245, 20, 1)       1308      
=================================================================
Total params: 1,360
Trainable params: 1,360
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.55021805  || Decoder Loss:  0.7705038 Validation Decoder Loss:  1.1993551
Encoder Loss:  0.3143798  || Decoder Loss:  0.19251014 Validation Decoder Loss:  0.47179863
Encoder Loss:  0.2864696  || Decoder Loss:  0.11142883 Validation Decoder Loss:  0.4314716
Encoder Loss:  0.28297183  || Decoder Loss:  0.10429376 Validation Decoder Loss:  0.40850663
Encoder Loss:  0.27962962  || Decoder Loss:  0.09760413 Validation Decoder Loss:  0.38858983
Encoder Loss:  0.27581972  || Decoder Loss:  0.09000904 Validation Decoder Loss:  0.3707276
Encoder Loss:  0.2710604  || Decoder Loss:  0.080399185 Validation Decoder Loss:  0.3569305
Encoder Loss:  0.26532266  || Decoder Loss:  0.06873794 Validation Decoder Loss:  0.36268124
Encoder Loss:  0.26201645  || Decoder Loss:  0.063113324 Validation Decoder Loss:  0.38437018
Encoder Loss:  0.26077977  || Decoder Loss:  0.06274225 Validation Decoder Loss:  0.38257885
Encoder Loss:  0.25954276  || Decoder Loss:  0.062852204 Validation Decoder Loss:  0.38742787
Encoder Loss:  0.25820148  || Decoder Loss:  0.06337038 Validation Decoder Loss:  0.39247516
Encoder Loss:  0.25670823  || Decoder Loss:  0.06447856 Validation Decoder Loss:  0.39873955
Encoder Loss:  0.25495607  || Decoder Loss:  0.06648046 Validation Decoder Loss:  0.40731183
Encoder Loss:  0.25270596  || Decoder Loss:  0.070044346 Validation Decoder Loss:  0.42035872
Encoder Loss:  0.24921517  || Decoder Loss:  0.077088624 Validation Decoder Loss:  0.4467573
Encoder Loss:  0.23870806  || Decoder Loss:  0.10619209 Validation Decoder Loss:  1.0428426
Encoder Loss:  0.25827315  || Decoder Loss:  0.38028732 Validation Decoder Loss:  1.2773316
Encoder Loss:  0.26530874  || Decoder Loss:  0.5127107 Validation Decoder Loss:  0.68153405
Encoder Loss:  0.2661546  || Decoder Loss:  0.5156777 Validation Decoder Loss:  0.7315392
Encoder Loss:  0.26038057  || Decoder Loss:  0.52378935 Validation Decoder Loss:  0.62901807
Encoder Loss:  0.25391173  || Decoder Loss:  0.5127259 Validation Decoder Loss:  0.56427145
Encoder Loss:  0.25298598  || Decoder Loss:  0.5092831 Validation Decoder Loss:  0.59018683
Encoder Loss:  0.25059512  || Decoder Loss:  0.5078582 Validation Decoder Loss:  0.6429572
Encoder Loss:  0.24903259  || Decoder Loss:  0.50466865 Validation Decoder Loss:  0.67524755
Encoder Loss:  0.24823092  || Decoder Loss:  0.49975803 Validation Decoder Loss:  0.6445011
Encoder Loss:  0.24580519  || Decoder Loss:  0.4980911 Validation Decoder Loss:  0.69585216
Encoder Loss:  0.24500024  || Decoder Loss:  0.49552417 Validation Decoder Loss:  0.69103885
Encoder Loss:  0.24460438  || Decoder Loss:  0.49361566 Validation Decoder Loss:  0.771698
Encoder Loss:  0.24165986  || Decoder Loss:  0.49277374 Validation Decoder Loss:  0.7685759
Encoder Loss:  0.2399728  || Decoder Loss:  0.48707497 Validation Decoder Loss:  0.7397659
Encoder Loss:  0.23709188  || Decoder Loss:  0.4785298 Validation Decoder Loss:  1.2310507
Encoder Loss:  0.24416111  || Decoder Loss:  0.5002902 Validation Decoder Loss:  1.2873127
Encoder Loss:  0.24398293  || Decoder Loss:  0.49915642 Validation Decoder Loss:  1.3257818
Encoder Loss:  0.2419036  || Decoder Loss:  0.49495924 Validation Decoder Loss:  1.3380833
Encoder Loss:  0.24179897  || Decoder Loss:  0.4947288 Validation Decoder Loss:  1.348238
Encoder Loss:  0.24079324  || Decoder Loss:  0.49274883 Validation Decoder Loss:  1.3583933
Encoder Loss:  0.23905085  || Decoder Loss:  0.4890013 Validation Decoder Loss:  1.359302
Encoder Loss:  0.23826079  || Decoder Loss:  0.4882306 Validation Decoder Loss:  1.3304093
Encoder Loss:  0.23788357  || Decoder Loss:  0.48780864 Validation Decoder Loss:  1.3198059
Model: siamese_net_lr_0.09870308405489982 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.3198059
Model: "sequential_678"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_377 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_783 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_378 (Conv3D (None, 184, 5, 20, 1)     66        
_________________________________________________________________
reshape_196 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_680"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_286 (Conv2D)          (None, 1130, 20, 1)       2117      
_________________________________________________________________
dropout_785 (Dropout)        (None, 1130, 20, 1)       0         
_________________________________________________________________
conv2d_287 (Conv2D)          (None, 920, 20, 1)        212       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_681"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_286 (Conv2D (None, 2740, 20, 1)       1822      
_________________________________________________________________
dropout_787 (Dropout)        (None, 2740, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_287 (Conv2D (None, 3245, 20, 1)       507       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.074929565  || Decoder Loss:  0.0752359 Validation Decoder Loss:  0.34898174
Encoder Loss:  0.038396303  || Decoder Loss:  0.037647054 Validation Decoder Loss:  0.34261495
Encoder Loss:  0.037118904  || Decoder Loss:  0.036318142 Validation Decoder Loss:  0.35592222
Encoder Loss:  0.036253184  || Decoder Loss:  0.035611633 Validation Decoder Loss:  0.33424598
Encoder Loss:  0.03550821  || Decoder Loss:  0.034947734 Validation Decoder Loss:  0.33277047
Encoder Loss:  0.034147654  || Decoder Loss:  0.033557292 Validation Decoder Loss:  0.342516
Encoder Loss:  0.0332458  || Decoder Loss:  0.0326293 Validation Decoder Loss:  0.3431547
Encoder Loss:  0.032614835  || Decoder Loss:  0.031976223 Validation Decoder Loss:  0.34228635
Encoder Loss:  0.032097936  || Decoder Loss:  0.031441472 Validation Decoder Loss:  0.34193093
Encoder Loss:  0.031661827  || Decoder Loss:  0.030990697 Validation Decoder Loss:  0.34235778
Encoder Loss:  0.031290725  || Decoder Loss:  0.030602193 Validation Decoder Loss:  0.34472737
Encoder Loss:  0.030975943  || Decoder Loss:  0.030277476 Validation Decoder Loss:  0.34421608
Encoder Loss:  0.030684676  || Decoder Loss:  0.029979628 Validation Decoder Loss:  0.34413868
Encoder Loss:  0.03043219  || Decoder Loss:  0.029718168 Validation Decoder Loss:  0.3436275
Encoder Loss:  0.030187905  || Decoder Loss:  0.029464524 Validation Decoder Loss:  0.34374443
Encoder Loss:  0.029972019  || Decoder Loss:  0.029241301 Validation Decoder Loss:  0.343688
Encoder Loss:  0.029745623  || Decoder Loss:  0.029006936 Validation Decoder Loss:  0.3440417
Encoder Loss:  0.029546158  || Decoder Loss:  0.028800827 Validation Decoder Loss:  0.34470412
Encoder Loss:  0.029342158  || Decoder Loss:  0.028586812 Validation Decoder Loss:  0.3448229
Encoder Loss:  0.02915414  || Decoder Loss:  0.02839184 Validation Decoder Loss:  0.34494966
Encoder Loss:  0.028963372  || Decoder Loss:  0.02819401 Validation Decoder Loss:  0.34558612
Encoder Loss:  0.02878042  || Decoder Loss:  0.028005404 Validation Decoder Loss:  0.34556568
Encoder Loss:  0.028596645  || Decoder Loss:  0.027817443 Validation Decoder Loss:  0.34634233
Encoder Loss:  0.028420804  || Decoder Loss:  0.027635975 Validation Decoder Loss:  0.34655806
Encoder Loss:  0.028232828  || Decoder Loss:  0.027438195 Validation Decoder Loss:  0.34759974
Encoder Loss:  0.02807728  || Decoder Loss:  0.027274907 Validation Decoder Loss:  0.34763393
Encoder Loss:  0.02789438  || Decoder Loss:  0.027090464 Validation Decoder Loss:  0.34801972
Encoder Loss:  0.02775316  || Decoder Loss:  0.026941197 Validation Decoder Loss:  0.34847093
Encoder Loss:  0.02762385  || Decoder Loss:  0.026803575 Validation Decoder Loss:  0.34777293
Encoder Loss:  0.027466936  || Decoder Loss:  0.026638594 Validation Decoder Loss:  0.34807462
Encoder Loss:  0.027351966  || Decoder Loss:  0.026529051 Validation Decoder Loss:  0.34840268
Encoder Loss:  0.027229317  || Decoder Loss:  0.026399022 Validation Decoder Loss:  0.3477044
Encoder Loss:  0.027123526  || Decoder Loss:  0.026290746 Validation Decoder Loss:  0.34727556
Encoder Loss:  0.027013367  || Decoder Loss:  0.02617187 Validation Decoder Loss:  0.34693372
Encoder Loss:  0.026925012  || Decoder Loss:  0.026077367 Validation Decoder Loss:  0.34689325
Encoder Loss:  0.026854813  || Decoder Loss:  0.026008293 Validation Decoder Loss:  0.34615326
Encoder Loss:  0.026774485  || Decoder Loss:  0.025927 Validation Decoder Loss:  0.34561294
Encoder Loss:  0.02671899  || Decoder Loss:  0.025872922 Validation Decoder Loss:  0.34578925
Encoder Loss:  0.026658798  || Decoder Loss:  0.02580772 Validation Decoder Loss:  0.3455335
Encoder Loss:  0.026590843  || Decoder Loss:  0.025740402 Validation Decoder Loss:  0.34535995
Model: siamese_net_lr_0.0005339334936755847 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34535995
Model: "sequential_682"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_380 (Conv3D (None, 70, 5, 20, 1)      8         
_________________________________________________________________
dropout_789 (Dropout)        (None, 70, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_381 (Conv3D (None, 184, 5, 20, 1)     47        
_________________________________________________________________
reshape_197 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 55
Trainable params: 55
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_684"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_288 (Conv2D)          (None, 2630, 20, 1)       617       
_________________________________________________________________
dropout_791 (Dropout)        (None, 2630, 20, 1)       0         
_________________________________________________________________
conv2d_289 (Conv2D)          (None, 920, 20, 1)        793       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_685"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_288 (Conv2D (None, 2760, 20, 1)       923       
_________________________________________________________________
dropout_793 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_289 (Conv2D (None, 3245, 20, 1)       487       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35763538  || Decoder Loss:  0.4593876 Validation Decoder Loss:  1.4158599
Encoder Loss:  0.32450828  || Decoder Loss:  0.42803487 Validation Decoder Loss:  1.2404329
Encoder Loss:  0.35100803  || Decoder Loss:  0.46361843 Validation Decoder Loss:  1.5394671
Encoder Loss:  0.3442083  || Decoder Loss:  0.4560518 Validation Decoder Loss:  1.4314742
Encoder Loss:  0.37822312  || Decoder Loss:  0.50315106 Validation Decoder Loss:  0.6758008
Encoder Loss:  0.3497222  || Decoder Loss:  0.46349472 Validation Decoder Loss:  1.3511474
Encoder Loss:  0.37890053  || Decoder Loss:  0.5038968 Validation Decoder Loss:  1.532634
Encoder Loss:  0.31751508  || Decoder Loss:  0.4174341 Validation Decoder Loss:  1.5604548
Encoder Loss:  0.36819085  || Decoder Loss:  0.48771736 Validation Decoder Loss:  1.453645
Encoder Loss:  0.32809636  || Decoder Loss:  0.43295777 Validation Decoder Loss:  1.2000636
Encoder Loss:  0.38656014  || Decoder Loss:  0.51523036 Validation Decoder Loss:  1.4519708
Encoder Loss:  0.3969139  || Decoder Loss:  0.52956444 Validation Decoder Loss:  1.0168507
Encoder Loss:  0.34002918  || Decoder Loss:  0.45056045 Validation Decoder Loss:  1.369551
Encoder Loss:  0.35563985  || Decoder Loss:  0.47213826 Validation Decoder Loss:  1.4001412
Encoder Loss:  0.35769185  || Decoder Loss:  0.4750237 Validation Decoder Loss:  1.391411
Encoder Loss:  0.35241315  || Decoder Loss:  0.46774167 Validation Decoder Loss:  1.3815652
Encoder Loss:  0.34701642  || Decoder Loss:  0.46029365 Validation Decoder Loss:  1.3736715
Encoder Loss:  0.34189433  || Decoder Loss:  0.45322448 Validation Decoder Loss:  1.3670485
Encoder Loss:  0.36806557  || Decoder Loss:  0.48964825 Validation Decoder Loss:  1.5442057
Encoder Loss:  0.354748  || Decoder Loss:  0.47059166 Validation Decoder Loss:  1.5384619
Encoder Loss:  0.3474234  || Decoder Loss:  0.46098006 Validation Decoder Loss:  1.5242324
Encoder Loss:  0.34440616  || Decoder Loss:  0.4561285 Validation Decoder Loss:  1.2674272
Encoder Loss:  0.37991962  || Decoder Loss:  0.5059438 Validation Decoder Loss:  1.395778
Encoder Loss:  0.32790616  || Decoder Loss:  0.4331461 Validation Decoder Loss:  1.4614916
Encoder Loss:  0.30887806  || Decoder Loss:  0.4076435 Validation Decoder Loss:  1.2954993
Encoder Loss:  0.37392217  || Decoder Loss:  0.49783614 Validation Decoder Loss:  1.3551404
Encoder Loss:  0.377718  || Decoder Loss:  0.5027986 Validation Decoder Loss:  1.4135728
Encoder Loss:  0.3570945  || Decoder Loss:  0.47457692 Validation Decoder Loss:  1.2497758
Encoder Loss:  0.35957524  || Decoder Loss:  0.47748652 Validation Decoder Loss:  1.4880745
Encoder Loss:  0.36774105  || Decoder Loss:  0.48982292 Validation Decoder Loss:  1.3939285
Encoder Loss:  0.3438038  || Decoder Loss:  0.4558995 Validation Decoder Loss:  1.331345
Encoder Loss:  0.37392768  || Decoder Loss:  0.49799526 Validation Decoder Loss:  1.460433
Encoder Loss:  0.3231699  || Decoder Loss:  0.42757377 Validation Decoder Loss:  1.3825345
Encoder Loss:  0.37963638  || Decoder Loss:  0.5059298 Validation Decoder Loss:  1.3860658
Encoder Loss:  0.33404595  || Decoder Loss:  0.4430185 Validation Decoder Loss:  1.4715401
Encoder Loss:  0.33689606  || Decoder Loss:  0.4464873 Validation Decoder Loss:  1.336496
Encoder Loss:  0.36864004  || Decoder Loss:  0.4906122 Validation Decoder Loss:  1.4449693
Encoder Loss:  0.34392697  || Decoder Loss:  0.45655903 Validation Decoder Loss:  0.9640303
Encoder Loss:  0.32720432  || Decoder Loss:  0.4326136 Validation Decoder Loss:  1.0484369
Encoder Loss:  0.37096584  || Decoder Loss:  0.49425384 Validation Decoder Loss:  1.0306098
Model: siamese_net_lr_0.0721343923695892 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0306098
Model: "sequential_686"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_383 (Conv3D (None, 162, 5, 20, 1)     37        
_________________________________________________________________
dropout_795 (Dropout)        (None, 162, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_384 (Conv3D (None, 184, 5, 20, 1)     24        
_________________________________________________________________
reshape_198 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_688"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_290 (Conv2D)          (None, 1660, 20, 1)       1587      
_________________________________________________________________
dropout_797 (Dropout)        (None, 1660, 20, 1)       0         
_________________________________________________________________
conv2d_291 (Conv2D)          (None, 920, 20, 1)        742       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_689"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_290 (Conv2D (None, 2920, 20, 1)       164       
_________________________________________________________________
dropout_799 (Dropout)        (None, 2920, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_291 (Conv2D (None, 3245, 20, 1)       327       
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19742842  || Decoder Loss:  0.17059757 Validation Decoder Loss:  1.3810706
Encoder Loss:  0.0977616  || Decoder Loss:  0.09916847 Validation Decoder Loss:  0.37071934
Encoder Loss:  0.055693626  || Decoder Loss:  0.036919985 Validation Decoder Loss:  0.35535508
Encoder Loss:  0.04833151  || Decoder Loss:  0.0369147 Validation Decoder Loss:  0.35614032
Encoder Loss:  0.048609447  || Decoder Loss:  0.036837477 Validation Decoder Loss:  0.3572225
Encoder Loss:  0.049087204  || Decoder Loss:  0.036767133 Validation Decoder Loss:  0.35758403
Encoder Loss:  0.046800777  || Decoder Loss:  0.036771037 Validation Decoder Loss:  0.35825527
Encoder Loss:  0.04669658  || Decoder Loss:  0.036729045 Validation Decoder Loss:  0.3587486
Encoder Loss:  0.048626833  || Decoder Loss:  0.036715087 Validation Decoder Loss:  0.35785288
Encoder Loss:  0.04761233  || Decoder Loss:  0.03675577 Validation Decoder Loss:  0.3562959
Encoder Loss:  0.049649123  || Decoder Loss:  0.03682779 Validation Decoder Loss:  0.35366368
Encoder Loss:  0.046355218  || Decoder Loss:  0.036976784 Validation Decoder Loss:  0.35243565
Encoder Loss:  0.04673319  || Decoder Loss:  0.03694143 Validation Decoder Loss:  0.3522361
Encoder Loss:  0.046284486  || Decoder Loss:  0.03691031 Validation Decoder Loss:  0.352194
Encoder Loss:  0.047209285  || Decoder Loss:  0.03685535 Validation Decoder Loss:  0.3521761
Encoder Loss:  0.046704084  || Decoder Loss:  0.036867492 Validation Decoder Loss:  0.3518257
Encoder Loss:  0.04713869  || Decoder Loss:  0.03680954 Validation Decoder Loss:  0.35208985
Encoder Loss:  0.046798125  || Decoder Loss:  0.036807023 Validation Decoder Loss:  0.351497
Encoder Loss:  0.046389222  || Decoder Loss:  0.036726158 Validation Decoder Loss:  0.35178387
Encoder Loss:  0.04653982  || Decoder Loss:  0.03670002 Validation Decoder Loss:  0.35215908
Encoder Loss:  0.04714024  || Decoder Loss:  0.036713913 Validation Decoder Loss:  0.35167766
Encoder Loss:  0.04718203  || Decoder Loss:  0.03666621 Validation Decoder Loss:  0.35200566
Encoder Loss:  0.046687104  || Decoder Loss:  0.03659929 Validation Decoder Loss:  0.35176945
Encoder Loss:  0.046204038  || Decoder Loss:  0.036582768 Validation Decoder Loss:  0.3518809
Encoder Loss:  0.046774436  || Decoder Loss:  0.03654185 Validation Decoder Loss:  0.35191643
Encoder Loss:  0.046652235  || Decoder Loss:  0.036514312 Validation Decoder Loss:  0.3515894
Encoder Loss:  0.046448525  || Decoder Loss:  0.036485337 Validation Decoder Loss:  0.35190842
Encoder Loss:  0.04649777  || Decoder Loss:  0.03651166 Validation Decoder Loss:  0.35156673
Encoder Loss:  0.046348847  || Decoder Loss:  0.03641478 Validation Decoder Loss:  0.3519665
Encoder Loss:  0.045991402  || Decoder Loss:  0.036399625 Validation Decoder Loss:  0.35167053
Encoder Loss:  0.047127083  || Decoder Loss:  0.036416408 Validation Decoder Loss:  0.35107255
Encoder Loss:  0.047353357  || Decoder Loss:  0.036360838 Validation Decoder Loss:  0.35174477
Encoder Loss:  0.046038017  || Decoder Loss:  0.036312327 Validation Decoder Loss:  0.35143137
Encoder Loss:  0.046312604  || Decoder Loss:  0.03632705 Validation Decoder Loss:  0.35118866
Encoder Loss:  0.04618467  || Decoder Loss:  0.036241647 Validation Decoder Loss:  0.35158867
Encoder Loss:  0.04608747  || Decoder Loss:  0.03623445 Validation Decoder Loss:  0.35138887
Encoder Loss:  0.046924997  || Decoder Loss:  0.03625222 Validation Decoder Loss:  0.3512379
Encoder Loss:  0.04613225  || Decoder Loss:  0.03614135 Validation Decoder Loss:  0.3510744
Encoder Loss:  0.046547156  || Decoder Loss:  0.036135927 Validation Decoder Loss:  0.35123795
Encoder Loss:  0.046201598  || Decoder Loss:  0.03607945 Validation Decoder Loss:  0.35097325
Model: siamese_net_lr_0.02639084588208036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3509732
Model: "sequential_690"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_386 (Conv3D (None, 176, 5, 20, 1)     114       
_________________________________________________________________
dropout_801 (Dropout)        (None, 176, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_387 (Conv3D (None, 184, 5, 20, 1)     10        
_________________________________________________________________
reshape_199 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_692"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_292 (Conv2D)          (None, 2230, 20, 1)       1017      
_________________________________________________________________
dropout_803 (Dropout)        (None, 2230, 20, 1)       0         
_________________________________________________________________
conv2d_293 (Conv2D)          (None, 920, 20, 1)        393       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_693"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_292 (Conv2D (None, 2300, 20, 1)       1382      
_________________________________________________________________
dropout_805 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_293 (Conv2D (None, 3245, 20, 1)       947       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.49665192  || Decoder Loss:  0.6845384 Validation Decoder Loss:  1.6065077
Encoder Loss:  0.57438713  || Decoder Loss:  0.87088615 Validation Decoder Loss:  1.6032472
Encoder Loss:  0.57025445  || Decoder Loss:  0.86687475 Validation Decoder Loss:  1.5975041
Encoder Loss:  0.5649468  || Decoder Loss:  0.8611993 Validation Decoder Loss:  1.5874524
Encoder Loss:  0.47929913  || Decoder Loss:  0.619711 Validation Decoder Loss:  0.4035114
Encoder Loss:  0.34305725  || Decoder Loss:  0.14321558 Validation Decoder Loss:  0.3996836
Encoder Loss:  0.33977738  || Decoder Loss:  0.13661763 Validation Decoder Loss:  0.3925274
Encoder Loss:  0.33644184  || Decoder Loss:  0.12959209 Validation Decoder Loss:  0.3861711
Encoder Loss:  0.3329321  || Decoder Loss:  0.12297007 Validation Decoder Loss:  0.38073245
Encoder Loss:  0.3290254  || Decoder Loss:  0.11663931 Validation Decoder Loss:  0.37615943
Encoder Loss:  0.32434243  || Decoder Loss:  0.11044769 Validation Decoder Loss:  0.3725366
Encoder Loss:  0.31808552  || Decoder Loss:  0.10428085 Validation Decoder Loss:  0.37032053
Encoder Loss:  0.3078987  || Decoder Loss:  0.09818343 Validation Decoder Loss:  0.37153795
Encoder Loss:  0.2788294  || Decoder Loss:  0.09405219 Validation Decoder Loss:  0.40868536
Encoder Loss:  0.24034752  || Decoder Loss:  0.44014955 Validation Decoder Loss:  1.2947259
Encoder Loss:  0.20690113  || Decoder Loss:  0.46246183 Validation Decoder Loss:  1.373229
Encoder Loss:  0.20586483  || Decoder Loss:  0.46363354 Validation Decoder Loss:  1.3641607
Encoder Loss:  0.20497622  || Decoder Loss:  0.46421468 Validation Decoder Loss:  1.3429328
Encoder Loss:  0.20439623  || Decoder Loss:  0.46615496 Validation Decoder Loss:  1.3109465
Encoder Loss:  0.19806828  || Decoder Loss:  0.45663607 Validation Decoder Loss:  1.2261014
Encoder Loss:  0.18811741  || Decoder Loss:  0.4350185 Validation Decoder Loss:  1.342291
Encoder Loss:  0.18881913  || Decoder Loss:  0.44226715 Validation Decoder Loss:  1.3712192
Encoder Loss:  0.186657  || Decoder Loss:  0.43863833 Validation Decoder Loss:  1.3507087
Encoder Loss:  0.18646851  || Decoder Loss:  0.4426587 Validation Decoder Loss:  1.3150342
Encoder Loss:  0.19158004  || Decoder Loss:  0.45641378 Validation Decoder Loss:  1.4184258
Encoder Loss:  0.18932082  || Decoder Loss:  0.45246577 Validation Decoder Loss:  1.1813445
Encoder Loss:  0.18387623  || Decoder Loss:  0.43889022 Validation Decoder Loss:  1.3907909
Encoder Loss:  0.1860302  || Decoder Loss:  0.44856885 Validation Decoder Loss:  1.2637343
Encoder Loss:  0.1814974  || Decoder Loss:  0.44591558 Validation Decoder Loss:  1.3556749
Encoder Loss:  0.18677491  || Decoder Loss:  0.45293716 Validation Decoder Loss:  1.3230913
Encoder Loss:  0.19928417  || Decoder Loss:  0.4830642 Validation Decoder Loss:  0.99263394
Encoder Loss:  0.18119206  || Decoder Loss:  0.43268862 Validation Decoder Loss:  1.4812274
Encoder Loss:  0.19407211  || Decoder Loss:  0.469635 Validation Decoder Loss:  1.0520009
Encoder Loss:  0.1861397  || Decoder Loss:  0.44858482 Validation Decoder Loss:  1.088567
Encoder Loss:  0.18472625  || Decoder Loss:  0.44612205 Validation Decoder Loss:  1.1268904
Encoder Loss:  0.18217647  || Decoder Loss:  0.4384083 Validation Decoder Loss:  1.0687478
Encoder Loss:  0.18015283  || Decoder Loss:  0.4359604 Validation Decoder Loss:  1.2253321
Encoder Loss:  0.18777184  || Decoder Loss:  0.45627803 Validation Decoder Loss:  1.2714804
Encoder Loss:  0.18447708  || Decoder Loss:  0.43640134 Validation Decoder Loss:  1.3676139
Encoder Loss:  0.19449145  || Decoder Loss:  0.46784732 Validation Decoder Loss:  1.2367272
Model: siamese_net_lr_0.08655273997610241 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2367272
Model: "sequential_694"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_389 (Conv3D (None, 106, 5, 20, 1)     44        
_________________________________________________________________
dropout_807 (Dropout)        (None, 106, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_390 (Conv3D (None, 184, 5, 20, 1)     80        
_________________________________________________________________
reshape_200 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_696"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_294 (Conv2D)          (None, 1870, 20, 1)       1377      
_________________________________________________________________
dropout_809 (Dropout)        (None, 1870, 20, 1)       0         
_________________________________________________________________
conv2d_295 (Conv2D)          (None, 920, 20, 1)        952       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_697"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_294 (Conv2D (None, 1000, 20, 1)       82        
_________________________________________________________________
dropout_811 (Dropout)        (None, 1000, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_295 (Conv2D (None, 3245, 20, 1)       1248      
=================================================================
Total params: 1,330
Trainable params: 1,330
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39933705  || Decoder Loss:  0.6660165 Validation Decoder Loss:  1.2832352
Encoder Loss:  0.21305099  || Decoder Loss:  0.5462006 Validation Decoder Loss:  0.5730993
Encoder Loss:  0.15586802  || Decoder Loss:  0.48409867 Validation Decoder Loss:  0.6187066
Encoder Loss:  0.15060383  || Decoder Loss:  0.49469537 Validation Decoder Loss:  0.6623862
Encoder Loss:  0.14645657  || Decoder Loss:  0.49292624 Validation Decoder Loss:  0.67355895
Encoder Loss:  0.14623164  || Decoder Loss:  0.493278 Validation Decoder Loss:  0.65219605
Encoder Loss:  0.14159921  || Decoder Loss:  0.49068275 Validation Decoder Loss:  0.7015139
Encoder Loss:  0.14269103  || Decoder Loss:  0.4923428 Validation Decoder Loss:  0.6563475
Encoder Loss:  0.14340946  || Decoder Loss:  0.49141502 Validation Decoder Loss:  0.67453164
Encoder Loss:  0.14277297  || Decoder Loss:  0.48920867 Validation Decoder Loss:  0.66849464
Encoder Loss:  0.14454168  || Decoder Loss:  0.49182016 Validation Decoder Loss:  0.69684607
Encoder Loss:  0.14729702  || Decoder Loss:  0.4945082 Validation Decoder Loss:  0.6199827
Encoder Loss:  0.15091863  || Decoder Loss:  0.48108172 Validation Decoder Loss:  0.7099042
Encoder Loss:  0.14703137  || Decoder Loss:  0.49166867 Validation Decoder Loss:  0.70640886
Encoder Loss:  0.14154421  || Decoder Loss:  0.48917347 Validation Decoder Loss:  0.687065
Encoder Loss:  0.14243098  || Decoder Loss:  0.4897767 Validation Decoder Loss:  0.71106046
Encoder Loss:  0.14063112  || Decoder Loss:  0.49002182 Validation Decoder Loss:  0.7026671
Encoder Loss:  0.14287725  || Decoder Loss:  0.4913105 Validation Decoder Loss:  0.70102704
Encoder Loss:  0.1407379  || Decoder Loss:  0.4894289 Validation Decoder Loss:  0.7225525
Encoder Loss:  0.14120217  || Decoder Loss:  0.4900405 Validation Decoder Loss:  0.71482015
Encoder Loss:  0.14090785  || Decoder Loss:  0.49000317 Validation Decoder Loss:  0.7207042
Encoder Loss:  0.14165713  || Decoder Loss:  0.4904435 Validation Decoder Loss:  0.723971
Encoder Loss:  0.1415758  || Decoder Loss:  0.4902199 Validation Decoder Loss:  0.73172945
Encoder Loss:  0.14055894  || Decoder Loss:  0.4901807 Validation Decoder Loss:  0.74869394
Encoder Loss:  0.14410475  || Decoder Loss:  0.48800084 Validation Decoder Loss:  0.70069826
Encoder Loss:  0.14912201  || Decoder Loss:  0.4834734 Validation Decoder Loss:  0.77879596
Encoder Loss:  0.1499866  || Decoder Loss:  0.49317357 Validation Decoder Loss:  0.77175075
Encoder Loss:  0.14282547  || Decoder Loss:  0.49011105 Validation Decoder Loss:  0.7577506
Encoder Loss:  0.14345361  || Decoder Loss:  0.49132785 Validation Decoder Loss:  0.7213787
Encoder Loss:  0.14745139  || Decoder Loss:  0.48291272 Validation Decoder Loss:  0.7540156
Encoder Loss:  0.14127836  || Decoder Loss:  0.4882654 Validation Decoder Loss:  0.78387976
Encoder Loss:  0.14154576  || Decoder Loss:  0.49052727 Validation Decoder Loss:  0.7866872
Encoder Loss:  0.14159398  || Decoder Loss:  0.48834264 Validation Decoder Loss:  0.79283583
Encoder Loss:  0.14403792  || Decoder Loss:  0.48968625 Validation Decoder Loss:  0.79936576
Encoder Loss:  0.14151117  || Decoder Loss:  0.48916572 Validation Decoder Loss:  0.78683853
Encoder Loss:  0.14354241  || Decoder Loss:  0.48835573 Validation Decoder Loss:  0.82470345
Encoder Loss:  0.14205083  || Decoder Loss:  0.48927552 Validation Decoder Loss:  0.8225991
Encoder Loss:  0.14376888  || Decoder Loss:  0.48858902 Validation Decoder Loss:  0.8050616
Encoder Loss:  0.14073119  || Decoder Loss:  0.48795402 Validation Decoder Loss:  0.81323725
Encoder Loss:  0.14062585  || Decoder Loss:  0.48794964 Validation Decoder Loss:  0.81511104
Model: siamese_net_lr_0.09404299098277777 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.81511104
Model: "sequential_698"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_392 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_813 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_393 (Conv3D (None, 184, 5, 20, 1)     7         
_________________________________________________________________
reshape_201 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 35
Trainable params: 35
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_700"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_296 (Conv2D)          (None, 2460, 20, 1)       787       
_________________________________________________________________
dropout_815 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_297 (Conv2D)          (None, 920, 20, 1)        1542      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_701"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_296 (Conv2D (None, 2160, 20, 1)       323       
_________________________________________________________________
dropout_817 (Dropout)        (None, 2160, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_297 (Conv2D (None, 3245, 20, 1)       1087      
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16400127  || Decoder Loss:  0.1550488 Validation Decoder Loss:  1.6089878
Encoder Loss:  0.54160345  || Decoder Loss:  0.5710294 Validation Decoder Loss:  1.571209
Encoder Loss:  0.50205296  || Decoder Loss:  0.5307639 Validation Decoder Loss:  0.30491924
Encoder Loss:  0.46453705  || Decoder Loss:  0.491027 Validation Decoder Loss:  1.0485644
Encoder Loss:  0.47395176  || Decoder Loss:  0.501102 Validation Decoder Loss:  0.36703467
Encoder Loss:  0.44420484  || Decoder Loss:  0.46943656 Validation Decoder Loss:  0.32229683
Encoder Loss:  0.4236086  || Decoder Loss:  0.44747838 Validation Decoder Loss:  0.34043968
Encoder Loss:  0.4001782  || Decoder Loss:  0.42252973 Validation Decoder Loss:  0.8958963
Encoder Loss:  0.41761184  || Decoder Loss:  0.44106042 Validation Decoder Loss:  0.29757437
Encoder Loss:  0.396327  || Decoder Loss:  0.4183851 Validation Decoder Loss:  1.1208577
Encoder Loss:  0.40982777  || Decoder Loss:  0.432803 Validation Decoder Loss:  0.31752318
Encoder Loss:  0.38930607  || Decoder Loss:  0.41104117 Validation Decoder Loss:  0.29453695
Encoder Loss:  0.2680701  || Decoder Loss:  0.28195855 Validation Decoder Loss:  0.30093414
Encoder Loss:  0.06879556  || Decoder Loss:  0.06984535 Validation Decoder Loss:  0.31765813
Encoder Loss:  0.0554509  || Decoder Loss:  0.055729102 Validation Decoder Loss:  0.32583016
Encoder Loss:  0.054442648  || Decoder Loss:  0.054653678 Validation Decoder Loss:  0.32994834
Encoder Loss:  0.054653578  || Decoder Loss:  0.054766603 Validation Decoder Loss:  0.35145465
Encoder Loss:  0.053155392  || Decoder Loss:  0.05323359 Validation Decoder Loss:  0.33259594
Encoder Loss:  0.051950052  || Decoder Loss:  0.051957294 Validation Decoder Loss:  0.31918138
Encoder Loss:  0.052342586  || Decoder Loss:  0.052373566 Validation Decoder Loss:  0.3251385
Encoder Loss:  0.05094547  || Decoder Loss:  0.05090184 Validation Decoder Loss:  0.3219439
Encoder Loss:  0.05102932  || Decoder Loss:  0.050979756 Validation Decoder Loss:  0.3575466
Encoder Loss:  0.050839644  || Decoder Loss:  0.050785203 Validation Decoder Loss:  0.32680482
Encoder Loss:  0.04835282  || Decoder Loss:  0.048181087 Validation Decoder Loss:  0.30033642
Encoder Loss:  0.05282818  || Decoder Loss:  0.0528374 Validation Decoder Loss:  0.34539336
Encoder Loss:  0.049015697  || Decoder Loss:  0.048816033 Validation Decoder Loss:  0.3741928
Encoder Loss:  0.047600187  || Decoder Loss:  0.047360767 Validation Decoder Loss:  0.35380885
Encoder Loss:  0.047350783  || Decoder Loss:  0.047078546 Validation Decoder Loss:  0.40530977
Encoder Loss:  0.049111728  || Decoder Loss:  0.048895475 Validation Decoder Loss:  0.38812947
Encoder Loss:  0.04898146  || Decoder Loss:  0.048759833 Validation Decoder Loss:  0.39676642
Encoder Loss:  0.047351968  || Decoder Loss:  0.047037926 Validation Decoder Loss:  0.34005946
Encoder Loss:  0.045283407  || Decoder Loss:  0.04488997 Validation Decoder Loss:  0.30468258
Encoder Loss:  0.04485624  || Decoder Loss:  0.04443787 Validation Decoder Loss:  0.34739143
Encoder Loss:  0.047518384  || Decoder Loss:  0.04724673 Validation Decoder Loss:  0.27406037
Encoder Loss:  0.045506593  || Decoder Loss:  0.04513821 Validation Decoder Loss:  0.33493897
Encoder Loss:  0.050490137  || Decoder Loss:  0.050336808 Validation Decoder Loss:  0.50191873
Encoder Loss:  0.0509233  || Decoder Loss:  0.0508939 Validation Decoder Loss:  0.3269791
Encoder Loss:  0.045011472  || Decoder Loss:  0.044584166 Validation Decoder Loss:  0.35174823
Encoder Loss:  0.046803854  || Decoder Loss:  0.046449017 Validation Decoder Loss:  0.6369845
Encoder Loss:  0.065524906  || Decoder Loss:  0.06620309 Validation Decoder Loss:  0.33414024
Model: siamese_net_lr_0.05213915286696854 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33414024
Model: "sequential_702"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_395 (Conv3D (None, 130, 5, 20, 1)     5         
_________________________________________________________________
dropout_819 (Dropout)        (None, 130, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_396 (Conv3D (None, 184, 5, 20, 1)     56        
_________________________________________________________________
reshape_202 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_704"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 1430, 20, 1)       388       
_________________________________________________________________
dropout_821 (Dropout)        (None, 1430, 20, 1)       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 920, 20, 1)        512       
=================================================================
Total params: 900
Trainable params: 900
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_705"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_298 (Conv2D (None, 1850, 20, 1)       932       
_________________________________________________________________
dropout_823 (Dropout)        (None, 1850, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_299 (Conv2D (None, 3245, 20, 1)       1397      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4940874  || Decoder Loss:  0.82178444 Validation Decoder Loss:  1.5763707
Encoder Loss:  0.51184773  || Decoder Loss:  0.8555424 Validation Decoder Loss:  1.5241221
Encoder Loss:  0.4896498  || Decoder Loss:  0.81723535 Validation Decoder Loss:  1.1033192
Encoder Loss:  0.24157694  || Decoder Loss:  0.5049216 Validation Decoder Loss:  0.5943767
Encoder Loss:  0.2019242  || Decoder Loss:  0.5034554 Validation Decoder Loss:  1.1604517
Encoder Loss:  0.16372584  || Decoder Loss:  0.4835228 Validation Decoder Loss:  1.2105836
Encoder Loss:  0.16644824  || Decoder Loss:  0.4838164 Validation Decoder Loss:  1.2697724
Encoder Loss:  0.1626589  || Decoder Loss:  0.48323083 Validation Decoder Loss:  1.1434156
Encoder Loss:  0.17014028  || Decoder Loss:  0.4744414 Validation Decoder Loss:  0.74312985
Encoder Loss:  0.18776813  || Decoder Loss:  0.49126405 Validation Decoder Loss:  0.87781006
Encoder Loss:  0.16126421  || Decoder Loss:  0.44307986 Validation Decoder Loss:  1.1775618
Encoder Loss:  0.16057816  || Decoder Loss:  0.48009154 Validation Decoder Loss:  1.3448181
Encoder Loss:  0.16597705  || Decoder Loss:  0.47975728 Validation Decoder Loss:  1.1430284
Encoder Loss:  0.15725476  || Decoder Loss:  0.4680051 Validation Decoder Loss:  1.218721
Encoder Loss:  0.15460292  || Decoder Loss:  0.4691518 Validation Decoder Loss:  1.1593735
Encoder Loss:  0.15518473  || Decoder Loss:  0.4636246 Validation Decoder Loss:  1.2577983
Encoder Loss:  0.15831321  || Decoder Loss:  0.4709921 Validation Decoder Loss:  1.2460594
Encoder Loss:  0.1574321  || Decoder Loss:  0.4593898 Validation Decoder Loss:  1.2033404
Encoder Loss:  0.15252334  || Decoder Loss:  0.4589328 Validation Decoder Loss:  1.2562636
Encoder Loss:  0.15847807  || Decoder Loss:  0.46169814 Validation Decoder Loss:  1.0569814
Encoder Loss:  0.15476598  || Decoder Loss:  0.45188943 Validation Decoder Loss:  1.2741275
Encoder Loss:  0.1567177  || Decoder Loss:  0.4602319 Validation Decoder Loss:  1.2755293
Encoder Loss:  0.15403394  || Decoder Loss:  0.44595596 Validation Decoder Loss:  1.2397404
Encoder Loss:  0.14968318  || Decoder Loss:  0.44055846 Validation Decoder Loss:  1.3240646
Encoder Loss:  0.1520106  || Decoder Loss:  0.44263455 Validation Decoder Loss:  1.3579156
Encoder Loss:  0.155391  || Decoder Loss:  0.44949418 Validation Decoder Loss:  1.0804546
Encoder Loss:  0.15272847  || Decoder Loss:  0.43163386 Validation Decoder Loss:  1.3622243
Encoder Loss:  0.15181454  || Decoder Loss:  0.4455607 Validation Decoder Loss:  1.25718
Encoder Loss:  0.15210482  || Decoder Loss:  0.43148413 Validation Decoder Loss:  1.1415579
Encoder Loss:  0.14777379  || Decoder Loss:  0.42927933 Validation Decoder Loss:  1.2158358
Encoder Loss:  0.14762434  || Decoder Loss:  0.43423194 Validation Decoder Loss:  1.2502623
Encoder Loss:  0.152871  || Decoder Loss:  0.4399522 Validation Decoder Loss:  1.3266531
Encoder Loss:  0.14799008  || Decoder Loss:  0.43365496 Validation Decoder Loss:  1.136982
Encoder Loss:  0.15792416  || Decoder Loss:  0.438005 Validation Decoder Loss:  1.3330982
Encoder Loss:  0.1484293  || Decoder Loss:  0.43756717 Validation Decoder Loss:  1.3130949
Encoder Loss:  0.14857094  || Decoder Loss:  0.43498328 Validation Decoder Loss:  1.3367131
Encoder Loss:  0.15001017  || Decoder Loss:  0.4302858 Validation Decoder Loss:  1.4184803
Encoder Loss:  0.15911241  || Decoder Loss:  0.44082496 Validation Decoder Loss:  1.421886
Encoder Loss:  0.15485144  || Decoder Loss:  0.44067872 Validation Decoder Loss:  1.255596
Encoder Loss:  0.1478623  || Decoder Loss:  0.4258189 Validation Decoder Loss:  1.4212902
Model: siamese_net_lr_0.05107431402919795 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.4212902
Model: "sequential_706"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_398 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_825 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_399 (Conv3D (None, 184, 5, 20, 1)     68        
_________________________________________________________________
reshape_203 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_708"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_300 (Conv2D)          (None, 1090, 20, 1)       2157      
_________________________________________________________________
dropout_827 (Dropout)        (None, 1090, 20, 1)       0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 920, 20, 1)        172       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_709"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_300 (Conv2D (None, 2750, 20, 1)       913       
_________________________________________________________________
dropout_829 (Dropout)        (None, 2750, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_301 (Conv2D (None, 3245, 20, 1)       497       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27730104  || Decoder Loss:  0.26749483 Validation Decoder Loss:  0.44750118
Encoder Loss:  0.20793746  || Decoder Loss:  0.17605694 Validation Decoder Loss:  0.53935987
Encoder Loss:  0.39444572  || Decoder Loss:  0.44935894 Validation Decoder Loss:  1.1219145
Encoder Loss:  0.43315396  || Decoder Loss:  0.51096845 Validation Decoder Loss:  1.2370518
Encoder Loss:  0.43041995  || Decoder Loss:  0.5098732 Validation Decoder Loss:  1.2427094
Encoder Loss:  0.43628284  || Decoder Loss:  0.51525587 Validation Decoder Loss:  1.1798031
Encoder Loss:  0.4411654  || Decoder Loss:  0.5205493 Validation Decoder Loss:  1.2057698
Encoder Loss:  0.43289402  || Decoder Loss:  0.51266193 Validation Decoder Loss:  1.3033514
Encoder Loss:  0.43324474  || Decoder Loss:  0.5136788 Validation Decoder Loss:  1.3462346
Encoder Loss:  0.44182748  || Decoder Loss:  0.5218347 Validation Decoder Loss:  1.3435922
Encoder Loss:  0.43672153  || Decoder Loss:  0.51343197 Validation Decoder Loss:  1.3480097
Encoder Loss:  0.43811318  || Decoder Loss:  0.5178584 Validation Decoder Loss:  1.2668188
Encoder Loss:  0.42870778  || Decoder Loss:  0.50736064 Validation Decoder Loss:  1.3340056
Encoder Loss:  0.43219241  || Decoder Loss:  0.51092786 Validation Decoder Loss:  1.2769963
Encoder Loss:  0.43163583  || Decoder Loss:  0.51127225 Validation Decoder Loss:  1.3218249
Encoder Loss:  0.43113804  || Decoder Loss:  0.51164573 Validation Decoder Loss:  1.3311809
Encoder Loss:  0.4348647  || Decoder Loss:  0.51563907 Validation Decoder Loss:  1.3889279
Encoder Loss:  0.43432468  || Decoder Loss:  0.5121998 Validation Decoder Loss:  1.3656696
Encoder Loss:  0.43710792  || Decoder Loss:  0.5169605 Validation Decoder Loss:  1.285649
Encoder Loss:  0.4274191  || Decoder Loss:  0.50270325 Validation Decoder Loss:  1.3180534
Encoder Loss:  0.43165264  || Decoder Loss:  0.5116395 Validation Decoder Loss:  1.366569
Encoder Loss:  0.43109667  || Decoder Loss:  0.5114174 Validation Decoder Loss:  1.4001546
Encoder Loss:  0.430104  || Decoder Loss:  0.50803477 Validation Decoder Loss:  1.3943195
Encoder Loss:  0.42984462  || Decoder Loss:  0.5095272 Validation Decoder Loss:  1.3789406
Encoder Loss:  0.42877644  || Decoder Loss:  0.507947 Validation Decoder Loss:  1.3558271
Encoder Loss:  0.4225695  || Decoder Loss:  0.49976566 Validation Decoder Loss:  1.3727217
Encoder Loss:  0.42277554  || Decoder Loss:  0.5015079 Validation Decoder Loss:  1.3889604
Encoder Loss:  0.42142278  || Decoder Loss:  0.49942183 Validation Decoder Loss:  1.382484
Encoder Loss:  0.41747764  || Decoder Loss:  0.49417427 Validation Decoder Loss:  1.3355929
Encoder Loss:  0.41621295  || Decoder Loss:  0.4920924 Validation Decoder Loss:  1.2837194
Encoder Loss:  0.41201007  || Decoder Loss:  0.4880691 Validation Decoder Loss:  1.208921
Encoder Loss:  0.41009533  || Decoder Loss:  0.48483396 Validation Decoder Loss:  1.1409743
Encoder Loss:  0.40882495  || Decoder Loss:  0.48423564 Validation Decoder Loss:  1.0927552
Encoder Loss:  0.40889525  || Decoder Loss:  0.48388934 Validation Decoder Loss:  1.0577817
Encoder Loss:  0.40830353  || Decoder Loss:  0.4832277 Validation Decoder Loss:  1.050819
Encoder Loss:  0.4080624  || Decoder Loss:  0.48352715 Validation Decoder Loss:  1.0382451
Encoder Loss:  0.40810004  || Decoder Loss:  0.48339093 Validation Decoder Loss:  1.0302231
Encoder Loss:  0.40775704  || Decoder Loss:  0.48331764 Validation Decoder Loss:  1.0265806
Encoder Loss:  0.40791526  || Decoder Loss:  0.48331606 Validation Decoder Loss:  1.0260532
Encoder Loss:  0.4073608  || Decoder Loss:  0.4831747 Validation Decoder Loss:  1.0245103
Model: siamese_net_lr_0.06815188024370476 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0245103
Model: "sequential_710"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_401 (Conv3D (None, 170, 5, 20, 1)     45        
_________________________________________________________________
dropout_831 (Dropout)        (None, 170, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_402 (Conv3D (None, 184, 5, 20, 1)     16        
_________________________________________________________________
reshape_204 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_712"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_302 (Conv2D)          (None, 2180, 20, 1)       1067      
_________________________________________________________________
dropout_833 (Dropout)        (None, 2180, 20, 1)       0         
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 920, 20, 1)        343       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_713"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_302 (Conv2D (None, 1440, 20, 1)       522       
_________________________________________________________________
dropout_835 (Dropout)        (None, 1440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_303 (Conv2D (None, 3245, 20, 1)       1807      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4014641  || Decoder Loss:  0.18469566 Validation Decoder Loss:  0.38328317
Encoder Loss:  0.42403907  || Decoder Loss:  0.100965835 Validation Decoder Loss:  0.3829977
Encoder Loss:  0.29815805  || Decoder Loss:  0.220885 Validation Decoder Loss:  1.4507492
Encoder Loss:  0.09517667  || Decoder Loss:  0.42862174 Validation Decoder Loss:  1.5648093
Encoder Loss:  0.08622663  || Decoder Loss:  0.486561 Validation Decoder Loss:  1.5776441
Encoder Loss:  0.08251497  || Decoder Loss:  0.5028919 Validation Decoder Loss:  1.3873935
Encoder Loss:  0.080237605  || Decoder Loss:  0.5078622 Validation Decoder Loss:  1.1513228
Encoder Loss:  0.07708636  || Decoder Loss:  0.4816756 Validation Decoder Loss:  1.3652501
Encoder Loss:  0.07753892  || Decoder Loss:  0.5025666 Validation Decoder Loss:  1.3546845
Encoder Loss:  0.07761788  || Decoder Loss:  0.46673125 Validation Decoder Loss:  1.3639455
Encoder Loss:  0.07816367  || Decoder Loss:  0.48889515 Validation Decoder Loss:  1.5565748
Encoder Loss:  0.07910918  || Decoder Loss:  0.45406878 Validation Decoder Loss:  1.5695218
Encoder Loss:  0.07775094  || Decoder Loss:  0.48372748 Validation Decoder Loss:  1.5672916
Encoder Loss:  0.0779448  || Decoder Loss:  0.49039745 Validation Decoder Loss:  1.3781096
Encoder Loss:  0.07784632  || Decoder Loss:  0.45510268 Validation Decoder Loss:  1.6035473
Encoder Loss:  0.07720549  || Decoder Loss:  0.45796958 Validation Decoder Loss:  1.5574772
Encoder Loss:  0.07669686  || Decoder Loss:  0.46635872 Validation Decoder Loss:  1.2708194
Encoder Loss:  0.07613214  || Decoder Loss:  0.4447151 Validation Decoder Loss:  1.5959103
Encoder Loss:  0.07903666  || Decoder Loss:  0.47765607 Validation Decoder Loss:  1.250314
Encoder Loss:  0.0748457  || Decoder Loss:  0.46642423 Validation Decoder Loss:  1.4420295
Encoder Loss:  0.07605879  || Decoder Loss:  0.47914216 Validation Decoder Loss:  1.3687935
Encoder Loss:  0.07477659  || Decoder Loss:  0.4495491 Validation Decoder Loss:  0.80415
Encoder Loss:  0.073267475  || Decoder Loss:  0.43415776 Validation Decoder Loss:  1.4607329
Encoder Loss:  0.07334295  || Decoder Loss:  0.42890248 Validation Decoder Loss:  1.4613187
Encoder Loss:  0.073414415  || Decoder Loss:  0.43919265 Validation Decoder Loss:  1.2369233
Encoder Loss:  0.07584149  || Decoder Loss:  0.4752137 Validation Decoder Loss:  1.5076514
Encoder Loss:  0.073602885  || Decoder Loss:  0.41040817 Validation Decoder Loss:  1.4979703
Encoder Loss:  0.07533774  || Decoder Loss:  0.4647403 Validation Decoder Loss:  1.2204068
Encoder Loss:  0.073987275  || Decoder Loss:  0.4561477 Validation Decoder Loss:  1.4084269
Encoder Loss:  0.0717351  || Decoder Loss:  0.40438166 Validation Decoder Loss:  1.2147753
Encoder Loss:  0.07251582  || Decoder Loss:  0.4270066 Validation Decoder Loss:  1.1476691
Encoder Loss:  0.07257516  || Decoder Loss:  0.4397552 Validation Decoder Loss:  1.1946101
Encoder Loss:  0.0711799  || Decoder Loss:  0.40540913 Validation Decoder Loss:  1.3978622
Encoder Loss:  0.072055854  || Decoder Loss:  0.42628166 Validation Decoder Loss:  1.3650709
Encoder Loss:  0.071011715  || Decoder Loss:  0.4060738 Validation Decoder Loss:  0.8844092
Encoder Loss:  0.07008166  || Decoder Loss:  0.39029634 Validation Decoder Loss:  0.727225
Encoder Loss:  0.07067557  || Decoder Loss:  0.39997432 Validation Decoder Loss:  1.078552
Encoder Loss:  0.07199382  || Decoder Loss:  0.4156004 Validation Decoder Loss:  1.3906054
Encoder Loss:  0.06934421  || Decoder Loss:  0.35279837 Validation Decoder Loss:  1.4282196
Encoder Loss:  0.072438076  || Decoder Loss:  0.41099036 Validation Decoder Loss:  1.3904045
Model: siamese_net_lr_0.09728912857330194 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.3904045
Model: "sequential_714"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_404 (Conv3D (None, 112, 5, 20, 1)     50        
_________________________________________________________________
dropout_837 (Dropout)        (None, 112, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_405 (Conv3D (None, 184, 5, 20, 1)     74        
_________________________________________________________________
reshape_205 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_716"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_304 (Conv2D)          (None, 1880, 20, 1)       1367      
_________________________________________________________________
dropout_839 (Dropout)        (None, 1880, 20, 1)       0         
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 920, 20, 1)        962       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_717"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_304 (Conv2D (None, 1000, 20, 1)       82        
_________________________________________________________________
dropout_841 (Dropout)        (None, 1000, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_305 (Conv2D (None, 3245, 20, 1)       1248      
=================================================================
Total params: 1,330
Trainable params: 1,330
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07785104  || Decoder Loss:  0.077728994 Validation Decoder Loss:  0.31922597
Encoder Loss:  0.06025002  || Decoder Loss:  0.038407244 Validation Decoder Loss:  0.33895913
Encoder Loss:  0.05809888  || Decoder Loss:  0.035627123 Validation Decoder Loss:  0.34144893
Encoder Loss:  0.06957552  || Decoder Loss:  0.03437241 Validation Decoder Loss:  0.34518355
Encoder Loss:  0.051201858  || Decoder Loss:  0.033470105 Validation Decoder Loss:  0.34936142
Encoder Loss:  0.04896355  || Decoder Loss:  0.03289775 Validation Decoder Loss:  0.34998173
Encoder Loss:  0.049136713  || Decoder Loss:  0.032491483 Validation Decoder Loss:  0.34955037
Encoder Loss:  0.052558184  || Decoder Loss:  0.03219446 Validation Decoder Loss:  0.34900007
Encoder Loss:  0.05572242  || Decoder Loss:  0.031985577 Validation Decoder Loss:  0.35076606
Encoder Loss:  0.048206706  || Decoder Loss:  0.031785533 Validation Decoder Loss:  0.35210633
Encoder Loss:  0.047184944  || Decoder Loss:  0.031517375 Validation Decoder Loss:  0.35039046
Encoder Loss:  0.050844245  || Decoder Loss:  0.031270992 Validation Decoder Loss:  0.35012144
Encoder Loss:  0.047580212  || Decoder Loss:  0.031104097 Validation Decoder Loss:  0.3494081
Encoder Loss:  0.047219187  || Decoder Loss:  0.030874284 Validation Decoder Loss:  0.34861264
Encoder Loss:  0.047264114  || Decoder Loss:  0.030671556 Validation Decoder Loss:  0.34860647
Encoder Loss:  0.048003945  || Decoder Loss:  0.030485602 Validation Decoder Loss:  0.34878087
Encoder Loss:  0.04752673  || Decoder Loss:  0.030322941 Validation Decoder Loss:  0.349404
Encoder Loss:  0.04683091  || Decoder Loss:  0.030143192 Validation Decoder Loss:  0.34931287
Encoder Loss:  0.046688348  || Decoder Loss:  0.029991403 Validation Decoder Loss:  0.34923717
Encoder Loss:  0.047094993  || Decoder Loss:  0.029839478 Validation Decoder Loss:  0.3487832
Encoder Loss:  0.04712853  || Decoder Loss:  0.029700363 Validation Decoder Loss:  0.34910572
Encoder Loss:  0.047601614  || Decoder Loss:  0.029577743 Validation Decoder Loss:  0.34921467
Encoder Loss:  0.047278356  || Decoder Loss:  0.029456448 Validation Decoder Loss:  0.3491034
Encoder Loss:  0.04664225  || Decoder Loss:  0.029343368 Validation Decoder Loss:  0.34840488
Encoder Loss:  0.04605534  || Decoder Loss:  0.029215092 Validation Decoder Loss:  0.34847048
Encoder Loss:  0.046427082  || Decoder Loss:  0.029110609 Validation Decoder Loss:  0.34874088
Encoder Loss:  0.046197265  || Decoder Loss:  0.028977478 Validation Decoder Loss:  0.34887716
Encoder Loss:  0.04614656  || Decoder Loss:  0.028860295 Validation Decoder Loss:  0.34871045
Encoder Loss:  0.046584368  || Decoder Loss:  0.028772006 Validation Decoder Loss:  0.34849852
Encoder Loss:  0.04615142  || Decoder Loss:  0.028659413 Validation Decoder Loss:  0.34834898
Encoder Loss:  0.04630044  || Decoder Loss:  0.028532436 Validation Decoder Loss:  0.34821755
Encoder Loss:  0.04697044  || Decoder Loss:  0.028460134 Validation Decoder Loss:  0.34879702
Encoder Loss:  0.046727423  || Decoder Loss:  0.028360862 Validation Decoder Loss:  0.34787327
Encoder Loss:  0.046029165  || Decoder Loss:  0.02827269 Validation Decoder Loss:  0.34738523
Encoder Loss:  0.046083584  || Decoder Loss:  0.028189145 Validation Decoder Loss:  0.34768802
Encoder Loss:  0.04562349  || Decoder Loss:  0.028020168 Validation Decoder Loss:  0.34785694
Encoder Loss:  0.04603957  || Decoder Loss:  0.028140895 Validation Decoder Loss:  0.3479761
Encoder Loss:  0.046211638  || Decoder Loss:  0.02799367 Validation Decoder Loss:  0.34709364
Encoder Loss:  0.04584942  || Decoder Loss:  0.027978795 Validation Decoder Loss:  0.34533224
Encoder Loss:  0.045878205  || Decoder Loss:  0.028344229 Validation Decoder Loss:  0.3457703
Model: siamese_net_lr_0.0013701914799416745 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3457703
Model: "sequential_718"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_407 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_843 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_408 (Conv3D (None, 184, 5, 20, 1)     59        
_________________________________________________________________
reshape_206 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_720"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_306 (Conv2D)          (None, 2280, 20, 1)       967       
_________________________________________________________________
dropout_845 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 920, 20, 1)        443       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_721"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_306 (Conv2D (None, 1080, 20, 1)       162       
_________________________________________________________________
dropout_847 (Dropout)        (None, 1080, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_307 (Conv2D (None, 3245, 20, 1)       1088      
=================================================================
Total params: 1,250
Trainable params: 1,250
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.250046  || Decoder Loss:  0.40606156 Validation Decoder Loss:  0.85550094
Encoder Loss:  0.1317274  || Decoder Loss:  0.24310362 Validation Decoder Loss:  0.44186217
Encoder Loss:  0.06236035  || Decoder Loss:  0.069469474 Validation Decoder Loss:  0.31522372
Encoder Loss:  0.052943133  || Decoder Loss:  0.052798912 Validation Decoder Loss:  0.3227233
Encoder Loss:  0.05470824  || Decoder Loss:  0.051607937 Validation Decoder Loss:  0.35090452
Encoder Loss:  0.052183542  || Decoder Loss:  0.050915018 Validation Decoder Loss:  0.3595932
Encoder Loss:  0.054604  || Decoder Loss:  0.051117603 Validation Decoder Loss:  0.31632406
Encoder Loss:  0.054511476  || Decoder Loss:  0.05068537 Validation Decoder Loss:  0.33322227
Encoder Loss:  0.0533812  || Decoder Loss:  0.05009518 Validation Decoder Loss:  0.3897761
Encoder Loss:  0.054637514  || Decoder Loss:  0.052023325 Validation Decoder Loss:  0.30317086
Encoder Loss:  0.05680276  || Decoder Loss:  0.05193877 Validation Decoder Loss:  0.40752012
Encoder Loss:  0.054248516  || Decoder Loss:  0.049141657 Validation Decoder Loss:  0.39067274
Encoder Loss:  0.052897453  || Decoder Loss:  0.048765488 Validation Decoder Loss:  0.35767362
Encoder Loss:  0.050704  || Decoder Loss:  0.046882953 Validation Decoder Loss:  0.34752092
Encoder Loss:  0.050756592  || Decoder Loss:  0.04652371 Validation Decoder Loss:  0.35794386
Encoder Loss:  0.04936554  || Decoder Loss:  0.04567597 Validation Decoder Loss:  0.33900005
Encoder Loss:  0.049782768  || Decoder Loss:  0.045230027 Validation Decoder Loss:  0.34723347
Encoder Loss:  0.050198283  || Decoder Loss:  0.04515921 Validation Decoder Loss:  0.36868724
Encoder Loss:  0.04896089  || Decoder Loss:  0.04403757 Validation Decoder Loss:  0.33003932
Encoder Loss:  0.04955351  || Decoder Loss:  0.044294428 Validation Decoder Loss:  0.35330236
Encoder Loss:  0.048743542  || Decoder Loss:  0.04328567 Validation Decoder Loss:  0.3671362
Encoder Loss:  0.049596906  || Decoder Loss:  0.043670516 Validation Decoder Loss:  0.34368896
Encoder Loss:  0.047848802  || Decoder Loss:  0.042323083 Validation Decoder Loss:  0.37570333
Encoder Loss:  0.048450194  || Decoder Loss:  0.04187943 Validation Decoder Loss:  0.3426671
Encoder Loss:  0.04845933  || Decoder Loss:  0.041812338 Validation Decoder Loss:  0.3540241
Encoder Loss:  0.04971737  || Decoder Loss:  0.041433636 Validation Decoder Loss:  0.35144925
Encoder Loss:  0.047772318  || Decoder Loss:  0.0400774 Validation Decoder Loss:  0.38081074
Encoder Loss:  0.049253836  || Decoder Loss:  0.039833423 Validation Decoder Loss:  0.37441993
Encoder Loss:  0.0494108  || Decoder Loss:  0.03949623 Validation Decoder Loss:  0.35699216
Encoder Loss:  0.046830215  || Decoder Loss:  0.03685455 Validation Decoder Loss:  0.33342087
Encoder Loss:  0.04667078  || Decoder Loss:  0.036625024 Validation Decoder Loss:  0.36748567
Encoder Loss:  0.05058534  || Decoder Loss:  0.045297936 Validation Decoder Loss:  0.68608415
Encoder Loss:  0.08586089  || Decoder Loss:  0.14210859 Validation Decoder Loss:  0.36571082
Encoder Loss:  0.052001294  || Decoder Loss:  0.052567147 Validation Decoder Loss:  0.36882177
Encoder Loss:  0.051426124  || Decoder Loss:  0.050424173 Validation Decoder Loss:  0.3722191
Encoder Loss:  0.051243447  || Decoder Loss:  0.04996066 Validation Decoder Loss:  0.37289268
Encoder Loss:  0.050546803  || Decoder Loss:  0.049593277 Validation Decoder Loss:  0.3705296
Encoder Loss:  0.052306212  || Decoder Loss:  0.05023197 Validation Decoder Loss:  0.33124137
Encoder Loss:  0.052253436  || Decoder Loss:  0.049725298 Validation Decoder Loss:  0.34524745
Encoder Loss:  0.051284626  || Decoder Loss:  0.04951359 Validation Decoder Loss:  0.32109383
Model: siamese_net_lr_0.00871835878979588 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32109383
Model: "sequential_722"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_410 (Conv3D (None, 176, 5, 20, 1)     51        
_________________________________________________________________
dropout_849 (Dropout)        (None, 176, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_411 (Conv3D (None, 184, 5, 20, 1)     10        
_________________________________________________________________
reshape_207 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_724"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_308 (Conv2D)          (None, 2160, 20, 1)       1087      
_________________________________________________________________
dropout_851 (Dropout)        (None, 2160, 20, 1)       0         
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 920, 20, 1)        323       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_725"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_308 (Conv2D (None, 1390, 20, 1)       472       
_________________________________________________________________
dropout_853 (Dropout)        (None, 1390, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_309 (Conv2D (None, 3245, 20, 1)       468       
=================================================================
Total params: 940
Trainable params: 940
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.54231274  || Decoder Loss:  0.5656049 Validation Decoder Loss:  0.5329501
Encoder Loss:  0.3292033  || Decoder Loss:  0.31739902 Validation Decoder Loss:  1.6876183
Encoder Loss:  0.65317833  || Decoder Loss:  0.6983722 Validation Decoder Loss:  1.7630173
Encoder Loss:  0.189429  || Decoder Loss:  0.16023001 Validation Decoder Loss:  0.36256716
Encoder Loss:  0.12438311  || Decoder Loss:  0.080414735 Validation Decoder Loss:  0.34541726
Encoder Loss:  0.118660145  || Decoder Loss:  0.07428122 Validation Decoder Loss:  0.35054326
Encoder Loss:  0.114778444  || Decoder Loss:  0.07151726 Validation Decoder Loss:  0.38566956
Encoder Loss:  0.68006057  || Decoder Loss:  0.72315043 Validation Decoder Loss:  1.7343631
Encoder Loss:  0.47091454  || Decoder Loss:  0.5115324 Validation Decoder Loss:  1.4914455
Encoder Loss:  0.43932736  || Decoder Loss:  0.4903342 Validation Decoder Loss:  0.8082565
Encoder Loss:  0.47515547  || Decoder Loss:  0.5294595 Validation Decoder Loss:  0.82684696
Encoder Loss:  0.4349921  || Decoder Loss:  0.48423684 Validation Decoder Loss:  0.9051925
Encoder Loss:  0.39967713  || Decoder Loss:  0.445891 Validation Decoder Loss:  1.1709148
Encoder Loss:  0.41948915  || Decoder Loss:  0.46954876 Validation Decoder Loss:  0.94908905
Encoder Loss:  0.41303027  || Decoder Loss:  0.4610281 Validation Decoder Loss:  0.91598606
Encoder Loss:  0.39818794  || Decoder Loss:  0.44586504 Validation Decoder Loss:  0.99095505
Encoder Loss:  0.39514062  || Decoder Loss:  0.4428207 Validation Decoder Loss:  0.92234635
Encoder Loss:  0.40037873  || Decoder Loss:  0.44827896 Validation Decoder Loss:  0.91562915
Encoder Loss:  0.41586435  || Decoder Loss:  0.46479908 Validation Decoder Loss:  1.0468365
Encoder Loss:  0.39351133  || Decoder Loss:  0.44073814 Validation Decoder Loss:  0.9365299
Encoder Loss:  0.38676825  || Decoder Loss:  0.43376106 Validation Decoder Loss:  0.89199173
Encoder Loss:  0.3751343  || Decoder Loss:  0.42032287 Validation Decoder Loss:  0.9633197
Encoder Loss:  0.36106107  || Decoder Loss:  0.40469947 Validation Decoder Loss:  0.7365844
Encoder Loss:  0.33609647  || Decoder Loss:  0.37564737 Validation Decoder Loss:  0.77194995
Encoder Loss:  0.18014883  || Decoder Loss:  0.19714847 Validation Decoder Loss:  0.3987763
Encoder Loss:  0.41173446  || Decoder Loss:  0.4611919 Validation Decoder Loss:  1.1465766
Encoder Loss:  0.25325096  || Decoder Loss:  0.28066975 Validation Decoder Loss:  0.38343698
Encoder Loss:  0.055315632  || Decoder Loss:  0.055356503 Validation Decoder Loss:  0.3096357
Encoder Loss:  0.041860662  || Decoder Loss:  0.040212683 Validation Decoder Loss:  0.31884685
Encoder Loss:  0.040193237  || Decoder Loss:  0.037886668 Validation Decoder Loss:  0.34215865
Encoder Loss:  0.042460665  || Decoder Loss:  0.039947547 Validation Decoder Loss:  0.30414107
Encoder Loss:  0.04009073  || Decoder Loss:  0.03790232 Validation Decoder Loss:  0.3384326
Encoder Loss:  0.039284207  || Decoder Loss:  0.036603156 Validation Decoder Loss:  0.33891195
Encoder Loss:  0.04090735  || Decoder Loss:  0.0378408 Validation Decoder Loss:  0.3068803
Encoder Loss:  0.039138027  || Decoder Loss:  0.036544032 Validation Decoder Loss:  0.33187723
Encoder Loss:  0.0387592  || Decoder Loss:  0.03665129 Validation Decoder Loss:  0.34541208
Encoder Loss:  0.038545247  || Decoder Loss:  0.036399856 Validation Decoder Loss:  0.34534496
Encoder Loss:  0.03881396  || Decoder Loss:  0.036646064 Validation Decoder Loss:  0.3388703
Encoder Loss:  0.038917415  || Decoder Loss:  0.036836617 Validation Decoder Loss:  0.3277823
Encoder Loss:  0.039089866  || Decoder Loss:  0.03684558 Validation Decoder Loss:  0.3459295
Model: siamese_net_lr_0.06524608344412997 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3459295
Model: "sequential_726"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_413 (Conv3D (None, 132, 5, 20, 1)     70        
_________________________________________________________________
dropout_855 (Dropout)        (None, 132, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_414 (Conv3D (None, 184, 5, 20, 1)     54        
_________________________________________________________________
reshape_208 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_728"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_310 (Conv2D)          (None, 3050, 20, 1)       197       
_________________________________________________________________
dropout_857 (Dropout)        (None, 3050, 20, 1)       0         
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 920, 20, 1)        2132      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_729"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_310 (Conv2D (None, 2820, 20, 1)       1902      
_________________________________________________________________
dropout_859 (Dropout)        (None, 2820, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_311 (Conv2D (None, 3245, 20, 1)       427       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.153112  || Decoder Loss:  0.09369347 Validation Decoder Loss:  0.36433178
Encoder Loss:  0.07762768  || Decoder Loss:  0.04136961 Validation Decoder Loss:  0.35957792
Encoder Loss:  0.060683016  || Decoder Loss:  0.039940182 Validation Decoder Loss:  0.35848063
Encoder Loss:  0.052473582  || Decoder Loss:  0.039152637 Validation Decoder Loss:  0.3586652
Encoder Loss:  0.05774467  || Decoder Loss:  0.038681734 Validation Decoder Loss:  0.3579911
Encoder Loss:  0.056602143  || Decoder Loss:  0.038391892 Validation Decoder Loss:  0.35671374
Encoder Loss:  0.052613594  || Decoder Loss:  0.03791848 Validation Decoder Loss:  0.35483837
Encoder Loss:  0.048459884  || Decoder Loss:  0.036977686 Validation Decoder Loss:  0.35223475
Encoder Loss:  0.049345836  || Decoder Loss:  0.036520906 Validation Decoder Loss:  0.34881395
Encoder Loss:  0.0491056  || Decoder Loss:  0.036010582 Validation Decoder Loss:  0.35100093
Encoder Loss:  0.05067124  || Decoder Loss:  0.035348456 Validation Decoder Loss:  0.3526808
Encoder Loss:  0.047640726  || Decoder Loss:  0.03462888 Validation Decoder Loss:  0.35623732
Encoder Loss:  0.049209703  || Decoder Loss:  0.03433761 Validation Decoder Loss:  0.35026914
Encoder Loss:  0.04758949  || Decoder Loss:  0.03342805 Validation Decoder Loss:  0.3502251
Encoder Loss:  0.04399206  || Decoder Loss:  0.03237201 Validation Decoder Loss:  0.34934297
Encoder Loss:  0.04488855  || Decoder Loss:  0.03135839 Validation Decoder Loss:  0.34764123
Encoder Loss:  0.04290485  || Decoder Loss:  0.03043392 Validation Decoder Loss:  0.34940514
Encoder Loss:  0.044037066  || Decoder Loss:  0.029846322 Validation Decoder Loss:  0.3477197
Encoder Loss:  0.044325456  || Decoder Loss:  0.02939657 Validation Decoder Loss:  0.3483079
Encoder Loss:  0.04525333  || Decoder Loss:  0.029160073 Validation Decoder Loss:  0.3505785
Encoder Loss:  0.045182552  || Decoder Loss:  0.02891882 Validation Decoder Loss:  0.35018814
Encoder Loss:  0.0448037  || Decoder Loss:  0.028726025 Validation Decoder Loss:  0.3507083
Encoder Loss:  0.043201018  || Decoder Loss:  0.028527541 Validation Decoder Loss:  0.35090554
Encoder Loss:  0.04311546  || Decoder Loss:  0.02840976 Validation Decoder Loss:  0.35057288
Encoder Loss:  0.044130836  || Decoder Loss:  0.028273806 Validation Decoder Loss:  0.3523041
Encoder Loss:  0.044005893  || Decoder Loss:  0.028121281 Validation Decoder Loss:  0.3509971
Encoder Loss:  0.042317837  || Decoder Loss:  0.027996968 Validation Decoder Loss:  0.35199255
Encoder Loss:  0.04276837  || Decoder Loss:  0.027855532 Validation Decoder Loss:  0.35211226
Encoder Loss:  0.04207517  || Decoder Loss:  0.027715947 Validation Decoder Loss:  0.35067752
Encoder Loss:  0.04138558  || Decoder Loss:  0.02758141 Validation Decoder Loss:  0.35053772
Encoder Loss:  0.04431293  || Decoder Loss:  0.027480995 Validation Decoder Loss:  0.3535904
Encoder Loss:  0.042272672  || Decoder Loss:  0.027305853 Validation Decoder Loss:  0.35037512
Encoder Loss:  0.041849013  || Decoder Loss:  0.02721963 Validation Decoder Loss:  0.34988293
Encoder Loss:  0.041529763  || Decoder Loss:  0.027147224 Validation Decoder Loss:  0.34974283
Encoder Loss:  0.04198681  || Decoder Loss:  0.026960287 Validation Decoder Loss:  0.34998846
Encoder Loss:  0.041811366  || Decoder Loss:  0.026841192 Validation Decoder Loss:  0.35015905
Encoder Loss:  0.04222616  || Decoder Loss:  0.026724294 Validation Decoder Loss:  0.35060376
Encoder Loss:  0.04086553  || Decoder Loss:  0.026572114 Validation Decoder Loss:  0.35129035
Encoder Loss:  0.041455638  || Decoder Loss:  0.026493756 Validation Decoder Loss:  0.3516889
Encoder Loss:  0.041582294  || Decoder Loss:  0.026399985 Validation Decoder Loss:  0.3519857
Model: siamese_net_lr_0.0038453798936558116 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3519857
Model: "sequential_730"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_416 (Conv3D (None, 140, 5, 20, 1)     78        
_________________________________________________________________
dropout_861 (Dropout)        (None, 140, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_417 (Conv3D (None, 184, 5, 20, 1)     46        
_________________________________________________________________
reshape_209 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_732"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_312 (Conv2D)          (None, 2760, 20, 1)       487       
_________________________________________________________________
dropout_863 (Dropout)        (None, 2760, 20, 1)       0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 920, 20, 1)        1842      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_733"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_312 (Conv2D (None, 950, 20, 1)        32        
_________________________________________________________________
dropout_865 (Dropout)        (None, 950, 20, 1)        0         
_________________________________________________________________
conv2d_transpose_313 (Conv2D (None, 3245, 20, 1)       2297      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28940955  || Decoder Loss:  0.059089474 Validation Decoder Loss:  0.337357
Encoder Loss:  0.32475978  || Decoder Loss:  0.033037208 Validation Decoder Loss:  0.34137633
Encoder Loss:  0.28292903  || Decoder Loss:  0.030161554 Validation Decoder Loss:  0.33893573
Encoder Loss:  0.20431896  || Decoder Loss:  0.029413847 Validation Decoder Loss:  0.3408446
Encoder Loss:  0.091362275  || Decoder Loss:  0.027775085 Validation Decoder Loss:  0.33892488
Encoder Loss:  0.07550685  || Decoder Loss:  0.02637434 Validation Decoder Loss:  0.331689
Encoder Loss:  0.0647586  || Decoder Loss:  0.026366083 Validation Decoder Loss:  0.3175645
Encoder Loss:  0.061118025  || Decoder Loss:  0.025405623 Validation Decoder Loss:  0.3305615
Encoder Loss:  0.059048228  || Decoder Loss:  0.02527004 Validation Decoder Loss:  0.34346452
Encoder Loss:  0.056855727  || Decoder Loss:  0.024827376 Validation Decoder Loss:  0.35871542
Encoder Loss:  0.0527365  || Decoder Loss:  0.024603834 Validation Decoder Loss:  0.34897357
Encoder Loss:  0.05315649  || Decoder Loss:  0.024465231 Validation Decoder Loss:  0.34451276
Encoder Loss:  0.051046036  || Decoder Loss:  0.024449376 Validation Decoder Loss:  0.31724274
Encoder Loss:  0.048115015  || Decoder Loss:  0.024334142 Validation Decoder Loss:  0.3136736
Encoder Loss:  0.045697384  || Decoder Loss:  0.024001 Validation Decoder Loss:  0.32169396
Encoder Loss:  0.049157724  || Decoder Loss:  0.02390958 Validation Decoder Loss:  0.3443825
Encoder Loss:  0.049463805  || Decoder Loss:  0.023647754 Validation Decoder Loss:  0.33106247
Encoder Loss:  0.047118064  || Decoder Loss:  0.024284037 Validation Decoder Loss:  0.3308095
Encoder Loss:  0.045457225  || Decoder Loss:  0.023151072 Validation Decoder Loss:  0.3283419
Encoder Loss:  0.045054093  || Decoder Loss:  0.02338905 Validation Decoder Loss:  0.33989134
Encoder Loss:  0.04670033  || Decoder Loss:  0.02320728 Validation Decoder Loss:  0.33347648
Encoder Loss:  0.046617374  || Decoder Loss:  0.02312322 Validation Decoder Loss:  0.32892552
Encoder Loss:  0.045384146  || Decoder Loss:  0.022914845 Validation Decoder Loss:  0.33525535
Encoder Loss:  0.04552053  || Decoder Loss:  0.022797856 Validation Decoder Loss:  0.34336513
Encoder Loss:  0.04490168  || Decoder Loss:  0.022788327 Validation Decoder Loss:  0.36275122
Encoder Loss:  0.044796955  || Decoder Loss:  0.022834793 Validation Decoder Loss:  0.34480578
Encoder Loss:  0.04620005  || Decoder Loss:  0.02283693 Validation Decoder Loss:  0.32972014
Encoder Loss:  0.046303064  || Decoder Loss:  0.022757554 Validation Decoder Loss:  0.32960522
Encoder Loss:  0.045517847  || Decoder Loss:  0.022369433 Validation Decoder Loss:  0.34435797
Encoder Loss:  0.04534936  || Decoder Loss:  0.022439232 Validation Decoder Loss:  0.35479575
Encoder Loss:  0.0450644  || Decoder Loss:  0.022430448 Validation Decoder Loss:  0.33340055
Encoder Loss:  0.045735553  || Decoder Loss:  0.022943102 Validation Decoder Loss:  0.3543167
Encoder Loss:  0.044581145  || Decoder Loss:  0.022552377 Validation Decoder Loss:  0.34986222
Encoder Loss:  0.044797517  || Decoder Loss:  0.022016395 Validation Decoder Loss:  0.3427447
Encoder Loss:  0.044933673  || Decoder Loss:  0.022399006 Validation Decoder Loss:  0.3379609
Encoder Loss:  0.044826776  || Decoder Loss:  0.022029206 Validation Decoder Loss:  0.35025832
Encoder Loss:  0.044892598  || Decoder Loss:  0.022061286 Validation Decoder Loss:  0.3329268
Encoder Loss:  0.045368675  || Decoder Loss:  0.02225728 Validation Decoder Loss:  0.32844472
Encoder Loss:  0.04484275  || Decoder Loss:  0.0217513 Validation Decoder Loss:  0.3424016
Encoder Loss:  0.044859882  || Decoder Loss:  0.022102665 Validation Decoder Loss:  0.34951544
Model: siamese_net_lr_0.006127013452332886 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34951544
Model: "sequential_734"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_419 (Conv3D (None, 162, 5, 20, 1)     37        
_________________________________________________________________
dropout_867 (Dropout)        (None, 162, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_420 (Conv3D (None, 184, 5, 20, 1)     24        
_________________________________________________________________
reshape_210 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_736"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_314 (Conv2D)          (None, 1830, 20, 1)       1417      
_________________________________________________________________
dropout_869 (Dropout)        (None, 1830, 20, 1)       0         
_________________________________________________________________
conv2d_315 (Conv2D)          (None, 920, 20, 1)        912       
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_737"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_314 (Conv2D (None, 2480, 20, 1)       643       
_________________________________________________________________
dropout_871 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_315 (Conv2D (None, 3245, 20, 1)       767       
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24084175  || Decoder Loss:  0.11517412 Validation Decoder Loss:  0.37028283
Encoder Loss:  0.23185144  || Decoder Loss:  0.09660666 Validation Decoder Loss:  0.35188392
Encoder Loss:  0.25252187  || Decoder Loss:  0.22435194 Validation Decoder Loss:  1.1621575
Encoder Loss:  0.37482905  || Decoder Loss:  0.550575 Validation Decoder Loss:  1.1251591
Encoder Loss:  0.32358506  || Decoder Loss:  0.48819858 Validation Decoder Loss:  0.8935556
Encoder Loss:  0.352071  || Decoder Loss:  0.50946116 Validation Decoder Loss:  1.2487941
Encoder Loss:  0.32827386  || Decoder Loss:  0.4983072 Validation Decoder Loss:  1.0495968
Encoder Loss:  0.31727877  || Decoder Loss:  0.4839149 Validation Decoder Loss:  0.9849465
Encoder Loss:  0.33151704  || Decoder Loss:  0.4916627 Validation Decoder Loss:  0.9294871
Encoder Loss:  0.31904483  || Decoder Loss:  0.48411557 Validation Decoder Loss:  0.8997059
Encoder Loss:  0.31808695  || Decoder Loss:  0.4849452 Validation Decoder Loss:  0.93698955
Encoder Loss:  0.32106876  || Decoder Loss:  0.4857711 Validation Decoder Loss:  0.944672
Encoder Loss:  0.314787  || Decoder Loss:  0.48465616 Validation Decoder Loss:  0.9398178
Encoder Loss:  0.30855235  || Decoder Loss:  0.48135674 Validation Decoder Loss:  1.0403495
Encoder Loss:  0.30269772  || Decoder Loss:  0.46978065 Validation Decoder Loss:  1.1462834
Encoder Loss:  0.29404294  || Decoder Loss:  0.45856717 Validation Decoder Loss:  1.0078889
Encoder Loss:  0.28446385  || Decoder Loss:  0.4427229 Validation Decoder Loss:  1.0145917
Encoder Loss:  0.28330517  || Decoder Loss:  0.44109592 Validation Decoder Loss:  0.8772526
Encoder Loss:  0.31413  || Decoder Loss:  0.49283126 Validation Decoder Loss:  0.9188203
Encoder Loss:  0.2984373  || Decoder Loss:  0.46649903 Validation Decoder Loss:  1.0972122
Encoder Loss:  0.2653955  || Decoder Loss:  0.41105163 Validation Decoder Loss:  1.0537384
Encoder Loss:  0.27427235  || Decoder Loss:  0.42581013 Validation Decoder Loss:  1.0549748
Encoder Loss:  0.30465564  || Decoder Loss:  0.47699463 Validation Decoder Loss:  0.8345597
Encoder Loss:  0.26298457  || Decoder Loss:  0.40699738 Validation Decoder Loss:  0.9238408
Encoder Loss:  0.2861059  || Decoder Loss:  0.44554183 Validation Decoder Loss:  0.9309062
Encoder Loss:  0.25490448  || Decoder Loss:  0.39363116 Validation Decoder Loss:  1.0692983
Encoder Loss:  0.29123965  || Decoder Loss:  0.45456982 Validation Decoder Loss:  0.90496266
Encoder Loss:  0.28882372  || Decoder Loss:  0.45056275 Validation Decoder Loss:  0.9283182
Encoder Loss:  0.24076106  || Decoder Loss:  0.36977702 Validation Decoder Loss:  0.79087687
Encoder Loss:  0.26679695  || Decoder Loss:  0.4133073 Validation Decoder Loss:  1.1157868
Encoder Loss:  0.2940082  || Decoder Loss:  0.45899272 Validation Decoder Loss:  1.0791221
Encoder Loss:  0.24489129  || Decoder Loss:  0.3764993 Validation Decoder Loss:  0.8342351
Encoder Loss:  0.24003817  || Decoder Loss:  0.3683507 Validation Decoder Loss:  0.96239984
Encoder Loss:  0.30302432  || Decoder Loss:  0.47423407 Validation Decoder Loss:  1.0443358
Encoder Loss:  0.30207008  || Decoder Loss:  0.47245818 Validation Decoder Loss:  1.0596205
Encoder Loss:  0.30063033  || Decoder Loss:  0.47007382 Validation Decoder Loss:  1.1414571
Encoder Loss:  0.30081725  || Decoder Loss:  0.47033936 Validation Decoder Loss:  1.1288317
Encoder Loss:  0.2973843  || Decoder Loss:  0.46460044 Validation Decoder Loss:  1.0331066
Encoder Loss:  0.2916305  || Decoder Loss:  0.45493492 Validation Decoder Loss:  1.1869172
Encoder Loss:  0.2758515  || Decoder Loss:  0.42850962 Validation Decoder Loss:  0.94620967
Model: siamese_net_lr_0.08522283852428515 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.94620967
Model: "sequential_738"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_422 (Conv3D (None, 180, 5, 20, 1)     118       
_________________________________________________________________
conv3d_transpose_423 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_211 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 124
Trainable params: 124
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_740"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_316 (Conv2D)          (None, 1020, 20, 1)       1208      
_________________________________________________________________
conv2d_317 (Conv2D)          (None, 920, 20, 1)        102       
=================================================================
Total params: 1,310
Trainable params: 1,310
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_741"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_316 (Conv2D (None, 1650, 20, 1)       732       
_________________________________________________________________
conv2d_transpose_317 (Conv2D (None, 3245, 20, 1)       1597      
=================================================================
Total params: 2,329
Trainable params: 2,329
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [6.94093338e-02 8.29846159e-01 9.14032536e-01 5.53426076e-01
 6.61629294e-01 3.18041542e-01 9.00000000e+02 1.02000000e+03
 1.65000000e+03]
Optimized Validation Decoder Loss: 0.2484336495399475











Optimizing at level  3
Model: "sequential_742"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_425 (Conv3D (None, 172, 5, 20, 1)     110       
_________________________________________________________________
dropout_873 (Dropout)        (None, 172, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_426 (Conv3D (None, 180, 5, 20, 1)     10        
_________________________________________________________________
dropout_874 (Dropout)        (None, 180, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_427 (Conv3D (None, 184, 5, 20, 1)     6         
_________________________________________________________________
reshape_212 (Reshape)        (None, 920, 20, 1)        0         
=================================================================
Total params: 126
Trainable params: 126
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_744"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_318 (Conv2D)          (None, 2430, 20, 1)       817       
_________________________________________________________________
dropout_876 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_319 (Conv2D)          (None, 1020, 20, 1)       393       
_________________________________________________________________
dropout_877 (Dropout)        (None, 1020, 20, 1)       0         
_________________________________________________________________
conv2d_320 (Conv2D)          (None, 920, 20, 1)        102       
=================================================================
Total params: 1,312
Trainable params: 1,312
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_745"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_318 (Conv2D (None, 1650, 20, 1)       732       
_________________________________________________________________
dropout_879 (Dropout)        (None, 1650, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_319 (Conv2D (None, 2190, 20, 1)       542       
_________________________________________________________________
dropout_880 (Dropout)        (None, 2190, 20, 1)       0         
=================================================================
Total params: 1,274
Trainable params: 1,274
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Traceback (most recent call last):
  File "iterative_naive_nas.py", line 748, in <module>
    nas.search()
  File "iterative_naive_nas.py", line 689, in search
    val_loss = synthesizer.BO()
  File "iterative_naive_nas.py", line 120, in BO
    eeg_domain, bold_domain, decoder_domain)
  File "/home/davidcalhas/eeg_to_fmri/src/bayesian_optimization.py", line 184, in hidden_layer_NAS_BO
    f=bayesian_optimization_function, domain=hyperparameters, model_type="GP_MCMC", acquisition_type="EI_MCMC")
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py", line 118, in __init__
    self._init_design_chooser()
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py", line 193, in _init_design_chooser
    self.Y, _ = self.objective.evaluate(self.X)
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/GPyOpt/core/task/objective.py", line 50, in evaluate
    f_evals, cost_evals = self._eval_func(x)
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/GPyOpt/core/task/objective.py", line 74, in _eval_func
    rlt = self.func(np.atleast_2d(x[i]))
  File "/home/davidcalhas/eeg_to_fmri/src/bayesian_optimization.py", line 162, in bayesian_optimization_function
    tv_y=tv_y)
  File "/home/davidcalhas/eeg_to_fmri/src/custom_training.py", line 192, in linear_combination_training
    decoder_loss, decoder_grads = grad_decoder(decoder_model, shared_eeg, X_train_bold[batch_start:batch_stop])
  File "/home/davidcalhas/eeg_to_fmri/src/custom_training.py", line 70, in grad_decoder
    reconstruction_loss = losses_utils.cross_correlation(outputs, targets)
  File "/home/davidcalhas/eeg_to_fmri/src/utils/losses_utils.py", line 36, in cross_correlation
    a = K.batch_dot(x, y, axes=1)
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/keras/backend.py", line 1710, in batch_dot
    out = math_ops.reduce_sum(math_ops.multiply(x, y), axes[0])
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py", line 180, in wrapper
    return target(*args, **kwargs)
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 322, in multiply
    return gen_math_ops.mul(x, y, name)
  File "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 6487, in mul
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File "<string>", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [64,43800] vs. [64,64900] [Op:Mul]
