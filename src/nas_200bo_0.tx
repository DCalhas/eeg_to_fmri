Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-21 16:14:08.371558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-21 16:14:08.374862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-21 16:14:08.375009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 16:14:08.376068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-21 16:14:08.377147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-21 16:14:08.377347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-21 16:14:08.378320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-21 16:14:08.378819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-21 16:14:08.380955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-21 16:14:08.382119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-21 16:14:08.382310: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-21 16:14:08.403860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-21 16:14:08.404731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e236862f50 executing computations on platform Host. Devices:
2019-11-21 16:14:08.404754: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-21 16:14:08.405602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-21 16:14:08.405630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 16:14:08.405640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-21 16:14:08.405650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-21 16:14:08.405660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-21 16:14:08.405669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-21 16:14:08.405679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-21 16:14:08.405689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-21 16:14:08.407102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-21 16:14:08.407126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 16:14:08.465360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-21 16:14:08.465389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-21 16:14:08.465394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-21 16:14:08.467135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-21 16:14:08.468325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e236db9360 executing computations on platform CUDA. Devices:
2019-11-21 16:14:08.468344: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-21 16:14:08.904114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 2607, 20)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 242, 10, 20, 1)    233       
_________________________________________________________________
reshape (Reshape)            (None, 2420, 20, 1)       0         
=================================================================
Total params: 233
Trainable params: 233
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36798364  || Decoder Loss:  0.042128388 Validation Decoder Loss:  0.33898166
Encoder Loss:  0.36680278  || Decoder Loss:  0.04321079 Validation Decoder Loss:  0.33753118
Encoder Loss:  0.3645558  || Decoder Loss:  0.04532545 Validation Decoder Loss:  0.33659023
Encoder Loss:  0.35908222  || Decoder Loss:  0.050292727 Validation Decoder Loss:  0.33715025
Encoder Loss:  0.33279893  || Decoder Loss:  0.06347926 Validation Decoder Loss:  0.32982302
Encoder Loss:  0.12733567  || Decoder Loss:  0.040736385 Validation Decoder Loss:  0.3324356
Encoder Loss:  0.08553832  || Decoder Loss:  0.037601244 Validation Decoder Loss:  0.33112115
Encoder Loss:  0.08520359  || Decoder Loss:  0.036676124 Validation Decoder Loss:  0.33040884
Encoder Loss:  0.08494323  || Decoder Loss:  0.0361112 Validation Decoder Loss:  0.32997665
Encoder Loss:  0.084766015  || Decoder Loss:  0.03575403 Validation Decoder Loss:  0.32972482
Encoder Loss:  0.08413271  || Decoder Loss:  0.03552261 Validation Decoder Loss:  0.32955596
Encoder Loss:  0.083898135  || Decoder Loss:  0.035371732 Validation Decoder Loss:  0.32944727
Encoder Loss:  0.083386935  || Decoder Loss:  0.03527074 Validation Decoder Loss:  0.3293556
Encoder Loss:  0.082536824  || Decoder Loss:  0.035200164 Validation Decoder Loss:  0.32929265
Encoder Loss:  0.066034034  || Decoder Loss:  0.035148904 Validation Decoder Loss:  0.32926646
Encoder Loss:  0.05233611  || Decoder Loss:  0.035120364 Validation Decoder Loss:  0.3292258
Encoder Loss:  0.05209804  || Decoder Loss:  0.035091206 Validation Decoder Loss:  0.32922173
Encoder Loss:  0.0518172  || Decoder Loss:  0.03506574 Validation Decoder Loss:  0.329244
Encoder Loss:  0.051536445  || Decoder Loss:  0.035046507 Validation Decoder Loss:  0.32928985
Encoder Loss:  0.051366698  || Decoder Loss:  0.035031237 Validation Decoder Loss:  0.32933885
Encoder Loss:  0.051186867  || Decoder Loss:  0.035019927 Validation Decoder Loss:  0.32941294
Encoder Loss:  0.05107862  || Decoder Loss:  0.03500935 Validation Decoder Loss:  0.329483
Encoder Loss:  0.050903354  || Decoder Loss:  0.034998205 Validation Decoder Loss:  0.32956845
Encoder Loss:  0.05077852  || Decoder Loss:  0.034984663 Validation Decoder Loss:  0.32966572
Encoder Loss:  0.050617374  || Decoder Loss:  0.03496758 Validation Decoder Loss:  0.3297828
Encoder Loss:  0.05047284  || Decoder Loss:  0.034948133 Validation Decoder Loss:  0.32991236
Encoder Loss:  0.050355196  || Decoder Loss:  0.034927092 Validation Decoder Loss:  0.3300478
Encoder Loss:  0.05011777  || Decoder Loss:  0.034901693 Validation Decoder Loss:  0.33018902
Encoder Loss:  0.04994125  || Decoder Loss:  0.034869686 Validation Decoder Loss:  0.3303357
Encoder Loss:  0.04979671  || Decoder Loss:  0.03483607 Validation Decoder Loss:  0.33048442
Encoder Loss:  0.0496452  || Decoder Loss:  0.03480055 Validation Decoder Loss:  0.33063182
Encoder Loss:  0.049484633  || Decoder Loss:  0.034763888 Validation Decoder Loss:  0.33078173
Encoder Loss:  0.049350973  || Decoder Loss:  0.034722503 Validation Decoder Loss:  0.33092827
Encoder Loss:  0.049158644  || Decoder Loss:  0.034680758 Validation Decoder Loss:  0.33108538
Encoder Loss:  0.049087945  || Decoder Loss:  0.03463787 Validation Decoder Loss:  0.3312375
Encoder Loss:  0.048936877  || Decoder Loss:  0.034592524 Validation Decoder Loss:  0.33138686
Encoder Loss:  0.048798453  || Decoder Loss:  0.03454561 Validation Decoder Loss:  0.33153188
Encoder Loss:  0.04872814  || Decoder Loss:  0.034498032 Validation Decoder Loss:  0.3316724
Encoder Loss:  0.048600707  || Decoder Loss:  0.034451805 Validation Decoder Loss:  0.33180508
Encoder Loss:  0.048497897  || Decoder Loss:  0.03440963 Validation Decoder Loss:  0.33193424
Model: siamese_net_lr_0.0005311150285461291 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33193424
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 504, 5, 20, 1)     127       
_________________________________________________________________
reshape_1 (Reshape)          (None, 2520, 20, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19032247  || Decoder Loss:  0.03699786 Validation Decoder Loss:  0.3337466
Encoder Loss:  0.19011395  || Decoder Loss:  0.037091684 Validation Decoder Loss:  0.33344916
Encoder Loss:  0.18981823  || Decoder Loss:  0.037383202 Validation Decoder Loss:  0.3332734
Encoder Loss:  0.1891874  || Decoder Loss:  0.03836543 Validation Decoder Loss:  0.33380932
Encoder Loss:  0.1706372  || Decoder Loss:  0.046413146 Validation Decoder Loss:  0.35324454
Encoder Loss:  0.0666531  || Decoder Loss:  0.04403175 Validation Decoder Loss:  0.32928583
Encoder Loss:  0.061459627  || Decoder Loss:  0.036497325 Validation Decoder Loss:  0.32906792
Encoder Loss:  0.06086348  || Decoder Loss:  0.03553269 Validation Decoder Loss:  0.32956544
Encoder Loss:  0.060790453  || Decoder Loss:  0.03544226 Validation Decoder Loss:  0.32968146
Encoder Loss:  0.06066728  || Decoder Loss:  0.03540987 Validation Decoder Loss:  0.32970756
Encoder Loss:  0.06061917  || Decoder Loss:  0.035377923 Validation Decoder Loss:  0.3297291
Encoder Loss:  0.060550097  || Decoder Loss:  0.035346203 Validation Decoder Loss:  0.32975358
Encoder Loss:  0.06048932  || Decoder Loss:  0.03531482 Validation Decoder Loss:  0.32978427
Encoder Loss:  0.060376886  || Decoder Loss:  0.035284277 Validation Decoder Loss:  0.3298159
Encoder Loss:  0.06028398  || Decoder Loss:  0.035254825 Validation Decoder Loss:  0.32985017
Encoder Loss:  0.060165077  || Decoder Loss:  0.035226837 Validation Decoder Loss:  0.32988977
Encoder Loss:  0.05992425  || Decoder Loss:  0.035200372 Validation Decoder Loss:  0.32992667
Encoder Loss:  0.059593383  || Decoder Loss:  0.03517614 Validation Decoder Loss:  0.3299629
Encoder Loss:  0.058251597  || Decoder Loss:  0.035154082 Validation Decoder Loss:  0.33000362
Encoder Loss:  0.04611271  || Decoder Loss:  0.035131577 Validation Decoder Loss:  0.33013022
Encoder Loss:  0.043235287  || Decoder Loss:  0.03511024 Validation Decoder Loss:  0.33012185
Encoder Loss:  0.043030027  || Decoder Loss:  0.035088982 Validation Decoder Loss:  0.3301191
Encoder Loss:  0.04288344  || Decoder Loss:  0.035068624 Validation Decoder Loss:  0.33013707
Encoder Loss:  0.04278811  || Decoder Loss:  0.035049323 Validation Decoder Loss:  0.3301759
Encoder Loss:  0.042691182  || Decoder Loss:  0.035030432 Validation Decoder Loss:  0.3302303
Encoder Loss:  0.04257933  || Decoder Loss:  0.035011627 Validation Decoder Loss:  0.33031175
Encoder Loss:  0.04244751  || Decoder Loss:  0.034992103 Validation Decoder Loss:  0.33041763
Encoder Loss:  0.04230663  || Decoder Loss:  0.034971558 Validation Decoder Loss:  0.33053362
Encoder Loss:  0.042157963  || Decoder Loss:  0.034952085 Validation Decoder Loss:  0.33065516
Encoder Loss:  0.041995503  || Decoder Loss:  0.034932766 Validation Decoder Loss:  0.33081126
Encoder Loss:  0.041773666  || Decoder Loss:  0.03491329 Validation Decoder Loss:  0.3310219
Encoder Loss:  0.041595522  || Decoder Loss:  0.034894105 Validation Decoder Loss:  0.33128253
Encoder Loss:  0.041392446  || Decoder Loss:  0.03487501 Validation Decoder Loss:  0.33158866
Encoder Loss:  0.0411761  || Decoder Loss:  0.03485781 Validation Decoder Loss:  0.33189923
Encoder Loss:  0.041011892  || Decoder Loss:  0.03484626 Validation Decoder Loss:  0.33214477
Encoder Loss:  0.040971737  || Decoder Loss:  0.03484027 Validation Decoder Loss:  0.33229217
Encoder Loss:  0.040930577  || Decoder Loss:  0.03483845 Validation Decoder Loss:  0.3323707
Encoder Loss:  0.040932246  || Decoder Loss:  0.034837704 Validation Decoder Loss:  0.33243597
Encoder Loss:  0.0409253  || Decoder Loss:  0.03483773 Validation Decoder Loss:  0.3324579
Encoder Loss:  0.04098276  || Decoder Loss:  0.03483694 Validation Decoder Loss:  0.3324765
Model: siamese_net_lr_0.0001549941569770357 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3324765
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 274, 5, 20, 1)     23        
_________________________________________________________________
reshape_2 (Reshape)          (None, 1370, 20, 1)       0         
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 1370, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4403561  || Decoder Loss:  0.07977107 Validation Decoder Loss:  0.35663503
Encoder Loss:  0.21594687  || Decoder Loss:  0.097932406 Validation Decoder Loss:  0.47308606
Encoder Loss:  0.09918236  || Decoder Loss:  0.053801276 Validation Decoder Loss:  0.3779079
Encoder Loss:  0.09738476  || Decoder Loss:  0.03937589 Validation Decoder Loss:  0.34898195
Encoder Loss:  0.09556429  || Decoder Loss:  0.034679137 Validation Decoder Loss:  0.33821929
Encoder Loss:  0.071053855  || Decoder Loss:  0.032816704 Validation Decoder Loss:  0.33470783
Encoder Loss:  0.056642596  || Decoder Loss:  0.032234058 Validation Decoder Loss:  0.335087
Encoder Loss:  0.05555768  || Decoder Loss:  0.032000944 Validation Decoder Loss:  0.33558622
Encoder Loss:  0.054846864  || Decoder Loss:  0.031825066 Validation Decoder Loss:  0.3363208
Encoder Loss:  0.054769333  || Decoder Loss:  0.031669937 Validation Decoder Loss:  0.33682305
Encoder Loss:  0.054415513  || Decoder Loss:  0.031525362 Validation Decoder Loss:  0.33745682
Encoder Loss:  0.053747132  || Decoder Loss:  0.03139964 Validation Decoder Loss:  0.33814365
Encoder Loss:  0.053615123  || Decoder Loss:  0.03128714 Validation Decoder Loss:  0.33882228
Encoder Loss:  0.05390772  || Decoder Loss:  0.031180682 Validation Decoder Loss:  0.3393376
Encoder Loss:  0.054068804  || Decoder Loss:  0.031084562 Validation Decoder Loss:  0.33982134
Encoder Loss:  0.05350363  || Decoder Loss:  0.03102361 Validation Decoder Loss:  0.340401
Encoder Loss:  0.0543445  || Decoder Loss:  0.030963344 Validation Decoder Loss:  0.34055012
Encoder Loss:  0.053168397  || Decoder Loss:  0.030923193 Validation Decoder Loss:  0.34118772
Encoder Loss:  0.05407636  || Decoder Loss:  0.030885734 Validation Decoder Loss:  0.3414417
Encoder Loss:  0.053738713  || Decoder Loss:  0.03086549 Validation Decoder Loss:  0.34155327
Encoder Loss:  0.054184645  || Decoder Loss:  0.030854322 Validation Decoder Loss:  0.34181476
Encoder Loss:  0.053473238  || Decoder Loss:  0.030847786 Validation Decoder Loss:  0.3421834
Encoder Loss:  0.053568657  || Decoder Loss:  0.03088887 Validation Decoder Loss:  0.3423891
Encoder Loss:  0.054558907  || Decoder Loss:  0.030860737 Validation Decoder Loss:  0.3422215
Encoder Loss:  0.05236708  || Decoder Loss:  0.030891437 Validation Decoder Loss:  0.3426562
Encoder Loss:  0.053379275  || Decoder Loss:  0.0309561 Validation Decoder Loss:  0.34260148
Encoder Loss:  0.053906973  || Decoder Loss:  0.030970896 Validation Decoder Loss:  0.34252924
Encoder Loss:  0.053687114  || Decoder Loss:  0.030961651 Validation Decoder Loss:  0.3426449
Encoder Loss:  0.054150637  || Decoder Loss:  0.030907854 Validation Decoder Loss:  0.34265533
Encoder Loss:  0.05340135  || Decoder Loss:  0.030938847 Validation Decoder Loss:  0.3425418
Encoder Loss:  0.05358912  || Decoder Loss:  0.030957568 Validation Decoder Loss:  0.3425148
Encoder Loss:  0.053570043  || Decoder Loss:  0.030911725 Validation Decoder Loss:  0.34266242
Encoder Loss:  0.053480364  || Decoder Loss:  0.031006958 Validation Decoder Loss:  0.34268254
Encoder Loss:  0.053250365  || Decoder Loss:  0.0310323 Validation Decoder Loss:  0.34246892
Encoder Loss:  0.053267535  || Decoder Loss:  0.031011958 Validation Decoder Loss:  0.3424011
Encoder Loss:  0.05310508  || Decoder Loss:  0.0309905 Validation Decoder Loss:  0.34247348
Encoder Loss:  0.05382156  || Decoder Loss:  0.030968608 Validation Decoder Loss:  0.34239966
Encoder Loss:  0.052527767  || Decoder Loss:  0.030974748 Validation Decoder Loss:  0.34248817
Encoder Loss:  0.05232137  || Decoder Loss:  0.031136556 Validation Decoder Loss:  0.34233534
Encoder Loss:  0.05283029  || Decoder Loss:  0.03119583 Validation Decoder Loss:  0.3421894
Model: siamese_net_lr_0.0005354720215742816 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34218937
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 88, 15, 20, 1)     276       
_________________________________________________________________
reshape_3 (Reshape)          (None, 1320, 20, 1)       0         
=================================================================
Total params: 276
Trainable params: 276
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16178621  || Decoder Loss:  0.093279675 Validation Decoder Loss:  0.36825836
Encoder Loss:  0.15735237  || Decoder Loss:  0.0884651 Validation Decoder Loss:  0.36574388
Encoder Loss:  0.15211271  || Decoder Loss:  0.08316887 Validation Decoder Loss:  0.3632621
Encoder Loss:  0.14550401  || Decoder Loss:  0.07733227 Validation Decoder Loss:  0.3617128
Encoder Loss:  0.13608462  || Decoder Loss:  0.07149119 Validation Decoder Loss:  0.36657095
Encoder Loss:  0.12774363  || Decoder Loss:  0.08292907 Validation Decoder Loss:  0.5850889
Encoder Loss:  0.31760377  || Decoder Loss:  0.3707488 Validation Decoder Loss:  1.1397648
Encoder Loss:  0.32571134  || Decoder Loss:  0.38350692 Validation Decoder Loss:  1.0935986
Encoder Loss:  0.29456735  || Decoder Loss:  0.3450827 Validation Decoder Loss:  1.0285695
Encoder Loss:  0.23820235  || Decoder Loss:  0.27511296 Validation Decoder Loss:  0.85047805
Encoder Loss:  0.14217116  || Decoder Loss:  0.15576889 Validation Decoder Loss:  0.49358594
Encoder Loss:  0.0589746  || Decoder Loss:  0.05246947 Validation Decoder Loss:  0.35262674
Encoder Loss:  0.044500705  || Decoder Loss:  0.03457389 Validation Decoder Loss:  0.34170243
Encoder Loss:  0.043240473  || Decoder Loss:  0.03306116 Validation Decoder Loss:  0.33889985
Encoder Loss:  0.042687252  || Decoder Loss:  0.032443874 Validation Decoder Loss:  0.3374408
Encoder Loss:  0.04230131  || Decoder Loss:  0.03207856 Validation Decoder Loss:  0.3366389
Encoder Loss:  0.04206846  || Decoder Loss:  0.03184302 Validation Decoder Loss:  0.3361851
Encoder Loss:  0.041859657  || Decoder Loss:  0.03167566 Validation Decoder Loss:  0.33594924
Encoder Loss:  0.041677505  || Decoder Loss:  0.031545173 Validation Decoder Loss:  0.3358438
Encoder Loss:  0.041549664  || Decoder Loss:  0.031438597 Validation Decoder Loss:  0.33579987
Encoder Loss:  0.041405987  || Decoder Loss:  0.031345006 Validation Decoder Loss:  0.33579183
Encoder Loss:  0.041253828  || Decoder Loss:  0.031262342 Validation Decoder Loss:  0.3358239
Encoder Loss:  0.041142877  || Decoder Loss:  0.031187212 Validation Decoder Loss:  0.335864
Encoder Loss:  0.04102252  || Decoder Loss:  0.031115934 Validation Decoder Loss:  0.33591995
Encoder Loss:  0.04091316  || Decoder Loss:  0.03105128 Validation Decoder Loss:  0.33596495
Encoder Loss:  0.040778585  || Decoder Loss:  0.03099112 Validation Decoder Loss:  0.3360012
Encoder Loss:  0.04061065  || Decoder Loss:  0.030935142 Validation Decoder Loss:  0.3360566
Encoder Loss:  0.040371656  || Decoder Loss:  0.030885465 Validation Decoder Loss:  0.3360794
Encoder Loss:  0.038423587  || Decoder Loss:  0.030890139 Validation Decoder Loss:  0.3358689
Encoder Loss:  0.037021797  || Decoder Loss:  0.031061737 Validation Decoder Loss:  0.336073
Encoder Loss:  0.036429144  || Decoder Loss:  0.031152701 Validation Decoder Loss:  0.33635455
Encoder Loss:  0.036255546  || Decoder Loss:  0.031193784 Validation Decoder Loss:  0.33656436
Encoder Loss:  0.036181692  || Decoder Loss:  0.031220196 Validation Decoder Loss:  0.33676046
Encoder Loss:  0.036073968  || Decoder Loss:  0.031228023 Validation Decoder Loss:  0.33694446
Encoder Loss:  0.036052793  || Decoder Loss:  0.031218968 Validation Decoder Loss:  0.33711383
Encoder Loss:  0.035978656  || Decoder Loss:  0.031184897 Validation Decoder Loss:  0.33725476
Encoder Loss:  0.035922296  || Decoder Loss:  0.031151745 Validation Decoder Loss:  0.337396
Encoder Loss:  0.035841707  || Decoder Loss:  0.0311104 Validation Decoder Loss:  0.3375232
Encoder Loss:  0.03579943  || Decoder Loss:  0.03107275 Validation Decoder Loss:  0.33766425
Encoder Loss:  0.035701312  || Decoder Loss:  0.031028619 Validation Decoder Loss:  0.3377968
Model: siamese_net_lr_0.0009467380254797984 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3377968
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 130, 14, 20, 1)    671       
_________________________________________________________________
reshape_4 (Reshape)          (None, 1820, 20, 1)       0         
=================================================================
Total params: 671
Trainable params: 671
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 1820, 20, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 20, 1)       789       
=================================================================
Total params: 789
Trainable params: 789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16919817  || Decoder Loss:  0.091646664 Validation Decoder Loss:  0.36720547
Encoder Loss:  0.16801603  || Decoder Loss:  0.09435424 Validation Decoder Loss:  0.36809397
Encoder Loss:  0.1636785  || Decoder Loss:  0.09700619 Validation Decoder Loss:  0.3697084
Encoder Loss:  0.14321893  || Decoder Loss:  0.09030895 Validation Decoder Loss:  0.44917083
Encoder Loss:  0.2151047  || Decoder Loss:  0.23992498 Validation Decoder Loss:  0.9687208
Encoder Loss:  0.20541993  || Decoder Loss:  0.24288101 Validation Decoder Loss:  0.6606773
Encoder Loss:  0.10001595  || Decoder Loss:  0.10625791 Validation Decoder Loss:  0.42670915
Encoder Loss:  0.058077406  || Decoder Loss:  0.051986456 Validation Decoder Loss:  0.36833793
Encoder Loss:  0.047981367  || Decoder Loss:  0.039006613 Validation Decoder Loss:  0.35009745
Encoder Loss:  0.04483119  || Decoder Loss:  0.035015933 Validation Decoder Loss:  0.3427505
Encoder Loss:  0.043636933  || Decoder Loss:  0.033566926 Validation Decoder Loss:  0.3395209
Encoder Loss:  0.04309208  || Decoder Loss:  0.03296083 Validation Decoder Loss:  0.3381909
Encoder Loss:  0.04278057  || Decoder Loss:  0.03265423 Validation Decoder Loss:  0.33776987
Encoder Loss:  0.042550262  || Decoder Loss:  0.032462824 Validation Decoder Loss:  0.33771846
Encoder Loss:  0.042346936  || Decoder Loss:  0.0323238 Validation Decoder Loss:  0.33780193
Encoder Loss:  0.04216288  || Decoder Loss:  0.032214936 Validation Decoder Loss:  0.33791533
Encoder Loss:  0.041944277  || Decoder Loss:  0.032128576 Validation Decoder Loss:  0.33801666
Encoder Loss:  0.041468497  || Decoder Loss:  0.032063287 Validation Decoder Loss:  0.33805847
Encoder Loss:  0.039396934  || Decoder Loss:  0.032049596 Validation Decoder Loss:  0.33791617
Encoder Loss:  0.03805173  || Decoder Loss:  0.032099824 Validation Decoder Loss:  0.33808458
Encoder Loss:  0.03748874  || Decoder Loss:  0.03215044 Validation Decoder Loss:  0.33832946
Encoder Loss:  0.037219573  || Decoder Loss:  0.03218849 Validation Decoder Loss:  0.3385412
Encoder Loss:  0.03705542  || Decoder Loss:  0.032204486 Validation Decoder Loss:  0.33870754
Encoder Loss:  0.0368401  || Decoder Loss:  0.032208964 Validation Decoder Loss:  0.33885235
Encoder Loss:  0.036718808  || Decoder Loss:  0.032215666 Validation Decoder Loss:  0.3389858
Encoder Loss:  0.036668357  || Decoder Loss:  0.03222462 Validation Decoder Loss:  0.33909267
Encoder Loss:  0.036664486  || Decoder Loss:  0.032225233 Validation Decoder Loss:  0.33917576
Encoder Loss:  0.036623586  || Decoder Loss:  0.032217827 Validation Decoder Loss:  0.3392344
Encoder Loss:  0.036607824  || Decoder Loss:  0.032203764 Validation Decoder Loss:  0.3392748
Encoder Loss:  0.036564168  || Decoder Loss:  0.03219007 Validation Decoder Loss:  0.3393277
Encoder Loss:  0.03657701  || Decoder Loss:  0.032178294 Validation Decoder Loss:  0.33936033
Encoder Loss:  0.03654758  || Decoder Loss:  0.032169987 Validation Decoder Loss:  0.33938867
Encoder Loss:  0.03656106  || Decoder Loss:  0.032159466 Validation Decoder Loss:  0.33941558
Encoder Loss:  0.03653926  || Decoder Loss:  0.03215127 Validation Decoder Loss:  0.33943224
Encoder Loss:  0.036543373  || Decoder Loss:  0.03214637 Validation Decoder Loss:  0.339449
Encoder Loss:  0.03655995  || Decoder Loss:  0.032144852 Validation Decoder Loss:  0.33942512
Encoder Loss:  0.036568213  || Decoder Loss:  0.032151252 Validation Decoder Loss:  0.33938694
Encoder Loss:  0.03655675  || Decoder Loss:  0.03215606 Validation Decoder Loss:  0.339337
Encoder Loss:  0.0365312  || Decoder Loss:  0.032163072 Validation Decoder Loss:  0.3393054
Encoder Loss:  0.036572564  || Decoder Loss:  0.032174014 Validation Decoder Loss:  0.33925414
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.00024292810117166263 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33925414
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 220, 11, 20, 1)    218       
_________________________________________________________________
reshape_5 (Reshape)          (None, 2420, 20, 1)       0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3682807  || Decoder Loss:  0.0409091 Validation Decoder Loss:  0.347089
Encoder Loss:  0.3673043  || Decoder Loss:  0.041321333 Validation Decoder Loss:  0.34737712
Encoder Loss:  0.3654509  || Decoder Loss:  0.04206805 Validation Decoder Loss:  0.3487128
Encoder Loss:  0.3605826  || Decoder Loss:  0.043799587 Validation Decoder Loss:  0.35275352
Encoder Loss:  0.3256629  || Decoder Loss:  0.050732926 Validation Decoder Loss:  0.36472148
Encoder Loss:  0.09531372  || Decoder Loss:  0.046904158 Validation Decoder Loss:  0.33294773
Encoder Loss:  0.08242315  || Decoder Loss:  0.039531685 Validation Decoder Loss:  0.33151257
Encoder Loss:  0.08179943  || Decoder Loss:  0.037826136 Validation Decoder Loss:  0.3309632
Encoder Loss:  0.081188336  || Decoder Loss:  0.03691515 Validation Decoder Loss:  0.33080345
Encoder Loss:  0.080532335  || Decoder Loss:  0.036389604 Validation Decoder Loss:  0.33075577
Encoder Loss:  0.08008913  || Decoder Loss:  0.036057945 Validation Decoder Loss:  0.33073437
Encoder Loss:  0.07953799  || Decoder Loss:  0.03582517 Validation Decoder Loss:  0.3307078
Encoder Loss:  0.0789004  || Decoder Loss:  0.03564619 Validation Decoder Loss:  0.3306787
Encoder Loss:  0.0780398  || Decoder Loss:  0.035503425 Validation Decoder Loss:  0.33064052
Encoder Loss:  0.07570292  || Decoder Loss:  0.03538823 Validation Decoder Loss:  0.33062077
Encoder Loss:  0.056869354  || Decoder Loss:  0.035292048 Validation Decoder Loss:  0.33072454
Encoder Loss:  0.053984936  || Decoder Loss:  0.03522739 Validation Decoder Loss:  0.33070877
Encoder Loss:  0.0535191  || Decoder Loss:  0.035174202 Validation Decoder Loss:  0.33074456
Encoder Loss:  0.05326082  || Decoder Loss:  0.03512965 Validation Decoder Loss:  0.33078998
Encoder Loss:  0.053038973  || Decoder Loss:  0.035096154 Validation Decoder Loss:  0.33083737
Encoder Loss:  0.052699707  || Decoder Loss:  0.03506965 Validation Decoder Loss:  0.33090177
Encoder Loss:  0.052500736  || Decoder Loss:  0.035050496 Validation Decoder Loss:  0.33094966
Encoder Loss:  0.052340202  || Decoder Loss:  0.035036467 Validation Decoder Loss:  0.33100027
Encoder Loss:  0.05215786  || Decoder Loss:  0.03502597 Validation Decoder Loss:  0.3310485
Encoder Loss:  0.051999852  || Decoder Loss:  0.03501791 Validation Decoder Loss:  0.33109426
Encoder Loss:  0.051851172  || Decoder Loss:  0.03501152 Validation Decoder Loss:  0.3311374
Encoder Loss:  0.051720146  || Decoder Loss:  0.035006143 Validation Decoder Loss:  0.33118385
Encoder Loss:  0.051588397  || Decoder Loss:  0.035001315 Validation Decoder Loss:  0.3312288
Encoder Loss:  0.05144084  || Decoder Loss:  0.034996748 Validation Decoder Loss:  0.3312762
Encoder Loss:  0.051307395  || Decoder Loss:  0.034992106 Validation Decoder Loss:  0.33132517
Encoder Loss:  0.051146455  || Decoder Loss:  0.034987282 Validation Decoder Loss:  0.33137876
Encoder Loss:  0.05098693  || Decoder Loss:  0.03498197 Validation Decoder Loss:  0.33143657
Encoder Loss:  0.050810523  || Decoder Loss:  0.034976035 Validation Decoder Loss:  0.33149606
Encoder Loss:  0.0506452  || Decoder Loss:  0.03496947 Validation Decoder Loss:  0.3315571
Encoder Loss:  0.050405353  || Decoder Loss:  0.034961864 Validation Decoder Loss:  0.33162364
Encoder Loss:  0.05029477  || Decoder Loss:  0.034953386 Validation Decoder Loss:  0.3316885
Encoder Loss:  0.050003704  || Decoder Loss:  0.034943838 Validation Decoder Loss:  0.33176345
Encoder Loss:  0.04978262  || Decoder Loss:  0.03493248 Validation Decoder Loss:  0.33184385
Encoder Loss:  0.04959075  || Decoder Loss:  0.034920175 Validation Decoder Loss:  0.33192694
Encoder Loss:  0.04938229  || Decoder Loss:  0.03490685 Validation Decoder Loss:  0.33201402
Model: siamese_net_lr_0.0005311086830074881 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.332014
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 126, 20, 20, 1)    1009      
_________________________________________________________________
reshape_6 (Reshape)          (None, 2520, 20, 1)       0         
=================================================================
Total params: 1,009
Trainable params: 1,009
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19238555  || Decoder Loss:  0.049160264 Validation Decoder Loss:  0.3301104
Encoder Loss:  0.19203688  || Decoder Loss:  0.0527057 Validation Decoder Loss:  0.33172467
Encoder Loss:  0.19099101  || Decoder Loss:  0.056866165 Validation Decoder Loss:  0.3340478
Encoder Loss:  0.18820672  || Decoder Loss:  0.060986236 Validation Decoder Loss:  0.33537963
Encoder Loss:  0.17104417  || Decoder Loss:  0.046480343 Validation Decoder Loss:  0.3377368
Encoder Loss:  0.15115692  || Decoder Loss:  0.034913026 Validation Decoder Loss:  0.33540156
Encoder Loss:  0.13012086  || Decoder Loss:  0.034735966 Validation Decoder Loss:  0.33281606
Encoder Loss:  0.09224152  || Decoder Loss:  0.034891058 Validation Decoder Loss:  0.32910615
Encoder Loss:  0.051318645  || Decoder Loss:  0.03516677 Validation Decoder Loss:  0.32826903
Encoder Loss:  0.050392218  || Decoder Loss:  0.035090797 Validation Decoder Loss:  0.32836154
Encoder Loss:  0.050218172  || Decoder Loss:  0.035035063 Validation Decoder Loss:  0.3284388
Encoder Loss:  0.050073963  || Decoder Loss:  0.034999475 Validation Decoder Loss:  0.32850474
Encoder Loss:  0.04992081  || Decoder Loss:  0.034975033 Validation Decoder Loss:  0.32855555
Encoder Loss:  0.04977346  || Decoder Loss:  0.034957558 Validation Decoder Loss:  0.32859617
Encoder Loss:  0.04960425  || Decoder Loss:  0.034944378 Validation Decoder Loss:  0.32862592
Encoder Loss:  0.04940546  || Decoder Loss:  0.034933895 Validation Decoder Loss:  0.32864642
Encoder Loss:  0.049138065  || Decoder Loss:  0.034924943 Validation Decoder Loss:  0.32865885
Encoder Loss:  0.048619226  || Decoder Loss:  0.034916744 Validation Decoder Loss:  0.3286692
Encoder Loss:  0.045937236  || Decoder Loss:  0.034907334 Validation Decoder Loss:  0.32873186
Encoder Loss:  0.04258604  || Decoder Loss:  0.034931548 Validation Decoder Loss:  0.3288773
Encoder Loss:  0.04233576  || Decoder Loss:  0.034961823 Validation Decoder Loss:  0.32891953
Encoder Loss:  0.042272434  || Decoder Loss:  0.034972988 Validation Decoder Loss:  0.32894015
Encoder Loss:  0.042230096  || Decoder Loss:  0.034979485 Validation Decoder Loss:  0.32896248
Encoder Loss:  0.042189255  || Decoder Loss:  0.03498591 Validation Decoder Loss:  0.3289975
Encoder Loss:  0.042137254  || Decoder Loss:  0.03499207 Validation Decoder Loss:  0.3290484
Encoder Loss:  0.042085372  || Decoder Loss:  0.03499682 Validation Decoder Loss:  0.32911256
Encoder Loss:  0.04202565  || Decoder Loss:  0.034998998 Validation Decoder Loss:  0.32920894
Encoder Loss:  0.041959886  || Decoder Loss:  0.03499599 Validation Decoder Loss:  0.3293141
Encoder Loss:  0.041885953  || Decoder Loss:  0.0349854 Validation Decoder Loss:  0.32943785
Encoder Loss:  0.04180411  || Decoder Loss:  0.034965873 Validation Decoder Loss:  0.3295547
Encoder Loss:  0.041715637  || Decoder Loss:  0.034938324 Validation Decoder Loss:  0.32966158
Encoder Loss:  0.04162551  || Decoder Loss:  0.034907706 Validation Decoder Loss:  0.32974404
Encoder Loss:  0.04153449  || Decoder Loss:  0.03488026 Validation Decoder Loss:  0.32981032
Encoder Loss:  0.041432485  || Decoder Loss:  0.034852825 Validation Decoder Loss:  0.32985538
Encoder Loss:  0.041349396  || Decoder Loss:  0.0348264 Validation Decoder Loss:  0.3298812
Encoder Loss:  0.0412551  || Decoder Loss:  0.03480274 Validation Decoder Loss:  0.32989538
Encoder Loss:  0.04116025  || Decoder Loss:  0.03478205 Validation Decoder Loss:  0.32991594
Encoder Loss:  0.041088387  || Decoder Loss:  0.03477407 Validation Decoder Loss:  0.32994092
Encoder Loss:  0.041052323  || Decoder Loss:  0.034770872 Validation Decoder Loss:  0.3299377
Encoder Loss:  0.041004848  || Decoder Loss:  0.034770254 Validation Decoder Loss:  0.32993513
Model: siamese_net_lr_0.00015499587019704198 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32993513
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 84, 30, 20, 1)     547       
_________________________________________________________________
reshape_7 (Reshape)          (None, 2520, 20, 1)       0         
=================================================================
Total params: 547
Trainable params: 547
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19057444  || Decoder Loss:  0.040132478 Validation Decoder Loss:  0.33542
Encoder Loss:  0.1901214  || Decoder Loss:  0.04138708 Validation Decoder Loss:  0.33664596
Encoder Loss:  0.18898419  || Decoder Loss:  0.043346986 Validation Decoder Loss:  0.3389849
Encoder Loss:  0.18593101  || Decoder Loss:  0.046664488 Validation Decoder Loss:  0.34327435
Encoder Loss:  0.1744657  || Decoder Loss:  0.049848773 Validation Decoder Loss:  0.3394453
Encoder Loss:  0.1197376  || Decoder Loss:  0.037304506 Validation Decoder Loss:  0.3299129
Encoder Loss:  0.054239873  || Decoder Loss:  0.03586673 Validation Decoder Loss:  0.3296739
Encoder Loss:  0.054001223  || Decoder Loss:  0.03552011 Validation Decoder Loss:  0.32982907
Encoder Loss:  0.053666223  || Decoder Loss:  0.03531223 Validation Decoder Loss:  0.32998413
Encoder Loss:  0.053436734  || Decoder Loss:  0.035194155 Validation Decoder Loss:  0.33011994
Encoder Loss:  0.053246137  || Decoder Loss:  0.03512983 Validation Decoder Loss:  0.33022836
Encoder Loss:  0.053076986  || Decoder Loss:  0.03509615 Validation Decoder Loss:  0.33031064
Encoder Loss:  0.052898508  || Decoder Loss:  0.035079025 Validation Decoder Loss:  0.33036968
Encoder Loss:  0.052735146  || Decoder Loss:  0.035070285 Validation Decoder Loss:  0.330411
Encoder Loss:  0.05256132  || Decoder Loss:  0.035065815 Validation Decoder Loss:  0.33043933
Encoder Loss:  0.052389167  || Decoder Loss:  0.035063498 Validation Decoder Loss:  0.33045986
Encoder Loss:  0.052185778  || Decoder Loss:  0.035062242 Validation Decoder Loss:  0.33047542
Encoder Loss:  0.051907733  || Decoder Loss:  0.03506166 Validation Decoder Loss:  0.33048475
Encoder Loss:  0.05148385  || Decoder Loss:  0.035061494 Validation Decoder Loss:  0.33049247
Encoder Loss:  0.04978839  || Decoder Loss:  0.035061546 Validation Decoder Loss:  0.33049607
Encoder Loss:  0.042818956  || Decoder Loss:  0.035059936 Validation Decoder Loss:  0.3305602
Encoder Loss:  0.042227287  || Decoder Loss:  0.035048857 Validation Decoder Loss:  0.33053613
Encoder Loss:  0.042020332  || Decoder Loss:  0.03503595 Validation Decoder Loss:  0.33051682
Encoder Loss:  0.041884307  || Decoder Loss:  0.03502291 Validation Decoder Loss:  0.33051363
Encoder Loss:  0.041822813  || Decoder Loss:  0.035013553 Validation Decoder Loss:  0.33053356
Encoder Loss:  0.04176284  || Decoder Loss:  0.03500736 Validation Decoder Loss:  0.33057058
Encoder Loss:  0.041706763  || Decoder Loss:  0.03500221 Validation Decoder Loss:  0.33061725
Encoder Loss:  0.041636575  || Decoder Loss:  0.03499489 Validation Decoder Loss:  0.33066845
Encoder Loss:  0.041569825  || Decoder Loss:  0.034988098 Validation Decoder Loss:  0.33072096
Encoder Loss:  0.041489005  || Decoder Loss:  0.03498173 Validation Decoder Loss:  0.33078045
Encoder Loss:  0.041426215  || Decoder Loss:  0.034976758 Validation Decoder Loss:  0.33083746
Encoder Loss:  0.04136248  || Decoder Loss:  0.03497264 Validation Decoder Loss:  0.33089703
Encoder Loss:  0.04130571  || Decoder Loss:  0.034968317 Validation Decoder Loss:  0.33094978
Encoder Loss:  0.041234087  || Decoder Loss:  0.034964755 Validation Decoder Loss:  0.3310024
Encoder Loss:  0.0411541  || Decoder Loss:  0.03496388 Validation Decoder Loss:  0.33105522
Encoder Loss:  0.041070856  || Decoder Loss:  0.03496599 Validation Decoder Loss:  0.33110878
Encoder Loss:  0.041009925  || Decoder Loss:  0.034968227 Validation Decoder Loss:  0.33115637
Encoder Loss:  0.040930286  || Decoder Loss:  0.034971975 Validation Decoder Loss:  0.33118543
Encoder Loss:  0.040864147  || Decoder Loss:  0.034976818 Validation Decoder Loss:  0.33119598
Encoder Loss:  0.040832534  || Decoder Loss:  0.034982037 Validation Decoder Loss:  0.3311808
Model: siamese_net_lr_0.00016016934594360188 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3311808
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 140, 18, 20, 1)    771       
_________________________________________________________________
reshape_8 (Reshape)          (None, 2520, 20, 1)       0         
=================================================================
Total params: 771
Trainable params: 771
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14025223  || Decoder Loss:  0.0453246 Validation Decoder Loss:  0.3281111
Encoder Loss:  0.14117602  || Decoder Loss:  0.04776429 Validation Decoder Loss:  0.32745484
Encoder Loss:  0.14229183  || Decoder Loss:  0.050713867 Validation Decoder Loss:  0.3271915
Encoder Loss:  0.14360389  || Decoder Loss:  0.054259367 Validation Decoder Loss:  0.32744592
Encoder Loss:  0.14498983  || Decoder Loss:  0.058338765 Validation Decoder Loss:  0.32809246
Encoder Loss:  0.14574026  || Decoder Loss:  0.062153295 Validation Decoder Loss:  0.32769927
Encoder Loss:  0.13772528  || Decoder Loss:  0.05515912 Validation Decoder Loss:  0.33026713
Encoder Loss:  0.119086705  || Decoder Loss:  0.035243765 Validation Decoder Loss:  0.33038718
Encoder Loss:  0.114049  || Decoder Loss:  0.035059057 Validation Decoder Loss:  0.33057734
Encoder Loss:  0.10685067  || Decoder Loss:  0.034977876 Validation Decoder Loss:  0.33037814
Encoder Loss:  0.09516341  || Decoder Loss:  0.035038475 Validation Decoder Loss:  0.329602
Encoder Loss:  0.07294051  || Decoder Loss:  0.035273448 Validation Decoder Loss:  0.32855695
Encoder Loss:  0.048269033  || Decoder Loss:  0.03546059 Validation Decoder Loss:  0.3284199
Encoder Loss:  0.047689587  || Decoder Loss:  0.03537488 Validation Decoder Loss:  0.32856792
Encoder Loss:  0.047601685  || Decoder Loss:  0.035299066 Validation Decoder Loss:  0.32869503
Encoder Loss:  0.047524646  || Decoder Loss:  0.035243567 Validation Decoder Loss:  0.3288039
Encoder Loss:  0.047460347  || Decoder Loss:  0.035202768 Validation Decoder Loss:  0.32889596
Encoder Loss:  0.047396705  || Decoder Loss:  0.03517244 Validation Decoder Loss:  0.32897076
Encoder Loss:  0.04733377  || Decoder Loss:  0.03514946 Validation Decoder Loss:  0.3290294
Encoder Loss:  0.047266725  || Decoder Loss:  0.035131577 Validation Decoder Loss:  0.32907385
Encoder Loss:  0.047186445  || Decoder Loss:  0.03511718 Validation Decoder Loss:  0.32910633
Encoder Loss:  0.047081232  || Decoder Loss:  0.035105146 Validation Decoder Loss:  0.32913
Encoder Loss:  0.046895675  || Decoder Loss:  0.035094816 Validation Decoder Loss:  0.3291464
Encoder Loss:  0.046433564  || Decoder Loss:  0.035085708 Validation Decoder Loss:  0.32916027
Encoder Loss:  0.043540712  || Decoder Loss:  0.03507689 Validation Decoder Loss:  0.32919815
Encoder Loss:  0.039539598  || Decoder Loss:  0.03507881 Validation Decoder Loss:  0.32920688
Encoder Loss:  0.039392125  || Decoder Loss:  0.035089117 Validation Decoder Loss:  0.3292429
Encoder Loss:  0.0392561  || Decoder Loss:  0.035097703 Validation Decoder Loss:  0.32929346
Encoder Loss:  0.039179817  || Decoder Loss:  0.035099007 Validation Decoder Loss:  0.32934332
Encoder Loss:  0.03915088  || Decoder Loss:  0.035095643 Validation Decoder Loss:  0.32937813
Encoder Loss:  0.039124757  || Decoder Loss:  0.035094324 Validation Decoder Loss:  0.3294009
Encoder Loss:  0.039103854  || Decoder Loss:  0.035095625 Validation Decoder Loss:  0.3294169
Encoder Loss:  0.039081987  || Decoder Loss:  0.03509916 Validation Decoder Loss:  0.32942885
Encoder Loss:  0.039062727  || Decoder Loss:  0.035104234 Validation Decoder Loss:  0.32943964
Encoder Loss:  0.039034285  || Decoder Loss:  0.035110064 Validation Decoder Loss:  0.32945448
Encoder Loss:  0.03901268  || Decoder Loss:  0.035115186 Validation Decoder Loss:  0.32947153
Encoder Loss:  0.03897618  || Decoder Loss:  0.035118554 Validation Decoder Loss:  0.3294998
Encoder Loss:  0.038947422  || Decoder Loss:  0.035118796 Validation Decoder Loss:  0.32953405
Encoder Loss:  0.038914043  || Decoder Loss:  0.03511532 Validation Decoder Loss:  0.32957533
Encoder Loss:  0.03888993  || Decoder Loss:  0.03510885 Validation Decoder Loss:  0.32961476
Model: siamese_net_lr_0.00011209233998673577 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32961476
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 504, 5, 20, 1)     253       
_________________________________________________________________
reshape_9 (Reshape)          (None, 2520, 20, 1)       0         
=================================================================
Total params: 253
Trainable params: 253
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.03827031  || Decoder Loss:  0.03827031 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270295  || Decoder Loss:  0.038270295 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270306  || Decoder Loss:  0.038270306 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.038270302  || Decoder Loss:  0.038270302 Validation Decoder Loss:  0.32995188
Encoder Loss:  0.0382703  || Decoder Loss:  0.0382703 Validation Decoder Loss:  0.32995188
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32995188
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 168, 15, 20, 1)    463       
_________________________________________________________________
reshape_10 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 463
Trainable params: 463
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011255  || Decoder Loss:  0.039011255 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.03901126  || Decoder Loss:  0.03901126 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011266  || Decoder Loss:  0.039011266 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451247
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Encoder Loss:  0.039011262  || Decoder Loss:  0.039011262 Validation Decoder Loss:  0.33451244
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33451247
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 504, 5, 20, 1)     190       
_________________________________________________________________
reshape_11 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 190
Trainable params: 190
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037561107  || Decoder Loss:  0.037561107 Validation Decoder Loss:  0.33112574
Encoder Loss:  0.037552822  || Decoder Loss:  0.037552822 Validation Decoder Loss:  0.3311178
Encoder Loss:  0.037545085  || Decoder Loss:  0.037545085 Validation Decoder Loss:  0.33111042
Encoder Loss:  0.03753774  || Decoder Loss:  0.03753774 Validation Decoder Loss:  0.33110335
Encoder Loss:  0.03753066  || Decoder Loss:  0.03753066 Validation Decoder Loss:  0.3310966
Encoder Loss:  0.037523802  || Decoder Loss:  0.037523802 Validation Decoder Loss:  0.33109
Encoder Loss:  0.03751704  || Decoder Loss:  0.03751704 Validation Decoder Loss:  0.33108357
Encoder Loss:  0.03751039  || Decoder Loss:  0.03751039 Validation Decoder Loss:  0.3310772
Encoder Loss:  0.037503775  || Decoder Loss:  0.037503775 Validation Decoder Loss:  0.33107084
Encoder Loss:  0.037497234  || Decoder Loss:  0.037497234 Validation Decoder Loss:  0.33106464
Encoder Loss:  0.03749067  || Decoder Loss:  0.03749067 Validation Decoder Loss:  0.33105838
Encoder Loss:  0.037484128  || Decoder Loss:  0.037484128 Validation Decoder Loss:  0.33105218
Encoder Loss:  0.037477612  || Decoder Loss:  0.037477612 Validation Decoder Loss:  0.33104602
Encoder Loss:  0.037471067  || Decoder Loss:  0.037471067 Validation Decoder Loss:  0.33103985
Encoder Loss:  0.037464514  || Decoder Loss:  0.037464514 Validation Decoder Loss:  0.33103374
Encoder Loss:  0.037458  || Decoder Loss:  0.037458 Validation Decoder Loss:  0.3310276
Encoder Loss:  0.037451435  || Decoder Loss:  0.037451435 Validation Decoder Loss:  0.33102146
Encoder Loss:  0.037444867  || Decoder Loss:  0.037444867 Validation Decoder Loss:  0.33101535
Encoder Loss:  0.03743832  || Decoder Loss:  0.03743832 Validation Decoder Loss:  0.33100927
Encoder Loss:  0.03743171  || Decoder Loss:  0.03743171 Validation Decoder Loss:  0.33100316
Encoder Loss:  0.037425146  || Decoder Loss:  0.037425146 Validation Decoder Loss:  0.33099708
Encoder Loss:  0.03741853  || Decoder Loss:  0.03741853 Validation Decoder Loss:  0.33099103
Encoder Loss:  0.037411932  || Decoder Loss:  0.037411932 Validation Decoder Loss:  0.33098498
Encoder Loss:  0.037405282  || Decoder Loss:  0.037405282 Validation Decoder Loss:  0.33097893
Encoder Loss:  0.037398666  || Decoder Loss:  0.037398666 Validation Decoder Loss:  0.33097294
Encoder Loss:  0.03739197  || Decoder Loss:  0.03739197 Validation Decoder Loss:  0.3309669
Encoder Loss:  0.037385337  || Decoder Loss:  0.037385337 Validation Decoder Loss:  0.33096087
Encoder Loss:  0.037378646  || Decoder Loss:  0.037378646 Validation Decoder Loss:  0.33095488
Encoder Loss:  0.03737195  || Decoder Loss:  0.03737195 Validation Decoder Loss:  0.3309489
Encoder Loss:  0.03736521  || Decoder Loss:  0.03736521 Validation Decoder Loss:  0.3309429
Encoder Loss:  0.037358467  || Decoder Loss:  0.037358467 Validation Decoder Loss:  0.33093694
Encoder Loss:  0.037351716  || Decoder Loss:  0.037351716 Validation Decoder Loss:  0.33093095
Encoder Loss:  0.037344955  || Decoder Loss:  0.037344955 Validation Decoder Loss:  0.33092502
Encoder Loss:  0.03733818  || Decoder Loss:  0.03733818 Validation Decoder Loss:  0.3309191
Encoder Loss:  0.037331343  || Decoder Loss:  0.037331343 Validation Decoder Loss:  0.33091313
Encoder Loss:  0.037324537  || Decoder Loss:  0.037324537 Validation Decoder Loss:  0.3309072
Encoder Loss:  0.037317716  || Decoder Loss:  0.037317716 Validation Decoder Loss:  0.33090127
Encoder Loss:  0.037310828  || Decoder Loss:  0.037310828 Validation Decoder Loss:  0.33089536
Encoder Loss:  0.03730397  || Decoder Loss:  0.03730397 Validation Decoder Loss:  0.33088946
Encoder Loss:  0.037297063  || Decoder Loss:  0.037297063 Validation Decoder Loss:  0.33088356
Model: siamese_net_lr_1.1561574120209244e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33088356
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 72, 35, 20, 1)     64        
_________________________________________________________________
reshape_12 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777593  || Decoder Loss:  0.036777593 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777593  || Decoder Loss:  0.036777593 Validation Decoder Loss:  0.33528358
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777608  || Decoder Loss:  0.036777608 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777593  || Decoder Loss:  0.036777593 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777608  || Decoder Loss:  0.036777608 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.03677761  || Decoder Loss:  0.03677761 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.03677759  || Decoder Loss:  0.03677759 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777608  || Decoder Loss:  0.036777608 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.036777608  || Decoder Loss:  0.036777608 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528355
Encoder Loss:  0.0367776  || Decoder Loss:  0.0367776 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Encoder Loss:  0.036777604  || Decoder Loss:  0.036777604 Validation Decoder Loss:  0.33528352
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33528352
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 242, 10, 20, 1)    319       
_________________________________________________________________
reshape_13 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 319
Trainable params: 319
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33720523  || Decoder Loss:  0.042703032 Validation Decoder Loss:  0.34646678
Encoder Loss:  0.3281139  || Decoder Loss:  0.04809113 Validation Decoder Loss:  0.35911894
Encoder Loss:  0.1462649  || Decoder Loss:  0.045708843 Validation Decoder Loss:  0.3297751
Encoder Loss:  0.07847407  || Decoder Loss:  0.036427032 Validation Decoder Loss:  0.32914227
Encoder Loss:  0.07759031  || Decoder Loss:  0.035408847 Validation Decoder Loss:  0.3293143
Encoder Loss:  0.076275796  || Decoder Loss:  0.0350635 Validation Decoder Loss:  0.32938373
Encoder Loss:  0.057356693  || Decoder Loss:  0.03488585 Validation Decoder Loss:  0.32966888
Encoder Loss:  0.04971032  || Decoder Loss:  0.03479192 Validation Decoder Loss:  0.3298421
Encoder Loss:  0.04954684  || Decoder Loss:  0.034746185 Validation Decoder Loss:  0.32996085
Encoder Loss:  0.049209155  || Decoder Loss:  0.03472105 Validation Decoder Loss:  0.33007663
Encoder Loss:  0.04910743  || Decoder Loss:  0.034705773 Validation Decoder Loss:  0.3301686
Encoder Loss:  0.048913375  || Decoder Loss:  0.03469579 Validation Decoder Loss:  0.33026698
Encoder Loss:  0.048767738  || Decoder Loss:  0.034689564 Validation Decoder Loss:  0.33036512
Encoder Loss:  0.048622366  || Decoder Loss:  0.034682844 Validation Decoder Loss:  0.33046573
Encoder Loss:  0.04851282  || Decoder Loss:  0.034675807 Validation Decoder Loss:  0.33054745
Encoder Loss:  0.048379943  || Decoder Loss:  0.03466563 Validation Decoder Loss:  0.33064437
Encoder Loss:  0.048237294  || Decoder Loss:  0.03465595 Validation Decoder Loss:  0.33071968
Encoder Loss:  0.048172306  || Decoder Loss:  0.034643497 Validation Decoder Loss:  0.33074635
Encoder Loss:  0.048105072  || Decoder Loss:  0.034629732 Validation Decoder Loss:  0.33073783
Encoder Loss:  0.047972642  || Decoder Loss:  0.034615885 Validation Decoder Loss:  0.33074915
Encoder Loss:  0.047855042  || Decoder Loss:  0.034601998 Validation Decoder Loss:  0.33074886
Encoder Loss:  0.047739636  || Decoder Loss:  0.0345865 Validation Decoder Loss:  0.3307212
Encoder Loss:  0.04768364  || Decoder Loss:  0.03457203 Validation Decoder Loss:  0.33065644
Encoder Loss:  0.04755422  || Decoder Loss:  0.034556147 Validation Decoder Loss:  0.33069187
Encoder Loss:  0.04741258  || Decoder Loss:  0.03454108 Validation Decoder Loss:  0.33073404
Encoder Loss:  0.047274638  || Decoder Loss:  0.03453136 Validation Decoder Loss:  0.33073455
Encoder Loss:  0.047282606  || Decoder Loss:  0.034519255 Validation Decoder Loss:  0.33073542
Encoder Loss:  0.04723368  || Decoder Loss:  0.034510624 Validation Decoder Loss:  0.3306457
Encoder Loss:  0.047081962  || Decoder Loss:  0.034505084 Validation Decoder Loss:  0.33062893
Encoder Loss:  0.04699836  || Decoder Loss:  0.034493405 Validation Decoder Loss:  0.33069238
Encoder Loss:  0.047121044  || Decoder Loss:  0.03448527 Validation Decoder Loss:  0.33059812
Encoder Loss:  0.046787262  || Decoder Loss:  0.03447814 Validation Decoder Loss:  0.33075193
Encoder Loss:  0.046827555  || Decoder Loss:  0.034466267 Validation Decoder Loss:  0.3307963
Encoder Loss:  0.046734057  || Decoder Loss:  0.03445884 Validation Decoder Loss:  0.33084708
Encoder Loss:  0.046751563  || Decoder Loss:  0.034455948 Validation Decoder Loss:  0.33085006
Encoder Loss:  0.046681903  || Decoder Loss:  0.03445485 Validation Decoder Loss:  0.33090985
Encoder Loss:  0.046635922  || Decoder Loss:  0.03445401 Validation Decoder Loss:  0.33097273
Encoder Loss:  0.046633326  || Decoder Loss:  0.034455243 Validation Decoder Loss:  0.3310092
Encoder Loss:  0.04667245  || Decoder Loss:  0.034461632 Validation Decoder Loss:  0.33091795
Encoder Loss:  0.046614546  || Decoder Loss:  0.03446769 Validation Decoder Loss:  0.3310029
Model: siamese_net_lr_0.0006273711536438114 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3310029
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 220, 11, 20, 1)    283       
_________________________________________________________________
reshape_14 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3037552  || Decoder Loss:  0.043664128 Validation Decoder Loss:  0.33717382
Encoder Loss:  0.28946868  || Decoder Loss:  0.05109945 Validation Decoder Loss:  0.3419805
Encoder Loss:  0.10920948  || Decoder Loss:  0.044641394 Validation Decoder Loss:  0.33073616
Encoder Loss:  0.06371618  || Decoder Loss:  0.036402427 Validation Decoder Loss:  0.32964048
Encoder Loss:  0.06313201  || Decoder Loss:  0.03567611 Validation Decoder Loss:  0.32928202
Encoder Loss:  0.06267433  || Decoder Loss:  0.035372972 Validation Decoder Loss:  0.32912403
Encoder Loss:  0.062234703  || Decoder Loss:  0.035231654 Validation Decoder Loss:  0.32899997
Encoder Loss:  0.061836425  || Decoder Loss:  0.035152312 Validation Decoder Loss:  0.32889098
Encoder Loss:  0.061342016  || Decoder Loss:  0.035097282 Validation Decoder Loss:  0.32880583
Encoder Loss:  0.059867315  || Decoder Loss:  0.035052918 Validation Decoder Loss:  0.32870138
Encoder Loss:  0.047794234  || Decoder Loss:  0.035025477 Validation Decoder Loss:  0.3287813
Encoder Loss:  0.046837274  || Decoder Loss:  0.035022385 Validation Decoder Loss:  0.32878038
Encoder Loss:  0.046759006  || Decoder Loss:  0.035023317 Validation Decoder Loss:  0.32884544
Encoder Loss:  0.046647206  || Decoder Loss:  0.03503094 Validation Decoder Loss:  0.3289334
Encoder Loss:  0.04657601  || Decoder Loss:  0.03504219 Validation Decoder Loss:  0.32904357
Encoder Loss:  0.04648848  || Decoder Loss:  0.035053954 Validation Decoder Loss:  0.32917762
Encoder Loss:  0.04643227  || Decoder Loss:  0.035062004 Validation Decoder Loss:  0.32931533
Encoder Loss:  0.046330344  || Decoder Loss:  0.0350641 Validation Decoder Loss:  0.32948488
Encoder Loss:  0.046253018  || Decoder Loss:  0.035055812 Validation Decoder Loss:  0.3296353
Encoder Loss:  0.046195388  || Decoder Loss:  0.035034385 Validation Decoder Loss:  0.3297422
Encoder Loss:  0.046092805  || Decoder Loss:  0.034999963 Validation Decoder Loss:  0.3298114
Encoder Loss:  0.045938287  || Decoder Loss:  0.03495349 Validation Decoder Loss:  0.32983202
Encoder Loss:  0.045845218  || Decoder Loss:  0.03489967 Validation Decoder Loss:  0.3297755
Encoder Loss:  0.045681577  || Decoder Loss:  0.03484188 Validation Decoder Loss:  0.3296944
Encoder Loss:  0.04555274  || Decoder Loss:  0.034784656 Validation Decoder Loss:  0.32953957
Encoder Loss:  0.045425273  || Decoder Loss:  0.0347351 Validation Decoder Loss:  0.32932982
Encoder Loss:  0.04525689  || Decoder Loss:  0.03469404 Validation Decoder Loss:  0.32920498
Encoder Loss:  0.04512156  || Decoder Loss:  0.03466301 Validation Decoder Loss:  0.3291812
Encoder Loss:  0.045098167  || Decoder Loss:  0.034651063 Validation Decoder Loss:  0.32885468
Encoder Loss:  0.04501874  || Decoder Loss:  0.03464917 Validation Decoder Loss:  0.32876444
Encoder Loss:  0.044946052  || Decoder Loss:  0.034653846 Validation Decoder Loss:  0.3288565
Encoder Loss:  0.04491638  || Decoder Loss:  0.034662846 Validation Decoder Loss:  0.32885274
Encoder Loss:  0.04490631  || Decoder Loss:  0.03468113 Validation Decoder Loss:  0.3288894
Encoder Loss:  0.04492749  || Decoder Loss:  0.03470022 Validation Decoder Loss:  0.32879826
Encoder Loss:  0.04490356  || Decoder Loss:  0.03471932 Validation Decoder Loss:  0.3288324
Encoder Loss:  0.044901982  || Decoder Loss:  0.03473853 Validation Decoder Loss:  0.32886422
Encoder Loss:  0.044908393  || Decoder Loss:  0.034755792 Validation Decoder Loss:  0.32885987
Encoder Loss:  0.044913106  || Decoder Loss:  0.03477381 Validation Decoder Loss:  0.32877678
Encoder Loss:  0.044905547  || Decoder Loss:  0.034787476 Validation Decoder Loss:  0.3288636
Encoder Loss:  0.044916447  || Decoder Loss:  0.034804653 Validation Decoder Loss:  0.3287441
Model: siamese_net_lr_0.0003084384378421522 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3287441
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 220, 11, 20, 1)    472       
_________________________________________________________________
reshape_15 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 472
Trainable params: 472
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.303323  || Decoder Loss:  0.045749377 Validation Decoder Loss:  0.33671913
Encoder Loss:  0.28476188  || Decoder Loss:  0.055875383 Validation Decoder Loss:  0.33167517
Encoder Loss:  0.120732285  || Decoder Loss:  0.041168146 Validation Decoder Loss:  0.33064246
Encoder Loss:  0.061652675  || Decoder Loss:  0.03609042 Validation Decoder Loss:  0.32966438
Encoder Loss:  0.06103437  || Decoder Loss:  0.035387326 Validation Decoder Loss:  0.32941848
Encoder Loss:  0.060506776  || Decoder Loss:  0.0351536 Validation Decoder Loss:  0.32926428
Encoder Loss:  0.060094886  || Decoder Loss:  0.035038065 Validation Decoder Loss:  0.3291464
Encoder Loss:  0.059561577  || Decoder Loss:  0.034962308 Validation Decoder Loss:  0.32906273
Encoder Loss:  0.05882364  || Decoder Loss:  0.03490531 Validation Decoder Loss:  0.32901898
Encoder Loss:  0.050793637  || Decoder Loss:  0.034864165 Validation Decoder Loss:  0.329024
Encoder Loss:  0.04678192  || Decoder Loss:  0.034863304 Validation Decoder Loss:  0.32908192
Encoder Loss:  0.046645332  || Decoder Loss:  0.03488471 Validation Decoder Loss:  0.32920215
Encoder Loss:  0.046542883  || Decoder Loss:  0.034915347 Validation Decoder Loss:  0.32937834
Encoder Loss:  0.04643755  || Decoder Loss:  0.03494892 Validation Decoder Loss:  0.32960933
Encoder Loss:  0.046342418  || Decoder Loss:  0.03497659 Validation Decoder Loss:  0.3299027
Encoder Loss:  0.046232253  || Decoder Loss:  0.034986086 Validation Decoder Loss:  0.33024687
Encoder Loss:  0.046104427  || Decoder Loss:  0.03496416 Validation Decoder Loss:  0.33059567
Encoder Loss:  0.045948185  || Decoder Loss:  0.034905106 Validation Decoder Loss:  0.3308832
Encoder Loss:  0.045799345  || Decoder Loss:  0.034814507 Validation Decoder Loss:  0.33102053
Encoder Loss:  0.045568597  || Decoder Loss:  0.034703292 Validation Decoder Loss:  0.33102378
Encoder Loss:  0.045350228  || Decoder Loss:  0.034585495 Validation Decoder Loss:  0.33093882
Encoder Loss:  0.045113616  || Decoder Loss:  0.03446363 Validation Decoder Loss:  0.33080727
Encoder Loss:  0.045012757  || Decoder Loss:  0.03436606 Validation Decoder Loss:  0.3307171
Encoder Loss:  0.044877324  || Decoder Loss:  0.034303725 Validation Decoder Loss:  0.330674
Encoder Loss:  0.04485501  || Decoder Loss:  0.034276456 Validation Decoder Loss:  0.33067673
Encoder Loss:  0.044914514  || Decoder Loss:  0.034294702 Validation Decoder Loss:  0.3306272
Encoder Loss:  0.044838987  || Decoder Loss:  0.03429468 Validation Decoder Loss:  0.33064628
Encoder Loss:  0.04482905  || Decoder Loss:  0.03431551 Validation Decoder Loss:  0.3306618
Encoder Loss:  0.044841625  || Decoder Loss:  0.03434873 Validation Decoder Loss:  0.3306746
Encoder Loss:  0.044864506  || Decoder Loss:  0.034388307 Validation Decoder Loss:  0.3306723
Encoder Loss:  0.044845343  || Decoder Loss:  0.034413725 Validation Decoder Loss:  0.33066392
Encoder Loss:  0.04487738  || Decoder Loss:  0.034450367 Validation Decoder Loss:  0.3306397
Encoder Loss:  0.044844583  || Decoder Loss:  0.03447108 Validation Decoder Loss:  0.3306511
Encoder Loss:  0.044843458  || Decoder Loss:  0.0345067 Validation Decoder Loss:  0.33066586
Encoder Loss:  0.044886824  || Decoder Loss:  0.03454804 Validation Decoder Loss:  0.33063287
Encoder Loss:  0.04489352  || Decoder Loss:  0.03457603 Validation Decoder Loss:  0.33060753
Encoder Loss:  0.044895153  || Decoder Loss:  0.03460187 Validation Decoder Loss:  0.3305689
Encoder Loss:  0.04487395  || Decoder Loss:  0.03462287 Validation Decoder Loss:  0.33057624
Encoder Loss:  0.044880323  || Decoder Loss:  0.03465274 Validation Decoder Loss:  0.33056748
Encoder Loss:  0.044886693  || Decoder Loss:  0.034680363 Validation Decoder Loss:  0.33054984
Model: siamese_net_lr_0.00031968088332752866 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3305498
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 121, 20, 20, 1)    465       
_________________________________________________________________
reshape_16 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 465
Trainable params: 465
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940396
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940396
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358017 Validation Decoder Loss:  0.339404
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940396
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358017 Validation Decoder Loss:  0.33940396
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358017 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.045358013 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.1375987  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Encoder Loss:  0.13759868  || Decoder Loss:  0.04535801 Validation Decoder Loss:  0.33940393
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33940393
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 72, 35, 20, 1)     244       
_________________________________________________________________
reshape_17 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 244
Trainable params: 244
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.091541186  || Decoder Loss:  0.037693292 Validation Decoder Loss:  0.33743864
Encoder Loss:  0.091564015  || Decoder Loss:  0.037795063 Validation Decoder Loss:  0.33767056
Encoder Loss:  0.09159147  || Decoder Loss:  0.037915353 Validation Decoder Loss:  0.33795893
Encoder Loss:  0.0916289  || Decoder Loss:  0.038067557 Validation Decoder Loss:  0.33831877
Encoder Loss:  0.09168001  || Decoder Loss:  0.038263965 Validation Decoder Loss:  0.33876964
Encoder Loss:  0.091747634  || Decoder Loss:  0.038520504 Validation Decoder Loss:  0.339342
Encoder Loss:  0.09183383  || Decoder Loss:  0.038860038 Validation Decoder Loss:  0.34008804
Encoder Loss:  0.09193836  || Decoder Loss:  0.03931825 Validation Decoder Loss:  0.34108862
Encoder Loss:  0.09205225  || Decoder Loss:  0.039952625 Validation Decoder Loss:  0.34247044
Encoder Loss:  0.09214109  || Decoder Loss:  0.04086527 Validation Decoder Loss:  0.3444568
Encoder Loss:  0.09207228  || Decoder Loss:  0.04225143 Validation Decoder Loss:  0.34750038
Encoder Loss:  0.09122521  || Decoder Loss:  0.04446617 Validation Decoder Loss:  0.3523881
Encoder Loss:  0.085878745  || Decoder Loss:  0.047726642 Validation Decoder Loss:  0.35799637
Encoder Loss:  0.06057153  || Decoder Loss:  0.047484804 Validation Decoder Loss:  0.34615508
Encoder Loss:  0.04645586  || Decoder Loss:  0.04000566 Validation Decoder Loss:  0.3363449
Encoder Loss:  0.043951154  || Decoder Loss:  0.037141334 Validation Decoder Loss:  0.33299863
Encoder Loss:  0.04322297  || Decoder Loss:  0.036332898 Validation Decoder Loss:  0.33183378
Encoder Loss:  0.04304588  || Decoder Loss:  0.03614763 Validation Decoder Loss:  0.33149773
Encoder Loss:  0.04296268  || Decoder Loss:  0.036069103 Validation Decoder Loss:  0.33140814
Encoder Loss:  0.042878248  || Decoder Loss:  0.035993364 Validation Decoder Loss:  0.33137274
Encoder Loss:  0.042794384  || Decoder Loss:  0.035915002 Validation Decoder Loss:  0.33134913
Encoder Loss:  0.042707592  || Decoder Loss:  0.03583558 Validation Decoder Loss:  0.3313319
Encoder Loss:  0.04262149  || Decoder Loss:  0.03575671 Validation Decoder Loss:  0.33132082
Encoder Loss:  0.04253757  || Decoder Loss:  0.035680305 Validation Decoder Loss:  0.33131582
Encoder Loss:  0.04245869  || Decoder Loss:  0.035607945 Validation Decoder Loss:  0.33131674
Encoder Loss:  0.042382106  || Decoder Loss:  0.035541102 Validation Decoder Loss:  0.33132255
Encoder Loss:  0.042306736  || Decoder Loss:  0.035481058 Validation Decoder Loss:  0.3313317
Encoder Loss:  0.0422484  || Decoder Loss:  0.035428233 Validation Decoder Loss:  0.33134454
Encoder Loss:  0.042192917  || Decoder Loss:  0.03538229 Validation Decoder Loss:  0.33136034
Encoder Loss:  0.04214024  || Decoder Loss:  0.03534307 Validation Decoder Loss:  0.33137822
Encoder Loss:  0.042091988  || Decoder Loss:  0.03530988 Validation Decoder Loss:  0.331397
Encoder Loss:  0.042052146  || Decoder Loss:  0.03528198 Validation Decoder Loss:  0.33141744
Encoder Loss:  0.0420108  || Decoder Loss:  0.03525874 Validation Decoder Loss:  0.3314379
Encoder Loss:  0.041975852  || Decoder Loss:  0.035239443 Validation Decoder Loss:  0.33145824
Encoder Loss:  0.041942872  || Decoder Loss:  0.035223436 Validation Decoder Loss:  0.33147836
Encoder Loss:  0.041912995  || Decoder Loss:  0.03521018 Validation Decoder Loss:  0.3314979
Encoder Loss:  0.041886162  || Decoder Loss:  0.035199236 Validation Decoder Loss:  0.3315171
Encoder Loss:  0.0418552  || Decoder Loss:  0.035190143 Validation Decoder Loss:  0.33153474
Encoder Loss:  0.041833162  || Decoder Loss:  0.0351826 Validation Decoder Loss:  0.3315522
Encoder Loss:  0.04180614  || Decoder Loss:  0.035176322 Validation Decoder Loss:  0.33156875
Model: siamese_net_lr_7.751572924663978e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33156875
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 84, 30, 20, 1)     463       
_________________________________________________________________
reshape_18 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 463
Trainable params: 463
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18031722  || Decoder Loss:  0.039263535 Validation Decoder Loss:  0.33472666
Encoder Loss:  0.18010023  || Decoder Loss:  0.03977195 Validation Decoder Loss:  0.33501133
Encoder Loss:  0.1797929  || Decoder Loss:  0.040401522 Validation Decoder Loss:  0.33542222
Encoder Loss:  0.17934334  || Decoder Loss:  0.041209966 Validation Decoder Loss:  0.33602157
Encoder Loss:  0.17865393  || Decoder Loss:  0.042258453 Validation Decoder Loss:  0.33693212
Encoder Loss:  0.1775332  || Decoder Loss:  0.043629322 Validation Decoder Loss:  0.33830467
Encoder Loss:  0.17558627  || Decoder Loss:  0.045425452 Validation Decoder Loss:  0.34021914
Encoder Loss:  0.1718524  || Decoder Loss:  0.047592808 Validation Decoder Loss:  0.34217292
Encoder Loss:  0.16328302  || Decoder Loss:  0.048643604 Validation Decoder Loss:  0.34027338
Encoder Loss:  0.13969846  || Decoder Loss:  0.04164202 Validation Decoder Loss:  0.33063346
Encoder Loss:  0.09131259  || Decoder Loss:  0.035827428 Validation Decoder Loss:  0.32970765
Encoder Loss:  0.053105187  || Decoder Loss:  0.035801254 Validation Decoder Loss:  0.32962537
Encoder Loss:  0.05320544  || Decoder Loss:  0.035641797 Validation Decoder Loss:  0.32968545
Encoder Loss:  0.053050857  || Decoder Loss:  0.035499763 Validation Decoder Loss:  0.32975453
Encoder Loss:  0.052910723  || Decoder Loss:  0.03538184 Validation Decoder Loss:  0.32982835
Encoder Loss:  0.05278952  || Decoder Loss:  0.035286855 Validation Decoder Loss:  0.32990378
Encoder Loss:  0.052685324  || Decoder Loss:  0.03521263 Validation Decoder Loss:  0.32997757
Encoder Loss:  0.052594334  || Decoder Loss:  0.03515656 Validation Decoder Loss:  0.33004862
Encoder Loss:  0.052504238  || Decoder Loss:  0.035115477 Validation Decoder Loss:  0.3301131
Encoder Loss:  0.052421466  || Decoder Loss:  0.035086144 Validation Decoder Loss:  0.33016983
Encoder Loss:  0.05234335  || Decoder Loss:  0.035065684 Validation Decoder Loss:  0.33021832
Encoder Loss:  0.052266832  || Decoder Loss:  0.03505152 Validation Decoder Loss:  0.33025873
Encoder Loss:  0.052193645  || Decoder Loss:  0.0350417 Validation Decoder Loss:  0.33029163
Encoder Loss:  0.052117888  || Decoder Loss:  0.03503484 Validation Decoder Loss:  0.33031923
Encoder Loss:  0.052030977  || Decoder Loss:  0.035029933 Validation Decoder Loss:  0.33034104
Encoder Loss:  0.051942468  || Decoder Loss:  0.035026323 Validation Decoder Loss:  0.33035815
Encoder Loss:  0.05183024  || Decoder Loss:  0.0350237 Validation Decoder Loss:  0.33037
Encoder Loss:  0.051712837  || Decoder Loss:  0.03502166 Validation Decoder Loss:  0.33037984
Encoder Loss:  0.051552486  || Decoder Loss:  0.03501999 Validation Decoder Loss:  0.33038816
Encoder Loss:  0.05129315  || Decoder Loss:  0.035018664 Validation Decoder Loss:  0.33039302
Encoder Loss:  0.05081713  || Decoder Loss:  0.035017718 Validation Decoder Loss:  0.33039504
Encoder Loss:  0.04939742  || Decoder Loss:  0.035016887 Validation Decoder Loss:  0.3303945
Encoder Loss:  0.043699298  || Decoder Loss:  0.03501564 Validation Decoder Loss:  0.33043802
Encoder Loss:  0.04188566  || Decoder Loss:  0.035010114 Validation Decoder Loss:  0.33042192
Encoder Loss:  0.04173059  || Decoder Loss:  0.035001785 Validation Decoder Loss:  0.3303978
Encoder Loss:  0.04157337  || Decoder Loss:  0.03499275 Validation Decoder Loss:  0.33037534
Encoder Loss:  0.041455697  || Decoder Loss:  0.03498336 Validation Decoder Loss:  0.33036047
Encoder Loss:  0.04137906  || Decoder Loss:  0.03497464 Validation Decoder Loss:  0.33036035
Encoder Loss:  0.04132617  || Decoder Loss:  0.03496712 Validation Decoder Loss:  0.3303736
Encoder Loss:  0.041276317  || Decoder Loss:  0.034961034 Validation Decoder Loss:  0.33039993
Model: siamese_net_lr_0.00010007442386250482 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33039993
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 242, 10, 20, 1)    107       
_________________________________________________________________
reshape_19 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 107
Trainable params: 107
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4359575  || Decoder Loss:  0.044344258 Validation Decoder Loss:  0.5141096
Encoder Loss:  0.118299395  || Decoder Loss:  0.045213923 Validation Decoder Loss:  0.32945696
Encoder Loss:  0.10295415  || Decoder Loss:  0.036660384 Validation Decoder Loss:  0.32920337
Encoder Loss:  0.0668941  || Decoder Loss:  0.036294628 Validation Decoder Loss:  0.32905617
Encoder Loss:  0.0556039  || Decoder Loss:  0.03604747 Validation Decoder Loss:  0.32912394
Encoder Loss:  0.054733653  || Decoder Loss:  0.035802588 Validation Decoder Loss:  0.32940096
Encoder Loss:  0.054224648  || Decoder Loss:  0.035527155 Validation Decoder Loss:  0.32966015
Encoder Loss:  0.053699497  || Decoder Loss:  0.03530849 Validation Decoder Loss:  0.32993996
Encoder Loss:  0.05324779  || Decoder Loss:  0.035163112 Validation Decoder Loss:  0.3302261
Encoder Loss:  0.05307891  || Decoder Loss:  0.035068367 Validation Decoder Loss:  0.33039892
Encoder Loss:  0.053075932  || Decoder Loss:  0.03500317 Validation Decoder Loss:  0.33032465
Encoder Loss:  0.052812997  || Decoder Loss:  0.034944914 Validation Decoder Loss:  0.3302573
Encoder Loss:  0.05257659  || Decoder Loss:  0.034892336 Validation Decoder Loss:  0.33026135
Encoder Loss:  0.052294664  || Decoder Loss:  0.03484318 Validation Decoder Loss:  0.33025834
Encoder Loss:  0.051996227  || Decoder Loss:  0.034800645 Validation Decoder Loss:  0.33039567
Encoder Loss:  0.051712297  || Decoder Loss:  0.034761354 Validation Decoder Loss:  0.33033732
Encoder Loss:  0.051573668  || Decoder Loss:  0.034727853 Validation Decoder Loss:  0.33039212
Encoder Loss:  0.0515082  || Decoder Loss:  0.034700148 Validation Decoder Loss:  0.33035606
Encoder Loss:  0.05137516  || Decoder Loss:  0.034676883 Validation Decoder Loss:  0.33038145
Encoder Loss:  0.051313754  || Decoder Loss:  0.034655392 Validation Decoder Loss:  0.33042556
Encoder Loss:  0.051447168  || Decoder Loss:  0.034635104 Validation Decoder Loss:  0.33032203
Encoder Loss:  0.051281754  || Decoder Loss:  0.03463547 Validation Decoder Loss:  0.33033162
Encoder Loss:  0.051195472  || Decoder Loss:  0.034621507 Validation Decoder Loss:  0.33041972
Encoder Loss:  0.051230226  || Decoder Loss:  0.03461558 Validation Decoder Loss:  0.3303824
Encoder Loss:  0.051140346  || Decoder Loss:  0.03460721 Validation Decoder Loss:  0.33040166
Encoder Loss:  0.051164877  || Decoder Loss:  0.034612592 Validation Decoder Loss:  0.33042246
Encoder Loss:  0.05117038  || Decoder Loss:  0.03461627 Validation Decoder Loss:  0.33036697
Encoder Loss:  0.05115174  || Decoder Loss:  0.034604184 Validation Decoder Loss:  0.33052465
Encoder Loss:  0.05117198  || Decoder Loss:  0.034620214 Validation Decoder Loss:  0.33033407
Encoder Loss:  0.05112319  || Decoder Loss:  0.03461509 Validation Decoder Loss:  0.33036953
Encoder Loss:  0.051069155  || Decoder Loss:  0.034616794 Validation Decoder Loss:  0.33055803
Encoder Loss:  0.051101316  || Decoder Loss:  0.03462762 Validation Decoder Loss:  0.33027682
Encoder Loss:  0.051039293  || Decoder Loss:  0.034633573 Validation Decoder Loss:  0.33012223
Encoder Loss:  0.051046267  || Decoder Loss:  0.03464089 Validation Decoder Loss:  0.330364
Encoder Loss:  0.051081244  || Decoder Loss:  0.034642227 Validation Decoder Loss:  0.33057067
Encoder Loss:  0.050957337  || Decoder Loss:  0.034648415 Validation Decoder Loss:  0.33028468
Encoder Loss:  0.051009182  || Decoder Loss:  0.03465522 Validation Decoder Loss:  0.3305053
Encoder Loss:  0.051094312  || Decoder Loss:  0.034661528 Validation Decoder Loss:  0.3300686
Encoder Loss:  0.050995197  || Decoder Loss:  0.03466263 Validation Decoder Loss:  0.33045214
Encoder Loss:  0.050981577  || Decoder Loss:  0.034668986 Validation Decoder Loss:  0.33038116
Model: siamese_net_lr_0.0006560987477568153 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33038118
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 504, 5, 20, 1)     64        
_________________________________________________________________
reshape_20 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21535255  || Decoder Loss:  0.03677441 Validation Decoder Loss:  0.33521026
Encoder Loss:  0.21532913  || Decoder Loss:  0.036761977 Validation Decoder Loss:  0.33519232
Encoder Loss:  0.21530691  || Decoder Loss:  0.03675042 Validation Decoder Loss:  0.33517587
Encoder Loss:  0.21528505  || Decoder Loss:  0.036739513 Validation Decoder Loss:  0.33516052
Encoder Loss:  0.21526378  || Decoder Loss:  0.036729053 Validation Decoder Loss:  0.33514598
Encoder Loss:  0.21524261  || Decoder Loss:  0.03671897 Validation Decoder Loss:  0.33513206
Encoder Loss:  0.21522148  || Decoder Loss:  0.03670915 Validation Decoder Loss:  0.33511865
Encoder Loss:  0.2152  || Decoder Loss:  0.03669949 Validation Decoder Loss:  0.33510566
Encoder Loss:  0.21517868  || Decoder Loss:  0.03669 Validation Decoder Loss:  0.33509296
Encoder Loss:  0.21515673  || Decoder Loss:  0.0366806 Validation Decoder Loss:  0.33508053
Encoder Loss:  0.2151345  || Decoder Loss:  0.03667127 Validation Decoder Loss:  0.33506835
Encoder Loss:  0.21511206  || Decoder Loss:  0.036662012 Validation Decoder Loss:  0.33505648
Encoder Loss:  0.21508914  || Decoder Loss:  0.036652826 Validation Decoder Loss:  0.3350448
Encoder Loss:  0.21506596  || Decoder Loss:  0.036643706 Validation Decoder Loss:  0.33503336
Encoder Loss:  0.21504216  || Decoder Loss:  0.036634628 Validation Decoder Loss:  0.3350221
Encoder Loss:  0.21501794  || Decoder Loss:  0.036625594 Validation Decoder Loss:  0.335011
Encoder Loss:  0.21499342  || Decoder Loss:  0.036616627 Validation Decoder Loss:  0.33500016
Encoder Loss:  0.21496835  || Decoder Loss:  0.036607668 Validation Decoder Loss:  0.3349895
Encoder Loss:  0.21494274  || Decoder Loss:  0.036598753 Validation Decoder Loss:  0.33497903
Encoder Loss:  0.21491662  || Decoder Loss:  0.036589887 Validation Decoder Loss:  0.33496875
Encoder Loss:  0.21488993  || Decoder Loss:  0.036581077 Validation Decoder Loss:  0.33495867
Encoder Loss:  0.2148629  || Decoder Loss:  0.036572285 Validation Decoder Loss:  0.33494878
Encoder Loss:  0.2148351  || Decoder Loss:  0.036563545 Validation Decoder Loss:  0.33493906
Encoder Loss:  0.2148067  || Decoder Loss:  0.036554858 Validation Decoder Loss:  0.33492956
Encoder Loss:  0.21477777  || Decoder Loss:  0.036546197 Validation Decoder Loss:  0.3349203
Encoder Loss:  0.2147482  || Decoder Loss:  0.036537576 Validation Decoder Loss:  0.33491117
Encoder Loss:  0.21471807  || Decoder Loss:  0.036529016 Validation Decoder Loss:  0.33490223
Encoder Loss:  0.21468712  || Decoder Loss:  0.036520507 Validation Decoder Loss:  0.3348935
Encoder Loss:  0.21465553  || Decoder Loss:  0.03651203 Validation Decoder Loss:  0.33488497
Encoder Loss:  0.21462312  || Decoder Loss:  0.03650357 Validation Decoder Loss:  0.3348766
Encoder Loss:  0.21459003  || Decoder Loss:  0.036495164 Validation Decoder Loss:  0.33486843
Encoder Loss:  0.21455608  || Decoder Loss:  0.036486857 Validation Decoder Loss:  0.3348605
Encoder Loss:  0.21452129  || Decoder Loss:  0.03647854 Validation Decoder Loss:  0.33485273
Encoder Loss:  0.21448557  || Decoder Loss:  0.03647029 Validation Decoder Loss:  0.3348452
Encoder Loss:  0.21444894  || Decoder Loss:  0.036462113 Validation Decoder Loss:  0.33483773
Encoder Loss:  0.21441132  || Decoder Loss:  0.036453985 Validation Decoder Loss:  0.33483058
Encoder Loss:  0.21437271  || Decoder Loss:  0.036445893 Validation Decoder Loss:  0.3348236
Encoder Loss:  0.21433291  || Decoder Loss:  0.03643788 Validation Decoder Loss:  0.3348168
Encoder Loss:  0.21429187  || Decoder Loss:  0.036429893 Validation Decoder Loss:  0.33481023
Encoder Loss:  0.21424967  || Decoder Loss:  0.036422018 Validation Decoder Loss:  0.33480382
Model: siamese_net_lr_2.036582555244255e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33480382
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 242, 10, 20, 1)    697       
_________________________________________________________________
reshape_21 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 697
Trainable params: 697
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38943046  || Decoder Loss:  0.050776884 Validation Decoder Loss:  0.3384004
Encoder Loss:  0.38377336  || Decoder Loss:  0.055290416 Validation Decoder Loss:  0.34006613
Encoder Loss:  0.37541434  || Decoder Loss:  0.061585713 Validation Decoder Loss:  0.34406745
Encoder Loss:  0.3622329  || Decoder Loss:  0.06897567 Validation Decoder Loss:  0.34802806
Encoder Loss:  0.33532977  || Decoder Loss:  0.042872593 Validation Decoder Loss:  0.33512816
Encoder Loss:  0.28461  || Decoder Loss:  0.036921915 Validation Decoder Loss:  0.33481842
Encoder Loss:  0.14103456  || Decoder Loss:  0.037463665 Validation Decoder Loss:  0.33245844
Encoder Loss:  0.08148506  || Decoder Loss:  0.03612071 Validation Decoder Loss:  0.3309005
Encoder Loss:  0.08093061  || Decoder Loss:  0.035452064 Validation Decoder Loss:  0.33017397
Encoder Loss:  0.08056627  || Decoder Loss:  0.03518387 Validation Decoder Loss:  0.32969669
Encoder Loss:  0.08008597  || Decoder Loss:  0.0350274 Validation Decoder Loss:  0.32936916
Encoder Loss:  0.078809045  || Decoder Loss:  0.03491978 Validation Decoder Loss:  0.32914388
Encoder Loss:  0.064758785  || Decoder Loss:  0.034837957 Validation Decoder Loss:  0.3290354
Encoder Loss:  0.052057944  || Decoder Loss:  0.03480884 Validation Decoder Loss:  0.32895175
Encoder Loss:  0.051746916  || Decoder Loss:  0.034787405 Validation Decoder Loss:  0.32892388
Encoder Loss:  0.051629294  || Decoder Loss:  0.034771763 Validation Decoder Loss:  0.32897627
Encoder Loss:  0.05150871  || Decoder Loss:  0.03476553 Validation Decoder Loss:  0.3290826
Encoder Loss:  0.051381294  || Decoder Loss:  0.03476475 Validation Decoder Loss:  0.32923445
Encoder Loss:  0.051250324  || Decoder Loss:  0.0347655 Validation Decoder Loss:  0.32942393
Encoder Loss:  0.051105484  || Decoder Loss:  0.034763206 Validation Decoder Loss:  0.3296455
Encoder Loss:  0.05094488  || Decoder Loss:  0.03475332 Validation Decoder Loss:  0.32989198
Encoder Loss:  0.050768413  || Decoder Loss:  0.034732476 Validation Decoder Loss:  0.33014733
Encoder Loss:  0.050581608  || Decoder Loss:  0.03470026 Validation Decoder Loss:  0.33038574
Encoder Loss:  0.05037708  || Decoder Loss:  0.03465834 Validation Decoder Loss:  0.33059335
Encoder Loss:  0.0503009  || Decoder Loss:  0.03460577 Validation Decoder Loss:  0.3307419
Encoder Loss:  0.050161187  || Decoder Loss:  0.03454861 Validation Decoder Loss:  0.33084905
Encoder Loss:  0.04995043  || Decoder Loss:  0.03449329 Validation Decoder Loss:  0.33092782
Encoder Loss:  0.049804114  || Decoder Loss:  0.03444699 Validation Decoder Loss:  0.33098274
Encoder Loss:  0.04957785  || Decoder Loss:  0.034407444 Validation Decoder Loss:  0.33103675
Encoder Loss:  0.04950763  || Decoder Loss:  0.034371737 Validation Decoder Loss:  0.3310814
Encoder Loss:  0.04934001  || Decoder Loss:  0.034346394 Validation Decoder Loss:  0.3311421
Encoder Loss:  0.04925052  || Decoder Loss:  0.0343203 Validation Decoder Loss:  0.33123305
Encoder Loss:  0.04924289  || Decoder Loss:  0.03430382 Validation Decoder Loss:  0.33131307
Encoder Loss:  0.049219884  || Decoder Loss:  0.034290925 Validation Decoder Loss:  0.33138433
Encoder Loss:  0.049140994  || Decoder Loss:  0.034283135 Validation Decoder Loss:  0.33147293
Encoder Loss:  0.049078476  || Decoder Loss:  0.03427641 Validation Decoder Loss:  0.33157274
Encoder Loss:  0.049058042  || Decoder Loss:  0.03427939 Validation Decoder Loss:  0.33165705
Encoder Loss:  0.04894419  || Decoder Loss:  0.034277488 Validation Decoder Loss:  0.3317678
Encoder Loss:  0.049067214  || Decoder Loss:  0.034289867 Validation Decoder Loss:  0.3318104
Encoder Loss:  0.04896762  || Decoder Loss:  0.034312923 Validation Decoder Loss:  0.3318529
Model: siamese_net_lr_0.00017724619168523162 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3318529
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 242, 10, 20, 1)    697       
_________________________________________________________________
reshape_22 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 697
Trainable params: 697
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37594655  || Decoder Loss:  0.054503735 Validation Decoder Loss:  0.34338856
Encoder Loss:  0.07405633  || Decoder Loss:  0.03810447 Validation Decoder Loss:  0.33052093
Encoder Loss:  0.053984385  || Decoder Loss:  0.035335783 Validation Decoder Loss:  0.3297947
Encoder Loss:  0.05353539  || Decoder Loss:  0.035115246 Validation Decoder Loss:  0.3298021
Encoder Loss:  0.05312824  || Decoder Loss:  0.034998722 Validation Decoder Loss:  0.33008558
Encoder Loss:  0.052305654  || Decoder Loss:  0.034840755 Validation Decoder Loss:  0.33023936
Encoder Loss:  0.051822457  || Decoder Loss:  0.03469692 Validation Decoder Loss:  0.330189
Encoder Loss:  0.05141706  || Decoder Loss:  0.034585305 Validation Decoder Loss:  0.33018667
Encoder Loss:  0.05135782  || Decoder Loss:  0.03454834 Validation Decoder Loss:  0.33009645
Encoder Loss:  0.051132508  || Decoder Loss:  0.034533117 Validation Decoder Loss:  0.3301113
Encoder Loss:  0.05099746  || Decoder Loss:  0.034549393 Validation Decoder Loss:  0.33013207
Encoder Loss:  0.050941724  || Decoder Loss:  0.034599084 Validation Decoder Loss:  0.33002326
Encoder Loss:  0.050950255  || Decoder Loss:  0.03464392 Validation Decoder Loss:  0.32995474
Encoder Loss:  0.050767664  || Decoder Loss:  0.034685574 Validation Decoder Loss:  0.329938
Encoder Loss:  0.05072392  || Decoder Loss:  0.034737855 Validation Decoder Loss:  0.3298875
Encoder Loss:  0.050715145  || Decoder Loss:  0.034777768 Validation Decoder Loss:  0.32983276
Encoder Loss:  0.050588574  || Decoder Loss:  0.034802593 Validation Decoder Loss:  0.32979465
Encoder Loss:  0.050588213  || Decoder Loss:  0.034824144 Validation Decoder Loss:  0.3297038
Encoder Loss:  0.050737165  || Decoder Loss:  0.03483384 Validation Decoder Loss:  0.3296678
Encoder Loss:  0.050689336  || Decoder Loss:  0.034835253 Validation Decoder Loss:  0.32968274
Encoder Loss:  0.050655723  || Decoder Loss:  0.03485164 Validation Decoder Loss:  0.3297228
Encoder Loss:  0.050633244  || Decoder Loss:  0.03485378 Validation Decoder Loss:  0.3296423
Encoder Loss:  0.050731644  || Decoder Loss:  0.034858093 Validation Decoder Loss:  0.32960576
Encoder Loss:  0.050785597  || Decoder Loss:  0.03485365 Validation Decoder Loss:  0.32962656
Encoder Loss:  0.050702944  || Decoder Loss:  0.034847587 Validation Decoder Loss:  0.3296379
Encoder Loss:  0.050692726  || Decoder Loss:  0.034851972 Validation Decoder Loss:  0.32960093
Encoder Loss:  0.050628453  || Decoder Loss:  0.034854613 Validation Decoder Loss:  0.3295795
Encoder Loss:  0.05069883  || Decoder Loss:  0.0348579 Validation Decoder Loss:  0.32953954
Encoder Loss:  0.050662328  || Decoder Loss:  0.034857757 Validation Decoder Loss:  0.32954225
Encoder Loss:  0.050659493  || Decoder Loss:  0.034857992 Validation Decoder Loss:  0.32957107
Encoder Loss:  0.050672818  || Decoder Loss:  0.03485657 Validation Decoder Loss:  0.3294419
Encoder Loss:  0.050656043  || Decoder Loss:  0.03486068 Validation Decoder Loss:  0.32948226
Encoder Loss:  0.050660443  || Decoder Loss:  0.034851234 Validation Decoder Loss:  0.32946146
Encoder Loss:  0.050746333  || Decoder Loss:  0.03484988 Validation Decoder Loss:  0.3293551
Encoder Loss:  0.050596155  || Decoder Loss:  0.034850642 Validation Decoder Loss:  0.32944542
Encoder Loss:  0.05072515  || Decoder Loss:  0.03484746 Validation Decoder Loss:  0.32937866
Encoder Loss:  0.05069532  || Decoder Loss:  0.034842256 Validation Decoder Loss:  0.32942325
Encoder Loss:  0.05064682  || Decoder Loss:  0.03484334 Validation Decoder Loss:  0.32939163
Encoder Loss:  0.050613236  || Decoder Loss:  0.03484539 Validation Decoder Loss:  0.3292543
Encoder Loss:  0.05063486  || Decoder Loss:  0.034838203 Validation Decoder Loss:  0.3293165
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3293165
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 484, 5, 20, 1)     422       
_________________________________________________________________
reshape_23 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 422
Trainable params: 422
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34259078  || Decoder Loss:  0.05029787 Validation Decoder Loss:  0.33480054
Encoder Loss:  0.08438802  || Decoder Loss:  0.03691049 Validation Decoder Loss:  0.33291328
Encoder Loss:  0.05525332  || Decoder Loss:  0.03530851 Validation Decoder Loss:  0.33242482
Encoder Loss:  0.053446542  || Decoder Loss:  0.03512535 Validation Decoder Loss:  0.33242503
Encoder Loss:  0.052914444  || Decoder Loss:  0.035122 Validation Decoder Loss:  0.3329631
Encoder Loss:  0.05214899  || Decoder Loss:  0.035054117 Validation Decoder Loss:  0.33374706
Encoder Loss:  0.051587373  || Decoder Loss:  0.03489171 Validation Decoder Loss:  0.33408362
Encoder Loss:  0.051127873  || Decoder Loss:  0.034696743 Validation Decoder Loss:  0.3340763
Encoder Loss:  0.05076924  || Decoder Loss:  0.03454237 Validation Decoder Loss:  0.33406392
Encoder Loss:  0.050789766  || Decoder Loss:  0.034451954 Validation Decoder Loss:  0.3340457
Encoder Loss:  0.050689388  || Decoder Loss:  0.0344141 Validation Decoder Loss:  0.33388627
Encoder Loss:  0.050662912  || Decoder Loss:  0.034397162 Validation Decoder Loss:  0.3336644
Encoder Loss:  0.050617486  || Decoder Loss:  0.034392778 Validation Decoder Loss:  0.33351502
Encoder Loss:  0.05058735  || Decoder Loss:  0.034390997 Validation Decoder Loss:  0.3334219
Encoder Loss:  0.050682668  || Decoder Loss:  0.03439628 Validation Decoder Loss:  0.3334282
Encoder Loss:  0.050650343  || Decoder Loss:  0.034398835 Validation Decoder Loss:  0.33356088
Encoder Loss:  0.050637912  || Decoder Loss:  0.034424417 Validation Decoder Loss:  0.33371258
Encoder Loss:  0.05063469  || Decoder Loss:  0.034441944 Validation Decoder Loss:  0.33384025
Encoder Loss:  0.05063711  || Decoder Loss:  0.034458786 Validation Decoder Loss:  0.33398122
Encoder Loss:  0.050665595  || Decoder Loss:  0.03448086 Validation Decoder Loss:  0.3340686
Encoder Loss:  0.05057369  || Decoder Loss:  0.034493543 Validation Decoder Loss:  0.33416831
Encoder Loss:  0.050569165  || Decoder Loss:  0.034501392 Validation Decoder Loss:  0.3342522
Encoder Loss:  0.05057124  || Decoder Loss:  0.034524623 Validation Decoder Loss:  0.3343107
Encoder Loss:  0.050545845  || Decoder Loss:  0.03453743 Validation Decoder Loss:  0.33438087
Encoder Loss:  0.050564885  || Decoder Loss:  0.03455064 Validation Decoder Loss:  0.3344004
Encoder Loss:  0.050499495  || Decoder Loss:  0.034553193 Validation Decoder Loss:  0.33445805
Encoder Loss:  0.05050785  || Decoder Loss:  0.03457039 Validation Decoder Loss:  0.3344683
Encoder Loss:  0.050573573  || Decoder Loss:  0.034598857 Validation Decoder Loss:  0.33446652
Encoder Loss:  0.05050451  || Decoder Loss:  0.03459688 Validation Decoder Loss:  0.33451647
Encoder Loss:  0.05044987  || Decoder Loss:  0.034616414 Validation Decoder Loss:  0.33443445
Encoder Loss:  0.05049937  || Decoder Loss:  0.034633785 Validation Decoder Loss:  0.334406
Encoder Loss:  0.05044378  || Decoder Loss:  0.0346395 Validation Decoder Loss:  0.33434284
Encoder Loss:  0.050464913  || Decoder Loss:  0.034654114 Validation Decoder Loss:  0.33421534
Encoder Loss:  0.050421357  || Decoder Loss:  0.034648012 Validation Decoder Loss:  0.3340782
Encoder Loss:  0.050424915  || Decoder Loss:  0.03463836 Validation Decoder Loss:  0.3340608
Encoder Loss:  0.050439533  || Decoder Loss:  0.034653403 Validation Decoder Loss:  0.33398622
Encoder Loss:  0.050459847  || Decoder Loss:  0.03467604 Validation Decoder Loss:  0.33392832
Encoder Loss:  0.050350916  || Decoder Loss:  0.034662165 Validation Decoder Loss:  0.3339172
Encoder Loss:  0.050364222  || Decoder Loss:  0.034668688 Validation Decoder Loss:  0.33388674
Encoder Loss:  0.050360158  || Decoder Loss:  0.034666415 Validation Decoder Loss:  0.33386648
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33386648
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 220, 11, 20, 1)    283       
_________________________________________________________________
reshape_24 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [3.08438438e-04 3.65041638e-01 5.44622580e-01 2.40790605e-01
 6.50628756e-01 4.00000000e+00 2.42000000e+03]
Optimized Validation Decoder Loss: 0.328744113445282











Optimizing at level  2
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_75 (Dropout)         (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_27 (Conv3DT (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_25 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_77 (Dropout)         (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_79 (Dropout)         (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_26 (Conv2DT (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13849959  || Decoder Loss:  0.11454153 Validation Decoder Loss:  0.3316706
Encoder Loss:  0.04013714  || Decoder Loss:  0.035763584 Validation Decoder Loss:  0.33016655
Encoder Loss:  0.03924824  || Decoder Loss:  0.03504354 Validation Decoder Loss:  0.330279
Encoder Loss:  0.039189175  || Decoder Loss:  0.03496058 Validation Decoder Loss:  0.33045405
Encoder Loss:  0.039128967  || Decoder Loss:  0.034880802 Validation Decoder Loss:  0.3306224
Encoder Loss:  0.03906505  || Decoder Loss:  0.03479075 Validation Decoder Loss:  0.33075503
Encoder Loss:  0.03899681  || Decoder Loss:  0.03469545 Validation Decoder Loss:  0.33081338
Encoder Loss:  0.03892939  || Decoder Loss:  0.034600724 Validation Decoder Loss:  0.3307454
Encoder Loss:  0.038868003  || Decoder Loss:  0.03451679 Validation Decoder Loss:  0.33054054
Encoder Loss:  0.03881705  || Decoder Loss:  0.03445192 Validation Decoder Loss:  0.33043534
Encoder Loss:  0.03878145  || Decoder Loss:  0.034404334 Validation Decoder Loss:  0.33095324
Encoder Loss:  0.03875394  || Decoder Loss:  0.034368202 Validation Decoder Loss:  0.33098084
Encoder Loss:  0.038758703  || Decoder Loss:  0.034375016 Validation Decoder Loss:  0.33004004
Encoder Loss:  0.038769506  || Decoder Loss:  0.03439007 Validation Decoder Loss:  0.32970762
Encoder Loss:  0.038798902  || Decoder Loss:  0.034431666 Validation Decoder Loss:  0.3301917
Encoder Loss:  0.038858842  || Decoder Loss:  0.03452038 Validation Decoder Loss:  0.32996002
Encoder Loss:  0.038887545  || Decoder Loss:  0.034560625 Validation Decoder Loss:  0.3292874
Encoder Loss:  0.0389132  || Decoder Loss:  0.034593806 Validation Decoder Loss:  0.3277809
Encoder Loss:  0.038891718  || Decoder Loss:  0.034569263 Validation Decoder Loss:  0.327146
Encoder Loss:  0.038841903  || Decoder Loss:  0.034500994 Validation Decoder Loss:  0.32562983
Encoder Loss:  0.038782742  || Decoder Loss:  0.034415457 Validation Decoder Loss:  0.32515848
Encoder Loss:  0.03873172  || Decoder Loss:  0.034350015 Validation Decoder Loss:  0.32493222
Encoder Loss:  0.038685523  || Decoder Loss:  0.034285236 Validation Decoder Loss:  0.32491767
Encoder Loss:  0.038652286  || Decoder Loss:  0.034239374 Validation Decoder Loss:  0.32500446
Encoder Loss:  0.038623  || Decoder Loss:  0.0341985 Validation Decoder Loss:  0.32513016
Encoder Loss:  0.038599145  || Decoder Loss:  0.03416505 Validation Decoder Loss:  0.32525957
Encoder Loss:  0.038577855  || Decoder Loss:  0.034135554 Validation Decoder Loss:  0.3254032
Encoder Loss:  0.038559206  || Decoder Loss:  0.034109995 Validation Decoder Loss:  0.3255946
Encoder Loss:  0.03854423  || Decoder Loss:  0.03408938 Validation Decoder Loss:  0.32570127
Encoder Loss:  0.038530823  || Decoder Loss:  0.03407111 Validation Decoder Loss:  0.3258398
Encoder Loss:  0.038522035  || Decoder Loss:  0.034055885 Validation Decoder Loss:  0.32615545
Encoder Loss:  0.038520887  || Decoder Loss:  0.03405529 Validation Decoder Loss:  0.32602644
Encoder Loss:  0.038502038  || Decoder Loss:  0.034031752 Validation Decoder Loss:  0.3261813
Encoder Loss:  0.03849499  || Decoder Loss:  0.034021903 Validation Decoder Loss:  0.3262924
Encoder Loss:  0.038490962  || Decoder Loss:  0.03401536 Validation Decoder Loss:  0.32638186
Encoder Loss:  0.038485914  || Decoder Loss:  0.03400839 Validation Decoder Loss:  0.3264826
Encoder Loss:  0.038479913  || Decoder Loss:  0.034000657 Validation Decoder Loss:  0.32654953
Encoder Loss:  0.03848441  || Decoder Loss:  0.034002602 Validation Decoder Loss:  0.32684886
Encoder Loss:  0.038472094  || Decoder Loss:  0.033989504 Validation Decoder Loss:  0.32694837
Encoder Loss:  0.038471024  || Decoder Loss:  0.033988535 Validation Decoder Loss:  0.3267683
2019-11-21 20:29:43.642605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_0.0009359830858013784 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3267683
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 197, 10, 20, 1)    17        
_________________________________________________________________
dropout_81 (Dropout)         (None, 197, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_30 (Conv3DT (None, 220, 11, 20, 1)    49        
_________________________________________________________________
reshape_26 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_83 (Dropout)         (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_85 (Dropout)         (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_28 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25479838  || Decoder Loss:  0.052462697 Validation Decoder Loss:  0.3647306
Encoder Loss:  0.2547468  || Decoder Loss:  0.052481946 Validation Decoder Loss:  0.36481884
Encoder Loss:  0.25469247  || Decoder Loss:  0.05249741 Validation Decoder Loss:  0.3648771
Encoder Loss:  0.25463694  || Decoder Loss:  0.052508894 Validation Decoder Loss:  0.36490792
Encoder Loss:  0.25458  || Decoder Loss:  0.052516628 Validation Decoder Loss:  0.36491516
Encoder Loss:  0.25452155  || Decoder Loss:  0.052520804 Validation Decoder Loss:  0.3649023
Encoder Loss:  0.25446165  || Decoder Loss:  0.05252152 Validation Decoder Loss:  0.364872
Encoder Loss:  0.2544001  || Decoder Loss:  0.052518807 Validation Decoder Loss:  0.36482596
Encoder Loss:  0.25433683  || Decoder Loss:  0.052512642 Validation Decoder Loss:  0.36476505
Encoder Loss:  0.2542718  || Decoder Loss:  0.052503046 Validation Decoder Loss:  0.36468998
Encoder Loss:  0.25420478  || Decoder Loss:  0.052489914 Validation Decoder Loss:  0.36460102
Encoder Loss:  0.25413564  || Decoder Loss:  0.05247317 Validation Decoder Loss:  0.3644985
Encoder Loss:  0.25406432  || Decoder Loss:  0.052452758 Validation Decoder Loss:  0.3643825
Encoder Loss:  0.25399062  || Decoder Loss:  0.052428495 Validation Decoder Loss:  0.36425328
Encoder Loss:  0.25391454  || Decoder Loss:  0.052400287 Validation Decoder Loss:  0.36411124
Encoder Loss:  0.2538357  || Decoder Loss:  0.052367948 Validation Decoder Loss:  0.36395678
Encoder Loss:  0.25375417  || Decoder Loss:  0.052331295 Validation Decoder Loss:  0.3637905
Encoder Loss:  0.2536696  || Decoder Loss:  0.052290086 Validation Decoder Loss:  0.3636129
Encoder Loss:  0.25358188  || Decoder Loss:  0.05224407 Validation Decoder Loss:  0.3634244
Encoder Loss:  0.25349084  || Decoder Loss:  0.052192904 Validation Decoder Loss:  0.3632252
Encoder Loss:  0.25339612  || Decoder Loss:  0.052136205 Validation Decoder Loss:  0.36301538
Encoder Loss:  0.2532977  || Decoder Loss:  0.052073576 Validation Decoder Loss:  0.36279488
Encoder Loss:  0.2531951  || Decoder Loss:  0.052004453 Validation Decoder Loss:  0.36256346
Encoder Loss:  0.25308797  || Decoder Loss:  0.05192831 Validation Decoder Loss:  0.36232087
Encoder Loss:  0.25297597  || Decoder Loss:  0.051844444 Validation Decoder Loss:  0.36206663
Encoder Loss:  0.25285876  || Decoder Loss:  0.051752113 Validation Decoder Loss:  0.36180025
Encoder Loss:  0.2527358  || Decoder Loss:  0.051650427 Validation Decoder Loss:  0.3615212
Encoder Loss:  0.2526066  || Decoder Loss:  0.051538367 Validation Decoder Loss:  0.36122876
Encoder Loss:  0.2524704  || Decoder Loss:  0.05141474 Validation Decoder Loss:  0.36092213
Encoder Loss:  0.2523266  || Decoder Loss:  0.051278118 Validation Decoder Loss:  0.36060023
Encoder Loss:  0.25217432  || Decoder Loss:  0.05112689 Validation Decoder Loss:  0.3602618
Encoder Loss:  0.2520126  || Decoder Loss:  0.05095901 Validation Decoder Loss:  0.35990512
Encoder Loss:  0.25184008  || Decoder Loss:  0.05077212 Validation Decoder Loss:  0.35952824
Encoder Loss:  0.2516555  || Decoder Loss:  0.05056327 Validation Decoder Loss:  0.35912853
Encoder Loss:  0.25145692  || Decoder Loss:  0.050328907 Validation Decoder Loss:  0.35870287
Encoder Loss:  0.25124234  || Decoder Loss:  0.050064597 Validation Decoder Loss:  0.35824716
Encoder Loss:  0.25100896  || Decoder Loss:  0.049764708 Validation Decoder Loss:  0.35775656
Encoder Loss:  0.25075328  || Decoder Loss:  0.04942209 Validation Decoder Loss:  0.35722452
Encoder Loss:  0.2504709  || Decoder Loss:  0.04902741 Validation Decoder Loss:  0.3566429
Encoder Loss:  0.2501559  || Decoder Loss:  0.048568368 Validation Decoder Loss:  0.3560012
Model: siamese_net_lr_0.00011751554816069377 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35600117
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 74, 10, 20, 1)     67        
_________________________________________________________________
dropout_87 (Dropout)         (None, 74, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_33 (Conv3DT (None, 220, 11, 20, 1)    295       
_________________________________________________________________
reshape_27 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 362
Trainable params: 362
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_89 (Dropout)         (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_91 (Dropout)         (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_30 (Conv2DT (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33647254  || Decoder Loss:  0.08970265 Validation Decoder Loss:  0.37065768
Encoder Loss:  0.3357523  || Decoder Loss:  0.09098968 Validation Decoder Loss:  0.37164807
Encoder Loss:  0.3348735  || Decoder Loss:  0.09255355 Validation Decoder Loss:  0.37278637
Encoder Loss:  0.33391446  || Decoder Loss:  0.094252974 Validation Decoder Loss:  0.37400272
Encoder Loss:  0.3329025  || Decoder Loss:  0.09603654 Validation Decoder Loss:  0.3752847
Encoder Loss:  0.3318431  || Decoder Loss:  0.097891554 Validation Decoder Loss:  0.37663227
Encoder Loss:  0.33073485  || Decoder Loss:  0.099816725 Validation Decoder Loss:  0.37804854
Encoder Loss:  0.32957432  || Decoder Loss:  0.10181368 Validation Decoder Loss:  0.37953782
Encoder Loss:  0.328357  || Decoder Loss:  0.10388486 Validation Decoder Loss:  0.38110378
Encoder Loss:  0.3270771  || Decoder Loss:  0.10603312 Validation Decoder Loss:  0.38274965
Encoder Loss:  0.3257276  || Decoder Loss:  0.1082616 Validation Decoder Loss:  0.38447863
Encoder Loss:  0.32429963  || Decoder Loss:  0.11057382 Validation Decoder Loss:  0.386294
Encoder Loss:  0.32278144  || Decoder Loss:  0.112973854 Validation Decoder Loss:  0.38820022
Encoder Loss:  0.3211575  || Decoder Loss:  0.11546656 Validation Decoder Loss:  0.39020318
Encoder Loss:  0.31940615  || Decoder Loss:  0.11805783 Validation Decoder Loss:  0.39231068
Encoder Loss:  0.31749693  || Decoder Loss:  0.12075525 Validation Decoder Loss:  0.39453346
Encoder Loss:  0.31538436  || Decoder Loss:  0.12356876 Validation Decoder Loss:  0.39688572
Encoder Loss:  0.31299818  || Decoder Loss:  0.12651204 Validation Decoder Loss:  0.39938778
Encoder Loss:  0.3102229  || Decoder Loss:  0.12960504 Validation Decoder Loss:  0.4020698
Encoder Loss:  0.3068552  || Decoder Loss:  0.13287918 Validation Decoder Loss:  0.40498152
Encoder Loss:  0.30250198  || Decoder Loss:  0.13638863 Validation Decoder Loss:  0.40821552
Encoder Loss:  0.29630214  || Decoder Loss:  0.1402397 Validation Decoder Loss:  0.4119767
Encoder Loss:  0.2859757  || Decoder Loss:  0.14468777 Validation Decoder Loss:  0.4168918
Encoder Loss:  0.26353812  || Decoder Loss:  0.1507016 Validation Decoder Loss:  0.42720222
Encoder Loss:  0.19658381  || Decoder Loss:  0.18849546 Validation Decoder Loss:  1.1580642
Encoder Loss:  0.19448155  || Decoder Loss:  0.56400794 Validation Decoder Loss:  1.1528311
Encoder Loss:  0.16184899  || Decoder Loss:  0.42858142 Validation Decoder Loss:  1.2006931
Encoder Loss:  0.17548126  || Decoder Loss:  0.48610035 Validation Decoder Loss:  1.1116023
Encoder Loss:  0.16222678  || Decoder Loss:  0.44294026 Validation Decoder Loss:  1.1372256
Encoder Loss:  0.15350634  || Decoder Loss:  0.38469675 Validation Decoder Loss:  0.9937513
Encoder Loss:  0.12303291  || Decoder Loss:  0.23857553 Validation Decoder Loss:  0.4311555
Encoder Loss:  0.10124263  || Decoder Loss:  0.12995972 Validation Decoder Loss:  0.46284968
Encoder Loss:  0.09664807  || Decoder Loss:  0.107193775 Validation Decoder Loss:  0.4686956
Encoder Loss:  0.09300888  || Decoder Loss:  0.090638995 Validation Decoder Loss:  0.3797485
Encoder Loss:  0.09035253  || Decoder Loss:  0.0771957 Validation Decoder Loss:  0.374323
Encoder Loss:  0.08792973  || Decoder Loss:  0.067600325 Validation Decoder Loss:  0.36093283
Encoder Loss:  0.08677193  || Decoder Loss:  0.060702827 Validation Decoder Loss:  0.34908324
Encoder Loss:  0.0855531  || Decoder Loss:  0.057172336 Validation Decoder Loss:  0.3455997
Encoder Loss:  0.085277446  || Decoder Loss:  0.0555165 Validation Decoder Loss:  0.34379554
Encoder Loss:  0.084589206  || Decoder Loss:  0.053927664 Validation Decoder Loss:  0.34275514
Model: siamese_net_lr_0.0006955868914251652 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34275514
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 191, 10, 20, 1)    769       
_________________________________________________________________
dropout_93 (Dropout)         (None, 191, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_36 (Conv3DT (None, 220, 11, 20, 1)    61        
_________________________________________________________________
reshape_28 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 830
Trainable params: 830
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_95 (Dropout)         (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_97 (Dropout)         (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_32 (Conv2DT (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22664648  || Decoder Loss:  0.07445345 Validation Decoder Loss:  0.36617827
Encoder Loss:  0.22637978  || Decoder Loss:  0.076608144 Validation Decoder Loss:  0.36603567
Encoder Loss:  0.22609635  || Decoder Loss:  0.079155415 Validation Decoder Loss:  0.3659473
Encoder Loss:  0.22580492  || Decoder Loss:  0.0821582 Validation Decoder Loss:  0.36607063
Encoder Loss:  0.22551045  || Decoder Loss:  0.08576516 Validation Decoder Loss:  0.3666013
Encoder Loss:  0.22522263  || Decoder Loss:  0.09018826 Validation Decoder Loss:  0.36778432
Encoder Loss:  0.22495984  || Decoder Loss:  0.09574219 Validation Decoder Loss:  0.36998063
Encoder Loss:  0.22475816  || Decoder Loss:  0.102914564 Validation Decoder Loss:  0.37382156
Encoder Loss:  0.22468923  || Decoder Loss:  0.11249978 Validation Decoder Loss:  0.38052195
Encoder Loss:  0.22490649  || Decoder Loss:  0.1258814 Validation Decoder Loss:  0.3925734
Encoder Loss:  0.22576995  || Decoder Loss:  0.14569749 Validation Decoder Loss:  0.4156065
Encoder Loss:  0.22825623  || Decoder Loss:  0.17767933 Validation Decoder Loss:  0.46458048
Encoder Loss:  0.23552252  || Decoder Loss:  0.23650552 Validation Decoder Loss:  0.58565164
Encoder Loss:  0.24709421  || Decoder Loss:  0.3405962 Validation Decoder Loss:  0.7853395
Encoder Loss:  0.21547565  || Decoder Loss:  0.33308274 Validation Decoder Loss:  0.7699535
Encoder Loss:  0.16693076  || Decoder Loss:  0.24325223 Validation Decoder Loss:  0.5359305
Encoder Loss:  0.08801416  || Decoder Loss:  0.09716791 Validation Decoder Loss:  0.34923512
Encoder Loss:  0.05989965  || Decoder Loss:  0.04555559 Validation Decoder Loss:  0.34335327
Encoder Loss:  0.05865009  || Decoder Loss:  0.04396675 Validation Decoder Loss:  0.3420434
Encoder Loss:  0.055900544  || Decoder Loss:  0.04305561 Validation Decoder Loss:  0.34119934
Encoder Loss:  0.048612334  || Decoder Loss:  0.042994782 Validation Decoder Loss:  0.34222317
Encoder Loss:  0.048037186  || Decoder Loss:  0.042897463 Validation Decoder Loss:  0.3427169
Encoder Loss:  0.047289573  || Decoder Loss:  0.042693276 Validation Decoder Loss:  0.34295475
Encoder Loss:  0.04658256  || Decoder Loss:  0.042342085 Validation Decoder Loss:  0.3427813
Encoder Loss:  0.045652546  || Decoder Loss:  0.041723084 Validation Decoder Loss:  0.34170002
Encoder Loss:  0.045121316  || Decoder Loss:  0.040783945 Validation Decoder Loss:  0.34048706
Encoder Loss:  0.044671774  || Decoder Loss:  0.03995389 Validation Decoder Loss:  0.33943474
Encoder Loss:  0.04428894  || Decoder Loss:  0.039255213 Validation Decoder Loss:  0.33855352
Encoder Loss:  0.04396678  || Decoder Loss:  0.03866532 Validation Decoder Loss:  0.33780327
Encoder Loss:  0.04369284  || Decoder Loss:  0.038164657 Validation Decoder Loss:  0.3371633
Encoder Loss:  0.043459103  || Decoder Loss:  0.03773889 Validation Decoder Loss:  0.33661905
Encoder Loss:  0.043259412  || Decoder Loss:  0.037376083 Validation Decoder Loss:  0.33615482
Encoder Loss:  0.043088645  || Decoder Loss:  0.037066482 Validation Decoder Loss:  0.3357591
Encoder Loss:  0.04294157  || Decoder Loss:  0.036801793 Validation Decoder Loss:  0.3354217
Encoder Loss:  0.04281529  || Decoder Loss:  0.036575083 Validation Decoder Loss:  0.33513266
Encoder Loss:  0.042706676  || Decoder Loss:  0.03638063 Validation Decoder Loss:  0.33488092
Encoder Loss:  0.042612232  || Decoder Loss:  0.036213506 Validation Decoder Loss:  0.3346604
Encoder Loss:  0.04253066  || Decoder Loss:  0.03606957 Validation Decoder Loss:  0.3344641
Encoder Loss:  0.042459503  || Decoder Loss:  0.035945434 Validation Decoder Loss:  0.334288
Encoder Loss:  0.042398594  || Decoder Loss:  0.035838455 Validation Decoder Loss:  0.3341287
Model: siamese_net_lr_0.0005115748131167265 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3341287
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_99 (Dropout)         (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_39 (Conv3DT (None, 220, 11, 20, 1)    310       
_________________________________________________________________
reshape_29 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 366
Trainable params: 366
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_101 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_103 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_34 (Conv2DT (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27708745  || Decoder Loss:  0.17264645 Validation Decoder Loss:  0.36555347
Encoder Loss:  0.08926205  || Decoder Loss:  0.04532914 Validation Decoder Loss:  0.3375438
Encoder Loss:  0.053162  || Decoder Loss:  0.03741871 Validation Decoder Loss:  0.33304644
Encoder Loss:  0.05004109  || Decoder Loss:  0.03552445 Validation Decoder Loss:  0.33222175
Encoder Loss:  0.049965072  || Decoder Loss:  0.035035953 Validation Decoder Loss:  0.33227956
Encoder Loss:  0.049939074  || Decoder Loss:  0.034871355 Validation Decoder Loss:  0.33231336
Encoder Loss:  0.049934816  || Decoder Loss:  0.034859873 Validation Decoder Loss:  0.33227623
Encoder Loss:  0.049928397  || Decoder Loss:  0.034854148 Validation Decoder Loss:  0.3322144
Encoder Loss:  0.049928874  || Decoder Loss:  0.034892995 Validation Decoder Loss:  0.3321126
Encoder Loss:  0.049935047  || Decoder Loss:  0.034916542 Validation Decoder Loss:  0.3320354
Encoder Loss:  0.049931422  || Decoder Loss:  0.03494641 Validation Decoder Loss:  0.33191854
Encoder Loss:  0.049932763  || Decoder Loss:  0.034980442 Validation Decoder Loss:  0.33178633
Encoder Loss:  0.049936622  || Decoder Loss:  0.03500632 Validation Decoder Loss:  0.33166525
Encoder Loss:  0.049925953  || Decoder Loss:  0.035031095 Validation Decoder Loss:  0.33151978
Encoder Loss:  0.04993125  || Decoder Loss:  0.03504321 Validation Decoder Loss:  0.33143884
Encoder Loss:  0.049924288  || Decoder Loss:  0.03504384 Validation Decoder Loss:  0.3313771
Encoder Loss:  0.049928185  || Decoder Loss:  0.03504276 Validation Decoder Loss:  0.33125094
Encoder Loss:  0.04993336  || Decoder Loss:  0.035033204 Validation Decoder Loss:  0.33106536
Encoder Loss:  0.04991914  || Decoder Loss:  0.035020612 Validation Decoder Loss:  0.33088338
Encoder Loss:  0.04991829  || Decoder Loss:  0.035000045 Validation Decoder Loss:  0.33072576
Encoder Loss:  0.049920697  || Decoder Loss:  0.03497343 Validation Decoder Loss:  0.33066905
Encoder Loss:  0.0499122  || Decoder Loss:  0.034937896 Validation Decoder Loss:  0.33052444
Encoder Loss:  0.049916554  || Decoder Loss:  0.0348972 Validation Decoder Loss:  0.33020586
Encoder Loss:  0.049918294  || Decoder Loss:  0.03484322 Validation Decoder Loss:  0.32995307
Encoder Loss:  0.04991928  || Decoder Loss:  0.034795005 Validation Decoder Loss:  0.3298484
Encoder Loss:  0.04991855  || Decoder Loss:  0.034752026 Validation Decoder Loss:  0.329768
Encoder Loss:  0.049916472  || Decoder Loss:  0.03468976 Validation Decoder Loss:  0.32969362
Encoder Loss:  0.04990971  || Decoder Loss:  0.034628328 Validation Decoder Loss:  0.329453
Encoder Loss:  0.04990588  || Decoder Loss:  0.034564342 Validation Decoder Loss:  0.32930332
Encoder Loss:  0.049906805  || Decoder Loss:  0.034511108 Validation Decoder Loss:  0.32918522
Encoder Loss:  0.049914822  || Decoder Loss:  0.034467027 Validation Decoder Loss:  0.3290453
Encoder Loss:  0.049902387  || Decoder Loss:  0.034426752 Validation Decoder Loss:  0.32906523
Encoder Loss:  0.049904183  || Decoder Loss:  0.03439128 Validation Decoder Loss:  0.32893685
Encoder Loss:  0.049912576  || Decoder Loss:  0.03437613 Validation Decoder Loss:  0.3291005
Encoder Loss:  0.049907457  || Decoder Loss:  0.034357633 Validation Decoder Loss:  0.32899547
Encoder Loss:  0.0499001  || Decoder Loss:  0.03433402 Validation Decoder Loss:  0.32894975
Encoder Loss:  0.04990016  || Decoder Loss:  0.034316357 Validation Decoder Loss:  0.328902
Encoder Loss:  0.049912777  || Decoder Loss:  0.034313563 Validation Decoder Loss:  0.3289639
Encoder Loss:  0.049907014  || Decoder Loss:  0.034297585 Validation Decoder Loss:  0.32894456
Encoder Loss:  0.04990196  || Decoder Loss:  0.034295004 Validation Decoder Loss:  0.3288675
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.000931903853233504 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3288675
Started Optimization Process
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 193, 10, 20, 1)    781       
_________________________________________________________________
dropout_105 (Dropout)        (None, 193, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_42 (Conv3DT (None, 220, 11, 20, 1)    57        
_________________________________________________________________
reshape_30 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 838
Trainable params: 838
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_107 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_36 (Conv2D)           (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_109 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_36 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25803754  || Decoder Loss:  0.07269804 Validation Decoder Loss:  0.3654235
Encoder Loss:  0.25741476  || Decoder Loss:  0.07439112 Validation Decoder Loss:  0.36538467
Encoder Loss:  0.25675198  || Decoder Loss:  0.07626923 Validation Decoder Loss:  0.36538553
Encoder Loss:  0.2560437  || Decoder Loss:  0.07836896 Validation Decoder Loss:  0.3655038
Encoder Loss:  0.25528237  || Decoder Loss:  0.080736846 Validation Decoder Loss:  0.36581323
Encoder Loss:  0.2544601  || Decoder Loss:  0.08342924 Validation Decoder Loss:  0.36638024
Encoder Loss:  0.25356734  || Decoder Loss:  0.08651673 Validation Decoder Loss:  0.36727464
Encoder Loss:  0.2525936  || Decoder Loss:  0.09008911 Validation Decoder Loss:  0.36858207
Encoder Loss:  0.25152647  || Decoder Loss:  0.094262324 Validation Decoder Loss:  0.37041762
Encoder Loss:  0.25035116  || Decoder Loss:  0.099189036 Validation Decoder Loss:  0.3729466
Encoder Loss:  0.24905016  || Decoder Loss:  0.10507314 Validation Decoder Loss:  0.3764238
Encoder Loss:  0.24760313  || Decoder Loss:  0.11219331 Validation Decoder Loss:  0.38125348
Encoder Loss:  0.24598528  || Decoder Loss:  0.120939896 Validation Decoder Loss:  0.38807642
Encoder Loss:  0.24416727  || Decoder Loss:  0.13187665 Validation Decoder Loss:  0.3979241
Encoder Loss:  0.24210939  || Decoder Loss:  0.14584446 Validation Decoder Loss:  0.4125288
Encoder Loss:  0.23972915  || Decoder Loss:  0.16410527 Validation Decoder Loss:  0.434946
Encoder Loss:  0.23644842  || Decoder Loss:  0.18775512 Validation Decoder Loss:  0.4689873
Encoder Loss:  0.20600116  || Decoder Loss:  0.16185217 Validation Decoder Loss:  0.45304966
Encoder Loss:  0.17381607  || Decoder Loss:  0.15058506 Validation Decoder Loss:  0.5387057
Encoder Loss:  0.15402228  || Decoder Loss:  0.19494963 Validation Decoder Loss:  0.5857563
Encoder Loss:  0.103474684  || Decoder Loss:  0.13781284 Validation Decoder Loss:  0.41506067
Encoder Loss:  0.08096389  || Decoder Loss:  0.08641761 Validation Decoder Loss:  0.39415282
Encoder Loss:  0.07687423  || Decoder Loss:  0.07737553 Validation Decoder Loss:  0.3826704
Encoder Loss:  0.07367096  || Decoder Loss:  0.070369646 Validation Decoder Loss:  0.37344623
Encoder Loss:  0.071010746  || Decoder Loss:  0.064626455 Validation Decoder Loss:  0.36607867
Encoder Loss:  0.06880772  || Decoder Loss:  0.05992552 Validation Decoder Loss:  0.36012322
Encoder Loss:  0.06697366  || Decoder Loss:  0.056040984 Validation Decoder Loss:  0.35525942
Encoder Loss:  0.065404035  || Decoder Loss:  0.052826747 Validation Decoder Loss:  0.351301
Encoder Loss:  0.06405451  || Decoder Loss:  0.05015593 Validation Decoder Loss:  0.34807336
Encoder Loss:  0.06283932  || Decoder Loss:  0.04793302 Validation Decoder Loss:  0.34544683
Encoder Loss:  0.06162362  || Decoder Loss:  0.046069916 Validation Decoder Loss:  0.3432853
Encoder Loss:  0.059569836  || Decoder Loss:  0.04451637 Validation Decoder Loss:  0.34154248
Encoder Loss:  0.051905204  || Decoder Loss:  0.043250937 Validation Decoder Loss:  0.34016076
Encoder Loss:  0.048270453  || Decoder Loss:  0.042204127 Validation Decoder Loss:  0.3390361
Encoder Loss:  0.047269024  || Decoder Loss:  0.041283265 Validation Decoder Loss:  0.3381658
Encoder Loss:  0.046384346  || Decoder Loss:  0.040528286 Validation Decoder Loss:  0.33745137
Encoder Loss:  0.04561864  || Decoder Loss:  0.03985677 Validation Decoder Loss:  0.33675432
Encoder Loss:  0.045257043  || Decoder Loss:  0.03917476 Validation Decoder Loss:  0.33606988
Encoder Loss:  0.044988375  || Decoder Loss:  0.038576428 Validation Decoder Loss:  0.3354983
Encoder Loss:  0.04475922  || Decoder Loss:  0.038066853 Validation Decoder Loss:  0.33502093
Model: siamese_net_lr_0.00022836817971942397 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33502093
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 193, 10, 20, 1)    403       
_________________________________________________________________
dropout_111 (Dropout)        (None, 193, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_45 (Conv3DT (None, 220, 11, 20, 1)    57        
_________________________________________________________________
reshape_31 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 460
Trainable params: 460
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_113 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_115 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_38 (Conv2DT (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.074946396  || Decoder Loss:  0.066018485 Validation Decoder Loss:  0.365222
Encoder Loss:  0.075307466  || Decoder Loss:  0.066405736 Validation Decoder Loss:  0.36530125
Encoder Loss:  0.07568214  || Decoder Loss:  0.066807546 Validation Decoder Loss:  0.36534968
Encoder Loss:  0.076068334  || Decoder Loss:  0.06722175 Validation Decoder Loss:  0.36537308
Encoder Loss:  0.07646638  || Decoder Loss:  0.067648716 Validation Decoder Loss:  0.36537772
Encoder Loss:  0.07687694  || Decoder Loss:  0.06808913 Validation Decoder Loss:  0.36536986
Encoder Loss:  0.07730076  || Decoder Loss:  0.06854384 Validation Decoder Loss:  0.36535528
Encoder Loss:  0.07773867  || Decoder Loss:  0.06901362 Validation Decoder Loss:  0.36533898
Encoder Loss:  0.078191645  || Decoder Loss:  0.06949965 Validation Decoder Loss:  0.36532515
Encoder Loss:  0.07866077  || Decoder Loss:  0.07000304 Validation Decoder Loss:  0.3653171
Encoder Loss:  0.079147175  || Decoder Loss:  0.07052502 Validation Decoder Loss:  0.36531734
Encoder Loss:  0.07965217  || Decoder Loss:  0.07106695 Validation Decoder Loss:  0.36532786
Encoder Loss:  0.0801771  || Decoder Loss:  0.07163034 Validation Decoder Loss:  0.36535048
Encoder Loss:  0.08072346  || Decoder Loss:  0.072216734 Validation Decoder Loss:  0.36538678
Encoder Loss:  0.081292845  || Decoder Loss:  0.072827876 Validation Decoder Loss:  0.3654384
Encoder Loss:  0.08188691  || Decoder Loss:  0.07346558 Validation Decoder Loss:  0.36550695
Encoder Loss:  0.08250759  || Decoder Loss:  0.074131906 Validation Decoder Loss:  0.36559403
Encoder Loss:  0.083156936  || Decoder Loss:  0.07482893 Validation Decoder Loss:  0.36570135
Encoder Loss:  0.08383711  || Decoder Loss:  0.075559184 Validation Decoder Loss:  0.3658308
Encoder Loss:  0.08455062  || Decoder Loss:  0.076325245 Validation Decoder Loss:  0.3659845
Encoder Loss:  0.0853002  || Decoder Loss:  0.07713013 Validation Decoder Loss:  0.36616483
Encoder Loss:  0.08608892  || Decoder Loss:  0.07797707 Validation Decoder Loss:  0.3663746
Encoder Loss:  0.08692019  || Decoder Loss:  0.07886981 Validation Decoder Loss:  0.36661702
Encoder Loss:  0.0877979  || Decoder Loss:  0.079812504 Validation Decoder Loss:  0.36689577
Encoder Loss:  0.08872639  || Decoder Loss:  0.08080983 Validation Decoder Loss:  0.36721504
Encoder Loss:  0.08971067  || Decoder Loss:  0.08186719 Validation Decoder Loss:  0.36757982
Encoder Loss:  0.090756394  || Decoder Loss:  0.082990706 Validation Decoder Loss:  0.36799598
Encoder Loss:  0.09187031  || Decoder Loss:  0.084187604 Validation Decoder Loss:  0.3684705
Encoder Loss:  0.09306052  || Decoder Loss:  0.08546665 Validation Decoder Loss:  0.36901176
Encoder Loss:  0.09433699  || Decoder Loss:  0.08683849 Validation Decoder Loss:  0.36963034
Encoder Loss:  0.09571216  || Decoder Loss:  0.08831648 Validation Decoder Loss:  0.37033924
Encoder Loss:  0.097201385  || Decoder Loss:  0.08991697 Validation Decoder Loss:  0.3711547
Encoder Loss:  0.09882305  || Decoder Loss:  0.09165954 Validation Decoder Loss:  0.37209696
Encoder Loss:  0.10059896  || Decoder Loss:  0.09356741 Validation Decoder Loss:  0.3731912
Encoder Loss:  0.102555476  || Decoder Loss:  0.09566865 Validation Decoder Loss:  0.3744697
Encoder Loss:  0.104725055  || Decoder Loss:  0.09799778 Validation Decoder Loss:  0.37597454
Encoder Loss:  0.107149236  || Decoder Loss:  0.100598976 Validation Decoder Loss:  0.37776262
Encoder Loss:  0.109881684  || Decoder Loss:  0.103529006 Validation Decoder Loss:  0.37991285
Encoder Loss:  0.11299158  || Decoder Loss:  0.10686124 Validation Decoder Loss:  0.38253582
Encoder Loss:  0.11656832  || Decoder Loss:  0.11069003 Validation Decoder Loss:  0.38579106
Model: siamese_net_lr_9.990820799523469e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38579106
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 116, 5, 20, 1)     54        
_________________________________________________________________
dropout_117 (Dropout)        (None, 116, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_48 (Conv3DT (None, 220, 11, 20, 1)    736       
_________________________________________________________________
reshape_32 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 790
Trainable params: 790
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_119 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_121 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_40 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13194235  || Decoder Loss:  0.108477935 Validation Decoder Loss:  0.38560253
Encoder Loss:  0.13849652  || Decoder Loss:  0.11723347 Validation Decoder Loss:  0.3942629
Encoder Loss:  0.21937247  || Decoder Loss:  0.21364017 Validation Decoder Loss:  1.0699213
Encoder Loss:  0.20572253  || Decoder Loss:  0.21658082 Validation Decoder Loss:  0.3575517
Encoder Loss:  0.048535213  || Decoder Loss:  0.04370432 Validation Decoder Loss:  0.33851042
Encoder Loss:  0.04397418  || Decoder Loss:  0.03940399 Validation Decoder Loss:  0.33684438
Encoder Loss:  0.04170624  || Decoder Loss:  0.03794603 Validation Decoder Loss:  0.3352577
Encoder Loss:  0.039148897  || Decoder Loss:  0.03681945 Validation Decoder Loss:  0.333992
Encoder Loss:  0.037389167  || Decoder Loss:  0.035887778 Validation Decoder Loss:  0.33290386
Encoder Loss:  0.036941  || Decoder Loss:  0.035400137 Validation Decoder Loss:  0.33254507
Encoder Loss:  0.036733724  || Decoder Loss:  0.035172407 Validation Decoder Loss:  0.33245686
Encoder Loss:  0.036600698  || Decoder Loss:  0.035027556 Validation Decoder Loss:  0.3325109
Encoder Loss:  0.03652029  || Decoder Loss:  0.03494025 Validation Decoder Loss:  0.3326152
Encoder Loss:  0.036461875  || Decoder Loss:  0.034877405 Validation Decoder Loss:  0.33271128
Encoder Loss:  0.036413606  || Decoder Loss:  0.03482583 Validation Decoder Loss:  0.3327918
Encoder Loss:  0.036371052  || Decoder Loss:  0.034780294 Validation Decoder Loss:  0.33285248
Encoder Loss:  0.0363318  || Decoder Loss:  0.034738537 Validation Decoder Loss:  0.3328978
Encoder Loss:  0.036293264  || Decoder Loss:  0.034698132 Validation Decoder Loss:  0.3329354
Encoder Loss:  0.036254324  || Decoder Loss:  0.03465721 Validation Decoder Loss:  0.33294937
Encoder Loss:  0.036211777  || Decoder Loss:  0.03461438 Validation Decoder Loss:  0.3329657
Encoder Loss:  0.036154665  || Decoder Loss:  0.034565095 Validation Decoder Loss:  0.3329395
Encoder Loss:  0.036036786  || Decoder Loss:  0.034513876 Validation Decoder Loss:  0.3329183
Encoder Loss:  0.03587666  || Decoder Loss:  0.034387074 Validation Decoder Loss:  0.33305323
Encoder Loss:  0.035713922  || Decoder Loss:  0.034226656 Validation Decoder Loss:  0.3332057
Encoder Loss:  0.035680335  || Decoder Loss:  0.034194235 Validation Decoder Loss:  0.33328247
Encoder Loss:  0.035674684  || Decoder Loss:  0.03418843 Validation Decoder Loss:  0.33333057
Encoder Loss:  0.03567255  || Decoder Loss:  0.034186114 Validation Decoder Loss:  0.33335203
Encoder Loss:  0.03567055  || Decoder Loss:  0.03418394 Validation Decoder Loss:  0.33337438
Encoder Loss:  0.035669874  || Decoder Loss:  0.03418336 Validation Decoder Loss:  0.3333975
Encoder Loss:  0.035671193  || Decoder Loss:  0.03418514 Validation Decoder Loss:  0.33342704
Encoder Loss:  0.035673577  || Decoder Loss:  0.03418795 Validation Decoder Loss:  0.3334555
Encoder Loss:  0.035677064  || Decoder Loss:  0.034192022 Validation Decoder Loss:  0.33349878
Encoder Loss:  0.035683587  || Decoder Loss:  0.03419951 Validation Decoder Loss:  0.3335408
Encoder Loss:  0.035692867  || Decoder Loss:  0.034209847 Validation Decoder Loss:  0.33358508
Encoder Loss:  0.03570542  || Decoder Loss:  0.03422385 Validation Decoder Loss:  0.33364096
Encoder Loss:  0.035720766  || Decoder Loss:  0.034241065 Validation Decoder Loss:  0.33369812
Encoder Loss:  0.035738524  || Decoder Loss:  0.03426068 Validation Decoder Loss:  0.33375233
Encoder Loss:  0.035756394  || Decoder Loss:  0.034280676 Validation Decoder Loss:  0.33381277
Encoder Loss:  0.03578176  || Decoder Loss:  0.034308795 Validation Decoder Loss:  0.3338604
Encoder Loss:  0.03580507  || Decoder Loss:  0.034334797 Validation Decoder Loss:  0.33392692
Model: siamese_net_lr_0.000509055377572285 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33392695
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 110, 11, 20, 1)    142       
_________________________________________________________________
dropout_123 (Dropout)        (None, 110, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_51 (Conv3DT (None, 220, 11, 20, 1)    3         
_________________________________________________________________
reshape_33 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 145
Trainable params: 145
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_125 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_127 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_42 (Conv2DT (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08540157  || Decoder Loss:  0.038652137 Validation Decoder Loss:  0.33191815
Encoder Loss:  0.039452992  || Decoder Loss:  0.034833964 Validation Decoder Loss:  0.32983682
Encoder Loss:  0.038540315  || Decoder Loss:  0.034063563 Validation Decoder Loss:  0.3296988
Encoder Loss:  0.038446546  || Decoder Loss:  0.03393819 Validation Decoder Loss:  0.33002573
Encoder Loss:  0.038403  || Decoder Loss:  0.033881515 Validation Decoder Loss:  0.33020264
Encoder Loss:  0.03836367  || Decoder Loss:  0.033829793 Validation Decoder Loss:  0.3303053
Encoder Loss:  0.03832438  || Decoder Loss:  0.033776995 Validation Decoder Loss:  0.33037308
Encoder Loss:  0.03828855  || Decoder Loss:  0.03372644 Validation Decoder Loss:  0.33044994
Encoder Loss:  0.03825481  || Decoder Loss:  0.033678778 Validation Decoder Loss:  0.33047268
Encoder Loss:  0.03821897  || Decoder Loss:  0.033630863 Validation Decoder Loss:  0.33056077
Encoder Loss:  0.038185116  || Decoder Loss:  0.03358481 Validation Decoder Loss:  0.33053857
Encoder Loss:  0.038154043  || Decoder Loss:  0.03354051 Validation Decoder Loss:  0.33072728
Encoder Loss:  0.038125273  || Decoder Loss:  0.033499952 Validation Decoder Loss:  0.33056778
Encoder Loss:  0.038097724  || Decoder Loss:  0.033462156 Validation Decoder Loss:  0.33054245
Encoder Loss:  0.038073547  || Decoder Loss:  0.03342869 Validation Decoder Loss:  0.33010688
Encoder Loss:  0.038052127  || Decoder Loss:  0.033398576 Validation Decoder Loss:  0.33086783
Encoder Loss:  0.038041133  || Decoder Loss:  0.03338338 Validation Decoder Loss:  0.3290581
Encoder Loss:  0.038014974  || Decoder Loss:  0.03334778 Validation Decoder Loss:  0.330068
Encoder Loss:  0.03799865  || Decoder Loss:  0.033324987 Validation Decoder Loss:  0.330127
Encoder Loss:  0.0379855  || Decoder Loss:  0.033307012 Validation Decoder Loss:  0.3312021
Encoder Loss:  0.037989322  || Decoder Loss:  0.033311106 Validation Decoder Loss:  0.32759383
Encoder Loss:  0.037978586  || Decoder Loss:  0.033298656 Validation Decoder Loss:  0.32834795
Encoder Loss:  0.037961736  || Decoder Loss:  0.033275835 Validation Decoder Loss:  0.33028102
Encoder Loss:  0.037947666  || Decoder Loss:  0.03325552 Validation Decoder Loss:  0.33046362
Encoder Loss:  0.037947703  || Decoder Loss:  0.033255115 Validation Decoder Loss:  0.3277098
Encoder Loss:  0.03794813  || Decoder Loss:  0.033256534 Validation Decoder Loss:  0.32821995
Encoder Loss:  0.037939142  || Decoder Loss:  0.03324481 Validation Decoder Loss:  0.32813242
Encoder Loss:  0.0379348  || Decoder Loss:  0.033238262 Validation Decoder Loss:  0.32765988
Encoder Loss:  0.037930116  || Decoder Loss:  0.033231445 Validation Decoder Loss:  0.32806927
Encoder Loss:  0.03792563  || Decoder Loss:  0.03322573 Validation Decoder Loss:  0.32855403
Encoder Loss:  0.03791711  || Decoder Loss:  0.033212513 Validation Decoder Loss:  0.3307883
Encoder Loss:  0.037908167  || Decoder Loss:  0.033201817 Validation Decoder Loss:  0.32983744
Encoder Loss:  0.03790861  || Decoder Loss:  0.033201706 Validation Decoder Loss:  0.32792225
Encoder Loss:  0.03790526  || Decoder Loss:  0.033197083 Validation Decoder Loss:  0.33121884
Encoder Loss:  0.03789738  || Decoder Loss:  0.03318782 Validation Decoder Loss:  0.33004293
Encoder Loss:  0.037898473  || Decoder Loss:  0.033188857 Validation Decoder Loss:  0.33103555
Encoder Loss:  0.037898723  || Decoder Loss:  0.033189345 Validation Decoder Loss:  0.33116347
Encoder Loss:  0.037895516  || Decoder Loss:  0.033184122 Validation Decoder Loss:  0.32904536
Encoder Loss:  0.03789774  || Decoder Loss:  0.033187553 Validation Decoder Loss:  0.32903305
Encoder Loss:  0.03789206  || Decoder Loss:  0.033179592 Validation Decoder Loss:  0.3302948
Model: siamese_net_lr_0.0009359830839807628 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3302948
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 110, 11, 20, 1)    142       
_________________________________________________________________
dropout_129 (Dropout)        (None, 110, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_54 (Conv3DT (None, 220, 11, 20, 1)    3         
_________________________________________________________________
reshape_34 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 145
Trainable params: 145
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_131 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_133 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_44 (Conv2DT (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43088707  || Decoder Loss:  0.04110663 Validation Decoder Loss:  0.34157687
Encoder Loss:  0.41102877  || Decoder Loss:  0.0414323 Validation Decoder Loss:  0.33982894
Encoder Loss:  0.35195747  || Decoder Loss:  0.042064942 Validation Decoder Loss:  0.33753803
Encoder Loss:  0.20724392  || Decoder Loss:  0.04128261 Validation Decoder Loss:  0.3323266
Encoder Loss:  0.057126198  || Decoder Loss:  0.036479555 Validation Decoder Loss:  0.33137155
Encoder Loss:  0.056723572  || Decoder Loss:  0.03610464 Validation Decoder Loss:  0.33057827
Encoder Loss:  0.0565197  || Decoder Loss:  0.03584323 Validation Decoder Loss:  0.3302127
Encoder Loss:  0.056327056  || Decoder Loss:  0.035603877 Validation Decoder Loss:  0.3301286
Encoder Loss:  0.056082502  || Decoder Loss:  0.035342272 Validation Decoder Loss:  0.33016998
Encoder Loss:  0.05576152  || Decoder Loss:  0.03505163 Validation Decoder Loss:  0.3301301
Encoder Loss:  0.055211693  || Decoder Loss:  0.034796476 Validation Decoder Loss:  0.3297307
Encoder Loss:  0.05377971  || Decoder Loss:  0.03461993 Validation Decoder Loss:  0.32923692
Encoder Loss:  0.051910616  || Decoder Loss:  0.034504153 Validation Decoder Loss:  0.32861245
Encoder Loss:  0.051014375  || Decoder Loss:  0.034414083 Validation Decoder Loss:  0.32817733
Encoder Loss:  0.050464056  || Decoder Loss:  0.034333896 Validation Decoder Loss:  0.32795778
Encoder Loss:  0.050022453  || Decoder Loss:  0.034267727 Validation Decoder Loss:  0.32775378
Encoder Loss:  0.049669456  || Decoder Loss:  0.034216765 Validation Decoder Loss:  0.32786113
Encoder Loss:  0.049491182  || Decoder Loss:  0.034181327 Validation Decoder Loss:  0.3280274
Encoder Loss:  0.04943201  || Decoder Loss:  0.034164153 Validation Decoder Loss:  0.32801896
Encoder Loss:  0.049416494  || Decoder Loss:  0.034151584 Validation Decoder Loss:  0.32802135
Encoder Loss:  0.049407467  || Decoder Loss:  0.034139022 Validation Decoder Loss:  0.32805687
Encoder Loss:  0.049402036  || Decoder Loss:  0.034125637 Validation Decoder Loss:  0.3280717
Encoder Loss:  0.049398627  || Decoder Loss:  0.034112986 Validation Decoder Loss:  0.32805037
Encoder Loss:  0.04939594  || Decoder Loss:  0.03410028 Validation Decoder Loss:  0.32805952
Encoder Loss:  0.04939376  || Decoder Loss:  0.034085974 Validation Decoder Loss:  0.32816657
Encoder Loss:  0.049392413  || Decoder Loss:  0.03407085 Validation Decoder Loss:  0.3281946
Encoder Loss:  0.04939039  || Decoder Loss:  0.034057394 Validation Decoder Loss:  0.3281318
Encoder Loss:  0.04939067  || Decoder Loss:  0.034038614 Validation Decoder Loss:  0.32827818
Encoder Loss:  0.04938884  || Decoder Loss:  0.03402767 Validation Decoder Loss:  0.32833415
Encoder Loss:  0.049386263  || Decoder Loss:  0.034015726 Validation Decoder Loss:  0.32823604
Encoder Loss:  0.04938565  || Decoder Loss:  0.034003533 Validation Decoder Loss:  0.32823938
Encoder Loss:  0.049384385  || Decoder Loss:  0.033995245 Validation Decoder Loss:  0.32798344
Encoder Loss:  0.049384266  || Decoder Loss:  0.033984717 Validation Decoder Loss:  0.3281032
Encoder Loss:  0.049382955  || Decoder Loss:  0.033972796 Validation Decoder Loss:  0.32799235
Encoder Loss:  0.049382705  || Decoder Loss:  0.033960655 Validation Decoder Loss:  0.32808828
Encoder Loss:  0.049381036  || Decoder Loss:  0.03395247 Validation Decoder Loss:  0.32805407
Encoder Loss:  0.049380388  || Decoder Loss:  0.033944238 Validation Decoder Loss:  0.32792884
Encoder Loss:  0.0493801  || Decoder Loss:  0.033938084 Validation Decoder Loss:  0.32802182
Encoder Loss:  0.049378633  || Decoder Loss:  0.033925056 Validation Decoder Loss:  0.32811505
Encoder Loss:  0.049377747  || Decoder Loss:  0.033921644 Validation Decoder Loss:  0.32791615
Model: siamese_net_lr_0.00013249375584208545 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32791612
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 122, 10, 20, 1)    119       
_________________________________________________________________
dropout_135 (Dropout)        (None, 122, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_57 (Conv3DT (None, 220, 11, 20, 1)    199       
_________________________________________________________________
reshape_35 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_137 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_139 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_46 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2574177  || Decoder Loss:  0.11823635 Validation Decoder Loss:  0.4130833
Encoder Loss:  0.13395838  || Decoder Loss:  0.13388868 Validation Decoder Loss:  0.3349822
Encoder Loss:  0.066509455  || Decoder Loss:  0.044149444 Validation Decoder Loss:  0.33054027
Encoder Loss:  0.048426114  || Decoder Loss:  0.03612265 Validation Decoder Loss:  0.32815838
Encoder Loss:  0.044622798  || Decoder Loss:  0.035154328 Validation Decoder Loss:  0.3284399
Encoder Loss:  0.04458152  || Decoder Loss:  0.03511455 Validation Decoder Loss:  0.32876927
Encoder Loss:  0.044564083  || Decoder Loss:  0.03509257 Validation Decoder Loss:  0.3289899
Encoder Loss:  0.044538926  || Decoder Loss:  0.035077713 Validation Decoder Loss:  0.3291766
Encoder Loss:  0.044517335  || Decoder Loss:  0.035065867 Validation Decoder Loss:  0.3293773
Encoder Loss:  0.04449909  || Decoder Loss:  0.03505484 Validation Decoder Loss:  0.3296119
Encoder Loss:  0.044466853  || Decoder Loss:  0.035043776 Validation Decoder Loss:  0.32983246
Encoder Loss:  0.044443175  || Decoder Loss:  0.035030395 Validation Decoder Loss:  0.33008718
Encoder Loss:  0.044398524  || Decoder Loss:  0.035014044 Validation Decoder Loss:  0.3303144
Encoder Loss:  0.044301763  || Decoder Loss:  0.034994088 Validation Decoder Loss:  0.33051717
Encoder Loss:  0.043593775  || Decoder Loss:  0.03492814 Validation Decoder Loss:  0.33048967
Encoder Loss:  0.043139797  || Decoder Loss:  0.0348603 Validation Decoder Loss:  0.3306309
Encoder Loss:  0.043122783  || Decoder Loss:  0.03485746 Validation Decoder Loss:  0.33074605
Encoder Loss:  0.043111797  || Decoder Loss:  0.03485857 Validation Decoder Loss:  0.33083636
Encoder Loss:  0.043104514  || Decoder Loss:  0.034864098 Validation Decoder Loss:  0.33092088
Encoder Loss:  0.043098852  || Decoder Loss:  0.03487584 Validation Decoder Loss:  0.3310011
Encoder Loss:  0.043096725  || Decoder Loss:  0.034884125 Validation Decoder Loss:  0.33107644
Encoder Loss:  0.043095585  || Decoder Loss:  0.034889992 Validation Decoder Loss:  0.3311418
Encoder Loss:  0.043090824  || Decoder Loss:  0.03488665 Validation Decoder Loss:  0.33119467
Encoder Loss:  0.043083884  || Decoder Loss:  0.034880802 Validation Decoder Loss:  0.3312616
Encoder Loss:  0.04307285  || Decoder Loss:  0.03486283 Validation Decoder Loss:  0.3313373
Encoder Loss:  0.043056358  || Decoder Loss:  0.03483312 Validation Decoder Loss:  0.33141077
Encoder Loss:  0.043032635  || Decoder Loss:  0.034783762 Validation Decoder Loss:  0.3314798
Encoder Loss:  0.042997103  || Decoder Loss:  0.034713373 Validation Decoder Loss:  0.33161998
Encoder Loss:  0.042949867  || Decoder Loss:  0.034620307 Validation Decoder Loss:  0.33207023
Encoder Loss:  0.042894274  || Decoder Loss:  0.034502577 Validation Decoder Loss:  0.33278668
Encoder Loss:  0.042832986  || Decoder Loss:  0.034376334 Validation Decoder Loss:  0.33336303
Encoder Loss:  0.042784587  || Decoder Loss:  0.03426962 Validation Decoder Loss:  0.33386615
Encoder Loss:  0.04274692  || Decoder Loss:  0.034192566 Validation Decoder Loss:  0.334238
Encoder Loss:  0.04272517  || Decoder Loss:  0.034142975 Validation Decoder Loss:  0.33443442
Encoder Loss:  0.042717453  || Decoder Loss:  0.034129143 Validation Decoder Loss:  0.3345086
Encoder Loss:  0.042712826  || Decoder Loss:  0.03411963 Validation Decoder Loss:  0.3345358
Encoder Loss:  0.04271141  || Decoder Loss:  0.034118343 Validation Decoder Loss:  0.3345073
Encoder Loss:  0.042716764  || Decoder Loss:  0.034130782 Validation Decoder Loss:  0.3344431
Encoder Loss:  0.042717434  || Decoder Loss:  0.034133065 Validation Decoder Loss:  0.3343634
Encoder Loss:  0.042723883  || Decoder Loss:  0.03414754 Validation Decoder Loss:  0.33430284
Model: siamese_net_lr_0.0006025123928952144 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33430284
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 205, 6, 20, 1)     285       
_________________________________________________________________
dropout_141 (Dropout)        (None, 205, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_60 (Conv3DT (None, 220, 11, 20, 1)    97        
_________________________________________________________________
reshape_36 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_143 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_145 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_48 (Conv2DT (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2720399  || Decoder Loss:  0.058850583 Validation Decoder Loss:  0.36072057
Encoder Loss:  0.26708993  || Decoder Loss:  0.06546636 Validation Decoder Loss:  0.36180633
Encoder Loss:  0.26030886  || Decoder Loss:  0.08470565 Validation Decoder Loss:  0.3784967
Encoder Loss:  0.2324752  || Decoder Loss:  0.19947979 Validation Decoder Loss:  0.6414304
Encoder Loss:  0.09971742  || Decoder Loss:  0.13031544 Validation Decoder Loss:  0.3674689
Encoder Loss:  0.068431854  || Decoder Loss:  0.04745197 Validation Decoder Loss:  0.36118504
Encoder Loss:  0.06717469  || Decoder Loss:  0.045206875 Validation Decoder Loss:  0.3569791
Encoder Loss:  0.06598681  || Decoder Loss:  0.043361563 Validation Decoder Loss:  0.35331613
Encoder Loss:  0.06482418  || Decoder Loss:  0.041557826 Validation Decoder Loss:  0.34964812
Encoder Loss:  0.063329645  || Decoder Loss:  0.039183117 Validation Decoder Loss:  0.34042716
Encoder Loss:  0.060586058  || Decoder Loss:  0.035944447 Validation Decoder Loss:  0.3332062
Encoder Loss:  0.046909127  || Decoder Loss:  0.03454482 Validation Decoder Loss:  0.3317591
Encoder Loss:  0.04509847  || Decoder Loss:  0.03424948 Validation Decoder Loss:  0.33103043
Encoder Loss:  0.044783972  || Decoder Loss:  0.034150384 Validation Decoder Loss:  0.33043355
Encoder Loss:  0.044535432  || Decoder Loss:  0.034092143 Validation Decoder Loss:  0.3299812
Encoder Loss:  0.04430526  || Decoder Loss:  0.034037005 Validation Decoder Loss:  0.32969683
Encoder Loss:  0.044191126  || Decoder Loss:  0.033995684 Validation Decoder Loss:  0.32971123
Encoder Loss:  0.044172626  || Decoder Loss:  0.033967406 Validation Decoder Loss:  0.32969612
Encoder Loss:  0.044165898  || Decoder Loss:  0.033944923 Validation Decoder Loss:  0.3297174
Encoder Loss:  0.04415667  || Decoder Loss:  0.033925362 Validation Decoder Loss:  0.3298084
Encoder Loss:  0.044151653  || Decoder Loss:  0.033908036 Validation Decoder Loss:  0.32992324
Encoder Loss:  0.04414454  || Decoder Loss:  0.03389284 Validation Decoder Loss:  0.33012253
Encoder Loss:  0.04413776  || Decoder Loss:  0.0338785 Validation Decoder Loss:  0.33022347
Encoder Loss:  0.04413433  || Decoder Loss:  0.033865638 Validation Decoder Loss:  0.33035046
Encoder Loss:  0.044126052  || Decoder Loss:  0.03385305 Validation Decoder Loss:  0.33043402
Encoder Loss:  0.044123918  || Decoder Loss:  0.03384223 Validation Decoder Loss:  0.3305093
Encoder Loss:  0.044117883  || Decoder Loss:  0.03383115 Validation Decoder Loss:  0.33055627
Encoder Loss:  0.044116527  || Decoder Loss:  0.033820957 Validation Decoder Loss:  0.3306174
Encoder Loss:  0.044113465  || Decoder Loss:  0.0338112 Validation Decoder Loss:  0.33064118
Encoder Loss:  0.044108458  || Decoder Loss:  0.033802073 Validation Decoder Loss:  0.33065358
Encoder Loss:  0.044102743  || Decoder Loss:  0.033793185 Validation Decoder Loss:  0.3306178
Encoder Loss:  0.044103157  || Decoder Loss:  0.033784952 Validation Decoder Loss:  0.33056232
Encoder Loss:  0.044096924  || Decoder Loss:  0.0337773 Validation Decoder Loss:  0.3305508
Encoder Loss:  0.044096883  || Decoder Loss:  0.033770796 Validation Decoder Loss:  0.33052957
Encoder Loss:  0.04409793  || Decoder Loss:  0.03376188 Validation Decoder Loss:  0.33054852
Encoder Loss:  0.04408865  || Decoder Loss:  0.03375325 Validation Decoder Loss:  0.33067864
Encoder Loss:  0.044089347  || Decoder Loss:  0.033745922 Validation Decoder Loss:  0.33074602
Encoder Loss:  0.044083558  || Decoder Loss:  0.033738017 Validation Decoder Loss:  0.33091822
Encoder Loss:  0.04408113  || Decoder Loss:  0.033730846 Validation Decoder Loss:  0.33098668
Encoder Loss:  0.044077504  || Decoder Loss:  0.03372418 Validation Decoder Loss:  0.33101887
Model: siamese_net_lr_0.00041290854272032763 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33101887
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 193, 10, 20, 1)    403       
_________________________________________________________________
dropout_147 (Dropout)        (None, 193, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_63 (Conv3DT (None, 220, 11, 20, 1)    57        
_________________________________________________________________
reshape_37 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 460
Trainable params: 460
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_149 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_151 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_50 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37029353  || Decoder Loss:  0.06656934 Validation Decoder Loss:  0.36561558
Encoder Loss:  0.3683791  || Decoder Loss:  0.06803557 Validation Decoder Loss:  0.36559594
Encoder Loss:  0.36613494  || Decoder Loss:  0.06973842 Validation Decoder Loss:  0.36554772
Encoder Loss:  0.36344472  || Decoder Loss:  0.071761765 Validation Decoder Loss:  0.36563683
Encoder Loss:  0.3601367  || Decoder Loss:  0.07423118 Validation Decoder Loss:  0.36602265
Encoder Loss:  0.3559395  || Decoder Loss:  0.0773445 Validation Decoder Loss:  0.36693072
Encoder Loss:  0.3503868  || Decoder Loss:  0.08144327 Validation Decoder Loss:  0.36873353
Encoder Loss:  0.34259048  || Decoder Loss:  0.08719287 Validation Decoder Loss:  0.37221184
Encoder Loss:  0.33062354  || Decoder Loss:  0.09616067 Validation Decoder Loss:  0.37961227
Encoder Loss:  0.30950922  || Decoder Loss:  0.113189824 Validation Decoder Loss:  0.40124816
Encoder Loss:  0.26138353  || Decoder Loss:  0.16239023 Validation Decoder Loss:  0.54658157
Encoder Loss:  0.13708058  || Decoder Loss:  0.26442468 Validation Decoder Loss:  0.6399087
Encoder Loss:  0.10059352  || Decoder Loss:  0.17094804 Validation Decoder Loss:  0.50206715
Encoder Loss:  0.09234443  || Decoder Loss:  0.10940175 Validation Decoder Loss:  0.4294849
Encoder Loss:  0.089515865  || Decoder Loss:  0.08830091 Validation Decoder Loss:  0.401973
Encoder Loss:  0.08751378  || Decoder Loss:  0.07422013 Validation Decoder Loss:  0.3808628
Encoder Loss:  0.08574156  || Decoder Loss:  0.06306513 Validation Decoder Loss:  0.3652933
Encoder Loss:  0.08444006  || Decoder Loss:  0.05449681 Validation Decoder Loss:  0.35391304
Encoder Loss:  0.08322031  || Decoder Loss:  0.04812361 Validation Decoder Loss:  0.34588856
Encoder Loss:  0.08179529  || Decoder Loss:  0.043630295 Validation Decoder Loss:  0.3406722
Encoder Loss:  0.074142694  || Decoder Loss:  0.040648594 Validation Decoder Loss:  0.33747938
Encoder Loss:  0.050864782  || Decoder Loss:  0.038806878 Validation Decoder Loss:  0.33547843
Encoder Loss:  0.04903015  || Decoder Loss:  0.037690643 Validation Decoder Loss:  0.33431217
Encoder Loss:  0.048357476  || Decoder Loss:  0.03698031 Validation Decoder Loss:  0.33361214
Encoder Loss:  0.048287857  || Decoder Loss:  0.03651724 Validation Decoder Loss:  0.33322307
Encoder Loss:  0.048245803  || Decoder Loss:  0.036206886 Validation Decoder Loss:  0.33293292
Encoder Loss:  0.048214912  || Decoder Loss:  0.03598093 Validation Decoder Loss:  0.33270475
Encoder Loss:  0.04819105  || Decoder Loss:  0.035809904 Validation Decoder Loss:  0.33252212
Encoder Loss:  0.048172794  || Decoder Loss:  0.035678342 Validation Decoder Loss:  0.33237422
Encoder Loss:  0.04815855  || Decoder Loss:  0.03557632 Validation Decoder Loss:  0.33225274
Encoder Loss:  0.048146456  || Decoder Loss:  0.035496693 Validation Decoder Loss:  0.3321494
Encoder Loss:  0.048137017  || Decoder Loss:  0.035434455 Validation Decoder Loss:  0.33206117
Encoder Loss:  0.048129693  || Decoder Loss:  0.035385117 Validation Decoder Loss:  0.33198774
Encoder Loss:  0.048123494  || Decoder Loss:  0.035345662 Validation Decoder Loss:  0.3319292
Encoder Loss:  0.048118614  || Decoder Loss:  0.035313502 Validation Decoder Loss:  0.3318842
Encoder Loss:  0.048114225  || Decoder Loss:  0.03528695 Validation Decoder Loss:  0.33184952
Encoder Loss:  0.048110157  || Decoder Loss:  0.03526454 Validation Decoder Loss:  0.33182383
Encoder Loss:  0.048108257  || Decoder Loss:  0.035245225 Validation Decoder Loss:  0.3318054
Encoder Loss:  0.048103675  || Decoder Loss:  0.035228346 Validation Decoder Loss:  0.33178928
Encoder Loss:  0.048102908  || Decoder Loss:  0.035213158 Validation Decoder Loss:  0.33178067
Model: siamese_net_lr_0.0003230674125156995 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33178067
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 116, 5, 20, 1)     54        
_________________________________________________________________
dropout_153 (Dropout)        (None, 116, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_66 (Conv3DT (None, 220, 11, 20, 1)    316       
_________________________________________________________________
reshape_38 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_155 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_157 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_52 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10400577  || Decoder Loss:  0.10400577 Validation Decoder Loss:  0.3854829
Encoder Loss:  0.0970048  || Decoder Loss:  0.0970048 Validation Decoder Loss:  0.3496388
Encoder Loss:  0.06352002  || Decoder Loss:  0.06352002 Validation Decoder Loss:  0.34036314
Encoder Loss:  0.048223615  || Decoder Loss:  0.048223615 Validation Decoder Loss:  0.33245647
Encoder Loss:  0.035530377  || Decoder Loss:  0.035530377 Validation Decoder Loss:  0.3292227
Encoder Loss:  0.03520857  || Decoder Loss:  0.03520857 Validation Decoder Loss:  0.32986045
Encoder Loss:  0.03511133  || Decoder Loss:  0.03511133 Validation Decoder Loss:  0.33032012
Encoder Loss:  0.035051547  || Decoder Loss:  0.035051547 Validation Decoder Loss:  0.33069354
Encoder Loss:  0.035004232  || Decoder Loss:  0.035004232 Validation Decoder Loss:  0.3311031
Encoder Loss:  0.034961656  || Decoder Loss:  0.034961656 Validation Decoder Loss:  0.33158866
Encoder Loss:  0.0349213  || Decoder Loss:  0.0349213 Validation Decoder Loss:  0.33202264
Encoder Loss:  0.034881998  || Decoder Loss:  0.034881998 Validation Decoder Loss:  0.3324402
Encoder Loss:  0.03484273  || Decoder Loss:  0.03484273 Validation Decoder Loss:  0.33285534
Encoder Loss:  0.03480301  || Decoder Loss:  0.03480301 Validation Decoder Loss:  0.33329576
Encoder Loss:  0.03476534  || Decoder Loss:  0.03476534 Validation Decoder Loss:  0.3340209
Encoder Loss:  0.034727518  || Decoder Loss:  0.034727518 Validation Decoder Loss:  0.33431274
Encoder Loss:  0.03468846  || Decoder Loss:  0.03468846 Validation Decoder Loss:  0.33454034
Encoder Loss:  0.03465079  || Decoder Loss:  0.03465079 Validation Decoder Loss:  0.33471683
Encoder Loss:  0.03461566  || Decoder Loss:  0.03461566 Validation Decoder Loss:  0.33485836
Encoder Loss:  0.034583926  || Decoder Loss:  0.034583926 Validation Decoder Loss:  0.3349738
Encoder Loss:  0.034556206  || Decoder Loss:  0.034556206 Validation Decoder Loss:  0.33506623
Encoder Loss:  0.03453271  || Decoder Loss:  0.03453271 Validation Decoder Loss:  0.3351376
Encoder Loss:  0.034513175  || Decoder Loss:  0.034513175 Validation Decoder Loss:  0.3351909
Encoder Loss:  0.03449713  || Decoder Loss:  0.03449713 Validation Decoder Loss:  0.33522964
Encoder Loss:  0.034483925  || Decoder Loss:  0.034483925 Validation Decoder Loss:  0.33525676
Encoder Loss:  0.03447296  || Decoder Loss:  0.03447296 Validation Decoder Loss:  0.3352747
Encoder Loss:  0.034463674  || Decoder Loss:  0.034463674 Validation Decoder Loss:  0.33528516
Encoder Loss:  0.034455687  || Decoder Loss:  0.034455687 Validation Decoder Loss:  0.33528972
Encoder Loss:  0.03444863  || Decoder Loss:  0.03444863 Validation Decoder Loss:  0.33528954
Encoder Loss:  0.034442246  || Decoder Loss:  0.034442246 Validation Decoder Loss:  0.33528578
Encoder Loss:  0.03443647  || Decoder Loss:  0.03443647 Validation Decoder Loss:  0.33527923
Encoder Loss:  0.034431156  || Decoder Loss:  0.034431156 Validation Decoder Loss:  0.33527076
Encoder Loss:  0.0344262  || Decoder Loss:  0.0344262 Validation Decoder Loss:  0.33526075
Encoder Loss:  0.034421586  || Decoder Loss:  0.034421586 Validation Decoder Loss:  0.3352496
Encoder Loss:  0.034417227  || Decoder Loss:  0.034417227 Validation Decoder Loss:  0.33523756
Encoder Loss:  0.03441311  || Decoder Loss:  0.03441311 Validation Decoder Loss:  0.33522472
Encoder Loss:  0.034409203  || Decoder Loss:  0.034409203 Validation Decoder Loss:  0.33521134
Encoder Loss:  0.03440545  || Decoder Loss:  0.03440545 Validation Decoder Loss:  0.33519745
Encoder Loss:  0.03440188  || Decoder Loss:  0.03440188 Validation Decoder Loss:  0.33518323
Encoder Loss:  0.034398433  || Decoder Loss:  0.034398433 Validation Decoder Loss:  0.3351687
Model: siamese_net_lr_0.0005651167737482412 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33516872
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 205, 6, 20, 1)     159       
_________________________________________________________________
dropout_159 (Dropout)        (None, 205, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_69 (Conv3DT (None, 220, 11, 20, 1)    97        
_________________________________________________________________
reshape_39 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 256
Trainable params: 256
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_161 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_163 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_54 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3904543  || Decoder Loss:  0.055281416 Validation Decoder Loss:  0.3625015
Encoder Loss:  0.38199818  || Decoder Loss:  0.05863028 Validation Decoder Loss:  0.36463776
Encoder Loss:  0.3678914  || Decoder Loss:  0.06871236 Validation Decoder Loss:  0.3735013
Encoder Loss:  0.2601429  || Decoder Loss:  0.20152882 Validation Decoder Loss:  0.73281145
Encoder Loss:  0.10197429  || Decoder Loss:  0.23448803 Validation Decoder Loss:  0.437109
Encoder Loss:  0.09524506  || Decoder Loss:  0.06566371 Validation Decoder Loss:  0.3595718
Encoder Loss:  0.09393323  || Decoder Loss:  0.046803962 Validation Decoder Loss:  0.3540145
Encoder Loss:  0.08235786  || Decoder Loss:  0.043991122 Validation Decoder Loss:  0.3500726
Encoder Loss:  0.05186549  || Decoder Loss:  0.04259196 Validation Decoder Loss:  0.3479545
Encoder Loss:  0.05128023  || Decoder Loss:  0.0410699 Validation Decoder Loss:  0.3435434
Encoder Loss:  0.050519813  || Decoder Loss:  0.03806801 Validation Decoder Loss:  0.33310145
Encoder Loss:  0.049821302  || Decoder Loss:  0.035073604 Validation Decoder Loss:  0.33003604
Encoder Loss:  0.04975154  || Decoder Loss:  0.03449002 Validation Decoder Loss:  0.33031416
Encoder Loss:  0.049749386  || Decoder Loss:  0.03442745 Validation Decoder Loss:  0.33041626
Encoder Loss:  0.049746986  || Decoder Loss:  0.03439586 Validation Decoder Loss:  0.3304546
Encoder Loss:  0.04974489  || Decoder Loss:  0.034373183 Validation Decoder Loss:  0.3304648
Encoder Loss:  0.049742926  || Decoder Loss:  0.034354333 Validation Decoder Loss:  0.3304609
Encoder Loss:  0.04974003  || Decoder Loss:  0.034337193 Validation Decoder Loss:  0.33044836
Encoder Loss:  0.0497373  || Decoder Loss:  0.034321055 Validation Decoder Loss:  0.3304347
Encoder Loss:  0.04973562  || Decoder Loss:  0.034305636 Validation Decoder Loss:  0.33041263
Encoder Loss:  0.049732696  || Decoder Loss:  0.034290724 Validation Decoder Loss:  0.33038968
Encoder Loss:  0.049730126  || Decoder Loss:  0.03427626 Validation Decoder Loss:  0.33037132
Encoder Loss:  0.049727723  || Decoder Loss:  0.034262225 Validation Decoder Loss:  0.33036488
Encoder Loss:  0.049725663  || Decoder Loss:  0.034248363 Validation Decoder Loss:  0.33035326
Encoder Loss:  0.049722496  || Decoder Loss:  0.03423457 Validation Decoder Loss:  0.33031335
Encoder Loss:  0.049720116  || Decoder Loss:  0.03422049 Validation Decoder Loss:  0.33026642
Encoder Loss:  0.049717084  || Decoder Loss:  0.03420646 Validation Decoder Loss:  0.330235
Encoder Loss:  0.04971334  || Decoder Loss:  0.034192547 Validation Decoder Loss:  0.33020976
Encoder Loss:  0.049710542  || Decoder Loss:  0.034178462 Validation Decoder Loss:  0.33018452
Encoder Loss:  0.04970825  || Decoder Loss:  0.03416388 Validation Decoder Loss:  0.33015642
Encoder Loss:  0.04970459  || Decoder Loss:  0.034149498 Validation Decoder Loss:  0.33013973
Encoder Loss:  0.049700808  || Decoder Loss:  0.03413496 Validation Decoder Loss:  0.33013916
Encoder Loss:  0.049697436  || Decoder Loss:  0.03411874 Validation Decoder Loss:  0.33015996
Encoder Loss:  0.049693692  || Decoder Loss:  0.034106072 Validation Decoder Loss:  0.3301416
Encoder Loss:  0.04969045  || Decoder Loss:  0.034094844 Validation Decoder Loss:  0.3301189
Encoder Loss:  0.049687248  || Decoder Loss:  0.034084335 Validation Decoder Loss:  0.33010346
Encoder Loss:  0.049685106  || Decoder Loss:  0.0340745 Validation Decoder Loss:  0.33009043
Encoder Loss:  0.049682964  || Decoder Loss:  0.034064997 Validation Decoder Loss:  0.33007255
Encoder Loss:  0.04968092  || Decoder Loss:  0.034056216 Validation Decoder Loss:  0.33005294
Encoder Loss:  0.04967983  || Decoder Loss:  0.034047496 Validation Decoder Loss:  0.3300377
Model: siamese_net_lr_0.0007846925906913141 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3300377
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_165 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_72 (Conv3DT (None, 220, 11, 20, 1)    322       
_________________________________________________________________
reshape_40 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 374
Trainable params: 374
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_167 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_56 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_169 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_56 (Conv2DT (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2102956  || Decoder Loss:  0.1058086 Validation Decoder Loss:  0.38256782
Encoder Loss:  0.20466083  || Decoder Loss:  0.11113554 Validation Decoder Loss:  0.38741696
Encoder Loss:  0.20135891  || Decoder Loss:  0.12804031 Validation Decoder Loss:  0.44005257
Encoder Loss:  0.20611458  || Decoder Loss:  0.2683579 Validation Decoder Loss:  0.37414503
Encoder Loss:  0.0694431  || Decoder Loss:  0.053960256 Validation Decoder Loss:  0.35903907
Encoder Loss:  0.06261181  || Decoder Loss:  0.04451585 Validation Decoder Loss:  0.3414374
Encoder Loss:  0.057074312  || Decoder Loss:  0.03852185 Validation Decoder Loss:  0.3345914
Encoder Loss:  0.042840652  || Decoder Loss:  0.03674334 Validation Decoder Loss:  0.3335719
Encoder Loss:  0.04168165  || Decoder Loss:  0.036187395 Validation Decoder Loss:  0.33298278
Encoder Loss:  0.041539293  || Decoder Loss:  0.03597703 Validation Decoder Loss:  0.33275265
Encoder Loss:  0.041427698  || Decoder Loss:  0.03579979 Validation Decoder Loss:  0.33259484
Encoder Loss:  0.04134336  || Decoder Loss:  0.035664458 Validation Decoder Loss:  0.332474
Encoder Loss:  0.041279696  || Decoder Loss:  0.0355612 Validation Decoder Loss:  0.3323697
Encoder Loss:  0.041230172  || Decoder Loss:  0.035480235 Validation Decoder Loss:  0.3322811
Encoder Loss:  0.041189086  || Decoder Loss:  0.03541313 Validation Decoder Loss:  0.33221424
Encoder Loss:  0.041157108  || Decoder Loss:  0.035360537 Validation Decoder Loss:  0.33215827
Encoder Loss:  0.04113087  || Decoder Loss:  0.035317633 Validation Decoder Loss:  0.3321159
Encoder Loss:  0.04111094  || Decoder Loss:  0.035284925 Validation Decoder Loss:  0.33208042
Encoder Loss:  0.04109732  || Decoder Loss:  0.035262693 Validation Decoder Loss:  0.33204582
Encoder Loss:  0.041087404  || Decoder Loss:  0.035246674 Validation Decoder Loss:  0.33201182
Encoder Loss:  0.041081246  || Decoder Loss:  0.03523661 Validation Decoder Loss:  0.33197442
Encoder Loss:  0.041077748  || Decoder Loss:  0.035231147 Validation Decoder Loss:  0.33194095
Encoder Loss:  0.041075863  || Decoder Loss:  0.035227977 Validation Decoder Loss:  0.331926
Encoder Loss:  0.041076012  || Decoder Loss:  0.03522824 Validation Decoder Loss:  0.3319372
Encoder Loss:  0.041076366  || Decoder Loss:  0.035228975 Validation Decoder Loss:  0.3319639
Encoder Loss:  0.04107681  || Decoder Loss:  0.035229795 Validation Decoder Loss:  0.33197707
Encoder Loss:  0.04107773  || Decoder Loss:  0.03523138 Validation Decoder Loss:  0.33197337
Encoder Loss:  0.041078914  || Decoder Loss:  0.035233647 Validation Decoder Loss:  0.3319785
Encoder Loss:  0.04107935  || Decoder Loss:  0.035234403 Validation Decoder Loss:  0.33197096
Encoder Loss:  0.041081093  || Decoder Loss:  0.035237685 Validation Decoder Loss:  0.33196276
Encoder Loss:  0.04108282  || Decoder Loss:  0.035240743 Validation Decoder Loss:  0.3319416
Encoder Loss:  0.041083407  || Decoder Loss:  0.035241917 Validation Decoder Loss:  0.3319313
Encoder Loss:  0.041085538  || Decoder Loss:  0.03524575 Validation Decoder Loss:  0.33189255
Encoder Loss:  0.041087914  || Decoder Loss:  0.03524934 Validation Decoder Loss:  0.33185053
Encoder Loss:  0.041090168  || Decoder Loss:  0.0352529 Validation Decoder Loss:  0.33180124
Encoder Loss:  0.041091103  || Decoder Loss:  0.0352554 Validation Decoder Loss:  0.3317594
Encoder Loss:  0.04109236  || Decoder Loss:  0.035257436 Validation Decoder Loss:  0.33173418
Encoder Loss:  0.04109423  || Decoder Loss:  0.035260897 Validation Decoder Loss:  0.33169657
Encoder Loss:  0.041095167  || Decoder Loss:  0.035262585 Validation Decoder Loss:  0.33168435
Encoder Loss:  0.04109657  || Decoder Loss:  0.035265166 Validation Decoder Loss:  0.33166623
Model: siamese_net_lr_0.0009385309490998557 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33166623
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_171 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_75 (Conv3DT (None, 220, 11, 20, 1)    722       
_________________________________________________________________
reshape_41 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_173 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_175 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_58 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16578196  || Decoder Loss:  0.11205569 Validation Decoder Loss:  0.39270312
Encoder Loss:  0.2349758  || Decoder Loss:  0.2412541 Validation Decoder Loss:  0.40540862
Encoder Loss:  0.058290407  || Decoder Loss:  0.049097646 Validation Decoder Loss:  0.33848798
Encoder Loss:  0.043470692  || Decoder Loss:  0.03710523 Validation Decoder Loss:  0.33301696
Encoder Loss:  0.03880858  || Decoder Loss:  0.035057295 Validation Decoder Loss:  0.33290064
Encoder Loss:  0.038546864  || Decoder Loss:  0.034739185 Validation Decoder Loss:  0.33300394
Encoder Loss:  0.038416546  || Decoder Loss:  0.034584735 Validation Decoder Loss:  0.33313724
Encoder Loss:  0.038313374  || Decoder Loss:  0.03446659 Validation Decoder Loss:  0.3332303
Encoder Loss:  0.038159825  || Decoder Loss:  0.034363333 Validation Decoder Loss:  0.3332886
Encoder Loss:  0.038014017  || Decoder Loss:  0.03453296 Validation Decoder Loss:  0.33358213
Encoder Loss:  0.03804043  || Decoder Loss:  0.034588087 Validation Decoder Loss:  0.3337075
Encoder Loss:  0.038064376  || Decoder Loss:  0.034620088 Validation Decoder Loss:  0.33382618
Encoder Loss:  0.038094513  || Decoder Loss:  0.034659024 Validation Decoder Loss:  0.3339072
Encoder Loss:  0.03812145  || Decoder Loss:  0.034694508 Validation Decoder Loss:  0.33397377
Encoder Loss:  0.03814364  || Decoder Loss:  0.03472392 Validation Decoder Loss:  0.33403277
Encoder Loss:  0.03816445  || Decoder Loss:  0.034751937 Validation Decoder Loss:  0.33409983
Encoder Loss:  0.0381829  || Decoder Loss:  0.034774452 Validation Decoder Loss:  0.33414394
Encoder Loss:  0.038194485  || Decoder Loss:  0.034791317 Validation Decoder Loss:  0.3341995
Encoder Loss:  0.03820518  || Decoder Loss:  0.034804177 Validation Decoder Loss:  0.33425295
Encoder Loss:  0.03821003  || Decoder Loss:  0.03481166 Validation Decoder Loss:  0.33428887
Encoder Loss:  0.038214345  || Decoder Loss:  0.03481648 Validation Decoder Loss:  0.33432335
Encoder Loss:  0.0382138  || Decoder Loss:  0.034816653 Validation Decoder Loss:  0.33434898
Encoder Loss:  0.038211554  || Decoder Loss:  0.03481495 Validation Decoder Loss:  0.33436656
Encoder Loss:  0.038210157  || Decoder Loss:  0.034813486 Validation Decoder Loss:  0.33441636
Encoder Loss:  0.038207497  || Decoder Loss:  0.03480938 Validation Decoder Loss:  0.3344432
Encoder Loss:  0.03820523  || Decoder Loss:  0.034805935 Validation Decoder Loss:  0.3344087
Encoder Loss:  0.038201917  || Decoder Loss:  0.034802623 Validation Decoder Loss:  0.33443135
Encoder Loss:  0.03820262  || Decoder Loss:  0.03480252 Validation Decoder Loss:  0.3344735
Encoder Loss:  0.038199306  || Decoder Loss:  0.034799043 Validation Decoder Loss:  0.33447558
Encoder Loss:  0.03819407  || Decoder Loss:  0.034793586 Validation Decoder Loss:  0.33447963
Encoder Loss:  0.03819249  || Decoder Loss:  0.03479135 Validation Decoder Loss:  0.33449805
Encoder Loss:  0.038190555  || Decoder Loss:  0.034789275 Validation Decoder Loss:  0.33451405
Encoder Loss:  0.03818928  || Decoder Loss:  0.034787882 Validation Decoder Loss:  0.33452302
Encoder Loss:  0.038188446  || Decoder Loss:  0.03478769 Validation Decoder Loss:  0.33453816
Encoder Loss:  0.03818965  || Decoder Loss:  0.03478834 Validation Decoder Loss:  0.33454862
Encoder Loss:  0.03818748  || Decoder Loss:  0.03478612 Validation Decoder Loss:  0.33457038
Encoder Loss:  0.038185395  || Decoder Loss:  0.034784157 Validation Decoder Loss:  0.33463562
Encoder Loss:  0.03818269  || Decoder Loss:  0.034779187 Validation Decoder Loss:  0.33463305
Encoder Loss:  0.038178116  || Decoder Loss:  0.034774896 Validation Decoder Loss:  0.33469486
Encoder Loss:  0.038173955  || Decoder Loss:  0.034767374 Validation Decoder Loss:  0.33462214
Model: siamese_net_lr_0.000981516958993881 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33462214
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 200, 6, 20, 1)     149       
_________________________________________________________________
dropout_177 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_78 (Conv3DT (None, 220, 11, 20, 1)    127       
_________________________________________________________________
reshape_42 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 276
Trainable params: 276
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_179 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_60 (Conv2D)           (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_181 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_60 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06345472  || Decoder Loss:  0.058215532 Validation Decoder Loss:  0.3644001
Encoder Loss:  0.06415511  || Decoder Loss:  0.058974613 Validation Decoder Loss:  0.36538896
Encoder Loss:  0.06496095  || Decoder Loss:  0.05983839 Validation Decoder Loss:  0.3662315
Encoder Loss:  0.065925084  || Decoder Loss:  0.060863227 Validation Decoder Loss:  0.36699432
Encoder Loss:  0.0671014  || Decoder Loss:  0.062105756 Validation Decoder Loss:  0.36770838
Encoder Loss:  0.06855959  || Decoder Loss:  0.06363818 Validation Decoder Loss:  0.3684142
Encoder Loss:  0.07039135  || Decoder Loss:  0.06555587 Validation Decoder Loss:  0.3692335
Encoder Loss:  0.07272723  || Decoder Loss:  0.06799435 Validation Decoder Loss:  0.37037647
Encoder Loss:  0.075772725  || Decoder Loss:  0.071166754 Validation Decoder Loss:  0.37204558
Encoder Loss:  0.07988679  || Decoder Loss:  0.07544405 Validation Decoder Loss:  0.37453562
Encoder Loss:  0.08569396  || Decoder Loss:  0.081469506 Validation Decoder Loss:  0.3785683
Encoder Loss:  0.0943651  || Decoder Loss:  0.09044922 Validation Decoder Loss:  0.38593066
Encoder Loss:  0.10850521  || Decoder Loss:  0.10506567 Validation Decoder Loss:  0.40192306
Encoder Loss:  0.13584618  || Decoder Loss:  0.13327724 Validation Decoder Loss:  0.45028314
Encoder Loss:  0.21118961  || Decoder Loss:  0.21088444 Validation Decoder Loss:  0.66448295
Encoder Loss:  0.32828033  || Decoder Loss:  0.33180496 Validation Decoder Loss:  0.7556051
Encoder Loss:  0.3032928  || Decoder Loss:  0.30660224 Validation Decoder Loss:  0.70666516
Encoder Loss:  0.26255515  || Decoder Loss:  0.26522955 Validation Decoder Loss:  0.63833505
Encoder Loss:  0.21013786  || Decoder Loss:  0.21199572 Validation Decoder Loss:  0.55044234
Encoder Loss:  0.15236434  || Decoder Loss:  0.15332231 Validation Decoder Loss:  0.46706253
Encoder Loss:  0.107234776  || Decoder Loss:  0.10749231 Validation Decoder Loss:  0.41723037
Encoder Loss:  0.083095625  || Decoder Loss:  0.08298349 Validation Decoder Loss:  0.39581066
Encoder Loss:  0.072178274  || Decoder Loss:  0.07190522 Validation Decoder Loss:  0.38497907
Encoder Loss:  0.06582261  || Decoder Loss:  0.06546096 Validation Decoder Loss:  0.376037
Encoder Loss:  0.06052033  || Decoder Loss:  0.060087785 Validation Decoder Loss:  0.36750776
Encoder Loss:  0.055680122  || Decoder Loss:  0.055185262 Validation Decoder Loss:  0.35973322
Encoder Loss:  0.05138062  || Decoder Loss:  0.050833464 Validation Decoder Loss:  0.35304117
Encoder Loss:  0.047717806  || Decoder Loss:  0.04713 Validation Decoder Loss:  0.34748203
Encoder Loss:  0.044697355  || Decoder Loss:  0.04408138 Validation Decoder Loss:  0.34302616
Encoder Loss:  0.042285427  || Decoder Loss:  0.04165375 Validation Decoder Loss:  0.33955178
Encoder Loss:  0.04040743  || Decoder Loss:  0.039772008 Validation Decoder Loss:  0.33691442
Encoder Loss:  0.03898484  || Decoder Loss:  0.03835791 Validation Decoder Loss:  0.33497864
Encoder Loss:  0.037931312  || Decoder Loss:  0.037325725 Validation Decoder Loss:  0.33360708
Encoder Loss:  0.0371626  || Decoder Loss:  0.036592927 Validation Decoder Loss:  0.33267286
Encoder Loss:  0.03660117  || Decoder Loss:  0.036083773 Validation Decoder Loss:  0.33206818
Encoder Loss:  0.03618427  || Decoder Loss:  0.03573366 Validation Decoder Loss:  0.33170885
Encoder Loss:  0.035871424  || Decoder Loss:  0.035491165 Validation Decoder Loss:  0.33153635
Encoder Loss:  0.03563956  || Decoder Loss:  0.03531833 Validation Decoder Loss:  0.3315001
Encoder Loss:  0.035469256  || Decoder Loss:  0.03518914 Validation Decoder Loss:  0.33155775
Encoder Loss:  0.035344623  || Decoder Loss:  0.03508915 Validation Decoder Loss:  0.33164448
Model: siamese_net_lr_4.5497313168107456e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33164448
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_183 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_81 (Conv3DT (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_43 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_185 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_187 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_62 (Conv2DT (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17224865  || Decoder Loss:  0.12845047 Validation Decoder Loss:  0.33899012
Encoder Loss:  0.047930833  || Decoder Loss:  0.037696533 Validation Decoder Loss:  0.33028302
Encoder Loss:  0.04183446  || Decoder Loss:  0.035066422 Validation Decoder Loss:  0.33054042
Encoder Loss:  0.041791476  || Decoder Loss:  0.03500728 Validation Decoder Loss:  0.33078426
Encoder Loss:  0.041148815  || Decoder Loss:  0.034998175 Validation Decoder Loss:  0.33176306
Encoder Loss:  0.040749107  || Decoder Loss:  0.034962185 Validation Decoder Loss:  0.33111984
Encoder Loss:  0.040733784  || Decoder Loss:  0.034938544 Validation Decoder Loss:  0.33111972
Encoder Loss:  0.04072286  || Decoder Loss:  0.03492006 Validation Decoder Loss:  0.33116645
Encoder Loss:  0.04070903  || Decoder Loss:  0.03489728 Validation Decoder Loss:  0.33149204
Encoder Loss:  0.040698458  || Decoder Loss:  0.034879822 Validation Decoder Loss:  0.32965276
Encoder Loss:  0.0406847  || Decoder Loss:  0.034856636 Validation Decoder Loss:  0.3312251
Encoder Loss:  0.040638823  || Decoder Loss:  0.034782823 Validation Decoder Loss:  0.3307507
Encoder Loss:  0.040612727  || Decoder Loss:  0.03474189 Validation Decoder Loss:  0.33066037
Encoder Loss:  0.040592294  || Decoder Loss:  0.034710538 Validation Decoder Loss:  0.33089322
Encoder Loss:  0.040576153  || Decoder Loss:  0.03468474 Validation Decoder Loss:  0.33080748
Encoder Loss:  0.040557947  || Decoder Loss:  0.034659576 Validation Decoder Loss:  0.33070844
Encoder Loss:  0.040552042  || Decoder Loss:  0.03464999 Validation Decoder Loss:  0.33045763
Encoder Loss:  0.040547654  || Decoder Loss:  0.03464651 Validation Decoder Loss:  0.3299796
Encoder Loss:  0.040552955  || Decoder Loss:  0.0346554 Validation Decoder Loss:  0.3289106
Encoder Loss:  0.040567383  || Decoder Loss:  0.034681503 Validation Decoder Loss:  0.32834655
Encoder Loss:  0.040535245  || Decoder Loss:  0.03463076 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.040478654  || Decoder Loss:  0.034538977 Validation Decoder Loss:  0.32565492
Encoder Loss:  0.04042385  || Decoder Loss:  0.034449738 Validation Decoder Loss:  0.3253922
Encoder Loss:  0.040373314  || Decoder Loss:  0.034367956 Validation Decoder Loss:  0.3253604
Encoder Loss:  0.040337607  || Decoder Loss:  0.034309693 Validation Decoder Loss:  0.32536665
Encoder Loss:  0.040298734  || Decoder Loss:  0.03424754 Validation Decoder Loss:  0.32526928
Encoder Loss:  0.040269446  || Decoder Loss:  0.03420092 Validation Decoder Loss:  0.32536578
Encoder Loss:  0.04024761  || Decoder Loss:  0.034164943 Validation Decoder Loss:  0.3254462
Encoder Loss:  0.040227674  || Decoder Loss:  0.034132753 Validation Decoder Loss:  0.32559335
Encoder Loss:  0.040222216  || Decoder Loss:  0.034120657 Validation Decoder Loss:  0.32589
Encoder Loss:  0.040200397  || Decoder Loss:  0.034088947 Validation Decoder Loss:  0.3260247
Encoder Loss:  0.040187582  || Decoder Loss:  0.034068033 Validation Decoder Loss:  0.3259706
Encoder Loss:  0.04017505  || Decoder Loss:  0.034048144 Validation Decoder Loss:  0.32609743
Encoder Loss:  0.04016677  || Decoder Loss:  0.034034315 Validation Decoder Loss:  0.3262046
Encoder Loss:  0.040168136  || Decoder Loss:  0.034032542 Validation Decoder Loss:  0.3264527
Encoder Loss:  0.040153686  || Decoder Loss:  0.03401366 Validation Decoder Loss:  0.32655376
Encoder Loss:  0.040149078  || Decoder Loss:  0.03400456 Validation Decoder Loss:  0.32666558
Encoder Loss:  0.040143322  || Decoder Loss:  0.0339957 Validation Decoder Loss:  0.32653224
Encoder Loss:  0.04013679  || Decoder Loss:  0.033985764 Validation Decoder Loss:  0.326613
Encoder Loss:  0.0401328  || Decoder Loss:  0.033979632 Validation Decoder Loss:  0.32668942
Model: siamese_net_lr_0.0006731199670352964 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32668942
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 80, 7, 20, 1)      52        
_________________________________________________________________
dropout_189 (Dropout)        (None, 80, 7, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_84 (Conv3DT (None, 220, 11, 20, 1)    311       
_________________________________________________________________
reshape_44 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 363
Trainable params: 363
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_191 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_64 (Conv2D)           (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 2590, 20, 1)       172       
_________________________________________________________________
dropout_193 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_64 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2363515  || Decoder Loss:  0.08406351 Validation Decoder Loss:  0.3725788
Encoder Loss:  0.23417829  || Decoder Loss:  0.08622143 Validation Decoder Loss:  0.37527734
Encoder Loss:  0.23138607  || Decoder Loss:  0.090375975 Validation Decoder Loss:  0.37888134
Encoder Loss:  0.22568804  || Decoder Loss:  0.11331001 Validation Decoder Loss:  0.6496376
Encoder Loss:  0.17580837  || Decoder Loss:  0.2496493 Validation Decoder Loss:  0.40149254
Encoder Loss:  0.08193  || Decoder Loss:  0.06149188 Validation Decoder Loss:  0.37853682
Encoder Loss:  0.07533299  || Decoder Loss:  0.051571433 Validation Decoder Loss:  0.36434728
Encoder Loss:  0.0704355  || Decoder Loss:  0.04733843 Validation Decoder Loss:  0.35466886
Encoder Loss:  0.05718567  || Decoder Loss:  0.045782253 Validation Decoder Loss:  0.34943455
Encoder Loss:  0.049151015  || Decoder Loss:  0.047535248 Validation Decoder Loss:  0.348373
Encoder Loss:  0.047718138  || Decoder Loss:  0.04509201 Validation Decoder Loss:  0.34401387
Encoder Loss:  0.046461158  || Decoder Loss:  0.042530943 Validation Decoder Loss:  0.34116355
Encoder Loss:  0.045616236  || Decoder Loss:  0.040798925 Validation Decoder Loss:  0.33909297
Encoder Loss:  0.045005515  || Decoder Loss:  0.039546646 Validation Decoder Loss:  0.33755258
Encoder Loss:  0.044554893  || Decoder Loss:  0.03862828 Validation Decoder Loss:  0.3363785
Encoder Loss:  0.0442245  || Decoder Loss:  0.037957177 Validation Decoder Loss:  0.33548784
Encoder Loss:  0.043974046  || Decoder Loss:  0.03744679 Validation Decoder Loss:  0.3347929
Encoder Loss:  0.04378065  || Decoder Loss:  0.037051298 Validation Decoder Loss:  0.3342749
Encoder Loss:  0.043624926  || Decoder Loss:  0.036734294 Validation Decoder Loss:  0.33384818
Encoder Loss:  0.04349915  || Decoder Loss:  0.03647679 Validation Decoder Loss:  0.33350736
Encoder Loss:  0.043395087  || Decoder Loss:  0.036265906 Validation Decoder Loss:  0.33322772
Encoder Loss:  0.043321785  || Decoder Loss:  0.036115814 Validation Decoder Loss:  0.33301902
Encoder Loss:  0.043261915  || Decoder Loss:  0.035994302 Validation Decoder Loss:  0.33284628
Encoder Loss:  0.043211747  || Decoder Loss:  0.035889912 Validation Decoder Loss:  0.33269265
Encoder Loss:  0.043168634  || Decoder Loss:  0.035802208 Validation Decoder Loss:  0.33255708
Encoder Loss:  0.04313156  || Decoder Loss:  0.0357265 Validation Decoder Loss:  0.33243603
Encoder Loss:  0.043101255  || Decoder Loss:  0.035666812 Validation Decoder Loss:  0.3323292
Encoder Loss:  0.04307611  || Decoder Loss:  0.03561584 Validation Decoder Loss:  0.3322354
Encoder Loss:  0.04305651  || Decoder Loss:  0.035575494 Validation Decoder Loss:  0.3321519
Encoder Loss:  0.043040134  || Decoder Loss:  0.03554339 Validation Decoder Loss:  0.33208027
Encoder Loss:  0.043028  || Decoder Loss:  0.03551792 Validation Decoder Loss:  0.33202177
Encoder Loss:  0.043017354  || Decoder Loss:  0.03549561 Validation Decoder Loss:  0.33196634
Encoder Loss:  0.043009326  || Decoder Loss:  0.035478637 Validation Decoder Loss:  0.33191997
Encoder Loss:  0.043002047  || Decoder Loss:  0.035465617 Validation Decoder Loss:  0.33187756
Encoder Loss:  0.042994738  || Decoder Loss:  0.03545383 Validation Decoder Loss:  0.33184385
Encoder Loss:  0.04299074  || Decoder Loss:  0.035442967 Validation Decoder Loss:  0.33181086
Encoder Loss:  0.04298787  || Decoder Loss:  0.035435647 Validation Decoder Loss:  0.33178088
Encoder Loss:  0.04298321  || Decoder Loss:  0.035429064 Validation Decoder Loss:  0.33175534
Encoder Loss:  0.04298234  || Decoder Loss:  0.035425406 Validation Decoder Loss:  0.33173293
Encoder Loss:  0.04297768  || Decoder Loss:  0.035417445 Validation Decoder Loss:  0.33171493
Model: siamese_net_lr_0.0007231273333952492 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33171493
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 125, 10, 20, 1)    125       
_________________________________________________________________
dropout_195 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_87 (Conv3DT (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_45 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_197 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_66 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_199 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_66 (Conv2DT (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28971845  || Decoder Loss:  0.11917309 Validation Decoder Loss:  0.425235
Encoder Loss:  0.11872039  || Decoder Loss:  0.120864265 Validation Decoder Loss:  0.3333485
Encoder Loss:  0.06856699  || Decoder Loss:  0.040721048 Validation Decoder Loss:  0.3292275
Encoder Loss:  0.04943113  || Decoder Loss:  0.038857702 Validation Decoder Loss:  0.32834142
Encoder Loss:  0.047666784  || Decoder Loss:  0.03759215 Validation Decoder Loss:  0.32756335
Encoder Loss:  0.047006182  || Decoder Loss:  0.035704423 Validation Decoder Loss:  0.32661173
Encoder Loss:  0.046672657  || Decoder Loss:  0.034773804 Validation Decoder Loss:  0.32709643
Encoder Loss:  0.046589676  || Decoder Loss:  0.03455248 Validation Decoder Loss:  0.32746553
Encoder Loss:  0.04655023  || Decoder Loss:  0.034476947 Validation Decoder Loss:  0.3277039
Encoder Loss:  0.046514936  || Decoder Loss:  0.034435067 Validation Decoder Loss:  0.32785803
Encoder Loss:  0.046485763  || Decoder Loss:  0.034401774 Validation Decoder Loss:  0.32795876
Encoder Loss:  0.04643965  || Decoder Loss:  0.03436879 Validation Decoder Loss:  0.32805172
Encoder Loss:  0.046329614  || Decoder Loss:  0.034328736 Validation Decoder Loss:  0.3281196
Encoder Loss:  0.0450216  || Decoder Loss:  0.034229223 Validation Decoder Loss:  0.32804912
Encoder Loss:  0.04482759  || Decoder Loss:  0.034196623 Validation Decoder Loss:  0.32801116
Encoder Loss:  0.0448032  || Decoder Loss:  0.034204576 Validation Decoder Loss:  0.32795417
Encoder Loss:  0.0447997  || Decoder Loss:  0.034214612 Validation Decoder Loss:  0.3278948
Encoder Loss:  0.044804726  || Decoder Loss:  0.034226708 Validation Decoder Loss:  0.32783034
Encoder Loss:  0.044793554  || Decoder Loss:  0.034229137 Validation Decoder Loss:  0.3277752
Encoder Loss:  0.044787172  || Decoder Loss:  0.03422576 Validation Decoder Loss:  0.32772237
Encoder Loss:  0.044777628  || Decoder Loss:  0.034211222 Validation Decoder Loss:  0.32766864
Encoder Loss:  0.04476714  || Decoder Loss:  0.034190048 Validation Decoder Loss:  0.3276229
Encoder Loss:  0.044754487  || Decoder Loss:  0.034160003 Validation Decoder Loss:  0.3275895
Encoder Loss:  0.044739813  || Decoder Loss:  0.03412225 Validation Decoder Loss:  0.32757866
Encoder Loss:  0.044727832  || Decoder Loss:  0.034080356 Validation Decoder Loss:  0.3275782
Encoder Loss:  0.044711314  || Decoder Loss:  0.034038607 Validation Decoder Loss:  0.32761112
Encoder Loss:  0.044696502  || Decoder Loss:  0.033999763 Validation Decoder Loss:  0.32765108
Encoder Loss:  0.04468446  || Decoder Loss:  0.03395918 Validation Decoder Loss:  0.32767904
Encoder Loss:  0.04467124  || Decoder Loss:  0.0339175 Validation Decoder Loss:  0.32774168
Encoder Loss:  0.04465774  || Decoder Loss:  0.033880517 Validation Decoder Loss:  0.32778212
Encoder Loss:  0.044645663  || Decoder Loss:  0.033846773 Validation Decoder Loss:  0.32781714
Encoder Loss:  0.044634003  || Decoder Loss:  0.03381685 Validation Decoder Loss:  0.3278367
Encoder Loss:  0.044626497  || Decoder Loss:  0.033788107 Validation Decoder Loss:  0.32785603
Encoder Loss:  0.04461738  || Decoder Loss:  0.03376291 Validation Decoder Loss:  0.32788473
Encoder Loss:  0.044610437  || Decoder Loss:  0.033740684 Validation Decoder Loss:  0.32791904
Encoder Loss:  0.04460244  || Decoder Loss:  0.033719257 Validation Decoder Loss:  0.32797438
Encoder Loss:  0.044596087  || Decoder Loss:  0.033701193 Validation Decoder Loss:  0.32802537
Encoder Loss:  0.044589445  || Decoder Loss:  0.0336844 Validation Decoder Loss:  0.3280833
Encoder Loss:  0.044585686  || Decoder Loss:  0.033669394 Validation Decoder Loss:  0.3281475
Encoder Loss:  0.044581477  || Decoder Loss:  0.033654608 Validation Decoder Loss:  0.3282106
Model: siamese_net_lr_0.0006407658972732629 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3282106
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 112, 5, 20, 1)     50        
_________________________________________________________________
dropout_201 (Dropout)        (None, 112, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_90 (Conv3DT (None, 220, 11, 20, 1)    328       
_________________________________________________________________
reshape_46 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 378
Trainable params: 378
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_203 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_68 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_205 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_68 (Conv2DT (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16264866  || Decoder Loss:  0.10480771 Validation Decoder Loss:  0.38093472
Encoder Loss:  0.162142  || Decoder Loss:  0.106619634 Validation Decoder Loss:  0.38275206
Encoder Loss:  0.16167687  || Decoder Loss:  0.10873627 Validation Decoder Loss:  0.38448963
Encoder Loss:  0.16167204  || Decoder Loss:  0.11162822 Validation Decoder Loss:  0.38673565
Encoder Loss:  0.16252941  || Decoder Loss:  0.11588905 Validation Decoder Loss:  0.39029756
Encoder Loss:  0.1653311  || Decoder Loss:  0.12342275 Validation Decoder Loss:  0.3984757
Encoder Loss:  0.20419966  || Decoder Loss:  0.18993834 Validation Decoder Loss:  1.2560456
Encoder Loss:  0.27072608  || Decoder Loss:  0.31720427 Validation Decoder Loss:  0.39670062
Encoder Loss:  0.069087125  || Decoder Loss:  0.062276393 Validation Decoder Loss:  0.3797702
Encoder Loss:  0.06118977  || Decoder Loss:  0.052455284 Validation Decoder Loss:  0.37091604
Encoder Loss:  0.05916064  || Decoder Loss:  0.050126497 Validation Decoder Loss:  0.36183435
Encoder Loss:  0.05686762  || Decoder Loss:  0.04748795 Validation Decoder Loss:  0.35324895
Encoder Loss:  0.054169774  || Decoder Loss:  0.04437743 Validation Decoder Loss:  0.34565222
Encoder Loss:  0.051493563  || Decoder Loss:  0.0411998 Validation Decoder Loss:  0.33965743
Encoder Loss:  0.049256153  || Decoder Loss:  0.038836904 Validation Decoder Loss:  0.33633825
Encoder Loss:  0.047810126  || Decoder Loss:  0.03757196 Validation Decoder Loss:  0.3347715
Encoder Loss:  0.043839432  || Decoder Loss:  0.037000164 Validation Decoder Loss:  0.3340063
Encoder Loss:  0.039630163  || Decoder Loss:  0.036611125 Validation Decoder Loss:  0.3336693
Encoder Loss:  0.03910995  || Decoder Loss:  0.036087714 Validation Decoder Loss:  0.3331437
Encoder Loss:  0.038856253  || Decoder Loss:  0.035796296 Validation Decoder Loss:  0.3327698
Encoder Loss:  0.038767636  || Decoder Loss:  0.035680152 Validation Decoder Loss:  0.33258367
Encoder Loss:  0.038698364  || Decoder Loss:  0.03559375 Validation Decoder Loss:  0.33246893
Encoder Loss:  0.03864149  || Decoder Loss:  0.035524245 Validation Decoder Loss:  0.33240864
Encoder Loss:  0.03859739  || Decoder Loss:  0.03546982 Validation Decoder Loss:  0.33232978
Encoder Loss:  0.03856637  || Decoder Loss:  0.035430003 Validation Decoder Loss:  0.33227715
Encoder Loss:  0.03854481  || Decoder Loss:  0.03540342 Validation Decoder Loss:  0.33221585
Encoder Loss:  0.038531706  || Decoder Loss:  0.03538728 Validation Decoder Loss:  0.33216178
Encoder Loss:  0.03852344  || Decoder Loss:  0.035378084 Validation Decoder Loss:  0.33213556
Encoder Loss:  0.038518894  || Decoder Loss:  0.035373945 Validation Decoder Loss:  0.3321055
Encoder Loss:  0.03851702  || Decoder Loss:  0.035371654 Validation Decoder Loss:  0.33205324
Encoder Loss:  0.038519215  || Decoder Loss:  0.035375465 Validation Decoder Loss:  0.33203337
Encoder Loss:  0.038520835  || Decoder Loss:  0.035378236 Validation Decoder Loss:  0.33204442
Encoder Loss:  0.038521454  || Decoder Loss:  0.035379354 Validation Decoder Loss:  0.33199823
Encoder Loss:  0.038521685  || Decoder Loss:  0.035380613 Validation Decoder Loss:  0.33196986
Encoder Loss:  0.03852118  || Decoder Loss:  0.03538071 Validation Decoder Loss:  0.33198267
Encoder Loss:  0.038519397  || Decoder Loss:  0.035379227 Validation Decoder Loss:  0.33199733
Encoder Loss:  0.038517237  || Decoder Loss:  0.035376754 Validation Decoder Loss:  0.3319959
Encoder Loss:  0.03851455  || Decoder Loss:  0.035374075 Validation Decoder Loss:  0.33199453
Encoder Loss:  0.038511764  || Decoder Loss:  0.035370864 Validation Decoder Loss:  0.33198905
Encoder Loss:  0.038509008  || Decoder Loss:  0.03536743 Validation Decoder Loss:  0.33197972
Model: siamese_net_lr_0.00042773073120784907 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33197972
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 150, 8, 20, 1)     97        
_________________________________________________________________
dropout_207 (Dropout)        (None, 150, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_93 (Conv3DT (None, 220, 11, 20, 1)    285       
_________________________________________________________________
reshape_47 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_209 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_211 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_70 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17721851  || Decoder Loss:  0.1551209 Validation Decoder Loss:  0.34863198
Encoder Loss:  0.045412723  || Decoder Loss:  0.041328494 Validation Decoder Loss:  0.33472377
Encoder Loss:  0.039238587  || Decoder Loss:  0.036727212 Validation Decoder Loss:  0.33279315
Encoder Loss:  0.038524732  || Decoder Loss:  0.035889972 Validation Decoder Loss:  0.3321385
Encoder Loss:  0.038286954  || Decoder Loss:  0.035608843 Validation Decoder Loss:  0.33181193
Encoder Loss:  0.03809689  || Decoder Loss:  0.03547553 Validation Decoder Loss:  0.3316971
Encoder Loss:  0.03800385  || Decoder Loss:  0.035405353 Validation Decoder Loss:  0.3316198
Encoder Loss:  0.037970666  || Decoder Loss:  0.035373162 Validation Decoder Loss:  0.33157086
Encoder Loss:  0.037954777  || Decoder Loss:  0.03535671 Validation Decoder Loss:  0.33151725
Encoder Loss:  0.03794153  || Decoder Loss:  0.035339784 Validation Decoder Loss:  0.3314818
Encoder Loss:  0.037921272  || Decoder Loss:  0.03531916 Validation Decoder Loss:  0.3314554
Encoder Loss:  0.037906107  || Decoder Loss:  0.03529928 Validation Decoder Loss:  0.33138913
Encoder Loss:  0.037888043  || Decoder Loss:  0.035279512 Validation Decoder Loss:  0.3313427
Encoder Loss:  0.03787465  || Decoder Loss:  0.03526259 Validation Decoder Loss:  0.33129436
Encoder Loss:  0.037861377  || Decoder Loss:  0.035247877 Validation Decoder Loss:  0.33122385
Encoder Loss:  0.037846185  || Decoder Loss:  0.035232972 Validation Decoder Loss:  0.3310938
Encoder Loss:  0.037834667  || Decoder Loss:  0.03521559 Validation Decoder Loss:  0.3310014
Encoder Loss:  0.037820745  || Decoder Loss:  0.035201777 Validation Decoder Loss:  0.33076727
Encoder Loss:  0.03780335  || Decoder Loss:  0.035179656 Validation Decoder Loss:  0.33056384
Encoder Loss:  0.03778023  || Decoder Loss:  0.035152458 Validation Decoder Loss:  0.3302859
Encoder Loss:  0.037749004  || Decoder Loss:  0.035117563 Validation Decoder Loss:  0.33017504
Encoder Loss:  0.03771393  || Decoder Loss:  0.035072617 Validation Decoder Loss:  0.329875
Encoder Loss:  0.037657734  || Decoder Loss:  0.035006557 Validation Decoder Loss:  0.32950288
Encoder Loss:  0.037589833  || Decoder Loss:  0.034923736 Validation Decoder Loss:  0.32921606
Encoder Loss:  0.03752108  || Decoder Loss:  0.03484242 Validation Decoder Loss:  0.32890338
Encoder Loss:  0.03744514  || Decoder Loss:  0.034751106 Validation Decoder Loss:  0.32862598
Encoder Loss:  0.037373528  || Decoder Loss:  0.034663845 Validation Decoder Loss:  0.32913047
Encoder Loss:  0.037279338  || Decoder Loss:  0.034550343 Validation Decoder Loss:  0.32937646
Encoder Loss:  0.037214678  || Decoder Loss:  0.034470063 Validation Decoder Loss:  0.3296525
Encoder Loss:  0.03715558  || Decoder Loss:  0.034400064 Validation Decoder Loss:  0.33008426
Encoder Loss:  0.037119478  || Decoder Loss:  0.034356862 Validation Decoder Loss:  0.33041757
Encoder Loss:  0.037083186  || Decoder Loss:  0.034311887 Validation Decoder Loss:  0.3306958
Encoder Loss:  0.03705262  || Decoder Loss:  0.034276012 Validation Decoder Loss:  0.33088502
Encoder Loss:  0.037024442  || Decoder Loss:  0.034243878 Validation Decoder Loss:  0.33142808
Encoder Loss:  0.037003044  || Decoder Loss:  0.03421529 Validation Decoder Loss:  0.33150896
Encoder Loss:  0.036986712  || Decoder Loss:  0.034197934 Validation Decoder Loss:  0.33158064
Encoder Loss:  0.03696724  || Decoder Loss:  0.03417254 Validation Decoder Loss:  0.33180735
Encoder Loss:  0.03693964  || Decoder Loss:  0.03413855 Validation Decoder Loss:  0.33199126
Encoder Loss:  0.03691912  || Decoder Loss:  0.034115873 Validation Decoder Loss:  0.33227807
Encoder Loss:  0.03691788  || Decoder Loss:  0.034114916 Validation Decoder Loss:  0.33213735
Model: siamese_net_lr_0.0005587641008511092 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33213735
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 200, 6, 20, 1)     275       
_________________________________________________________________
dropout_213 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_96 (Conv3DT (None, 220, 11, 20, 1)    127       
_________________________________________________________________
reshape_48 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 402
Trainable params: 402
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_215 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_72 (Conv2D)           (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_217 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_72 (Conv2DT (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17238148  || Decoder Loss:  0.14814126 Validation Decoder Loss:  0.7404907
Encoder Loss:  0.08034284  || Decoder Loss:  0.080486275 Validation Decoder Loss:  0.3322909
Encoder Loss:  0.037691917  || Decoder Loss:  0.034461983 Validation Decoder Loss:  0.33194727
Encoder Loss:  0.03644578  || Decoder Loss:  0.03418593 Validation Decoder Loss:  0.33284628
Encoder Loss:  0.03636856  || Decoder Loss:  0.034107007 Validation Decoder Loss:  0.33318442
Encoder Loss:  0.036344003  || Decoder Loss:  0.034078807 Validation Decoder Loss:  0.3334117
Encoder Loss:  0.036329277  || Decoder Loss:  0.03406226 Validation Decoder Loss:  0.33359548
Encoder Loss:  0.03632406  || Decoder Loss:  0.034056198 Validation Decoder Loss:  0.33374524
Encoder Loss:  0.036319412  || Decoder Loss:  0.034050845 Validation Decoder Loss:  0.33385023
Encoder Loss:  0.036317028  || Decoder Loss:  0.03404797 Validation Decoder Loss:  0.33390063
Encoder Loss:  0.03631261  || Decoder Loss:  0.034042813 Validation Decoder Loss:  0.3338814
Encoder Loss:  0.036307566  || Decoder Loss:  0.03403753 Validation Decoder Loss:  0.3338641
Encoder Loss:  0.03629843  || Decoder Loss:  0.034026485 Validation Decoder Loss:  0.33390927
Encoder Loss:  0.036288258  || Decoder Loss:  0.034014486 Validation Decoder Loss:  0.33403146
Encoder Loss:  0.036276992  || Decoder Loss:  0.034002163 Validation Decoder Loss:  0.33392686
Encoder Loss:  0.03626161  || Decoder Loss:  0.033984482 Validation Decoder Loss:  0.33395392
Encoder Loss:  0.03624331  || Decoder Loss:  0.03396303 Validation Decoder Loss:  0.33407134
Encoder Loss:  0.036226247  || Decoder Loss:  0.03394308 Validation Decoder Loss:  0.33415902
Encoder Loss:  0.036207885  || Decoder Loss:  0.033921607 Validation Decoder Loss:  0.33416548
Encoder Loss:  0.036194623  || Decoder Loss:  0.033905793 Validation Decoder Loss:  0.33390343
Encoder Loss:  0.036182217  || Decoder Loss:  0.033891443 Validation Decoder Loss:  0.33413494
Encoder Loss:  0.03616519  || Decoder Loss:  0.033872116 Validation Decoder Loss:  0.33399338
Encoder Loss:  0.036157623  || Decoder Loss:  0.0338629 Validation Decoder Loss:  0.33401006
Encoder Loss:  0.036148068  || Decoder Loss:  0.03385201 Validation Decoder Loss:  0.3338005
Encoder Loss:  0.036132976  || Decoder Loss:  0.03383436 Validation Decoder Loss:  0.33375117
Encoder Loss:  0.03611527  || Decoder Loss:  0.033814415 Validation Decoder Loss:  0.33374977
Encoder Loss:  0.03610947  || Decoder Loss:  0.033807255 Validation Decoder Loss:  0.33363914
Encoder Loss:  0.036090788  || Decoder Loss:  0.033785928 Validation Decoder Loss:  0.33365828
Encoder Loss:  0.036082253  || Decoder Loss:  0.033773288 Validation Decoder Loss:  0.3336685
Encoder Loss:  0.036070038  || Decoder Loss:  0.033761557 Validation Decoder Loss:  0.33345044
Encoder Loss:  0.036052123  || Decoder Loss:  0.033741053 Validation Decoder Loss:  0.33345547
Encoder Loss:  0.03604792  || Decoder Loss:  0.03373537 Validation Decoder Loss:  0.3330388
Encoder Loss:  0.036035147  || Decoder Loss:  0.03372121 Validation Decoder Loss:  0.3328559
Encoder Loss:  0.03602858  || Decoder Loss:  0.033713654 Validation Decoder Loss:  0.3325011
Encoder Loss:  0.036028486  || Decoder Loss:  0.033713557 Validation Decoder Loss:  0.33238322
Encoder Loss:  0.036029223  || Decoder Loss:  0.03371417 Validation Decoder Loss:  0.33220458
Encoder Loss:  0.03603762  || Decoder Loss:  0.033723827 Validation Decoder Loss:  0.33141512
Encoder Loss:  0.036028102  || Decoder Loss:  0.033712544 Validation Decoder Loss:  0.33140236
Encoder Loss:  0.03603196  || Decoder Loss:  0.03371765 Validation Decoder Loss:  0.3311695
Encoder Loss:  0.036034994  || Decoder Loss:  0.03372071 Validation Decoder Loss:  0.33148688
Model: siamese_net_lr_0.000940920900224081 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33148688
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_219 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_99 (Conv3DT (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_49 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_221 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_74 (Conv2D)           (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_223 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_74 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14862224  || Decoder Loss:  0.10982664 Validation Decoder Loss:  0.38767976
Encoder Loss:  0.15959325  || Decoder Loss:  0.1251852 Validation Decoder Loss:  0.4066105
Encoder Loss:  0.25333238  || Decoder Loss:  0.26270694 Validation Decoder Loss:  0.44875818
Encoder Loss:  0.061815403  || Decoder Loss:  0.05654429 Validation Decoder Loss:  0.34071344
Encoder Loss:  0.048734155  || Decoder Loss:  0.04175093 Validation Decoder Loss:  0.33752796
Encoder Loss:  0.046265557  || Decoder Loss:  0.03957438 Validation Decoder Loss:  0.33610225
Encoder Loss:  0.043980684  || Decoder Loss:  0.03814642 Validation Decoder Loss:  0.33510104
Encoder Loss:  0.040876497  || Decoder Loss:  0.037277073 Validation Decoder Loss:  0.3343823
Encoder Loss:  0.03878901  || Decoder Loss:  0.03651593 Validation Decoder Loss:  0.33353615
Encoder Loss:  0.038295925  || Decoder Loss:  0.03594109 Validation Decoder Loss:  0.3330446
Encoder Loss:  0.037999094  || Decoder Loss:  0.035596732 Validation Decoder Loss:  0.33287382
Encoder Loss:  0.03781942  || Decoder Loss:  0.035389367 Validation Decoder Loss:  0.33283192
Encoder Loss:  0.037722267  || Decoder Loss:  0.035276745 Validation Decoder Loss:  0.33303475
Encoder Loss:  0.03765984  || Decoder Loss:  0.0352064 Validation Decoder Loss:  0.33338326
Encoder Loss:  0.037620123  || Decoder Loss:  0.035161518 Validation Decoder Loss:  0.3336553
Encoder Loss:  0.03759567  || Decoder Loss:  0.035135478 Validation Decoder Loss:  0.3338107
Encoder Loss:  0.037578188  || Decoder Loss:  0.035120178 Validation Decoder Loss:  0.3338902
Encoder Loss:  0.037567552  || Decoder Loss:  0.035109542 Validation Decoder Loss:  0.33393335
Encoder Loss:  0.037555203  || Decoder Loss:  0.035100948 Validation Decoder Loss:  0.33395618
Encoder Loss:  0.037544888  || Decoder Loss:  0.035092637 Validation Decoder Loss:  0.33396715
Encoder Loss:  0.037531525  || Decoder Loss:  0.035083823 Validation Decoder Loss:  0.3339749
Encoder Loss:  0.03751648  || Decoder Loss:  0.03507371 Validation Decoder Loss:  0.333978
Encoder Loss:  0.037496723  || Decoder Loss:  0.03506182 Validation Decoder Loss:  0.33398283
Encoder Loss:  0.037467584  || Decoder Loss:  0.035046343 Validation Decoder Loss:  0.33398485
Encoder Loss:  0.03742097  || Decoder Loss:  0.035025347 Validation Decoder Loss:  0.33398944
Encoder Loss:  0.037257124  || Decoder Loss:  0.034982536 Validation Decoder Loss:  0.33400568
Encoder Loss:  0.0370724  || Decoder Loss:  0.034921464 Validation Decoder Loss:  0.33399558
Encoder Loss:  0.037070286  || Decoder Loss:  0.034921113 Validation Decoder Loss:  0.33397964
Encoder Loss:  0.03707394  || Decoder Loss:  0.034925994 Validation Decoder Loss:  0.33396894
Encoder Loss:  0.037080206  || Decoder Loss:  0.034934364 Validation Decoder Loss:  0.33396667
Encoder Loss:  0.03708768  || Decoder Loss:  0.03494425 Validation Decoder Loss:  0.33396143
Encoder Loss:  0.037095997  || Decoder Loss:  0.034954928 Validation Decoder Loss:  0.33395648
Encoder Loss:  0.0371049  || Decoder Loss:  0.03496598 Validation Decoder Loss:  0.33396167
Encoder Loss:  0.03711306  || Decoder Loss:  0.034976885 Validation Decoder Loss:  0.33396035
Encoder Loss:  0.03712128  || Decoder Loss:  0.034986928 Validation Decoder Loss:  0.33396113
Encoder Loss:  0.037128653  || Decoder Loss:  0.034996334 Validation Decoder Loss:  0.33395448
Encoder Loss:  0.037133545  || Decoder Loss:  0.035002753 Validation Decoder Loss:  0.33395773
Encoder Loss:  0.03713634  || Decoder Loss:  0.035006404 Validation Decoder Loss:  0.33394885
Encoder Loss:  0.037134744  || Decoder Loss:  0.035005383 Validation Decoder Loss:  0.33394182
Encoder Loss:  0.037131816  || Decoder Loss:  0.035002712 Validation Decoder Loss:  0.3339332
Model: siamese_net_lr_0.00029905535373891577 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3339332
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_225 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_102 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_50 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_227 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_76 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_229 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_76 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13767497  || Decoder Loss:  0.1089556 Validation Decoder Loss:  0.38657302
Encoder Loss:  0.14748195  || Decoder Loss:  0.12132533 Validation Decoder Loss:  0.39971575
Encoder Loss:  0.2480969  || Decoder Loss:  0.24559993 Validation Decoder Loss:  1.0450966
Encoder Loss:  0.13672087  || Decoder Loss:  0.14155667 Validation Decoder Loss:  0.3510751
Encoder Loss:  0.051963277  || Decoder Loss:  0.047294103 Validation Decoder Loss:  0.3400883
Encoder Loss:  0.04567989  || Decoder Loss:  0.040744968 Validation Decoder Loss:  0.3353393
Encoder Loss:  0.04215004  || Decoder Loss:  0.037608854 Validation Decoder Loss:  0.33361816
Encoder Loss:  0.039184697  || Decoder Loss:  0.036217164 Validation Decoder Loss:  0.33311284
Encoder Loss:  0.037369907  || Decoder Loss:  0.035598755 Validation Decoder Loss:  0.33272445
Encoder Loss:  0.03714277  || Decoder Loss:  0.035352506 Validation Decoder Loss:  0.33278474
Encoder Loss:  0.037049867  || Decoder Loss:  0.03524935 Validation Decoder Loss:  0.33286715
Encoder Loss:  0.03700354  || Decoder Loss:  0.035197828 Validation Decoder Loss:  0.33293653
Encoder Loss:  0.036974724  || Decoder Loss:  0.03516713 Validation Decoder Loss:  0.3330572
Encoder Loss:  0.036952987  || Decoder Loss:  0.035144478 Validation Decoder Loss:  0.3331773
Encoder Loss:  0.036937315  || Decoder Loss:  0.03512711 Validation Decoder Loss:  0.33328658
Encoder Loss:  0.036924385  || Decoder Loss:  0.035113707 Validation Decoder Loss:  0.33338502
Encoder Loss:  0.036913417  || Decoder Loss:  0.03510297 Validation Decoder Loss:  0.33347142
Encoder Loss:  0.036904126  || Decoder Loss:  0.03509451 Validation Decoder Loss:  0.33354604
Encoder Loss:  0.0368959  || Decoder Loss:  0.03508771 Validation Decoder Loss:  0.33361396
Encoder Loss:  0.036890093  || Decoder Loss:  0.035081755 Validation Decoder Loss:  0.33367848
Encoder Loss:  0.03688376  || Decoder Loss:  0.03507669 Validation Decoder Loss:  0.3337371
Encoder Loss:  0.036876857  || Decoder Loss:  0.035072107 Validation Decoder Loss:  0.33378667
Encoder Loss:  0.036871437  || Decoder Loss:  0.035067465 Validation Decoder Loss:  0.33382994
Encoder Loss:  0.03686396  || Decoder Loss:  0.035062905 Validation Decoder Loss:  0.3338635
Encoder Loss:  0.036856826  || Decoder Loss:  0.03505796 Validation Decoder Loss:  0.33388853
Encoder Loss:  0.03684728  || Decoder Loss:  0.03505268 Validation Decoder Loss:  0.33390477
Encoder Loss:  0.036836997  || Decoder Loss:  0.035046663 Validation Decoder Loss:  0.333915
Encoder Loss:  0.03682311  || Decoder Loss:  0.035040043 Validation Decoder Loss:  0.3339193
Encoder Loss:  0.036802385  || Decoder Loss:  0.0350324 Validation Decoder Loss:  0.3339194
Encoder Loss:  0.036740493  || Decoder Loss:  0.03502252 Validation Decoder Loss:  0.3339175
Encoder Loss:  0.036600027  || Decoder Loss:  0.035004385 Validation Decoder Loss:  0.33386493
Encoder Loss:  0.036583137  || Decoder Loss:  0.03499575 Validation Decoder Loss:  0.33385193
Encoder Loss:  0.036579568  || Decoder Loss:  0.034992263 Validation Decoder Loss:  0.33385676
Encoder Loss:  0.03657515  || Decoder Loss:  0.034989364 Validation Decoder Loss:  0.33386683
Encoder Loss:  0.0365714  || Decoder Loss:  0.03498714 Validation Decoder Loss:  0.33388147
Encoder Loss:  0.036569566  || Decoder Loss:  0.03498522 Validation Decoder Loss:  0.33389312
Encoder Loss:  0.036566585  || Decoder Loss:  0.03498336 Validation Decoder Loss:  0.33390558
Encoder Loss:  0.036563773  || Decoder Loss:  0.034981936 Validation Decoder Loss:  0.33392012
Encoder Loss:  0.036561996  || Decoder Loss:  0.03498095 Validation Decoder Loss:  0.33393922
Encoder Loss:  0.036560737  || Decoder Loss:  0.03498053 Validation Decoder Loss:  0.33395165
Model: siamese_net_lr_0.0005189046046175415 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33395165
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 170, 7, 20, 1)     322       
_________________________________________________________________
dropout_231 (Dropout)        (None, 170, 7, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_105 (Conv3D (None, 220, 11, 20, 1)    256       
_________________________________________________________________
reshape_51 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 578
Trainable params: 578
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_233 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_78 (Conv2D)           (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_235 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_78 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28284505  || Decoder Loss:  0.10927292 Validation Decoder Loss:  0.45603204
Encoder Loss:  0.114031665  || Decoder Loss:  0.15259805 Validation Decoder Loss:  0.34914473
Encoder Loss:  0.056305386  || Decoder Loss:  0.042735264 Validation Decoder Loss:  0.3360044
Encoder Loss:  0.046244685  || Decoder Loss:  0.03564754 Validation Decoder Loss:  0.33278745
Encoder Loss:  0.046002842  || Decoder Loss:  0.034830764 Validation Decoder Loss:  0.33241785
Encoder Loss:  0.045981377  || Decoder Loss:  0.034751154 Validation Decoder Loss:  0.33241338
Encoder Loss:  0.04597058  || Decoder Loss:  0.03471465 Validation Decoder Loss:  0.332472
Encoder Loss:  0.045962676  || Decoder Loss:  0.0346962 Validation Decoder Loss:  0.33254492
Encoder Loss:  0.045963444  || Decoder Loss:  0.034696594 Validation Decoder Loss:  0.3326192
Encoder Loss:  0.045967285  || Decoder Loss:  0.034716383 Validation Decoder Loss:  0.332731
Encoder Loss:  0.0459766  || Decoder Loss:  0.034751896 Validation Decoder Loss:  0.33283803
Encoder Loss:  0.045984883  || Decoder Loss:  0.03479065 Validation Decoder Loss:  0.33289984
Encoder Loss:  0.04599782  || Decoder Loss:  0.034835104 Validation Decoder Loss:  0.33294168
Encoder Loss:  0.04600768  || Decoder Loss:  0.03487735 Validation Decoder Loss:  0.33291942
Encoder Loss:  0.04601547  || Decoder Loss:  0.03491333 Validation Decoder Loss:  0.3328813
Encoder Loss:  0.046017632  || Decoder Loss:  0.03492871 Validation Decoder Loss:  0.33281624
Encoder Loss:  0.046022892  || Decoder Loss:  0.03493858 Validation Decoder Loss:  0.33269772
Encoder Loss:  0.046020802  || Decoder Loss:  0.03493773 Validation Decoder Loss:  0.33265138
Encoder Loss:  0.046016145  || Decoder Loss:  0.03492659 Validation Decoder Loss:  0.33258438
Encoder Loss:  0.046010617  || Decoder Loss:  0.03491332 Validation Decoder Loss:  0.33252752
Encoder Loss:  0.046005737  || Decoder Loss:  0.034886315 Validation Decoder Loss:  0.33267722
Encoder Loss:  0.04599751  || Decoder Loss:  0.034859627 Validation Decoder Loss:  0.3324136
Encoder Loss:  0.045988135  || Decoder Loss:  0.03482783 Validation Decoder Loss:  0.33251613
Encoder Loss:  0.045992132  || Decoder Loss:  0.03484334 Validation Decoder Loss:  0.33239058
Encoder Loss:  0.045969844  || Decoder Loss:  0.03476104 Validation Decoder Loss:  0.33240318
Encoder Loss:  0.04596365  || Decoder Loss:  0.03473979 Validation Decoder Loss:  0.33241278
Encoder Loss:  0.045984104  || Decoder Loss:  0.034820765 Validation Decoder Loss:  0.33213776
Encoder Loss:  0.04595246  || Decoder Loss:  0.034686662 Validation Decoder Loss:  0.3323119
Encoder Loss:  0.045946814  || Decoder Loss:  0.0346792 Validation Decoder Loss:  0.33219844
Encoder Loss:  0.04594549  || Decoder Loss:  0.034677926 Validation Decoder Loss:  0.3318983
Encoder Loss:  0.045946974  || Decoder Loss:  0.034683608 Validation Decoder Loss:  0.3309999
Encoder Loss:  0.045938026  || Decoder Loss:  0.034654107 Validation Decoder Loss:  0.3318531
Encoder Loss:  0.045941543  || Decoder Loss:  0.034668416 Validation Decoder Loss:  0.33131266
Encoder Loss:  0.045931276  || Decoder Loss:  0.03462823 Validation Decoder Loss:  0.33169204
Encoder Loss:  0.045933228  || Decoder Loss:  0.034614287 Validation Decoder Loss:  0.33172107
Encoder Loss:  0.04608219  || Decoder Loss:  0.0352009 Validation Decoder Loss:  0.33094314
Encoder Loss:  0.045924067  || Decoder Loss:  0.034607586 Validation Decoder Loss:  0.33106267
Encoder Loss:  0.045921423  || Decoder Loss:  0.034594815 Validation Decoder Loss:  0.33109003
Encoder Loss:  0.04592124  || Decoder Loss:  0.034597 Validation Decoder Loss:  0.33101028
Encoder Loss:  0.045922846  || Decoder Loss:  0.034604356 Validation Decoder Loss:  0.3308295
Model: siamese_net_lr_0.0007972510112643678 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33082953
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 193, 10, 20, 1)    25        
_________________________________________________________________
dropout_237 (Dropout)        (None, 193, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 220, 11, 20, 1)    57        
_________________________________________________________________
reshape_52 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 82
Trainable params: 82
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_239 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_80 (Conv2D)           (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_241 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_80 (Conv2DT (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16320713  || Decoder Loss:  0.05911124 Validation Decoder Loss:  0.37495872
Encoder Loss:  0.11628811  || Decoder Loss:  0.058788694 Validation Decoder Loss:  0.3351835
Encoder Loss:  0.054982677  || Decoder Loss:  0.056334443 Validation Decoder Loss:  0.33064485
Encoder Loss:  0.045050215  || Decoder Loss:  0.042993803 Validation Decoder Loss:  0.33525136
Encoder Loss:  0.039076023  || Decoder Loss:  0.034670003 Validation Decoder Loss:  0.33811742
Encoder Loss:  0.0387986  || Decoder Loss:  0.034304995 Validation Decoder Loss:  0.33956063
Encoder Loss:  0.038704008  || Decoder Loss:  0.034183174 Validation Decoder Loss:  0.33984715
Encoder Loss:  0.038643356  || Decoder Loss:  0.0341117 Validation Decoder Loss:  0.3399495
Encoder Loss:  0.03860194  || Decoder Loss:  0.034057826 Validation Decoder Loss:  0.3397553
Encoder Loss:  0.038563598  || Decoder Loss:  0.03400796 Validation Decoder Loss:  0.33924842
Encoder Loss:  0.03851366  || Decoder Loss:  0.033943184 Validation Decoder Loss:  0.33907452
Encoder Loss:  0.03846874  || Decoder Loss:  0.033881914 Validation Decoder Loss:  0.3389535
Encoder Loss:  0.03842944  || Decoder Loss:  0.03382796 Validation Decoder Loss:  0.33889726
Encoder Loss:  0.03839811  || Decoder Loss:  0.033784598 Validation Decoder Loss:  0.33887976
Encoder Loss:  0.038373444  || Decoder Loss:  0.033750188 Validation Decoder Loss:  0.33894736
Encoder Loss:  0.038351625  || Decoder Loss:  0.033719882 Validation Decoder Loss:  0.33907256
Encoder Loss:  0.038332235  || Decoder Loss:  0.033692993 Validation Decoder Loss:  0.3392359
Encoder Loss:  0.038313653  || Decoder Loss:  0.033667304 Validation Decoder Loss:  0.33945164
Encoder Loss:  0.038298063  || Decoder Loss:  0.033644482 Validation Decoder Loss:  0.33970445
Encoder Loss:  0.038286854  || Decoder Loss:  0.03363048 Validation Decoder Loss:  0.3400402
Encoder Loss:  0.038276657  || Decoder Loss:  0.03361619 Validation Decoder Loss:  0.34038138
Encoder Loss:  0.038268596  || Decoder Loss:  0.033604607 Validation Decoder Loss:  0.34070945
Encoder Loss:  0.03826251  || Decoder Loss:  0.033596657 Validation Decoder Loss:  0.34104258
Encoder Loss:  0.038253058  || Decoder Loss:  0.033584107 Validation Decoder Loss:  0.3413027
Encoder Loss:  0.038244538  || Decoder Loss:  0.033571713 Validation Decoder Loss:  0.34147486
Encoder Loss:  0.03823772  || Decoder Loss:  0.033560783 Validation Decoder Loss:  0.341596
Encoder Loss:  0.03822712  || Decoder Loss:  0.033548344 Validation Decoder Loss:  0.3416612
Encoder Loss:  0.03822103  || Decoder Loss:  0.033539742 Validation Decoder Loss:  0.34167898
Encoder Loss:  0.03821158  || Decoder Loss:  0.033526942 Validation Decoder Loss:  0.34165943
Encoder Loss:  0.038201816  || Decoder Loss:  0.033513375 Validation Decoder Loss:  0.34161693
Encoder Loss:  0.038192514  || Decoder Loss:  0.033499256 Validation Decoder Loss:  0.34159273
Encoder Loss:  0.03818147  || Decoder Loss:  0.03348513 Validation Decoder Loss:  0.3415895
Encoder Loss:  0.03817243  || Decoder Loss:  0.033472106 Validation Decoder Loss:  0.3416031
Encoder Loss:  0.038161255  || Decoder Loss:  0.033456646 Validation Decoder Loss:  0.34152788
Encoder Loss:  0.038147505  || Decoder Loss:  0.033438593 Validation Decoder Loss:  0.3414657
Encoder Loss:  0.038137168  || Decoder Loss:  0.033422537 Validation Decoder Loss:  0.34154186
Encoder Loss:  0.03812273  || Decoder Loss:  0.033403944 Validation Decoder Loss:  0.34192944
Encoder Loss:  0.03810431  || Decoder Loss:  0.033377804 Validation Decoder Loss:  0.34245837
Encoder Loss:  0.038075034  || Decoder Loss:  0.033336204 Validation Decoder Loss:  0.34401718
Encoder Loss:  0.038045242  || Decoder Loss:  0.033295665 Validation Decoder Loss:  0.3449141
Model: siamese_net_lr_0.0003675895776565732 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3449141
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_243 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 220, 11, 20, 1)    757       
_________________________________________________________________
reshape_53 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 822
Trainable params: 822
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_245 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_82 (Conv2D)           (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 2590, 20, 1)       172       
_________________________________________________________________
dropout_247 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_82 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16199793  || Decoder Loss:  0.106006734 Validation Decoder Loss:  0.38547564
Encoder Loss:  0.16811873  || Decoder Loss:  0.11771727 Validation Decoder Loss:  0.39631522
Encoder Loss:  0.17755331  || Decoder Loss:  0.13612482 Validation Decoder Loss:  0.4261521
Encoder Loss:  0.27343535  || Decoder Loss:  0.30601996 Validation Decoder Loss:  0.46387595
Encoder Loss:  0.09261052  || Decoder Loss:  0.091415636 Validation Decoder Loss:  0.37108383
Encoder Loss:  0.068249404  || Decoder Loss:  0.064925246 Validation Decoder Loss:  0.35796118
Encoder Loss:  0.06277806  || Decoder Loss:  0.06609021 Validation Decoder Loss:  0.35942695
Encoder Loss:  0.059828386  || Decoder Loss:  0.062465385 Validation Decoder Loss:  0.35337535
Encoder Loss:  0.055288576  || Decoder Loss:  0.056694165 Validation Decoder Loss:  0.3475498
Encoder Loss:  0.05049213  || Decoder Loss:  0.050557252 Validation Decoder Loss:  0.342614
Encoder Loss:  0.04673621  || Decoder Loss:  0.04572388 Validation Decoder Loss:  0.33935976
Encoder Loss:  0.043984197  || Decoder Loss:  0.042192496 Validation Decoder Loss:  0.33719355
Encoder Loss:  0.042041793  || Decoder Loss:  0.039708313 Validation Decoder Loss:  0.3356191
Encoder Loss:  0.040725473  || Decoder Loss:  0.038024843 Validation Decoder Loss:  0.33464876
Encoder Loss:  0.039857563  || Decoder Loss:  0.03691964 Validation Decoder Loss:  0.33391196
Encoder Loss:  0.039327376  || Decoder Loss:  0.03624831 Validation Decoder Loss:  0.33339044
Encoder Loss:  0.038998574  || Decoder Loss:  0.03582635 Validation Decoder Loss:  0.33291796
Encoder Loss:  0.0388088  || Decoder Loss:  0.035586253 Validation Decoder Loss:  0.33262193
Encoder Loss:  0.038720265  || Decoder Loss:  0.035475567 Validation Decoder Loss:  0.3324084
Encoder Loss:  0.038685847  || Decoder Loss:  0.035434384 Validation Decoder Loss:  0.33222252
Encoder Loss:  0.03868667  || Decoder Loss:  0.03543529 Validation Decoder Loss:  0.33211598
Encoder Loss:  0.038697198  || Decoder Loss:  0.035452172 Validation Decoder Loss:  0.3319924
Encoder Loss:  0.03871012  || Decoder Loss:  0.035469696 Validation Decoder Loss:  0.33192998
Encoder Loss:  0.038727023  || Decoder Loss:  0.035491973 Validation Decoder Loss:  0.33183712
Encoder Loss:  0.038738538  || Decoder Loss:  0.035509035 Validation Decoder Loss:  0.3317967
Encoder Loss:  0.038746458  || Decoder Loss:  0.03551986 Validation Decoder Loss:  0.33173448
Encoder Loss:  0.038755655  || Decoder Loss:  0.035531957 Validation Decoder Loss:  0.33167365
Encoder Loss:  0.038766176  || Decoder Loss:  0.035546172 Validation Decoder Loss:  0.33162513
Encoder Loss:  0.03877638  || Decoder Loss:  0.03555995 Validation Decoder Loss:  0.33158535
Encoder Loss:  0.038785525  || Decoder Loss:  0.03557307 Validation Decoder Loss:  0.3315271
Encoder Loss:  0.0387895  || Decoder Loss:  0.035577327 Validation Decoder Loss:  0.33151466
Encoder Loss:  0.03879647  || Decoder Loss:  0.035587702 Validation Decoder Loss:  0.33146966
Encoder Loss:  0.03879747  || Decoder Loss:  0.035588067 Validation Decoder Loss:  0.33143872
Encoder Loss:  0.038800318  || Decoder Loss:  0.03559246 Validation Decoder Loss:  0.33141297
Encoder Loss:  0.038802188  || Decoder Loss:  0.03559562 Validation Decoder Loss:  0.3313902
Encoder Loss:  0.038802672  || Decoder Loss:  0.035596803 Validation Decoder Loss:  0.33137158
Encoder Loss:  0.038803533  || Decoder Loss:  0.03559753 Validation Decoder Loss:  0.33137655
Encoder Loss:  0.038805056  || Decoder Loss:  0.035599146 Validation Decoder Loss:  0.33131748
Encoder Loss:  0.03880286  || Decoder Loss:  0.035596605 Validation Decoder Loss:  0.33130687
Encoder Loss:  0.038800813  || Decoder Loss:  0.035593692 Validation Decoder Loss:  0.33131754
Model: siamese_net_lr_0.0009127276666027993 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33131754
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 200, 6, 20, 1)     23        
_________________________________________________________________
dropout_249 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 220, 11, 20, 1)    127       
_________________________________________________________________
reshape_54 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_251 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_84 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_253 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_84 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18349479  || Decoder Loss:  0.053448487 Validation Decoder Loss:  0.3772809
Encoder Loss:  0.1379428  || Decoder Loss:  0.04990337 Validation Decoder Loss:  0.35622078
Encoder Loss:  0.047344662  || Decoder Loss:  0.045505524 Validation Decoder Loss:  0.35347015
Encoder Loss:  0.044282626  || Decoder Loss:  0.04063259 Validation Decoder Loss:  0.34255528
Encoder Loss:  0.040538687  || Decoder Loss:  0.034569487 Validation Decoder Loss:  0.34371847
Encoder Loss:  0.04013926  || Decoder Loss:  0.03391001 Validation Decoder Loss:  0.3451749
Encoder Loss:  0.04003068  || Decoder Loss:  0.03375171 Validation Decoder Loss:  0.3457262
Encoder Loss:  0.039970383  || Decoder Loss:  0.033665285 Validation Decoder Loss:  0.34609154
Encoder Loss:  0.039937805  || Decoder Loss:  0.03358887 Validation Decoder Loss:  0.3463884
Encoder Loss:  0.03988279  || Decoder Loss:  0.033504523 Validation Decoder Loss:  0.34670252
Encoder Loss:  0.039817408  || Decoder Loss:  0.033395413 Validation Decoder Loss:  0.3467025
Encoder Loss:  0.03973961  || Decoder Loss:  0.03329884 Validation Decoder Loss:  0.34656498
Encoder Loss:  0.039687265  || Decoder Loss:  0.033206467 Validation Decoder Loss:  0.346328
Encoder Loss:  0.03962579  || Decoder Loss:  0.03311197 Validation Decoder Loss:  0.34601846
Encoder Loss:  0.039578967  || Decoder Loss:  0.03304781 Validation Decoder Loss:  0.345759
Encoder Loss:  0.039543323  || Decoder Loss:  0.032988604 Validation Decoder Loss:  0.3454414
Encoder Loss:  0.03951372  || Decoder Loss:  0.032959525 Validation Decoder Loss:  0.34531373
Encoder Loss:  0.03950368  || Decoder Loss:  0.03294676 Validation Decoder Loss:  0.34511256
Encoder Loss:  0.039494555  || Decoder Loss:  0.032934908 Validation Decoder Loss:  0.34492388
Encoder Loss:  0.039492857  || Decoder Loss:  0.032934677 Validation Decoder Loss:  0.34468842
Encoder Loss:  0.039495926  || Decoder Loss:  0.03294046 Validation Decoder Loss:  0.34441608
Encoder Loss:  0.03950006  || Decoder Loss:  0.032947954 Validation Decoder Loss:  0.34410793
Encoder Loss:  0.03950467  || Decoder Loss:  0.03295583 Validation Decoder Loss:  0.34387776
Encoder Loss:  0.039508447  || Decoder Loss:  0.032962784 Validation Decoder Loss:  0.3436975
Encoder Loss:  0.039512638  || Decoder Loss:  0.032969676 Validation Decoder Loss:  0.34356874
Encoder Loss:  0.03951333  || Decoder Loss:  0.03297157 Validation Decoder Loss:  0.34351468
Encoder Loss:  0.0395153  || Decoder Loss:  0.032972373 Validation Decoder Loss:  0.34350315
Encoder Loss:  0.03951322  || Decoder Loss:  0.032972053 Validation Decoder Loss:  0.3435307
Encoder Loss:  0.039512835  || Decoder Loss:  0.032971147 Validation Decoder Loss:  0.3434996
Encoder Loss:  0.039515976  || Decoder Loss:  0.032974757 Validation Decoder Loss:  0.34340543
Encoder Loss:  0.039512176  || Decoder Loss:  0.032971762 Validation Decoder Loss:  0.34340286
Encoder Loss:  0.03951215  || Decoder Loss:  0.03297203 Validation Decoder Loss:  0.34344876
Encoder Loss:  0.039514612  || Decoder Loss:  0.03297133 Validation Decoder Loss:  0.34352484
Encoder Loss:  0.03951337  || Decoder Loss:  0.032973215 Validation Decoder Loss:  0.34350225
Encoder Loss:  0.03951286  || Decoder Loss:  0.032974444 Validation Decoder Loss:  0.34351325
Encoder Loss:  0.039516743  || Decoder Loss:  0.032975893 Validation Decoder Loss:  0.34352124
Encoder Loss:  0.039511558  || Decoder Loss:  0.032972615 Validation Decoder Loss:  0.3435641
Encoder Loss:  0.039511368  || Decoder Loss:  0.03297232 Validation Decoder Loss:  0.343529
Encoder Loss:  0.039510492  || Decoder Loss:  0.032968435 Validation Decoder Loss:  0.34361273
Encoder Loss:  0.039508935  || Decoder Loss:  0.032966226 Validation Decoder Loss:  0.34353048
Model: siamese_net_lr_0.0006602286867215449 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34353048
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_255 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_55 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_257 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_86 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_259 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_86 (Conv2DT (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35332185  || Decoder Loss:  0.11182785 Validation Decoder Loss:  0.39125922
Encoder Loss:  0.3279524  || Decoder Loss:  0.14152317 Validation Decoder Loss:  0.57936513
Encoder Loss:  0.1076461  || Decoder Loss:  0.1704669 Validation Decoder Loss:  0.3530463
Encoder Loss:  0.08735309  || Decoder Loss:  0.05027648 Validation Decoder Loss:  0.3412472
Encoder Loss:  0.08248362  || Decoder Loss:  0.04121763 Validation Decoder Loss:  0.3352905
Encoder Loss:  0.07548088  || Decoder Loss:  0.036730636 Validation Decoder Loss:  0.33256236
Encoder Loss:  0.061363474  || Decoder Loss:  0.03549061 Validation Decoder Loss:  0.33231002
Encoder Loss:  0.050764475  || Decoder Loss:  0.035246197 Validation Decoder Loss:  0.33249715
Encoder Loss:  0.050730772  || Decoder Loss:  0.035166793 Validation Decoder Loss:  0.33297482
Encoder Loss:  0.050710797  || Decoder Loss:  0.035131402 Validation Decoder Loss:  0.333296
Encoder Loss:  0.050692253  || Decoder Loss:  0.035116125 Validation Decoder Loss:  0.3334409
Encoder Loss:  0.050582286  || Decoder Loss:  0.035110854 Validation Decoder Loss:  0.3335061
Encoder Loss:  0.04877414  || Decoder Loss:  0.035093606 Validation Decoder Loss:  0.33356765
Encoder Loss:  0.048429236  || Decoder Loss:  0.03507961 Validation Decoder Loss:  0.3336317
Encoder Loss:  0.048427075  || Decoder Loss:  0.03507025 Validation Decoder Loss:  0.3336714
Encoder Loss:  0.04842528  || Decoder Loss:  0.03506259 Validation Decoder Loss:  0.3337003
Encoder Loss:  0.04842539  || Decoder Loss:  0.03505553 Validation Decoder Loss:  0.33373034
Encoder Loss:  0.048424315  || Decoder Loss:  0.03504919 Validation Decoder Loss:  0.33376288
Encoder Loss:  0.04842334  || Decoder Loss:  0.035043597 Validation Decoder Loss:  0.33379698
Encoder Loss:  0.048421532  || Decoder Loss:  0.035038184 Validation Decoder Loss:  0.3338201
Encoder Loss:  0.048421517  || Decoder Loss:  0.03503381 Validation Decoder Loss:  0.33384278
Encoder Loss:  0.04842045  || Decoder Loss:  0.03503045 Validation Decoder Loss:  0.33385673
Encoder Loss:  0.048419822  || Decoder Loss:  0.035027873 Validation Decoder Loss:  0.33385593
Encoder Loss:  0.04841938  || Decoder Loss:  0.03502801 Validation Decoder Loss:  0.33384633
Encoder Loss:  0.048418093  || Decoder Loss:  0.035029296 Validation Decoder Loss:  0.33382142
Encoder Loss:  0.04841644  || Decoder Loss:  0.03502968 Validation Decoder Loss:  0.33378288
Encoder Loss:  0.048415877  || Decoder Loss:  0.03502991 Validation Decoder Loss:  0.33372888
Encoder Loss:  0.048415087  || Decoder Loss:  0.035027996 Validation Decoder Loss:  0.3336423
Encoder Loss:  0.048412345  || Decoder Loss:  0.035029218 Validation Decoder Loss:  0.33353996
Encoder Loss:  0.04841192  || Decoder Loss:  0.03502654 Validation Decoder Loss:  0.33346027
Encoder Loss:  0.048411883  || Decoder Loss:  0.035019804 Validation Decoder Loss:  0.33335516
Encoder Loss:  0.048408974  || Decoder Loss:  0.035012163 Validation Decoder Loss:  0.3332613
Encoder Loss:  0.048408795  || Decoder Loss:  0.035009556 Validation Decoder Loss:  0.33316296
Encoder Loss:  0.048407134  || Decoder Loss:  0.035005704 Validation Decoder Loss:  0.3330768
Encoder Loss:  0.048406776  || Decoder Loss:  0.035002116 Validation Decoder Loss:  0.33299243
Encoder Loss:  0.048405867  || Decoder Loss:  0.034999765 Validation Decoder Loss:  0.3329137
Encoder Loss:  0.04840475  || Decoder Loss:  0.034998454 Validation Decoder Loss:  0.33285344
Encoder Loss:  0.048404478  || Decoder Loss:  0.034995977 Validation Decoder Loss:  0.33277813
Encoder Loss:  0.0484048  || Decoder Loss:  0.034992926 Validation Decoder Loss:  0.33274361
Encoder Loss:  0.048403915  || Decoder Loss:  0.034987405 Validation Decoder Loss:  0.33267516
Model: siamese_net_lr_0.00019438510319210546 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33267516
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 112, 5, 20, 1)     50        
_________________________________________________________________
dropout_261 (Dropout)        (None, 112, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 220, 11, 20, 1)    328       
_________________________________________________________________
reshape_56 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 378
Trainable params: 378
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_263 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_88 (Conv2D)           (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_265 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_88 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3623393  || Decoder Loss:  0.10456204 Validation Decoder Loss:  0.38024968
Encoder Loss:  0.35718006  || Decoder Loss:  0.10572151 Validation Decoder Loss:  0.3816194
Encoder Loss:  0.3514415  || Decoder Loss:  0.106923915 Validation Decoder Loss:  0.38280815
Encoder Loss:  0.34535217  || Decoder Loss:  0.10828295 Validation Decoder Loss:  0.38395232
Encoder Loss:  0.33897683  || Decoder Loss:  0.10993325 Validation Decoder Loss:  0.3852184
Encoder Loss:  0.33231327  || Decoder Loss:  0.11200451 Validation Decoder Loss:  0.38675866
Encoder Loss:  0.32525957  || Decoder Loss:  0.11467869 Validation Decoder Loss:  0.3887863
Encoder Loss:  0.3175049  || Decoder Loss:  0.11833303 Validation Decoder Loss:  0.39174587
Encoder Loss:  0.30805534  || Decoder Loss:  0.12399741 Validation Decoder Loss:  0.397098
Encoder Loss:  0.29167894  || Decoder Loss:  0.13627177 Validation Decoder Loss:  0.41616088
Encoder Loss:  0.1899654  || Decoder Loss:  0.32611668 Validation Decoder Loss:  1.2017267
Encoder Loss:  0.11543178  || Decoder Loss:  0.44833034 Validation Decoder Loss:  0.8785713
Encoder Loss:  0.10104347  || Decoder Loss:  0.22926584 Validation Decoder Loss:  0.43712795
Encoder Loss:  0.09409035  || Decoder Loss:  0.103328355 Validation Decoder Loss:  0.36561435
Encoder Loss:  0.09136793  || Decoder Loss:  0.057625942 Validation Decoder Loss:  0.3680753
Encoder Loss:  0.09092829  || Decoder Loss:  0.05173094 Validation Decoder Loss:  0.36991757
Encoder Loss:  0.09061758  || Decoder Loss:  0.051707026 Validation Decoder Loss:  0.3691097
Encoder Loss:  0.09059416  || Decoder Loss:  0.052088674 Validation Decoder Loss:  0.36777088
Encoder Loss:  0.09059753  || Decoder Loss:  0.05251712 Validation Decoder Loss:  0.36605108
Encoder Loss:  0.08985159  || Decoder Loss:  0.052992005 Validation Decoder Loss:  0.36366916
Encoder Loss:  0.08868833  || Decoder Loss:  0.053421367 Validation Decoder Loss:  0.36184365
Encoder Loss:  0.087746054  || Decoder Loss:  0.05370349 Validation Decoder Loss:  0.35926604
Encoder Loss:  0.085753635  || Decoder Loss:  0.053601913 Validation Decoder Loss:  0.35664004
Encoder Loss:  0.07854507  || Decoder Loss:  0.05271242 Validation Decoder Loss:  0.35328624
Encoder Loss:  0.05254448  || Decoder Loss:  0.050703764 Validation Decoder Loss:  0.34995374
Encoder Loss:  0.05047617  || Decoder Loss:  0.046894822 Validation Decoder Loss:  0.345778
Encoder Loss:  0.049892634  || Decoder Loss:  0.04256558 Validation Decoder Loss:  0.34105432
Encoder Loss:  0.049533807  || Decoder Loss:  0.039260883 Validation Decoder Loss:  0.33776096
Encoder Loss:  0.049443774  || Decoder Loss:  0.037969634 Validation Decoder Loss:  0.3363073
Encoder Loss:  0.049415804  || Decoder Loss:  0.037470657 Validation Decoder Loss:  0.33557975
Encoder Loss:  0.04939755  || Decoder Loss:  0.03711637 Validation Decoder Loss:  0.33506697
Encoder Loss:  0.049380835  || Decoder Loss:  0.03681247 Validation Decoder Loss:  0.3346309
Encoder Loss:  0.04936475  || Decoder Loss:  0.03655316 Validation Decoder Loss:  0.33423832
Encoder Loss:  0.049353514  || Decoder Loss:  0.03632827 Validation Decoder Loss:  0.33388585
Encoder Loss:  0.04934129  || Decoder Loss:  0.03613765 Validation Decoder Loss:  0.33357036
Encoder Loss:  0.04933364  || Decoder Loss:  0.035976373 Validation Decoder Loss:  0.33329123
Encoder Loss:  0.04932409  || Decoder Loss:  0.035838757 Validation Decoder Loss:  0.33304393
Encoder Loss:  0.049318638  || Decoder Loss:  0.035726637 Validation Decoder Loss:  0.33283335
Encoder Loss:  0.049312554  || Decoder Loss:  0.035631154 Validation Decoder Loss:  0.33264905
Encoder Loss:  0.049305964  || Decoder Loss:  0.035554092 Validation Decoder Loss:  0.33249202
Model: siamese_net_lr_0.000497162504138932 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.332492
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_267 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_57 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 550
Trainable params: 550
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_269 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_90 (Conv2D)           (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_271 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_90 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3598905  || Decoder Loss:  0.11537117 Validation Decoder Loss:  0.39113235
Encoder Loss:  0.34734505  || Decoder Loss:  0.1263772 Validation Decoder Loss:  0.40153313
Encoder Loss:  0.32897326  || Decoder Loss:  0.14093025 Validation Decoder Loss:  0.41787592
Encoder Loss:  0.29101032  || Decoder Loss:  0.16790862 Validation Decoder Loss:  0.47208056
Encoder Loss:  0.13998888  || Decoder Loss:  0.21233107 Validation Decoder Loss:  0.500969
Encoder Loss:  0.08003757  || Decoder Loss:  0.067611 Validation Decoder Loss:  0.35255957
Encoder Loss:  0.07778835  || Decoder Loss:  0.05084324 Validation Decoder Loss:  0.34580168
Encoder Loss:  0.075798094  || Decoder Loss:  0.046406128 Validation Decoder Loss:  0.34209839
Encoder Loss:  0.07249939  || Decoder Loss:  0.043610867 Validation Decoder Loss:  0.34003657
Encoder Loss:  0.053933248  || Decoder Loss:  0.041826583 Validation Decoder Loss:  0.34179977
Encoder Loss:  0.04963921  || Decoder Loss:  0.04050882 Validation Decoder Loss:  0.3398198
Encoder Loss:  0.049560405  || Decoder Loss:  0.03917502 Validation Decoder Loss:  0.33807904
Encoder Loss:  0.049506523  || Decoder Loss:  0.038123693 Validation Decoder Loss:  0.33662668
Encoder Loss:  0.04946141  || Decoder Loss:  0.03729165 Validation Decoder Loss:  0.33546734
Encoder Loss:  0.049432173  || Decoder Loss:  0.036652155 Validation Decoder Loss:  0.3345421
Encoder Loss:  0.049419228  || Decoder Loss:  0.03620009 Validation Decoder Loss:  0.33374473
Encoder Loss:  0.04939191  || Decoder Loss:  0.03583894 Validation Decoder Loss:  0.33318585
Encoder Loss:  0.04937325  || Decoder Loss:  0.03557073 Validation Decoder Loss:  0.33276403
Encoder Loss:  0.049362335  || Decoder Loss:  0.035371296 Validation Decoder Loss:  0.3325406
Encoder Loss:  0.049373914  || Decoder Loss:  0.035229813 Validation Decoder Loss:  0.3325081
Encoder Loss:  0.04934468  || Decoder Loss:  0.035134323 Validation Decoder Loss:  0.332316
Encoder Loss:  0.04934888  || Decoder Loss:  0.035060454 Validation Decoder Loss:  0.3321651
Encoder Loss:  0.049339723  || Decoder Loss:  0.035024226 Validation Decoder Loss:  0.3319049
Encoder Loss:  0.04934343  || Decoder Loss:  0.03499864 Validation Decoder Loss:  0.33154932
Encoder Loss:  0.049337648  || Decoder Loss:  0.03498116 Validation Decoder Loss:  0.3314765
Encoder Loss:  0.049340438  || Decoder Loss:  0.03496337 Validation Decoder Loss:  0.33141398
Encoder Loss:  0.049334016  || Decoder Loss:  0.034968957 Validation Decoder Loss:  0.33139944
Encoder Loss:  0.049341  || Decoder Loss:  0.03496367 Validation Decoder Loss:  0.3313439
Encoder Loss:  0.049337097  || Decoder Loss:  0.03496935 Validation Decoder Loss:  0.33125353
Encoder Loss:  0.04933371  || Decoder Loss:  0.034970276 Validation Decoder Loss:  0.3312062
Encoder Loss:  0.049334288  || Decoder Loss:  0.03496516 Validation Decoder Loss:  0.33115882
Encoder Loss:  0.04933301  || Decoder Loss:  0.034974568 Validation Decoder Loss:  0.3311041
Encoder Loss:  0.049336743  || Decoder Loss:  0.0349752 Validation Decoder Loss:  0.33103782
Encoder Loss:  0.04933498  || Decoder Loss:  0.034979343 Validation Decoder Loss:  0.33098423
Encoder Loss:  0.04933263  || Decoder Loss:  0.03497917 Validation Decoder Loss:  0.33094275
Encoder Loss:  0.04933221  || Decoder Loss:  0.03498423 Validation Decoder Loss:  0.3308946
Encoder Loss:  0.04933059  || Decoder Loss:  0.034976862 Validation Decoder Loss:  0.33084893
Encoder Loss:  0.049331058  || Decoder Loss:  0.034976564 Validation Decoder Loss:  0.33082578
Encoder Loss:  0.049330663  || Decoder Loss:  0.034980178 Validation Decoder Loss:  0.33079803
Encoder Loss:  0.0493291  || Decoder Loss:  0.034976684 Validation Decoder Loss:  0.3307779
Model: siamese_net_lr_0.0004329776465535423 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3307779
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 194, 10, 20, 1)    409       
_________________________________________________________________
dropout_273 (Dropout)        (None, 194, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 220, 11, 20, 1)    55        
_________________________________________________________________
reshape_58 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 464
Trainable params: 464
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_275 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_92 (Conv2D)           (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_277 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_92 (Conv2DT (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33190745  || Decoder Loss:  0.06672049 Validation Decoder Loss:  0.3650728
Encoder Loss:  0.32754534  || Decoder Loss:  0.07095053 Validation Decoder Loss:  0.36554834
Encoder Loss:  0.32012236  || Decoder Loss:  0.07810561 Validation Decoder Loss:  0.3688147
Encoder Loss:  0.30293915  || Decoder Loss:  0.09501412 Validation Decoder Loss:  0.38968483
Encoder Loss:  0.22302963  || Decoder Loss:  0.23488542 Validation Decoder Loss:  0.79583395
Encoder Loss:  0.121491164  || Decoder Loss:  0.21197107 Validation Decoder Loss:  0.44705653
Encoder Loss:  0.08914221  || Decoder Loss:  0.08606338 Validation Decoder Loss:  0.37444526
Encoder Loss:  0.079167366  || Decoder Loss:  0.049104013 Validation Decoder Loss:  0.3351312
Encoder Loss:  0.053422082  || Decoder Loss:  0.036614254 Validation Decoder Loss:  0.33261096
Encoder Loss:  0.04666563  || Decoder Loss:  0.03583962 Validation Decoder Loss:  0.33214772
Encoder Loss:  0.046593238  || Decoder Loss:  0.035602767 Validation Decoder Loss:  0.33193022
Encoder Loss:  0.046559945  || Decoder Loss:  0.0354722 Validation Decoder Loss:  0.33178878
Encoder Loss:  0.046541706  || Decoder Loss:  0.035396926 Validation Decoder Loss:  0.33170283
Encoder Loss:  0.046530534  || Decoder Loss:  0.035350807 Validation Decoder Loss:  0.331644
Encoder Loss:  0.04652133  || Decoder Loss:  0.03531986 Validation Decoder Loss:  0.3316012
Encoder Loss:  0.046516057  || Decoder Loss:  0.03529723 Validation Decoder Loss:  0.33157128
Encoder Loss:  0.046510868  || Decoder Loss:  0.03527992 Validation Decoder Loss:  0.33154595
Encoder Loss:  0.046506714  || Decoder Loss:  0.035265435 Validation Decoder Loss:  0.33152556
Encoder Loss:  0.046503413  || Decoder Loss:  0.035253063 Validation Decoder Loss:  0.33150905
Encoder Loss:  0.046500087  || Decoder Loss:  0.035242487 Validation Decoder Loss:  0.3314975
Encoder Loss:  0.046497237  || Decoder Loss:  0.035232678 Validation Decoder Loss:  0.33148712
Encoder Loss:  0.04649417  || Decoder Loss:  0.03522405 Validation Decoder Loss:  0.33148575
Encoder Loss:  0.04649207  || Decoder Loss:  0.03521581 Validation Decoder Loss:  0.331487
Encoder Loss:  0.046489567  || Decoder Loss:  0.035208408 Validation Decoder Loss:  0.3315028
Encoder Loss:  0.04648779  || Decoder Loss:  0.03520114 Validation Decoder Loss:  0.33151972
Encoder Loss:  0.046485726  || Decoder Loss:  0.03519452 Validation Decoder Loss:  0.33155617
Encoder Loss:  0.046483923  || Decoder Loss:  0.035187963 Validation Decoder Loss:  0.33160752
Encoder Loss:  0.04648233  || Decoder Loss:  0.035181716 Validation Decoder Loss:  0.33167475
Encoder Loss:  0.04648072  || Decoder Loss:  0.0351756 Validation Decoder Loss:  0.33174765
Encoder Loss:  0.046479  || Decoder Loss:  0.035169467 Validation Decoder Loss:  0.33178705
Encoder Loss:  0.046477284  || Decoder Loss:  0.035163604 Validation Decoder Loss:  0.3317892
Encoder Loss:  0.046475954  || Decoder Loss:  0.03515821 Validation Decoder Loss:  0.33181402
Encoder Loss:  0.046474338  || Decoder Loss:  0.035153143 Validation Decoder Loss:  0.3318349
Encoder Loss:  0.046473023  || Decoder Loss:  0.03514797 Validation Decoder Loss:  0.3318239
Encoder Loss:  0.046471983  || Decoder Loss:  0.035143018 Validation Decoder Loss:  0.33184132
Encoder Loss:  0.046470642  || Decoder Loss:  0.035137746 Validation Decoder Loss:  0.33183026
Encoder Loss:  0.0464692  || Decoder Loss:  0.035132896 Validation Decoder Loss:  0.33184293
Encoder Loss:  0.046468243  || Decoder Loss:  0.035128288 Validation Decoder Loss:  0.33185363
Encoder Loss:  0.04646705  || Decoder Loss:  0.035123184 Validation Decoder Loss:  0.33184123
Encoder Loss:  0.046465624  || Decoder Loss:  0.03511824 Validation Decoder Loss:  0.33184448
Model: siamese_net_lr_0.000738933807123635 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33184448
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 123, 10, 20, 1)    361       
_________________________________________________________________
dropout_279 (Dropout)        (None, 123, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 220, 11, 20, 1)    197       
_________________________________________________________________
reshape_59 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 558
Trainable params: 558
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_281 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_94 (Conv2D)           (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_283 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_94 (Conv2DT (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3138471  || Decoder Loss:  0.12802503 Validation Decoder Loss:  0.4186859
Encoder Loss:  0.16801487  || Decoder Loss:  0.119654305 Validation Decoder Loss:  0.36795276
Encoder Loss:  0.070668414  || Decoder Loss:  0.04352473 Validation Decoder Loss:  0.33261725
Encoder Loss:  0.05071797  || Decoder Loss:  0.03551216 Validation Decoder Loss:  0.3313414
Encoder Loss:  0.04727895  || Decoder Loss:  0.034776486 Validation Decoder Loss:  0.33149374
Encoder Loss:  0.047182437  || Decoder Loss:  0.03437525 Validation Decoder Loss:  0.3314466
Encoder Loss:  0.047138263  || Decoder Loss:  0.03416363 Validation Decoder Loss:  0.33130857
Encoder Loss:  0.04711917  || Decoder Loss:  0.034098513 Validation Decoder Loss:  0.3316058
Encoder Loss:  0.04710203  || Decoder Loss:  0.034008432 Validation Decoder Loss:  0.33158058
Encoder Loss:  0.04709699  || Decoder Loss:  0.033988148 Validation Decoder Loss:  0.3314628
Encoder Loss:  0.047079287  || Decoder Loss:  0.033930644 Validation Decoder Loss:  0.33169538
Encoder Loss:  0.047080737  || Decoder Loss:  0.03393934 Validation Decoder Loss:  0.33168548
Encoder Loss:  0.047080703  || Decoder Loss:  0.033949874 Validation Decoder Loss:  0.3317099
Encoder Loss:  0.047078025  || Decoder Loss:  0.03395249 Validation Decoder Loss:  0.3317085
Encoder Loss:  0.047081288  || Decoder Loss:  0.033966504 Validation Decoder Loss:  0.33166343
Encoder Loss:  0.04708079  || Decoder Loss:  0.033970147 Validation Decoder Loss:  0.33150482
Encoder Loss:  0.047081865  || Decoder Loss:  0.0339858 Validation Decoder Loss:  0.33131325
Encoder Loss:  0.04708656  || Decoder Loss:  0.034008432 Validation Decoder Loss:  0.3310775
Encoder Loss:  0.04709046  || Decoder Loss:  0.034037057 Validation Decoder Loss:  0.33094716
Encoder Loss:  0.04711621  || Decoder Loss:  0.03416878 Validation Decoder Loss:  0.3308
Encoder Loss:  0.04710581  || Decoder Loss:  0.034121472 Validation Decoder Loss:  0.33075333
Encoder Loss:  0.04711716  || Decoder Loss:  0.034189295 Validation Decoder Loss:  0.33029044
Encoder Loss:  0.047124434  || Decoder Loss:  0.034225695 Validation Decoder Loss:  0.33026636
Encoder Loss:  0.047131985  || Decoder Loss:  0.034272473 Validation Decoder Loss:  0.3303997
Encoder Loss:  0.047136653  || Decoder Loss:  0.034287404 Validation Decoder Loss:  0.3299521
Encoder Loss:  0.04714487  || Decoder Loss:  0.03433343 Validation Decoder Loss:  0.3297754
Encoder Loss:  0.04715186  || Decoder Loss:  0.034361944 Validation Decoder Loss:  0.32969534
Encoder Loss:  0.047149688  || Decoder Loss:  0.03437965 Validation Decoder Loss:  0.329059
Encoder Loss:  0.047153  || Decoder Loss:  0.03440008 Validation Decoder Loss:  0.32898048
Encoder Loss:  0.047153357  || Decoder Loss:  0.034396417 Validation Decoder Loss:  0.32808304
Encoder Loss:  0.047154646  || Decoder Loss:  0.034376193 Validation Decoder Loss:  0.32814327
Encoder Loss:  0.047144994  || Decoder Loss:  0.034355912 Validation Decoder Loss:  0.32779062
Encoder Loss:  0.047139816  || Decoder Loss:  0.034332167 Validation Decoder Loss:  0.3276407
Encoder Loss:  0.047136847  || Decoder Loss:  0.034307353 Validation Decoder Loss:  0.32712513
Encoder Loss:  0.047130026  || Decoder Loss:  0.034280997 Validation Decoder Loss:  0.32650775
Encoder Loss:  0.04712493  || Decoder Loss:  0.03425333 Validation Decoder Loss:  0.3261299
Encoder Loss:  0.04711897  || Decoder Loss:  0.034226224 Validation Decoder Loss:  0.3257706
Encoder Loss:  0.047115646  || Decoder Loss:  0.034195185 Validation Decoder Loss:  0.32563394
Encoder Loss:  0.04711005  || Decoder Loss:  0.034165725 Validation Decoder Loss:  0.32550874
Encoder Loss:  0.04710346  || Decoder Loss:  0.034141537 Validation Decoder Loss:  0.32535475
Model: siamese_net_lr_0.00033311342366764546 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32535475
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 127, 10, 20, 1)    129       
_________________________________________________________________
dropout_285 (Dropout)        (None, 127, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 220, 11, 20, 1)    189       
_________________________________________________________________
reshape_60 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_287 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_96 (Conv2D)           (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_289 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_96 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25168964  || Decoder Loss:  0.11950272 Validation Decoder Loss:  0.43481946
Encoder Loss:  0.11621362  || Decoder Loss:  0.12063208 Validation Decoder Loss:  0.33635056
Encoder Loss:  0.06285743  || Decoder Loss:  0.04413118 Validation Decoder Loss:  0.3290657
Encoder Loss:  0.045344424  || Decoder Loss:  0.036776826 Validation Decoder Loss:  0.32839456
Encoder Loss:  0.044080637  || Decoder Loss:  0.03482091 Validation Decoder Loss:  0.32854497
Encoder Loss:  0.044043235  || Decoder Loss:  0.034761023 Validation Decoder Loss:  0.32887942
Encoder Loss:  0.04399938  || Decoder Loss:  0.034731597 Validation Decoder Loss:  0.32911974
Encoder Loss:  0.043978777  || Decoder Loss:  0.034709968 Validation Decoder Loss:  0.329296
Encoder Loss:  0.04395464  || Decoder Loss:  0.034690138 Validation Decoder Loss:  0.32944864
Encoder Loss:  0.043938436  || Decoder Loss:  0.034668382 Validation Decoder Loss:  0.32957184
Encoder Loss:  0.043907978  || Decoder Loss:  0.0346442 Validation Decoder Loss:  0.32970023
Encoder Loss:  0.043817263  || Decoder Loss:  0.034609884 Validation Decoder Loss:  0.32981944
Encoder Loss:  0.042699337  || Decoder Loss:  0.034636386 Validation Decoder Loss:  0.329745
Encoder Loss:  0.042645857  || Decoder Loss:  0.034638915 Validation Decoder Loss:  0.3298058
Encoder Loss:  0.04264179  || Decoder Loss:  0.03465344 Validation Decoder Loss:  0.32985377
Encoder Loss:  0.04265141  || Decoder Loss:  0.034680065 Validation Decoder Loss:  0.32987675
Encoder Loss:  0.04266528  || Decoder Loss:  0.03471307 Validation Decoder Loss:  0.32987612
Encoder Loss:  0.042681802  || Decoder Loss:  0.034751046 Validation Decoder Loss:  0.32990405
Encoder Loss:  0.042698838  || Decoder Loss:  0.034789726 Validation Decoder Loss:  0.33047944
Encoder Loss:  0.04270985  || Decoder Loss:  0.034814913 Validation Decoder Loss:  0.33088726
Encoder Loss:  0.04271565  || Decoder Loss:  0.034826197 Validation Decoder Loss:  0.33132148
Encoder Loss:  0.0427196  || Decoder Loss:  0.0348357 Validation Decoder Loss:  0.33157367
Encoder Loss:  0.042719718  || Decoder Loss:  0.03483678 Validation Decoder Loss:  0.3315602
Encoder Loss:  0.04271529  || Decoder Loss:  0.034828447 Validation Decoder Loss:  0.33164144
Encoder Loss:  0.042712737  || Decoder Loss:  0.034820825 Validation Decoder Loss:  0.33157262
Encoder Loss:  0.04270566  || Decoder Loss:  0.03480915 Validation Decoder Loss:  0.3316207
Encoder Loss:  0.042703424  || Decoder Loss:  0.034795765 Validation Decoder Loss:  0.33171612
Encoder Loss:  0.042695597  || Decoder Loss:  0.034787897 Validation Decoder Loss:  0.3316157
Encoder Loss:  0.04269043  || Decoder Loss:  0.034775816 Validation Decoder Loss:  0.33155894
Encoder Loss:  0.0426859  || Decoder Loss:  0.034762684 Validation Decoder Loss:  0.3316934
Encoder Loss:  0.042677484  || Decoder Loss:  0.03475068 Validation Decoder Loss:  0.33183375
Encoder Loss:  0.042670812  || Decoder Loss:  0.034734663 Validation Decoder Loss:  0.33188337
Encoder Loss:  0.04266519  || Decoder Loss:  0.034721397 Validation Decoder Loss:  0.33176813
Encoder Loss:  0.042658243  || Decoder Loss:  0.03470788 Validation Decoder Loss:  0.3317864
Encoder Loss:  0.042649716  || Decoder Loss:  0.034692317 Validation Decoder Loss:  0.3318649
Encoder Loss:  0.042640563  || Decoder Loss:  0.034673892 Validation Decoder Loss:  0.33196414
Encoder Loss:  0.042632226  || Decoder Loss:  0.034655955 Validation Decoder Loss:  0.3321051
Encoder Loss:  0.042621437  || Decoder Loss:  0.034632806 Validation Decoder Loss:  0.33208877
Encoder Loss:  0.0426108  || Decoder Loss:  0.034610834 Validation Decoder Loss:  0.33229804
Encoder Loss:  0.042604968  || Decoder Loss:  0.034600526 Validation Decoder Loss:  0.33244598
Model: siamese_net_lr_0.0006575610360699212 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33244598
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 200, 6, 20, 1)     275       
_________________________________________________________________
dropout_291 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 220, 11, 20, 1)    127       
_________________________________________________________________
reshape_61 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 402
Trainable params: 402
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_293 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_98 (Conv2D)           (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_295 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_98 (Conv2DT (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13007955  || Decoder Loss:  0.06483248 Validation Decoder Loss:  0.36523753
Encoder Loss:  0.14171223  || Decoder Loss:  0.08618572 Validation Decoder Loss:  0.3896592
Encoder Loss:  0.24916574  || Decoder Loss:  0.26701555 Validation Decoder Loss:  0.5565598
Encoder Loss:  0.08153303  || Decoder Loss:  0.081846915 Validation Decoder Loss:  0.39026895
Encoder Loss:  0.056647696  || Decoder Loss:  0.05086257 Validation Decoder Loss:  0.33987337
Encoder Loss:  0.044044737  || Decoder Loss:  0.035373673 Validation Decoder Loss:  0.33243063
Encoder Loss:  0.04303786  || Decoder Loss:  0.034551267 Validation Decoder Loss:  0.33149338
Encoder Loss:  0.04107903  || Decoder Loss:  0.034457255 Validation Decoder Loss:  0.3310073
Encoder Loss:  0.037696138  || Decoder Loss:  0.034343734 Validation Decoder Loss:  0.33008468
Encoder Loss:  0.037417673  || Decoder Loss:  0.0341714 Validation Decoder Loss:  0.33156076
Encoder Loss:  0.037340913  || Decoder Loss:  0.034125786 Validation Decoder Loss:  0.33167756
Encoder Loss:  0.03732073  || Decoder Loss:  0.034101073 Validation Decoder Loss:  0.33171666
Encoder Loss:  0.037308503  || Decoder Loss:  0.034085978 Validation Decoder Loss:  0.33175007
Encoder Loss:  0.03730218  || Decoder Loss:  0.03407835 Validation Decoder Loss:  0.3318121
Encoder Loss:  0.03730086  || Decoder Loss:  0.034076788 Validation Decoder Loss:  0.33188874
Encoder Loss:  0.037302267  || Decoder Loss:  0.034078702 Validation Decoder Loss:  0.3319468
Encoder Loss:  0.037305202  || Decoder Loss:  0.034082796 Validation Decoder Loss:  0.33197182
Encoder Loss:  0.037308313  || Decoder Loss:  0.034086715 Validation Decoder Loss:  0.33195484
Encoder Loss:  0.037310213  || Decoder Loss:  0.034089208 Validation Decoder Loss:  0.33191425
Encoder Loss:  0.03731197  || Decoder Loss:  0.034091573 Validation Decoder Loss:  0.33190742
Encoder Loss:  0.03731182  || Decoder Loss:  0.034091722 Validation Decoder Loss:  0.331985
Encoder Loss:  0.037311397  || Decoder Loss:  0.034091197 Validation Decoder Loss:  0.33205634
Encoder Loss:  0.037310015  || Decoder Loss:  0.034089793 Validation Decoder Loss:  0.33208227
Encoder Loss:  0.03730505  || Decoder Loss:  0.034083407 Validation Decoder Loss:  0.3320582
Encoder Loss:  0.03729856  || Decoder Loss:  0.034075867 Validation Decoder Loss:  0.3320254
Encoder Loss:  0.03728887  || Decoder Loss:  0.034063693 Validation Decoder Loss:  0.33197498
Encoder Loss:  0.037275318  || Decoder Loss:  0.034046754 Validation Decoder Loss:  0.33194053
Encoder Loss:  0.037259914  || Decoder Loss:  0.034027886 Validation Decoder Loss:  0.33187616
Encoder Loss:  0.037242163  || Decoder Loss:  0.034005687 Validation Decoder Loss:  0.33180943
Encoder Loss:  0.037219204  || Decoder Loss:  0.03397702 Validation Decoder Loss:  0.33173025
Encoder Loss:  0.037195712  || Decoder Loss:  0.03394738 Validation Decoder Loss:  0.33166778
Encoder Loss:  0.037169136  || Decoder Loss:  0.033914275 Validation Decoder Loss:  0.33159363
Encoder Loss:  0.03714171  || Decoder Loss:  0.033879835 Validation Decoder Loss:  0.33154625
Encoder Loss:  0.037114847  || Decoder Loss:  0.033846315 Validation Decoder Loss:  0.33148283
Encoder Loss:  0.037088227  || Decoder Loss:  0.033812944 Validation Decoder Loss:  0.33143055
Encoder Loss:  0.037066016  || Decoder Loss:  0.03378506 Validation Decoder Loss:  0.33133817
Encoder Loss:  0.037040427  || Decoder Loss:  0.033753153 Validation Decoder Loss:  0.3312269
Encoder Loss:  0.03702047  || Decoder Loss:  0.033728153 Validation Decoder Loss:  0.33114132
Encoder Loss:  0.037006453  || Decoder Loss:  0.033710405 Validation Decoder Loss:  0.33111456
Encoder Loss:  0.03699392  || Decoder Loss:  0.033694886 Validation Decoder Loss:  0.33107185
Model: siamese_net_lr_0.0003296538792637598 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33107185
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 120, 10, 20, 1)    343       
_________________________________________________________________
dropout_297 (Dropout)        (None, 120, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 220, 11, 20, 1)    203       
_________________________________________________________________
reshape_62 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 546
Trainable params: 546
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_299 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_100 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_301 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_100 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29339737  || Decoder Loss:  0.116998434 Validation Decoder Loss:  0.3947474
Encoder Loss:  0.28419378  || Decoder Loss:  0.13280982 Validation Decoder Loss:  0.4115477
Encoder Loss:  0.26341784  || Decoder Loss:  0.16172042 Validation Decoder Loss:  0.470388
Encoder Loss:  0.12251746  || Decoder Loss:  0.11361766 Validation Decoder Loss:  0.39441937
Encoder Loss:  0.07726038  || Decoder Loss:  0.07104281 Validation Decoder Loss:  0.34929076
Encoder Loss:  0.06588746  || Decoder Loss:  0.03882723 Validation Decoder Loss:  0.33148938
Encoder Loss:  0.061085477  || Decoder Loss:  0.035650596 Validation Decoder Loss:  0.33081564
Encoder Loss:  0.04591011  || Decoder Loss:  0.035079837 Validation Decoder Loss:  0.33087856
Encoder Loss:  0.045434445  || Decoder Loss:  0.03471622 Validation Decoder Loss:  0.3311984
Encoder Loss:  0.045409046  || Decoder Loss:  0.034707703 Validation Decoder Loss:  0.33120567
Encoder Loss:  0.045402214  || Decoder Loss:  0.034702968 Validation Decoder Loss:  0.331281
Encoder Loss:  0.045392565  || Decoder Loss:  0.0346773 Validation Decoder Loss:  0.33137262
Encoder Loss:  0.045391675  || Decoder Loss:  0.034675628 Validation Decoder Loss:  0.3314104
Encoder Loss:  0.04540806  || Decoder Loss:  0.034702808 Validation Decoder Loss:  0.33146513
Encoder Loss:  0.045398813  || Decoder Loss:  0.03468612 Validation Decoder Loss:  0.33145824
Encoder Loss:  0.045388114  || Decoder Loss:  0.03467654 Validation Decoder Loss:  0.3314636
Encoder Loss:  0.04538982  || Decoder Loss:  0.034670666 Validation Decoder Loss:  0.3314607
Encoder Loss:  0.045386653  || Decoder Loss:  0.03469275 Validation Decoder Loss:  0.33143377
Encoder Loss:  0.04539106  || Decoder Loss:  0.034672108 Validation Decoder Loss:  0.33143878
Encoder Loss:  0.04538592  || Decoder Loss:  0.03465743 Validation Decoder Loss:  0.33142483
Encoder Loss:  0.04538465  || Decoder Loss:  0.03465874 Validation Decoder Loss:  0.33136797
Encoder Loss:  0.0453723  || Decoder Loss:  0.034652494 Validation Decoder Loss:  0.3312834
Encoder Loss:  0.045368124  || Decoder Loss:  0.034636367 Validation Decoder Loss:  0.3310577
Encoder Loss:  0.045368746  || Decoder Loss:  0.034628574 Validation Decoder Loss:  0.33089978
Encoder Loss:  0.04535757  || Decoder Loss:  0.034583546 Validation Decoder Loss:  0.33077604
Encoder Loss:  0.04534974  || Decoder Loss:  0.03456353 Validation Decoder Loss:  0.3307556
Encoder Loss:  0.045343738  || Decoder Loss:  0.034549616 Validation Decoder Loss:  0.33071542
Encoder Loss:  0.04533811  || Decoder Loss:  0.034541648 Validation Decoder Loss:  0.33069247
Encoder Loss:  0.04532884  || Decoder Loss:  0.034501486 Validation Decoder Loss:  0.3306541
Encoder Loss:  0.04532568  || Decoder Loss:  0.034490623 Validation Decoder Loss:  0.33064076
Encoder Loss:  0.045317892  || Decoder Loss:  0.03448445 Validation Decoder Loss:  0.33057785
Encoder Loss:  0.04531205  || Decoder Loss:  0.034462795 Validation Decoder Loss:  0.33052796
Encoder Loss:  0.045307964  || Decoder Loss:  0.034436427 Validation Decoder Loss:  0.3305425
Encoder Loss:  0.045303628  || Decoder Loss:  0.034428693 Validation Decoder Loss:  0.33048165
Encoder Loss:  0.04529705  || Decoder Loss:  0.03440989 Validation Decoder Loss:  0.3304435
Encoder Loss:  0.04529299  || Decoder Loss:  0.034393996 Validation Decoder Loss:  0.3304564
Encoder Loss:  0.04527995  || Decoder Loss:  0.03435839 Validation Decoder Loss:  0.3304252
Encoder Loss:  0.045279738  || Decoder Loss:  0.03436295 Validation Decoder Loss:  0.33040267
Encoder Loss:  0.04527993  || Decoder Loss:  0.034357246 Validation Decoder Loss:  0.33037716
Encoder Loss:  0.04527736  || Decoder Loss:  0.03435243 Validation Decoder Loss:  0.33035308
Model: siamese_net_lr_0.0005611046399261668 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33035308
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_303 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_63 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 550
Trainable params: 550
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_305 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_102 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_307 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_102 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12246974  || Decoder Loss:  0.11415746 Validation Decoder Loss:  0.38913426
Encoder Loss:  0.12936985  || Decoder Loss:  0.121581644 Validation Decoder Loss:  0.3959853
Encoder Loss:  0.13727584  || Decoder Loss:  0.13010967 Validation Decoder Loss:  0.4040899
Encoder Loss:  0.14706612  || Decoder Loss:  0.14070496 Validation Decoder Loss:  0.41507414
Encoder Loss:  0.16104935  || Decoder Loss:  0.15589498 Validation Decoder Loss:  0.43495095
Encoder Loss:  0.169494  || Decoder Loss:  0.16618012 Validation Decoder Loss:  0.3774015
Encoder Loss:  0.109972544  || Decoder Loss:  0.109602414 Validation Decoder Loss:  0.41763467
Encoder Loss:  0.092419  || Decoder Loss:  0.09279238 Validation Decoder Loss:  0.38360918
Encoder Loss:  0.07305212  || Decoder Loss:  0.07281265 Validation Decoder Loss:  0.36050695
Encoder Loss:  0.055942275  || Decoder Loss:  0.055171147 Validation Decoder Loss:  0.34627217
Encoder Loss:  0.044141263  || Decoder Loss:  0.043015394 Validation Decoder Loss:  0.33707654
Encoder Loss:  0.038862154  || Decoder Loss:  0.03761337 Validation Decoder Loss:  0.33347782
Encoder Loss:  0.037197817  || Decoder Loss:  0.03596419 Validation Decoder Loss:  0.3324417
Encoder Loss:  0.036687594  || Decoder Loss:  0.03554173 Validation Decoder Loss:  0.33234873
Encoder Loss:  0.036391318  || Decoder Loss:  0.035401467 Validation Decoder Loss:  0.33256304
Encoder Loss:  0.03608101  || Decoder Loss:  0.035306904 Validation Decoder Loss:  0.33283305
Encoder Loss:  0.035844024  || Decoder Loss:  0.035210647 Validation Decoder Loss:  0.3328876
Encoder Loss:  0.035695933  || Decoder Loss:  0.03510864 Validation Decoder Loss:  0.332815
Encoder Loss:  0.035570715  || Decoder Loss:  0.035017677 Validation Decoder Loss:  0.33270442
Encoder Loss:  0.035513464  || Decoder Loss:  0.034982033 Validation Decoder Loss:  0.3326045
Encoder Loss:  0.035514284  || Decoder Loss:  0.03500745 Validation Decoder Loss:  0.3325789
Encoder Loss:  0.035510972  || Decoder Loss:  0.035024367 Validation Decoder Loss:  0.33238822
Encoder Loss:  0.03547524  || Decoder Loss:  0.034992624 Validation Decoder Loss:  0.33275443
Encoder Loss:  0.035426687  || Decoder Loss:  0.034942504 Validation Decoder Loss:  0.3329348
Encoder Loss:  0.035399064  || Decoder Loss:  0.03491397 Validation Decoder Loss:  0.33307284
Encoder Loss:  0.035376042  || Decoder Loss:  0.034890223 Validation Decoder Loss:  0.33322674
Encoder Loss:  0.035355415  || Decoder Loss:  0.03486892 Validation Decoder Loss:  0.33336595
Encoder Loss:  0.035337757  || Decoder Loss:  0.0348507 Validation Decoder Loss:  0.33347768
Encoder Loss:  0.035322  || Decoder Loss:  0.034834445 Validation Decoder Loss:  0.33355922
Encoder Loss:  0.03530806  || Decoder Loss:  0.034820043 Validation Decoder Loss:  0.33361176
Encoder Loss:  0.035295896  || Decoder Loss:  0.034807492 Validation Decoder Loss:  0.33364618
Encoder Loss:  0.035284817  || Decoder Loss:  0.034796048 Validation Decoder Loss:  0.33366856
Encoder Loss:  0.035274062  || Decoder Loss:  0.034785002 Validation Decoder Loss:  0.33368045
Encoder Loss:  0.035265006  || Decoder Loss:  0.034775656 Validation Decoder Loss:  0.33369672
Encoder Loss:  0.035256483  || Decoder Loss:  0.034766894 Validation Decoder Loss:  0.3337107
Encoder Loss:  0.035248533  || Decoder Loss:  0.034758642 Validation Decoder Loss:  0.3337407
Encoder Loss:  0.035240084  || Decoder Loss:  0.03475001 Validation Decoder Loss:  0.33375022
Encoder Loss:  0.035232756  || Decoder Loss:  0.03474243 Validation Decoder Loss:  0.3337674
Encoder Loss:  0.035223965  || Decoder Loss:  0.034733385 Validation Decoder Loss:  0.3337776
Encoder Loss:  0.035215605  || Decoder Loss:  0.03472476 Validation Decoder Loss:  0.3337754
Model: siamese_net_lr_0.00031430670715372407 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3337754
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 110, 11, 20, 1)    142       
_________________________________________________________________
dropout_309 (Dropout)        (None, 110, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 220, 11, 20, 1)    3         
_________________________________________________________________
reshape_64 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 145
Trainable params: 145
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_311 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_104 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_313 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_104 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147746 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.04114776 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147765 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.04114776 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147754 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Encoder Loss:  0.4486171  || Decoder Loss:  0.041147757 Validation Decoder Loss:  0.34541178
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34541178
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 155, 8, 20, 1)     117       
_________________________________________________________________
dropout_315 (Dropout)        (None, 155, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 220, 11, 20, 1)    265       
_________________________________________________________________
reshape_65 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_317 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_106 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_319 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_106 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24148381  || Decoder Loss:  0.15018931 Validation Decoder Loss:  0.3610015
Encoder Loss:  0.050530873  || Decoder Loss:  0.038094338 Validation Decoder Loss:  0.33089334
Encoder Loss:  0.049211875  || Decoder Loss:  0.035447188 Validation Decoder Loss:  0.33076686
Encoder Loss:  0.049038906  || Decoder Loss:  0.0352725 Validation Decoder Loss:  0.33070362
Encoder Loss:  0.04897389  || Decoder Loss:  0.035161115 Validation Decoder Loss:  0.3306716
Encoder Loss:  0.048965  || Decoder Loss:  0.035079744 Validation Decoder Loss:  0.33066297
Encoder Loss:  0.04887099  || Decoder Loss:  0.03501165 Validation Decoder Loss:  0.3306602
Encoder Loss:  0.048654266  || Decoder Loss:  0.034974113 Validation Decoder Loss:  0.33064476
Encoder Loss:  0.048446927  || Decoder Loss:  0.03497635 Validation Decoder Loss:  0.33064243
Encoder Loss:  0.048433658  || Decoder Loss:  0.035006 Validation Decoder Loss:  0.33060163
Encoder Loss:  0.048428718  || Decoder Loss:  0.035014864 Validation Decoder Loss:  0.330566
Encoder Loss:  0.048424583  || Decoder Loss:  0.03502917 Validation Decoder Loss:  0.33052763
Encoder Loss:  0.04843187  || Decoder Loss:  0.03503461 Validation Decoder Loss:  0.33042166
Encoder Loss:  0.048423056  || Decoder Loss:  0.035007905 Validation Decoder Loss:  0.33085606
Encoder Loss:  0.048406493  || Decoder Loss:  0.034916807 Validation Decoder Loss:  0.33041233
Encoder Loss:  0.04838276  || Decoder Loss:  0.03466772 Validation Decoder Loss:  0.32962567
Encoder Loss:  0.048345696  || Decoder Loss:  0.03438165 Validation Decoder Loss:  0.3284486
Encoder Loss:  0.04833273  || Decoder Loss:  0.034253124 Validation Decoder Loss:  0.32733595
Encoder Loss:  0.048321202  || Decoder Loss:  0.03418379 Validation Decoder Loss:  0.32663345
Encoder Loss:  0.048315983  || Decoder Loss:  0.034135573 Validation Decoder Loss:  0.32623503
Encoder Loss:  0.048308425  || Decoder Loss:  0.034093026 Validation Decoder Loss:  0.3263188
Encoder Loss:  0.04830182  || Decoder Loss:  0.034067795 Validation Decoder Loss:  0.32719916
Encoder Loss:  0.048289374  || Decoder Loss:  0.034041267 Validation Decoder Loss:  0.3285338
Encoder Loss:  0.04828382  || Decoder Loss:  0.034018394 Validation Decoder Loss:  0.32893103
Encoder Loss:  0.04827677  || Decoder Loss:  0.033981785 Validation Decoder Loss:  0.32952183
Encoder Loss:  0.048264228  || Decoder Loss:  0.03395504 Validation Decoder Loss:  0.3296967
Encoder Loss:  0.04826146  || Decoder Loss:  0.033929553 Validation Decoder Loss:  0.32987067
Encoder Loss:  0.048259176  || Decoder Loss:  0.033907857 Validation Decoder Loss:  0.33009636
Encoder Loss:  0.04825568  || Decoder Loss:  0.03389429 Validation Decoder Loss:  0.33013013
Encoder Loss:  0.04825519  || Decoder Loss:  0.033881344 Validation Decoder Loss:  0.3304057
Encoder Loss:  0.048250936  || Decoder Loss:  0.033871718 Validation Decoder Loss:  0.33038285
Encoder Loss:  0.04824962  || Decoder Loss:  0.033866085 Validation Decoder Loss:  0.33057562
Encoder Loss:  0.048247572  || Decoder Loss:  0.03386458 Validation Decoder Loss:  0.3304796
Encoder Loss:  0.048247814  || Decoder Loss:  0.03386113 Validation Decoder Loss:  0.3306173
Encoder Loss:  0.048247352  || Decoder Loss:  0.033861533 Validation Decoder Loss:  0.3305486
Encoder Loss:  0.04824362  || Decoder Loss:  0.033855475 Validation Decoder Loss:  0.33082741
Encoder Loss:  0.04824376  || Decoder Loss:  0.033857618 Validation Decoder Loss:  0.33075112
Encoder Loss:  0.048243552  || Decoder Loss:  0.033853374 Validation Decoder Loss:  0.33094788
Encoder Loss:  0.04824244  || Decoder Loss:  0.033856098 Validation Decoder Loss:  0.3308133
Encoder Loss:  0.048242614  || Decoder Loss:  0.033851516 Validation Decoder Loss:  0.3309022
Model: siamese_net_lr_0.0006841311756026121 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3309022
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 125, 10, 20, 1)    125       
_________________________________________________________________
dropout_321 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_66 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_107 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_323 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_108 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_107 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_325 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_108 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34550655  || Decoder Loss:  0.108769484 Validation Decoder Loss:  0.3868091
Encoder Loss:  0.33596596  || Decoder Loss:  0.12201933 Validation Decoder Loss:  0.4016009
Encoder Loss:  0.24201602  || Decoder Loss:  0.21374339 Validation Decoder Loss:  0.45766407
Encoder Loss:  0.08988759  || Decoder Loss:  0.06814035 Validation Decoder Loss:  0.33749884
Encoder Loss:  0.08468747  || Decoder Loss:  0.04481099 Validation Decoder Loss:  0.33479077
Encoder Loss:  0.081799366  || Decoder Loss:  0.044302776 Validation Decoder Loss:  0.33283958
Encoder Loss:  0.076969646  || Decoder Loss:  0.042500433 Validation Decoder Loss:  0.33121252
Encoder Loss:  0.06689478  || Decoder Loss:  0.03778019 Validation Decoder Loss:  0.32953572
Encoder Loss:  0.051611036  || Decoder Loss:  0.035110477 Validation Decoder Loss:  0.3292067
Encoder Loss:  0.050043106  || Decoder Loss:  0.034822747 Validation Decoder Loss:  0.32932246
Encoder Loss:  0.05002989  || Decoder Loss:  0.034771573 Validation Decoder Loss:  0.3294519
Encoder Loss:  0.050018772  || Decoder Loss:  0.034752086 Validation Decoder Loss:  0.32956082
Encoder Loss:  0.05001344  || Decoder Loss:  0.0347415 Validation Decoder Loss:  0.3296513
Encoder Loss:  0.05000265  || Decoder Loss:  0.034735397 Validation Decoder Loss:  0.32973582
Encoder Loss:  0.049989544  || Decoder Loss:  0.034729574 Validation Decoder Loss:  0.32980895
Encoder Loss:  0.04997628  || Decoder Loss:  0.03472545 Validation Decoder Loss:  0.32988134
Encoder Loss:  0.049969252  || Decoder Loss:  0.034720954 Validation Decoder Loss:  0.32995123
Encoder Loss:  0.049958173  || Decoder Loss:  0.03471565 Validation Decoder Loss:  0.33001924
Encoder Loss:  0.049934577  || Decoder Loss:  0.034709454 Validation Decoder Loss:  0.33008748
Encoder Loss:  0.04991746  || Decoder Loss:  0.03470223 Validation Decoder Loss:  0.33015627
Encoder Loss:  0.04989885  || Decoder Loss:  0.034693304 Validation Decoder Loss:  0.33022606
Encoder Loss:  0.049870882  || Decoder Loss:  0.034682818 Validation Decoder Loss:  0.3303009
Encoder Loss:  0.049836878  || Decoder Loss:  0.03466996 Validation Decoder Loss:  0.33038098
Encoder Loss:  0.049780153  || Decoder Loss:  0.03465403 Validation Decoder Loss:  0.3304727
Encoder Loss:  0.0496371  || Decoder Loss:  0.034631882 Validation Decoder Loss:  0.33058432
Encoder Loss:  0.04826435  || Decoder Loss:  0.034587983 Validation Decoder Loss:  0.33071655
Encoder Loss:  0.047893018  || Decoder Loss:  0.034561716 Validation Decoder Loss:  0.3307382
Encoder Loss:  0.047879595  || Decoder Loss:  0.034566965 Validation Decoder Loss:  0.33075118
Encoder Loss:  0.047876902  || Decoder Loss:  0.034573626 Validation Decoder Loss:  0.3307538
Encoder Loss:  0.0478762  || Decoder Loss:  0.03458344 Validation Decoder Loss:  0.33073705
Encoder Loss:  0.04787521  || Decoder Loss:  0.034595184 Validation Decoder Loss:  0.33069807
Encoder Loss:  0.047874913  || Decoder Loss:  0.034606334 Validation Decoder Loss:  0.3306182
Encoder Loss:  0.047871202  || Decoder Loss:  0.03461914 Validation Decoder Loss:  0.3304714
Encoder Loss:  0.047869846  || Decoder Loss:  0.034628678 Validation Decoder Loss:  0.3307598
Encoder Loss:  0.04786417  || Decoder Loss:  0.034607712 Validation Decoder Loss:  0.33148015
Encoder Loss:  0.047856808  || Decoder Loss:  0.034599837 Validation Decoder Loss:  0.33178923
Encoder Loss:  0.047854055  || Decoder Loss:  0.03460336 Validation Decoder Loss:  0.33192784
Encoder Loss:  0.04785023  || Decoder Loss:  0.03461318 Validation Decoder Loss:  0.3320273
Encoder Loss:  0.047846533  || Decoder Loss:  0.034628104 Validation Decoder Loss:  0.33211643
Encoder Loss:  0.047843963  || Decoder Loss:  0.03465104 Validation Decoder Loss:  0.3321916
Model: siamese_net_lr_0.0002828262610552701 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3321916
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 150, 8, 20, 1)     349       
_________________________________________________________________
dropout_327 (Dropout)        (None, 150, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 220, 11, 20, 1)    285       
_________________________________________________________________
reshape_67 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 634
Trainable params: 634
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_109 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_329 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_110 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_109 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_331 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_110 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10203399  || Decoder Loss:  0.10203399 Validation Decoder Loss:  0.3845269
Encoder Loss:  0.101548344  || Decoder Loss:  0.101548344 Validation Decoder Loss:  0.3967533
Encoder Loss:  0.07221425  || Decoder Loss:  0.07221425 Validation Decoder Loss:  0.3560193
Encoder Loss:  0.060940474  || Decoder Loss:  0.060940474 Validation Decoder Loss:  0.35470176
Encoder Loss:  0.05877665  || Decoder Loss:  0.05877665 Validation Decoder Loss:  0.3535288
Encoder Loss:  0.05560279  || Decoder Loss:  0.05560279 Validation Decoder Loss:  0.35135323
Encoder Loss:  0.05065138  || Decoder Loss:  0.05065138 Validation Decoder Loss:  0.34928185
Encoder Loss:  0.046552163  || Decoder Loss:  0.046552163 Validation Decoder Loss:  0.34604022
Encoder Loss:  0.04160307  || Decoder Loss:  0.04160307 Validation Decoder Loss:  0.34165376
Encoder Loss:  0.03744439  || Decoder Loss:  0.03744439 Validation Decoder Loss:  0.33852535
Encoder Loss:  0.035618022  || Decoder Loss:  0.035618022 Validation Decoder Loss:  0.33654627
Encoder Loss:  0.03504471  || Decoder Loss:  0.03504471 Validation Decoder Loss:  0.33593816
Encoder Loss:  0.034808364  || Decoder Loss:  0.034808364 Validation Decoder Loss:  0.33608213
Encoder Loss:  0.03466764  || Decoder Loss:  0.03466764 Validation Decoder Loss:  0.33651832
Encoder Loss:  0.034644864  || Decoder Loss:  0.034644864 Validation Decoder Loss:  0.3355092
Encoder Loss:  0.034530036  || Decoder Loss:  0.034530036 Validation Decoder Loss:  0.3360425
Encoder Loss:  0.03448495  || Decoder Loss:  0.03448495 Validation Decoder Loss:  0.33658844
Encoder Loss:  0.034454033  || Decoder Loss:  0.034454033 Validation Decoder Loss:  0.33704126
Encoder Loss:  0.03443112  || Decoder Loss:  0.03443112 Validation Decoder Loss:  0.33732012
Encoder Loss:  0.034412574  || Decoder Loss:  0.034412574 Validation Decoder Loss:  0.3374697
Encoder Loss:  0.034395684  || Decoder Loss:  0.034395684 Validation Decoder Loss:  0.3375784
Encoder Loss:  0.034378443  || Decoder Loss:  0.034378443 Validation Decoder Loss:  0.33771217
Encoder Loss:  0.034359947  || Decoder Loss:  0.034359947 Validation Decoder Loss:  0.33789414
Encoder Loss:  0.034340415  || Decoder Loss:  0.034340415 Validation Decoder Loss:  0.33811337
Encoder Loss:  0.03432063  || Decoder Loss:  0.03432063 Validation Decoder Loss:  0.33834925
Encoder Loss:  0.034301214  || Decoder Loss:  0.034301214 Validation Decoder Loss:  0.33858556
Encoder Loss:  0.0342825  || Decoder Loss:  0.0342825 Validation Decoder Loss:  0.33881068
Encoder Loss:  0.034264423  || Decoder Loss:  0.034264423 Validation Decoder Loss:  0.33901745
Encoder Loss:  0.03424668  || Decoder Loss:  0.03424668 Validation Decoder Loss:  0.33920243
Encoder Loss:  0.034228973  || Decoder Loss:  0.034228973 Validation Decoder Loss:  0.3393702
Encoder Loss:  0.034212157  || Decoder Loss:  0.034212157 Validation Decoder Loss:  0.33952415
Encoder Loss:  0.034196712  || Decoder Loss:  0.034196712 Validation Decoder Loss:  0.33965066
Encoder Loss:  0.034182034  || Decoder Loss:  0.034182034 Validation Decoder Loss:  0.3397562
Encoder Loss:  0.034167767  || Decoder Loss:  0.034167767 Validation Decoder Loss:  0.33984345
Encoder Loss:  0.034153752  || Decoder Loss:  0.034153752 Validation Decoder Loss:  0.33991277
Encoder Loss:  0.034140006  || Decoder Loss:  0.034140006 Validation Decoder Loss:  0.339971
Encoder Loss:  0.03412643  || Decoder Loss:  0.03412643 Validation Decoder Loss:  0.34003338
Encoder Loss:  0.03411308  || Decoder Loss:  0.03411308 Validation Decoder Loss:  0.34011394
Encoder Loss:  0.034099907  || Decoder Loss:  0.034099907 Validation Decoder Loss:  0.34017876
Encoder Loss:  0.034086574  || Decoder Loss:  0.034086574 Validation Decoder Loss:  0.34009117
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34009117
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_155 (Conv3D (None, 194, 10, 20, 1)    409       
_________________________________________________________________
dropout_333 (Dropout)        (None, 194, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_156 (Conv3D (None, 220, 11, 20, 1)    55        
_________________________________________________________________
reshape_68 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 464
Trainable params: 464
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_111 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_335 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_112 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_111 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_337 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_112 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2632062  || Decoder Loss:  0.06669183 Validation Decoder Loss:  0.36523914
Encoder Loss:  0.26120862  || Decoder Loss:  0.07065312 Validation Decoder Loss:  0.36570406
Encoder Loss:  0.25793475  || Decoder Loss:  0.07709855 Validation Decoder Loss:  0.3684855
Encoder Loss:  0.25104928  || Decoder Loss:  0.090835236 Validation Decoder Loss:  0.38264844
Encoder Loss:  0.23000807  || Decoder Loss:  0.17483453 Validation Decoder Loss:  0.7933052
Encoder Loss:  0.1696441  || Decoder Loss:  0.26990992 Validation Decoder Loss:  0.4840142
Encoder Loss:  0.09632121  || Decoder Loss:  0.103912175 Validation Decoder Loss:  0.40361142
Encoder Loss:  0.07361393  || Decoder Loss:  0.053161882 Validation Decoder Loss:  0.33477622
Encoder Loss:  0.06140639  || Decoder Loss:  0.036365163 Validation Decoder Loss:  0.3323398
Encoder Loss:  0.04408167  || Decoder Loss:  0.03562391 Validation Decoder Loss:  0.33165145
Encoder Loss:  0.043684453  || Decoder Loss:  0.035454463 Validation Decoder Loss:  0.33156642
Encoder Loss:  0.04364966  || Decoder Loss:  0.035386816 Validation Decoder Loss:  0.3315434
Encoder Loss:  0.043629438  || Decoder Loss:  0.0353445 Validation Decoder Loss:  0.33151904
Encoder Loss:  0.043615412  || Decoder Loss:  0.0353142 Validation Decoder Loss:  0.33150074
Encoder Loss:  0.043604568  || Decoder Loss:  0.03529113 Validation Decoder Loss:  0.33148772
Encoder Loss:  0.043595996  || Decoder Loss:  0.03527284 Validation Decoder Loss:  0.3314772
Encoder Loss:  0.043589048  || Decoder Loss:  0.035258163 Validation Decoder Loss:  0.33147013
Encoder Loss:  0.043583285  || Decoder Loss:  0.035245977 Validation Decoder Loss:  0.33146444
Encoder Loss:  0.0435783  || Decoder Loss:  0.03523554 Validation Decoder Loss:  0.3314606
Encoder Loss:  0.04357419  || Decoder Loss:  0.035226427 Validation Decoder Loss:  0.331459
Encoder Loss:  0.043570448  || Decoder Loss:  0.035218347 Validation Decoder Loss:  0.33145732
Encoder Loss:  0.043566875  || Decoder Loss:  0.035210803 Validation Decoder Loss:  0.33145392
Encoder Loss:  0.04356365  || Decoder Loss:  0.03520397 Validation Decoder Loss:  0.33145627
Encoder Loss:  0.04356064  || Decoder Loss:  0.03519757 Validation Decoder Loss:  0.33145624
Encoder Loss:  0.043557853  || Decoder Loss:  0.035191607 Validation Decoder Loss:  0.3314571
Encoder Loss:  0.043555394  || Decoder Loss:  0.035186097 Validation Decoder Loss:  0.33146206
Encoder Loss:  0.04355295  || Decoder Loss:  0.035180837 Validation Decoder Loss:  0.3314672
Encoder Loss:  0.043550536  || Decoder Loss:  0.03517543 Validation Decoder Loss:  0.33147064
Encoder Loss:  0.04354805  || Decoder Loss:  0.035170045 Validation Decoder Loss:  0.33147302
Encoder Loss:  0.043545827  || Decoder Loss:  0.035164922 Validation Decoder Loss:  0.33147708
Encoder Loss:  0.043543532  || Decoder Loss:  0.03515966 Validation Decoder Loss:  0.33147663
Encoder Loss:  0.0435415  || Decoder Loss:  0.0351546 Validation Decoder Loss:  0.33148277
Encoder Loss:  0.043539535  || Decoder Loss:  0.035149448 Validation Decoder Loss:  0.33148038
Encoder Loss:  0.043536548  || Decoder Loss:  0.035144337 Validation Decoder Loss:  0.3314743
Encoder Loss:  0.043534324  || Decoder Loss:  0.035139225 Validation Decoder Loss:  0.3314722
Encoder Loss:  0.04353203  || Decoder Loss:  0.035134133 Validation Decoder Loss:  0.33146894
Encoder Loss:  0.04352985  || Decoder Loss:  0.035129074 Validation Decoder Loss:  0.33146602
Encoder Loss:  0.04352789  || Decoder Loss:  0.03512347 Validation Decoder Loss:  0.33146065
Encoder Loss:  0.043525003  || Decoder Loss:  0.035118245 Validation Decoder Loss:  0.33145887
Encoder Loss:  0.043522514  || Decoder Loss:  0.035112783 Validation Decoder Loss:  0.33145446
Model: siamese_net_lr_0.0007064740419097372 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33145446
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_158 (Conv3D (None, 110, 11, 20, 1)    330       
_________________________________________________________________
dropout_339 (Dropout)        (None, 110, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_159 (Conv3D (None, 220, 11, 20, 1)    112       
_________________________________________________________________
reshape_69 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 442
Trainable params: 442
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_113 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_341 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_114 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_113 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_343 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_114 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21984725  || Decoder Loss:  0.14276588 Validation Decoder Loss:  0.7012846
Encoder Loss:  0.06628416  || Decoder Loss:  0.05610074 Validation Decoder Loss:  0.33411232
Encoder Loss:  0.043365274  || Decoder Loss:  0.037797526 Validation Decoder Loss:  0.3328191
Encoder Loss:  0.042304825  || Decoder Loss:  0.03685531 Validation Decoder Loss:  0.3320312
Encoder Loss:  0.041923065  || Decoder Loss:  0.03624266 Validation Decoder Loss:  0.33195943
Encoder Loss:  0.041701064  || Decoder Loss:  0.03587239 Validation Decoder Loss:  0.3317191
Encoder Loss:  0.041557103  || Decoder Loss:  0.03563533 Validation Decoder Loss:  0.3317685
Encoder Loss:  0.041475043  || Decoder Loss:  0.035494365 Validation Decoder Loss:  0.3318184
Encoder Loss:  0.041416626  || Decoder Loss:  0.035401702 Validation Decoder Loss:  0.331738
Encoder Loss:  0.04138749  || Decoder Loss:  0.035351444 Validation Decoder Loss:  0.33181673
Encoder Loss:  0.0413659  || Decoder Loss:  0.03531495 Validation Decoder Loss:  0.33191213
Encoder Loss:  0.041353993  || Decoder Loss:  0.035297517 Validation Decoder Loss:  0.33201653
Encoder Loss:  0.041349247  || Decoder Loss:  0.03528698 Validation Decoder Loss:  0.33207
Encoder Loss:  0.041346494  || Decoder Loss:  0.035283063 Validation Decoder Loss:  0.33210647
Encoder Loss:  0.041342698  || Decoder Loss:  0.035277627 Validation Decoder Loss:  0.33209255
Encoder Loss:  0.041341275  || Decoder Loss:  0.035274487 Validation Decoder Loss:  0.33208758
Encoder Loss:  0.04134141  || Decoder Loss:  0.03527498 Validation Decoder Loss:  0.3320939
Encoder Loss:  0.041341163  || Decoder Loss:  0.035275266 Validation Decoder Loss:  0.33208022
Encoder Loss:  0.041342292  || Decoder Loss:  0.03527681 Validation Decoder Loss:  0.3320984
Encoder Loss:  0.041339617  || Decoder Loss:  0.035274446 Validation Decoder Loss:  0.3321048
Encoder Loss:  0.041338526  || Decoder Loss:  0.03527005 Validation Decoder Loss:  0.33212194
Encoder Loss:  0.04134086  || Decoder Loss:  0.035271104 Validation Decoder Loss:  0.3320683
Encoder Loss:  0.041340604  || Decoder Loss:  0.03527296 Validation Decoder Loss:  0.33209187
Encoder Loss:  0.04133607  || Decoder Loss:  0.035268895 Validation Decoder Loss:  0.33211333
Encoder Loss:  0.041330982  || Decoder Loss:  0.03526191 Validation Decoder Loss:  0.33213627
Encoder Loss:  0.041327085  || Decoder Loss:  0.035253048 Validation Decoder Loss:  0.3321324
Encoder Loss:  0.041322216  || Decoder Loss:  0.035245687 Validation Decoder Loss:  0.3321647
Encoder Loss:  0.041313414  || Decoder Loss:  0.03522726 Validation Decoder Loss:  0.33221364
Encoder Loss:  0.041300587  || Decoder Loss:  0.03520676 Validation Decoder Loss:  0.3322465
Encoder Loss:  0.041291628  || Decoder Loss:  0.035192512 Validation Decoder Loss:  0.3322686
Encoder Loss:  0.04128481  || Decoder Loss:  0.035182152 Validation Decoder Loss:  0.3322969
Encoder Loss:  0.041274328  || Decoder Loss:  0.035165373 Validation Decoder Loss:  0.33232966
Encoder Loss:  0.04126304  || Decoder Loss:  0.035146367 Validation Decoder Loss:  0.33235148
Encoder Loss:  0.04125219  || Decoder Loss:  0.035128836 Validation Decoder Loss:  0.33239084
Encoder Loss:  0.041242328  || Decoder Loss:  0.035111662 Validation Decoder Loss:  0.33235365
Encoder Loss:  0.041238714  || Decoder Loss:  0.035108346 Validation Decoder Loss:  0.33233827
Encoder Loss:  0.04123911  || Decoder Loss:  0.035108328 Validation Decoder Loss:  0.33229113
Encoder Loss:  0.041218262  || Decoder Loss:  0.035068564 Validation Decoder Loss:  0.3323702
Encoder Loss:  0.041214563  || Decoder Loss:  0.03506235 Validation Decoder Loss:  0.3325881
Encoder Loss:  0.041182753  || Decoder Loss:  0.035013888 Validation Decoder Loss:  0.33244765
Model: siamese_net_lr_0.0009388251391460843 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33244762
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_161 (Conv3D (None, 118, 10, 20, 1)    111       
_________________________________________________________________
dropout_345 (Dropout)        (None, 118, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_162 (Conv3D (None, 220, 11, 20, 1)    207       
_________________________________________________________________
reshape_70 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_115 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_347 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_116 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_115 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_349 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_116 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20011829  || Decoder Loss:  0.11324818 Validation Decoder Loss:  0.394355
Encoder Loss:  0.23773631  || Decoder Loss:  0.22601154 Validation Decoder Loss:  0.48797172
Encoder Loss:  0.07125953  || Decoder Loss:  0.060331777 Validation Decoder Loss:  0.34291637
Encoder Loss:  0.05633449  || Decoder Loss:  0.04108327 Validation Decoder Loss:  0.33551726
Encoder Loss:  0.049807195  || Decoder Loss:  0.03728528 Validation Decoder Loss:  0.33315796
Encoder Loss:  0.0417937  || Decoder Loss:  0.035860125 Validation Decoder Loss:  0.33242548
Encoder Loss:  0.04094023  || Decoder Loss:  0.035338078 Validation Decoder Loss:  0.33245823
Encoder Loss:  0.040838014  || Decoder Loss:  0.035190746 Validation Decoder Loss:  0.33260557
Encoder Loss:  0.040791053  || Decoder Loss:  0.035128545 Validation Decoder Loss:  0.33284774
Encoder Loss:  0.04075926  || Decoder Loss:  0.035092223 Validation Decoder Loss:  0.33305866
Encoder Loss:  0.04073516  || Decoder Loss:  0.03506996 Validation Decoder Loss:  0.33322263
Encoder Loss:  0.040716305  || Decoder Loss:  0.035057176 Validation Decoder Loss:  0.33333898
Encoder Loss:  0.04069883  || Decoder Loss:  0.035050645 Validation Decoder Loss:  0.33342573
Encoder Loss:  0.040682655  || Decoder Loss:  0.035048176 Validation Decoder Loss:  0.33348328
Encoder Loss:  0.04066304  || Decoder Loss:  0.035048544 Validation Decoder Loss:  0.3335248
Encoder Loss:  0.040625963  || Decoder Loss:  0.03505138 Validation Decoder Loss:  0.33355743
Encoder Loss:  0.040469345  || Decoder Loss:  0.035056807 Validation Decoder Loss:  0.33358365
Encoder Loss:  0.039951336  || Decoder Loss:  0.03504619 Validation Decoder Loss:  0.33350554
Encoder Loss:  0.039930973  || Decoder Loss:  0.035027795 Validation Decoder Loss:  0.33350664
Encoder Loss:  0.039917275  || Decoder Loss:  0.03501394 Validation Decoder Loss:  0.3335203
Encoder Loss:  0.039902706  || Decoder Loss:  0.034997474 Validation Decoder Loss:  0.33353627
Encoder Loss:  0.03988596  || Decoder Loss:  0.034976102 Validation Decoder Loss:  0.33355662
Encoder Loss:  0.039863586  || Decoder Loss:  0.034947794 Validation Decoder Loss:  0.33357686
Encoder Loss:  0.03983762  || Decoder Loss:  0.034912392 Validation Decoder Loss:  0.33360058
Encoder Loss:  0.039807085  || Decoder Loss:  0.03487023 Validation Decoder Loss:  0.33362356
Encoder Loss:  0.039770905  || Decoder Loss:  0.034821175 Validation Decoder Loss:  0.33363262
Encoder Loss:  0.03972765  || Decoder Loss:  0.034758784 Validation Decoder Loss:  0.33364227
Encoder Loss:  0.039676026  || Decoder Loss:  0.034685757 Validation Decoder Loss:  0.33363944
Encoder Loss:  0.039616615  || Decoder Loss:  0.034600466 Validation Decoder Loss:  0.333647
Encoder Loss:  0.03955339  || Decoder Loss:  0.03450868 Validation Decoder Loss:  0.33366203
Encoder Loss:  0.03948482  || Decoder Loss:  0.03440958 Validation Decoder Loss:  0.33369598
Encoder Loss:  0.039417196  || Decoder Loss:  0.03431137 Validation Decoder Loss:  0.333736
Encoder Loss:  0.03936419  || Decoder Loss:  0.034233615 Validation Decoder Loss:  0.33377907
Encoder Loss:  0.039323974  || Decoder Loss:  0.034176227 Validation Decoder Loss:  0.33381808
Encoder Loss:  0.039312296  || Decoder Loss:  0.034157842 Validation Decoder Loss:  0.33385122
Encoder Loss:  0.03930598  || Decoder Loss:  0.034149345 Validation Decoder Loss:  0.33387902
Encoder Loss:  0.03932056  || Decoder Loss:  0.034172222 Validation Decoder Loss:  0.33390546
Encoder Loss:  0.039342355  || Decoder Loss:  0.034205336 Validation Decoder Loss:  0.33392435
Encoder Loss:  0.039362144  || Decoder Loss:  0.03423427 Validation Decoder Loss:  0.33391708
Encoder Loss:  0.039384317  || Decoder Loss:  0.034267526 Validation Decoder Loss:  0.33393326
Model: siamese_net_lr_0.00042345933804420444 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33393323
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_164 (Conv3D (None, 122, 10, 20, 1)    119       
_________________________________________________________________
dropout_351 (Dropout)        (None, 122, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_165 (Conv3D (None, 220, 11, 20, 1)    199       
_________________________________________________________________
reshape_71 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_117 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_353 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_118 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_117 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_355 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_118 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22246379  || Decoder Loss:  0.106999725 Validation Decoder Loss:  0.38325316
Encoder Loss:  0.22363102  || Decoder Loss:  0.11297903 Validation Decoder Loss:  0.38864708
Encoder Loss:  0.22492813  || Decoder Loss:  0.120429374 Validation Decoder Loss:  0.39566052
Encoder Loss:  0.22649549  || Decoder Loss:  0.13257594 Validation Decoder Loss:  0.41088748
Encoder Loss:  0.25125787  || Decoder Loss:  0.25084147 Validation Decoder Loss:  1.0333571
Encoder Loss:  0.1430698  || Decoder Loss:  0.17646252 Validation Decoder Loss:  0.35186
Encoder Loss:  0.07127221  || Decoder Loss:  0.05520795 Validation Decoder Loss:  0.34445193
Encoder Loss:  0.06814287  || Decoder Loss:  0.050965503 Validation Decoder Loss:  0.34006122
Encoder Loss:  0.06345309  || Decoder Loss:  0.04417917 Validation Decoder Loss:  0.33578685
Encoder Loss:  0.058808617  || Decoder Loss:  0.037773706 Validation Decoder Loss:  0.33274692
Encoder Loss:  0.056415968  || Decoder Loss:  0.035660468 Validation Decoder Loss:  0.33181685
Encoder Loss:  0.054644477  || Decoder Loss:  0.035259984 Validation Decoder Loss:  0.33160976
Encoder Loss:  0.05213765  || Decoder Loss:  0.035112504 Validation Decoder Loss:  0.33171043
Encoder Loss:  0.04789735  || Decoder Loss:  0.035037734 Validation Decoder Loss:  0.33202118
Encoder Loss:  0.042756587  || Decoder Loss:  0.03498158 Validation Decoder Loss:  0.3321427
Encoder Loss:  0.04222947  || Decoder Loss:  0.034940813 Validation Decoder Loss:  0.33213705
Encoder Loss:  0.042205464  || Decoder Loss:  0.03491386 Validation Decoder Loss:  0.3321789
Encoder Loss:  0.042194605  || Decoder Loss:  0.034895703 Validation Decoder Loss:  0.3322186
Encoder Loss:  0.042187106  || Decoder Loss:  0.03488291 Validation Decoder Loss:  0.33224496
Encoder Loss:  0.042174134  || Decoder Loss:  0.034872923 Validation Decoder Loss:  0.33226538
Encoder Loss:  0.042166032  || Decoder Loss:  0.034864318 Validation Decoder Loss:  0.33228964
Encoder Loss:  0.042161584  || Decoder Loss:  0.03485623 Validation Decoder Loss:  0.332322
Encoder Loss:  0.04215212  || Decoder Loss:  0.034848455 Validation Decoder Loss:  0.3323593
Encoder Loss:  0.042144094  || Decoder Loss:  0.034840655 Validation Decoder Loss:  0.3324082
Encoder Loss:  0.042136453  || Decoder Loss:  0.034832865 Validation Decoder Loss:  0.33246738
Encoder Loss:  0.042128276  || Decoder Loss:  0.034824982 Validation Decoder Loss:  0.33253565
Encoder Loss:  0.04212103  || Decoder Loss:  0.034817148 Validation Decoder Loss:  0.33260584
Encoder Loss:  0.04211313  || Decoder Loss:  0.03480953 Validation Decoder Loss:  0.33266956
Encoder Loss:  0.042105626  || Decoder Loss:  0.034802333 Validation Decoder Loss:  0.33272177
Encoder Loss:  0.04209789  || Decoder Loss:  0.03479562 Validation Decoder Loss:  0.33276215
Encoder Loss:  0.0420906  || Decoder Loss:  0.0347893 Validation Decoder Loss:  0.3327955
Encoder Loss:  0.042080387  || Decoder Loss:  0.03478348 Validation Decoder Loss:  0.33281493
Encoder Loss:  0.042075958  || Decoder Loss:  0.034778066 Validation Decoder Loss:  0.3328333
Encoder Loss:  0.04206823  || Decoder Loss:  0.034772847 Validation Decoder Loss:  0.33284503
Encoder Loss:  0.04206007  || Decoder Loss:  0.034767855 Validation Decoder Loss:  0.33285215
Encoder Loss:  0.042052113  || Decoder Loss:  0.034763 Validation Decoder Loss:  0.3328547
Encoder Loss:  0.042044286  || Decoder Loss:  0.03475807 Validation Decoder Loss:  0.33285636
Encoder Loss:  0.04203458  || Decoder Loss:  0.034753054 Validation Decoder Loss:  0.3328561
Encoder Loss:  0.042022184  || Decoder Loss:  0.03474793 Validation Decoder Loss:  0.33285376
Encoder Loss:  0.042011004  || Decoder Loss:  0.034742497 Validation Decoder Loss:  0.332855
Model: siamese_net_lr_0.0003099052022242674 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33285496
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_167 (Conv3D (None, 123, 10, 20, 1)    361       
_________________________________________________________________
dropout_357 (Dropout)        (None, 123, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_168 (Conv3D (None, 220, 11, 20, 1)    197       
_________________________________________________________________
reshape_72 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 558
Trainable params: 558
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_119 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_359 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_120 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_119 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_361 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_120 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31354383  || Decoder Loss:  0.12852892 Validation Decoder Loss:  0.42027527
Encoder Loss:  0.16108942  || Decoder Loss:  0.11695133 Validation Decoder Loss:  0.36484724
Encoder Loss:  0.07009099  || Decoder Loss:  0.041919474 Validation Decoder Loss:  0.33257598
Encoder Loss:  0.04942873  || Decoder Loss:  0.035440713 Validation Decoder Loss:  0.33127272
Encoder Loss:  0.047282685  || Decoder Loss:  0.034739967 Validation Decoder Loss:  0.3314833
Encoder Loss:  0.04718058  || Decoder Loss:  0.03431716 Validation Decoder Loss:  0.3314752
Encoder Loss:  0.047146488  || Decoder Loss:  0.03417006 Validation Decoder Loss:  0.33145785
Encoder Loss:  0.04712016  || Decoder Loss:  0.034040794 Validation Decoder Loss:  0.3313536
Encoder Loss:  0.047111  || Decoder Loss:  0.034004863 Validation Decoder Loss:  0.3319263
Encoder Loss:  0.047095515  || Decoder Loss:  0.033949863 Validation Decoder Loss:  0.3316682
Encoder Loss:  0.04709961  || Decoder Loss:  0.03397736 Validation Decoder Loss:  0.3312401
Encoder Loss:  0.04709054  || Decoder Loss:  0.033941433 Validation Decoder Loss:  0.33197698
Encoder Loss:  0.04709572  || Decoder Loss:  0.03397491 Validation Decoder Loss:  0.33131737
Encoder Loss:  0.047093663  || Decoder Loss:  0.03397294 Validation Decoder Loss:  0.3303554
Encoder Loss:  0.047123127  || Decoder Loss:  0.034132134 Validation Decoder Loss:  0.331474
Encoder Loss:  0.04710387  || Decoder Loss:  0.034035638 Validation Decoder Loss:  0.33088052
Encoder Loss:  0.04711228  || Decoder Loss:  0.034093577 Validation Decoder Loss:  0.33060035
Encoder Loss:  0.047123667  || Decoder Loss:  0.034155067 Validation Decoder Loss:  0.33018243
Encoder Loss:  0.047130037  || Decoder Loss:  0.034192976 Validation Decoder Loss:  0.3308739
Encoder Loss:  0.047136836  || Decoder Loss:  0.034229897 Validation Decoder Loss:  0.3307757
Encoder Loss:  0.04714544  || Decoder Loss:  0.0342618 Validation Decoder Loss:  0.3301551
Encoder Loss:  0.047146555  || Decoder Loss:  0.034285553 Validation Decoder Loss:  0.33005214
Encoder Loss:  0.04715253  || Decoder Loss:  0.03430779 Validation Decoder Loss:  0.33054549
Encoder Loss:  0.047158036  || Decoder Loss:  0.034358688 Validation Decoder Loss:  0.32952547
Encoder Loss:  0.04716872  || Decoder Loss:  0.034409333 Validation Decoder Loss:  0.32934004
Encoder Loss:  0.04717285  || Decoder Loss:  0.03444398 Validation Decoder Loss:  0.32956085
Encoder Loss:  0.047177218  || Decoder Loss:  0.0344648 Validation Decoder Loss:  0.32852143
Encoder Loss:  0.0471765  || Decoder Loss:  0.034464262 Validation Decoder Loss:  0.3280937
Encoder Loss:  0.04717505  || Decoder Loss:  0.034459565 Validation Decoder Loss:  0.32782745
Encoder Loss:  0.047170553  || Decoder Loss:  0.034442913 Validation Decoder Loss:  0.32744908
Encoder Loss:  0.047166128  || Decoder Loss:  0.03441881 Validation Decoder Loss:  0.32724005
Encoder Loss:  0.047168106  || Decoder Loss:  0.03437389 Validation Decoder Loss:  0.32730824
Encoder Loss:  0.04715301  || Decoder Loss:  0.034345604 Validation Decoder Loss:  0.32674313
Encoder Loss:  0.04714687  || Decoder Loss:  0.034316313 Validation Decoder Loss:  0.3262887
Encoder Loss:  0.047141213  || Decoder Loss:  0.034283426 Validation Decoder Loss:  0.32596534
Encoder Loss:  0.047135305  || Decoder Loss:  0.03425274 Validation Decoder Loss:  0.3256533
Encoder Loss:  0.047128964  || Decoder Loss:  0.034222547 Validation Decoder Loss:  0.3254832
Encoder Loss:  0.047125384  || Decoder Loss:  0.034195267 Validation Decoder Loss:  0.32530552
Encoder Loss:  0.0471187  || Decoder Loss:  0.034168188 Validation Decoder Loss:  0.32519317
Encoder Loss:  0.047113646  || Decoder Loss:  0.034144178 Validation Decoder Loss:  0.32515666
Model: siamese_net_lr_0.00033991787847724637 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3251567
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_170 (Conv3D (None, 200, 6, 20, 1)     23        
_________________________________________________________________
dropout_363 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_171 (Conv3D (None, 220, 11, 20, 1)    127       
_________________________________________________________________
reshape_73 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_121 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_365 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_122 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_121 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_367 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_122 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3062474  || Decoder Loss:  0.053700343 Validation Decoder Loss:  0.37714654
Encoder Loss:  0.29201066  || Decoder Loss:  0.05320745 Validation Decoder Loss:  0.3861956
Encoder Loss:  0.12789121  || Decoder Loss:  0.046731323 Validation Decoder Loss:  0.35325947
Encoder Loss:  0.04891339  || Decoder Loss:  0.045366492 Validation Decoder Loss:  0.35137343
Encoder Loss:  0.04837351  || Decoder Loss:  0.04328172 Validation Decoder Loss:  0.34754378
Encoder Loss:  0.046951298  || Decoder Loss:  0.038066573 Validation Decoder Loss:  0.34252274
Encoder Loss:  0.04609633  || Decoder Loss:  0.034788623 Validation Decoder Loss:  0.3401569
Encoder Loss:  0.04588779  || Decoder Loss:  0.033998746 Validation Decoder Loss:  0.3408652
Encoder Loss:  0.045852575  || Decoder Loss:  0.03373035 Validation Decoder Loss:  0.341775
Encoder Loss:  0.045773875  || Decoder Loss:  0.03359903 Validation Decoder Loss:  0.34255064
Encoder Loss:  0.045796547  || Decoder Loss:  0.03352272 Validation Decoder Loss:  0.3433677
Encoder Loss:  0.045758296  || Decoder Loss:  0.03346283 Validation Decoder Loss:  0.34447294
Encoder Loss:  0.045732494  || Decoder Loss:  0.03342267 Validation Decoder Loss:  0.3457241
Encoder Loss:  0.04571586  || Decoder Loss:  0.033381492 Validation Decoder Loss:  0.34483284
Encoder Loss:  0.045689125  || Decoder Loss:  0.03331992 Validation Decoder Loss:  0.3453282
Encoder Loss:  0.045689087  || Decoder Loss:  0.03327155 Validation Decoder Loss:  0.34573776
Encoder Loss:  0.04569794  || Decoder Loss:  0.03320829 Validation Decoder Loss:  0.3460308
Encoder Loss:  0.045646083  || Decoder Loss:  0.033161268 Validation Decoder Loss:  0.34633267
Encoder Loss:  0.045660734  || Decoder Loss:  0.033130877 Validation Decoder Loss:  0.346521
Encoder Loss:  0.045624875  || Decoder Loss:  0.033083938 Validation Decoder Loss:  0.34642607
Encoder Loss:  0.04561398  || Decoder Loss:  0.033073958 Validation Decoder Loss:  0.3464877
Encoder Loss:  0.0456186  || Decoder Loss:  0.033024266 Validation Decoder Loss:  0.34613174
Encoder Loss:  0.045597486  || Decoder Loss:  0.033007514 Validation Decoder Loss:  0.34622985
Encoder Loss:  0.045590397  || Decoder Loss:  0.032991152 Validation Decoder Loss:  0.34617248
Encoder Loss:  0.045588005  || Decoder Loss:  0.032976657 Validation Decoder Loss:  0.34600073
Encoder Loss:  0.0455779  || Decoder Loss:  0.032948256 Validation Decoder Loss:  0.34587684
Encoder Loss:  0.04557449  || Decoder Loss:  0.03294053 Validation Decoder Loss:  0.34578836
Encoder Loss:  0.04556635  || Decoder Loss:  0.03290726 Validation Decoder Loss:  0.3458333
Encoder Loss:  0.045560695  || Decoder Loss:  0.03290365 Validation Decoder Loss:  0.34569117
Encoder Loss:  0.04555876  || Decoder Loss:  0.032899573 Validation Decoder Loss:  0.3455926
Encoder Loss:  0.0455579  || Decoder Loss:  0.03289836 Validation Decoder Loss:  0.34557566
Encoder Loss:  0.04555697  || Decoder Loss:  0.032898575 Validation Decoder Loss:  0.34543535
Encoder Loss:  0.045556687  || Decoder Loss:  0.0328987 Validation Decoder Loss:  0.34543565
Encoder Loss:  0.045556482  || Decoder Loss:  0.03289776 Validation Decoder Loss:  0.34530342
Encoder Loss:  0.045555726  || Decoder Loss:  0.032896128 Validation Decoder Loss:  0.34527236
Encoder Loss:  0.045554776  || Decoder Loss:  0.03289439 Validation Decoder Loss:  0.345206
Encoder Loss:  0.04555379  || Decoder Loss:  0.032891933 Validation Decoder Loss:  0.345091
Encoder Loss:  0.0455527  || Decoder Loss:  0.032890085 Validation Decoder Loss:  0.34510803
Encoder Loss:  0.0455513  || Decoder Loss:  0.03288832 Validation Decoder Loss:  0.3450908
Encoder Loss:  0.045550868  || Decoder Loss:  0.03288268 Validation Decoder Loss:  0.34499508
Model: siamese_net_lr_0.0009660138887365844 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34499505
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_173 (Conv3D (None, 170, 7, 20, 1)     322       
_________________________________________________________________
dropout_369 (Dropout)        (None, 170, 7, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_174 (Conv3D (None, 220, 11, 20, 1)    256       
_________________________________________________________________
reshape_74 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 578
Trainable params: 578
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_123 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_371 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_124 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_123 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_373 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_124 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.121617645  || Decoder Loss:  0.08788054 Validation Decoder Loss:  0.3739288
Encoder Loss:  0.12244413  || Decoder Loss:  0.08913592 Validation Decoder Loss:  0.374813
Encoder Loss:  0.123305835  || Decoder Loss:  0.09042677 Validation Decoder Loss:  0.37565255
Encoder Loss:  0.124221176  || Decoder Loss:  0.0917799 Validation Decoder Loss:  0.37647521
Encoder Loss:  0.12520294  || Decoder Loss:  0.093214005 Validation Decoder Loss:  0.3773048
Encoder Loss:  0.12626424  || Decoder Loss:  0.09474793 Validation Decoder Loss:  0.37816334
Encoder Loss:  0.12741897  || Decoder Loss:  0.09640087 Validation Decoder Loss:  0.3790721
Encoder Loss:  0.12868303  || Decoder Loss:  0.098193824 Validation Decoder Loss:  0.38005376
Encoder Loss:  0.13007337  || Decoder Loss:  0.10014969 Validation Decoder Loss:  0.381135
Encoder Loss:  0.13161014  || Decoder Loss:  0.10229438 Validation Decoder Loss:  0.38234562
Encoder Loss:  0.13331646  || Decoder Loss:  0.10465813 Validation Decoder Loss:  0.38371885
Encoder Loss:  0.13521957  || Decoder Loss:  0.10727643 Validation Decoder Loss:  0.38529253
Encoder Loss:  0.13735266  || Decoder Loss:  0.110191755 Validation Decoder Loss:  0.38711303
Encoder Loss:  0.1397565  || Decoder Loss:  0.113456555 Validation Decoder Loss:  0.38924047
Encoder Loss:  0.14248155  || Decoder Loss:  0.1171356 Validation Decoder Loss:  0.3917545
Encoder Loss:  0.14559191  || Decoder Loss:  0.12131071 Validation Decoder Loss:  0.39476156
Encoder Loss:  0.14916949  || Decoder Loss:  0.1260862 Validation Decoder Loss:  0.39840734
Encoder Loss:  0.15331997  || Decoder Loss:  0.1315971 Validation Decoder Loss:  0.40289742
Encoder Loss:  0.15818332  || Decoder Loss:  0.13802086 Validation Decoder Loss:  0.40852636
Encoder Loss:  0.16394798  || Decoder Loss:  0.1455966 Validation Decoder Loss:  0.41572315
Encoder Loss:  0.17087445  || Decoder Loss:  0.15465418 Validation Decoder Loss:  0.42513192
Encoder Loss:  0.17933221  || Decoder Loss:  0.16566023 Validation Decoder Loss:  0.43775678
Encoder Loss:  0.18985951  || Decoder Loss:  0.17929657 Validation Decoder Loss:  0.45522386
Encoder Loss:  0.2032682  || Decoder Loss:  0.19659485 Validation Decoder Loss:  0.480218
Encoder Loss:  0.22068393  || Decoder Loss:  0.2190263 Validation Decoder Loss:  0.5167836
Encoder Loss:  0.23786718  || Decoder Loss:  0.24212351 Validation Decoder Loss:  0.5476655
Encoder Loss:  0.17993547  || Decoder Loss:  0.18140051 Validation Decoder Loss:  0.5578176
Encoder Loss:  0.19520912  || Decoder Loss:  0.20534006 Validation Decoder Loss:  0.68427557
Encoder Loss:  0.2249471  || Decoder Loss:  0.24436006 Validation Decoder Loss:  0.7079809
Encoder Loss:  0.19599569  || Decoder Loss:  0.21165639 Validation Decoder Loss:  0.5541126
Encoder Loss:  0.13514829  || Decoder Loss:  0.14265828 Validation Decoder Loss:  0.46445972
Encoder Loss:  0.11579752  || Decoder Loss:  0.12073661 Validation Decoder Loss:  0.43669868
Encoder Loss:  0.102418445  || Decoder Loss:  0.105590954 Validation Decoder Loss:  0.41440603
Encoder Loss:  0.090961315  || Decoder Loss:  0.09262863 Validation Decoder Loss:  0.3960882
Encoder Loss:  0.081126615  || Decoder Loss:  0.08151128 Validation Decoder Loss:  0.38117445
Encoder Loss:  0.07274618  || Decoder Loss:  0.07204761 Validation Decoder Loss:  0.36916822
Encoder Loss:  0.065662086  || Decoder Loss:  0.06405758 Validation Decoder Loss:  0.35957962
Encoder Loss:  0.059708286  || Decoder Loss:  0.05735467 Validation Decoder Loss:  0.35199866
Encoder Loss:  0.05475243  || Decoder Loss:  0.051787462 Validation Decoder Loss:  0.34610346
Encoder Loss:  0.050694548  || Decoder Loss:  0.04724528 Validation Decoder Loss:  0.341677
Model: siamese_net_lr_5.617922674321672e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.341677
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_176 (Conv3D (None, 118, 10, 20, 1)    111       
_________________________________________________________________
dropout_375 (Dropout)        (None, 118, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_177 (Conv3D (None, 220, 11, 20, 1)    207       
_________________________________________________________________
reshape_75 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_125 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_377 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_126 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_125 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_379 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_126 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28742647  || Decoder Loss:  0.10521486 Validation Decoder Loss:  0.37987506
Encoder Loss:  0.28721485  || Decoder Loss:  0.10609354 Validation Decoder Loss:  0.38061035
Encoder Loss:  0.2870079  || Decoder Loss:  0.10694701 Validation Decoder Loss:  0.38132435
Encoder Loss:  0.28680384  || Decoder Loss:  0.10778219 Validation Decoder Loss:  0.38202164
Encoder Loss:  0.28660166  || Decoder Loss:  0.108603984 Validation Decoder Loss:  0.38270634
Encoder Loss:  0.2864002  || Decoder Loss:  0.10941653 Validation Decoder Loss:  0.38338226
Encoder Loss:  0.28619838  || Decoder Loss:  0.11022349 Validation Decoder Loss:  0.38405263
Encoder Loss:  0.2859957  || Decoder Loss:  0.11102799 Validation Decoder Loss:  0.3847203
Encoder Loss:  0.28579095  || Decoder Loss:  0.1118328 Validation Decoder Loss:  0.38538742
Encoder Loss:  0.28558356  || Decoder Loss:  0.112640455 Validation Decoder Loss:  0.3860561
Encoder Loss:  0.28537285  || Decoder Loss:  0.11345333 Validation Decoder Loss:  0.38672835
Encoder Loss:  0.28515813  || Decoder Loss:  0.11427349 Validation Decoder Loss:  0.38740593
Encoder Loss:  0.28493848  || Decoder Loss:  0.11510286 Validation Decoder Loss:  0.3880905
Encoder Loss:  0.2847136  || Decoder Loss:  0.11594337 Validation Decoder Loss:  0.3887835
Encoder Loss:  0.28448248  || Decoder Loss:  0.11679682 Validation Decoder Loss:  0.3894865
Encoder Loss:  0.28424445  || Decoder Loss:  0.11766499 Validation Decoder Loss:  0.39020082
Encoder Loss:  0.2839989  || Decoder Loss:  0.11854966 Validation Decoder Loss:  0.390928
Encoder Loss:  0.283745  || Decoder Loss:  0.11945255 Validation Decoder Loss:  0.39166957
Encoder Loss:  0.28348157  || Decoder Loss:  0.12037569 Validation Decoder Loss:  0.3924272
Encoder Loss:  0.28320792  || Decoder Loss:  0.12132111 Validation Decoder Loss:  0.3932026
Encoder Loss:  0.28292286  || Decoder Loss:  0.12229088 Validation Decoder Loss:  0.3939978
Encoder Loss:  0.28262523  || Decoder Loss:  0.12328747 Validation Decoder Loss:  0.3948148
Encoder Loss:  0.2823138  || Decoder Loss:  0.12431342 Validation Decoder Loss:  0.39565596
Encoder Loss:  0.28198686  || Decoder Loss:  0.12537166 Validation Decoder Loss:  0.39652398
Encoder Loss:  0.28164282  || Decoder Loss:  0.12646547 Validation Decoder Loss:  0.397422
Encoder Loss:  0.28127965  || Decoder Loss:  0.12759848 Validation Decoder Loss:  0.3983534
Encoder Loss:  0.28089505  || Decoder Loss:  0.12877494 Validation Decoder Loss:  0.3993224
Encoder Loss:  0.28048646  || Decoder Loss:  0.12999968 Validation Decoder Loss:  0.40033376
Encoder Loss:  0.28005067  || Decoder Loss:  0.13127837 Validation Decoder Loss:  0.40139315
Encoder Loss:  0.27958402  || Decoder Loss:  0.13261749 Validation Decoder Loss:  0.4025076
Encoder Loss:  0.27908245  || Decoder Loss:  0.13402477 Validation Decoder Loss:  0.4036855
Encoder Loss:  0.27854064  || Decoder Loss:  0.13550943 Validation Decoder Loss:  0.4049372
Encoder Loss:  0.27795258  || Decoder Loss:  0.13708232 Validation Decoder Loss:  0.40627566
Encoder Loss:  0.27731067  || Decoder Loss:  0.13875686 Validation Decoder Loss:  0.40771714
Encoder Loss:  0.27660593  || Decoder Loss:  0.14054939 Validation Decoder Loss:  0.4092823
Encoder Loss:  0.2758269  || Decoder Loss:  0.14248013 Validation Decoder Loss:  0.41099763
Encoder Loss:  0.27495974  || Decoder Loss:  0.14457457 Validation Decoder Loss:  0.41289786
Encoder Loss:  0.27398625  || Decoder Loss:  0.14686519 Validation Decoder Loss:  0.41502914
Encoder Loss:  0.27288374  || Decoder Loss:  0.1493944 Validation Decoder Loss:  0.41745475
Encoder Loss:  0.27162167  || Decoder Loss:  0.15221879 Validation Decoder Loss:  0.42026284
Model: siamese_net_lr_4.9288809557105624e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.42026284
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_179 (Conv3D (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_381 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_180 (Conv3D (None, 220, 11, 20, 1)    750       
_________________________________________________________________
reshape_76 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 802
Trainable params: 802
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_127 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_383 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_128 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_127 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_385 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_128 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19031091  || Decoder Loss:  0.13730368 Validation Decoder Loss:  0.3383485
Encoder Loss:  0.04988394  || Decoder Loss:  0.038173802 Validation Decoder Loss:  0.3350247
Encoder Loss:  0.04574525  || Decoder Loss:  0.036493823 Validation Decoder Loss:  0.33399692
Encoder Loss:  0.04526959  || Decoder Loss:  0.035804566 Validation Decoder Loss:  0.33422387
Encoder Loss:  0.045145836  || Decoder Loss:  0.03543855 Validation Decoder Loss:  0.3333364
Encoder Loss:  0.045089938  || Decoder Loss:  0.035269506 Validation Decoder Loss:  0.3335284
Encoder Loss:  0.045060325  || Decoder Loss:  0.035173766 Validation Decoder Loss:  0.333466
Encoder Loss:  0.045041658  || Decoder Loss:  0.03511774 Validation Decoder Loss:  0.3335145
Encoder Loss:  0.04502366  || Decoder Loss:  0.035078768 Validation Decoder Loss:  0.33349913
Encoder Loss:  0.045014232  || Decoder Loss:  0.035055112 Validation Decoder Loss:  0.3336352
Encoder Loss:  0.045010194  || Decoder Loss:  0.03503795 Validation Decoder Loss:  0.33360466
Encoder Loss:  0.044998635  || Decoder Loss:  0.0350204 Validation Decoder Loss:  0.3336571
Encoder Loss:  0.044988904  || Decoder Loss:  0.034999203 Validation Decoder Loss:  0.3335611
Encoder Loss:  0.045004692  || Decoder Loss:  0.03505573 Validation Decoder Loss:  0.33429313
Encoder Loss:  0.044959437  || Decoder Loss:  0.034925126 Validation Decoder Loss:  0.33364406
Encoder Loss:  0.04497119  || Decoder Loss:  0.034968298 Validation Decoder Loss:  0.33469746
Encoder Loss:  0.0449769  || Decoder Loss:  0.035000097 Validation Decoder Loss:  0.33499122
Encoder Loss:  0.044993952  || Decoder Loss:  0.035057064 Validation Decoder Loss:  0.3350142
Encoder Loss:  0.045014154  || Decoder Loss:  0.035123374 Validation Decoder Loss:  0.33479118
Encoder Loss:  0.045040693  || Decoder Loss:  0.03520016 Validation Decoder Loss:  0.33430076
Encoder Loss:  0.04504885  || Decoder Loss:  0.035227276 Validation Decoder Loss:  0.33430505
Encoder Loss:  0.045044757  || Decoder Loss:  0.0352189 Validation Decoder Loss:  0.33529496
Encoder Loss:  0.045037594  || Decoder Loss:  0.03519762 Validation Decoder Loss:  0.33410192
Encoder Loss:  0.045036636  || Decoder Loss:  0.035195664 Validation Decoder Loss:  0.33252925
Encoder Loss:  0.04503116  || Decoder Loss:  0.035181433 Validation Decoder Loss:  0.33397204
Encoder Loss:  0.045032334  || Decoder Loss:  0.035184298 Validation Decoder Loss:  0.3347552
Encoder Loss:  0.04503604  || Decoder Loss:  0.035196368 Validation Decoder Loss:  0.333774
Encoder Loss:  0.04503591  || Decoder Loss:  0.03519517 Validation Decoder Loss:  0.33386564
Encoder Loss:  0.04504471  || Decoder Loss:  0.035216004 Validation Decoder Loss:  0.3317668
Encoder Loss:  0.045042135  || Decoder Loss:  0.03521773 Validation Decoder Loss:  0.33171633
Encoder Loss:  0.045035135  || Decoder Loss:  0.035196643 Validation Decoder Loss:  0.3318535
Encoder Loss:  0.045038447  || Decoder Loss:  0.035205554 Validation Decoder Loss:  0.33185464
Encoder Loss:  0.04504318  || Decoder Loss:  0.035220295 Validation Decoder Loss:  0.33231038
Encoder Loss:  0.045038067  || Decoder Loss:  0.035206404 Validation Decoder Loss:  0.33180147
Encoder Loss:  0.04503736  || Decoder Loss:  0.035201885 Validation Decoder Loss:  0.3319559
Encoder Loss:  0.045041133  || Decoder Loss:  0.035212077 Validation Decoder Loss:  0.33288106
Encoder Loss:  0.045039624  || Decoder Loss:  0.035210904 Validation Decoder Loss:  0.3319188
Encoder Loss:  0.04503764  || Decoder Loss:  0.03520537 Validation Decoder Loss:  0.3319508
Encoder Loss:  0.045036957  || Decoder Loss:  0.035203185 Validation Decoder Loss:  0.33185863
Encoder Loss:  0.045038376  || Decoder Loss:  0.035207585 Validation Decoder Loss:  0.332081
Model: siamese_net_lr_0.0007595852558087403 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.332081
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_182 (Conv3D (None, 150, 8, 20, 1)     97        
_________________________________________________________________
dropout_387 (Dropout)        (None, 150, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_183 (Conv3D (None, 220, 11, 20, 1)    285       
_________________________________________________________________
reshape_77 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_129 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_389 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_130 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_129 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_391 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_130 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001037 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147876  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.38147873  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.38147873  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.09001036 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.3707083
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.37070826
Encoder Loss:  0.3814787  || Decoder Loss:  0.090010345 Validation Decoder Loss:  0.37070826
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3707083
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_185 (Conv3D (None, 124, 10, 20, 1)    367       
_________________________________________________________________
dropout_393 (Dropout)        (None, 124, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_186 (Conv3D (None, 220, 11, 20, 1)    195       
_________________________________________________________________
reshape_78 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 562
Trainable params: 562
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_131 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_395 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_132 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_131 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_397 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_132 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1518861  || Decoder Loss:  0.121186286 Validation Decoder Loss:  0.362908
Encoder Loss:  0.050266217  || Decoder Loss:  0.047981467 Validation Decoder Loss:  0.3292939
Encoder Loss:  0.038827933  || Decoder Loss:  0.03550401 Validation Decoder Loss:  0.33034563
Encoder Loss:  0.038437266  || Decoder Loss:  0.035015114 Validation Decoder Loss:  0.33042505
Encoder Loss:  0.038163744  || Decoder Loss:  0.03467128 Validation Decoder Loss:  0.330185
Encoder Loss:  0.038011808  || Decoder Loss:  0.034474995 Validation Decoder Loss:  0.3300754
Encoder Loss:  0.037937947  || Decoder Loss:  0.03438067 Validation Decoder Loss:  0.3303734
Encoder Loss:  0.037890512  || Decoder Loss:  0.034323815 Validation Decoder Loss:  0.3304875
Encoder Loss:  0.037899584  || Decoder Loss:  0.03433743 Validation Decoder Loss:  0.3305714
Encoder Loss:  0.03791336  || Decoder Loss:  0.034357578 Validation Decoder Loss:  0.33068824
Encoder Loss:  0.037931424  || Decoder Loss:  0.03438108 Validation Decoder Loss:  0.330764
Encoder Loss:  0.037938323  || Decoder Loss:  0.03439068 Validation Decoder Loss:  0.33051422
Encoder Loss:  0.037918035  || Decoder Loss:  0.034364507 Validation Decoder Loss:  0.330656
Encoder Loss:  0.037898578  || Decoder Loss:  0.034337893 Validation Decoder Loss:  0.33027193
Encoder Loss:  0.037883606  || Decoder Loss:  0.034320697 Validation Decoder Loss:  0.32975268
Encoder Loss:  0.037912976  || Decoder Loss:  0.034356713 Validation Decoder Loss:  0.32904136
Encoder Loss:  0.03789454  || Decoder Loss:  0.034334894 Validation Decoder Loss:  0.32793015
Encoder Loss:  0.037859548  || Decoder Loss:  0.034292568 Validation Decoder Loss:  0.326782
Encoder Loss:  0.037844528  || Decoder Loss:  0.034269474 Validation Decoder Loss:  0.32742476
Encoder Loss:  0.03781044  || Decoder Loss:  0.034227017 Validation Decoder Loss:  0.32683653
Encoder Loss:  0.03776967  || Decoder Loss:  0.034175042 Validation Decoder Loss:  0.3256445
Encoder Loss:  0.037739716  || Decoder Loss:  0.034135766 Validation Decoder Loss:  0.3253222
Encoder Loss:  0.037717655  || Decoder Loss:  0.034109365 Validation Decoder Loss:  0.32565656
Encoder Loss:  0.037698153  || Decoder Loss:  0.034083497 Validation Decoder Loss:  0.32489324
Encoder Loss:  0.037674345  || Decoder Loss:  0.034047816 Validation Decoder Loss:  0.3251666
Encoder Loss:  0.037669305  || Decoder Loss:  0.03404725 Validation Decoder Loss:  0.32486978
Encoder Loss:  0.037657503  || Decoder Loss:  0.034031797 Validation Decoder Loss:  0.32475364
Encoder Loss:  0.03764288  || Decoder Loss:  0.034009248 Validation Decoder Loss:  0.32485467
Encoder Loss:  0.037635807  || Decoder Loss:  0.03400329 Validation Decoder Loss:  0.3248289
Encoder Loss:  0.03762227  || Decoder Loss:  0.033985958 Validation Decoder Loss:  0.32484066
Encoder Loss:  0.03762106  || Decoder Loss:  0.033985518 Validation Decoder Loss:  0.32477596
Encoder Loss:  0.03761388  || Decoder Loss:  0.033975616 Validation Decoder Loss:  0.32482547
Encoder Loss:  0.037602652  || Decoder Loss:  0.033959784 Validation Decoder Loss:  0.32490242
Encoder Loss:  0.037602626  || Decoder Loss:  0.033962205 Validation Decoder Loss:  0.32488823
Encoder Loss:  0.037600137  || Decoder Loss:  0.033958234 Validation Decoder Loss:  0.3249089
Encoder Loss:  0.037598163  || Decoder Loss:  0.0339562 Validation Decoder Loss:  0.3250162
Encoder Loss:  0.03759725  || Decoder Loss:  0.033955704 Validation Decoder Loss:  0.32496
Encoder Loss:  0.037595715  || Decoder Loss:  0.03395269 Validation Decoder Loss:  0.32499912
Encoder Loss:  0.03759698  || Decoder Loss:  0.03395496 Validation Decoder Loss:  0.32511204
Encoder Loss:  0.037596885  || Decoder Loss:  0.03395596 Validation Decoder Loss:  0.3250437
Model: siamese_net_lr_0.0006854224177881298 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3250437
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_188 (Conv3D (None, 198, 10, 20, 1)    271       
_________________________________________________________________
dropout_399 (Dropout)        (None, 198, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_189 (Conv3D (None, 220, 11, 20, 1)    47        
_________________________________________________________________
reshape_79 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_133 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_401 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_134 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_133 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_403 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_134 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39785573  || Decoder Loss:  0.05909829 Validation Decoder Loss:  0.3622162
Encoder Loss:  0.39621064  || Decoder Loss:  0.060541373 Validation Decoder Loss:  0.36105627
Encoder Loss:  0.39415976  || Decoder Loss:  0.062256858 Validation Decoder Loss:  0.35967457
Encoder Loss:  0.39143553  || Decoder Loss:  0.06434696 Validation Decoder Loss:  0.3580746
Encoder Loss:  0.38757393  || Decoder Loss:  0.06647911 Validation Decoder Loss:  0.3553744
Encoder Loss:  0.38040134  || Decoder Loss:  0.0517477 Validation Decoder Loss:  0.3534893
Encoder Loss:  0.36961925  || Decoder Loss:  0.03794911 Validation Decoder Loss:  0.35052305
Encoder Loss:  0.352009  || Decoder Loss:  0.03774957 Validation Decoder Loss:  0.34842533
Encoder Loss:  0.3139557  || Decoder Loss:  0.037659828 Validation Decoder Loss:  0.34664512
Encoder Loss:  0.2113604  || Decoder Loss:  0.037622157 Validation Decoder Loss:  0.3450371
Encoder Loss:  0.08440242  || Decoder Loss:  0.037574753 Validation Decoder Loss:  0.3439921
Encoder Loss:  0.083470985  || Decoder Loss:  0.03747832 Validation Decoder Loss:  0.34330413
Encoder Loss:  0.083326235  || Decoder Loss:  0.037384786 Validation Decoder Loss:  0.34281778
Encoder Loss:  0.08315205  || Decoder Loss:  0.037283637 Validation Decoder Loss:  0.34245342
Encoder Loss:  0.082969286  || Decoder Loss:  0.03716646 Validation Decoder Loss:  0.34212866
Encoder Loss:  0.08274434  || Decoder Loss:  0.037028503 Validation Decoder Loss:  0.34178597
Encoder Loss:  0.082530305  || Decoder Loss:  0.03686401 Validation Decoder Loss:  0.3413875
Encoder Loss:  0.082242794  || Decoder Loss:  0.036664616 Validation Decoder Loss:  0.34089524
Encoder Loss:  0.0818854  || Decoder Loss:  0.036418423 Validation Decoder Loss:  0.34026057
Encoder Loss:  0.08141811  || Decoder Loss:  0.036110885 Validation Decoder Loss:  0.33941704
Encoder Loss:  0.08062664  || Decoder Loss:  0.03572938 Validation Decoder Loss:  0.33828628
Encoder Loss:  0.07908887  || Decoder Loss:  0.03527736 Validation Decoder Loss:  0.33684212
Encoder Loss:  0.07436748  || Decoder Loss:  0.034799483 Validation Decoder Loss:  0.3352203
Encoder Loss:  0.06049314  || Decoder Loss:  0.034386918 Validation Decoder Loss:  0.3336778
Encoder Loss:  0.054069377  || Decoder Loss:  0.034121856 Validation Decoder Loss:  0.33260536
Encoder Loss:  0.052582048  || Decoder Loss:  0.033998903 Validation Decoder Loss:  0.33209047
Encoder Loss:  0.05184005  || Decoder Loss:  0.033947833 Validation Decoder Loss:  0.33191454
Encoder Loss:  0.051350046  || Decoder Loss:  0.03391634 Validation Decoder Loss:  0.33184266
Encoder Loss:  0.051001526  || Decoder Loss:  0.033888787 Validation Decoder Loss:  0.33182478
Encoder Loss:  0.050729975  || Decoder Loss:  0.03386183 Validation Decoder Loss:  0.33185145
Encoder Loss:  0.050511837  || Decoder Loss:  0.03383486 Validation Decoder Loss:  0.33191627
Encoder Loss:  0.050321426  || Decoder Loss:  0.033808142 Validation Decoder Loss:  0.33201146
Encoder Loss:  0.05013125  || Decoder Loss:  0.033782013 Validation Decoder Loss:  0.3321281
Encoder Loss:  0.049950022  || Decoder Loss:  0.033756994 Validation Decoder Loss:  0.33225638
Encoder Loss:  0.049788486  || Decoder Loss:  0.03373346 Validation Decoder Loss:  0.3323893
Encoder Loss:  0.049654387  || Decoder Loss:  0.033711564 Validation Decoder Loss:  0.33252054
Encoder Loss:  0.04953281  || Decoder Loss:  0.03369141 Validation Decoder Loss:  0.3326466
Encoder Loss:  0.049408384  || Decoder Loss:  0.0336729 Validation Decoder Loss:  0.33276898
Encoder Loss:  0.04933855  || Decoder Loss:  0.033655986 Validation Decoder Loss:  0.33288366
Encoder Loss:  0.049273383  || Decoder Loss:  0.03364044 Validation Decoder Loss:  0.3329901
Model: siamese_net_lr_6.067532751540904e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3329901
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_191 (Conv3D (None, 125, 10, 20, 1)    373       
_________________________________________________________________
dropout_405 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_192 (Conv3D (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_80 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 566
Trainable params: 566
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_135 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_407 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_136 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_135 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_409 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_136 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2451573  || Decoder Loss:  0.11188643 Validation Decoder Loss:  0.38444296
Encoder Loss:  0.24495935  || Decoder Loss:  0.11382227 Validation Decoder Loss:  0.38622683
Encoder Loss:  0.24475011  || Decoder Loss:  0.11573666 Validation Decoder Loss:  0.38798288
Encoder Loss:  0.24452682  || Decoder Loss:  0.117644094 Validation Decoder Loss:  0.3897243
Encoder Loss:  0.24428812  || Decoder Loss:  0.11955684 Validation Decoder Loss:  0.39146277
Encoder Loss:  0.24403234  || Decoder Loss:  0.12148616 Validation Decoder Loss:  0.39320827
Encoder Loss:  0.24375771  || Decoder Loss:  0.12344267 Validation Decoder Loss:  0.3949709
Encoder Loss:  0.2434625  || Decoder Loss:  0.12543628 Validation Decoder Loss:  0.3967609
Encoder Loss:  0.24314412  || Decoder Loss:  0.12747717 Validation Decoder Loss:  0.39858878
Encoder Loss:  0.24280024  || Decoder Loss:  0.12957536 Validation Decoder Loss:  0.4004656
Encoder Loss:  0.24242727  || Decoder Loss:  0.13174134 Validation Decoder Loss:  0.40240404
Encoder Loss:  0.24202171  || Decoder Loss:  0.13398643 Validation Decoder Loss:  0.40441793
Encoder Loss:  0.24157901  || Decoder Loss:  0.13632283 Validation Decoder Loss:  0.4065233
Encoder Loss:  0.24109389  || Decoder Loss:  0.13876443 Validation Decoder Loss:  0.40873906
Encoder Loss:  0.2405597  || Decoder Loss:  0.14132755 Validation Decoder Loss:  0.41108894
Encoder Loss:  0.23996937  || Decoder Loss:  0.14403202 Validation Decoder Loss:  0.4136047
Encoder Loss:  0.23931454  || Decoder Loss:  0.14690375 Validation Decoder Loss:  0.41633093
Encoder Loss:  0.23858742  || Decoder Loss:  0.14997658 Validation Decoder Loss:  0.41932946
Encoder Loss:  0.23777819  || Decoder Loss:  0.1532904 Validation Decoder Loss:  0.42268342
Encoder Loss:  0.23687176  || Decoder Loss:  0.15688944 Validation Decoder Loss:  0.42650956
Encoder Loss:  0.23584248  || Decoder Loss:  0.16081637 Validation Decoder Loss:  0.43099287
Encoder Loss:  0.23463543  || Decoder Loss:  0.16508165 Validation Decoder Loss:  0.43646902
Encoder Loss:  0.23303942  || Decoder Loss:  0.16941464 Validation Decoder Loss:  0.44401628
Encoder Loss:  0.22797757  || Decoder Loss:  0.1678078 Validation Decoder Loss:  0.46242797
Encoder Loss:  0.17743242  || Decoder Loss:  0.075662285 Validation Decoder Loss:  0.3480407
Encoder Loss:  0.15745251  || Decoder Loss:  0.04703905 Validation Decoder Loss:  0.3466794
Encoder Loss:  0.15083613  || Decoder Loss:  0.04782937 Validation Decoder Loss:  0.3455957
Encoder Loss:  0.14253005  || Decoder Loss:  0.048651844 Validation Decoder Loss:  0.3441523
Encoder Loss:  0.13165356  || Decoder Loss:  0.049376205 Validation Decoder Loss:  0.34145224
Encoder Loss:  0.11695938  || Decoder Loss:  0.04987811 Validation Decoder Loss:  0.3411061
Encoder Loss:  0.09724236  || Decoder Loss:  0.050146632 Validation Decoder Loss:  0.34009165
Encoder Loss:  0.07292436  || Decoder Loss:  0.05015438 Validation Decoder Loss:  0.3389728
Encoder Loss:  0.06455316  || Decoder Loss:  0.049758267 Validation Decoder Loss:  0.33765
Encoder Loss:  0.06435145  || Decoder Loss:  0.04926361 Validation Decoder Loss:  0.33674413
Encoder Loss:  0.06402456  || Decoder Loss:  0.04881679 Validation Decoder Loss:  0.33616874
Encoder Loss:  0.06372121  || Decoder Loss:  0.048420362 Validation Decoder Loss:  0.33569282
Encoder Loss:  0.063431114  || Decoder Loss:  0.04806489 Validation Decoder Loss:  0.3352436
Encoder Loss:  0.063147314  || Decoder Loss:  0.047742482 Validation Decoder Loss:  0.33480158
Encoder Loss:  0.06285666  || Decoder Loss:  0.047446024 Validation Decoder Loss:  0.33436793
Encoder Loss:  0.06256416  || Decoder Loss:  0.047169417 Validation Decoder Loss:  0.33393985
Model: siamese_net_lr_9.161829950023909e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33393982
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_194 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_411 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_195 (Conv3D (None, 220, 11, 20, 1)    708       
_________________________________________________________________
reshape_81 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 766
Trainable params: 766
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_137 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_413 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_138 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_137 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_415 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_138 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27641955  || Decoder Loss:  0.11025776 Validation Decoder Loss:  0.38813323
Encoder Loss:  0.2591738  || Decoder Loss:  0.19248343 Validation Decoder Loss:  1.1032875
Encoder Loss:  0.11613252  || Decoder Loss:  0.15351063 Validation Decoder Loss:  0.34296906
Encoder Loss:  0.07346103  || Decoder Loss:  0.040311255 Validation Decoder Loss:  0.33830985
Encoder Loss:  0.06334206  || Decoder Loss:  0.03840084 Validation Decoder Loss:  0.33570576
Encoder Loss:  0.048846666  || Decoder Loss:  0.03691491 Validation Decoder Loss:  0.33376822
Encoder Loss:  0.046658464  || Decoder Loss:  0.035821207 Validation Decoder Loss:  0.3329099
Encoder Loss:  0.046504445  || Decoder Loss:  0.03540358 Validation Decoder Loss:  0.33296752
Encoder Loss:  0.046411194  || Decoder Loss:  0.03518267 Validation Decoder Loss:  0.33322752
Encoder Loss:  0.04633005  || Decoder Loss:  0.035058722 Validation Decoder Loss:  0.33350423
Encoder Loss:  0.046059255  || Decoder Loss:  0.034973543 Validation Decoder Loss:  0.33374918
Encoder Loss:  0.045251112  || Decoder Loss:  0.03494053 Validation Decoder Loss:  0.3340444
Encoder Loss:  0.045180336  || Decoder Loss:  0.03492127 Validation Decoder Loss:  0.33411947
Encoder Loss:  0.045176733  || Decoder Loss:  0.034911934 Validation Decoder Loss:  0.33415085
Encoder Loss:  0.045173593  || Decoder Loss:  0.034905728 Validation Decoder Loss:  0.33417696
Encoder Loss:  0.04517167  || Decoder Loss:  0.03490374 Validation Decoder Loss:  0.33420375
Encoder Loss:  0.045171943  || Decoder Loss:  0.034905113 Validation Decoder Loss:  0.33423865
Encoder Loss:  0.045172647  || Decoder Loss:  0.034908693 Validation Decoder Loss:  0.33426887
Encoder Loss:  0.045172576  || Decoder Loss:  0.034912135 Validation Decoder Loss:  0.33431718
Encoder Loss:  0.045175336  || Decoder Loss:  0.03491885 Validation Decoder Loss:  0.334345
Encoder Loss:  0.045176372  || Decoder Loss:  0.034922183 Validation Decoder Loss:  0.33436581
Encoder Loss:  0.04517394  || Decoder Loss:  0.034923404 Validation Decoder Loss:  0.334414
Encoder Loss:  0.045173164  || Decoder Loss:  0.034921616 Validation Decoder Loss:  0.33440334
Encoder Loss:  0.045171633  || Decoder Loss:  0.03491753 Validation Decoder Loss:  0.3344608
Encoder Loss:  0.045169905  || Decoder Loss:  0.034912698 Validation Decoder Loss:  0.3344689
Encoder Loss:  0.045166537  || Decoder Loss:  0.03490611 Validation Decoder Loss:  0.33451134
Encoder Loss:  0.04516193  || Decoder Loss:  0.03489808 Validation Decoder Loss:  0.33452517
Encoder Loss:  0.04515771  || Decoder Loss:  0.03488929 Validation Decoder Loss:  0.33455083
Encoder Loss:  0.045157176  || Decoder Loss:  0.034881417 Validation Decoder Loss:  0.3345702
Encoder Loss:  0.04515437  || Decoder Loss:  0.03487426 Validation Decoder Loss:  0.33460093
Encoder Loss:  0.045149207  || Decoder Loss:  0.03486636 Validation Decoder Loss:  0.33464178
Encoder Loss:  0.045149397  || Decoder Loss:  0.034860134 Validation Decoder Loss:  0.33467335
Encoder Loss:  0.045146767  || Decoder Loss:  0.03485617 Validation Decoder Loss:  0.33474082
Encoder Loss:  0.045144342  || Decoder Loss:  0.03485186 Validation Decoder Loss:  0.33478343
Encoder Loss:  0.04514257  || Decoder Loss:  0.03484817 Validation Decoder Loss:  0.33484462
Encoder Loss:  0.04514287  || Decoder Loss:  0.03484644 Validation Decoder Loss:  0.33488452
Encoder Loss:  0.045141455  || Decoder Loss:  0.03484499 Validation Decoder Loss:  0.33494884
Encoder Loss:  0.045139704  || Decoder Loss:  0.034844592 Validation Decoder Loss:  0.33502793
Encoder Loss:  0.045138836  || Decoder Loss:  0.034845218 Validation Decoder Loss:  0.33508414
Encoder Loss:  0.045140553  || Decoder Loss:  0.034849558 Validation Decoder Loss:  0.33516088
Model: siamese_net_lr_0.00039814381379135256 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33516088
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_197 (Conv3D (None, 205, 6, 20, 1)     285       
_________________________________________________________________
dropout_417 (Dropout)        (None, 205, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_198 (Conv3D (None, 220, 11, 20, 1)    97        
_________________________________________________________________
reshape_82 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_139 (Conv2D)          (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_419 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_140 (Conv2D)          (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_139 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_421 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_140 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08718858  || Decoder Loss:  0.05908185 Validation Decoder Loss:  0.3608541
Encoder Loss:  0.093593806  || Decoder Loss:  0.0673207 Validation Decoder Loss:  0.3628727
Encoder Loss:  0.12005584  || Decoder Loss:  0.09920707 Validation Decoder Loss:  0.4142885
Encoder Loss:  0.26828483  || Decoder Loss:  0.27862385 Validation Decoder Loss:  0.588358
Encoder Loss:  0.09585485  || Decoder Loss:  0.097236216 Validation Decoder Loss:  0.37755984
Encoder Loss:  0.054546922  || Decoder Loss:  0.05221497 Validation Decoder Loss:  0.3694625
Encoder Loss:  0.050795957  || Decoder Loss:  0.048198733 Validation Decoder Loss:  0.361866
Encoder Loss:  0.045298632  || Decoder Loss:  0.042407732 Validation Decoder Loss:  0.33728513
Encoder Loss:  0.03664976  || Decoder Loss:  0.03496908 Validation Decoder Loss:  0.33224726
Encoder Loss:  0.035976812  || Decoder Loss:  0.034348205 Validation Decoder Loss:  0.33205238
Encoder Loss:  0.035677932  || Decoder Loss:  0.034163646 Validation Decoder Loss:  0.3319968
Encoder Loss:  0.035503745  || Decoder Loss:  0.03403078 Validation Decoder Loss:  0.33190978
Encoder Loss:  0.035348658  || Decoder Loss:  0.03391289 Validation Decoder Loss:  0.33181894
Encoder Loss:  0.03523589  || Decoder Loss:  0.03380808 Validation Decoder Loss:  0.33166116
Encoder Loss:  0.03514357  || Decoder Loss:  0.03372872 Validation Decoder Loss:  0.33153534
Encoder Loss:  0.03510932  || Decoder Loss:  0.033696163 Validation Decoder Loss:  0.33145642
Encoder Loss:  0.03510008  || Decoder Loss:  0.033694237 Validation Decoder Loss:  0.33141378
Encoder Loss:  0.035100725  || Decoder Loss:  0.033698253 Validation Decoder Loss:  0.3313681
Encoder Loss:  0.03510489  || Decoder Loss:  0.033704147 Validation Decoder Loss:  0.33130562
Encoder Loss:  0.035107784  || Decoder Loss:  0.033709064 Validation Decoder Loss:  0.331213
Encoder Loss:  0.03511328  || Decoder Loss:  0.033715975 Validation Decoder Loss:  0.33108956
Encoder Loss:  0.03511197  || Decoder Loss:  0.033722527 Validation Decoder Loss:  0.330983
Encoder Loss:  0.035120588  || Decoder Loss:  0.03373011 Validation Decoder Loss:  0.33088243
Encoder Loss:  0.03512883  || Decoder Loss:  0.03373751 Validation Decoder Loss:  0.3308311
Encoder Loss:  0.035132732  || Decoder Loss:  0.03374388 Validation Decoder Loss:  0.3308546
Encoder Loss:  0.03514172  || Decoder Loss:  0.03375164 Validation Decoder Loss:  0.33094132
Encoder Loss:  0.03514952  || Decoder Loss:  0.033762068 Validation Decoder Loss:  0.33102286
Encoder Loss:  0.035153452  || Decoder Loss:  0.03376825 Validation Decoder Loss:  0.33111
Encoder Loss:  0.03515488  || Decoder Loss:  0.033772968 Validation Decoder Loss:  0.33119452
Encoder Loss:  0.035164054  || Decoder Loss:  0.03378177 Validation Decoder Loss:  0.33119252
Encoder Loss:  0.0351694  || Decoder Loss:  0.033788677 Validation Decoder Loss:  0.33122277
Encoder Loss:  0.03517834  || Decoder Loss:  0.033799373 Validation Decoder Loss:  0.3312615
Encoder Loss:  0.03519023  || Decoder Loss:  0.033811484 Validation Decoder Loss:  0.33127156
Encoder Loss:  0.035206407  || Decoder Loss:  0.03382152 Validation Decoder Loss:  0.33115724
Encoder Loss:  0.03520822  || Decoder Loss:  0.033828765 Validation Decoder Loss:  0.3311451
Encoder Loss:  0.035216972  || Decoder Loss:  0.033836953 Validation Decoder Loss:  0.3310687
Encoder Loss:  0.035228327  || Decoder Loss:  0.03384782 Validation Decoder Loss:  0.33098316
Encoder Loss:  0.035232212  || Decoder Loss:  0.033852786 Validation Decoder Loss:  0.3309531
Encoder Loss:  0.03523746  || Decoder Loss:  0.033858035 Validation Decoder Loss:  0.3309884
Encoder Loss:  0.035238452  || Decoder Loss:  0.0338618 Validation Decoder Loss:  0.33104658
Model: siamese_net_lr_0.00045869376192014013 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33104658
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_200 (Conv3D (None, 199, 10, 20, 1)    817       
_________________________________________________________________
dropout_423 (Dropout)        (None, 199, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_201 (Conv3D (None, 220, 11, 20, 1)    45        
_________________________________________________________________
reshape_83 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 862
Trainable params: 862
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_141 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_425 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_142 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_141 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_427 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_142 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15472698  || Decoder Loss:  0.061825868 Validation Decoder Loss:  0.3492575
Encoder Loss:  0.085425116  || Decoder Loss:  0.03767035 Validation Decoder Loss:  0.34258562
Encoder Loss:  0.047617152  || Decoder Loss:  0.03689493 Validation Decoder Loss:  0.34051988
Encoder Loss:  0.040571056  || Decoder Loss:  0.03554883 Validation Decoder Loss:  0.33641326
Encoder Loss:  0.03864194  || Decoder Loss:  0.034021515 Validation Decoder Loss:  0.3320038
Encoder Loss:  0.038144812  || Decoder Loss:  0.033481415 Validation Decoder Loss:  0.3315906
Encoder Loss:  0.038029164  || Decoder Loss:  0.033360317 Validation Decoder Loss:  0.33152753
Encoder Loss:  0.037980493  || Decoder Loss:  0.03329529 Validation Decoder Loss:  0.3314356
Encoder Loss:  0.037944704  || Decoder Loss:  0.033246115 Validation Decoder Loss:  0.33133543
Encoder Loss:  0.037915036  || Decoder Loss:  0.033205293 Validation Decoder Loss:  0.3312478
Encoder Loss:  0.037889525  || Decoder Loss:  0.033170264 Validation Decoder Loss:  0.33117935
Encoder Loss:  0.0378671  || Decoder Loss:  0.033139557 Validation Decoder Loss:  0.33112568
Encoder Loss:  0.037847303  || Decoder Loss:  0.033112142 Validation Decoder Loss:  0.33108118
Encoder Loss:  0.037829187  || Decoder Loss:  0.033087272 Validation Decoder Loss:  0.3310445
Encoder Loss:  0.037812788  || Decoder Loss:  0.03306448 Validation Decoder Loss:  0.33101255
Encoder Loss:  0.03779711  || Decoder Loss:  0.03304343 Validation Decoder Loss:  0.33098465
Encoder Loss:  0.03778326  || Decoder Loss:  0.03302391 Validation Decoder Loss:  0.33095938
Encoder Loss:  0.037769567  || Decoder Loss:  0.033005726 Validation Decoder Loss:  0.33093867
Encoder Loss:  0.03775725  || Decoder Loss:  0.03298875 Validation Decoder Loss:  0.33091748
Encoder Loss:  0.037745714  || Decoder Loss:  0.032972835 Validation Decoder Loss:  0.3309008
Encoder Loss:  0.037735034  || Decoder Loss:  0.0329579 Validation Decoder Loss:  0.33088762
Encoder Loss:  0.03772464  || Decoder Loss:  0.032943822 Validation Decoder Loss:  0.33087525
Encoder Loss:  0.03771509  || Decoder Loss:  0.032930594 Validation Decoder Loss:  0.33086547
Encoder Loss:  0.037707444  || Decoder Loss:  0.032918163 Validation Decoder Loss:  0.33085966
Encoder Loss:  0.03769766  || Decoder Loss:  0.032906402 Validation Decoder Loss:  0.33085385
Encoder Loss:  0.037689246  || Decoder Loss:  0.032895338 Validation Decoder Loss:  0.33085278
Encoder Loss:  0.037681613  || Decoder Loss:  0.03288485 Validation Decoder Loss:  0.33085215
Encoder Loss:  0.03767416  || Decoder Loss:  0.03287491 Validation Decoder Loss:  0.3308549
Encoder Loss:  0.037668798  || Decoder Loss:  0.032865662 Validation Decoder Loss:  0.33085918
Encoder Loss:  0.037661284  || Decoder Loss:  0.032856777 Validation Decoder Loss:  0.33086607
Encoder Loss:  0.037655212  || Decoder Loss:  0.032848403 Validation Decoder Loss:  0.33087134
Encoder Loss:  0.037648812  || Decoder Loss:  0.032840513 Validation Decoder Loss:  0.33088064
Encoder Loss:  0.037643667  || Decoder Loss:  0.032833077 Validation Decoder Loss:  0.33089012
Encoder Loss:  0.037639044  || Decoder Loss:  0.03282607 Validation Decoder Loss:  0.3309005
Encoder Loss:  0.037633717  || Decoder Loss:  0.032819375 Validation Decoder Loss:  0.3309109
Encoder Loss:  0.03762932  || Decoder Loss:  0.032813042 Validation Decoder Loss:  0.33092135
Encoder Loss:  0.037624553  || Decoder Loss:  0.032807015 Validation Decoder Loss:  0.3309317
Encoder Loss:  0.037620507  || Decoder Loss:  0.032801356 Validation Decoder Loss:  0.33094528
Encoder Loss:  0.03761681  || Decoder Loss:  0.032796063 Validation Decoder Loss:  0.33095852
Encoder Loss:  0.037613355  || Decoder Loss:  0.03279102 Validation Decoder Loss:  0.33096993
Model: siamese_net_lr_0.0006085439350708188 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33096993
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_203 (Conv3D (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_429 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_204 (Conv3D (None, 220, 11, 20, 1)    750       
_________________________________________________________________
reshape_84 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 802
Trainable params: 802
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_143 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_431 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_144 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_143 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_433 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_144 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31523424  || Decoder Loss:  0.10660676 Validation Decoder Loss:  0.38249153
Encoder Loss:  0.31110188  || Decoder Loss:  0.10953631 Validation Decoder Loss:  0.38512412
Encoder Loss:  0.30675137  || Decoder Loss:  0.11301354 Validation Decoder Loss:  0.3879467
Encoder Loss:  0.3020086  || Decoder Loss:  0.11741202 Validation Decoder Loss:  0.391401
Encoder Loss:  0.29644632  || Decoder Loss:  0.1237576 Validation Decoder Loss:  0.39688396
Encoder Loss:  0.28796273  || Decoder Loss:  0.13729595 Validation Decoder Loss:  0.41821694
Encoder Loss:  0.21105392  || Decoder Loss:  0.34502932 Validation Decoder Loss:  1.0691202
Encoder Loss:  0.13794744  || Decoder Loss:  0.28991756 Validation Decoder Loss:  0.38727257
Encoder Loss:  0.09332557  || Decoder Loss:  0.06269363 Validation Decoder Loss:  0.35941994
Encoder Loss:  0.0889096  || Decoder Loss:  0.04881782 Validation Decoder Loss:  0.34267974
Encoder Loss:  0.08558608  || Decoder Loss:  0.041558795 Validation Decoder Loss:  0.3363117
Encoder Loss:  0.08241954  || Decoder Loss:  0.038660645 Validation Decoder Loss:  0.3344948
Encoder Loss:  0.07946309  || Decoder Loss:  0.037657037 Validation Decoder Loss:  0.334274
Encoder Loss:  0.076157816  || Decoder Loss:  0.037257876 Validation Decoder Loss:  0.33444425
Encoder Loss:  0.072164655  || Decoder Loss:  0.036997978 Validation Decoder Loss:  0.3346949
Encoder Loss:  0.06691548  || Decoder Loss:  0.036782574 Validation Decoder Loss:  0.33490983
Encoder Loss:  0.057032097  || Decoder Loss:  0.036604717 Validation Decoder Loss:  0.33500344
Encoder Loss:  0.047618207  || Decoder Loss:  0.036299974 Validation Decoder Loss:  0.33519447
Encoder Loss:  0.047524177  || Decoder Loss:  0.036018282 Validation Decoder Loss:  0.33494127
Encoder Loss:  0.04747285  || Decoder Loss:  0.03583941 Validation Decoder Loss:  0.3346877
Encoder Loss:  0.04742783  || Decoder Loss:  0.035683848 Validation Decoder Loss:  0.33447814
Encoder Loss:  0.047389746  || Decoder Loss:  0.0355543 Validation Decoder Loss:  0.3342894
Encoder Loss:  0.047362696  || Decoder Loss:  0.035460245 Validation Decoder Loss:  0.3340983
Encoder Loss:  0.047345538  || Decoder Loss:  0.035391565 Validation Decoder Loss:  0.33387357
Encoder Loss:  0.04733396  || Decoder Loss:  0.035345864 Validation Decoder Loss:  0.33370125
Encoder Loss:  0.04732919  || Decoder Loss:  0.035314556 Validation Decoder Loss:  0.33360618
Encoder Loss:  0.04732508  || Decoder Loss:  0.03529184 Validation Decoder Loss:  0.33357996
Encoder Loss:  0.047321316  || Decoder Loss:  0.03527139 Validation Decoder Loss:  0.33358493
Encoder Loss:  0.04731696  || Decoder Loss:  0.035250593 Validation Decoder Loss:  0.33359644
Encoder Loss:  0.04731121  || Decoder Loss:  0.035233065 Validation Decoder Loss:  0.33361477
Encoder Loss:  0.047310848  || Decoder Loss:  0.03521966 Validation Decoder Loss:  0.3336238
Encoder Loss:  0.04730863  || Decoder Loss:  0.035207447 Validation Decoder Loss:  0.3336327
Encoder Loss:  0.047303747  || Decoder Loss:  0.035191976 Validation Decoder Loss:  0.33363247
Encoder Loss:  0.047303066  || Decoder Loss:  0.035186123 Validation Decoder Loss:  0.33364356
Encoder Loss:  0.04730041  || Decoder Loss:  0.03517514 Validation Decoder Loss:  0.33364832
Encoder Loss:  0.04729961  || Decoder Loss:  0.03516726 Validation Decoder Loss:  0.3336484
Encoder Loss:  0.04729809  || Decoder Loss:  0.035160862 Validation Decoder Loss:  0.33365136
Encoder Loss:  0.0472964  || Decoder Loss:  0.03515301 Validation Decoder Loss:  0.33365396
Encoder Loss:  0.047295075  || Decoder Loss:  0.035147775 Validation Decoder Loss:  0.33364987
Encoder Loss:  0.04729233  || Decoder Loss:  0.035142872 Validation Decoder Loss:  0.33365172
Model: siamese_net_lr_0.0004373242667368621 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33365172
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_206 (Conv3D (None, 205, 6, 20, 1)     285       
_________________________________________________________________
dropout_435 (Dropout)        (None, 205, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_207 (Conv3D (None, 220, 11, 20, 1)    97        
_________________________________________________________________
reshape_85 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_145 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_437 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_146 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_145 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_439 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_146 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14061762  || Decoder Loss:  0.1268918 Validation Decoder Loss:  0.33236492
Encoder Loss:  0.039192718  || Decoder Loss:  0.03536579 Validation Decoder Loss:  0.3309998
Encoder Loss:  0.036282375  || Decoder Loss:  0.03436071 Validation Decoder Loss:  0.33039576
Encoder Loss:  0.036111914  || Decoder Loss:  0.034208015 Validation Decoder Loss:  0.33067188
Encoder Loss:  0.036033165  || Decoder Loss:  0.034119915 Validation Decoder Loss:  0.33090046
Encoder Loss:  0.03595561  || Decoder Loss:  0.034032796 Validation Decoder Loss:  0.33111542
Encoder Loss:  0.035903383  || Decoder Loss:  0.033974003 Validation Decoder Loss:  0.33079234
Encoder Loss:  0.0358593  || Decoder Loss:  0.03392395 Validation Decoder Loss:  0.33058316
Encoder Loss:  0.035812903  || Decoder Loss:  0.033870865 Validation Decoder Loss:  0.3302919
Encoder Loss:  0.03577227  || Decoder Loss:  0.033824295 Validation Decoder Loss:  0.32998064
Encoder Loss:  0.035720456  || Decoder Loss:  0.033765364 Validation Decoder Loss:  0.32949865
Encoder Loss:  0.035671692  || Decoder Loss:  0.033710435 Validation Decoder Loss:  0.3289795
Encoder Loss:  0.035622668  || Decoder Loss:  0.03365442 Validation Decoder Loss:  0.3283556
Encoder Loss:  0.035577618  || Decoder Loss:  0.033603817 Validation Decoder Loss:  0.3277905
Encoder Loss:  0.035542477  || Decoder Loss:  0.033565044 Validation Decoder Loss:  0.32736558
Encoder Loss:  0.035516784  || Decoder Loss:  0.033535663 Validation Decoder Loss:  0.3272726
Encoder Loss:  0.035491556  || Decoder Loss:  0.033506613 Validation Decoder Loss:  0.32713795
Encoder Loss:  0.035456154  || Decoder Loss:  0.033464544 Validation Decoder Loss:  0.32869038
Encoder Loss:  0.035454165  || Decoder Loss:  0.03346378 Validation Decoder Loss:  0.32693946
Encoder Loss:  0.035453886  || Decoder Loss:  0.03346486 Validation Decoder Loss:  0.32648703
Encoder Loss:  0.03543804  || Decoder Loss:  0.033445377 Validation Decoder Loss:  0.32786036
Encoder Loss:  0.035464715  || Decoder Loss:  0.033478025 Validation Decoder Loss:  0.3263762
Encoder Loss:  0.03548304  || Decoder Loss:  0.033498622 Validation Decoder Loss:  0.32628042
Encoder Loss:  0.035509776  || Decoder Loss:  0.033529453 Validation Decoder Loss:  0.32759
Encoder Loss:  0.035523504  || Decoder Loss:  0.033545002 Validation Decoder Loss:  0.32629442
Encoder Loss:  0.035493556  || Decoder Loss:  0.033507884 Validation Decoder Loss:  0.32740435
Encoder Loss:  0.035522062  || Decoder Loss:  0.03354463 Validation Decoder Loss:  0.32652563
Encoder Loss:  0.035511408  || Decoder Loss:  0.03353047 Validation Decoder Loss:  0.32717288
Encoder Loss:  0.035532784  || Decoder Loss:  0.03355592 Validation Decoder Loss:  0.326344
Encoder Loss:  0.03552158  || Decoder Loss:  0.03354274 Validation Decoder Loss:  0.32722807
Encoder Loss:  0.035536114  || Decoder Loss:  0.03356106 Validation Decoder Loss:  0.3265114
Encoder Loss:  0.03552767  || Decoder Loss:  0.033549607 Validation Decoder Loss:  0.3268746
Encoder Loss:  0.035526127  || Decoder Loss:  0.033549678 Validation Decoder Loss:  0.32687032
Encoder Loss:  0.035522394  || Decoder Loss:  0.03354474 Validation Decoder Loss:  0.3269519
Encoder Loss:  0.035524447  || Decoder Loss:  0.0335481 Validation Decoder Loss:  0.32699233
Encoder Loss:  0.035521194  || Decoder Loss:  0.03354467 Validation Decoder Loss:  0.32704288
Encoder Loss:  0.035518397  || Decoder Loss:  0.03354154 Validation Decoder Loss:  0.3271537
Encoder Loss:  0.035517093  || Decoder Loss:  0.033540264 Validation Decoder Loss:  0.32708186
Encoder Loss:  0.035515375  || Decoder Loss:  0.03353837 Validation Decoder Loss:  0.32702652
Encoder Loss:  0.035514142  || Decoder Loss:  0.033537 Validation Decoder Loss:  0.3269024
Model: siamese_net_lr_0.0006983934540874706 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3269024
Model: "sequential_319"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_209 (Conv3D (None, 153, 10, 20, 1)    541       
_________________________________________________________________
dropout_441 (Dropout)        (None, 153, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_210 (Conv3D (None, 220, 11, 20, 1)    137       
_________________________________________________________________
reshape_86 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 678
Trainable params: 678
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_147 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_443 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_148 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_147 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_445 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_148 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12684745  || Decoder Loss:  0.10262799 Validation Decoder Loss:  0.3773459
Encoder Loss:  0.12796111  || Decoder Loss:  0.10401864 Validation Decoder Loss:  0.3786063
Encoder Loss:  0.1291451  || Decoder Loss:  0.10549798 Validation Decoder Loss:  0.37986207
Encoder Loss:  0.13037567  || Decoder Loss:  0.10703657 Validation Decoder Loss:  0.3811256
Encoder Loss:  0.13166064  || Decoder Loss:  0.108644046 Validation Decoder Loss:  0.3824083
Encoder Loss:  0.13300952  || Decoder Loss:  0.11033204 Validation Decoder Loss:  0.38372278
Encoder Loss:  0.13443305  || Decoder Loss:  0.11211396 Validation Decoder Loss:  0.38508314
Encoder Loss:  0.13594371  || Decoder Loss:  0.11400516 Validation Decoder Loss:  0.38650468
Encoder Loss:  0.13755615  || Decoder Loss:  0.116023876 Validation Decoder Loss:  0.3880054
Encoder Loss:  0.13928811  || Decoder Loss:  0.11819202 Validation Decoder Loss:  0.38960797
Encoder Loss:  0.14116125  || Decoder Loss:  0.12053643 Validation Decoder Loss:  0.3913416
Encoder Loss:  0.14320232  || Decoder Loss:  0.12309003 Validation Decoder Loss:  0.39324352
Encoder Loss:  0.14544478  || Decoder Loss:  0.12589428 Validation Decoder Loss:  0.39536223
Encoder Loss:  0.14793153  || Decoder Loss:  0.12900198 Validation Decoder Loss:  0.39776212
Encoder Loss:  0.15071851  || Decoder Loss:  0.1324818 Validation Decoder Loss:  0.40053105
Encoder Loss:  0.15388006  || Decoder Loss:  0.136425 Validation Decoder Loss:  0.40379214
Encoder Loss:  0.1575174  || Decoder Loss:  0.14095558 Validation Decoder Loss:  0.40772417
Encoder Loss:  0.16177261  || Decoder Loss:  0.14624691 Validation Decoder Loss:  0.4125974
Encoder Loss:  0.16685174  || Decoder Loss:  0.15254997 Validation Decoder Loss:  0.4188376
Encoder Loss:  0.17306668  || Decoder Loss:  0.16024311 Validation Decoder Loss:  0.42714703
Encoder Loss:  0.18091176  || Decoder Loss:  0.1699235 Validation Decoder Loss:  0.43874824
Encoder Loss:  0.19120178  || Decoder Loss:  0.18257168 Validation Decoder Loss:  0.45587552
Encoder Loss:  0.20522273  || Decoder Loss:  0.199741 Validation Decoder Loss:  0.48238406
Encoder Loss:  0.2220001  || Decoder Loss:  0.22061436 Validation Decoder Loss:  0.50375676
Encoder Loss:  0.17501885  || Decoder Loss:  0.17280865 Validation Decoder Loss:  0.4641223
Encoder Loss:  0.16369835  || Decoder Loss:  0.16588108 Validation Decoder Loss:  0.56078875
Encoder Loss:  0.20205125  || Decoder Loss:  0.21359853 Validation Decoder Loss:  0.59556484
Encoder Loss:  0.17537321  || Decoder Loss:  0.18452813 Validation Decoder Loss:  0.51151305
Encoder Loss:  0.14423898  || Decoder Loss:  0.1504503 Validation Decoder Loss:  0.47601447
Encoder Loss:  0.1314432  || Decoder Loss:  0.13646318 Validation Decoder Loss:  0.4574315
Encoder Loss:  0.12103891  || Decoder Loss:  0.12509318 Validation Decoder Loss:  0.440728
Encoder Loss:  0.11126059  || Decoder Loss:  0.114409134 Validation Decoder Loss:  0.4253244
Encoder Loss:  0.10197189  || Decoder Loss:  0.10426146 Validation Decoder Loss:  0.41146672
Encoder Loss:  0.093255445  || Decoder Loss:  0.09474073 Validation Decoder Loss:  0.39914948
Encoder Loss:  0.08513217  || Decoder Loss:  0.085871525 Validation Decoder Loss:  0.3879068
Encoder Loss:  0.07768376  || Decoder Loss:  0.07774429 Validation Decoder Loss:  0.37817025
Encoder Loss:  0.07097844  || Decoder Loss:  0.07043287 Validation Decoder Loss:  0.36991674
Encoder Loss:  0.06502795  || Decoder Loss:  0.06394925 Validation Decoder Loss:  0.36267388
Encoder Loss:  0.059854325  || Decoder Loss:  0.058324564 Validation Decoder Loss:  0.35676682
Encoder Loss:  0.055442363  || Decoder Loss:  0.053537216 Validation Decoder Loss:  0.35147077
Model: siamese_net_lr_0.0002907016579943614 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35147077
Model: "sequential_323"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_212 (Conv3D (None, 210, 6, 20, 1)     295       
_________________________________________________________________
dropout_447 (Dropout)        (None, 210, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_213 (Conv3D (None, 220, 11, 20, 1)    67        
_________________________________________________________________
reshape_87 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 362
Trainable params: 362
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_149 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_449 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_150 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_149 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_451 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_150 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.096853994  || Decoder Loss:  0.05447258 Validation Decoder Loss:  0.35609743
Encoder Loss:  0.10155355  || Decoder Loss:  0.06156839 Validation Decoder Loss:  0.355933
Encoder Loss:  0.12063211  || Decoder Loss:  0.08719883 Validation Decoder Loss:  0.38683802
Encoder Loss:  0.22192915  || Decoder Loss:  0.22603014 Validation Decoder Loss:  0.43502975
Encoder Loss:  0.07081085  || Decoder Loss:  0.06935167 Validation Decoder Loss:  0.3855561
Encoder Loss:  0.057902075  || Decoder Loss:  0.054797128 Validation Decoder Loss:  0.36730286
Encoder Loss:  0.050165907  || Decoder Loss:  0.046123654 Validation Decoder Loss:  0.34948203
Encoder Loss:  0.042163264  || Decoder Loss:  0.0371616 Validation Decoder Loss:  0.3343959
Encoder Loss:  0.03865927  || Decoder Loss:  0.03446352 Validation Decoder Loss:  0.33351868
Encoder Loss:  0.0366234  || Decoder Loss:  0.034374267 Validation Decoder Loss:  0.3333726
Encoder Loss:  0.036550373  || Decoder Loss:  0.034422137 Validation Decoder Loss:  0.33339077
Encoder Loss:  0.036484506  || Decoder Loss:  0.034443337 Validation Decoder Loss:  0.33341378
Encoder Loss:  0.036463533  || Decoder Loss:  0.034451958 Validation Decoder Loss:  0.33340594
Encoder Loss:  0.03645027  || Decoder Loss:  0.03445513 Validation Decoder Loss:  0.33339822
Encoder Loss:  0.036434043  || Decoder Loss:  0.034452792 Validation Decoder Loss:  0.3333997
Encoder Loss:  0.03641462  || Decoder Loss:  0.03444505 Validation Decoder Loss:  0.33331573
Encoder Loss:  0.036395893  || Decoder Loss:  0.034431454 Validation Decoder Loss:  0.33322668
Encoder Loss:  0.036364757  || Decoder Loss:  0.034409508 Validation Decoder Loss:  0.33313823
Encoder Loss:  0.036336888  || Decoder Loss:  0.034380626 Validation Decoder Loss:  0.333025
Encoder Loss:  0.036291264  || Decoder Loss:  0.03434867 Validation Decoder Loss:  0.3330543
Encoder Loss:  0.03627114  || Decoder Loss:  0.034323346 Validation Decoder Loss:  0.33310992
Encoder Loss:  0.03624978  || Decoder Loss:  0.03430321 Validation Decoder Loss:  0.3331683
Encoder Loss:  0.036235563  || Decoder Loss:  0.034285136 Validation Decoder Loss:  0.3332122
Encoder Loss:  0.036227085  || Decoder Loss:  0.0342671 Validation Decoder Loss:  0.33308864
Encoder Loss:  0.036215294  || Decoder Loss:  0.034252126 Validation Decoder Loss:  0.3330177
Encoder Loss:  0.036193248  || Decoder Loss:  0.03423699 Validation Decoder Loss:  0.33304596
Encoder Loss:  0.03618319  || Decoder Loss:  0.034223612 Validation Decoder Loss:  0.33303097
Encoder Loss:  0.036170173  || Decoder Loss:  0.03421288 Validation Decoder Loss:  0.333037
Encoder Loss:  0.036161795  || Decoder Loss:  0.034202985 Validation Decoder Loss:  0.33302176
Encoder Loss:  0.036152627  || Decoder Loss:  0.034193687 Validation Decoder Loss:  0.33297646
Encoder Loss:  0.036144566  || Decoder Loss:  0.034184903 Validation Decoder Loss:  0.33293572
Encoder Loss:  0.036141943  || Decoder Loss:  0.034176033 Validation Decoder Loss:  0.33285007
Encoder Loss:  0.036127083  || Decoder Loss:  0.034165494 Validation Decoder Loss:  0.33282647
Encoder Loss:  0.036119193  || Decoder Loss:  0.034155153 Validation Decoder Loss:  0.33279464
Encoder Loss:  0.03610629  || Decoder Loss:  0.0341441 Validation Decoder Loss:  0.3327431
Encoder Loss:  0.036098525  || Decoder Loss:  0.034135364 Validation Decoder Loss:  0.33267373
Encoder Loss:  0.03609498  || Decoder Loss:  0.034126423 Validation Decoder Loss:  0.33254597
Encoder Loss:  0.036081877  || Decoder Loss:  0.034115456 Validation Decoder Loss:  0.3324679
Encoder Loss:  0.036071308  || Decoder Loss:  0.03410448 Validation Decoder Loss:  0.33240414
Encoder Loss:  0.03606121  || Decoder Loss:  0.034093052 Validation Decoder Loss:  0.33233392
Model: siamese_net_lr_0.0008591534331722469 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3323339
Model: "sequential_327"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_215 (Conv3D (None, 122, 10, 20, 1)    119       
_________________________________________________________________
dropout_453 (Dropout)        (None, 122, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_216 (Conv3D (None, 220, 11, 20, 1)    199       
_________________________________________________________________
reshape_88 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_151 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_455 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_152 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_151 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_457 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_152 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2762211  || Decoder Loss:  0.10608785 Validation Decoder Loss:  0.38160336
Encoder Loss:  0.27560496  || Decoder Loss:  0.10966472 Validation Decoder Loss:  0.38481286
Encoder Loss:  0.27489787  || Decoder Loss:  0.11350158 Validation Decoder Loss:  0.38822925
Encoder Loss:  0.2740251  || Decoder Loss:  0.117819615 Validation Decoder Loss:  0.3920665
Encoder Loss:  0.2728373  || Decoder Loss:  0.12300251 Validation Decoder Loss:  0.3967698
Encoder Loss:  0.27095422  || Decoder Loss:  0.12993191 Validation Decoder Loss:  0.40363392
Encoder Loss:  0.26698712  || Decoder Loss:  0.14157197 Validation Decoder Loss:  0.4191656
Encoder Loss:  0.24827155  || Decoder Loss:  0.18853943 Validation Decoder Loss:  0.72988296
Encoder Loss:  0.13969177  || Decoder Loss:  0.20809628 Validation Decoder Loss:  0.38672405
Encoder Loss:  0.0883537  || Decoder Loss:  0.07839398 Validation Decoder Loss:  0.332339
Encoder Loss:  0.07368626  || Decoder Loss:  0.042515535 Validation Decoder Loss:  0.3339547
Encoder Loss:  0.07240576  || Decoder Loss:  0.04041387 Validation Decoder Loss:  0.33363342
Encoder Loss:  0.07189688  || Decoder Loss:  0.040464543 Validation Decoder Loss:  0.3325078
Encoder Loss:  0.071376786  || Decoder Loss:  0.04057647 Validation Decoder Loss:  0.3314963
Encoder Loss:  0.070774615  || Decoder Loss:  0.040677715 Validation Decoder Loss:  0.33061463
Encoder Loss:  0.07002901  || Decoder Loss:  0.04073885 Validation Decoder Loss:  0.32983074
Encoder Loss:  0.069138326  || Decoder Loss:  0.04073622 Validation Decoder Loss:  0.32912686
Encoder Loss:  0.06806596  || Decoder Loss:  0.0406508 Validation Decoder Loss:  0.3284968
Encoder Loss:  0.0667739  || Decoder Loss:  0.040472895 Validation Decoder Loss:  0.32794136
Encoder Loss:  0.06513647  || Decoder Loss:  0.040198155 Validation Decoder Loss:  0.3274664
Encoder Loss:  0.06297338  || Decoder Loss:  0.0398259 Validation Decoder Loss:  0.3271082
Encoder Loss:  0.06007232  || Decoder Loss:  0.039373726 Validation Decoder Loss:  0.32689917
Encoder Loss:  0.05618926  || Decoder Loss:  0.038887415 Validation Decoder Loss:  0.32686627
Encoder Loss:  0.051301632  || Decoder Loss:  0.038407747 Validation Decoder Loss:  0.32702646
Encoder Loss:  0.04707898  || Decoder Loss:  0.03796842 Validation Decoder Loss:  0.32712853
Encoder Loss:  0.046688408  || Decoder Loss:  0.037657212 Validation Decoder Loss:  0.32714158
Encoder Loss:  0.046563596  || Decoder Loss:  0.037359167 Validation Decoder Loss:  0.32713926
Encoder Loss:  0.046435002  || Decoder Loss:  0.037055694 Validation Decoder Loss:  0.32714
Encoder Loss:  0.04631584  || Decoder Loss:  0.036760528 Validation Decoder Loss:  0.3271514
Encoder Loss:  0.04620357  || Decoder Loss:  0.03648486 Validation Decoder Loss:  0.32717657
Encoder Loss:  0.04610095  || Decoder Loss:  0.036231622 Validation Decoder Loss:  0.32721624
Encoder Loss:  0.046009187  || Decoder Loss:  0.03599948 Validation Decoder Loss:  0.3272679
Encoder Loss:  0.04591928  || Decoder Loss:  0.03578965 Validation Decoder Loss:  0.32732898
Encoder Loss:  0.04584287  || Decoder Loss:  0.035604097 Validation Decoder Loss:  0.3273991
Encoder Loss:  0.045775257  || Decoder Loss:  0.035443306 Validation Decoder Loss:  0.32747328
Encoder Loss:  0.0457193  || Decoder Loss:  0.035306193 Validation Decoder Loss:  0.32754964
Encoder Loss:  0.04566359  || Decoder Loss:  0.035190593 Validation Decoder Loss:  0.32762745
Encoder Loss:  0.04561496  || Decoder Loss:  0.035093788 Validation Decoder Loss:  0.32770443
Encoder Loss:  0.04556235  || Decoder Loss:  0.035012882 Validation Decoder Loss:  0.32777768
Encoder Loss:  0.04543373  || Decoder Loss:  0.034945805 Validation Decoder Loss:  0.3278402
Model: siamese_net_lr_0.00019834899777502029 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32784015
Model: "sequential_331"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_218 (Conv3D (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_459 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_219 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_89 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_153 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_461 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_154 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_153 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_463 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_154 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24019855  || Decoder Loss:  0.121637926 Validation Decoder Loss:  0.43806475
Encoder Loss:  0.11460521  || Decoder Loss:  0.117109686 Validation Decoder Loss:  0.33852303
Encoder Loss:  0.06067572  || Decoder Loss:  0.037909377 Validation Decoder Loss:  0.3294751
Encoder Loss:  0.04822986  || Decoder Loss:  0.03517001 Validation Decoder Loss:  0.33015963
Encoder Loss:  0.043367982  || Decoder Loss:  0.035054628 Validation Decoder Loss:  0.33038345
Encoder Loss:  0.04333987  || Decoder Loss:  0.035018414 Validation Decoder Loss:  0.3307427
Encoder Loss:  0.043309383  || Decoder Loss:  0.03499099 Validation Decoder Loss:  0.3310431
Encoder Loss:  0.043279182  || Decoder Loss:  0.034969024 Validation Decoder Loss:  0.33131054
Encoder Loss:  0.043247722  || Decoder Loss:  0.03495181 Validation Decoder Loss:  0.33152196
Encoder Loss:  0.04321104  || Decoder Loss:  0.034937456 Validation Decoder Loss:  0.33163622
Encoder Loss:  0.043127924  || Decoder Loss:  0.03492169 Validation Decoder Loss:  0.33162674
Encoder Loss:  0.042330507  || Decoder Loss:  0.034867216 Validation Decoder Loss:  0.33149737
Encoder Loss:  0.042037643  || Decoder Loss:  0.034824558 Validation Decoder Loss:  0.33160174
Encoder Loss:  0.042027134  || Decoder Loss:  0.03481955 Validation Decoder Loss:  0.331643
Encoder Loss:  0.04201702  || Decoder Loss:  0.03481065 Validation Decoder Loss:  0.33065915
Encoder Loss:  0.04200365  || Decoder Loss:  0.03479303 Validation Decoder Loss:  0.33059657
Encoder Loss:  0.04199004  || Decoder Loss:  0.034768976 Validation Decoder Loss:  0.3305272
Encoder Loss:  0.041974932  || Decoder Loss:  0.03474285 Validation Decoder Loss:  0.33101884
Encoder Loss:  0.041964754  || Decoder Loss:  0.034723878 Validation Decoder Loss:  0.33039814
Encoder Loss:  0.0419531  || Decoder Loss:  0.034701154 Validation Decoder Loss:  0.33039236
Encoder Loss:  0.04194446  || Decoder Loss:  0.034686517 Validation Decoder Loss:  0.33036393
Encoder Loss:  0.041940674  || Decoder Loss:  0.03468045 Validation Decoder Loss:  0.3311069
Encoder Loss:  0.041942123  || Decoder Loss:  0.03468247 Validation Decoder Loss:  0.3300423
Encoder Loss:  0.04194321  || Decoder Loss:  0.034685783 Validation Decoder Loss:  0.3297818
Encoder Loss:  0.041949425  || Decoder Loss:  0.034698904 Validation Decoder Loss:  0.33046168
Encoder Loss:  0.04195493  || Decoder Loss:  0.03471082 Validation Decoder Loss:  0.33058882
Encoder Loss:  0.0419646  || Decoder Loss:  0.034730457 Validation Decoder Loss:  0.3294441
Encoder Loss:  0.041971497  || Decoder Loss:  0.034744933 Validation Decoder Loss:  0.3294231
Encoder Loss:  0.04197344  || Decoder Loss:  0.034744576 Validation Decoder Loss:  0.32896253
Encoder Loss:  0.041970026  || Decoder Loss:  0.034742754 Validation Decoder Loss:  0.32846594
Encoder Loss:  0.041965228  || Decoder Loss:  0.03473424 Validation Decoder Loss:  0.3273465
Encoder Loss:  0.04192746  || Decoder Loss:  0.034663163 Validation Decoder Loss:  0.326787
Encoder Loss:  0.041893397  || Decoder Loss:  0.03459795 Validation Decoder Loss:  0.326445
Encoder Loss:  0.041858345  || Decoder Loss:  0.034532 Validation Decoder Loss:  0.32616705
Encoder Loss:  0.041828167  || Decoder Loss:  0.034473676 Validation Decoder Loss:  0.32603356
Encoder Loss:  0.041796613  || Decoder Loss:  0.03441571 Validation Decoder Loss:  0.32590514
Encoder Loss:  0.041770183  || Decoder Loss:  0.0343649 Validation Decoder Loss:  0.32584715
Encoder Loss:  0.041747265  || Decoder Loss:  0.03432226 Validation Decoder Loss:  0.3257551
Encoder Loss:  0.04172909  || Decoder Loss:  0.034286764 Validation Decoder Loss:  0.32571572
Encoder Loss:  0.041711245  || Decoder Loss:  0.034254283 Validation Decoder Loss:  0.32569316
Model: siamese_net_lr_0.00033279867190448017 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32569316
Model: "sequential_335"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_221 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_465 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_222 (Conv3D (None, 220, 11, 20, 1)    310       
_________________________________________________________________
reshape_90 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 366
Trainable params: 366
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_155 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_467 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_156 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_155 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_469 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_156 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19221826  || Decoder Loss:  0.10724252 Validation Decoder Loss:  0.38396704
Encoder Loss:  0.18897498  || Decoder Loss:  0.118943565 Validation Decoder Loss:  0.4022894
Encoder Loss:  0.19227342  || Decoder Loss:  0.21839981 Validation Decoder Loss:  0.35082424
Encoder Loss:  0.062247552  || Decoder Loss:  0.047300924 Validation Decoder Loss:  0.34884298
Encoder Loss:  0.056399547  || Decoder Loss:  0.039805785 Validation Decoder Loss:  0.34339622
Encoder Loss:  0.0551316  || Decoder Loss:  0.039574634 Validation Decoder Loss:  0.33865672
Encoder Loss:  0.053559013  || Decoder Loss:  0.039331675 Validation Decoder Loss:  0.33515534
Encoder Loss:  0.050260395  || Decoder Loss:  0.038724642 Validation Decoder Loss:  0.33303607
Encoder Loss:  0.04225041  || Decoder Loss:  0.03768864 Validation Decoder Loss:  0.33256927
Encoder Loss:  0.040422842  || Decoder Loss:  0.03556891 Validation Decoder Loss:  0.33168173
Encoder Loss:  0.039900076  || Decoder Loss:  0.03481592 Validation Decoder Loss:  0.33113182
Encoder Loss:  0.039656732  || Decoder Loss:  0.03446352 Validation Decoder Loss:  0.33086103
Encoder Loss:  0.03954634  || Decoder Loss:  0.03431061 Validation Decoder Loss:  0.33072203
Encoder Loss:  0.039514557  || Decoder Loss:  0.03426674 Validation Decoder Loss:  0.33068624
Encoder Loss:  0.03951755  || Decoder Loss:  0.034281712 Validation Decoder Loss:  0.33075172
Encoder Loss:  0.03953899  || Decoder Loss:  0.034314346 Validation Decoder Loss:  0.33094794
Encoder Loss:  0.03955083  || Decoder Loss:  0.03433724 Validation Decoder Loss:  0.33142534
Encoder Loss:  0.039565727  || Decoder Loss:  0.03436382 Validation Decoder Loss:  0.3319209
Encoder Loss:  0.03959138  || Decoder Loss:  0.03440526 Validation Decoder Loss:  0.33217686
Encoder Loss:  0.0396107  || Decoder Loss:  0.034437016 Validation Decoder Loss:  0.3324095
Encoder Loss:  0.03963504  || Decoder Loss:  0.034471676 Validation Decoder Loss:  0.3325767
Encoder Loss:  0.03966587  || Decoder Loss:  0.034521293 Validation Decoder Loss:  0.33265966
Encoder Loss:  0.039691936  || Decoder Loss:  0.034566894 Validation Decoder Loss:  0.33276853
Encoder Loss:  0.0397173  || Decoder Loss:  0.03461032 Validation Decoder Loss:  0.33284777
Encoder Loss:  0.039745405  || Decoder Loss:  0.0346537 Validation Decoder Loss:  0.33289987
Encoder Loss:  0.039781686  || Decoder Loss:  0.034703806 Validation Decoder Loss:  0.3328792
Encoder Loss:  0.03980851  || Decoder Loss:  0.034746874 Validation Decoder Loss:  0.3327551
Encoder Loss:  0.039832406  || Decoder Loss:  0.034785874 Validation Decoder Loss:  0.3327167
Encoder Loss:  0.039855063  || Decoder Loss:  0.034821883 Validation Decoder Loss:  0.33261397
Encoder Loss:  0.03987391  || Decoder Loss:  0.034853674 Validation Decoder Loss:  0.33255225
Encoder Loss:  0.03988605  || Decoder Loss:  0.03487383 Validation Decoder Loss:  0.33242404
Encoder Loss:  0.03990524  || Decoder Loss:  0.034903184 Validation Decoder Loss:  0.33230743
Encoder Loss:  0.03991572  || Decoder Loss:  0.034920942 Validation Decoder Loss:  0.33224657
Encoder Loss:  0.039931864  || Decoder Loss:  0.034943495 Validation Decoder Loss:  0.33204344
Encoder Loss:  0.039937127  || Decoder Loss:  0.034956016 Validation Decoder Loss:  0.33202475
Encoder Loss:  0.039944768  || Decoder Loss:  0.034968413 Validation Decoder Loss:  0.33195683
Encoder Loss:  0.039950356  || Decoder Loss:  0.034977324 Validation Decoder Loss:  0.33196157
Encoder Loss:  0.039960247  || Decoder Loss:  0.03499063 Validation Decoder Loss:  0.33186245
Encoder Loss:  0.039962724  || Decoder Loss:  0.034997866 Validation Decoder Loss:  0.33172697
Encoder Loss:  0.03996832  || Decoder Loss:  0.03500711 Validation Decoder Loss:  0.3317813
Model: siamese_net_lr_0.00017188696626929467 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33178133
Model: "sequential_339"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_224 (Conv3D (None, 200, 10, 20, 1)    149       
_________________________________________________________________
dropout_471 (Dropout)        (None, 200, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_225 (Conv3D (None, 220, 11, 20, 1)    43        
_________________________________________________________________
reshape_91 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_157 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_473 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_158 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_157 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_475 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_158 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.040765435  || Decoder Loss:  0.040611044 Validation Decoder Loss:  0.33763635
Encoder Loss:  0.034056522  || Decoder Loss:  0.03399853 Validation Decoder Loss:  0.33050072
Encoder Loss:  0.033453245  || Decoder Loss:  0.03339652 Validation Decoder Loss:  0.33016196
Encoder Loss:  0.033303723  || Decoder Loss:  0.033246983 Validation Decoder Loss:  0.33003086
Encoder Loss:  0.033212114  || Decoder Loss:  0.033156052 Validation Decoder Loss:  0.33002567
Encoder Loss:  0.033139125  || Decoder Loss:  0.03309133 Validation Decoder Loss:  0.32998276
Encoder Loss:  0.033054393  || Decoder Loss:  0.03303857 Validation Decoder Loss:  0.3299113
Encoder Loss:  0.033010166  || Decoder Loss:  0.032996003 Validation Decoder Loss:  0.3298338
Encoder Loss:  0.03297497  || Decoder Loss:  0.03296074 Validation Decoder Loss:  0.32974982
Encoder Loss:  0.032944895  || Decoder Loss:  0.032930635 Validation Decoder Loss:  0.32967487
Encoder Loss:  0.032918982  || Decoder Loss:  0.032904714 Validation Decoder Loss:  0.32960784
Encoder Loss:  0.032896407  || Decoder Loss:  0.032882206 Validation Decoder Loss:  0.32954663
Encoder Loss:  0.03287681  || Decoder Loss:  0.032862585 Validation Decoder Loss:  0.32948947
Encoder Loss:  0.03285971  || Decoder Loss:  0.032845452 Validation Decoder Loss:  0.3294375
Encoder Loss:  0.032844607  || Decoder Loss:  0.032830343 Validation Decoder Loss:  0.3293916
Encoder Loss:  0.03283111  || Decoder Loss:  0.032816816 Validation Decoder Loss:  0.3293487
Encoder Loss:  0.032819025  || Decoder Loss:  0.032804716 Validation Decoder Loss:  0.32930562
Encoder Loss:  0.032808248  || Decoder Loss:  0.032793928 Validation Decoder Loss:  0.32928348
Encoder Loss:  0.032798547  || Decoder Loss:  0.032784276 Validation Decoder Loss:  0.32928425
Encoder Loss:  0.032790016  || Decoder Loss:  0.032775715 Validation Decoder Loss:  0.3292736
Encoder Loss:  0.03278246  || Decoder Loss:  0.032768153 Validation Decoder Loss:  0.3292767
Encoder Loss:  0.032775737  || Decoder Loss:  0.032761436 Validation Decoder Loss:  0.32928658
Encoder Loss:  0.032769732  || Decoder Loss:  0.032755405 Validation Decoder Loss:  0.3292932
Encoder Loss:  0.032764312  || Decoder Loss:  0.03275 Validation Decoder Loss:  0.32930237
Encoder Loss:  0.03275945  || Decoder Loss:  0.032745127 Validation Decoder Loss:  0.32931003
Encoder Loss:  0.032755002  || Decoder Loss:  0.032740656 Validation Decoder Loss:  0.32931757
Encoder Loss:  0.03275099  || Decoder Loss:  0.032736555 Validation Decoder Loss:  0.3293184
Encoder Loss:  0.032747235  || Decoder Loss:  0.03273292 Validation Decoder Loss:  0.32933164
Encoder Loss:  0.032743834  || Decoder Loss:  0.032729503 Validation Decoder Loss:  0.32933784
Encoder Loss:  0.032740716  || Decoder Loss:  0.032726385 Validation Decoder Loss:  0.32934403
Encoder Loss:  0.032737795  || Decoder Loss:  0.032723475 Validation Decoder Loss:  0.32934237
Encoder Loss:  0.032735188  || Decoder Loss:  0.03272082 Validation Decoder Loss:  0.3293543
Encoder Loss:  0.03273268  || Decoder Loss:  0.03271836 Validation Decoder Loss:  0.3293599
Encoder Loss:  0.03273038  || Decoder Loss:  0.032716047 Validation Decoder Loss:  0.32936385
Encoder Loss:  0.03272829  || Decoder Loss:  0.03271393 Validation Decoder Loss:  0.32936633
Encoder Loss:  0.032726273  || Decoder Loss:  0.032711934 Validation Decoder Loss:  0.32937083
Encoder Loss:  0.03272437  || Decoder Loss:  0.032710046 Validation Decoder Loss:  0.32937026
Encoder Loss:  0.03272263  || Decoder Loss:  0.032708272 Validation Decoder Loss:  0.32937446
Encoder Loss:  0.032720994  || Decoder Loss:  0.03270664 Validation Decoder Loss:  0.32937366
Encoder Loss:  0.03271944  || Decoder Loss:  0.032705076 Validation Decoder Loss:  0.3293767
Model: siamese_net_lr_0.0009728393026940442 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3293767
Model: "sequential_343"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_227 (Conv3D (None, 205, 6, 20, 1)     159       
_________________________________________________________________
dropout_477 (Dropout)        (None, 205, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_228 (Conv3D (None, 220, 11, 20, 1)    97        
_________________________________________________________________
reshape_92 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 256
Trainable params: 256
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_159 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_479 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_160 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_159 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_481 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_160 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31878483  || Decoder Loss:  0.07703646 Validation Decoder Loss:  0.77210104
Encoder Loss:  0.101674646  || Decoder Loss:  0.12413436 Validation Decoder Loss:  0.3644327
Encoder Loss:  0.079919636  || Decoder Loss:  0.039714314 Validation Decoder Loss:  0.3315634
Encoder Loss:  0.048514318  || Decoder Loss:  0.034793492 Validation Decoder Loss:  0.33016965
Encoder Loss:  0.04743794  || Decoder Loss:  0.034721524 Validation Decoder Loss:  0.3301661
Encoder Loss:  0.047179934  || Decoder Loss:  0.034702174 Validation Decoder Loss:  0.33029273
Encoder Loss:  0.047164664  || Decoder Loss:  0.03464268 Validation Decoder Loss:  0.3302169
Encoder Loss:  0.047146905  || Decoder Loss:  0.03457511 Validation Decoder Loss:  0.33011472
Encoder Loss:  0.047128092  || Decoder Loss:  0.03450872 Validation Decoder Loss:  0.3300159
Encoder Loss:  0.04710681  || Decoder Loss:  0.03444264 Validation Decoder Loss:  0.32987273
Encoder Loss:  0.04708881  || Decoder Loss:  0.03437574 Validation Decoder Loss:  0.32972592
Encoder Loss:  0.04707086  || Decoder Loss:  0.034302007 Validation Decoder Loss:  0.32955652
Encoder Loss:  0.04705322  || Decoder Loss:  0.034220055 Validation Decoder Loss:  0.32932243
Encoder Loss:  0.047033936  || Decoder Loss:  0.03413224 Validation Decoder Loss:  0.32908908
Encoder Loss:  0.047014847  || Decoder Loss:  0.034042686 Validation Decoder Loss:  0.32882082
Encoder Loss:  0.047000505  || Decoder Loss:  0.033965196 Validation Decoder Loss:  0.3286788
Encoder Loss:  0.04698833  || Decoder Loss:  0.03390549 Validation Decoder Loss:  0.3286168
Encoder Loss:  0.046978556  || Decoder Loss:  0.03386314 Validation Decoder Loss:  0.32857364
Encoder Loss:  0.0469726  || Decoder Loss:  0.033835772 Validation Decoder Loss:  0.32846886
Encoder Loss:  0.04696958  || Decoder Loss:  0.033822082 Validation Decoder Loss:  0.32837796
Encoder Loss:  0.04696635  || Decoder Loss:  0.033821076 Validation Decoder Loss:  0.3282472
Encoder Loss:  0.046966013  || Decoder Loss:  0.033828992 Validation Decoder Loss:  0.32823193
Encoder Loss:  0.046960264  || Decoder Loss:  0.033837147 Validation Decoder Loss:  0.32825848
Encoder Loss:  0.04696188  || Decoder Loss:  0.033846468 Validation Decoder Loss:  0.3283419
Encoder Loss:  0.04696483  || Decoder Loss:  0.033850092 Validation Decoder Loss:  0.32839698
Encoder Loss:  0.04696076  || Decoder Loss:  0.033856288 Validation Decoder Loss:  0.32851082
Encoder Loss:  0.046960063  || Decoder Loss:  0.03386 Validation Decoder Loss:  0.3292594
Encoder Loss:  0.046969604  || Decoder Loss:  0.033860687 Validation Decoder Loss:  0.32932174
Encoder Loss:  0.046958975  || Decoder Loss:  0.03386073 Validation Decoder Loss:  0.32933888
Encoder Loss:  0.046959437  || Decoder Loss:  0.033866365 Validation Decoder Loss:  0.3296395
Encoder Loss:  0.04695949  || Decoder Loss:  0.033866674 Validation Decoder Loss:  0.32969174
Encoder Loss:  0.04696792  || Decoder Loss:  0.033865117 Validation Decoder Loss:  0.32976526
Encoder Loss:  0.046958026  || Decoder Loss:  0.033868246 Validation Decoder Loss:  0.3299592
Encoder Loss:  0.046958342  || Decoder Loss:  0.033870015 Validation Decoder Loss:  0.33009815
Encoder Loss:  0.046958685  || Decoder Loss:  0.033873014 Validation Decoder Loss:  0.33014983
Encoder Loss:  0.046959877  || Decoder Loss:  0.03387575 Validation Decoder Loss:  0.33027804
Encoder Loss:  0.046959814  || Decoder Loss:  0.033879705 Validation Decoder Loss:  0.33041847
Encoder Loss:  0.046960734  || Decoder Loss:  0.033882808 Validation Decoder Loss:  0.33052468
Encoder Loss:  0.04695935  || Decoder Loss:  0.03388577 Validation Decoder Loss:  0.3305527
Encoder Loss:  0.0469608  || Decoder Loss:  0.033887908 Validation Decoder Loss:  0.3306074
Model: siamese_net_lr_0.0003657455800240564 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33060744
Model: "sequential_347"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_230 (Conv3D (None, 190, 10, 20, 1)    129       
_________________________________________________________________
dropout_483 (Dropout)        (None, 190, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_231 (Conv3D (None, 220, 11, 20, 1)    63        
_________________________________________________________________
reshape_93 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_161 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_485 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_162 (Conv2D)          (None, 2420, 20, 1)       162       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_161 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_487 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_162 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20867902  || Decoder Loss:  0.06238273 Validation Decoder Loss:  0.3685879
Encoder Loss:  0.20869106  || Decoder Loss:  0.062491283 Validation Decoder Loss:  0.36865664
Encoder Loss:  0.20870277  || Decoder Loss:  0.062602974 Validation Decoder Loss:  0.36871094
Encoder Loss:  0.2087145  || Decoder Loss:  0.062716454 Validation Decoder Loss:  0.36875153
Encoder Loss:  0.20872614  || Decoder Loss:  0.06283214 Validation Decoder Loss:  0.3687795
Encoder Loss:  0.20873797  || Decoder Loss:  0.062950246 Validation Decoder Loss:  0.36879605
Encoder Loss:  0.2087499  || Decoder Loss:  0.063071005 Validation Decoder Loss:  0.36880213
Encoder Loss:  0.2087619  || Decoder Loss:  0.06319469 Validation Decoder Loss:  0.3687985
Encoder Loss:  0.20877409  || Decoder Loss:  0.06332146 Validation Decoder Loss:  0.36878565
Encoder Loss:  0.20878647  || Decoder Loss:  0.063451596 Validation Decoder Loss:  0.36876398
Encoder Loss:  0.20879906  || Decoder Loss:  0.06358534 Validation Decoder Loss:  0.3687338
Encoder Loss:  0.20881185  || Decoder Loss:  0.06372299 Validation Decoder Loss:  0.3686952
Encoder Loss:  0.20882496  || Decoder Loss:  0.06386484 Validation Decoder Loss:  0.36864835
Encoder Loss:  0.20883842  || Decoder Loss:  0.06401122 Validation Decoder Loss:  0.36859336
Encoder Loss:  0.2088522  || Decoder Loss:  0.06416248 Validation Decoder Loss:  0.3685304
Encoder Loss:  0.20886642  || Decoder Loss:  0.06431899 Validation Decoder Loss:  0.36845964
Encoder Loss:  0.20888108  || Decoder Loss:  0.06448117 Validation Decoder Loss:  0.36838132
Encoder Loss:  0.20889622  || Decoder Loss:  0.06464947 Validation Decoder Loss:  0.3682958
Encoder Loss:  0.20891199  || Decoder Loss:  0.064824395 Validation Decoder Loss:  0.3682034
Encoder Loss:  0.2089283  || Decoder Loss:  0.065006435 Validation Decoder Loss:  0.3681044
Encoder Loss:  0.20894535  || Decoder Loss:  0.06519623 Validation Decoder Loss:  0.36799914
Encoder Loss:  0.20896313  || Decoder Loss:  0.065394364 Validation Decoder Loss:  0.36788797
Encoder Loss:  0.20898172  || Decoder Loss:  0.06560163 Validation Decoder Loss:  0.3677712
Encoder Loss:  0.2090012  || Decoder Loss:  0.065818794 Validation Decoder Loss:  0.36764914
Encoder Loss:  0.20902169  || Decoder Loss:  0.066046774 Validation Decoder Loss:  0.36752212
Encoder Loss:  0.2090433  || Decoder Loss:  0.06628658 Validation Decoder Loss:  0.36739057
Encoder Loss:  0.2090661  || Decoder Loss:  0.066539384 Validation Decoder Loss:  0.36725497
Encoder Loss:  0.20909017  || Decoder Loss:  0.066806465 Validation Decoder Loss:  0.36711577
Encoder Loss:  0.20911583  || Decoder Loss:  0.0670893 Validation Decoder Loss:  0.36697376
Encoder Loss:  0.20914297  || Decoder Loss:  0.06738963 Validation Decoder Loss:  0.3668296
Encoder Loss:  0.20917197  || Decoder Loss:  0.06770934 Validation Decoder Loss:  0.36668414
Encoder Loss:  0.2092029  || Decoder Loss:  0.068050735 Validation Decoder Loss:  0.3665384
Encoder Loss:  0.20923609  || Decoder Loss:  0.06841642 Validation Decoder Loss:  0.3663935
Encoder Loss:  0.20927164  || Decoder Loss:  0.06880941 Validation Decoder Loss:  0.36625075
Encoder Loss:  0.20930997  || Decoder Loss:  0.06923336 Validation Decoder Loss:  0.36611164
Encoder Loss:  0.20935129  || Decoder Loss:  0.06969248 Validation Decoder Loss:  0.365978
Encoder Loss:  0.20939611  || Decoder Loss:  0.07019189 Validation Decoder Loss:  0.36585218
Encoder Loss:  0.20944473  || Decoder Loss:  0.070737734 Validation Decoder Loss:  0.36573693
Encoder Loss:  0.20949775  || Decoder Loss:  0.07133743 Validation Decoder Loss:  0.36563587
Encoder Loss:  0.20955583  || Decoder Loss:  0.07200015 Validation Decoder Loss:  0.36555374
Model: siamese_net_lr_0.00010253334885156369 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36555374
Model: "sequential_351"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_233 (Conv3D (None, 100, 6, 20, 1)     75        
_________________________________________________________________
dropout_489 (Dropout)        (None, 100, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_234 (Conv3D (None, 220, 11, 20, 1)    727       
_________________________________________________________________
reshape_94 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 802
Trainable params: 802
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_163 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_491 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_164 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_163 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_493 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_164 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13976033  || Decoder Loss:  0.10471079 Validation Decoder Loss:  0.3803986
Encoder Loss:  0.14092617  || Decoder Loss:  0.106370755 Validation Decoder Loss:  0.38194343
Encoder Loss:  0.1420464  || Decoder Loss:  0.107972406 Validation Decoder Loss:  0.38343358
Encoder Loss:  0.14313085  || Decoder Loss:  0.109529905 Validation Decoder Loss:  0.38488275
Encoder Loss:  0.14418939  || Decoder Loss:  0.111056745 Validation Decoder Loss:  0.3863029
Encoder Loss:  0.14522943  || Decoder Loss:  0.11256394 Validation Decoder Loss:  0.38770413
Encoder Loss:  0.14625783  || Decoder Loss:  0.114061154 Validation Decoder Loss:  0.38909554
Encoder Loss:  0.14728293  || Decoder Loss:  0.1155601 Validation Decoder Loss:  0.39048702
Encoder Loss:  0.14831778  || Decoder Loss:  0.1170777 Validation Decoder Loss:  0.39189202
Encoder Loss:  0.14937995  || Decoder Loss:  0.11863624 Validation Decoder Loss:  0.3933258
Encoder Loss:  0.15048704  || Decoder Loss:  0.12025751 Validation Decoder Loss:  0.39480287
Encoder Loss:  0.1516528  || Decoder Loss:  0.12195927 Validation Decoder Loss:  0.39633638
Encoder Loss:  0.15288839  || Decoder Loss:  0.12375635 Validation Decoder Loss:  0.39793932
Encoder Loss:  0.1542043  || Decoder Loss:  0.12566333 Validation Decoder Loss:  0.39962596
Encoder Loss:  0.15561248  || Decoder Loss:  0.1276964 Validation Decoder Loss:  0.40141356
Encoder Loss:  0.15712681  || Decoder Loss:  0.12987527 Validation Decoder Loss:  0.4033237
Encoder Loss:  0.15876469  || Decoder Loss:  0.13222413 Validation Decoder Loss:  0.40538466
Encoder Loss:  0.16054882  || Decoder Loss:  0.13477439 Validation Decoder Loss:  0.4076345
Encoder Loss:  0.16250858  || Decoder Loss:  0.13756746 Validation Decoder Loss:  0.4101263
Encoder Loss:  0.16468444  || Decoder Loss:  0.14065963 Validation Decoder Loss:  0.41293633
Encoder Loss:  0.1671338  || Decoder Loss:  0.14413081 Validation Decoder Loss:  0.41617957
Encoder Loss:  0.16994181  || Decoder Loss:  0.14809991 Validation Decoder Loss:  0.4200413
Encoder Loss:  0.17324463  || Decoder Loss:  0.1527568 Validation Decoder Loss:  0.42484915
Encoder Loss:  0.17728125  || Decoder Loss:  0.15843533 Validation Decoder Loss:  0.4312551
Encoder Loss:  0.18253532  || Decoder Loss:  0.16581112 Validation Decoder Loss:  0.44081658
Encoder Loss:  0.19024111  || Decoder Loss:  0.17660917 Validation Decoder Loss:  0.4587925
Encoder Loss:  0.20539783  || Decoder Loss:  0.19775948 Validation Decoder Loss:  0.52565193
Encoder Loss:  0.27677906  || Decoder Loss:  0.29311353 Validation Decoder Loss:  1.0159193
Encoder Loss:  0.33506054  || Decoder Loss:  0.37264946 Validation Decoder Loss:  0.6006815
Encoder Loss:  0.19771577  || Decoder Loss:  0.2135426 Validation Decoder Loss:  0.47280437
Encoder Loss:  0.12481995  || Decoder Loss:  0.12916051 Validation Decoder Loss:  0.3974396
Encoder Loss:  0.08837882  || Decoder Loss:  0.08702411 Validation Decoder Loss:  0.39219695
Encoder Loss:  0.08139829  || Decoder Loss:  0.0790567 Validation Decoder Loss:  0.39062172
Encoder Loss:  0.07845916  || Decoder Loss:  0.07577898 Validation Decoder Loss:  0.38649473
Encoder Loss:  0.075797126  || Decoder Loss:  0.07282787 Validation Decoder Loss:  0.38238907
Encoder Loss:  0.07388405  || Decoder Loss:  0.07075197 Validation Decoder Loss:  0.37775922
Encoder Loss:  0.072464794  || Decoder Loss:  0.069264084 Validation Decoder Loss:  0.3738814
Encoder Loss:  0.07139139  || Decoder Loss:  0.06818476 Validation Decoder Loss:  0.37080252
Encoder Loss:  0.070582315  || Decoder Loss:  0.0674233 Validation Decoder Loss:  0.36834577
Encoder Loss:  0.069985196  || Decoder Loss:  0.066914715 Validation Decoder Loss:  0.36623207
Model: siamese_net_lr_8.191910257515338e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36623207
Model: "sequential_355"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_236 (Conv3D (None, 120, 5, 20, 1)     58        
_________________________________________________________________
dropout_495 (Dropout)        (None, 120, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_237 (Conv3D (None, 220, 11, 20, 1)    708       
_________________________________________________________________
reshape_95 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 766
Trainable params: 766
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_165 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_497 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_166 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_165 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_499 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_166 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12774499  || Decoder Loss:  0.11347562 Validation Decoder Loss:  0.39652616
Encoder Loss:  0.1925014  || Decoder Loss:  0.19429664 Validation Decoder Loss:  0.3498063
Encoder Loss:  0.044336487  || Decoder Loss:  0.0415804 Validation Decoder Loss:  0.33663672
Encoder Loss:  0.037872184  || Decoder Loss:  0.036397237 Validation Decoder Loss:  0.3333583
Encoder Loss:  0.03624469  || Decoder Loss:  0.035243507 Validation Decoder Loss:  0.33362138
Encoder Loss:  0.036035143  || Decoder Loss:  0.035023063 Validation Decoder Loss:  0.33396852
Encoder Loss:  0.0359449  || Decoder Loss:  0.034928355 Validation Decoder Loss:  0.33420816
Encoder Loss:  0.035889138  || Decoder Loss:  0.034870137 Validation Decoder Loss:  0.33434236
Encoder Loss:  0.035848618  || Decoder Loss:  0.03482905 Validation Decoder Loss:  0.33441746
Encoder Loss:  0.03581666  || Decoder Loss:  0.03479553 Validation Decoder Loss:  0.33445096
Encoder Loss:  0.035788618  || Decoder Loss:  0.03476694 Validation Decoder Loss:  0.33446676
Encoder Loss:  0.03576268  || Decoder Loss:  0.034740668 Validation Decoder Loss:  0.3344724
Encoder Loss:  0.035738014  || Decoder Loss:  0.03471507 Validation Decoder Loss:  0.33448327
Encoder Loss:  0.035713527  || Decoder Loss:  0.034690306 Validation Decoder Loss:  0.33448824
Encoder Loss:  0.0356874  || Decoder Loss:  0.03466331 Validation Decoder Loss:  0.33448333
Encoder Loss:  0.035660177  || Decoder Loss:  0.034635663 Validation Decoder Loss:  0.3344714
Encoder Loss:  0.035632566  || Decoder Loss:  0.034607295 Validation Decoder Loss:  0.33446312
Encoder Loss:  0.03559997  || Decoder Loss:  0.034574345 Validation Decoder Loss:  0.33442372
Encoder Loss:  0.035564385  || Decoder Loss:  0.034537863 Validation Decoder Loss:  0.33437723
Encoder Loss:  0.0355251  || Decoder Loss:  0.034498125 Validation Decoder Loss:  0.33433628
Encoder Loss:  0.035474893  || Decoder Loss:  0.034449756 Validation Decoder Loss:  0.33427152
Encoder Loss:  0.03538409  || Decoder Loss:  0.034405604 Validation Decoder Loss:  0.33435196
Encoder Loss:  0.035350103  || Decoder Loss:  0.034402095 Validation Decoder Loss:  0.334417
Encoder Loss:  0.035348114  || Decoder Loss:  0.034401678 Validation Decoder Loss:  0.33444357
Encoder Loss:  0.035350446  || Decoder Loss:  0.03440538 Validation Decoder Loss:  0.33444113
Encoder Loss:  0.035363976  || Decoder Loss:  0.034420326 Validation Decoder Loss:  0.33442837
Encoder Loss:  0.035383504  || Decoder Loss:  0.034441907 Validation Decoder Loss:  0.33446732
Encoder Loss:  0.035411783  || Decoder Loss:  0.034472417 Validation Decoder Loss:  0.33456254
Encoder Loss:  0.035449043  || Decoder Loss:  0.034513086 Validation Decoder Loss:  0.33461696
Encoder Loss:  0.035482924  || Decoder Loss:  0.034549274 Validation Decoder Loss:  0.33468825
Encoder Loss:  0.03551729  || Decoder Loss:  0.03458651 Validation Decoder Loss:  0.3348325
Encoder Loss:  0.035552636  || Decoder Loss:  0.034623925 Validation Decoder Loss:  0.3349657
Encoder Loss:  0.035593268  || Decoder Loss:  0.034667496 Validation Decoder Loss:  0.33513206
Encoder Loss:  0.03562931  || Decoder Loss:  0.03470603 Validation Decoder Loss:  0.3352948
Encoder Loss:  0.035655547  || Decoder Loss:  0.034734245 Validation Decoder Loss:  0.33541948
Encoder Loss:  0.035682775  || Decoder Loss:  0.03476307 Validation Decoder Loss:  0.33561492
Encoder Loss:  0.03573107  || Decoder Loss:  0.03481393 Validation Decoder Loss:  0.33592984
Encoder Loss:  0.03576995  || Decoder Loss:  0.03485582 Validation Decoder Loss:  0.33606935
Encoder Loss:  0.03579134  || Decoder Loss:  0.03487894 Validation Decoder Loss:  0.33605134
Encoder Loss:  0.03580188  || Decoder Loss:  0.034890752 Validation Decoder Loss:  0.33602902
Model: siamese_net_lr_0.0005597670209222342 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.336029
Model: "sequential_359"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_239 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_501 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_240 (Conv3D (None, 220, 11, 20, 1)    757       
_________________________________________________________________
reshape_96 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 822
Trainable params: 822
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_167 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_503 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_168 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_167 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_505 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_168 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22549962  || Decoder Loss:  0.109101474 Validation Decoder Loss:  0.39106244
Encoder Loss:  0.22498785  || Decoder Loss:  0.13223766 Validation Decoder Loss:  0.43333295
Encoder Loss:  0.19323274  || Decoder Loss:  0.2513654 Validation Decoder Loss:  0.39038956
Encoder Loss:  0.06576636  || Decoder Loss:  0.043095253 Validation Decoder Loss:  0.33373815
Encoder Loss:  0.0519472  || Decoder Loss:  0.03702215 Validation Decoder Loss:  0.3344536
Encoder Loss:  0.043890182  || Decoder Loss:  0.03646082 Validation Decoder Loss:  0.33401003
Encoder Loss:  0.043611813  || Decoder Loss:  0.036180235 Validation Decoder Loss:  0.33355796
Encoder Loss:  0.043489475  || Decoder Loss:  0.03596887 Validation Decoder Loss:  0.33323488
Encoder Loss:  0.043392953  || Decoder Loss:  0.035805758 Validation Decoder Loss:  0.33301327
Encoder Loss:  0.043313604  || Decoder Loss:  0.035673574 Validation Decoder Loss:  0.33287978
Encoder Loss:  0.043244362  || Decoder Loss:  0.035559867 Validation Decoder Loss:  0.33278593
Encoder Loss:  0.04318382  || Decoder Loss:  0.035459228 Validation Decoder Loss:  0.33267763
Encoder Loss:  0.043125395  || Decoder Loss:  0.035372302 Validation Decoder Loss:  0.33256078
Encoder Loss:  0.04307761  || Decoder Loss:  0.035298333 Validation Decoder Loss:  0.3324859
Encoder Loss:  0.0430303  || Decoder Loss:  0.03523274 Validation Decoder Loss:  0.33245915
Encoder Loss:  0.04298796  || Decoder Loss:  0.03517195 Validation Decoder Loss:  0.33250135
Encoder Loss:  0.04294107  || Decoder Loss:  0.035114687 Validation Decoder Loss:  0.33258212
Encoder Loss:  0.042895265  || Decoder Loss:  0.035059616 Validation Decoder Loss:  0.33268845
Encoder Loss:  0.042846147  || Decoder Loss:  0.03500656 Validation Decoder Loss:  0.33280188
Encoder Loss:  0.042794302  || Decoder Loss:  0.034955487 Validation Decoder Loss:  0.3329336
Encoder Loss:  0.04272089  || Decoder Loss:  0.034905687 Validation Decoder Loss:  0.3330673
Encoder Loss:  0.042505063  || Decoder Loss:  0.03485507 Validation Decoder Loss:  0.33313423
Encoder Loss:  0.042143334  || Decoder Loss:  0.034835532 Validation Decoder Loss:  0.33319932
Encoder Loss:  0.042142477  || Decoder Loss:  0.034850914 Validation Decoder Loss:  0.3331977
Encoder Loss:  0.042153567  || Decoder Loss:  0.034868617 Validation Decoder Loss:  0.3332216
Encoder Loss:  0.04215605  || Decoder Loss:  0.034887616 Validation Decoder Loss:  0.33322576
Encoder Loss:  0.042165924  || Decoder Loss:  0.03490775 Validation Decoder Loss:  0.33322474
Encoder Loss:  0.042176075  || Decoder Loss:  0.034928408 Validation Decoder Loss:  0.3332139
Encoder Loss:  0.04218597  || Decoder Loss:  0.03495135 Validation Decoder Loss:  0.33320475
Encoder Loss:  0.042192385  || Decoder Loss:  0.034975406 Validation Decoder Loss:  0.33319005
Encoder Loss:  0.04220337  || Decoder Loss:  0.034998752 Validation Decoder Loss:  0.33316582
Encoder Loss:  0.04221671  || Decoder Loss:  0.03502146 Validation Decoder Loss:  0.33313492
Encoder Loss:  0.042225856  || Decoder Loss:  0.035043787 Validation Decoder Loss:  0.33311284
Encoder Loss:  0.042230915  || Decoder Loss:  0.035065122 Validation Decoder Loss:  0.33309126
Encoder Loss:  0.042237174  || Decoder Loss:  0.03508336 Validation Decoder Loss:  0.3330789
Encoder Loss:  0.042244133  || Decoder Loss:  0.035098515 Validation Decoder Loss:  0.33307257
Encoder Loss:  0.04224903  || Decoder Loss:  0.035110336 Validation Decoder Loss:  0.33307123
Encoder Loss:  0.04225195  || Decoder Loss:  0.035118874 Validation Decoder Loss:  0.3330773
Encoder Loss:  0.04224906  || Decoder Loss:  0.035122417 Validation Decoder Loss:  0.3330604
Encoder Loss:  0.042245913  || Decoder Loss:  0.035120387 Validation Decoder Loss:  0.33301002
Model: siamese_net_lr_0.0006909434705060228 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33301002
Model: "sequential_363"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_242 (Conv3D (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_507 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_243 (Conv3D (None, 220, 11, 20, 1)    322       
_________________________________________________________________
reshape_97 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 374
Trainable params: 374
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_169 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_509 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_170 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_169 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_511 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_170 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30816913  || Decoder Loss:  0.110131495 Validation Decoder Loss:  0.39015293
Encoder Loss:  0.16917317  || Decoder Loss:  0.12668799 Validation Decoder Loss:  0.37700897
Encoder Loss:  0.07971218  || Decoder Loss:  0.048896093 Validation Decoder Loss:  0.33961862
Encoder Loss:  0.056726504  || Decoder Loss:  0.038754065 Validation Decoder Loss:  0.336222
Encoder Loss:  0.047687866  || Decoder Loss:  0.035692338 Validation Decoder Loss:  0.334404
Encoder Loss:  0.047469225  || Decoder Loss:  0.034938987 Validation Decoder Loss:  0.3333706
Encoder Loss:  0.047406048  || Decoder Loss:  0.034735724 Validation Decoder Loss:  0.33297986
Encoder Loss:  0.04738355  || Decoder Loss:  0.03475056 Validation Decoder Loss:  0.33294916
Encoder Loss:  0.047397703  || Decoder Loss:  0.034938138 Validation Decoder Loss:  0.33280355
Encoder Loss:  0.04743085  || Decoder Loss:  0.035219215 Validation Decoder Loss:  0.33254862
Encoder Loss:  0.047438577  || Decoder Loss:  0.035398412 Validation Decoder Loss:  0.33218366
Encoder Loss:  0.047436472  || Decoder Loss:  0.035492852 Validation Decoder Loss:  0.33180326
Encoder Loss:  0.0474345  || Decoder Loss:  0.03551167 Validation Decoder Loss:  0.33153582
Encoder Loss:  0.047426548  || Decoder Loss:  0.035484537 Validation Decoder Loss:  0.33137187
Encoder Loss:  0.047420096  || Decoder Loss:  0.035458036 Validation Decoder Loss:  0.3313786
Encoder Loss:  0.047410537  || Decoder Loss:  0.03542303 Validation Decoder Loss:  0.33157447
Encoder Loss:  0.04740479  || Decoder Loss:  0.035395574 Validation Decoder Loss:  0.3315258
Encoder Loss:  0.047400963  || Decoder Loss:  0.03536581 Validation Decoder Loss:  0.33144632
Encoder Loss:  0.047393423  || Decoder Loss:  0.03533369 Validation Decoder Loss:  0.33134174
Encoder Loss:  0.047387615  || Decoder Loss:  0.03530261 Validation Decoder Loss:  0.33122694
Encoder Loss:  0.04738082  || Decoder Loss:  0.035277724 Validation Decoder Loss:  0.33103693
Encoder Loss:  0.047375936  || Decoder Loss:  0.03525062 Validation Decoder Loss:  0.33087328
Encoder Loss:  0.047370587  || Decoder Loss:  0.03522669 Validation Decoder Loss:  0.3307184
Encoder Loss:  0.047369912  || Decoder Loss:  0.035203803 Validation Decoder Loss:  0.33070683
Encoder Loss:  0.047362905  || Decoder Loss:  0.03517665 Validation Decoder Loss:  0.33047467
Encoder Loss:  0.047356583  || Decoder Loss:  0.035144173 Validation Decoder Loss:  0.33019453
Encoder Loss:  0.047350906  || Decoder Loss:  0.03511323 Validation Decoder Loss:  0.33006585
Encoder Loss:  0.04734698  || Decoder Loss:  0.035082962 Validation Decoder Loss:  0.32989046
Encoder Loss:  0.04734002  || Decoder Loss:  0.035048347 Validation Decoder Loss:  0.32977247
Encoder Loss:  0.04733233  || Decoder Loss:  0.035024337 Validation Decoder Loss:  0.32961598
Encoder Loss:  0.047327235  || Decoder Loss:  0.03500174 Validation Decoder Loss:  0.32940602
Encoder Loss:  0.04732314  || Decoder Loss:  0.034976497 Validation Decoder Loss:  0.32928142
Encoder Loss:  0.047318097  || Decoder Loss:  0.03494905 Validation Decoder Loss:  0.32908642
Encoder Loss:  0.047311973  || Decoder Loss:  0.03492291 Validation Decoder Loss:  0.32887146
Encoder Loss:  0.04731035  || Decoder Loss:  0.03490027 Validation Decoder Loss:  0.3289178
Encoder Loss:  0.047303952  || Decoder Loss:  0.03487094 Validation Decoder Loss:  0.32880956
Encoder Loss:  0.04729821  || Decoder Loss:  0.03484653 Validation Decoder Loss:  0.3286649
Encoder Loss:  0.047294036  || Decoder Loss:  0.03482388 Validation Decoder Loss:  0.32860342
Encoder Loss:  0.04729183  || Decoder Loss:  0.03480458 Validation Decoder Loss:  0.32858413
Encoder Loss:  0.04728639  || Decoder Loss:  0.03478214 Validation Decoder Loss:  0.32851517
Model: siamese_net_lr_0.00031258319818307874 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32851517
Model: "sequential_367"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_245 (Conv3D (None, 201, 10, 20, 1)    151       
_________________________________________________________________
dropout_513 (Dropout)        (None, 201, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_246 (Conv3D (None, 220, 11, 20, 1)    41        
_________________________________________________________________
reshape_98 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_171 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_515 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_172 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_171 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_517 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_172 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2830877  || Decoder Loss:  0.047773343 Validation Decoder Loss:  0.34189242
Encoder Loss:  0.08717804  || Decoder Loss:  0.036981486 Validation Decoder Loss:  0.33949888
Encoder Loss:  0.049200583  || Decoder Loss:  0.035018563 Validation Decoder Loss:  0.33200902
Encoder Loss:  0.047697663  || Decoder Loss:  0.033705436 Validation Decoder Loss:  0.33147162
Encoder Loss:  0.047308713  || Decoder Loss:  0.03357055 Validation Decoder Loss:  0.3314461
Encoder Loss:  0.047212556  || Decoder Loss:  0.03346035 Validation Decoder Loss:  0.33126068
Encoder Loss:  0.0471719  || Decoder Loss:  0.033361707 Validation Decoder Loss:  0.33086324
Encoder Loss:  0.047146954  || Decoder Loss:  0.033280265 Validation Decoder Loss:  0.33044595
Encoder Loss:  0.04713054  || Decoder Loss:  0.03321679 Validation Decoder Loss:  0.33011815
Encoder Loss:  0.047116928  || Decoder Loss:  0.03316923 Validation Decoder Loss:  0.32987493
Encoder Loss:  0.04710569  || Decoder Loss:  0.03313255 Validation Decoder Loss:  0.32969052
Encoder Loss:  0.047092676  || Decoder Loss:  0.033102416 Validation Decoder Loss:  0.32953686
Encoder Loss:  0.047086257  || Decoder Loss:  0.033076204 Validation Decoder Loss:  0.32937458
Encoder Loss:  0.047077917  || Decoder Loss:  0.03305255 Validation Decoder Loss:  0.32919157
Encoder Loss:  0.047064286  || Decoder Loss:  0.033030607 Validation Decoder Loss:  0.32902235
Encoder Loss:  0.047055855  || Decoder Loss:  0.03300991 Validation Decoder Loss:  0.32887447
Encoder Loss:  0.047050864  || Decoder Loss:  0.03299024 Validation Decoder Loss:  0.32874304
Encoder Loss:  0.04704814  || Decoder Loss:  0.032971524 Validation Decoder Loss:  0.32862055
Encoder Loss:  0.04704542  || Decoder Loss:  0.032953806 Validation Decoder Loss:  0.32850468
Encoder Loss:  0.04704022  || Decoder Loss:  0.032937195 Validation Decoder Loss:  0.32839584
Encoder Loss:  0.047042593  || Decoder Loss:  0.03292177 Validation Decoder Loss:  0.3282944
Encoder Loss:  0.047035612  || Decoder Loss:  0.03290747 Validation Decoder Loss:  0.32820076
Encoder Loss:  0.047031943  || Decoder Loss:  0.03289419 Validation Decoder Loss:  0.32811332
Encoder Loss:  0.04703351  || Decoder Loss:  0.032881886 Validation Decoder Loss:  0.3280326
Encoder Loss:  0.047029  || Decoder Loss:  0.032870308 Validation Decoder Loss:  0.32795805
Encoder Loss:  0.04702438  || Decoder Loss:  0.03285943 Validation Decoder Loss:  0.32788926
Encoder Loss:  0.047024824  || Decoder Loss:  0.032849196 Validation Decoder Loss:  0.3278268
Encoder Loss:  0.0470236  || Decoder Loss:  0.03283955 Validation Decoder Loss:  0.3277681
Encoder Loss:  0.04702195  || Decoder Loss:  0.032830372 Validation Decoder Loss:  0.32771742
Encoder Loss:  0.04701711  || Decoder Loss:  0.03282171 Validation Decoder Loss:  0.32766992
Encoder Loss:  0.04701467  || Decoder Loss:  0.032813624 Validation Decoder Loss:  0.3276265
Encoder Loss:  0.04702114  || Decoder Loss:  0.032805875 Validation Decoder Loss:  0.3275913
Encoder Loss:  0.047013197  || Decoder Loss:  0.03279844 Validation Decoder Loss:  0.32755765
Encoder Loss:  0.04701509  || Decoder Loss:  0.03279156 Validation Decoder Loss:  0.32752988
Encoder Loss:  0.047013305  || Decoder Loss:  0.03278512 Validation Decoder Loss:  0.32749864
Encoder Loss:  0.04701248  || Decoder Loss:  0.032779776 Validation Decoder Loss:  0.32749972
Encoder Loss:  0.047010064  || Decoder Loss:  0.03277379 Validation Decoder Loss:  0.3274753
Encoder Loss:  0.046999976  || Decoder Loss:  0.03276943 Validation Decoder Loss:  0.32747895
Encoder Loss:  0.047011863  || Decoder Loss:  0.032763407 Validation Decoder Loss:  0.3274452
Encoder Loss:  0.047001638  || Decoder Loss:  0.03275891 Validation Decoder Loss:  0.32743576
Model: siamese_net_lr_0.0009120281200454582 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32743576
Model: "sequential_371"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_248 (Conv3D (None, 123, 10, 20, 1)    361       
_________________________________________________________________
dropout_519 (Dropout)        (None, 123, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_249 (Conv3D (None, 220, 11, 20, 1)    197       
_________________________________________________________________
reshape_99 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 558
Trainable params: 558
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_173 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_521 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_174 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_173 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_523 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_174 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25659093  || Decoder Loss:  0.11558404 Validation Decoder Loss:  0.39138258
Encoder Loss:  0.25420284  || Decoder Loss:  0.12582491 Validation Decoder Loss:  0.40102077
Encoder Loss:  0.25052497  || Decoder Loss:  0.13830902 Validation Decoder Loss:  0.41378343
Encoder Loss:  0.24392134  || Decoder Loss:  0.15647003 Validation Decoder Loss:  0.43830943
Encoder Loss:  0.19397062  || Decoder Loss:  0.122325525 Validation Decoder Loss:  0.35755837
Encoder Loss:  0.084793404  || Decoder Loss:  0.07481528 Validation Decoder Loss:  0.36208785
Encoder Loss:  0.073877856  || Decoder Loss:  0.06799279 Validation Decoder Loss:  0.3544457
Encoder Loss:  0.05992854  || Decoder Loss:  0.061823778 Validation Decoder Loss:  0.35189262
Encoder Loss:  0.054145955  || Decoder Loss:  0.05686902 Validation Decoder Loss:  0.3480391
Encoder Loss:  0.04954  || Decoder Loss:  0.047617994 Validation Decoder Loss:  0.3348141
Encoder Loss:  0.04377467  || Decoder Loss:  0.035539676 Validation Decoder Loss:  0.3288591
Encoder Loss:  0.04331045  || Decoder Loss:  0.0346165 Validation Decoder Loss:  0.32824007
Encoder Loss:  0.0430964  || Decoder Loss:  0.034169894 Validation Decoder Loss:  0.3278855
Encoder Loss:  0.042877287  || Decoder Loss:  0.033821613 Validation Decoder Loss:  0.32767382
Encoder Loss:  0.04275738  || Decoder Loss:  0.03355035 Validation Decoder Loss:  0.327622
Encoder Loss:  0.042642802  || Decoder Loss:  0.0333308 Validation Decoder Loss:  0.32764772
Encoder Loss:  0.04260322  || Decoder Loss:  0.03315793 Validation Decoder Loss:  0.32782787
Encoder Loss:  0.04259809  || Decoder Loss:  0.033217844 Validation Decoder Loss:  0.32784417
Encoder Loss:  0.042512164  || Decoder Loss:  0.032974552 Validation Decoder Loss:  0.32795063
Encoder Loss:  0.042479347  || Decoder Loss:  0.032940645 Validation Decoder Loss:  0.32807827
Encoder Loss:  0.04244965  || Decoder Loss:  0.032891642 Validation Decoder Loss:  0.3283365
Encoder Loss:  0.042442985  || Decoder Loss:  0.032867137 Validation Decoder Loss:  0.32846487
Encoder Loss:  0.042412966  || Decoder Loss:  0.03281276 Validation Decoder Loss:  0.328628
Encoder Loss:  0.04240526  || Decoder Loss:  0.03279687 Validation Decoder Loss:  0.32866466
Encoder Loss:  0.042417802  || Decoder Loss:  0.03277197 Validation Decoder Loss:  0.3288332
Encoder Loss:  0.042376094  || Decoder Loss:  0.03273321 Validation Decoder Loss:  0.329023
Encoder Loss:  0.04236789  || Decoder Loss:  0.032715008 Validation Decoder Loss:  0.32909852
Encoder Loss:  0.042358875  || Decoder Loss:  0.032692254 Validation Decoder Loss:  0.32919797
Encoder Loss:  0.04237385  || Decoder Loss:  0.03269208 Validation Decoder Loss:  0.32930726
Encoder Loss:  0.042345673  || Decoder Loss:  0.032665282 Validation Decoder Loss:  0.32950318
Encoder Loss:  0.0423618  || Decoder Loss:  0.03267343 Validation Decoder Loss:  0.32959265
Encoder Loss:  0.042338207  || Decoder Loss:  0.0326522 Validation Decoder Loss:  0.32968116
Encoder Loss:  0.04235162  || Decoder Loss:  0.03265731 Validation Decoder Loss:  0.32975316
Encoder Loss:  0.0423416  || Decoder Loss:  0.032652844 Validation Decoder Loss:  0.32984978
Encoder Loss:  0.042325597  || Decoder Loss:  0.032642744 Validation Decoder Loss:  0.32990706
Encoder Loss:  0.042318292  || Decoder Loss:  0.032632094 Validation Decoder Loss:  0.32996196
Encoder Loss:  0.04233357  || Decoder Loss:  0.03264381 Validation Decoder Loss:  0.3299538
Encoder Loss:  0.042317305  || Decoder Loss:  0.032632586 Validation Decoder Loss:  0.33004954
Encoder Loss:  0.042334404  || Decoder Loss:  0.032647643 Validation Decoder Loss:  0.3300842
Encoder Loss:  0.042325716  || Decoder Loss:  0.032638315 Validation Decoder Loss:  0.33010748
Model: siamese_net_lr_0.00021342105174943735 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33010745
Model: "sequential_375"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_251 (Conv3D (None, 122, 10, 20, 1)    119       
_________________________________________________________________
dropout_525 (Dropout)        (None, 122, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_252 (Conv3D (None, 220, 11, 20, 1)    199       
_________________________________________________________________
reshape_100 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_175 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_527 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_176 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_175 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_529 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_176 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29995632  || Decoder Loss:  0.11112759 Validation Decoder Loss:  0.39054313
Encoder Loss:  0.2849667  || Decoder Loss:  0.14915638 Validation Decoder Loss:  1.0683345
Encoder Loss:  0.11892394  || Decoder Loss:  0.17272109 Validation Decoder Loss:  0.3478671
Encoder Loss:  0.07703183  || Decoder Loss:  0.045018896 Validation Decoder Loss:  0.3349761
Encoder Loss:  0.07077367  || Decoder Loss:  0.03666995 Validation Decoder Loss:  0.33215636
Encoder Loss:  0.06197474  || Decoder Loss:  0.035323597 Validation Decoder Loss:  0.3321899
Encoder Loss:  0.048136137  || Decoder Loss:  0.035126507 Validation Decoder Loss:  0.33239514
Encoder Loss:  0.04724867  || Decoder Loss:  0.035038486 Validation Decoder Loss:  0.33241946
Encoder Loss:  0.047229692  || Decoder Loss:  0.035002653 Validation Decoder Loss:  0.33251372
Encoder Loss:  0.047214814  || Decoder Loss:  0.03498333 Validation Decoder Loss:  0.33267313
Encoder Loss:  0.047195617  || Decoder Loss:  0.034968816 Validation Decoder Loss:  0.33283508
Encoder Loss:  0.04717736  || Decoder Loss:  0.034956597 Validation Decoder Loss:  0.33296478
Encoder Loss:  0.04716715  || Decoder Loss:  0.03494551 Validation Decoder Loss:  0.33307114
Encoder Loss:  0.04714623  || Decoder Loss:  0.034934867 Validation Decoder Loss:  0.3331523
Encoder Loss:  0.047121033  || Decoder Loss:  0.034923755 Validation Decoder Loss:  0.33321056
Encoder Loss:  0.04709494  || Decoder Loss:  0.034911208 Validation Decoder Loss:  0.33325702
Encoder Loss:  0.04705827  || Decoder Loss:  0.034896582 Validation Decoder Loss:  0.33329123
Encoder Loss:  0.04701492  || Decoder Loss:  0.034878854 Validation Decoder Loss:  0.3333164
Encoder Loss:  0.04693941  || Decoder Loss:  0.03485692 Validation Decoder Loss:  0.33333313
Encoder Loss:  0.04676523  || Decoder Loss:  0.03482644 Validation Decoder Loss:  0.33333713
Encoder Loss:  0.045759387  || Decoder Loss:  0.034728173 Validation Decoder Loss:  0.3332945
Encoder Loss:  0.045431305  || Decoder Loss:  0.034646258 Validation Decoder Loss:  0.33330786
Encoder Loss:  0.045421716  || Decoder Loss:  0.034633268 Validation Decoder Loss:  0.33335394
Encoder Loss:  0.04541484  || Decoder Loss:  0.03463252 Validation Decoder Loss:  0.3333985
Encoder Loss:  0.045406133  || Decoder Loss:  0.034627568 Validation Decoder Loss:  0.3334446
Encoder Loss:  0.04539876  || Decoder Loss:  0.034628823 Validation Decoder Loss:  0.3335032
Encoder Loss:  0.04539102  || Decoder Loss:  0.034632552 Validation Decoder Loss:  0.33356208
Encoder Loss:  0.045382448  || Decoder Loss:  0.034639336 Validation Decoder Loss:  0.33362997
Encoder Loss:  0.045375448  || Decoder Loss:  0.034651347 Validation Decoder Loss:  0.33370775
Encoder Loss:  0.045366205  || Decoder Loss:  0.034663163 Validation Decoder Loss:  0.33379608
Encoder Loss:  0.045361415  || Decoder Loss:  0.034677938 Validation Decoder Loss:  0.33388564
Encoder Loss:  0.04535574  || Decoder Loss:  0.034685284 Validation Decoder Loss:  0.33396906
Encoder Loss:  0.045349177  || Decoder Loss:  0.034683358 Validation Decoder Loss:  0.33405328
Encoder Loss:  0.04534184  || Decoder Loss:  0.03467291 Validation Decoder Loss:  0.33412498
Encoder Loss:  0.045334987  || Decoder Loss:  0.034656662 Validation Decoder Loss:  0.3341757
Encoder Loss:  0.045327436  || Decoder Loss:  0.034638748 Validation Decoder Loss:  0.33419657
Encoder Loss:  0.045321826  || Decoder Loss:  0.034622308 Validation Decoder Loss:  0.3341992
Encoder Loss:  0.0453176  || Decoder Loss:  0.034609925 Validation Decoder Loss:  0.33418298
Encoder Loss:  0.0453131  || Decoder Loss:  0.034597997 Validation Decoder Loss:  0.33415782
Encoder Loss:  0.04530832  || Decoder Loss:  0.034583185 Validation Decoder Loss:  0.3341558
Model: siamese_net_lr_0.0003642316387146009 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3341558
Model: "sequential_379"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_254 (Conv3D (None, 140, 9, 20, 1)     71        
_________________________________________________________________
dropout_531 (Dropout)        (None, 140, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_255 (Conv3D (None, 220, 11, 20, 1)    244       
_________________________________________________________________
reshape_101 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 315
Trainable params: 315
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_177 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_533 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_178 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_177 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_535 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_178 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29226357  || Decoder Loss:  0.09674655 Validation Decoder Loss:  0.37711868
Encoder Loss:  0.28722978  || Decoder Loss:  0.103453666 Validation Decoder Loss:  0.38446468
Encoder Loss:  0.19065484  || Decoder Loss:  0.2308415 Validation Decoder Loss:  0.4402905
Encoder Loss:  0.09430449  || Decoder Loss:  0.08545241 Validation Decoder Loss:  0.35773683
Encoder Loss:  0.08363214  || Decoder Loss:  0.05513367 Validation Decoder Loss:  0.34334025
Encoder Loss:  0.07867232  || Decoder Loss:  0.04371343 Validation Decoder Loss:  0.340384
Encoder Loss:  0.074960686  || Decoder Loss:  0.039377898 Validation Decoder Loss:  0.33659074
Encoder Loss:  0.05697031  || Decoder Loss:  0.036504313 Validation Decoder Loss:  0.33230066
Encoder Loss:  0.0454741  || Decoder Loss:  0.03522261 Validation Decoder Loss:  0.3314385
Encoder Loss:  0.045391697  || Decoder Loss:  0.035023723 Validation Decoder Loss:  0.33129662
Encoder Loss:  0.045341168  || Decoder Loss:  0.0349332 Validation Decoder Loss:  0.33118412
Encoder Loss:  0.045299422  || Decoder Loss:  0.034874614 Validation Decoder Loss:  0.33108112
Encoder Loss:  0.045264766  || Decoder Loss:  0.034845587 Validation Decoder Loss:  0.33102953
Encoder Loss:  0.045243915  || Decoder Loss:  0.03484606 Validation Decoder Loss:  0.3309999
Encoder Loss:  0.04522972  || Decoder Loss:  0.034864847 Validation Decoder Loss:  0.330998
Encoder Loss:  0.045221373  || Decoder Loss:  0.034893822 Validation Decoder Loss:  0.33098894
Encoder Loss:  0.045219358  || Decoder Loss:  0.034927387 Validation Decoder Loss:  0.3309778
Encoder Loss:  0.045220118  || Decoder Loss:  0.034949217 Validation Decoder Loss:  0.33096853
Encoder Loss:  0.045218334  || Decoder Loss:  0.03495126 Validation Decoder Loss:  0.33096156
Encoder Loss:  0.045217708  || Decoder Loss:  0.034950133 Validation Decoder Loss:  0.33095026
Encoder Loss:  0.04521369  || Decoder Loss:  0.03494247 Validation Decoder Loss:  0.33093357
Encoder Loss:  0.045210645  || Decoder Loss:  0.034935072 Validation Decoder Loss:  0.33091617
Encoder Loss:  0.045207925  || Decoder Loss:  0.03492761 Validation Decoder Loss:  0.3308705
Encoder Loss:  0.04520355  || Decoder Loss:  0.03491608 Validation Decoder Loss:  0.33084553
Encoder Loss:  0.04519793  || Decoder Loss:  0.03490141 Validation Decoder Loss:  0.33081385
Encoder Loss:  0.045192584  || Decoder Loss:  0.03488274 Validation Decoder Loss:  0.33079615
Encoder Loss:  0.045184445  || Decoder Loss:  0.034860052 Validation Decoder Loss:  0.33073726
Encoder Loss:  0.045175932  || Decoder Loss:  0.034833495 Validation Decoder Loss:  0.3306752
Encoder Loss:  0.045163836  || Decoder Loss:  0.034798384 Validation Decoder Loss:  0.3305666
Encoder Loss:  0.045150217  || Decoder Loss:  0.034753542 Validation Decoder Loss:  0.33049437
Encoder Loss:  0.045128997  || Decoder Loss:  0.034691792 Validation Decoder Loss:  0.33030814
Encoder Loss:  0.04510225  || Decoder Loss:  0.034608502 Validation Decoder Loss:  0.33003312
Encoder Loss:  0.04506932  || Decoder Loss:  0.034510236 Validation Decoder Loss:  0.329787
Encoder Loss:  0.04504013  || Decoder Loss:  0.034414772 Validation Decoder Loss:  0.32967567
Encoder Loss:  0.04501412  || Decoder Loss:  0.034342036 Validation Decoder Loss:  0.3296131
Encoder Loss:  0.044996295  || Decoder Loss:  0.03429596 Validation Decoder Loss:  0.32972264
Encoder Loss:  0.044985306  || Decoder Loss:  0.03426702 Validation Decoder Loss:  0.3298857
Encoder Loss:  0.044977993  || Decoder Loss:  0.034247883 Validation Decoder Loss:  0.33005798
Encoder Loss:  0.044972766  || Decoder Loss:  0.0342356 Validation Decoder Loss:  0.330226
Encoder Loss:  0.04496709  || Decoder Loss:  0.034220528 Validation Decoder Loss:  0.330364
Model: siamese_net_lr_0.00016628858911036949 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.330364
Model: "sequential_383"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_257 (Conv3D (None, 125, 10, 20, 1)    125       
_________________________________________________________________
dropout_537 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_258 (Conv3D (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_102 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_179 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_539 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_180 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_179 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_541 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_180 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20880602  || Decoder Loss:  0.14547268 Validation Decoder Loss:  0.33234364
Encoder Loss:  0.051198278  || Decoder Loss:  0.038953863 Validation Decoder Loss:  0.3292227
Encoder Loss:  0.04851409  || Decoder Loss:  0.03679037 Validation Decoder Loss:  0.32715738
Encoder Loss:  0.04822855  || Decoder Loss:  0.034407184 Validation Decoder Loss:  0.32744414
Encoder Loss:  0.048173808  || Decoder Loss:  0.034079734 Validation Decoder Loss:  0.3274678
Encoder Loss:  0.048158776  || Decoder Loss:  0.033986572 Validation Decoder Loss:  0.32728395
Encoder Loss:  0.04815366  || Decoder Loss:  0.033943065 Validation Decoder Loss:  0.32701826
Encoder Loss:  0.04813549  || Decoder Loss:  0.03390728 Validation Decoder Loss:  0.32683834
Encoder Loss:  0.048136786  || Decoder Loss:  0.033861227 Validation Decoder Loss:  0.3266971
Encoder Loss:  0.048121117  || Decoder Loss:  0.033825938 Validation Decoder Loss:  0.32643715
Encoder Loss:  0.04811628  || Decoder Loss:  0.0337772 Validation Decoder Loss:  0.326142
Encoder Loss:  0.048112124  || Decoder Loss:  0.033748936 Validation Decoder Loss:  0.32584164
Encoder Loss:  0.048105206  || Decoder Loss:  0.033724427 Validation Decoder Loss:  0.32568073
Encoder Loss:  0.04809732  || Decoder Loss:  0.033742644 Validation Decoder Loss:  0.32546198
Encoder Loss:  0.048095614  || Decoder Loss:  0.033741545 Validation Decoder Loss:  0.3252896
Encoder Loss:  0.048081115  || Decoder Loss:  0.033674326 Validation Decoder Loss:  0.32515836
Encoder Loss:  0.04806992  || Decoder Loss:  0.03361378 Validation Decoder Loss:  0.3251723
Encoder Loss:  0.048064213  || Decoder Loss:  0.03357199 Validation Decoder Loss:  0.3252033
Encoder Loss:  0.048055083  || Decoder Loss:  0.033548366 Validation Decoder Loss:  0.32527184
Encoder Loss:  0.04805303  || Decoder Loss:  0.03353096 Validation Decoder Loss:  0.32530892
Encoder Loss:  0.048047308  || Decoder Loss:  0.033521373 Validation Decoder Loss:  0.32533687
Encoder Loss:  0.048110217  || Decoder Loss:  0.033507667 Validation Decoder Loss:  0.3254711
Encoder Loss:  0.04805024  || Decoder Loss:  0.033501033 Validation Decoder Loss:  0.32557476
Encoder Loss:  0.048046816  || Decoder Loss:  0.033488356 Validation Decoder Loss:  0.32564884
Encoder Loss:  0.048053354  || Decoder Loss:  0.03348752 Validation Decoder Loss:  0.32563818
Encoder Loss:  0.048044305  || Decoder Loss:  0.033479705 Validation Decoder Loss:  0.3256598
Encoder Loss:  0.048049908  || Decoder Loss:  0.033480152 Validation Decoder Loss:  0.32564777
Encoder Loss:  0.04805272  || Decoder Loss:  0.033479773 Validation Decoder Loss:  0.32563618
Encoder Loss:  0.048043743  || Decoder Loss:  0.03347694 Validation Decoder Loss:  0.3257394
Encoder Loss:  0.048046045  || Decoder Loss:  0.03347799 Validation Decoder Loss:  0.3257065
Encoder Loss:  0.048051253  || Decoder Loss:  0.033487357 Validation Decoder Loss:  0.3253081
Encoder Loss:  0.048041224  || Decoder Loss:  0.03348442 Validation Decoder Loss:  0.32542953
Encoder Loss:  0.048046976  || Decoder Loss:  0.033482254 Validation Decoder Loss:  0.32553086
Encoder Loss:  0.048041426  || Decoder Loss:  0.033482872 Validation Decoder Loss:  0.32553637
Encoder Loss:  0.04804155  || Decoder Loss:  0.033482216 Validation Decoder Loss:  0.3255315
Encoder Loss:  0.04804346  || Decoder Loss:  0.03348011 Validation Decoder Loss:  0.32557318
Encoder Loss:  0.04804206  || Decoder Loss:  0.03348319 Validation Decoder Loss:  0.32559922
Encoder Loss:  0.048040934  || Decoder Loss:  0.033484116 Validation Decoder Loss:  0.32562286
Encoder Loss:  0.048051693  || Decoder Loss:  0.03347758 Validation Decoder Loss:  0.32588384
Encoder Loss:  0.048041772  || Decoder Loss:  0.033476662 Validation Decoder Loss:  0.32595503
Model: siamese_net_lr_0.0008388537825493743 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32595497
Model: "sequential_387"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_260 (Conv3D (None, 140, 9, 20, 1)     386       
_________________________________________________________________
dropout_543 (Dropout)        (None, 140, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_261 (Conv3D (None, 220, 11, 20, 1)    244       
_________________________________________________________________
reshape_103 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 630
Trainable params: 630
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_181 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_545 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_182 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_181 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_547 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_182 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24144433  || Decoder Loss:  0.11478498 Validation Decoder Loss:  0.39297843
Encoder Loss:  0.23809421  || Decoder Loss:  0.13631554 Validation Decoder Loss:  0.4207427
Encoder Loss:  0.18658753  || Decoder Loss:  0.15029818 Validation Decoder Loss:  0.45960307
Encoder Loss:  0.084029436  || Decoder Loss:  0.08918667 Validation Decoder Loss:  0.37600648
Encoder Loss:  0.05959233  || Decoder Loss:  0.043248482 Validation Decoder Loss:  0.3329578
Encoder Loss:  0.047832467  || Decoder Loss:  0.034933656 Validation Decoder Loss:  0.33141422
Encoder Loss:  0.042474404  || Decoder Loss:  0.03415578 Validation Decoder Loss:  0.33224764
Encoder Loss:  0.042170145  || Decoder Loss:  0.03370121 Validation Decoder Loss:  0.33250695
Encoder Loss:  0.042050295  || Decoder Loss:  0.033482324 Validation Decoder Loss:  0.33274856
Encoder Loss:  0.041965403  || Decoder Loss:  0.033351887 Validation Decoder Loss:  0.3328513
Encoder Loss:  0.041919407  || Decoder Loss:  0.033278953 Validation Decoder Loss:  0.332758
Encoder Loss:  0.04190585  || Decoder Loss:  0.03326219 Validation Decoder Loss:  0.33258235
Encoder Loss:  0.041913684  || Decoder Loss:  0.03327954 Validation Decoder Loss:  0.33253878
Encoder Loss:  0.041927062  || Decoder Loss:  0.03330633 Validation Decoder Loss:  0.3324901
Encoder Loss:  0.0419394  || Decoder Loss:  0.03333389 Validation Decoder Loss:  0.33245182
Encoder Loss:  0.04195506  || Decoder Loss:  0.033366907 Validation Decoder Loss:  0.3324019
Encoder Loss:  0.04197421  || Decoder Loss:  0.033406276 Validation Decoder Loss:  0.33234328
Encoder Loss:  0.04199679  || Decoder Loss:  0.03345371 Validation Decoder Loss:  0.33229253
Encoder Loss:  0.042020336  || Decoder Loss:  0.03350362 Validation Decoder Loss:  0.33220583
Encoder Loss:  0.042046543  || Decoder Loss:  0.033557948 Validation Decoder Loss:  0.3321581
Encoder Loss:  0.042071015  || Decoder Loss:  0.033611465 Validation Decoder Loss:  0.33210146
Encoder Loss:  0.04209544  || Decoder Loss:  0.033661414 Validation Decoder Loss:  0.33199218
Encoder Loss:  0.042124476  || Decoder Loss:  0.033722874 Validation Decoder Loss:  0.33193314
Encoder Loss:  0.0421546  || Decoder Loss:  0.03378483 Validation Decoder Loss:  0.33184022
Encoder Loss:  0.042178735  || Decoder Loss:  0.033837944 Validation Decoder Loss:  0.33179745
Encoder Loss:  0.042205647  || Decoder Loss:  0.033893682 Validation Decoder Loss:  0.3316952
Encoder Loss:  0.04223343  || Decoder Loss:  0.033952683 Validation Decoder Loss:  0.3316354
Encoder Loss:  0.042264085  || Decoder Loss:  0.034015022 Validation Decoder Loss:  0.3315416
Encoder Loss:  0.042294983  || Decoder Loss:  0.034080934 Validation Decoder Loss:  0.33152616
Encoder Loss:  0.042318  || Decoder Loss:  0.034131397 Validation Decoder Loss:  0.33151847
Encoder Loss:  0.042344376  || Decoder Loss:  0.03418929 Validation Decoder Loss:  0.3314917
Encoder Loss:  0.042367138  || Decoder Loss:  0.034236375 Validation Decoder Loss:  0.33148405
Encoder Loss:  0.042387992  || Decoder Loss:  0.03428033 Validation Decoder Loss:  0.33143395
Encoder Loss:  0.042404555  || Decoder Loss:  0.034315623 Validation Decoder Loss:  0.33138505
Encoder Loss:  0.042430162  || Decoder Loss:  0.03436949 Validation Decoder Loss:  0.33137333
Encoder Loss:  0.042447515  || Decoder Loss:  0.034405302 Validation Decoder Loss:  0.33133242
Encoder Loss:  0.04246156  || Decoder Loss:  0.03443566 Validation Decoder Loss:  0.33129856
Encoder Loss:  0.042474862  || Decoder Loss:  0.03446577 Validation Decoder Loss:  0.331236
Encoder Loss:  0.042486377  || Decoder Loss:  0.03448875 Validation Decoder Loss:  0.3311348
Encoder Loss:  0.04249673  || Decoder Loss:  0.034511186 Validation Decoder Loss:  0.3310867
Model: siamese_net_lr_0.0003692394137782314 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3310867
Model: "sequential_391"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_263 (Conv3D (None, 123, 10, 20, 1)    121       
_________________________________________________________________
dropout_549 (Dropout)        (None, 123, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_264 (Conv3D (None, 220, 11, 20, 1)    197       
_________________________________________________________________
reshape_104 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_183 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_551 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_184 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_183 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_553 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_184 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.3783513
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.38920125  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.38920125  || Decoder Loss:  0.1043179 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.104317896 Validation Decoder Loss:  0.37835127
Encoder Loss:  0.3892012  || Decoder Loss:  0.10431791 Validation Decoder Loss:  0.37835127
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37835127
Model: "sequential_395"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_266 (Conv3D (None, 126, 10, 20, 1)    127       
_________________________________________________________________
dropout_555 (Dropout)        (None, 126, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_267 (Conv3D (None, 220, 11, 20, 1)    191       
_________________________________________________________________
reshape_105 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_185 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_557 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_186 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_185 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_559 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_186 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28366324  || Decoder Loss:  0.11018774 Validation Decoder Loss:  0.389126
Encoder Loss:  0.27691582  || Decoder Loss:  0.1319887 Validation Decoder Loss:  0.4320808
Encoder Loss:  0.15145028  || Decoder Loss:  0.18688789 Validation Decoder Loss:  0.34749097
Encoder Loss:  0.077050775  || Decoder Loss:  0.052039523 Validation Decoder Loss:  0.33990738
Encoder Loss:  0.07090067  || Decoder Loss:  0.041236073 Validation Decoder Loss:  0.3343333
Encoder Loss:  0.06520657  || Decoder Loss:  0.03542752 Validation Decoder Loss:  0.33264875
Encoder Loss:  0.05729168  || Decoder Loss:  0.034750007 Validation Decoder Loss:  0.3324558
Encoder Loss:  0.04678137  || Decoder Loss:  0.03455928 Validation Decoder Loss:  0.33228958
Encoder Loss:  0.04596911  || Decoder Loss:  0.034513723 Validation Decoder Loss:  0.33219093
Encoder Loss:  0.045960527  || Decoder Loss:  0.034499828 Validation Decoder Loss:  0.33213803
Encoder Loss:  0.0459436  || Decoder Loss:  0.03448974 Validation Decoder Loss:  0.3320967
Encoder Loss:  0.04593493  || Decoder Loss:  0.034480695 Validation Decoder Loss:  0.33205086
Encoder Loss:  0.04591327  || Decoder Loss:  0.034470893 Validation Decoder Loss:  0.33197045
Encoder Loss:  0.045862008  || Decoder Loss:  0.034434672 Validation Decoder Loss:  0.33273715
Encoder Loss:  0.045233354  || Decoder Loss:  0.034410156 Validation Decoder Loss:  0.33320814
Encoder Loss:  0.044432525  || Decoder Loss:  0.034567524 Validation Decoder Loss:  0.3333249
Encoder Loss:  0.044370316  || Decoder Loss:  0.034577146 Validation Decoder Loss:  0.33342183
Encoder Loss:  0.044364747  || Decoder Loss:  0.034563407 Validation Decoder Loss:  0.33348373
Encoder Loss:  0.044361006  || Decoder Loss:  0.034554616 Validation Decoder Loss:  0.33352065
Encoder Loss:  0.044359818  || Decoder Loss:  0.034551874 Validation Decoder Loss:  0.33354318
Encoder Loss:  0.044359483  || Decoder Loss:  0.034552477 Validation Decoder Loss:  0.33353892
Encoder Loss:  0.04436111  || Decoder Loss:  0.034557994 Validation Decoder Loss:  0.3335277
Encoder Loss:  0.04436384  || Decoder Loss:  0.03456468 Validation Decoder Loss:  0.33348736
Encoder Loss:  0.04436389  || Decoder Loss:  0.034567226 Validation Decoder Loss:  0.33348638
Encoder Loss:  0.044363305  || Decoder Loss:  0.034566343 Validation Decoder Loss:  0.33347955
Encoder Loss:  0.044363614  || Decoder Loss:  0.03456627 Validation Decoder Loss:  0.3334383
Encoder Loss:  0.044362873  || Decoder Loss:  0.034567546 Validation Decoder Loss:  0.33344662
Encoder Loss:  0.044362344  || Decoder Loss:  0.034565266 Validation Decoder Loss:  0.3333987
Encoder Loss:  0.044361435  || Decoder Loss:  0.034561895 Validation Decoder Loss:  0.33343157
Encoder Loss:  0.04435882  || Decoder Loss:  0.034556556 Validation Decoder Loss:  0.3333775
Encoder Loss:  0.04435952  || Decoder Loss:  0.034558907 Validation Decoder Loss:  0.3333885
Encoder Loss:  0.0443589  || Decoder Loss:  0.03455821 Validation Decoder Loss:  0.3333273
Encoder Loss:  0.044361435  || Decoder Loss:  0.03456577 Validation Decoder Loss:  0.3332487
Encoder Loss:  0.044368472  || Decoder Loss:  0.034586724 Validation Decoder Loss:  0.3331424
Encoder Loss:  0.044380378  || Decoder Loss:  0.034621045 Validation Decoder Loss:  0.33301505
Encoder Loss:  0.044395544  || Decoder Loss:  0.03466343 Validation Decoder Loss:  0.33272287
Encoder Loss:  0.044420823  || Decoder Loss:  0.034735937 Validation Decoder Loss:  0.33250484
Encoder Loss:  0.044443134  || Decoder Loss:  0.034797087 Validation Decoder Loss:  0.33235824
Encoder Loss:  0.044460285  || Decoder Loss:  0.034845907 Validation Decoder Loss:  0.33192778
Encoder Loss:  0.044473737  || Decoder Loss:  0.03488351 Validation Decoder Loss:  0.33288014
Model: siamese_net_lr_0.00018577398259674212 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33288014
Model: "sequential_399"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_269 (Conv3D (None, 70, 6, 20, 1)      15        
_________________________________________________________________
dropout_561 (Dropout)        (None, 70, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_270 (Conv3D (None, 220, 11, 20, 1)    79        
_________________________________________________________________
reshape_106 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 94
Trainable params: 94
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_187 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_563 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_188 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_187 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_565 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_188 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3466504  || Decoder Loss:  0.04351854 Validation Decoder Loss:  0.3537469
Encoder Loss:  0.3206774  || Decoder Loss:  0.042458836 Validation Decoder Loss:  0.35129023
Encoder Loss:  0.27824873  || Decoder Loss:  0.040241655 Validation Decoder Loss:  0.3440091
Encoder Loss:  0.23298194  || Decoder Loss:  0.036972824 Validation Decoder Loss:  0.33700937
Encoder Loss:  0.18547791  || Decoder Loss:  0.03635301 Validation Decoder Loss:  0.33676633
Encoder Loss:  0.09176922  || Decoder Loss:  0.03624061 Validation Decoder Loss:  0.33641562
Encoder Loss:  0.048321635  || Decoder Loss:  0.036050376 Validation Decoder Loss:  0.3358456
Encoder Loss:  0.047911186  || Decoder Loss:  0.035925917 Validation Decoder Loss:  0.33546734
Encoder Loss:  0.04778406  || Decoder Loss:  0.03580833 Validation Decoder Loss:  0.33516407
Encoder Loss:  0.04780594  || Decoder Loss:  0.035682738 Validation Decoder Loss:  0.33485496
Encoder Loss:  0.047720995  || Decoder Loss:  0.035540704 Validation Decoder Loss:  0.3344999
Encoder Loss:  0.047684055  || Decoder Loss:  0.03537061 Validation Decoder Loss:  0.33405516
Encoder Loss:  0.047655955  || Decoder Loss:  0.03515273 Validation Decoder Loss:  0.33344775
Encoder Loss:  0.04764834  || Decoder Loss:  0.034851365 Validation Decoder Loss:  0.33255416
Encoder Loss:  0.047520574  || Decoder Loss:  0.034416184 Validation Decoder Loss:  0.33126158
Encoder Loss:  0.04745564  || Decoder Loss:  0.03401474 Validation Decoder Loss:  0.33049172
Encoder Loss:  0.047427405  || Decoder Loss:  0.033940166 Validation Decoder Loss:  0.33028924
Encoder Loss:  0.047432497  || Decoder Loss:  0.033920586 Validation Decoder Loss:  0.33013877
Encoder Loss:  0.047403507  || Decoder Loss:  0.033902816 Validation Decoder Loss:  0.33000806
Encoder Loss:  0.047402877  || Decoder Loss:  0.033886813 Validation Decoder Loss:  0.32989356
Encoder Loss:  0.04740712  || Decoder Loss:  0.03387223 Validation Decoder Loss:  0.32979625
Encoder Loss:  0.047401085  || Decoder Loss:  0.033858616 Validation Decoder Loss:  0.32971448
Encoder Loss:  0.047398437  || Decoder Loss:  0.033845767 Validation Decoder Loss:  0.32964766
Encoder Loss:  0.047427025  || Decoder Loss:  0.033833526 Validation Decoder Loss:  0.3295958
Encoder Loss:  0.047387913  || Decoder Loss:  0.033821695 Validation Decoder Loss:  0.3295548
Encoder Loss:  0.04739399  || Decoder Loss:  0.033810116 Validation Decoder Loss:  0.32952467
Encoder Loss:  0.047380686  || Decoder Loss:  0.03379875 Validation Decoder Loss:  0.32950515
Encoder Loss:  0.047394156  || Decoder Loss:  0.03378757 Validation Decoder Loss:  0.32949227
Encoder Loss:  0.047382616  || Decoder Loss:  0.03377655 Validation Decoder Loss:  0.3294903
Encoder Loss:  0.04737706  || Decoder Loss:  0.03376554 Validation Decoder Loss:  0.3294953
Encoder Loss:  0.047374524  || Decoder Loss:  0.033754587 Validation Decoder Loss:  0.32950404
Encoder Loss:  0.047369987  || Decoder Loss:  0.033743758 Validation Decoder Loss:  0.3295191
Encoder Loss:  0.047368236  || Decoder Loss:  0.033732902 Validation Decoder Loss:  0.32953864
Encoder Loss:  0.047364898  || Decoder Loss:  0.03372227 Validation Decoder Loss:  0.32956135
Encoder Loss:  0.04736509  || Decoder Loss:  0.03371174 Validation Decoder Loss:  0.3295862
Encoder Loss:  0.047361903  || Decoder Loss:  0.033701383 Validation Decoder Loss:  0.32961774
Encoder Loss:  0.04736126  || Decoder Loss:  0.033691213 Validation Decoder Loss:  0.3296532
Encoder Loss:  0.047357157  || Decoder Loss:  0.033681158 Validation Decoder Loss:  0.32968435
Encoder Loss:  0.047354817  || Decoder Loss:  0.033671368 Validation Decoder Loss:  0.3297196
Encoder Loss:  0.047355  || Decoder Loss:  0.033661768 Validation Decoder Loss:  0.3297611
Model: siamese_net_lr_0.0004377546872620276 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32976106
Model: "sequential_403"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_272 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_567 (Dropout)        (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_273 (Conv3D (None, 220, 11, 20, 1)    722       
_________________________________________________________________
reshape_107 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_189 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_569 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_190 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_189 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_571 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_190 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23080301  || Decoder Loss:  0.10756456 Validation Decoder Loss:  0.38353318
Encoder Loss:  0.22892292  || Decoder Loss:  0.11185967 Validation Decoder Loss:  0.3872253
Encoder Loss:  0.227355  || Decoder Loss:  0.1170011 Validation Decoder Loss:  0.39158902
Encoder Loss:  0.22613588  || Decoder Loss:  0.12403539 Validation Decoder Loss:  0.39793587
Encoder Loss:  0.22576839  || Decoder Loss:  0.13652302 Validation Decoder Loss:  0.4134065
Encoder Loss:  0.24492611  || Decoder Loss:  0.26126084 Validation Decoder Loss:  1.0479912
Encoder Loss:  0.21138293  || Decoder Loss:  0.3189436 Validation Decoder Loss:  0.39160994
Encoder Loss:  0.08486727  || Decoder Loss:  0.074729316 Validation Decoder Loss:  0.36209917
Encoder Loss:  0.07539387  || Decoder Loss:  0.059118617 Validation Decoder Loss:  0.35664392
Encoder Loss:  0.071423054  || Decoder Loss:  0.05470989 Validation Decoder Loss:  0.3515129
Encoder Loss:  0.06804699  || Decoder Loss:  0.052047774 Validation Decoder Loss:  0.3476719
Encoder Loss:  0.06445439  || Decoder Loss:  0.04957963 Validation Decoder Loss:  0.34386337
Encoder Loss:  0.060336642  || Decoder Loss:  0.04688844 Validation Decoder Loss:  0.33987215
Encoder Loss:  0.055553295  || Decoder Loss:  0.044009242 Validation Decoder Loss:  0.33661765
Encoder Loss:  0.05031982  || Decoder Loss:  0.041151233 Validation Decoder Loss:  0.33447075
Encoder Loss:  0.04551661  || Decoder Loss:  0.038579885 Validation Decoder Loss:  0.33338797
Encoder Loss:  0.043971065  || Decoder Loss:  0.036645453 Validation Decoder Loss:  0.3330199
Encoder Loss:  0.043470763  || Decoder Loss:  0.035680648 Validation Decoder Loss:  0.33263463
Encoder Loss:  0.043277144  || Decoder Loss:  0.035312705 Validation Decoder Loss:  0.33220324
Encoder Loss:  0.0431759  || Decoder Loss:  0.03512555 Validation Decoder Loss:  0.33249083
Encoder Loss:  0.043096393  || Decoder Loss:  0.03498469 Validation Decoder Loss:  0.33303416
Encoder Loss:  0.043039102  || Decoder Loss:  0.034891393 Validation Decoder Loss:  0.33315682
Encoder Loss:  0.042991538  || Decoder Loss:  0.034822468 Validation Decoder Loss:  0.33314985
Encoder Loss:  0.042942535  || Decoder Loss:  0.03476215 Validation Decoder Loss:  0.3331334
Encoder Loss:  0.042877987  || Decoder Loss:  0.034707017 Validation Decoder Loss:  0.33312806
Encoder Loss:  0.042769905  || Decoder Loss:  0.034656547 Validation Decoder Loss:  0.33315554
Encoder Loss:  0.042542156  || Decoder Loss:  0.034623448 Validation Decoder Loss:  0.3332673
Encoder Loss:  0.04230017  || Decoder Loss:  0.03463347 Validation Decoder Loss:  0.33345667
Encoder Loss:  0.042198543  || Decoder Loss:  0.034656707 Validation Decoder Loss:  0.33359867
Encoder Loss:  0.042173494  || Decoder Loss:  0.034689177 Validation Decoder Loss:  0.33370644
Encoder Loss:  0.042174198  || Decoder Loss:  0.034709472 Validation Decoder Loss:  0.33379924
Encoder Loss:  0.04217703  || Decoder Loss:  0.034717754 Validation Decoder Loss:  0.3338828
Encoder Loss:  0.04217729  || Decoder Loss:  0.03472066 Validation Decoder Loss:  0.3339629
Encoder Loss:  0.0421778  || Decoder Loss:  0.03472151 Validation Decoder Loss:  0.33403483
Encoder Loss:  0.04217963  || Decoder Loss:  0.034725577 Validation Decoder Loss:  0.33410928
Encoder Loss:  0.04218174  || Decoder Loss:  0.034731124 Validation Decoder Loss:  0.33418527
Encoder Loss:  0.042185828  || Decoder Loss:  0.034739353 Validation Decoder Loss:  0.33425933
Encoder Loss:  0.042189475  || Decoder Loss:  0.034747228 Validation Decoder Loss:  0.33432332
Encoder Loss:  0.042193264  || Decoder Loss:  0.034756128 Validation Decoder Loss:  0.33439022
Encoder Loss:  0.042198338  || Decoder Loss:  0.03476649 Validation Decoder Loss:  0.33445483
Model: siamese_net_lr_8.927638030372099e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33445483
Model: "sequential_407"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_275 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_573 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_276 (Conv3D (None, 220, 11, 20, 1)    757       
_________________________________________________________________
reshape_108 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 822
Trainable params: 822
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_191 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_575 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_192 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_191 (Conv2D (None, 2590, 20, 1)       172       
_________________________________________________________________
dropout_577 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_192 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26265934  || Decoder Loss:  0.101752445 Validation Decoder Loss:  0.37720686
Encoder Loss:  0.262457  || Decoder Loss:  0.10243636 Validation Decoder Loss:  0.3778352
Encoder Loss:  0.26224932  || Decoder Loss:  0.10313371 Validation Decoder Loss:  0.37845272
Encoder Loss:  0.2620414  || Decoder Loss:  0.10382631 Validation Decoder Loss:  0.37906
Encoder Loss:  0.26183307  || Decoder Loss:  0.10451483 Validation Decoder Loss:  0.37965828
Encoder Loss:  0.26162422  || Decoder Loss:  0.10519978 Validation Decoder Loss:  0.3802489
Encoder Loss:  0.2614146  || Decoder Loss:  0.1058818 Validation Decoder Loss:  0.38083285
Encoder Loss:  0.261204  || Decoder Loss:  0.106561534 Validation Decoder Loss:  0.38141108
Encoder Loss:  0.2609923  || Decoder Loss:  0.10723961 Validation Decoder Loss:  0.38198435
Encoder Loss:  0.26077935  || Decoder Loss:  0.1079165 Validation Decoder Loss:  0.38255373
Encoder Loss:  0.26056498  || Decoder Loss:  0.10859286 Validation Decoder Loss:  0.38311994
Encoder Loss:  0.2603491  || Decoder Loss:  0.1092692 Validation Decoder Loss:  0.38368374
Encoder Loss:  0.26013145  || Decoder Loss:  0.10994604 Validation Decoder Loss:  0.38424578
Encoder Loss:  0.25991184  || Decoder Loss:  0.110623926 Validation Decoder Loss:  0.38480684
Encoder Loss:  0.2596901  || Decoder Loss:  0.11130329 Validation Decoder Loss:  0.3853675
Encoder Loss:  0.25946608  || Decoder Loss:  0.11198455 Validation Decoder Loss:  0.38592857
Encoder Loss:  0.25923946  || Decoder Loss:  0.11266823 Validation Decoder Loss:  0.38649064
Encoder Loss:  0.25901017  || Decoder Loss:  0.11335478 Validation Decoder Loss:  0.38705432
Encoder Loss:  0.25877792  || Decoder Loss:  0.114044674 Validation Decoder Loss:  0.38762027
Encoder Loss:  0.2585424  || Decoder Loss:  0.11473846 Validation Decoder Loss:  0.38818908
Encoder Loss:  0.25830355  || Decoder Loss:  0.115436524 Validation Decoder Loss:  0.38876134
Encoder Loss:  0.2580609  || Decoder Loss:  0.11613948 Validation Decoder Loss:  0.3893377
Encoder Loss:  0.25781435  || Decoder Loss:  0.11684788 Validation Decoder Loss:  0.38991883
Encoder Loss:  0.25756356  || Decoder Loss:  0.117562234 Validation Decoder Loss:  0.3905054
Encoder Loss:  0.25730821  || Decoder Loss:  0.118283235 Validation Decoder Loss:  0.3910982
Encoder Loss:  0.25704804  || Decoder Loss:  0.119011514 Validation Decoder Loss:  0.3916979
Encoder Loss:  0.25678277  || Decoder Loss:  0.11974792 Validation Decoder Loss:  0.39230543
Encoder Loss:  0.25651208  || Decoder Loss:  0.120493285 Validation Decoder Loss:  0.3929217
Encoder Loss:  0.2562355  || Decoder Loss:  0.121248655 Validation Decoder Loss:  0.3935477
Encoder Loss:  0.25595298  || Decoder Loss:  0.12201518 Validation Decoder Loss:  0.39418477
Encoder Loss:  0.2556642  || Decoder Loss:  0.12279421 Validation Decoder Loss:  0.3948341
Encoder Loss:  0.2553689  || Decoder Loss:  0.12358724 Validation Decoder Loss:  0.39549726
Encoder Loss:  0.25506675  || Decoder Loss:  0.12439608 Validation Decoder Loss:  0.39617595
Encoder Loss:  0.2547576  || Decoder Loss:  0.12522253 Validation Decoder Loss:  0.39687198
Encoder Loss:  0.25444117  || Decoder Loss:  0.12606873 Validation Decoder Loss:  0.39758745
Encoder Loss:  0.25411716  || Decoder Loss:  0.126937 Validation Decoder Loss:  0.39832458
Encoder Loss:  0.25378522  || Decoder Loss:  0.12782982 Validation Decoder Loss:  0.39908597
Encoder Loss:  0.25344503  || Decoder Loss:  0.12874982 Validation Decoder Loss:  0.39987427
Encoder Loss:  0.25309595  || Decoder Loss:  0.12969987 Validation Decoder Loss:  0.40069258
Encoder Loss:  0.2527374  || Decoder Loss:  0.13068314 Validation Decoder Loss:  0.40154424
Model: siamese_net_lr_0.00010951927116466407 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.40154424
Model: "sequential_411"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_278 (Conv3D (None, 122, 5, 20, 1)     60        
_________________________________________________________________
dropout_579 (Dropout)        (None, 122, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_279 (Conv3D (None, 220, 11, 20, 1)    298       
_________________________________________________________________
reshape_109 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 358
Trainable params: 358
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_193 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_581 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_194 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_193 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_583 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_194 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3672045  || Decoder Loss:  0.10499017 Validation Decoder Loss:  0.3800956
Encoder Loss:  0.35321558  || Decoder Loss:  0.10767842 Validation Decoder Loss:  0.38228858
Encoder Loss:  0.3383195  || Decoder Loss:  0.111834265 Validation Decoder Loss:  0.3857832
Encoder Loss:  0.3209055  || Decoder Loss:  0.12004984 Validation Decoder Loss:  0.3945661
Encoder Loss:  0.24469398  || Decoder Loss:  0.21487221 Validation Decoder Loss:  1.0934467
Encoder Loss:  0.09617791  || Decoder Loss:  0.2389451 Validation Decoder Loss:  0.3720128
Encoder Loss:  0.09177631  || Decoder Loss:  0.057442885 Validation Decoder Loss:  0.35388923
Encoder Loss:  0.090504445  || Decoder Loss:  0.04336549 Validation Decoder Loss:  0.35168886
Encoder Loss:  0.08935235  || Decoder Loss:  0.04173528 Validation Decoder Loss:  0.3471378
Encoder Loss:  0.08802497  || Decoder Loss:  0.040785402 Validation Decoder Loss:  0.34333885
Encoder Loss:  0.08653505  || Decoder Loss:  0.03983876 Validation Decoder Loss:  0.34035617
Encoder Loss:  0.08477738  || Decoder Loss:  0.038654245 Validation Decoder Loss:  0.3379215
Encoder Loss:  0.08269442  || Decoder Loss:  0.03738371 Validation Decoder Loss:  0.33588573
Encoder Loss:  0.08019938  || Decoder Loss:  0.036360335 Validation Decoder Loss:  0.33446506
Encoder Loss:  0.07526295  || Decoder Loss:  0.03574122 Validation Decoder Loss:  0.33367223
Encoder Loss:  0.054414343  || Decoder Loss:  0.0354519 Validation Decoder Loss:  0.33319587
Encoder Loss:  0.05050545  || Decoder Loss:  0.035093866 Validation Decoder Loss:  0.33257738
Encoder Loss:  0.049844764  || Decoder Loss:  0.03449114 Validation Decoder Loss:  0.33261263
Encoder Loss:  0.049788833  || Decoder Loss:  0.034373447 Validation Decoder Loss:  0.3327545
Encoder Loss:  0.049805846  || Decoder Loss:  0.034366835 Validation Decoder Loss:  0.3328274
Encoder Loss:  0.049792066  || Decoder Loss:  0.034356717 Validation Decoder Loss:  0.33284497
Encoder Loss:  0.049784716  || Decoder Loss:  0.034358244 Validation Decoder Loss:  0.3328665
Encoder Loss:  0.049788497  || Decoder Loss:  0.03435699 Validation Decoder Loss:  0.3328915
Encoder Loss:  0.04978755  || Decoder Loss:  0.0343542 Validation Decoder Loss:  0.33290076
Encoder Loss:  0.049784854  || Decoder Loss:  0.03435626 Validation Decoder Loss:  0.3329214
Encoder Loss:  0.049781516  || Decoder Loss:  0.03436316 Validation Decoder Loss:  0.33294332
Encoder Loss:  0.04978577  || Decoder Loss:  0.03436131 Validation Decoder Loss:  0.33296853
Encoder Loss:  0.049788732  || Decoder Loss:  0.034372814 Validation Decoder Loss:  0.33300382
Encoder Loss:  0.049790926  || Decoder Loss:  0.03437653 Validation Decoder Loss:  0.33305168
Encoder Loss:  0.04978359  || Decoder Loss:  0.03438349 Validation Decoder Loss:  0.3330789
Encoder Loss:  0.04977712  || Decoder Loss:  0.034391027 Validation Decoder Loss:  0.33311808
Encoder Loss:  0.04978161  || Decoder Loss:  0.034397785 Validation Decoder Loss:  0.33317387
Encoder Loss:  0.049780812  || Decoder Loss:  0.034408174 Validation Decoder Loss:  0.33319333
Encoder Loss:  0.04977247  || Decoder Loss:  0.034406904 Validation Decoder Loss:  0.33323967
Encoder Loss:  0.049772058  || Decoder Loss:  0.034413937 Validation Decoder Loss:  0.33329022
Encoder Loss:  0.049775675  || Decoder Loss:  0.03442327 Validation Decoder Loss:  0.33335364
Encoder Loss:  0.049773246  || Decoder Loss:  0.03443094 Validation Decoder Loss:  0.3333548
Encoder Loss:  0.049776636  || Decoder Loss:  0.03442974 Validation Decoder Loss:  0.33338502
Encoder Loss:  0.04977802  || Decoder Loss:  0.03445569 Validation Decoder Loss:  0.33341366
Encoder Loss:  0.049768418  || Decoder Loss:  0.03445421 Validation Decoder Loss:  0.33338615
Model: siamese_net_lr_0.00016729492504133424 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33338618
Model: "sequential_415"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_281 (Conv3D (None, 125, 10, 20, 1)    125       
_________________________________________________________________
dropout_585 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_282 (Conv3D (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_110 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_195 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_587 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_196 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_195 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_589 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_196 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21500248  || Decoder Loss:  0.10585183 Validation Decoder Loss:  0.3815544
Encoder Loss:  0.21608481  || Decoder Loss:  0.11029032 Validation Decoder Loss:  0.38556454
Encoder Loss:  0.21725458  || Decoder Loss:  0.11534455 Validation Decoder Loss:  0.39008504
Encoder Loss:  0.21859282  || Decoder Loss:  0.12170334 Validation Decoder Loss:  0.39599136
Encoder Loss:  0.22025415  || Decoder Loss:  0.1313813 Validation Decoder Loss:  0.40707898
Encoder Loss:  0.21868664  || Decoder Loss:  0.15237276 Validation Decoder Loss:  0.4471108
Encoder Loss:  0.08548819  || Decoder Loss:  0.06842856 Validation Decoder Loss:  0.33749142
Encoder Loss:  0.05897837  || Decoder Loss:  0.03666475 Validation Decoder Loss:  0.33709937
Encoder Loss:  0.058519553  || Decoder Loss:  0.036554065 Validation Decoder Loss:  0.33584604
Encoder Loss:  0.058074504  || Decoder Loss:  0.036482446 Validation Decoder Loss:  0.33483315
Encoder Loss:  0.05756003  || Decoder Loss:  0.036414627 Validation Decoder Loss:  0.33391017
Encoder Loss:  0.056961894  || Decoder Loss:  0.03634206 Validation Decoder Loss:  0.33321285
Encoder Loss:  0.056288894  || Decoder Loss:  0.036258917 Validation Decoder Loss:  0.33280095
Encoder Loss:  0.055412766  || Decoder Loss:  0.0361582 Validation Decoder Loss:  0.33258617
Encoder Loss:  0.05430893  || Decoder Loss:  0.036030322 Validation Decoder Loss:  0.3324744
Encoder Loss:  0.05278182  || Decoder Loss:  0.035867307 Validation Decoder Loss:  0.33238485
Encoder Loss:  0.050530013  || Decoder Loss:  0.03566447 Validation Decoder Loss:  0.3322735
Encoder Loss:  0.04698787  || Decoder Loss:  0.035432484 Validation Decoder Loss:  0.3322343
Encoder Loss:  0.042652015  || Decoder Loss:  0.03521118 Validation Decoder Loss:  0.33221343
Encoder Loss:  0.041874055  || Decoder Loss:  0.03511728 Validation Decoder Loss:  0.33216906
Encoder Loss:  0.04184914  || Decoder Loss:  0.035072535 Validation Decoder Loss:  0.33216032
Encoder Loss:  0.041816235  || Decoder Loss:  0.03503191 Validation Decoder Loss:  0.33215803
Encoder Loss:  0.041794468  || Decoder Loss:  0.034994632 Validation Decoder Loss:  0.33215377
Encoder Loss:  0.041770115  || Decoder Loss:  0.03495887 Validation Decoder Loss:  0.33214694
Encoder Loss:  0.041748047  || Decoder Loss:  0.03492459 Validation Decoder Loss:  0.33213407
Encoder Loss:  0.041723847  || Decoder Loss:  0.03489034 Validation Decoder Loss:  0.33212042
Encoder Loss:  0.041701924  || Decoder Loss:  0.034856223 Validation Decoder Loss:  0.3321021
Encoder Loss:  0.041680843  || Decoder Loss:  0.03482134 Validation Decoder Loss:  0.33208138
Encoder Loss:  0.041654456  || Decoder Loss:  0.03478576 Validation Decoder Loss:  0.3320586
Encoder Loss:  0.041630197  || Decoder Loss:  0.03474953 Validation Decoder Loss:  0.33203518
Encoder Loss:  0.04160545  || Decoder Loss:  0.03471237 Validation Decoder Loss:  0.33200943
Encoder Loss:  0.04157944  || Decoder Loss:  0.034674067 Validation Decoder Loss:  0.33198017
Encoder Loss:  0.04155243  || Decoder Loss:  0.03463485 Validation Decoder Loss:  0.33195078
Encoder Loss:  0.041527256  || Decoder Loss:  0.03459423 Validation Decoder Loss:  0.33191633
Encoder Loss:  0.04149682  || Decoder Loss:  0.03455293 Validation Decoder Loss:  0.33188006
Encoder Loss:  0.041468706  || Decoder Loss:  0.034511074 Validation Decoder Loss:  0.33183983
Encoder Loss:  0.04143933  || Decoder Loss:  0.03446823 Validation Decoder Loss:  0.3317961
Encoder Loss:  0.041409243  || Decoder Loss:  0.034424633 Validation Decoder Loss:  0.3317471
Encoder Loss:  0.041376755  || Decoder Loss:  0.034380857 Validation Decoder Loss:  0.3316956
Encoder Loss:  0.04134825  || Decoder Loss:  0.03433651 Validation Decoder Loss:  0.33163893
Model: siamese_net_lr_0.00024900267744666616 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33163893
Model: "sequential_419"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_284 (Conv3D (None, 127, 10, 20, 1)    385       
_________________________________________________________________
dropout_591 (Dropout)        (None, 127, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_285 (Conv3D (None, 220, 11, 20, 1)    189       
_________________________________________________________________
reshape_111 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_197 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_593 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_198 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_197 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_595 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_198 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24647953  || Decoder Loss:  0.12627168 Validation Decoder Loss:  0.41563848
Encoder Loss:  0.15377669  || Decoder Loss:  0.11969784 Validation Decoder Loss:  0.36309344
Encoder Loss:  0.06985118  || Decoder Loss:  0.064144045 Validation Decoder Loss:  0.3354359
Encoder Loss:  0.044440184  || Decoder Loss:  0.037880436 Validation Decoder Loss:  0.33009267
Encoder Loss:  0.042989273  || Decoder Loss:  0.035303894 Validation Decoder Loss:  0.3313521
Encoder Loss:  0.042652424  || Decoder Loss:  0.03462693 Validation Decoder Loss:  0.33178428
Encoder Loss:  0.042503063  || Decoder Loss:  0.03431312 Validation Decoder Loss:  0.3318599
Encoder Loss:  0.042421937  || Decoder Loss:  0.034165855 Validation Decoder Loss:  0.3320219
Encoder Loss:  0.042385183  || Decoder Loss:  0.03408634 Validation Decoder Loss:  0.3321542
Encoder Loss:  0.042361178  || Decoder Loss:  0.03404368 Validation Decoder Loss:  0.33228463
Encoder Loss:  0.04235531  || Decoder Loss:  0.034029413 Validation Decoder Loss:  0.3323288
Encoder Loss:  0.042352285  || Decoder Loss:  0.034027997 Validation Decoder Loss:  0.3323943
Encoder Loss:  0.042359397  || Decoder Loss:  0.03404067 Validation Decoder Loss:  0.33244008
Encoder Loss:  0.042368066  || Decoder Loss:  0.03406247 Validation Decoder Loss:  0.33246595
Encoder Loss:  0.042381693  || Decoder Loss:  0.03409376 Validation Decoder Loss:  0.33243018
Encoder Loss:  0.042402253  || Decoder Loss:  0.034136813 Validation Decoder Loss:  0.33233434
Encoder Loss:  0.04242425  || Decoder Loss:  0.03418285 Validation Decoder Loss:  0.3322075
Encoder Loss:  0.042447075  || Decoder Loss:  0.03423003 Validation Decoder Loss:  0.33208218
Encoder Loss:  0.042469576  || Decoder Loss:  0.034277916 Validation Decoder Loss:  0.3319329
Encoder Loss:  0.042486954  || Decoder Loss:  0.03431839 Validation Decoder Loss:  0.33179367
Encoder Loss:  0.042507414  || Decoder Loss:  0.034359187 Validation Decoder Loss:  0.33159143
Encoder Loss:  0.042526107  || Decoder Loss:  0.034397744 Validation Decoder Loss:  0.3314321
Encoder Loss:  0.04253715  || Decoder Loss:  0.03442354 Validation Decoder Loss:  0.33130553
Encoder Loss:  0.042546935  || Decoder Loss:  0.034445185 Validation Decoder Loss:  0.33122075
Encoder Loss:  0.042554345  || Decoder Loss:  0.034461398 Validation Decoder Loss:  0.3311051
Encoder Loss:  0.042560473  || Decoder Loss:  0.034473572 Validation Decoder Loss:  0.33100796
Encoder Loss:  0.04256211  || Decoder Loss:  0.034476034 Validation Decoder Loss:  0.33088297
Encoder Loss:  0.04256098  || Decoder Loss:  0.034476582 Validation Decoder Loss:  0.3308152
Encoder Loss:  0.042560667  || Decoder Loss:  0.034475476 Validation Decoder Loss:  0.3306362
Encoder Loss:  0.042556047  || Decoder Loss:  0.034467507 Validation Decoder Loss:  0.33037132
Encoder Loss:  0.04255182  || Decoder Loss:  0.034458674 Validation Decoder Loss:  0.33003652
Encoder Loss:  0.042546853  || Decoder Loss:  0.034447774 Validation Decoder Loss:  0.3297249
Encoder Loss:  0.042540908  || Decoder Loss:  0.034433447 Validation Decoder Loss:  0.32932585
Encoder Loss:  0.042532086  || Decoder Loss:  0.034416474 Validation Decoder Loss:  0.32891858
Encoder Loss:  0.04252306  || Decoder Loss:  0.034398776 Validation Decoder Loss:  0.32849
Encoder Loss:  0.042512327  || Decoder Loss:  0.034375023 Validation Decoder Loss:  0.32809877
Encoder Loss:  0.042499762  || Decoder Loss:  0.034354318 Validation Decoder Loss:  0.32784364
Encoder Loss:  0.04249006  || Decoder Loss:  0.03433193 Validation Decoder Loss:  0.32760996
Encoder Loss:  0.042477597  || Decoder Loss:  0.03430812 Validation Decoder Loss:  0.32746583
Encoder Loss:  0.042466637  || Decoder Loss:  0.034286514 Validation Decoder Loss:  0.3272506
Model: siamese_net_lr_0.0006274343511409354 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3272506
Model: "sequential_423"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_287 (Conv3D (None, 155, 8, 20, 1)     117       
_________________________________________________________________
dropout_597 (Dropout)        (None, 155, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_288 (Conv3D (None, 220, 11, 20, 1)    265       
_________________________________________________________________
reshape_112 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_199 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_599 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_200 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_199 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_601 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_200 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17228065  || Decoder Loss:  0.11258073 Validation Decoder Loss:  0.33123988
Encoder Loss:  0.047498427  || Decoder Loss:  0.035952717 Validation Decoder Loss:  0.33061606
Encoder Loss:  0.04707561  || Decoder Loss:  0.035265084 Validation Decoder Loss:  0.33060217
Encoder Loss:  0.04702924  || Decoder Loss:  0.035118937 Validation Decoder Loss:  0.33063263
Encoder Loss:  0.04691533  || Decoder Loss:  0.03502063 Validation Decoder Loss:  0.33062524
Encoder Loss:  0.046473578  || Decoder Loss:  0.035021327 Validation Decoder Loss:  0.33062994
Encoder Loss:  0.04641024  || Decoder Loss:  0.03503814 Validation Decoder Loss:  0.3306168
Encoder Loss:  0.04640784  || Decoder Loss:  0.035039905 Validation Decoder Loss:  0.33061048
Encoder Loss:  0.046403974  || Decoder Loss:  0.035049714 Validation Decoder Loss:  0.33054543
Encoder Loss:  0.04639879  || Decoder Loss:  0.0350583 Validation Decoder Loss:  0.33047512
Encoder Loss:  0.046408843  || Decoder Loss:  0.03505559 Validation Decoder Loss:  0.33060917
Encoder Loss:  0.04639399  || Decoder Loss:  0.034998648 Validation Decoder Loss:  0.33077592
Encoder Loss:  0.0463548  || Decoder Loss:  0.034873195 Validation Decoder Loss:  0.32970905
Encoder Loss:  0.046275463  || Decoder Loss:  0.03455111 Validation Decoder Loss:  0.32841033
Encoder Loss:  0.04621634  || Decoder Loss:  0.034304123 Validation Decoder Loss:  0.32721245
Encoder Loss:  0.046194702  || Decoder Loss:  0.034206882 Validation Decoder Loss:  0.32634264
Encoder Loss:  0.04616378  || Decoder Loss:  0.03414363 Validation Decoder Loss:  0.32618564
Encoder Loss:  0.046152133  || Decoder Loss:  0.034092326 Validation Decoder Loss:  0.32701945
Encoder Loss:  0.046129044  || Decoder Loss:  0.03404913 Validation Decoder Loss:  0.32825708
Encoder Loss:  0.046111573  || Decoder Loss:  0.034003783 Validation Decoder Loss:  0.32923788
Encoder Loss:  0.046095725  || Decoder Loss:  0.0339593 Validation Decoder Loss:  0.32979178
Encoder Loss:  0.046088222  || Decoder Loss:  0.033932757 Validation Decoder Loss:  0.32963276
Encoder Loss:  0.046081785  || Decoder Loss:  0.03391534 Validation Decoder Loss:  0.3300156
Encoder Loss:  0.046077047  || Decoder Loss:  0.03389775 Validation Decoder Loss:  0.32994244
Encoder Loss:  0.04607819  || Decoder Loss:  0.033896197 Validation Decoder Loss:  0.33024883
Encoder Loss:  0.0460693  || Decoder Loss:  0.03388179 Validation Decoder Loss:  0.33039647
Encoder Loss:  0.04606903  || Decoder Loss:  0.033877112 Validation Decoder Loss:  0.33038518
Encoder Loss:  0.046065137  || Decoder Loss:  0.033870224 Validation Decoder Loss:  0.33036447
Encoder Loss:  0.04606421  || Decoder Loss:  0.03386843 Validation Decoder Loss:  0.33075988
Encoder Loss:  0.046063114  || Decoder Loss:  0.033867273 Validation Decoder Loss:  0.33059356
Encoder Loss:  0.046061743  || Decoder Loss:  0.033865523 Validation Decoder Loss:  0.3309481
Encoder Loss:  0.04606863  || Decoder Loss:  0.033882238 Validation Decoder Loss:  0.33068103
Encoder Loss:  0.04606073  || Decoder Loss:  0.033864446 Validation Decoder Loss:  0.33081222
Encoder Loss:  0.0460603  || Decoder Loss:  0.033864956 Validation Decoder Loss:  0.33090016
Encoder Loss:  0.04605992  || Decoder Loss:  0.0338655 Validation Decoder Loss:  0.33093578
Encoder Loss:  0.046061978  || Decoder Loss:  0.033867586 Validation Decoder Loss:  0.3308931
Encoder Loss:  0.046059657  || Decoder Loss:  0.03386811 Validation Decoder Loss:  0.33100352
Encoder Loss:  0.04605811  || Decoder Loss:  0.03386493 Validation Decoder Loss:  0.33095607
Encoder Loss:  0.04605866  || Decoder Loss:  0.033866867 Validation Decoder Loss:  0.33089867
Encoder Loss:  0.046058778  || Decoder Loss:  0.03386766 Validation Decoder Loss:  0.33096457
Model: siamese_net_lr_0.0009665483914788224 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33096457
Model: "sequential_427"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_290 (Conv3D (None, 155, 8, 20, 1)     117       
_________________________________________________________________
dropout_603 (Dropout)        (None, 155, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_291 (Conv3D (None, 220, 11, 20, 1)    265       
_________________________________________________________________
reshape_113 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_201 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_605 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_202 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_201 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_607 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_202 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17019777  || Decoder Loss:  0.118245706 Validation Decoder Loss:  0.3314616
Encoder Loss:  0.04732878  || Decoder Loss:  0.03665297 Validation Decoder Loss:  0.33073705
Encoder Loss:  0.04692772  || Decoder Loss:  0.035569943 Validation Decoder Loss:  0.33068925
Encoder Loss:  0.046766218  || Decoder Loss:  0.035319608 Validation Decoder Loss:  0.33068675
Encoder Loss:  0.046529077  || Decoder Loss:  0.03519244 Validation Decoder Loss:  0.330719
Encoder Loss:  0.04617165  || Decoder Loss:  0.03516017 Validation Decoder Loss:  0.3307503
Encoder Loss:  0.046161924  || Decoder Loss:  0.03513988 Validation Decoder Loss:  0.33074746
Encoder Loss:  0.046151023  || Decoder Loss:  0.0351318 Validation Decoder Loss:  0.3307546
Encoder Loss:  0.046151027  || Decoder Loss:  0.035142053 Validation Decoder Loss:  0.33075643
Encoder Loss:  0.046156816  || Decoder Loss:  0.03513459 Validation Decoder Loss:  0.33069575
Encoder Loss:  0.04615561  || Decoder Loss:  0.03511922 Validation Decoder Loss:  0.33054656
Encoder Loss:  0.046145953  || Decoder Loss:  0.03510496 Validation Decoder Loss:  0.33041018
Encoder Loss:  0.04612688  || Decoder Loss:  0.035043202 Validation Decoder Loss:  0.33067042
Encoder Loss:  0.046081215  || Decoder Loss:  0.034870997 Validation Decoder Loss:  0.32914764
Encoder Loss:  0.045986105  || Decoder Loss:  0.03452608 Validation Decoder Loss:  0.3280395
Encoder Loss:  0.045932706  || Decoder Loss:  0.034312468 Validation Decoder Loss:  0.32692933
Encoder Loss:  0.045902234  || Decoder Loss:  0.034223676 Validation Decoder Loss:  0.32679623
Encoder Loss:  0.045875326  || Decoder Loss:  0.034159135 Validation Decoder Loss:  0.32746994
Encoder Loss:  0.045846447  || Decoder Loss:  0.034094315 Validation Decoder Loss:  0.32846427
Encoder Loss:  0.045827717  || Decoder Loss:  0.034035083 Validation Decoder Loss:  0.3289274
Encoder Loss:  0.045813393  || Decoder Loss:  0.03398675 Validation Decoder Loss:  0.32915407
Encoder Loss:  0.045801803  || Decoder Loss:  0.03395325 Validation Decoder Loss:  0.32938367
Encoder Loss:  0.045794014  || Decoder Loss:  0.033927444 Validation Decoder Loss:  0.3295743
Encoder Loss:  0.045787  || Decoder Loss:  0.033910584 Validation Decoder Loss:  0.32992706
Encoder Loss:  0.045782156  || Decoder Loss:  0.03389658 Validation Decoder Loss:  0.3300215
Encoder Loss:  0.045780808  || Decoder Loss:  0.03388767 Validation Decoder Loss:  0.3301456
Encoder Loss:  0.045776658  || Decoder Loss:  0.033880375 Validation Decoder Loss:  0.33030653
Encoder Loss:  0.04577434  || Decoder Loss:  0.03387579 Validation Decoder Loss:  0.3305235
Encoder Loss:  0.04577201  || Decoder Loss:  0.03387133 Validation Decoder Loss:  0.33044747
Encoder Loss:  0.04577145  || Decoder Loss:  0.033868644 Validation Decoder Loss:  0.33049452
Encoder Loss:  0.04577036  || Decoder Loss:  0.033867676 Validation Decoder Loss:  0.33076245
Encoder Loss:  0.04596053  || Decoder Loss:  0.033896014 Validation Decoder Loss:  0.32888824
Encoder Loss:  0.04577051  || Decoder Loss:  0.03386737 Validation Decoder Loss:  0.33003026
Encoder Loss:  0.04576359  || Decoder Loss:  0.033851583 Validation Decoder Loss:  0.33055615
Encoder Loss:  0.045763157  || Decoder Loss:  0.03384879 Validation Decoder Loss:  0.33072948
Encoder Loss:  0.04576334  || Decoder Loss:  0.03384997 Validation Decoder Loss:  0.33095607
Encoder Loss:  0.04576411  || Decoder Loss:  0.033853948 Validation Decoder Loss:  0.33094773
Encoder Loss:  0.04576549  || Decoder Loss:  0.03385788 Validation Decoder Loss:  0.33104226
Encoder Loss:  0.045765657  || Decoder Loss:  0.033858947 Validation Decoder Loss:  0.33096653
Encoder Loss:  0.04576604  || Decoder Loss:  0.03386103 Validation Decoder Loss:  0.331141
Model: siamese_net_lr_0.0009986738606228395 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.331141
Model: "sequential_431"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_293 (Conv3D (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_609 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_294 (Conv3D (None, 220, 11, 20, 1)    201       
_________________________________________________________________
reshape_114 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 550
Trainable params: 550
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_203 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_611 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_204 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_203 (Conv2D (None, 2550, 20, 1)       132       
_________________________________________________________________
dropout_613 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_204 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093812 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.377089  || Decoder Loss:  0.11093812 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.377089  || Decoder Loss:  0.11093812 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093812 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.377089  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093815 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093814 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093814 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.377089  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.377089  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093811 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093813 Validation Decoder Loss:  0.38302273
Encoder Loss:  0.37708905  || Decoder Loss:  0.11093814 Validation Decoder Loss:  0.38302273
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38302273
Model: "sequential_435"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_296 (Conv3D (None, 155, 8, 20, 1)     369       
_________________________________________________________________
dropout_615 (Dropout)        (None, 155, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_297 (Conv3D (None, 220, 11, 20, 1)    265       
_________________________________________________________________
reshape_115 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 634
Trainable params: 634
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_205 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_617 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_206 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_205 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_619 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_206 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16968971  || Decoder Loss:  0.10392271 Validation Decoder Loss:  0.383495
Encoder Loss:  0.17546797  || Decoder Loss:  0.11928881 Validation Decoder Loss:  0.4012135
Encoder Loss:  0.18629496  || Decoder Loss:  0.16089113 Validation Decoder Loss:  0.4384531
Encoder Loss:  0.078877926  || Decoder Loss:  0.08036665 Validation Decoder Loss:  0.3821273
Encoder Loss:  0.055970713  || Decoder Loss:  0.05512718 Validation Decoder Loss:  0.33313325
Encoder Loss:  0.040011503  || Decoder Loss:  0.03617204 Validation Decoder Loss:  0.3312276
Encoder Loss:  0.039365042  || Decoder Loss:  0.03542082 Validation Decoder Loss:  0.33093202
Encoder Loss:  0.039187342  || Decoder Loss:  0.035187177 Validation Decoder Loss:  0.33080968
Encoder Loss:  0.039094117  || Decoder Loss:  0.035082012 Validation Decoder Loss:  0.33075806
Encoder Loss:  0.03903485  || Decoder Loss:  0.03502137 Validation Decoder Loss:  0.33073938
Encoder Loss:  0.038990643  || Decoder Loss:  0.034979653 Validation Decoder Loss:  0.33074203
Encoder Loss:  0.038955588  || Decoder Loss:  0.03494649 Validation Decoder Loss:  0.33077225
Encoder Loss:  0.038911976  || Decoder Loss:  0.03491744 Validation Decoder Loss:  0.33085263
Encoder Loss:  0.038857363  || Decoder Loss:  0.034892842 Validation Decoder Loss:  0.33098108
Encoder Loss:  0.038796064  || Decoder Loss:  0.03487735 Validation Decoder Loss:  0.3311574
Encoder Loss:  0.038765315  || Decoder Loss:  0.03486087 Validation Decoder Loss:  0.33133733
Encoder Loss:  0.03873621  || Decoder Loss:  0.034830727 Validation Decoder Loss:  0.33149362
Encoder Loss:  0.03871358  || Decoder Loss:  0.034801956 Validation Decoder Loss:  0.33162022
Encoder Loss:  0.03868984  || Decoder Loss:  0.03477194 Validation Decoder Loss:  0.33171433
Encoder Loss:  0.03866574  || Decoder Loss:  0.034740876 Validation Decoder Loss:  0.33178052
Encoder Loss:  0.03863327  || Decoder Loss:  0.034705404 Validation Decoder Loss:  0.3318413
Encoder Loss:  0.038602322  || Decoder Loss:  0.034666892 Validation Decoder Loss:  0.33189303
Encoder Loss:  0.038568437  || Decoder Loss:  0.034624178 Validation Decoder Loss:  0.33195972
Encoder Loss:  0.03853111  || Decoder Loss:  0.03457804 Validation Decoder Loss:  0.33205557
Encoder Loss:  0.038493875  || Decoder Loss:  0.034529436 Validation Decoder Loss:  0.33217263
Encoder Loss:  0.03845379  || Decoder Loss:  0.034478217 Validation Decoder Loss:  0.33229092
Encoder Loss:  0.038411878  || Decoder Loss:  0.03442522 Validation Decoder Loss:  0.3323933
Encoder Loss:  0.03838091  || Decoder Loss:  0.03438309 Validation Decoder Loss:  0.33244413
Encoder Loss:  0.03835137  || Decoder Loss:  0.0343457 Validation Decoder Loss:  0.33250532
Encoder Loss:  0.038328413  || Decoder Loss:  0.03431509 Validation Decoder Loss:  0.3325313
Encoder Loss:  0.03830796  || Decoder Loss:  0.03428836 Validation Decoder Loss:  0.3325197
Encoder Loss:  0.03828945  || Decoder Loss:  0.034262598 Validation Decoder Loss:  0.3324321
Encoder Loss:  0.038274176  || Decoder Loss:  0.03424205 Validation Decoder Loss:  0.33227417
Encoder Loss:  0.038260806  || Decoder Loss:  0.03422237 Validation Decoder Loss:  0.33225197
Encoder Loss:  0.038241252  || Decoder Loss:  0.034197874 Validation Decoder Loss:  0.33260876
Encoder Loss:  0.03821529  || Decoder Loss:  0.034164608 Validation Decoder Loss:  0.3327614
Encoder Loss:  0.03819646  || Decoder Loss:  0.03413759 Validation Decoder Loss:  0.33278272
Encoder Loss:  0.03817295  || Decoder Loss:  0.03410722 Validation Decoder Loss:  0.33260012
Encoder Loss:  0.0381578  || Decoder Loss:  0.034084454 Validation Decoder Loss:  0.33256203
Encoder Loss:  0.038137194  || Decoder Loss:  0.034058977 Validation Decoder Loss:  0.3326018
Model: siamese_net_lr_0.0006474171028331563 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3326018
Model: "sequential_439"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_299 (Conv3D (None, 140, 11, 20, 1)    540       
_________________________________________________________________
dropout_621 (Dropout)        (None, 140, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_300 (Conv3D (None, 220, 11, 20, 1)    82        
_________________________________________________________________
reshape_116 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 622
Trainable params: 622
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_207 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_623 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_208 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_207 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_625 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_208 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37407494  || Decoder Loss:  0.1076591 Validation Decoder Loss:  0.3791541
Encoder Loss:  0.37277883  || Decoder Loss:  0.108839266 Validation Decoder Loss:  0.38024437
Encoder Loss:  0.37119335  || Decoder Loss:  0.110264145 Validation Decoder Loss:  0.3814361
Encoder Loss:  0.36945346  || Decoder Loss:  0.11180504 Validation Decoder Loss:  0.3826571
Encoder Loss:  0.3676014  || Decoder Loss:  0.1134196 Validation Decoder Loss:  0.38390413
Encoder Loss:  0.36563858  || Decoder Loss:  0.1151033 Validation Decoder Loss:  0.38519627
Encoder Loss:  0.36355302  || Decoder Loss:  0.116863474 Validation Decoder Loss:  0.38654798
Encoder Loss:  0.36132687  || Decoder Loss:  0.11871183 Validation Decoder Loss:  0.38797057
Encoder Loss:  0.35893804  || Decoder Loss:  0.120663136 Validation Decoder Loss:  0.38947853
Encoder Loss:  0.35635945  || Decoder Loss:  0.12273527 Validation Decoder Loss:  0.3910921
Encoder Loss:  0.35355785  || Decoder Loss:  0.12495018 Validation Decoder Loss:  0.39283758
Encoder Loss:  0.350492  || Decoder Loss:  0.12733491 Validation Decoder Loss:  0.39474884
Encoder Loss:  0.34710976  || Decoder Loss:  0.12992379 Validation Decoder Loss:  0.39686948
Encoder Loss:  0.3433444  || Decoder Loss:  0.13276145 Validation Decoder Loss:  0.39925802
Encoder Loss:  0.3391086  || Decoder Loss:  0.135907 Validation Decoder Loss:  0.40199518
Encoder Loss:  0.3342858  || Decoder Loss:  0.13944075 Validation Decoder Loss:  0.40519685
Encoder Loss:  0.3287175  || Decoder Loss:  0.14347494 Validation Decoder Loss:  0.40903622
Encoder Loss:  0.32218307  || Decoder Loss:  0.14817265 Validation Decoder Loss:  0.41378343
Encoder Loss:  0.31436983  || Decoder Loss:  0.15377903 Validation Decoder Loss:  0.4198773
Encoder Loss:  0.30482543  || Decoder Loss:  0.16067204 Validation Decoder Loss:  0.42805701
Encoder Loss:  0.29287672  || Decoder Loss:  0.16942488 Validation Decoder Loss:  0.43954745
Encoder Loss:  0.27747023  || Decoder Loss:  0.18062839 Validation Decoder Loss:  0.45534068
Encoder Loss:  0.25623935  || Decoder Loss:  0.18008104 Validation Decoder Loss:  0.45142102
Encoder Loss:  0.2268303  || Decoder Loss:  0.18164156 Validation Decoder Loss:  0.444668
Encoder Loss:  0.18371224  || Decoder Loss:  0.1715145 Validation Decoder Loss:  0.4349087
Encoder Loss:  0.12133296  || Decoder Loss:  0.16474587 Validation Decoder Loss:  0.4180575
Encoder Loss:  0.08590066  || Decoder Loss:  0.15204579 Validation Decoder Loss:  0.40090144
Encoder Loss:  0.08643063  || Decoder Loss:  0.14138958 Validation Decoder Loss:  0.38979226
Encoder Loss:  0.08263559  || Decoder Loss:  0.13272889 Validation Decoder Loss:  0.38078663
Encoder Loss:  0.08198258  || Decoder Loss:  0.123516016 Validation Decoder Loss:  0.3728454
Encoder Loss:  0.080517955  || Decoder Loss:  0.11143584 Validation Decoder Loss:  0.36955318
Encoder Loss:  0.07831001  || Decoder Loss:  0.10292267 Validation Decoder Loss:  0.3606543
Encoder Loss:  0.07215239  || Decoder Loss:  0.09684702 Validation Decoder Loss:  0.35754448
Encoder Loss:  0.059499677  || Decoder Loss:  0.09054361 Validation Decoder Loss:  0.3528014
Encoder Loss:  0.054904316  || Decoder Loss:  0.0853378 Validation Decoder Loss:  0.34954697
Encoder Loss:  0.054470334  || Decoder Loss:  0.08055046 Validation Decoder Loss:  0.34643492
Encoder Loss:  0.054272704  || Decoder Loss:  0.076215446 Validation Decoder Loss:  0.3439489
Encoder Loss:  0.053935315  || Decoder Loss:  0.072242245 Validation Decoder Loss:  0.34168267
Encoder Loss:  0.053679164  || Decoder Loss:  0.06867153 Validation Decoder Loss:  0.33983898
Encoder Loss:  0.053534087  || Decoder Loss:  0.06549002 Validation Decoder Loss:  0.33825064
Model: siamese_net_lr_0.0009536556676893712 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33825067
Model: "sequential_443"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_302 (Conv3D (None, 122, 10, 20, 1)    119       
_________________________________________________________________
dropout_627 (Dropout)        (None, 122, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_303 (Conv3D (None, 220, 11, 20, 1)    199       
_________________________________________________________________
reshape_117 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_209 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_629 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_210 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_209 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_631 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_210 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2542826  || Decoder Loss:  0.11156514 Validation Decoder Loss:  0.390955
Encoder Loss:  0.25158775  || Decoder Loss:  0.13820238 Validation Decoder Loss:  0.48876002
Encoder Loss:  0.11923187  || Decoder Loss:  0.13255009 Validation Decoder Loss:  0.33730936
Encoder Loss:  0.06946265  || Decoder Loss:  0.044905324 Validation Decoder Loss:  0.3335695
Encoder Loss:  0.06674667  || Decoder Loss:  0.044089742 Validation Decoder Loss:  0.331417
Encoder Loss:  0.05298517  || Decoder Loss:  0.03953848 Validation Decoder Loss:  0.3294475
Encoder Loss:  0.043123905  || Decoder Loss:  0.0342227 Validation Decoder Loss:  0.32724494
Encoder Loss:  0.042389143  || Decoder Loss:  0.03333759 Validation Decoder Loss:  0.3268783
Encoder Loss:  0.042220794  || Decoder Loss:  0.033131078 Validation Decoder Loss:  0.32686087
Encoder Loss:  0.04211657  || Decoder Loss:  0.033006392 Validation Decoder Loss:  0.32700402
Encoder Loss:  0.042066023  || Decoder Loss:  0.032922957 Validation Decoder Loss:  0.32728428
Encoder Loss:  0.04203493  || Decoder Loss:  0.03286799 Validation Decoder Loss:  0.32766137
Encoder Loss:  0.042033922  || Decoder Loss:  0.032825656 Validation Decoder Loss:  0.3281271
Encoder Loss:  0.041990064  || Decoder Loss:  0.032773186 Validation Decoder Loss:  0.3285694
Encoder Loss:  0.041978613  || Decoder Loss:  0.032735955 Validation Decoder Loss:  0.32904124
Encoder Loss:  0.041961875  || Decoder Loss:  0.032706734 Validation Decoder Loss:  0.32940772
Encoder Loss:  0.041936886  || Decoder Loss:  0.03266411 Validation Decoder Loss:  0.32981476
Encoder Loss:  0.04193193  || Decoder Loss:  0.03264183 Validation Decoder Loss:  0.33022496
Encoder Loss:  0.041906476  || Decoder Loss:  0.03260445 Validation Decoder Loss:  0.330659
Encoder Loss:  0.041897275  || Decoder Loss:  0.032576796 Validation Decoder Loss:  0.33107156
Encoder Loss:  0.041884027  || Decoder Loss:  0.032550495 Validation Decoder Loss:  0.33146006
Encoder Loss:  0.041868266  || Decoder Loss:  0.032517817 Validation Decoder Loss:  0.33176118
Encoder Loss:  0.041855205  || Decoder Loss:  0.032491654 Validation Decoder Loss:  0.33194202
Encoder Loss:  0.041825697  || Decoder Loss:  0.0324524 Validation Decoder Loss:  0.33225986
Encoder Loss:  0.041825637  || Decoder Loss:  0.03244163 Validation Decoder Loss:  0.33234674
Encoder Loss:  0.041805625  || Decoder Loss:  0.032422084 Validation Decoder Loss:  0.3326738
Encoder Loss:  0.04180933  || Decoder Loss:  0.032395497 Validation Decoder Loss:  0.33281115
Encoder Loss:  0.04178706  || Decoder Loss:  0.032357235 Validation Decoder Loss:  0.3329416
Encoder Loss:  0.041773096  || Decoder Loss:  0.03235046 Validation Decoder Loss:  0.33304608
Encoder Loss:  0.041780397  || Decoder Loss:  0.032338947 Validation Decoder Loss:  0.3331402
Encoder Loss:  0.041766103  || Decoder Loss:  0.03230838 Validation Decoder Loss:  0.33338723
Encoder Loss:  0.0417556  || Decoder Loss:  0.032304548 Validation Decoder Loss:  0.33335772
Encoder Loss:  0.04174674  || Decoder Loss:  0.032295134 Validation Decoder Loss:  0.33352476
Encoder Loss:  0.04174036  || Decoder Loss:  0.03228098 Validation Decoder Loss:  0.33367956
Encoder Loss:  0.041726045  || Decoder Loss:  0.032262065 Validation Decoder Loss:  0.33370906
Encoder Loss:  0.041720238  || Decoder Loss:  0.03224365 Validation Decoder Loss:  0.33375373
Encoder Loss:  0.041718345  || Decoder Loss:  0.032249257 Validation Decoder Loss:  0.33377558
Encoder Loss:  0.041720066  || Decoder Loss:  0.032245997 Validation Decoder Loss:  0.33384
Encoder Loss:  0.041717593  || Decoder Loss:  0.032241147 Validation Decoder Loss:  0.33385792
Encoder Loss:  0.041705452  || Decoder Loss:  0.032214515 Validation Decoder Loss:  0.33383173
Model: siamese_net_lr_0.00019209424576912255 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33383173
Model: "sequential_447"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_305 (Conv3D (None, 127, 10, 20, 1)    385       
_________________________________________________________________
dropout_633 (Dropout)        (None, 127, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_306 (Conv3D (None, 220, 11, 20, 1)    189       
_________________________________________________________________
reshape_118 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_211 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_635 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_212 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_211 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_637 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_212 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2465984  || Decoder Loss:  0.12651931 Validation Decoder Loss:  0.41639173
Encoder Loss:  0.1511765  || Decoder Loss:  0.11872385 Validation Decoder Loss:  0.3629986
Encoder Loss:  0.06952158  || Decoder Loss:  0.06421229 Validation Decoder Loss:  0.3351857
Encoder Loss:  0.04424243  || Decoder Loss:  0.037739873 Validation Decoder Loss:  0.33014578
Encoder Loss:  0.042983927  || Decoder Loss:  0.035270214 Validation Decoder Loss:  0.33146173
Encoder Loss:  0.04265928  || Decoder Loss:  0.03462085 Validation Decoder Loss:  0.33172706
Encoder Loss:  0.042514846  || Decoder Loss:  0.03432305 Validation Decoder Loss:  0.33184785
Encoder Loss:  0.042443067  || Decoder Loss:  0.03417189 Validation Decoder Loss:  0.33206445
Encoder Loss:  0.042400595  || Decoder Loss:  0.03409823 Validation Decoder Loss:  0.3321401
Encoder Loss:  0.042378034  || Decoder Loss:  0.03405379 Validation Decoder Loss:  0.3322062
Encoder Loss:  0.04236914  || Decoder Loss:  0.03403725 Validation Decoder Loss:  0.33228272
Encoder Loss:  0.042369813  || Decoder Loss:  0.034040518 Validation Decoder Loss:  0.33227864
Encoder Loss:  0.04237774  || Decoder Loss:  0.034054615 Validation Decoder Loss:  0.3323372
Encoder Loss:  0.042388428  || Decoder Loss:  0.03407968 Validation Decoder Loss:  0.3323593
Encoder Loss:  0.042404722  || Decoder Loss:  0.034117404 Validation Decoder Loss:  0.33232662
Encoder Loss:  0.042425007  || Decoder Loss:  0.034160823 Validation Decoder Loss:  0.33223116
Encoder Loss:  0.0424467  || Decoder Loss:  0.034206275 Validation Decoder Loss:  0.33212757
Encoder Loss:  0.042468987  || Decoder Loss:  0.03425236 Validation Decoder Loss:  0.33198574
Encoder Loss:  0.042487957  || Decoder Loss:  0.03429569 Validation Decoder Loss:  0.33184856
Encoder Loss:  0.04250998  || Decoder Loss:  0.034338467 Validation Decoder Loss:  0.33170375
Encoder Loss:  0.04252533  || Decoder Loss:  0.034375545 Validation Decoder Loss:  0.33155072
Encoder Loss:  0.042542502  || Decoder Loss:  0.03441164 Validation Decoder Loss:  0.33142406
Encoder Loss:  0.0425566  || Decoder Loss:  0.034437884 Validation Decoder Loss:  0.33127192
Encoder Loss:  0.042563986  || Decoder Loss:  0.034455337 Validation Decoder Loss:  0.3311621
Encoder Loss:  0.042569995  || Decoder Loss:  0.034469806 Validation Decoder Loss:  0.3311044
Encoder Loss:  0.042574473  || Decoder Loss:  0.034477375 Validation Decoder Loss:  0.331267
Encoder Loss:  0.04257573  || Decoder Loss:  0.03447993 Validation Decoder Loss:  0.3311839
Encoder Loss:  0.04257599  || Decoder Loss:  0.034479327 Validation Decoder Loss:  0.33098185
Encoder Loss:  0.042572737  || Decoder Loss:  0.03447264 Validation Decoder Loss:  0.33072948
Encoder Loss:  0.04256776  || Decoder Loss:  0.03446502 Validation Decoder Loss:  0.33061087
Encoder Loss:  0.042563  || Decoder Loss:  0.03445509 Validation Decoder Loss:  0.3302951
Encoder Loss:  0.042556416  || Decoder Loss:  0.034441832 Validation Decoder Loss:  0.3298735
Encoder Loss:  0.04254905  || Decoder Loss:  0.034429654 Validation Decoder Loss:  0.3294363
Encoder Loss:  0.042542554  || Decoder Loss:  0.034415618 Validation Decoder Loss:  0.32895857
Encoder Loss:  0.04253369  || Decoder Loss:  0.034397956 Validation Decoder Loss:  0.32851622
Encoder Loss:  0.042523686  || Decoder Loss:  0.034379683 Validation Decoder Loss:  0.32819104
Encoder Loss:  0.042515006  || Decoder Loss:  0.03436242 Validation Decoder Loss:  0.32787615
Encoder Loss:  0.04250668  || Decoder Loss:  0.03434431 Validation Decoder Loss:  0.3276531
Encoder Loss:  0.042495407  || Decoder Loss:  0.03432162 Validation Decoder Loss:  0.32742018
Encoder Loss:  0.0424845  || Decoder Loss:  0.034298528 Validation Decoder Loss:  0.3271943
Model: siamese_net_lr_0.0006346082629203034 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32719427
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_213 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_639 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_214 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_213 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_641 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_214 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_308 (Conv3D (None, 193, 10, 20, 1)    135       
_________________________________________________________________
dropout_643 (Dropout)        (None, 193, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_309 (Conv3D (None, 220, 11, 20, 1)    57        
_________________________________________________________________
reshape_119 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_215 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_645 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_216 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_457"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_215 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_647 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_216 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42696866  || Decoder Loss:  0.060669146 Validation Decoder Loss:  0.36805475
Encoder Loss:  0.42628327  || Decoder Loss:  0.06122078 Validation Decoder Loss:  0.3680557
Encoder Loss:  0.42539456  || Decoder Loss:  0.061932307 Validation Decoder Loss:  0.36777887
Encoder Loss:  0.4242611  || Decoder Loss:  0.06284283 Validation Decoder Loss:  0.3672313
Encoder Loss:  0.42272353  || Decoder Loss:  0.06408505 Validation Decoder Loss:  0.36646658
Encoder Loss:  0.4204268  || Decoder Loss:  0.065948516 Validation Decoder Loss:  0.36558068
Encoder Loss:  0.41641805  || Decoder Loss:  0.06919226 Validation Decoder Loss:  0.36499542
Encoder Loss:  0.40718186  || Decoder Loss:  0.0765409 Validation Decoder Loss:  0.36782286
Encoder Loss:  0.36922646  || Decoder Loss:  0.106975995 Validation Decoder Loss:  0.4500303
Encoder Loss:  0.15758881  || Decoder Loss:  0.40694955 Validation Decoder Loss:  1.0269444
Encoder Loss:  0.10700304  || Decoder Loss:  0.45056972 Validation Decoder Loss:  0.9805426
Encoder Loss:  0.108777955  || Decoder Loss:  0.3944345 Validation Decoder Loss:  0.7211477
Encoder Loss:  0.11093098  || Decoder Loss:  0.31730655 Validation Decoder Loss:  0.70863914
Encoder Loss:  0.10789581  || Decoder Loss:  0.2626289 Validation Decoder Loss:  0.5688863
Encoder Loss:  0.105455436  || Decoder Loss:  0.1533608 Validation Decoder Loss:  0.4129396
Encoder Loss:  0.105207995  || Decoder Loss:  0.09837407 Validation Decoder Loss:  0.38142535
Encoder Loss:  0.104988664  || Decoder Loss:  0.08015516 Validation Decoder Loss:  0.3691211
Encoder Loss:  0.10446146  || Decoder Loss:  0.066226706 Validation Decoder Loss:  0.35556412
Encoder Loss:  0.103108265  || Decoder Loss:  0.055535976 Validation Decoder Loss:  0.34618688
Encoder Loss:  0.10296133  || Decoder Loss:  0.04773448 Validation Decoder Loss:  0.3398786
Encoder Loss:  0.099129036  || Decoder Loss:  0.042358164 Validation Decoder Loss:  0.3360137
Encoder Loss:  0.07115541  || Decoder Loss:  0.03900968 Validation Decoder Loss:  0.33384645
Encoder Loss:  0.05269201  || Decoder Loss:  0.037126705 Validation Decoder Loss:  0.33275786
Encoder Loss:  0.050394144  || Decoder Loss:  0.0362654 Validation Decoder Loss:  0.33268428
Encoder Loss:  0.050130755  || Decoder Loss:  0.03590095 Validation Decoder Loss:  0.3328563
Encoder Loss:  0.050106745  || Decoder Loss:  0.035728395 Validation Decoder Loss:  0.33284986
Encoder Loss:  0.050093457  || Decoder Loss:  0.035642754 Validation Decoder Loss:  0.33284143
Encoder Loss:  0.05009241  || Decoder Loss:  0.035590403 Validation Decoder Loss:  0.33280027
Encoder Loss:  0.050091263  || Decoder Loss:  0.03554997 Validation Decoder Loss:  0.33275643
Encoder Loss:  0.050091505  || Decoder Loss:  0.035515837 Validation Decoder Loss:  0.33271092
Encoder Loss:  0.050090656  || Decoder Loss:  0.035485625 Validation Decoder Loss:  0.3326614
Encoder Loss:  0.050090127  || Decoder Loss:  0.035458706 Validation Decoder Loss:  0.33261693
Encoder Loss:  0.050089255  || Decoder Loss:  0.035434328 Validation Decoder Loss:  0.3325742
Encoder Loss:  0.05008871  || Decoder Loss:  0.035412204 Validation Decoder Loss:  0.33253416
Encoder Loss:  0.05008815  || Decoder Loss:  0.03539207 Validation Decoder Loss:  0.33249795
Encoder Loss:  0.050088033  || Decoder Loss:  0.035373703 Validation Decoder Loss:  0.33246475
Encoder Loss:  0.050087225  || Decoder Loss:  0.035356887 Validation Decoder Loss:  0.33243215
Encoder Loss:  0.050087128  || Decoder Loss:  0.035341546 Validation Decoder Loss:  0.3324052
Encoder Loss:  0.050086282  || Decoder Loss:  0.03532743 Validation Decoder Loss:  0.33237725
Encoder Loss:  0.05008572  || Decoder Loss:  0.03531439 Validation Decoder Loss:  0.33235273
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33235273
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_311 (Conv3D (None, 100, 5, 20, 1)     38        
_________________________________________________________________
dropout_649 (Dropout)        (None, 100, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_312 (Conv3D (None, 220, 11, 20, 1)    364       
_________________________________________________________________
reshape_120 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 402
Trainable params: 402
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_217 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_651 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_218 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_217 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_653 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_218 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37146664  || Decoder Loss:  0.10402012 Validation Decoder Loss:  0.38269717
Encoder Loss:  0.34627572  || Decoder Loss:  0.11086955 Validation Decoder Loss:  0.38886553
Encoder Loss:  0.31700882  || Decoder Loss:  0.11999789 Validation Decoder Loss:  0.39747155
Encoder Loss:  0.28082666  || Decoder Loss:  0.118607074 Validation Decoder Loss:  0.36707956
Encoder Loss:  0.109089725  || Decoder Loss:  0.08146991 Validation Decoder Loss:  0.379575
Encoder Loss:  0.053685036  || Decoder Loss:  0.07432923 Validation Decoder Loss:  0.375293
Encoder Loss:  0.051649634  || Decoder Loss:  0.046944078 Validation Decoder Loss:  0.33640617
Encoder Loss:  0.051400222  || Decoder Loss:  0.037949547 Validation Decoder Loss:  0.3341871
Encoder Loss:  0.052184034  || Decoder Loss:  0.037326105 Validation Decoder Loss:  0.3337663
Encoder Loss:  0.052098032  || Decoder Loss:  0.036872 Validation Decoder Loss:  0.33341527
Encoder Loss:  0.051839978  || Decoder Loss:  0.03652463 Validation Decoder Loss:  0.33314314
Encoder Loss:  0.051018443  || Decoder Loss:  0.03623038 Validation Decoder Loss:  0.33293855
Encoder Loss:  0.051778134  || Decoder Loss:  0.035999518 Validation Decoder Loss:  0.33274662
Encoder Loss:  0.05137554  || Decoder Loss:  0.035772093 Validation Decoder Loss:  0.3326384
Encoder Loss:  0.051695127  || Decoder Loss:  0.035577897 Validation Decoder Loss:  0.33252275
Encoder Loss:  0.05169414  || Decoder Loss:  0.03541673 Validation Decoder Loss:  0.33241707
Encoder Loss:  0.051026564  || Decoder Loss:  0.03528236 Validation Decoder Loss:  0.33231342
Encoder Loss:  0.052163407  || Decoder Loss:  0.03521187 Validation Decoder Loss:  0.33215553
Encoder Loss:  0.051088534  || Decoder Loss:  0.03514832 Validation Decoder Loss:  0.33200818
Encoder Loss:  0.051182777  || Decoder Loss:  0.035090398 Validation Decoder Loss:  0.33193365
Encoder Loss:  0.051174335  || Decoder Loss:  0.035016064 Validation Decoder Loss:  0.33187485
Encoder Loss:  0.051249493  || Decoder Loss:  0.03494725 Validation Decoder Loss:  0.3317971
Encoder Loss:  0.051208586  || Decoder Loss:  0.034931462 Validation Decoder Loss:  0.33167666
Encoder Loss:  0.051137246  || Decoder Loss:  0.034931388 Validation Decoder Loss:  0.33155262
Encoder Loss:  0.051004324  || Decoder Loss:  0.03493108 Validation Decoder Loss:  0.33142114
Encoder Loss:  0.0508546  || Decoder Loss:  0.03496971 Validation Decoder Loss:  0.33125758
Encoder Loss:  0.050756797  || Decoder Loss:  0.03500038 Validation Decoder Loss:  0.331096
Encoder Loss:  0.05103721  || Decoder Loss:  0.035056945 Validation Decoder Loss:  0.33091128
Encoder Loss:  0.05122387  || Decoder Loss:  0.035139784 Validation Decoder Loss:  0.33063835
Encoder Loss:  0.05080617  || Decoder Loss:  0.035228472 Validation Decoder Loss:  0.33028832
Encoder Loss:  0.050989393  || Decoder Loss:  0.035312884 Validation Decoder Loss:  0.32988933
Encoder Loss:  0.05098127  || Decoder Loss:  0.03536484 Validation Decoder Loss:  0.32933968
Encoder Loss:  0.05086493  || Decoder Loss:  0.035411198 Validation Decoder Loss:  0.32896405
Encoder Loss:  0.050683323  || Decoder Loss:  0.035363473 Validation Decoder Loss:  0.3287995
Encoder Loss:  0.05050469  || Decoder Loss:  0.035191678 Validation Decoder Loss:  0.32868814
Encoder Loss:  0.05031778  || Decoder Loss:  0.034832165 Validation Decoder Loss:  0.32949555
Encoder Loss:  0.050286163  || Decoder Loss:  0.034712195 Validation Decoder Loss:  0.3294481
Encoder Loss:  0.050279938  || Decoder Loss:  0.034642022 Validation Decoder Loss:  0.32949796
Encoder Loss:  0.050278015  || Decoder Loss:  0.03458737 Validation Decoder Loss:  0.32951754
Encoder Loss:  0.050276637  || Decoder Loss:  0.034546092 Validation Decoder Loss:  0.32954466
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32954466
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_314 (Conv3D (None, 108, 5, 20, 1)     46        
_________________________________________________________________
dropout_655 (Dropout)        (None, 108, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_315 (Conv3D (None, 220, 11, 20, 1)    792       
_________________________________________________________________
reshape_121 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 838
Trainable params: 838
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_219 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_657 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_220 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_219 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_659 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_220 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3621412  || Decoder Loss:  0.106517315 Validation Decoder Loss:  0.38379845
Encoder Loss:  0.35459316  || Decoder Loss:  0.11075919 Validation Decoder Loss:  0.38829434
Encoder Loss:  0.34599686  || Decoder Loss:  0.116264604 Validation Decoder Loss:  0.3935122
Encoder Loss:  0.33533153  || Decoder Loss:  0.124579154 Validation Decoder Loss:  0.40173024
Encoder Loss:  0.30972373  || Decoder Loss:  0.15280095 Validation Decoder Loss:  0.66026306
Encoder Loss:  0.11326886  || Decoder Loss:  0.4569352 Validation Decoder Loss:  1.0422392
Encoder Loss:  0.10460619  || Decoder Loss:  0.27821836 Validation Decoder Loss:  0.41595376
Encoder Loss:  0.10021776  || Decoder Loss:  0.08961089 Validation Decoder Loss:  0.33907044
Encoder Loss:  0.093895465  || Decoder Loss:  0.048047274 Validation Decoder Loss:  0.33459488
Encoder Loss:  0.087094486  || Decoder Loss:  0.04804684 Validation Decoder Loss:  0.332885
Encoder Loss:  0.07887437  || Decoder Loss:  0.048326105 Validation Decoder Loss:  0.33264446
Encoder Loss:  0.068459414  || Decoder Loss:  0.04798577 Validation Decoder Loss:  0.33194855
Encoder Loss:  0.051389825  || Decoder Loss:  0.0474688 Validation Decoder Loss:  0.3292094
Encoder Loss:  0.050232343  || Decoder Loss:  0.045407165 Validation Decoder Loss:  0.3304259
Encoder Loss:  0.050194457  || Decoder Loss:  0.04113504 Validation Decoder Loss:  0.331142
Encoder Loss:  0.05013853  || Decoder Loss:  0.036519226 Validation Decoder Loss:  0.33054653
Encoder Loss:  0.050094094  || Decoder Loss:  0.035121195 Validation Decoder Loss:  0.33054602
Encoder Loss:  0.05006533  || Decoder Loss:  0.03485667 Validation Decoder Loss:  0.33066508
Encoder Loss:  0.050044023  || Decoder Loss:  0.03467167 Validation Decoder Loss:  0.33086583
Encoder Loss:  0.050026942  || Decoder Loss:  0.034551706 Validation Decoder Loss:  0.33097523
Encoder Loss:  0.050022054  || Decoder Loss:  0.034479298 Validation Decoder Loss:  0.33119157
Encoder Loss:  0.050020307  || Decoder Loss:  0.03443845 Validation Decoder Loss:  0.33128145
Encoder Loss:  0.050020628  || Decoder Loss:  0.03440979 Validation Decoder Loss:  0.33132362
Encoder Loss:  0.05002051  || Decoder Loss:  0.034390103 Validation Decoder Loss:  0.3314076
Encoder Loss:  0.05002017  || Decoder Loss:  0.03436573 Validation Decoder Loss:  0.3315258
Encoder Loss:  0.050020542  || Decoder Loss:  0.034349173 Validation Decoder Loss:  0.33159602
Encoder Loss:  0.05002003  || Decoder Loss:  0.034334563 Validation Decoder Loss:  0.33162737
Encoder Loss:  0.05001977  || Decoder Loss:  0.034327094 Validation Decoder Loss:  0.33166197
Encoder Loss:  0.05001937  || Decoder Loss:  0.03431594 Validation Decoder Loss:  0.3316986
Encoder Loss:  0.050019607  || Decoder Loss:  0.03430586 Validation Decoder Loss:  0.33171996
Encoder Loss:  0.05001913  || Decoder Loss:  0.03430366 Validation Decoder Loss:  0.33176845
Encoder Loss:  0.05001916  || Decoder Loss:  0.03429439 Validation Decoder Loss:  0.33181626
Encoder Loss:  0.050018467  || Decoder Loss:  0.03429237 Validation Decoder Loss:  0.33183378
Encoder Loss:  0.05001853  || Decoder Loss:  0.03429024 Validation Decoder Loss:  0.33185253
Encoder Loss:  0.050018243  || Decoder Loss:  0.034286104 Validation Decoder Loss:  0.33189
Encoder Loss:  0.050018206  || Decoder Loss:  0.03428572 Validation Decoder Loss:  0.33191222
Encoder Loss:  0.05001807  || Decoder Loss:  0.034285314 Validation Decoder Loss:  0.3319462
Encoder Loss:  0.050017834  || Decoder Loss:  0.034286547 Validation Decoder Loss:  0.33196008
Encoder Loss:  0.05001754  || Decoder Loss:  0.03428812 Validation Decoder Loss:  0.33195946
Encoder Loss:  0.05001737  || Decoder Loss:  0.03428882 Validation Decoder Loss:  0.33197373
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33197373
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_317 (Conv3D (None, 125, 10, 20, 1)    125       
_________________________________________________________________
dropout_661 (Dropout)        (None, 125, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_318 (Conv3D (None, 220, 11, 20, 1)    193       
_________________________________________________________________
reshape_122 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_221 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_663 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_222 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_469"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_221 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_665 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_222 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10373602  || Decoder Loss:  0.10373602 Validation Decoder Loss:  0.37831074
Encoder Loss:  0.1036883  || Decoder Loss:  0.1036883 Validation Decoder Loss:  0.37922108
Encoder Loss:  0.103636354  || Decoder Loss:  0.103636354 Validation Decoder Loss:  0.3800819
Encoder Loss:  0.10358379  || Decoder Loss:  0.10358379 Validation Decoder Loss:  0.38088083
Encoder Loss:  0.103529885  || Decoder Loss:  0.103529885 Validation Decoder Loss:  0.38162953
Encoder Loss:  0.10347333  || Decoder Loss:  0.10347333 Validation Decoder Loss:  0.3823418
Encoder Loss:  0.10341259  || Decoder Loss:  0.10341259 Validation Decoder Loss:  0.3830343
Encoder Loss:  0.10334564  || Decoder Loss:  0.10334564 Validation Decoder Loss:  0.38372642
Encoder Loss:  0.10326978  || Decoder Loss:  0.10326978 Validation Decoder Loss:  0.38444158
Encoder Loss:  0.10318074  || Decoder Loss:  0.10318074 Validation Decoder Loss:  0.3852104
Encoder Loss:  0.10307146  || Decoder Loss:  0.10307146 Validation Decoder Loss:  0.38608032
Encoder Loss:  0.10292841  || Decoder Loss:  0.10292841 Validation Decoder Loss:  0.38714033
Encoder Loss:  0.102720864  || Decoder Loss:  0.102720864 Validation Decoder Loss:  0.38859662
Encoder Loss:  0.102355674  || Decoder Loss:  0.102355674 Validation Decoder Loss:  0.39115298
Encoder Loss:  0.10129217  || Decoder Loss:  0.10129217 Validation Decoder Loss:  0.40190938
Encoder Loss:  0.09119943  || Decoder Loss:  0.09119943 Validation Decoder Loss:  0.33048347
Encoder Loss:  0.08151361  || Decoder Loss:  0.08151361 Validation Decoder Loss:  0.34926987
Encoder Loss:  0.08013708  || Decoder Loss:  0.08013708 Validation Decoder Loss:  0.35259926
Encoder Loss:  0.0789814  || Decoder Loss:  0.0789814 Validation Decoder Loss:  0.3514372
Encoder Loss:  0.075611085  || Decoder Loss:  0.075611085 Validation Decoder Loss:  0.3503109
Encoder Loss:  0.06389579  || Decoder Loss:  0.06389579 Validation Decoder Loss:  0.3452688
Encoder Loss:  0.060632195  || Decoder Loss:  0.060632195 Validation Decoder Loss:  0.34626883
Encoder Loss:  0.058639213  || Decoder Loss:  0.058639213 Validation Decoder Loss:  0.34567255
Encoder Loss:  0.05658032  || Decoder Loss:  0.05658032 Validation Decoder Loss:  0.34474623
Encoder Loss:  0.054286342  || Decoder Loss:  0.054286342 Validation Decoder Loss:  0.3440607
Encoder Loss:  0.051665753  || Decoder Loss:  0.051665753 Validation Decoder Loss:  0.34335762
Encoder Loss:  0.04867586  || Decoder Loss:  0.04867586 Validation Decoder Loss:  0.34248772
Encoder Loss:  0.045363184  || Decoder Loss:  0.045363184 Validation Decoder Loss:  0.34074944
Encoder Loss:  0.04202896  || Decoder Loss:  0.04202896 Validation Decoder Loss:  0.3385766
Encoder Loss:  0.039313845  || Decoder Loss:  0.039313845 Validation Decoder Loss:  0.33718568
Encoder Loss:  0.03755672  || Decoder Loss:  0.03755672 Validation Decoder Loss:  0.3356123
Encoder Loss:  0.036610566  || Decoder Loss:  0.036610566 Validation Decoder Loss:  0.3350872
Encoder Loss:  0.036031038  || Decoder Loss:  0.036031038 Validation Decoder Loss:  0.3344462
Encoder Loss:  0.035703085  || Decoder Loss:  0.035703085 Validation Decoder Loss:  0.3353455
Encoder Loss:  0.035463605  || Decoder Loss:  0.035463605 Validation Decoder Loss:  0.33345076
Encoder Loss:  0.035335734  || Decoder Loss:  0.035335734 Validation Decoder Loss:  0.33330813
Encoder Loss:  0.035214845  || Decoder Loss:  0.035214845 Validation Decoder Loss:  0.33306065
Encoder Loss:  0.035150014  || Decoder Loss:  0.035150014 Validation Decoder Loss:  0.33316782
Encoder Loss:  0.035096973  || Decoder Loss:  0.035096973 Validation Decoder Loss:  0.33319807
Encoder Loss:  0.035033464  || Decoder Loss:  0.035033464 Validation Decoder Loss:  0.3324498
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3324498
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_320 (Conv3D (None, 140, 9, 20, 1)     386       
_________________________________________________________________
dropout_667 (Dropout)        (None, 140, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_321 (Conv3D (None, 220, 11, 20, 1)    244       
_________________________________________________________________
reshape_123 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 630
Trainable params: 630
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_223 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_669 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_224 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_473"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_223 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_671 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_224 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10330155  || Decoder Loss:  0.10330155 Validation Decoder Loss:  0.38219464
Encoder Loss:  0.07537238  || Decoder Loss:  0.07537238 Validation Decoder Loss:  0.3523025
Encoder Loss:  0.038266696  || Decoder Loss:  0.038266696 Validation Decoder Loss:  0.35140848
Encoder Loss:  0.036993843  || Decoder Loss:  0.036993843 Validation Decoder Loss:  0.35068542
Encoder Loss:  0.036194492  || Decoder Loss:  0.036194492 Validation Decoder Loss:  0.3500607
Encoder Loss:  0.035617743  || Decoder Loss:  0.035617743 Validation Decoder Loss:  0.34947085
Encoder Loss:  0.03518112  || Decoder Loss:  0.03518112 Validation Decoder Loss:  0.34892213
Encoder Loss:  0.034845125  || Decoder Loss:  0.034845125 Validation Decoder Loss:  0.34842026
Encoder Loss:  0.03458665  || Decoder Loss:  0.03458665 Validation Decoder Loss:  0.347974
Encoder Loss:  0.03438924  || Decoder Loss:  0.03438924 Validation Decoder Loss:  0.34758928
Encoder Loss:  0.034238916  || Decoder Loss:  0.034238916 Validation Decoder Loss:  0.34726334
Encoder Loss:  0.034122955  || Decoder Loss:  0.034122955 Validation Decoder Loss:  0.34698933
Encoder Loss:  0.034030747  || Decoder Loss:  0.034030747 Validation Decoder Loss:  0.34675354
Encoder Loss:  0.03395377  || Decoder Loss:  0.03395377 Validation Decoder Loss:  0.34654093
Encoder Loss:  0.03388591  || Decoder Loss:  0.03388591 Validation Decoder Loss:  0.34633613
Encoder Loss:  0.033823203  || Decoder Loss:  0.033823203 Validation Decoder Loss:  0.3461255
Encoder Loss:  0.03376306  || Decoder Loss:  0.03376306 Validation Decoder Loss:  0.34589577
Encoder Loss:  0.033704326  || Decoder Loss:  0.033704326 Validation Decoder Loss:  0.3456397
Encoder Loss:  0.033646986  || Decoder Loss:  0.033646986 Validation Decoder Loss:  0.3453549
Encoder Loss:  0.033591606  || Decoder Loss:  0.033591606 Validation Decoder Loss:  0.34504667
Encoder Loss:  0.033539053  || Decoder Loss:  0.033539053 Validation Decoder Loss:  0.34472185
Encoder Loss:  0.033490162  || Decoder Loss:  0.033490162 Validation Decoder Loss:  0.34438866
Encoder Loss:  0.03344552  || Decoder Loss:  0.03344552 Validation Decoder Loss:  0.34405556
Encoder Loss:  0.03340536  || Decoder Loss:  0.03340536 Validation Decoder Loss:  0.3437294
Encoder Loss:  0.033369757  || Decoder Loss:  0.033369757 Validation Decoder Loss:  0.343415
Encoder Loss:  0.03333852  || Decoder Loss:  0.03333852 Validation Decoder Loss:  0.34311664
Encoder Loss:  0.03331132  || Decoder Loss:  0.03331132 Validation Decoder Loss:  0.34283626
Encoder Loss:  0.03328771  || Decoder Loss:  0.03328771 Validation Decoder Loss:  0.34257406
Encoder Loss:  0.03326725  || Decoder Loss:  0.03326725 Validation Decoder Loss:  0.3423297
Encoder Loss:  0.033249408  || Decoder Loss:  0.033249408 Validation Decoder Loss:  0.34210107
Encoder Loss:  0.033233736  || Decoder Loss:  0.033233736 Validation Decoder Loss:  0.34188563
Encoder Loss:  0.033219803  || Decoder Loss:  0.033219803 Validation Decoder Loss:  0.34168085
Encoder Loss:  0.033207122  || Decoder Loss:  0.033207122 Validation Decoder Loss:  0.34148458
Encoder Loss:  0.033195335  || Decoder Loss:  0.033195335 Validation Decoder Loss:  0.3412968
Encoder Loss:  0.03318407  || Decoder Loss:  0.03318407 Validation Decoder Loss:  0.34111983
Encoder Loss:  0.033172973  || Decoder Loss:  0.033172973 Validation Decoder Loss:  0.34095216
Encoder Loss:  0.033161603  || Decoder Loss:  0.033161603 Validation Decoder Loss:  0.34078676
Encoder Loss:  0.03314974  || Decoder Loss:  0.03314974 Validation Decoder Loss:  0.34062886
Encoder Loss:  0.03313706  || Decoder Loss:  0.03313706 Validation Decoder Loss:  0.34048307
Encoder Loss:  0.033123422  || Decoder Loss:  0.033123422 Validation Decoder Loss:  0.34034756
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34034753
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_323 (Conv3D (None, 189, 10, 20, 1)    253       
_________________________________________________________________
dropout_673 (Dropout)        (None, 189, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_324 (Conv3D (None, 220, 11, 20, 1)    65        
_________________________________________________________________
reshape_124 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_476"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_225 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_675 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_226 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_225 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_677 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_226 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4209338  || Decoder Loss:  0.06676319 Validation Decoder Loss:  0.3676062
Encoder Loss:  0.41804227  || Decoder Loss:  0.06924877 Validation Decoder Loss:  0.36645308
Encoder Loss:  0.41329163  || Decoder Loss:  0.0733717 Validation Decoder Loss:  0.36480677
Encoder Loss:  0.40321323  || Decoder Loss:  0.082255885 Validation Decoder Loss:  0.36594883
Encoder Loss:  0.3651652  || Decoder Loss:  0.11742797 Validation Decoder Loss:  0.43943486
Encoder Loss:  0.14877614  || Decoder Loss:  0.39317894 Validation Decoder Loss:  0.88265246
Encoder Loss:  0.08686716  || Decoder Loss:  0.4102259 Validation Decoder Loss:  0.656671
Encoder Loss:  0.088415384  || Decoder Loss:  0.15698622 Validation Decoder Loss:  0.39902455
Encoder Loss:  0.08834302  || Decoder Loss:  0.05458913 Validation Decoder Loss:  0.35780895
Encoder Loss:  0.08686414  || Decoder Loss:  0.046583608 Validation Decoder Loss:  0.35005248
Encoder Loss:  0.08650132  || Decoder Loss:  0.04272246 Validation Decoder Loss:  0.34403163
Encoder Loss:  0.08501339  || Decoder Loss:  0.039792314 Validation Decoder Loss:  0.33980808
Encoder Loss:  0.08437157  || Decoder Loss:  0.03780032 Validation Decoder Loss:  0.33668447
Encoder Loss:  0.06579645  || Decoder Loss:  0.03657944 Validation Decoder Loss:  0.334707
Encoder Loss:  0.050892793  || Decoder Loss:  0.03601075 Validation Decoder Loss:  0.3333225
Encoder Loss:  0.050096236  || Decoder Loss:  0.03589464 Validation Decoder Loss:  0.3328439
Encoder Loss:  0.050042614  || Decoder Loss:  0.03566652 Validation Decoder Loss:  0.3324973
Encoder Loss:  0.050040647  || Decoder Loss:  0.03552962 Validation Decoder Loss:  0.33227032
Encoder Loss:  0.05004032  || Decoder Loss:  0.035453755 Validation Decoder Loss:  0.3321288
Encoder Loss:  0.050040215  || Decoder Loss:  0.03540931 Validation Decoder Loss:  0.33204082
Encoder Loss:  0.050039805  || Decoder Loss:  0.03537981 Validation Decoder Loss:  0.33198422
Encoder Loss:  0.050039906  || Decoder Loss:  0.03535868 Validation Decoder Loss:  0.3319552
Encoder Loss:  0.050041024  || Decoder Loss:  0.035341315 Validation Decoder Loss:  0.33194786
Encoder Loss:  0.050045077  || Decoder Loss:  0.035326216 Validation Decoder Loss:  0.33195102
Encoder Loss:  0.050046217  || Decoder Loss:  0.035312865 Validation Decoder Loss:  0.3319565
Encoder Loss:  0.05003863  || Decoder Loss:  0.035304014 Validation Decoder Loss:  0.3319375
Encoder Loss:  0.050038204  || Decoder Loss:  0.035291925 Validation Decoder Loss:  0.33193192
Encoder Loss:  0.050038274  || Decoder Loss:  0.03528132 Validation Decoder Loss:  0.33194155
Encoder Loss:  0.05003747  || Decoder Loss:  0.035271477 Validation Decoder Loss:  0.33194607
Encoder Loss:  0.050037082  || Decoder Loss:  0.035262413 Validation Decoder Loss:  0.33192334
Encoder Loss:  0.050036594  || Decoder Loss:  0.035254247 Validation Decoder Loss:  0.33188224
Encoder Loss:  0.050036088  || Decoder Loss:  0.035246335 Validation Decoder Loss:  0.3318354
Encoder Loss:  0.050036214  || Decoder Loss:  0.035238907 Validation Decoder Loss:  0.33180225
Encoder Loss:  0.050035354  || Decoder Loss:  0.03523203 Validation Decoder Loss:  0.33178493
Encoder Loss:  0.050034963  || Decoder Loss:  0.035225127 Validation Decoder Loss:  0.3317883
Encoder Loss:  0.050034314  || Decoder Loss:  0.0352186 Validation Decoder Loss:  0.3318049
Encoder Loss:  0.0500341  || Decoder Loss:  0.035211932 Validation Decoder Loss:  0.3318236
Encoder Loss:  0.050033733  || Decoder Loss:  0.035205554 Validation Decoder Loss:  0.3318496
Encoder Loss:  0.050033167  || Decoder Loss:  0.035199024 Validation Decoder Loss:  0.33187634
Encoder Loss:  0.050032854  || Decoder Loss:  0.035192434 Validation Decoder Loss:  0.33190596
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.331906
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_326 (Conv3D (None, 122, 5, 20, 1)     60        
_________________________________________________________________
dropout_679 (Dropout)        (None, 122, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_327 (Conv3D (None, 220, 11, 20, 1)    694       
_________________________________________________________________
reshape_125 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 754
Trainable params: 754
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_227 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_681 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_228 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_227 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_683 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_228 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1825265  || Decoder Loss:  0.11915049 Validation Decoder Loss:  0.3406936
Encoder Loss:  0.050277878  || Decoder Loss:  0.03611978 Validation Decoder Loss:  0.33334434
Encoder Loss:  0.0500852  || Decoder Loss:  0.034893576 Validation Decoder Loss:  0.33467692
Encoder Loss:  0.050081838  || Decoder Loss:  0.034826025 Validation Decoder Loss:  0.33461228
Encoder Loss:  0.050088316  || Decoder Loss:  0.034776997 Validation Decoder Loss:  0.33436006
Encoder Loss:  0.050088156  || Decoder Loss:  0.03472413 Validation Decoder Loss:  0.33430213
Encoder Loss:  0.050091065  || Decoder Loss:  0.03465798 Validation Decoder Loss:  0.33394736
Encoder Loss:  0.050074  || Decoder Loss:  0.034583613 Validation Decoder Loss:  0.33328477
Encoder Loss:  0.050074033  || Decoder Loss:  0.034530353 Validation Decoder Loss:  0.3332727
Encoder Loss:  0.050061032  || Decoder Loss:  0.034491178 Validation Decoder Loss:  0.33313742
Encoder Loss:  0.050049376  || Decoder Loss:  0.034457847 Validation Decoder Loss:  0.33320454
Encoder Loss:  0.050043322  || Decoder Loss:  0.0344637 Validation Decoder Loss:  0.3334033
Encoder Loss:  0.05004468  || Decoder Loss:  0.034506444 Validation Decoder Loss:  0.33426234
Encoder Loss:  0.050034586  || Decoder Loss:  0.03457806 Validation Decoder Loss:  0.33307138
Encoder Loss:  0.050069645  || Decoder Loss:  0.034615617 Validation Decoder Loss:  0.33260083
Encoder Loss:  0.050021257  || Decoder Loss:  0.034660626 Validation Decoder Loss:  0.33119345
Encoder Loss:  0.05001443  || Decoder Loss:  0.034766663 Validation Decoder Loss:  0.33090633
Encoder Loss:  0.050012726  || Decoder Loss:  0.034835823 Validation Decoder Loss:  0.32930094
Encoder Loss:  0.05001581  || Decoder Loss:  0.034857385 Validation Decoder Loss:  0.32983214
Encoder Loss:  0.05001314  || Decoder Loss:  0.034806296 Validation Decoder Loss:  0.32908294
Encoder Loss:  0.050010875  || Decoder Loss:  0.03470941 Validation Decoder Loss:  0.3280534
Encoder Loss:  0.050010096  || Decoder Loss:  0.034621798 Validation Decoder Loss:  0.3274681
Encoder Loss:  0.050015178  || Decoder Loss:  0.034534425 Validation Decoder Loss:  0.32681668
Encoder Loss:  0.050009828  || Decoder Loss:  0.03443916 Validation Decoder Loss:  0.32611725
Encoder Loss:  0.050006684  || Decoder Loss:  0.034366492 Validation Decoder Loss:  0.32603976
Encoder Loss:  0.05000887  || Decoder Loss:  0.034299105 Validation Decoder Loss:  0.32650363
Encoder Loss:  0.05000968  || Decoder Loss:  0.03425624 Validation Decoder Loss:  0.32621983
Encoder Loss:  0.050005727  || Decoder Loss:  0.034215022 Validation Decoder Loss:  0.32645047
Encoder Loss:  0.050007444  || Decoder Loss:  0.03418125 Validation Decoder Loss:  0.32666427
Encoder Loss:  0.05000578  || Decoder Loss:  0.034156285 Validation Decoder Loss:  0.3267573
Encoder Loss:  0.05000641  || Decoder Loss:  0.03413318 Validation Decoder Loss:  0.3271004
Encoder Loss:  0.05000532  || Decoder Loss:  0.03411491 Validation Decoder Loss:  0.32708296
Encoder Loss:  0.050004587  || Decoder Loss:  0.034099847 Validation Decoder Loss:  0.3272879
Encoder Loss:  0.050004732  || Decoder Loss:  0.03408657 Validation Decoder Loss:  0.3274194
Encoder Loss:  0.05000411  || Decoder Loss:  0.034075346 Validation Decoder Loss:  0.32751125
Encoder Loss:  0.050003447  || Decoder Loss:  0.034067806 Validation Decoder Loss:  0.32766193
Encoder Loss:  0.05000467  || Decoder Loss:  0.034049615 Validation Decoder Loss:  0.32812285
Encoder Loss:  0.050012447  || Decoder Loss:  0.03407551 Validation Decoder Loss:  0.32761967
Encoder Loss:  0.050002392  || Decoder Loss:  0.034053624 Validation Decoder Loss:  0.32793027
Encoder Loss:  0.05000206  || Decoder Loss:  0.034045827 Validation Decoder Loss:  0.32806227
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32806227
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_329 (Conv3D (None, 131, 10, 20, 1)    31        
_________________________________________________________________
dropout_685 (Dropout)        (None, 131, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_330 (Conv3D (None, 220, 11, 20, 1)    181       
_________________________________________________________________
reshape_126 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 212
Trainable params: 212
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_229 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_687 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_230 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_229 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_689 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_230 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08065809  || Decoder Loss:  0.08065809 Validation Decoder Loss:  0.34032783
Encoder Loss:  0.040371533  || Decoder Loss:  0.040371533 Validation Decoder Loss:  0.33331585
Encoder Loss:  0.035808474  || Decoder Loss:  0.035808474 Validation Decoder Loss:  0.3325471
Encoder Loss:  0.03541  || Decoder Loss:  0.03541 Validation Decoder Loss:  0.33223325
Encoder Loss:  0.035310343  || Decoder Loss:  0.035310343 Validation Decoder Loss:  0.33240637
Encoder Loss:  0.035241343  || Decoder Loss:  0.035241343 Validation Decoder Loss:  0.33296207
Encoder Loss:  0.03519213  || Decoder Loss:  0.03519213 Validation Decoder Loss:  0.33261847
Encoder Loss:  0.03513491  || Decoder Loss:  0.03513491 Validation Decoder Loss:  0.33296502
Encoder Loss:  0.035092775  || Decoder Loss:  0.035092775 Validation Decoder Loss:  0.33310983
Encoder Loss:  0.035047743  || Decoder Loss:  0.035047743 Validation Decoder Loss:  0.33325303
Encoder Loss:  0.035014216  || Decoder Loss:  0.035014216 Validation Decoder Loss:  0.33346048
Encoder Loss:  0.03497313  || Decoder Loss:  0.03497313 Validation Decoder Loss:  0.33330157
Encoder Loss:  0.034936316  || Decoder Loss:  0.034936316 Validation Decoder Loss:  0.33381462
Encoder Loss:  0.03490597  || Decoder Loss:  0.03490597 Validation Decoder Loss:  0.33353692
Encoder Loss:  0.03487871  || Decoder Loss:  0.03487871 Validation Decoder Loss:  0.33378637
Encoder Loss:  0.034852263  || Decoder Loss:  0.034852263 Validation Decoder Loss:  0.33399546
Encoder Loss:  0.034826502  || Decoder Loss:  0.034826502 Validation Decoder Loss:  0.33403578
Encoder Loss:  0.03480158  || Decoder Loss:  0.03480158 Validation Decoder Loss:  0.3339281
Encoder Loss:  0.03477787  || Decoder Loss:  0.03477787 Validation Decoder Loss:  0.33421052
Encoder Loss:  0.03475474  || Decoder Loss:  0.03475474 Validation Decoder Loss:  0.33420914
Encoder Loss:  0.034732237  || Decoder Loss:  0.034732237 Validation Decoder Loss:  0.33439666
Encoder Loss:  0.03470989  || Decoder Loss:  0.03470989 Validation Decoder Loss:  0.33466524
Encoder Loss:  0.03468774  || Decoder Loss:  0.03468774 Validation Decoder Loss:  0.33491504
Encoder Loss:  0.03466557  || Decoder Loss:  0.03466557 Validation Decoder Loss:  0.3351812
Encoder Loss:  0.03464362  || Decoder Loss:  0.03464362 Validation Decoder Loss:  0.33571586
Encoder Loss:  0.034620684  || Decoder Loss:  0.034620684 Validation Decoder Loss:  0.3363733
Encoder Loss:  0.03459811  || Decoder Loss:  0.03459811 Validation Decoder Loss:  0.3369076
Encoder Loss:  0.034574695  || Decoder Loss:  0.034574695 Validation Decoder Loss:  0.33745337
Encoder Loss:  0.03455017  || Decoder Loss:  0.03455017 Validation Decoder Loss:  0.3380314
Encoder Loss:  0.03452379  || Decoder Loss:  0.03452379 Validation Decoder Loss:  0.33865914
Encoder Loss:  0.034494184  || Decoder Loss:  0.034494184 Validation Decoder Loss:  0.33938304
Encoder Loss:  0.034459956  || Decoder Loss:  0.034459956 Validation Decoder Loss:  0.34025443
Encoder Loss:  0.034420498  || Decoder Loss:  0.034420498 Validation Decoder Loss:  0.34125936
Encoder Loss:  0.03437499  || Decoder Loss:  0.03437499 Validation Decoder Loss:  0.34234285
Encoder Loss:  0.034323458  || Decoder Loss:  0.034323458 Validation Decoder Loss:  0.3432966
Encoder Loss:  0.034270182  || Decoder Loss:  0.034270182 Validation Decoder Loss:  0.34390438
Encoder Loss:  0.034221347  || Decoder Loss:  0.034221347 Validation Decoder Loss:  0.34418076
Encoder Loss:  0.034179676  || Decoder Loss:  0.034179676 Validation Decoder Loss:  0.3442592
Encoder Loss:  0.034144484  || Decoder Loss:  0.034144484 Validation Decoder Loss:  0.34425855
Encoder Loss:  0.034114387  || Decoder Loss:  0.034114387 Validation Decoder Loss:  0.34423286
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34423286
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_332 (Conv3D (None, 117, 10, 20, 1)    325       
_________________________________________________________________
dropout_691 (Dropout)        (None, 117, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_333 (Conv3D (None, 220, 11, 20, 1)    209       
_________________________________________________________________
reshape_127 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 534
Trainable params: 534
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_488"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_231 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_693 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_232 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_231 (Conv2D (None, 2440, 20, 1)       22        
_________________________________________________________________
dropout_695 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_232 (Conv2D (None, 2607, 20, 1)       169       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.092757724  || Decoder Loss:  0.092757724 Validation Decoder Loss:  0.36079854
Encoder Loss:  0.061725564  || Decoder Loss:  0.061725564 Validation Decoder Loss:  0.33431542
Encoder Loss:  0.035224024  || Decoder Loss:  0.035224024 Validation Decoder Loss:  0.33047223
Encoder Loss:  0.03503501  || Decoder Loss:  0.03503501 Validation Decoder Loss:  0.33092472
Encoder Loss:  0.034987748  || Decoder Loss:  0.034987748 Validation Decoder Loss:  0.332178
Encoder Loss:  0.03496815  || Decoder Loss:  0.03496815 Validation Decoder Loss:  0.33311018
Encoder Loss:  0.034967076  || Decoder Loss:  0.034967076 Validation Decoder Loss:  0.33284187
Encoder Loss:  0.034973234  || Decoder Loss:  0.034973234 Validation Decoder Loss:  0.33293086
Encoder Loss:  0.03498047  || Decoder Loss:  0.03498047 Validation Decoder Loss:  0.33423066
Encoder Loss:  0.03495971  || Decoder Loss:  0.03495971 Validation Decoder Loss:  0.33134323
Encoder Loss:  0.034935597  || Decoder Loss:  0.034935597 Validation Decoder Loss:  0.33251643
Encoder Loss:  0.034921896  || Decoder Loss:  0.034921896 Validation Decoder Loss:  0.3308679
Encoder Loss:  0.03473083  || Decoder Loss:  0.03473083 Validation Decoder Loss:  0.33453566
Encoder Loss:  0.034674354  || Decoder Loss:  0.034674354 Validation Decoder Loss:  0.33426806
Encoder Loss:  0.034619033  || Decoder Loss:  0.034619033 Validation Decoder Loss:  0.33416978
Encoder Loss:  0.03456501  || Decoder Loss:  0.03456501 Validation Decoder Loss:  0.33401135
Encoder Loss:  0.03451438  || Decoder Loss:  0.03451438 Validation Decoder Loss:  0.33401543
Encoder Loss:  0.034468893  || Decoder Loss:  0.034468893 Validation Decoder Loss:  0.33404946
Encoder Loss:  0.03442958  || Decoder Loss:  0.03442958 Validation Decoder Loss:  0.33409303
Encoder Loss:  0.03439622  || Decoder Loss:  0.03439622 Validation Decoder Loss:  0.33413985
Encoder Loss:  0.034368  || Decoder Loss:  0.034368 Validation Decoder Loss:  0.33418638
Encoder Loss:  0.03434408  || Decoder Loss:  0.03434408 Validation Decoder Loss:  0.3342331
Encoder Loss:  0.034323834  || Decoder Loss:  0.034323834 Validation Decoder Loss:  0.33428085
Encoder Loss:  0.03430665  || Decoder Loss:  0.03430665 Validation Decoder Loss:  0.33432803
Encoder Loss:  0.03429194  || Decoder Loss:  0.03429194 Validation Decoder Loss:  0.3343758
Encoder Loss:  0.03427941  || Decoder Loss:  0.03427941 Validation Decoder Loss:  0.33442405
Encoder Loss:  0.03426868  || Decoder Loss:  0.03426868 Validation Decoder Loss:  0.33447814
Encoder Loss:  0.03425952  || Decoder Loss:  0.03425952 Validation Decoder Loss:  0.33453417
Encoder Loss:  0.03425166  || Decoder Loss:  0.03425166 Validation Decoder Loss:  0.33458474
Encoder Loss:  0.034244876  || Decoder Loss:  0.034244876 Validation Decoder Loss:  0.33462876
Encoder Loss:  0.034238968  || Decoder Loss:  0.034238968 Validation Decoder Loss:  0.3346666
Encoder Loss:  0.034233775  || Decoder Loss:  0.034233775 Validation Decoder Loss:  0.33469903
Encoder Loss:  0.034229178  || Decoder Loss:  0.034229178 Validation Decoder Loss:  0.3347263
Encoder Loss:  0.034225117  || Decoder Loss:  0.034225117 Validation Decoder Loss:  0.33474916
Encoder Loss:  0.03422142  || Decoder Loss:  0.03422142 Validation Decoder Loss:  0.3347683
Encoder Loss:  0.034218058  || Decoder Loss:  0.034218058 Validation Decoder Loss:  0.33478433
Encoder Loss:  0.03421496  || Decoder Loss:  0.03421496 Validation Decoder Loss:  0.33479762
Encoder Loss:  0.034212083  || Decoder Loss:  0.034212083 Validation Decoder Loss:  0.3348087
Encoder Loss:  0.034209467  || Decoder Loss:  0.034209467 Validation Decoder Loss:  0.33481774
Encoder Loss:  0.03420698  || Decoder Loss:  0.03420698 Validation Decoder Loss:  0.33482504
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33482504
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_335 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_697 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_336 (Conv3D (None, 220, 11, 20, 1)    466       
_________________________________________________________________
reshape_128 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_233 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_699 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_234 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_233 (Conv2D (None, 2460, 20, 1)       42        
_________________________________________________________________
dropout_701 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_234 (Conv2D (None, 2607, 20, 1)       149       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33797604  || Decoder Loss:  0.08399619 Validation Decoder Loss:  0.37004042
Encoder Loss:  0.3326882  || Decoder Loss:  0.086545125 Validation Decoder Loss:  0.37201458
Encoder Loss:  0.32670256  || Decoder Loss:  0.08943629 Validation Decoder Loss:  0.3740657
Encoder Loss:  0.32023388  || Decoder Loss:  0.09267805 Validation Decoder Loss:  0.37628257
Encoder Loss:  0.31335914  || Decoder Loss:  0.09633246 Validation Decoder Loss:  0.37873286
Encoder Loss:  0.30613223  || Decoder Loss:  0.1004576 Validation Decoder Loss:  0.38149264
Encoder Loss:  0.2985831  || Decoder Loss:  0.10510852 Validation Decoder Loss:  0.38467693
Encoder Loss:  0.29071632  || Decoder Loss:  0.11032503 Validation Decoder Loss:  0.38849598
Encoder Loss:  0.28249255  || Decoder Loss:  0.11603025 Validation Decoder Loss:  0.39369595
Encoder Loss:  0.27305052  || Decoder Loss:  0.117675655 Validation Decoder Loss:  0.46314812
Encoder Loss:  0.25953636  || Decoder Loss:  0.09972798 Validation Decoder Loss:  0.44433555
Encoder Loss:  0.24038787  || Decoder Loss:  0.054367308 Validation Decoder Loss:  0.38621813
Encoder Loss:  0.22580753  || Decoder Loss:  0.041262913 Validation Decoder Loss:  0.36899182
Encoder Loss:  0.21005698  || Decoder Loss:  0.037943315 Validation Decoder Loss:  0.35681713
Encoder Loss:  0.15908593  || Decoder Loss:  0.037188094 Validation Decoder Loss:  0.35171992
Encoder Loss:  0.05193823  || Decoder Loss:  0.037002325 Validation Decoder Loss:  0.34956884
Encoder Loss:  0.04879767  || Decoder Loss:  0.036905378 Validation Decoder Loss:  0.34837702
Encoder Loss:  0.04864501  || Decoder Loss:  0.036826953 Validation Decoder Loss:  0.34755155
Encoder Loss:  0.048569936  || Decoder Loss:  0.036754392 Validation Decoder Loss:  0.34688774
Encoder Loss:  0.04850149  || Decoder Loss:  0.036685273 Validation Decoder Loss:  0.34630945
Encoder Loss:  0.048551064  || Decoder Loss:  0.03661886 Validation Decoder Loss:  0.34578788
Encoder Loss:  0.048399433  || Decoder Loss:  0.036554307 Validation Decoder Loss:  0.34531364
Encoder Loss:  0.048432488  || Decoder Loss:  0.03649114 Validation Decoder Loss:  0.3448804
Encoder Loss:  0.048377804  || Decoder Loss:  0.036428727 Validation Decoder Loss:  0.34448427
Encoder Loss:  0.04827849  || Decoder Loss:  0.036366925 Validation Decoder Loss:  0.34412494
Encoder Loss:  0.04827067  || Decoder Loss:  0.036305558 Validation Decoder Loss:  0.34379983
Encoder Loss:  0.048238885  || Decoder Loss:  0.036244508 Validation Decoder Loss:  0.3435039
Encoder Loss:  0.048206907  || Decoder Loss:  0.036183383 Validation Decoder Loss:  0.34323746
Encoder Loss:  0.04863249  || Decoder Loss:  0.036124937 Validation Decoder Loss:  0.3430032
Encoder Loss:  0.04825449  || Decoder Loss:  0.036071654 Validation Decoder Loss:  0.34278947
Encoder Loss:  0.04812168  || Decoder Loss:  0.036011387 Validation Decoder Loss:  0.34259734
Encoder Loss:  0.048113912  || Decoder Loss:  0.035951566 Validation Decoder Loss:  0.3424275
Encoder Loss:  0.048107337  || Decoder Loss:  0.035893053 Validation Decoder Loss:  0.3422749
Encoder Loss:  0.047861166  || Decoder Loss:  0.035836153 Validation Decoder Loss:  0.342134
Encoder Loss:  0.047600895  || Decoder Loss:  0.035799637 Validation Decoder Loss:  0.3420167
Encoder Loss:  0.047499537  || Decoder Loss:  0.035834417 Validation Decoder Loss:  0.34192878
Encoder Loss:  0.047493964  || Decoder Loss:  0.035851944 Validation Decoder Loss:  0.3418609
Encoder Loss:  0.04749181  || Decoder Loss:  0.0358458 Validation Decoder Loss:  0.3417833
Encoder Loss:  0.04748963  || Decoder Loss:  0.03583583 Validation Decoder Loss:  0.34168708
Encoder Loss:  0.047487468  || Decoder Loss:  0.035825904 Validation Decoder Loss:  0.34158283
Model: siamese_net_lr_0.0005231390456603412 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34158283
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_338 (Conv3D (None, 71, 10, 20, 1)     17        
_________________________________________________________________
dropout_703 (Dropout)        (None, 71, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_339 (Conv3D (None, 220, 11, 20, 1)    21        
_________________________________________________________________
reshape_129 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 38
Trainable params: 38
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_235 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_705 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_236 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_235 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_707 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_236 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20493877  || Decoder Loss:  0.038430046 Validation Decoder Loss:  0.3327782
Encoder Loss:  0.05005217  || Decoder Loss:  0.03419425 Validation Decoder Loss:  0.33252245
Encoder Loss:  0.05004111  || Decoder Loss:  0.034098282 Validation Decoder Loss:  0.33247
Encoder Loss:  0.050033703  || Decoder Loss:  0.03403439 Validation Decoder Loss:  0.33252186
Encoder Loss:  0.050030958  || Decoder Loss:  0.03398865 Validation Decoder Loss:  0.33261257
Encoder Loss:  0.05003223  || Decoder Loss:  0.033949196 Validation Decoder Loss:  0.33271098
Encoder Loss:  0.050027426  || Decoder Loss:  0.033915397 Validation Decoder Loss:  0.33302417
Encoder Loss:  0.05002349  || Decoder Loss:  0.033892997 Validation Decoder Loss:  0.33310544
Encoder Loss:  0.050024427  || Decoder Loss:  0.033889458 Validation Decoder Loss:  0.3326428
Encoder Loss:  0.05001872  || Decoder Loss:  0.033877853 Validation Decoder Loss:  0.33310047
Encoder Loss:  0.05001444  || Decoder Loss:  0.033850636 Validation Decoder Loss:  0.3332504
Encoder Loss:  0.050015677  || Decoder Loss:  0.0338324 Validation Decoder Loss:  0.33291027
Encoder Loss:  0.05001477  || Decoder Loss:  0.03381748 Validation Decoder Loss:  0.33296713
Encoder Loss:  0.050013997  || Decoder Loss:  0.03381031 Validation Decoder Loss:  0.33239993
Encoder Loss:  0.05001324  || Decoder Loss:  0.03380151 Validation Decoder Loss:  0.33214355
Encoder Loss:  0.05001627  || Decoder Loss:  0.033808637 Validation Decoder Loss:  0.3324894
Encoder Loss:  0.05001562  || Decoder Loss:  0.033789944 Validation Decoder Loss:  0.33264107
Encoder Loss:  0.050013147  || Decoder Loss:  0.033782672 Validation Decoder Loss:  0.33226678
Encoder Loss:  0.05001366  || Decoder Loss:  0.033788882 Validation Decoder Loss:  0.33168152
Encoder Loss:  0.050012723  || Decoder Loss:  0.033746585 Validation Decoder Loss:  0.3324185
Encoder Loss:  0.05001342  || Decoder Loss:  0.0337441 Validation Decoder Loss:  0.33231524
Encoder Loss:  0.050014473  || Decoder Loss:  0.033724945 Validation Decoder Loss:  0.3322373
Encoder Loss:  0.05001262  || Decoder Loss:  0.03372694 Validation Decoder Loss:  0.332248
Encoder Loss:  0.050011497  || Decoder Loss:  0.033727564 Validation Decoder Loss:  0.3323685
Encoder Loss:  0.050012656  || Decoder Loss:  0.03370009 Validation Decoder Loss:  0.33232713
Encoder Loss:  0.050011076  || Decoder Loss:  0.03369917 Validation Decoder Loss:  0.33221394
Encoder Loss:  0.050012708  || Decoder Loss:  0.033687 Validation Decoder Loss:  0.33214378
Encoder Loss:  0.050010517  || Decoder Loss:  0.033667136 Validation Decoder Loss:  0.33236027
Encoder Loss:  0.050011173  || Decoder Loss:  0.033682387 Validation Decoder Loss:  0.3315792
Encoder Loss:  0.050011143  || Decoder Loss:  0.03367375 Validation Decoder Loss:  0.3322928
Encoder Loss:  0.050012425  || Decoder Loss:  0.03364716 Validation Decoder Loss:  0.33230805
Encoder Loss:  0.050011516  || Decoder Loss:  0.033646926 Validation Decoder Loss:  0.33184367
Encoder Loss:  0.05001209  || Decoder Loss:  0.033641156 Validation Decoder Loss:  0.3316393
Encoder Loss:  0.05001301  || Decoder Loss:  0.03361925 Validation Decoder Loss:  0.33153784
Encoder Loss:  0.050009903  || Decoder Loss:  0.03362977 Validation Decoder Loss:  0.3318319
Encoder Loss:  0.050011445  || Decoder Loss:  0.033607546 Validation Decoder Loss:  0.33135867
Encoder Loss:  0.050010487  || Decoder Loss:  0.033621117 Validation Decoder Loss:  0.3316862
Encoder Loss:  0.05001079  || Decoder Loss:  0.03358617 Validation Decoder Loss:  0.33163908
Encoder Loss:  0.050010037  || Decoder Loss:  0.0335883 Validation Decoder Loss:  0.33118626
Encoder Loss:  0.05001136  || Decoder Loss:  0.033616137 Validation Decoder Loss:  0.33171952
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33171952
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_341 (Conv3D (None, 138, 10, 20, 1)    451       
_________________________________________________________________
dropout_709 (Dropout)        (None, 138, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_342 (Conv3D (None, 220, 11, 20, 1)    167       
_________________________________________________________________
reshape_130 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 618
Trainable params: 618
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_500"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_237 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_711 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_238 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_237 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_713 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_238 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09593283  || Decoder Loss:  0.09593283 Validation Decoder Loss:  0.34959298
Encoder Loss:  0.04614168  || Decoder Loss:  0.04614168 Validation Decoder Loss:  0.35031325
Encoder Loss:  0.04094216  || Decoder Loss:  0.04094216 Validation Decoder Loss:  0.35029718
Encoder Loss:  0.038988497  || Decoder Loss:  0.038988497 Validation Decoder Loss:  0.3491593
Encoder Loss:  0.037802193  || Decoder Loss:  0.037802193 Validation Decoder Loss:  0.34813407
Encoder Loss:  0.03690025  || Decoder Loss:  0.03690025 Validation Decoder Loss:  0.34717873
Encoder Loss:  0.036197845  || Decoder Loss:  0.036197845 Validation Decoder Loss:  0.34626523
Encoder Loss:  0.035648808  || Decoder Loss:  0.035648808 Validation Decoder Loss:  0.34540573
Encoder Loss:  0.035220217  || Decoder Loss:  0.035220217 Validation Decoder Loss:  0.34461537
Encoder Loss:  0.034884203  || Decoder Loss:  0.034884203 Validation Decoder Loss:  0.34389627
Encoder Loss:  0.034617215  || Decoder Loss:  0.034617215 Validation Decoder Loss:  0.34323782
Encoder Loss:  0.034401286  || Decoder Loss:  0.034401286 Validation Decoder Loss:  0.34262526
Encoder Loss:  0.03422435  || Decoder Loss:  0.03422435 Validation Decoder Loss:  0.3420465
Encoder Loss:  0.034079053  || Decoder Loss:  0.034079053 Validation Decoder Loss:  0.34149492
Encoder Loss:  0.033960834  || Decoder Loss:  0.033960834 Validation Decoder Loss:  0.34097236
Encoder Loss:  0.033866078  || Decoder Loss:  0.033866078 Validation Decoder Loss:  0.3404895
Encoder Loss:  0.033791088  || Decoder Loss:  0.033791088 Validation Decoder Loss:  0.3400619
Encoder Loss:  0.033731647  || Decoder Loss:  0.033731647 Validation Decoder Loss:  0.33970335
Encoder Loss:  0.03368375  || Decoder Loss:  0.03368375 Validation Decoder Loss:  0.33941948
Encoder Loss:  0.033643946  || Decoder Loss:  0.033643946 Validation Decoder Loss:  0.33919117
Encoder Loss:  0.033609804  || Decoder Loss:  0.033609804 Validation Decoder Loss:  0.3389957
Encoder Loss:  0.033579595  || Decoder Loss:  0.033579595 Validation Decoder Loss:  0.3388381
Encoder Loss:  0.033552215  || Decoder Loss:  0.033552215 Validation Decoder Loss:  0.3387143
Encoder Loss:  0.033526786  || Decoder Loss:  0.033526786 Validation Decoder Loss:  0.3386141
Encoder Loss:  0.033502802  || Decoder Loss:  0.033502802 Validation Decoder Loss:  0.33853173
Encoder Loss:  0.03347988  || Decoder Loss:  0.03347988 Validation Decoder Loss:  0.338465
Encoder Loss:  0.033457816  || Decoder Loss:  0.033457816 Validation Decoder Loss:  0.3384099
Encoder Loss:  0.033436462  || Decoder Loss:  0.033436462 Validation Decoder Loss:  0.338363
Encoder Loss:  0.03341574  || Decoder Loss:  0.03341574 Validation Decoder Loss:  0.33832192
Encoder Loss:  0.03339562  || Decoder Loss:  0.03339562 Validation Decoder Loss:  0.3382818
Encoder Loss:  0.033376053  || Decoder Loss:  0.033376053 Validation Decoder Loss:  0.3382458
Encoder Loss:  0.03335832  || Decoder Loss:  0.03335832 Validation Decoder Loss:  0.33821446
Encoder Loss:  0.033338904  || Decoder Loss:  0.033338904 Validation Decoder Loss:  0.33819282
Encoder Loss:  0.033320922  || Decoder Loss:  0.033320922 Validation Decoder Loss:  0.33817694
Encoder Loss:  0.033303604  || Decoder Loss:  0.033303604 Validation Decoder Loss:  0.33816725
Encoder Loss:  0.033286903  || Decoder Loss:  0.033286903 Validation Decoder Loss:  0.33816493
Encoder Loss:  0.03327072  || Decoder Loss:  0.03327072 Validation Decoder Loss:  0.33816946
Encoder Loss:  0.03325507  || Decoder Loss:  0.03325507 Validation Decoder Loss:  0.33817905
Encoder Loss:  0.033239923  || Decoder Loss:  0.033239923 Validation Decoder Loss:  0.33819276
Encoder Loss:  0.033225134  || Decoder Loss:  0.033225134 Validation Decoder Loss:  0.3382101
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33821008
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_344 (Conv3D (None, 207, 10, 20, 1)    289       
_________________________________________________________________
dropout_715 (Dropout)        (None, 207, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_345 (Conv3D (None, 220, 11, 20, 1)    29        
_________________________________________________________________
reshape_131 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_239 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_717 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_240 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_239 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_719 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_240 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389843  || Decoder Loss:  0.049389843 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.049389843  || Decoder Loss:  0.049389843 Validation Decoder Loss:  0.35484934
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.04938984  || Decoder Loss:  0.04938984 Validation Decoder Loss:  0.3548493
Encoder Loss:  0.049389835  || Decoder Loss:  0.049389835 Validation Decoder Loss:  0.35484934
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3548493
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_347 (Conv3D (None, 220, 5, 20, 1)     95        
_________________________________________________________________
dropout_721 (Dropout)        (None, 220, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_348 (Conv3D (None, 220, 11, 20, 1)    4         
_________________________________________________________________
reshape_132 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_241 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_723 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_242 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_241 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_725 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_242 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03849853  || Decoder Loss:  0.03849853 Validation Decoder Loss:  0.33051988
Encoder Loss:  0.034125544  || Decoder Loss:  0.034125544 Validation Decoder Loss:  0.32827085
Encoder Loss:  0.03375183  || Decoder Loss:  0.03375183 Validation Decoder Loss:  0.3284803
Encoder Loss:  0.033476  || Decoder Loss:  0.033476 Validation Decoder Loss:  0.32846433
Encoder Loss:  0.03329912  || Decoder Loss:  0.03329912 Validation Decoder Loss:  0.32851142
Encoder Loss:  0.03316926  || Decoder Loss:  0.03316926 Validation Decoder Loss:  0.3287613
Encoder Loss:  0.033071686  || Decoder Loss:  0.033071686 Validation Decoder Loss:  0.32909042
Encoder Loss:  0.03299342  || Decoder Loss:  0.03299342 Validation Decoder Loss:  0.32942075
Encoder Loss:  0.032925654  || Decoder Loss:  0.032925654 Validation Decoder Loss:  0.329709
Encoder Loss:  0.03286846  || Decoder Loss:  0.03286846 Validation Decoder Loss:  0.32994863
Encoder Loss:  0.0328212  || Decoder Loss:  0.0328212 Validation Decoder Loss:  0.3301466
Encoder Loss:  0.032781657  || Decoder Loss:  0.032781657 Validation Decoder Loss:  0.33031535
Encoder Loss:  0.03274888  || Decoder Loss:  0.03274888 Validation Decoder Loss:  0.33046687
Encoder Loss:  0.032723933  || Decoder Loss:  0.032723933 Validation Decoder Loss:  0.33059204
Encoder Loss:  0.03270614  || Decoder Loss:  0.03270614 Validation Decoder Loss:  0.33069158
Encoder Loss:  0.03269322  || Decoder Loss:  0.03269322 Validation Decoder Loss:  0.33077472
Encoder Loss:  0.03268345  || Decoder Loss:  0.03268345 Validation Decoder Loss:  0.33084708
Encoder Loss:  0.032675687  || Decoder Loss:  0.032675687 Validation Decoder Loss:  0.3309117
Encoder Loss:  0.03266921  || Decoder Loss:  0.03266921 Validation Decoder Loss:  0.33097044
Encoder Loss:  0.03266357  || Decoder Loss:  0.03266357 Validation Decoder Loss:  0.33102417
Encoder Loss:  0.032658562  || Decoder Loss:  0.032658562 Validation Decoder Loss:  0.33107328
Encoder Loss:  0.03265401  || Decoder Loss:  0.03265401 Validation Decoder Loss:  0.3311182
Encoder Loss:  0.03264976  || Decoder Loss:  0.03264976 Validation Decoder Loss:  0.33115903
Encoder Loss:  0.032645836  || Decoder Loss:  0.032645836 Validation Decoder Loss:  0.33119604
Encoder Loss:  0.032642182  || Decoder Loss:  0.032642182 Validation Decoder Loss:  0.33122948
Encoder Loss:  0.032638714  || Decoder Loss:  0.032638714 Validation Decoder Loss:  0.33125958
Encoder Loss:  0.032635443  || Decoder Loss:  0.032635443 Validation Decoder Loss:  0.33128664
Encoder Loss:  0.03263239  || Decoder Loss:  0.03263239 Validation Decoder Loss:  0.33131093
Encoder Loss:  0.032629486  || Decoder Loss:  0.032629486 Validation Decoder Loss:  0.33133277
Encoder Loss:  0.032626793  || Decoder Loss:  0.032626793 Validation Decoder Loss:  0.3313524
Encoder Loss:  0.03262422  || Decoder Loss:  0.03262422 Validation Decoder Loss:  0.33137015
Encoder Loss:  0.032621793  || Decoder Loss:  0.032621793 Validation Decoder Loss:  0.3313862
Encoder Loss:  0.032619566  || Decoder Loss:  0.032619566 Validation Decoder Loss:  0.33140075
Encoder Loss:  0.03261751  || Decoder Loss:  0.03261751 Validation Decoder Loss:  0.33141404
Encoder Loss:  0.032615572  || Decoder Loss:  0.032615572 Validation Decoder Loss:  0.33142623
Encoder Loss:  0.03261377  || Decoder Loss:  0.03261377 Validation Decoder Loss:  0.33143738
Encoder Loss:  0.03261211  || Decoder Loss:  0.03261211 Validation Decoder Loss:  0.33144763
Encoder Loss:  0.032610565  || Decoder Loss:  0.032610565 Validation Decoder Loss:  0.33145705
Encoder Loss:  0.032609172  || Decoder Loss:  0.032609172 Validation Decoder Loss:  0.33146578
Encoder Loss:  0.032607842  || Decoder Loss:  0.032607842 Validation Decoder Loss:  0.33147383
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33147383
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_350 (Conv3D (None, 104, 5, 20, 1)     42        
_________________________________________________________________
dropout_727 (Dropout)        (None, 104, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_351 (Conv3D (None, 220, 11, 20, 1)    820       
_________________________________________________________________
reshape_133 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 862
Trainable params: 862
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_512"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_243 (Conv2D)          (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_729 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_244 (Conv2D)          (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_243 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_731 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_244 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36319184  || Decoder Loss:  0.105680674 Validation Decoder Loss:  0.38308877
Encoder Loss:  0.35547924  || Decoder Loss:  0.11016546 Validation Decoder Loss:  0.38778636
Encoder Loss:  0.34666085  || Decoder Loss:  0.11588864 Validation Decoder Loss:  0.39326185
Encoder Loss:  0.3357808  || Decoder Loss:  0.124273434 Validation Decoder Loss:  0.40171787
Encoder Loss:  0.3101191  || Decoder Loss:  0.15202612 Validation Decoder Loss:  0.7136294
Encoder Loss:  0.11233915  || Decoder Loss:  0.45609015 Validation Decoder Loss:  0.9790903
Encoder Loss:  0.103736  || Decoder Loss:  0.24198826 Validation Decoder Loss:  0.39619678
Encoder Loss:  0.099234745  || Decoder Loss:  0.07925239 Validation Decoder Loss:  0.33840775
Encoder Loss:  0.093145415  || Decoder Loss:  0.046510134 Validation Decoder Loss:  0.33642697
Encoder Loss:  0.0788701  || Decoder Loss:  0.04698045 Validation Decoder Loss:  0.3342102
Encoder Loss:  0.052500423  || Decoder Loss:  0.04588279 Validation Decoder Loss:  0.3340612
Encoder Loss:  0.050817553  || Decoder Loss:  0.04374187 Validation Decoder Loss:  0.33031213
Encoder Loss:  0.050707098  || Decoder Loss:  0.04249222 Validation Decoder Loss:  0.32988232
Encoder Loss:  0.050445884  || Decoder Loss:  0.040649533 Validation Decoder Loss:  0.32992828
Encoder Loss:  0.05041497  || Decoder Loss:  0.037596468 Validation Decoder Loss:  0.32879904
Encoder Loss:  0.050325498  || Decoder Loss:  0.034257095 Validation Decoder Loss:  0.32567286
Encoder Loss:  0.050199885  || Decoder Loss:  0.033766314 Validation Decoder Loss:  0.32561004
Encoder Loss:  0.050189048  || Decoder Loss:  0.033703204 Validation Decoder Loss:  0.32562163
Encoder Loss:  0.05018199  || Decoder Loss:  0.033711094 Validation Decoder Loss:  0.3257597
Encoder Loss:  0.0501748  || Decoder Loss:  0.033752803 Validation Decoder Loss:  0.32593066
Encoder Loss:  0.05017223  || Decoder Loss:  0.033810463 Validation Decoder Loss:  0.32613564
Encoder Loss:  0.05015796  || Decoder Loss:  0.033886537 Validation Decoder Loss:  0.32638383
Encoder Loss:  0.050148293  || Decoder Loss:  0.033973716 Validation Decoder Loss:  0.3266214
Encoder Loss:  0.050139904  || Decoder Loss:  0.03406711 Validation Decoder Loss:  0.32687807
Encoder Loss:  0.050137725  || Decoder Loss:  0.034166798 Validation Decoder Loss:  0.3271216
Encoder Loss:  0.050132312  || Decoder Loss:  0.03426507 Validation Decoder Loss:  0.3273592
Encoder Loss:  0.050125707  || Decoder Loss:  0.034368165 Validation Decoder Loss:  0.32760674
Encoder Loss:  0.05011672  || Decoder Loss:  0.034469884 Validation Decoder Loss:  0.32781264
Encoder Loss:  0.050112367  || Decoder Loss:  0.03456524 Validation Decoder Loss:  0.32804185
Encoder Loss:  0.050106674  || Decoder Loss:  0.034652874 Validation Decoder Loss:  0.32822803
Encoder Loss:  0.050102286  || Decoder Loss:  0.03472978 Validation Decoder Loss:  0.3284197
Encoder Loss:  0.050097417  || Decoder Loss:  0.0347958 Validation Decoder Loss:  0.32859808
Encoder Loss:  0.050095387  || Decoder Loss:  0.034848794 Validation Decoder Loss:  0.32876188
Encoder Loss:  0.05009064  || Decoder Loss:  0.034890294 Validation Decoder Loss:  0.32888955
Encoder Loss:  0.050087854  || Decoder Loss:  0.034914874 Validation Decoder Loss:  0.32901844
Encoder Loss:  0.050085545  || Decoder Loss:  0.03494363 Validation Decoder Loss:  0.32914358
Encoder Loss:  0.05008378  || Decoder Loss:  0.034947462 Validation Decoder Loss:  0.32922462
Encoder Loss:  0.050079495  || Decoder Loss:  0.034948897 Validation Decoder Loss:  0.32935476
Encoder Loss:  0.050078467  || Decoder Loss:  0.03494095 Validation Decoder Loss:  0.3294692
Encoder Loss:  0.05007057  || Decoder Loss:  0.034931198 Validation Decoder Loss:  0.32958117
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32958117
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_353 (Conv3D (None, 200, 5, 20, 1)     138       
_________________________________________________________________
dropout_733 (Dropout)        (None, 200, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_354 (Conv3D (None, 220, 11, 20, 1)    148       
_________________________________________________________________
reshape_134 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 286
Trainable params: 286
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_245 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_735 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_246 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_245 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_737 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_246 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054035813  || Decoder Loss:  0.054035813 Validation Decoder Loss:  0.35338894
Encoder Loss:  0.039380096  || Decoder Loss:  0.039380096 Validation Decoder Loss:  0.3333582
Encoder Loss:  0.03475337  || Decoder Loss:  0.03475337 Validation Decoder Loss:  0.33304596
Encoder Loss:  0.034376804  || Decoder Loss:  0.034376804 Validation Decoder Loss:  0.3336494
Encoder Loss:  0.034204073  || Decoder Loss:  0.034204073 Validation Decoder Loss:  0.33410835
Encoder Loss:  0.03410604  || Decoder Loss:  0.03410604 Validation Decoder Loss:  0.33453923
Encoder Loss:  0.034042533  || Decoder Loss:  0.034042533 Validation Decoder Loss:  0.33490866
Encoder Loss:  0.033997457  || Decoder Loss:  0.033997457 Validation Decoder Loss:  0.33524108
Encoder Loss:  0.03396283  || Decoder Loss:  0.03396283 Validation Decoder Loss:  0.33556956
Encoder Loss:  0.033935398  || Decoder Loss:  0.033935398 Validation Decoder Loss:  0.3358888
Encoder Loss:  0.033911895  || Decoder Loss:  0.033911895 Validation Decoder Loss:  0.3362239
Encoder Loss:  0.03389192  || Decoder Loss:  0.03389192 Validation Decoder Loss:  0.33660263
Encoder Loss:  0.03387447  || Decoder Loss:  0.03387447 Validation Decoder Loss:  0.33705395
Encoder Loss:  0.03385873  || Decoder Loss:  0.03385873 Validation Decoder Loss:  0.33760583
Encoder Loss:  0.033843912  || Decoder Loss:  0.033843912 Validation Decoder Loss:  0.33827165
Encoder Loss:  0.0338295  || Decoder Loss:  0.0338295 Validation Decoder Loss:  0.33903667
Encoder Loss:  0.03381485  || Decoder Loss:  0.03381485 Validation Decoder Loss:  0.33986318
Encoder Loss:  0.033799395  || Decoder Loss:  0.033799395 Validation Decoder Loss:  0.34071225
Encoder Loss:  0.033783022  || Decoder Loss:  0.033783022 Validation Decoder Loss:  0.3415578
Encoder Loss:  0.03376557  || Decoder Loss:  0.03376557 Validation Decoder Loss:  0.3423865
Encoder Loss:  0.033747207  || Decoder Loss:  0.033747207 Validation Decoder Loss:  0.3431914
Encoder Loss:  0.033728134  || Decoder Loss:  0.033728134 Validation Decoder Loss:  0.34396762
Encoder Loss:  0.033708543  || Decoder Loss:  0.033708543 Validation Decoder Loss:  0.3447113
Encoder Loss:  0.03368865  || Decoder Loss:  0.03368865 Validation Decoder Loss:  0.34541875
Encoder Loss:  0.03366866  || Decoder Loss:  0.03366866 Validation Decoder Loss:  0.34608686
Encoder Loss:  0.03364875  || Decoder Loss:  0.03364875 Validation Decoder Loss:  0.34671307
Encoder Loss:  0.033629607  || Decoder Loss:  0.033629607 Validation Decoder Loss:  0.34726965
Encoder Loss:  0.033610415  || Decoder Loss:  0.033610415 Validation Decoder Loss:  0.34779468
Encoder Loss:  0.03359242  || Decoder Loss:  0.03359242 Validation Decoder Loss:  0.3482833
Encoder Loss:  0.03357767  || Decoder Loss:  0.03357767 Validation Decoder Loss:  0.3486995
Encoder Loss:  0.033560053  || Decoder Loss:  0.033560053 Validation Decoder Loss:  0.34905323
Encoder Loss:  0.033546094  || Decoder Loss:  0.033546094 Validation Decoder Loss:  0.34940535
Encoder Loss:  0.033532187  || Decoder Loss:  0.033532187 Validation Decoder Loss:  0.34972075
Encoder Loss:  0.0335191  || Decoder Loss:  0.0335191 Validation Decoder Loss:  0.35000712
Encoder Loss:  0.033506673  || Decoder Loss:  0.033506673 Validation Decoder Loss:  0.35026467
Encoder Loss:  0.033494856  || Decoder Loss:  0.033494856 Validation Decoder Loss:  0.35049516
Encoder Loss:  0.033483714  || Decoder Loss:  0.033483714 Validation Decoder Loss:  0.35069948
Encoder Loss:  0.03347319  || Decoder Loss:  0.03347319 Validation Decoder Loss:  0.35087967
Encoder Loss:  0.033463217  || Decoder Loss:  0.033463217 Validation Decoder Loss:  0.351037
Encoder Loss:  0.03345386  || Decoder Loss:  0.03345386 Validation Decoder Loss:  0.35117298
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.351173
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_356 (Conv3D (None, 142, 5, 20, 1)     17        
_________________________________________________________________
dropout_739 (Dropout)        (None, 142, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_357 (Conv3D (None, 220, 11, 20, 1)    238       
_________________________________________________________________
reshape_135 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 255
Trainable params: 255
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_247 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_741 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_248 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_247 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_743 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_248 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21366692  || Decoder Loss:  0.075940944 Validation Decoder Loss:  0.34319326
Encoder Loss:  0.050066795  || Decoder Loss:  0.04034369 Validation Decoder Loss:  0.3392325
Encoder Loss:  0.05002609  || Decoder Loss:  0.036851723 Validation Decoder Loss:  0.3384825
Encoder Loss:  0.05002384  || Decoder Loss:  0.03550709 Validation Decoder Loss:  0.33818752
Encoder Loss:  0.050028097  || Decoder Loss:  0.035025887 Validation Decoder Loss:  0.33854604
Encoder Loss:  0.05002995  || Decoder Loss:  0.034825116 Validation Decoder Loss:  0.3385325
Encoder Loss:  0.05006713  || Decoder Loss:  0.034713663 Validation Decoder Loss:  0.33813518
Encoder Loss:  0.050020352  || Decoder Loss:  0.034652434 Validation Decoder Loss:  0.33807313
Encoder Loss:  0.05006145  || Decoder Loss:  0.034559816 Validation Decoder Loss:  0.33734828
Encoder Loss:  0.050033107  || Decoder Loss:  0.034545965 Validation Decoder Loss:  0.33730948
Encoder Loss:  0.050155725  || Decoder Loss:  0.034506213 Validation Decoder Loss:  0.33773753
Encoder Loss:  0.050031148  || Decoder Loss:  0.03447064 Validation Decoder Loss:  0.33694968
Encoder Loss:  0.050045  || Decoder Loss:  0.03445431 Validation Decoder Loss:  0.33732143
Encoder Loss:  0.050025363  || Decoder Loss:  0.0344347 Validation Decoder Loss:  0.3382635
Encoder Loss:  0.050120126  || Decoder Loss:  0.034378592 Validation Decoder Loss:  0.33860156
Encoder Loss:  0.050026923  || Decoder Loss:  0.03433176 Validation Decoder Loss:  0.33803993
Encoder Loss:  0.050096508  || Decoder Loss:  0.034313194 Validation Decoder Loss:  0.3387661
Encoder Loss:  0.050109014  || Decoder Loss:  0.0343412 Validation Decoder Loss:  0.33894902
Encoder Loss:  0.050025616  || Decoder Loss:  0.034285173 Validation Decoder Loss:  0.33883414
Encoder Loss:  0.05003646  || Decoder Loss:  0.03428165 Validation Decoder Loss:  0.3390508
Encoder Loss:  0.050060347  || Decoder Loss:  0.034282427 Validation Decoder Loss:  0.3396518
Encoder Loss:  0.050024234  || Decoder Loss:  0.034302592 Validation Decoder Loss:  0.34028322
Encoder Loss:  0.05002534  || Decoder Loss:  0.03431345 Validation Decoder Loss:  0.34079432
Encoder Loss:  0.050202638  || Decoder Loss:  0.034466073 Validation Decoder Loss:  0.3410294
Encoder Loss:  0.050013065  || Decoder Loss:  0.03444225 Validation Decoder Loss:  0.34053987
Encoder Loss:  0.050017104  || Decoder Loss:  0.034415293 Validation Decoder Loss:  0.34042305
Encoder Loss:  0.050019577  || Decoder Loss:  0.034416944 Validation Decoder Loss:  0.340868
Encoder Loss:  0.050128266  || Decoder Loss:  0.03451286 Validation Decoder Loss:  0.33996373
Encoder Loss:  0.050015382  || Decoder Loss:  0.034456804 Validation Decoder Loss:  0.33976358
Encoder Loss:  0.05009416  || Decoder Loss:  0.034537088 Validation Decoder Loss:  0.33935517
Encoder Loss:  0.05001964  || Decoder Loss:  0.034486257 Validation Decoder Loss:  0.33880413
Encoder Loss:  0.05004093  || Decoder Loss:  0.0345021 Validation Decoder Loss:  0.33896455
Encoder Loss:  0.0500201  || Decoder Loss:  0.034500208 Validation Decoder Loss:  0.3389868
Encoder Loss:  0.050176546  || Decoder Loss:  0.03465601 Validation Decoder Loss:  0.33731824
Encoder Loss:  0.05000911  || Decoder Loss:  0.03458048 Validation Decoder Loss:  0.3376782
Encoder Loss:  0.05001337  || Decoder Loss:  0.034560904 Validation Decoder Loss:  0.3374542
Encoder Loss:  0.050023302  || Decoder Loss:  0.03456421 Validation Decoder Loss:  0.33742446
Encoder Loss:  0.050065614  || Decoder Loss:  0.03462789 Validation Decoder Loss:  0.33661085
Encoder Loss:  0.0500122  || Decoder Loss:  0.034593523 Validation Decoder Loss:  0.33670264
Encoder Loss:  0.05001821  || Decoder Loss:  0.03458835 Validation Decoder Loss:  0.33652824
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33652827
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_359 (Conv3D (None, 76, 5, 20, 1)      14        
_________________________________________________________________
dropout_745 (Dropout)        (None, 76, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_360 (Conv3D (None, 220, 11, 20, 1)    1016      
_________________________________________________________________
reshape_136 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 1,030
Trainable params: 1,030
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_249 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_747 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_250 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_249 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_749 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_250 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10644167  || Decoder Loss:  0.095683105 Validation Decoder Loss:  0.3747302
Encoder Loss:  0.060870003  || Decoder Loss:  0.04968113 Validation Decoder Loss:  0.34713703
Encoder Loss:  0.04685072  || Decoder Loss:  0.0375674 Validation Decoder Loss:  0.3446963
Encoder Loss:  0.040015038  || Decoder Loss:  0.037356008 Validation Decoder Loss:  0.3425654
Encoder Loss:  0.03745038  || Decoder Loss:  0.036907 Validation Decoder Loss:  0.34148985
Encoder Loss:  0.03678134  || Decoder Loss:  0.036215976 Validation Decoder Loss:  0.33986455
Encoder Loss:  0.03578175  || Decoder Loss:  0.035179544 Validation Decoder Loss:  0.33663192
Encoder Loss:  0.034730673  || Decoder Loss:  0.034084827 Validation Decoder Loss:  0.33352667
Encoder Loss:  0.034385353  || Decoder Loss:  0.03372468 Validation Decoder Loss:  0.33279675
Encoder Loss:  0.034317266  || Decoder Loss:  0.033654466 Validation Decoder Loss:  0.33294562
Encoder Loss:  0.03427424  || Decoder Loss:  0.033609297 Validation Decoder Loss:  0.33309078
Encoder Loss:  0.034234945  || Decoder Loss:  0.033568762 Validation Decoder Loss:  0.333194
Encoder Loss:  0.03419695  || Decoder Loss:  0.033529352 Validation Decoder Loss:  0.333287
Encoder Loss:  0.03415905  || Decoder Loss:  0.03348978 Validation Decoder Loss:  0.3333662
Encoder Loss:  0.034119714  || Decoder Loss:  0.033449415 Validation Decoder Loss:  0.33340383
Encoder Loss:  0.034080647  || Decoder Loss:  0.03340857 Validation Decoder Loss:  0.33339432
Encoder Loss:  0.034041  || Decoder Loss:  0.033367816 Validation Decoder Loss:  0.33334595
Encoder Loss:  0.034002982  || Decoder Loss:  0.033328433 Validation Decoder Loss:  0.3332819
Encoder Loss:  0.033967722  || Decoder Loss:  0.033291765 Validation Decoder Loss:  0.33322468
Encoder Loss:  0.033935737  || Decoder Loss:  0.0332584 Validation Decoder Loss:  0.33318746
Encoder Loss:  0.03390782  || Decoder Loss:  0.0332296 Validation Decoder Loss:  0.3331638
Encoder Loss:  0.03388384  || Decoder Loss:  0.03320475 Validation Decoder Loss:  0.33315843
Encoder Loss:  0.033863246  || Decoder Loss:  0.03318332 Validation Decoder Loss:  0.33316368
Encoder Loss:  0.03384517  || Decoder Loss:  0.03316453 Validation Decoder Loss:  0.3331685
Encoder Loss:  0.033829164  || Decoder Loss:  0.03314779 Validation Decoder Loss:  0.3331776
Encoder Loss:  0.033814237  || Decoder Loss:  0.033132225 Validation Decoder Loss:  0.33318487
Encoder Loss:  0.0338002  || Decoder Loss:  0.033117674 Validation Decoder Loss:  0.33319515
Encoder Loss:  0.03378686  || Decoder Loss:  0.033103816 Validation Decoder Loss:  0.33320653
Encoder Loss:  0.03377414  || Decoder Loss:  0.033090606 Validation Decoder Loss:  0.3332115
Encoder Loss:  0.033761896  || Decoder Loss:  0.033077937 Validation Decoder Loss:  0.33321407
Encoder Loss:  0.033750106  || Decoder Loss:  0.033065666 Validation Decoder Loss:  0.33321837
Encoder Loss:  0.033738777  || Decoder Loss:  0.033053916 Validation Decoder Loss:  0.33321565
Encoder Loss:  0.03372784  || Decoder Loss:  0.033042558 Validation Decoder Loss:  0.33321643
Encoder Loss:  0.033717293  || Decoder Loss:  0.033031564 Validation Decoder Loss:  0.33321807
Encoder Loss:  0.03370702  || Decoder Loss:  0.03302092 Validation Decoder Loss:  0.33321735
Encoder Loss:  0.033697132  || Decoder Loss:  0.033010658 Validation Decoder Loss:  0.333217
Encoder Loss:  0.033687573  || Decoder Loss:  0.03300075 Validation Decoder Loss:  0.33321592
Encoder Loss:  0.0336783  || Decoder Loss:  0.032991186 Validation Decoder Loss:  0.3332103
Encoder Loss:  0.03366944  || Decoder Loss:  0.03298193 Validation Decoder Loss:  0.33321467
Encoder Loss:  0.033660743  || Decoder Loss:  0.032972988 Validation Decoder Loss:  0.3332091
Model: siamese_net_lr_0.00021999840280807398 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3332091
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_362 (Conv3D (None, 207, 10, 20, 1)    163       
_________________________________________________________________
dropout_751 (Dropout)        (None, 207, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_363 (Conv3D (None, 220, 11, 20, 1)    29        
_________________________________________________________________
reshape_137 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_251 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_753 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_252 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_251 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_755 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_252 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20806126  || Decoder Loss:  0.07406552 Validation Decoder Loss:  0.3305632
Encoder Loss:  0.051146794  || Decoder Loss:  0.034835987 Validation Decoder Loss:  0.32958478
Encoder Loss:  0.05012131  || Decoder Loss:  0.034653626 Validation Decoder Loss:  0.32967404
Encoder Loss:  0.050098583  || Decoder Loss:  0.034599498 Validation Decoder Loss:  0.3295487
Encoder Loss:  0.05008471  || Decoder Loss:  0.034499403 Validation Decoder Loss:  0.32918936
Encoder Loss:  0.050077654  || Decoder Loss:  0.034173008 Validation Decoder Loss:  0.329984
Encoder Loss:  0.050074495  || Decoder Loss:  0.033916537 Validation Decoder Loss:  0.32941753
Encoder Loss:  0.05007335  || Decoder Loss:  0.03383356 Validation Decoder Loss:  0.3282954
Encoder Loss:  0.050070543  || Decoder Loss:  0.033745993 Validation Decoder Loss:  0.3277014
Encoder Loss:  0.0500676  || Decoder Loss:  0.033659805 Validation Decoder Loss:  0.32698825
Encoder Loss:  0.05006678  || Decoder Loss:  0.03357726 Validation Decoder Loss:  0.32654175
Encoder Loss:  0.050068174  || Decoder Loss:  0.033503152 Validation Decoder Loss:  0.3260085
Encoder Loss:  0.05006598  || Decoder Loss:  0.033433244 Validation Decoder Loss:  0.32555193
Encoder Loss:  0.05005901  || Decoder Loss:  0.033354472 Validation Decoder Loss:  0.32539147
Encoder Loss:  0.050085064  || Decoder Loss:  0.033388127 Validation Decoder Loss:  0.32638997
Encoder Loss:  0.05007063  || Decoder Loss:  0.033260714 Validation Decoder Loss:  0.32584295
Encoder Loss:  0.050058126  || Decoder Loss:  0.03326149 Validation Decoder Loss:  0.3258227
Encoder Loss:  0.050056204  || Decoder Loss:  0.033239212 Validation Decoder Loss:  0.3258759
Encoder Loss:  0.050112568  || Decoder Loss:  0.033263877 Validation Decoder Loss:  0.326747
Encoder Loss:  0.050049853  || Decoder Loss:  0.033304706 Validation Decoder Loss:  0.32672793
Encoder Loss:  0.050055366  || Decoder Loss:  0.033302683 Validation Decoder Loss:  0.32677853
Encoder Loss:  0.05008456  || Decoder Loss:  0.033245414 Validation Decoder Loss:  0.32580426
Encoder Loss:  0.05004578  || Decoder Loss:  0.033301692 Validation Decoder Loss:  0.3269729
Encoder Loss:  0.0500597  || Decoder Loss:  0.033241313 Validation Decoder Loss:  0.3271806
Encoder Loss:  0.050049555  || Decoder Loss:  0.033263728 Validation Decoder Loss:  0.32704467
Encoder Loss:  0.0500568  || Decoder Loss:  0.03314286 Validation Decoder Loss:  0.32638198
Encoder Loss:  0.050046865  || Decoder Loss:  0.03312753 Validation Decoder Loss:  0.32630524
Encoder Loss:  0.050045896  || Decoder Loss:  0.03311892 Validation Decoder Loss:  0.3262809
Encoder Loss:  0.050046492  || Decoder Loss:  0.033116404 Validation Decoder Loss:  0.3264045
Encoder Loss:  0.050045375  || Decoder Loss:  0.033136133 Validation Decoder Loss:  0.32620203
Encoder Loss:  0.05004389  || Decoder Loss:  0.033097044 Validation Decoder Loss:  0.3263066
Encoder Loss:  0.050037336  || Decoder Loss:  0.03307225 Validation Decoder Loss:  0.32648665
Encoder Loss:  0.0500366  || Decoder Loss:  0.033082277 Validation Decoder Loss:  0.32637244
Encoder Loss:  0.050052606  || Decoder Loss:  0.033089694 Validation Decoder Loss:  0.32730842
Encoder Loss:  0.05003789  || Decoder Loss:  0.033015087 Validation Decoder Loss:  0.3263166
Encoder Loss:  0.050038848  || Decoder Loss:  0.03306816 Validation Decoder Loss:  0.32601827
Encoder Loss:  0.05004818  || Decoder Loss:  0.033038307 Validation Decoder Loss:  0.3270652
Encoder Loss:  0.050042197  || Decoder Loss:  0.033063576 Validation Decoder Loss:  0.3272065
Encoder Loss:  0.050036106  || Decoder Loss:  0.0330493 Validation Decoder Loss:  0.32612333
Encoder Loss:  0.050039247  || Decoder Loss:  0.03299657 Validation Decoder Loss:  0.32635534
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3263554
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_365 (Conv3D (None, 209, 10, 20, 1)    41        
_________________________________________________________________
dropout_757 (Dropout)        (None, 209, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_366 (Conv3D (None, 220, 11, 20, 1)    25        
_________________________________________________________________
reshape_138 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_253 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_759 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_254 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_253 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_761 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_254 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25966573  || Decoder Loss:  0.03852287 Validation Decoder Loss:  0.3350929
Encoder Loss:  0.05074685  || Decoder Loss:  0.034295704 Validation Decoder Loss:  0.32953206
Encoder Loss:  0.050451655  || Decoder Loss:  0.03353214 Validation Decoder Loss:  0.3293184
Encoder Loss:  0.050237373  || Decoder Loss:  0.03330422 Validation Decoder Loss:  0.32993
Encoder Loss:  0.050172146  || Decoder Loss:  0.033158343 Validation Decoder Loss:  0.33034885
Encoder Loss:  0.050092187  || Decoder Loss:  0.0330425 Validation Decoder Loss:  0.33026427
Encoder Loss:  0.050074905  || Decoder Loss:  0.03295349 Validation Decoder Loss:  0.32999444
Encoder Loss:  0.050091032  || Decoder Loss:  0.032889675 Validation Decoder Loss:  0.32969242
Encoder Loss:  0.050306268  || Decoder Loss:  0.032842997 Validation Decoder Loss:  0.3295921
Encoder Loss:  0.050049923  || Decoder Loss:  0.032805838 Validation Decoder Loss:  0.32945752
Encoder Loss:  0.050169062  || Decoder Loss:  0.03277667 Validation Decoder Loss:  0.32930624
Encoder Loss:  0.050061826  || Decoder Loss:  0.03275169 Validation Decoder Loss:  0.32922542
Encoder Loss:  0.050052647  || Decoder Loss:  0.032729723 Validation Decoder Loss:  0.32912236
Encoder Loss:  0.05004597  || Decoder Loss:  0.032710228 Validation Decoder Loss:  0.3290224
Encoder Loss:  0.050042853  || Decoder Loss:  0.032693654 Validation Decoder Loss:  0.32890242
Encoder Loss:  0.050040767  || Decoder Loss:  0.0326792 Validation Decoder Loss:  0.32880282
Encoder Loss:  0.050049555  || Decoder Loss:  0.03266597 Validation Decoder Loss:  0.32869405
Encoder Loss:  0.05003657  || Decoder Loss:  0.032654483 Validation Decoder Loss:  0.32858264
Encoder Loss:  0.050173413  || Decoder Loss:  0.032643672 Validation Decoder Loss:  0.32847604
Encoder Loss:  0.050035413  || Decoder Loss:  0.03263484 Validation Decoder Loss:  0.32837138
Encoder Loss:  0.050034262  || Decoder Loss:  0.032626435 Validation Decoder Loss:  0.3282785
Encoder Loss:  0.05027356  || Decoder Loss:  0.03261905 Validation Decoder Loss:  0.32820284
Encoder Loss:  0.050037406  || Decoder Loss:  0.03261225 Validation Decoder Loss:  0.32812536
Encoder Loss:  0.050039396  || Decoder Loss:  0.032605886 Validation Decoder Loss:  0.32806522
Encoder Loss:  0.05003848  || Decoder Loss:  0.032600317 Validation Decoder Loss:  0.3279982
Encoder Loss:  0.050115965  || Decoder Loss:  0.032595504 Validation Decoder Loss:  0.32795104
Encoder Loss:  0.05004444  || Decoder Loss:  0.032591015 Validation Decoder Loss:  0.32789114
Encoder Loss:  0.050052848  || Decoder Loss:  0.032586623 Validation Decoder Loss:  0.32783622
Encoder Loss:  0.05005404  || Decoder Loss:  0.03258304 Validation Decoder Loss:  0.3278
Encoder Loss:  0.05007809  || Decoder Loss:  0.03257973 Validation Decoder Loss:  0.3277542
Encoder Loss:  0.050037503  || Decoder Loss:  0.032576606 Validation Decoder Loss:  0.3277082
Encoder Loss:  0.050136086  || Decoder Loss:  0.032573994 Validation Decoder Loss:  0.327667
Encoder Loss:  0.050042767  || Decoder Loss:  0.032571577 Validation Decoder Loss:  0.32763714
Encoder Loss:  0.050039478  || Decoder Loss:  0.032568906 Validation Decoder Loss:  0.32760155
Encoder Loss:  0.050049912  || Decoder Loss:  0.032566525 Validation Decoder Loss:  0.32756954
Encoder Loss:  0.050036665  || Decoder Loss:  0.03256484 Validation Decoder Loss:  0.3275354
Encoder Loss:  0.050036497  || Decoder Loss:  0.032562826 Validation Decoder Loss:  0.32751325
Encoder Loss:  0.050044175  || Decoder Loss:  0.03256124 Validation Decoder Loss:  0.32747436
Encoder Loss:  0.050141286  || Decoder Loss:  0.03255992 Validation Decoder Loss:  0.32745412
Encoder Loss:  0.05003579  || Decoder Loss:  0.032558072 Validation Decoder Loss:  0.32743984
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32743984
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_368 (Conv3D (None, 213, 10, 20, 1)    301       
_________________________________________________________________
dropout_763 (Dropout)        (None, 213, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_369 (Conv3D (None, 220, 11, 20, 1)    17        
_________________________________________________________________
reshape_139 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_255 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_765 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_256 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_255 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_767 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_256 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37325087  || Decoder Loss:  0.06448438 Validation Decoder Loss:  0.361813
Encoder Loss:  0.08788934  || Decoder Loss:  0.043309506 Validation Decoder Loss:  0.3361587
Encoder Loss:  0.055215035  || Decoder Loss:  0.036202826 Validation Decoder Loss:  0.32581884
Encoder Loss:  0.05021552  || Decoder Loss:  0.033837434 Validation Decoder Loss:  0.32654497
Encoder Loss:  0.05008559  || Decoder Loss:  0.03366051 Validation Decoder Loss:  0.32690063
Encoder Loss:  0.049988832  || Decoder Loss:  0.033641607 Validation Decoder Loss:  0.32746136
Encoder Loss:  0.04968424  || Decoder Loss:  0.03363688 Validation Decoder Loss:  0.3280143
Encoder Loss:  0.049409814  || Decoder Loss:  0.033631887 Validation Decoder Loss:  0.32871118
Encoder Loss:  0.048944708  || Decoder Loss:  0.033613697 Validation Decoder Loss:  0.32908377
Encoder Loss:  0.04869323  || Decoder Loss:  0.033579644 Validation Decoder Loss:  0.32878238
Encoder Loss:  0.04871018  || Decoder Loss:  0.033549592 Validation Decoder Loss:  0.3285006
Encoder Loss:  0.048727106  || Decoder Loss:  0.033515498 Validation Decoder Loss:  0.32804912
Encoder Loss:  0.048706554  || Decoder Loss:  0.033475492 Validation Decoder Loss:  0.32768503
Encoder Loss:  0.048685517  || Decoder Loss:  0.033438805 Validation Decoder Loss:  0.32737178
Encoder Loss:  0.048702475  || Decoder Loss:  0.033398062 Validation Decoder Loss:  0.3269955
Encoder Loss:  0.048653565  || Decoder Loss:  0.03336281 Validation Decoder Loss:  0.32670033
Encoder Loss:  0.048677932  || Decoder Loss:  0.033321682 Validation Decoder Loss:  0.32685357
Encoder Loss:  0.04864066  || Decoder Loss:  0.03329664 Validation Decoder Loss:  0.326447
Encoder Loss:  0.048646346  || Decoder Loss:  0.033268515 Validation Decoder Loss:  0.32676715
Encoder Loss:  0.048625436  || Decoder Loss:  0.03325632 Validation Decoder Loss:  0.32586643
Encoder Loss:  0.048634015  || Decoder Loss:  0.03324591 Validation Decoder Loss:  0.3257668
Encoder Loss:  0.048619725  || Decoder Loss:  0.033228826 Validation Decoder Loss:  0.3263071
Encoder Loss:  0.04861961  || Decoder Loss:  0.03323582 Validation Decoder Loss:  0.32594728
Encoder Loss:  0.04859448  || Decoder Loss:  0.03323278 Validation Decoder Loss:  0.3263436
Encoder Loss:  0.04861626  || Decoder Loss:  0.033251204 Validation Decoder Loss:  0.32551807
Encoder Loss:  0.048591394  || Decoder Loss:  0.03325013 Validation Decoder Loss:  0.32641625
Encoder Loss:  0.048600823  || Decoder Loss:  0.03326075 Validation Decoder Loss:  0.32669142
Encoder Loss:  0.048615232  || Decoder Loss:  0.03326747 Validation Decoder Loss:  0.32629177
Encoder Loss:  0.04856448  || Decoder Loss:  0.03326622 Validation Decoder Loss:  0.32555813
Encoder Loss:  0.048552796  || Decoder Loss:  0.03329776 Validation Decoder Loss:  0.32626367
Encoder Loss:  0.048547555  || Decoder Loss:  0.033343084 Validation Decoder Loss:  0.3262725
Encoder Loss:  0.048559763  || Decoder Loss:  0.03335785 Validation Decoder Loss:  0.3271113
Encoder Loss:  0.04855517  || Decoder Loss:  0.033355683 Validation Decoder Loss:  0.32746214
Encoder Loss:  0.048546012  || Decoder Loss:  0.033361148 Validation Decoder Loss:  0.32724643
Encoder Loss:  0.048571438  || Decoder Loss:  0.03336189 Validation Decoder Loss:  0.32732472
Encoder Loss:  0.048537873  || Decoder Loss:  0.033346787 Validation Decoder Loss:  0.32754248
Encoder Loss:  0.048531618  || Decoder Loss:  0.033361834 Validation Decoder Loss:  0.3274284
Encoder Loss:  0.048529204  || Decoder Loss:  0.033369806 Validation Decoder Loss:  0.3282052
Encoder Loss:  0.048533157  || Decoder Loss:  0.033366956 Validation Decoder Loss:  0.32798266
Encoder Loss:  0.04857414  || Decoder Loss:  0.03333857 Validation Decoder Loss:  0.32797235
Model: siamese_net_lr_0.0006983608271483714 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32797235
Model: "sequential_538"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_371 (Conv3D (None, 217, 10, 20, 1)    57        
_________________________________________________________________
dropout_769 (Dropout)        (None, 217, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_372 (Conv3D (None, 220, 11, 20, 1)    9         
_________________________________________________________________
reshape_140 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_257 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_771 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_258 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_257 (Conv2D (None, 2480, 20, 1)       62        
_________________________________________________________________
dropout_773 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_258 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.112577446  || Decoder Loss:  0.04056634 Validation Decoder Loss:  0.34370494
Encoder Loss:  0.041113667  || Decoder Loss:  0.03621611 Validation Decoder Loss:  0.33455378
Encoder Loss:  0.039738048  || Decoder Loss:  0.034356225 Validation Decoder Loss:  0.3364086
Encoder Loss:  0.03941068  || Decoder Loss:  0.033780836 Validation Decoder Loss:  0.33578378
Encoder Loss:  0.039020155  || Decoder Loss:  0.033287436 Validation Decoder Loss:  0.33414602
Encoder Loss:  0.03882551  || Decoder Loss:  0.033051852 Validation Decoder Loss:  0.3329907
Encoder Loss:  0.03872706  || Decoder Loss:  0.032952644 Validation Decoder Loss:  0.33211032
Encoder Loss:  0.038662106  || Decoder Loss:  0.032916047 Validation Decoder Loss:  0.3323846
Encoder Loss:  0.038605828  || Decoder Loss:  0.032851174 Validation Decoder Loss:  0.33218563
Encoder Loss:  0.03858787  || Decoder Loss:  0.03279472 Validation Decoder Loss:  0.33237475
Encoder Loss:  0.03859154  || Decoder Loss:  0.032763254 Validation Decoder Loss:  0.3322275
Encoder Loss:  0.038526203  || Decoder Loss:  0.03272815 Validation Decoder Loss:  0.33252567
Encoder Loss:  0.03852712  || Decoder Loss:  0.032691244 Validation Decoder Loss:  0.33235613
Encoder Loss:  0.038474657  || Decoder Loss:  0.032654565 Validation Decoder Loss:  0.33255708
Encoder Loss:  0.038461853  || Decoder Loss:  0.03263084 Validation Decoder Loss:  0.33256134
Encoder Loss:  0.038441837  || Decoder Loss:  0.032599848 Validation Decoder Loss:  0.33256495
Encoder Loss:  0.038401283  || Decoder Loss:  0.032560144 Validation Decoder Loss:  0.33271396
Encoder Loss:  0.038390998  || Decoder Loss:  0.032521904 Validation Decoder Loss:  0.3326698
Encoder Loss:  0.03835176  || Decoder Loss:  0.03249644 Validation Decoder Loss:  0.33266056
Encoder Loss:  0.03834379  || Decoder Loss:  0.032471977 Validation Decoder Loss:  0.33294407
Encoder Loss:  0.03832214  || Decoder Loss:  0.03244736 Validation Decoder Loss:  0.3329166
Encoder Loss:  0.0383369  || Decoder Loss:  0.032420024 Validation Decoder Loss:  0.33280015
Encoder Loss:  0.038298436  || Decoder Loss:  0.03239932 Validation Decoder Loss:  0.33304366
Encoder Loss:  0.038312085  || Decoder Loss:  0.03238323 Validation Decoder Loss:  0.33292907
Encoder Loss:  0.038272634  || Decoder Loss:  0.03236738 Validation Decoder Loss:  0.33299372
Encoder Loss:  0.038301524  || Decoder Loss:  0.032349683 Validation Decoder Loss:  0.33297685
Encoder Loss:  0.038246427  || Decoder Loss:  0.032330755 Validation Decoder Loss:  0.333096
Encoder Loss:  0.038239732  || Decoder Loss:  0.03232159 Validation Decoder Loss:  0.333093
Encoder Loss:  0.038239256  || Decoder Loss:  0.032308806 Validation Decoder Loss:  0.33308044
Encoder Loss:  0.038220227  || Decoder Loss:  0.032299697 Validation Decoder Loss:  0.33311456
Encoder Loss:  0.038327787  || Decoder Loss:  0.03228894 Validation Decoder Loss:  0.33309424
Encoder Loss:  0.038200118  || Decoder Loss:  0.032276604 Validation Decoder Loss:  0.33310154
Encoder Loss:  0.038201477  || Decoder Loss:  0.03226571 Validation Decoder Loss:  0.33309376
Encoder Loss:  0.03820374  || Decoder Loss:  0.032254208 Validation Decoder Loss:  0.33309758
Encoder Loss:  0.03818279  || Decoder Loss:  0.032245427 Validation Decoder Loss:  0.33301258
Encoder Loss:  0.038197607  || Decoder Loss:  0.032235578 Validation Decoder Loss:  0.33306468
Encoder Loss:  0.03818625  || Decoder Loss:  0.03222867 Validation Decoder Loss:  0.3331574
Encoder Loss:  0.03819088  || Decoder Loss:  0.03221747 Validation Decoder Loss:  0.33316284
Encoder Loss:  0.038162466  || Decoder Loss:  0.032206092 Validation Decoder Loss:  0.33291507
Encoder Loss:  0.038157698  || Decoder Loss:  0.032200366 Validation Decoder Loss:  0.33311
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33311003
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_374 (Conv3D (None, 214, 10, 20, 1)    51        
_________________________________________________________________
dropout_775 (Dropout)        (None, 214, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_375 (Conv3D (None, 220, 11, 20, 1)    15        
_________________________________________________________________
reshape_141 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_259 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_777 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_260 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_259 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_779 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_260 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37715608  || Decoder Loss:  0.043536197 Validation Decoder Loss:  0.3550683
Encoder Loss:  0.37651813  || Decoder Loss:  0.043551408 Validation Decoder Loss:  0.35514343
Encoder Loss:  0.37592804  || Decoder Loss:  0.043512553 Validation Decoder Loss:  0.35512078
Encoder Loss:  0.37528226  || Decoder Loss:  0.043431792 Validation Decoder Loss:  0.35496974
Encoder Loss:  0.3743669  || Decoder Loss:  0.04331206 Validation Decoder Loss:  0.35462618
Encoder Loss:  0.3724917  || Decoder Loss:  0.043151334 Validation Decoder Loss:  0.35397536
Encoder Loss:  0.36359352  || Decoder Loss:  0.04296092 Validation Decoder Loss:  0.3528549
Encoder Loss:  0.18677166  || Decoder Loss:  0.0427479 Validation Decoder Loss:  0.35271943
Encoder Loss:  0.04919922  || Decoder Loss:  0.04182807 Validation Decoder Loss:  0.34796113
Encoder Loss:  0.048708826  || Decoder Loss:  0.04093224 Validation Decoder Loss:  0.34662393
Encoder Loss:  0.048562214  || Decoder Loss:  0.04024265 Validation Decoder Loss:  0.34660494
Encoder Loss:  0.048398796  || Decoder Loss:  0.039627727 Validation Decoder Loss:  0.34618247
Encoder Loss:  0.048269976  || Decoder Loss:  0.03880801 Validation Decoder Loss:  0.3449403
Encoder Loss:  0.04807997  || Decoder Loss:  0.037645873 Validation Decoder Loss:  0.34290826
Encoder Loss:  0.047854915  || Decoder Loss:  0.036264136 Validation Decoder Loss:  0.34044915
Encoder Loss:  0.047676615  || Decoder Loss:  0.03515105 Validation Decoder Loss:  0.33855087
Encoder Loss:  0.04758945  || Decoder Loss:  0.034584098 Validation Decoder Loss:  0.3379808
Encoder Loss:  0.047542676  || Decoder Loss:  0.03428634 Validation Decoder Loss:  0.33822337
Encoder Loss:  0.04750775  || Decoder Loss:  0.034073908 Validation Decoder Loss:  0.33794892
Encoder Loss:  0.04749361  || Decoder Loss:  0.03394771 Validation Decoder Loss:  0.33758557
Encoder Loss:  0.04747845  || Decoder Loss:  0.033866253 Validation Decoder Loss:  0.33738965
Encoder Loss:  0.04752255  || Decoder Loss:  0.033809453 Validation Decoder Loss:  0.33725727
Encoder Loss:  0.047462597  || Decoder Loss:  0.03376727 Validation Decoder Loss:  0.33716977
Encoder Loss:  0.04747888  || Decoder Loss:  0.033741593 Validation Decoder Loss:  0.3370978
Encoder Loss:  0.047452744  || Decoder Loss:  0.033706456 Validation Decoder Loss:  0.33706585
Encoder Loss:  0.047448616  || Decoder Loss:  0.033681348 Validation Decoder Loss:  0.3370303
Encoder Loss:  0.04744658  || Decoder Loss:  0.033662423 Validation Decoder Loss:  0.33699852
Encoder Loss:  0.04743663  || Decoder Loss:  0.033645336 Validation Decoder Loss:  0.336991
Encoder Loss:  0.047435187  || Decoder Loss:  0.03363057 Validation Decoder Loss:  0.3369788
Encoder Loss:  0.047435  || Decoder Loss:  0.03361915 Validation Decoder Loss:  0.33697206
Encoder Loss:  0.047432523  || Decoder Loss:  0.03360816 Validation Decoder Loss:  0.33697057
Encoder Loss:  0.047441002  || Decoder Loss:  0.03359879 Validation Decoder Loss:  0.33696795
Encoder Loss:  0.047451057  || Decoder Loss:  0.03359193 Validation Decoder Loss:  0.33696657
Encoder Loss:  0.047426518  || Decoder Loss:  0.033584226 Validation Decoder Loss:  0.33697468
Encoder Loss:  0.047431074  || Decoder Loss:  0.03357715 Validation Decoder Loss:  0.3369801
Encoder Loss:  0.04745174  || Decoder Loss:  0.033572637 Validation Decoder Loss:  0.33698404
Encoder Loss:  0.047476735  || Decoder Loss:  0.033569366 Validation Decoder Loss:  0.33699048
Encoder Loss:  0.047443412  || Decoder Loss:  0.033564255 Validation Decoder Loss:  0.33700404
Encoder Loss:  0.047530122  || Decoder Loss:  0.033560902 Validation Decoder Loss:  0.33701968
Encoder Loss:  0.047430106  || Decoder Loss:  0.033558246 Validation Decoder Loss:  0.33703136
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33703136
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_377 (Conv3D (None, 80, 5, 20, 1)      18        
_________________________________________________________________
dropout_781 (Dropout)        (None, 80, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_378 (Conv3D (None, 220, 11, 20, 1)    988       
_________________________________________________________________
reshape_142 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 1,006
Trainable params: 1,006
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_261 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_783 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_262 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_261 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_785 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_262 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36293954  || Decoder Loss:  0.091131434 Validation Decoder Loss:  0.36924583
Encoder Loss:  0.3618026  || Decoder Loss:  0.09181153 Validation Decoder Loss:  0.36984134
Encoder Loss:  0.36044154  || Decoder Loss:  0.09262844 Validation Decoder Loss:  0.37051553
Encoder Loss:  0.35899094  || Decoder Loss:  0.093503125 Validation Decoder Loss:  0.37121212
Encoder Loss:  0.35749957  || Decoder Loss:  0.094406456 Validation Decoder Loss:  0.37191352
Encoder Loss:  0.35597965  || Decoder Loss:  0.09532985 Validation Decoder Loss:  0.37261665
Encoder Loss:  0.35443303  || Decoder Loss:  0.096271 Validation Decoder Loss:  0.37331986
Encoder Loss:  0.35285848  || Decoder Loss:  0.097229175 Validation Decoder Loss:  0.37402222
Encoder Loss:  0.3512541  || Decoder Loss:  0.09820385 Validation Decoder Loss:  0.37472355
Encoder Loss:  0.3496177  || Decoder Loss:  0.09919409 Validation Decoder Loss:  0.37542337
Encoder Loss:  0.3479471  || Decoder Loss:  0.10019844 Validation Decoder Loss:  0.3761208
Encoder Loss:  0.3462397  || Decoder Loss:  0.10121477 Validation Decoder Loss:  0.37681407
Encoder Loss:  0.34449297  || Decoder Loss:  0.10223983 Validation Decoder Loss:  0.37750036
Encoder Loss:  0.34270424  || Decoder Loss:  0.103268966 Validation Decoder Loss:  0.37817502
Encoder Loss:  0.34087035  || Decoder Loss:  0.104295425 Validation Decoder Loss:  0.37883115
Encoder Loss:  0.33898795  || Decoder Loss:  0.10530934 Validation Decoder Loss:  0.3794579
Encoder Loss:  0.33705333  || Decoder Loss:  0.10629615 Validation Decoder Loss:  0.38003904
Encoder Loss:  0.33506233  || Decoder Loss:  0.107234076 Validation Decoder Loss:  0.3805494
Encoder Loss:  0.33300975  || Decoder Loss:  0.10808937 Validation Decoder Loss:  0.3809492
Encoder Loss:  0.33088973  || Decoder Loss:  0.10880787 Validation Decoder Loss:  0.3811728
Encoder Loss:  0.32869455  || Decoder Loss:  0.10929798 Validation Decoder Loss:  0.38110614
Encoder Loss:  0.32641357  || Decoder Loss:  0.10939373 Validation Decoder Loss:  0.38053465
Encoder Loss:  0.32403013  || Decoder Loss:  0.10876273 Validation Decoder Loss:  0.37900883
Encoder Loss:  0.32151264  || Decoder Loss:  0.10663478 Validation Decoder Loss:  0.37542123
Encoder Loss:  0.3187803  || Decoder Loss:  0.100752555 Validation Decoder Loss:  0.36627367
Encoder Loss:  0.3154977  || Decoder Loss:  0.08105425 Validation Decoder Loss:  0.34020734
Encoder Loss:  0.31151107  || Decoder Loss:  0.04310634 Validation Decoder Loss:  0.34135365
Encoder Loss:  0.30852985  || Decoder Loss:  0.039845917 Validation Decoder Loss:  0.36210138
Encoder Loss:  0.30547136  || Decoder Loss:  0.03835903 Validation Decoder Loss:  0.34571585
Encoder Loss:  0.30229846  || Decoder Loss:  0.037967894 Validation Decoder Loss:  0.3500521
Encoder Loss:  0.29896608  || Decoder Loss:  0.03784423 Validation Decoder Loss:  0.34887815
Encoder Loss:  0.2954464  || Decoder Loss:  0.03779466 Validation Decoder Loss:  0.3471887
Encoder Loss:  0.29171082  || Decoder Loss:  0.037759718 Validation Decoder Loss:  0.34770697
Encoder Loss:  0.28772599  || Decoder Loss:  0.037728928 Validation Decoder Loss:  0.3470795
Encoder Loss:  0.2834493  || Decoder Loss:  0.037702873 Validation Decoder Loss:  0.34682053
Encoder Loss:  0.27882406  || Decoder Loss:  0.03767866 Validation Decoder Loss:  0.3467433
Encoder Loss:  0.27377126  || Decoder Loss:  0.03765579 Validation Decoder Loss:  0.3465392
Encoder Loss:  0.26817265  || Decoder Loss:  0.03763443 Validation Decoder Loss:  0.34642494
Encoder Loss:  0.26183292  || Decoder Loss:  0.03761428 Validation Decoder Loss:  0.34631693
Encoder Loss:  0.25438073  || Decoder Loss:  0.0375953 Validation Decoder Loss:  0.34619868
Model: siamese_net_lr_0.0006120447607841907 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3461987
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_380 (Conv3D (None, 110, 5, 20, 1)     48        
_________________________________________________________________
dropout_787 (Dropout)        (None, 110, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_381 (Conv3D (None, 220, 11, 20, 1)    778       
_________________________________________________________________
reshape_143 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 826
Trainable params: 826
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_263 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_789 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_264 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_263 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_791 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_264 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18089694  || Decoder Loss:  0.12419269 Validation Decoder Loss:  0.33699402
Encoder Loss:  0.050923105  || Decoder Loss:  0.04525718 Validation Decoder Loss:  0.33116287
Encoder Loss:  0.050206825  || Decoder Loss:  0.03921278 Validation Decoder Loss:  0.33414978
Encoder Loss:  0.05020945  || Decoder Loss:  0.038395196 Validation Decoder Loss:  0.33478802
Encoder Loss:  0.050203096  || Decoder Loss:  0.037839275 Validation Decoder Loss:  0.335204
Encoder Loss:  0.050180145  || Decoder Loss:  0.03734689 Validation Decoder Loss:  0.33452478
Encoder Loss:  0.050174948  || Decoder Loss:  0.036903095 Validation Decoder Loss:  0.33439904
Encoder Loss:  0.05017078  || Decoder Loss:  0.036557127 Validation Decoder Loss:  0.33391482
Encoder Loss:  0.050187763  || Decoder Loss:  0.03619166 Validation Decoder Loss:  0.3336454
Encoder Loss:  0.05016665  || Decoder Loss:  0.035912793 Validation Decoder Loss:  0.33354372
Encoder Loss:  0.050151717  || Decoder Loss:  0.036585413 Validation Decoder Loss:  0.3336494
Encoder Loss:  0.05017713  || Decoder Loss:  0.035435572 Validation Decoder Loss:  0.33358726
Encoder Loss:  0.0501512  || Decoder Loss:  0.035308085 Validation Decoder Loss:  0.33366418
Encoder Loss:  0.050136466  || Decoder Loss:  0.0352111 Validation Decoder Loss:  0.33360016
Encoder Loss:  0.050174713  || Decoder Loss:  0.035156317 Validation Decoder Loss:  0.33399457
Encoder Loss:  0.050144013  || Decoder Loss:  0.035138324 Validation Decoder Loss:  0.3340125
Encoder Loss:  0.050142966  || Decoder Loss:  0.035127133 Validation Decoder Loss:  0.33383918
Encoder Loss:  0.05016037  || Decoder Loss:  0.035125874 Validation Decoder Loss:  0.33369198
Encoder Loss:  0.05014722  || Decoder Loss:  0.035119165 Validation Decoder Loss:  0.33390307
Encoder Loss:  0.050146088  || Decoder Loss:  0.03512006 Validation Decoder Loss:  0.33348668
Encoder Loss:  0.050133392  || Decoder Loss:  0.035108045 Validation Decoder Loss:  0.33294278
Encoder Loss:  0.05018931  || Decoder Loss:  0.035084795 Validation Decoder Loss:  0.33345556
Encoder Loss:  0.05012437  || Decoder Loss:  0.03502178 Validation Decoder Loss:  0.33351392
Encoder Loss:  0.050105516  || Decoder Loss:  0.035044696 Validation Decoder Loss:  0.3333889
Encoder Loss:  0.050104227  || Decoder Loss:  0.03502837 Validation Decoder Loss:  0.3332513
Encoder Loss:  0.05011694  || Decoder Loss:  0.035031237 Validation Decoder Loss:  0.3330577
Encoder Loss:  0.05011412  || Decoder Loss:  0.035040148 Validation Decoder Loss:  0.3330715
Encoder Loss:  0.05010407  || Decoder Loss:  0.035044495 Validation Decoder Loss:  0.33313447
Encoder Loss:  0.050090853  || Decoder Loss:  0.035015166 Validation Decoder Loss:  0.33289337
Encoder Loss:  0.050092865  || Decoder Loss:  0.035007812 Validation Decoder Loss:  0.33292407
Encoder Loss:  0.050092917  || Decoder Loss:  0.03503063 Validation Decoder Loss:  0.33301356
Encoder Loss:  0.050079316  || Decoder Loss:  0.035060547 Validation Decoder Loss:  0.3331654
Encoder Loss:  0.050072897  || Decoder Loss:  0.035099458 Validation Decoder Loss:  0.33332857
Encoder Loss:  0.050184306  || Decoder Loss:  0.034953915 Validation Decoder Loss:  0.33275855
Encoder Loss:  0.050082173  || Decoder Loss:  0.034999207 Validation Decoder Loss:  0.33301163
Encoder Loss:  0.05006978  || Decoder Loss:  0.035063315 Validation Decoder Loss:  0.3331629
Encoder Loss:  0.050115556  || Decoder Loss:  0.034969673 Validation Decoder Loss:  0.33288872
Encoder Loss:  0.050072864  || Decoder Loss:  0.03503901 Validation Decoder Loss:  0.33313847
Encoder Loss:  0.05008319  || Decoder Loss:  0.035022736 Validation Decoder Loss:  0.33315367
Encoder Loss:  0.050057665  || Decoder Loss:  0.035089493 Validation Decoder Loss:  0.33316362
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33316362
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_383 (Conv3D (None, 218, 10, 20, 1)    311       
_________________________________________________________________
dropout_793 (Dropout)        (None, 218, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_384 (Conv3D (None, 220, 11, 20, 1)    7         
_________________________________________________________________
reshape_144 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_265 (Conv2D)          (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_795 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_266 (Conv2D)          (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_265 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_797 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_266 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2624033  || Decoder Loss:  0.041257977 Validation Decoder Loss:  0.34484446
Encoder Loss:  0.26226583  || Decoder Loss:  0.04127012 Validation Decoder Loss:  0.34425786
Encoder Loss:  0.26211536  || Decoder Loss:  0.0412855 Validation Decoder Loss:  0.3436653
Encoder Loss:  0.26195785  || Decoder Loss:  0.041306935 Validation Decoder Loss:  0.3430626
Encoder Loss:  0.26178432  || Decoder Loss:  0.04133555 Validation Decoder Loss:  0.34244514
Encoder Loss:  0.26158273  || Decoder Loss:  0.041369233 Validation Decoder Loss:  0.3418158
Encoder Loss:  0.2613413  || Decoder Loss:  0.041404657 Validation Decoder Loss:  0.3411784
Encoder Loss:  0.26104715  || Decoder Loss:  0.041438345 Validation Decoder Loss:  0.34053648
Encoder Loss:  0.26068437  || Decoder Loss:  0.041466497 Validation Decoder Loss:  0.33989516
Encoder Loss:  0.26023188  || Decoder Loss:  0.041484565 Validation Decoder Loss:  0.33926165
Encoder Loss:  0.25966036  || Decoder Loss:  0.04148695 Validation Decoder Loss:  0.33864665
Encoder Loss:  0.25892827  || Decoder Loss:  0.041466795 Validation Decoder Loss:  0.3380652
Encoder Loss:  0.25797406  || Decoder Loss:  0.041415792 Validation Decoder Loss:  0.33753833
Encoder Loss:  0.25670427  || Decoder Loss:  0.04132436 Validation Decoder Loss:  0.33709362
Encoder Loss:  0.25496954  || Decoder Loss:  0.041181974 Validation Decoder Loss:  0.33676526
Encoder Loss:  0.2525178  || Decoder Loss:  0.040978197 Validation Decoder Loss:  0.33659327
Encoder Loss:  0.24889235  || Decoder Loss:  0.040704444 Validation Decoder Loss:  0.336623
Encoder Loss:  0.24319208  || Decoder Loss:  0.04035662 Validation Decoder Loss:  0.33690572
Encoder Loss:  0.23343544  || Decoder Loss:  0.039938904 Validation Decoder Loss:  0.33749604
Encoder Loss:  0.21473362  || Decoder Loss:  0.039469525 Validation Decoder Loss:  0.3384422
Encoder Loss:  0.1743974  || Decoder Loss:  0.038985774 Validation Decoder Loss:  0.3397472
Encoder Loss:  0.092796296  || Decoder Loss:  0.03855418 Validation Decoder Loss:  0.34117103
Encoder Loss:  0.07343337  || Decoder Loss:  0.03825628 Validation Decoder Loss:  0.342328
Encoder Loss:  0.0649882  || Decoder Loss:  0.038047563 Validation Decoder Loss:  0.3433131
Encoder Loss:  0.06663296  || Decoder Loss:  0.037889212 Validation Decoder Loss:  0.3441106
Encoder Loss:  0.06639864  || Decoder Loss:  0.03776689 Validation Decoder Loss:  0.3447367
Encoder Loss:  0.06599854  || Decoder Loss:  0.037667654 Validation Decoder Loss:  0.3452055
Encoder Loss:  0.06596423  || Decoder Loss:  0.037583925 Validation Decoder Loss:  0.34553874
Encoder Loss:  0.06569434  || Decoder Loss:  0.03750989 Validation Decoder Loss:  0.34575266
Encoder Loss:  0.06567353  || Decoder Loss:  0.037442457 Validation Decoder Loss:  0.3458736
Encoder Loss:  0.06541008  || Decoder Loss:  0.03737908 Validation Decoder Loss:  0.3459193
Encoder Loss:  0.06536533  || Decoder Loss:  0.037318733 Validation Decoder Loss:  0.34591746
Encoder Loss:  0.065141454  || Decoder Loss:  0.037260044 Validation Decoder Loss:  0.34588337
Encoder Loss:  0.065041475  || Decoder Loss:  0.037202533 Validation Decoder Loss:  0.34583473
Encoder Loss:  0.06493004  || Decoder Loss:  0.037145384 Validation Decoder Loss:  0.3457806
Encoder Loss:  0.06480105  || Decoder Loss:  0.037088107 Validation Decoder Loss:  0.34572566
Encoder Loss:  0.06468469  || Decoder Loss:  0.0370302 Validation Decoder Loss:  0.34567174
Encoder Loss:  0.06458164  || Decoder Loss:  0.036971178 Validation Decoder Loss:  0.3456184
Encoder Loss:  0.064447924  || Decoder Loss:  0.036910664 Validation Decoder Loss:  0.34556293
Encoder Loss:  0.06433526  || Decoder Loss:  0.036848307 Validation Decoder Loss:  0.34550363
Model: siamese_net_lr_0.0004298901552485967 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34550363
Model: "sequential_558"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_386 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_799 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_387 (Conv3D (None, 220, 11, 20, 1)    388       
_________________________________________________________________
reshape_145 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 418
Trainable params: 418
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_267 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_801 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_268 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_267 (Conv2D (None, 2590, 20, 1)       172       
_________________________________________________________________
dropout_803 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_268 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20996924  || Decoder Loss:  0.08956387 Validation Decoder Loss:  0.32942086
Encoder Loss:  0.05000885  || Decoder Loss:  0.03520881 Validation Decoder Loss:  0.32904023
Encoder Loss:  0.05000945  || Decoder Loss:  0.035001576 Validation Decoder Loss:  0.3288776
Encoder Loss:  0.050012335  || Decoder Loss:  0.03491304 Validation Decoder Loss:  0.3288591
Encoder Loss:  0.0500131  || Decoder Loss:  0.03484876 Validation Decoder Loss:  0.32882267
Encoder Loss:  0.050016366  || Decoder Loss:  0.034824163 Validation Decoder Loss:  0.32897097
Encoder Loss:  0.050152995  || Decoder Loss:  0.03477125 Validation Decoder Loss:  0.32895738
Encoder Loss:  0.05001647  || Decoder Loss:  0.034718677 Validation Decoder Loss:  0.32900718
Encoder Loss:  0.050016847  || Decoder Loss:  0.03468519 Validation Decoder Loss:  0.32890075
Encoder Loss:  0.05004088  || Decoder Loss:  0.034575593 Validation Decoder Loss:  0.32862025
Encoder Loss:  0.050019726  || Decoder Loss:  0.034609854 Validation Decoder Loss:  0.32856518
Encoder Loss:  0.050019413  || Decoder Loss:  0.034640495 Validation Decoder Loss:  0.32851994
Encoder Loss:  0.05007993  || Decoder Loss:  0.034536816 Validation Decoder Loss:  0.32828793
Encoder Loss:  0.050021723  || Decoder Loss:  0.034533434 Validation Decoder Loss:  0.32857195
Encoder Loss:  0.05001584  || Decoder Loss:  0.034552738 Validation Decoder Loss:  0.32882318
Encoder Loss:  0.05001532  || Decoder Loss:  0.034584075 Validation Decoder Loss:  0.32910073
Encoder Loss:  0.050016932  || Decoder Loss:  0.034617744 Validation Decoder Loss:  0.33117998
Encoder Loss:  0.050018955  || Decoder Loss:  0.03473878 Validation Decoder Loss:  0.3298369
Encoder Loss:  0.050010122  || Decoder Loss:  0.034711014 Validation Decoder Loss:  0.3292818
Encoder Loss:  0.05001993  || Decoder Loss:  0.034699306 Validation Decoder Loss:  0.33007094
Encoder Loss:  0.05001909  || Decoder Loss:  0.034735963 Validation Decoder Loss:  0.33022544
Encoder Loss:  0.050014447  || Decoder Loss:  0.03475806 Validation Decoder Loss:  0.32989222
Encoder Loss:  0.05001159  || Decoder Loss:  0.034732956 Validation Decoder Loss:  0.33025503
Encoder Loss:  0.050017614  || Decoder Loss:  0.03477552 Validation Decoder Loss:  0.33003157
Encoder Loss:  0.050013233  || Decoder Loss:  0.034763616 Validation Decoder Loss:  0.3303359
Encoder Loss:  0.050011035  || Decoder Loss:  0.034791134 Validation Decoder Loss:  0.3301422
Encoder Loss:  0.050012995  || Decoder Loss:  0.034789514 Validation Decoder Loss:  0.33039486
Encoder Loss:  0.05005581  || Decoder Loss:  0.034872375 Validation Decoder Loss:  0.33047223
Encoder Loss:  0.050006986  || Decoder Loss:  0.0348881 Validation Decoder Loss:  0.3305768
Encoder Loss:  0.050007235  || Decoder Loss:  0.034874395 Validation Decoder Loss:  0.3305986
Encoder Loss:  0.050008617  || Decoder Loss:  0.03486518 Validation Decoder Loss:  0.33063632
Encoder Loss:  0.050027918  || Decoder Loss:  0.034889743 Validation Decoder Loss:  0.33079946
Encoder Loss:  0.050006725  || Decoder Loss:  0.03487129 Validation Decoder Loss:  0.33086455
Encoder Loss:  0.05000803  || Decoder Loss:  0.034883704 Validation Decoder Loss:  0.3308838
Encoder Loss:  0.050013285  || Decoder Loss:  0.034919366 Validation Decoder Loss:  0.33105206
Encoder Loss:  0.050006475  || Decoder Loss:  0.034910318 Validation Decoder Loss:  0.33109263
Encoder Loss:  0.050011408  || Decoder Loss:  0.034942955 Validation Decoder Loss:  0.33128405
Encoder Loss:  0.05000586  || Decoder Loss:  0.034924496 Validation Decoder Loss:  0.33134496
Encoder Loss:  0.050006777  || Decoder Loss:  0.034939036 Validation Decoder Loss:  0.33139414
Encoder Loss:  0.050007053  || Decoder Loss:  0.034948718 Validation Decoder Loss:  0.331477
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.331477
Model: "sequential_562"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_389 (Conv3D (None, 207, 10, 20, 1)    37        
_________________________________________________________________
dropout_805 (Dropout)        (None, 207, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_390 (Conv3D (None, 220, 11, 20, 1)    29        
_________________________________________________________________
reshape_146 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_269 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_807 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_270 (Conv2D)          (None, 2420, 20, 1)       12        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_269 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_809 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_270 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43713757  || Decoder Loss:  0.048569664 Validation Decoder Loss:  0.364169
Encoder Loss:  0.4367243  || Decoder Loss:  0.0486746 Validation Decoder Loss:  0.36481678
Encoder Loss:  0.43628067  || Decoder Loss:  0.048767105 Validation Decoder Loss:  0.36528692
Encoder Loss:  0.43581626  || Decoder Loss:  0.04884387 Validation Decoder Loss:  0.36559817
Encoder Loss:  0.43530628  || Decoder Loss:  0.04890782 Validation Decoder Loss:  0.36580902
Encoder Loss:  0.4347226  || Decoder Loss:  0.048960105 Validation Decoder Loss:  0.36592957
Encoder Loss:  0.4340277  || Decoder Loss:  0.049001593 Validation Decoder Loss:  0.36595786
Encoder Loss:  0.43316537  || Decoder Loss:  0.04903191 Validation Decoder Loss:  0.36589983
Encoder Loss:  0.43204102  || Decoder Loss:  0.049048685 Validation Decoder Loss:  0.36576378
Encoder Loss:  0.4304696  || Decoder Loss:  0.049046706 Validation Decoder Loss:  0.36555177
Encoder Loss:  0.42800316  || Decoder Loss:  0.04901605 Validation Decoder Loss:  0.36524832
Encoder Loss:  0.42305633  || Decoder Loss:  0.048936933 Validation Decoder Loss:  0.36477587
Encoder Loss:  0.40254036  || Decoder Loss:  0.048766732 Validation Decoder Loss:  0.36382383
Encoder Loss:  0.17954485  || Decoder Loss:  0.0483722 Validation Decoder Loss:  0.3620583
Encoder Loss:  0.06840517  || Decoder Loss:  0.047148496 Validation Decoder Loss:  0.3529681
Encoder Loss:  0.05361381  || Decoder Loss:  0.045580138 Validation Decoder Loss:  0.34538126
Encoder Loss:  0.05251528  || Decoder Loss:  0.04518586 Validation Decoder Loss:  0.3443823
Encoder Loss:  0.05284829  || Decoder Loss:  0.045077898 Validation Decoder Loss:  0.34467283
Encoder Loss:  0.05182534  || Decoder Loss:  0.0449991 Validation Decoder Loss:  0.34436178
Encoder Loss:  0.05133749  || Decoder Loss:  0.044942908 Validation Decoder Loss:  0.34408104
Encoder Loss:  0.051465705  || Decoder Loss:  0.044898134 Validation Decoder Loss:  0.34383655
Encoder Loss:  0.051607665  || Decoder Loss:  0.04484436 Validation Decoder Loss:  0.34365487
Encoder Loss:  0.05059675  || Decoder Loss:  0.04476437 Validation Decoder Loss:  0.3435355
Encoder Loss:  0.05121423  || Decoder Loss:  0.044649296 Validation Decoder Loss:  0.34340847
Encoder Loss:  0.051070675  || Decoder Loss:  0.044494156 Validation Decoder Loss:  0.3433409
Encoder Loss:  0.05091705  || Decoder Loss:  0.0443297 Validation Decoder Loss:  0.34321102
Encoder Loss:  0.05063842  || Decoder Loss:  0.04415304 Validation Decoder Loss:  0.34306234
Encoder Loss:  0.050992705  || Decoder Loss:  0.043964025 Validation Decoder Loss:  0.3428087
Encoder Loss:  0.05087089  || Decoder Loss:  0.04375579 Validation Decoder Loss:  0.34252042
Encoder Loss:  0.050803598  || Decoder Loss:  0.04348097 Validation Decoder Loss:  0.34217724
Encoder Loss:  0.050753206  || Decoder Loss:  0.04314583 Validation Decoder Loss:  0.3417048
Encoder Loss:  0.050788783  || Decoder Loss:  0.04270721 Validation Decoder Loss:  0.34109282
Encoder Loss:  0.050508294  || Decoder Loss:  0.042068604 Validation Decoder Loss:  0.3402419
Encoder Loss:  0.050368242  || Decoder Loss:  0.04107729 Validation Decoder Loss:  0.33889177
Encoder Loss:  0.050850794  || Decoder Loss:  0.039547578 Validation Decoder Loss:  0.33766967
Encoder Loss:  0.05047603  || Decoder Loss:  0.037806805 Validation Decoder Loss:  0.335865
Encoder Loss:  0.05061395  || Decoder Loss:  0.036374155 Validation Decoder Loss:  0.33523136
Encoder Loss:  0.050611805  || Decoder Loss:  0.035280615 Validation Decoder Loss:  0.33498788
Encoder Loss:  0.05032367  || Decoder Loss:  0.034492925 Validation Decoder Loss:  0.33543932
Encoder Loss:  0.050342914  || Decoder Loss:  0.03407152 Validation Decoder Loss:  0.3367181
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33671814
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_392 (Conv3D (None, 211, 10, 20, 1)    133       
_________________________________________________________________
dropout_811 (Dropout)        (None, 211, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_393 (Conv3D (None, 220, 11, 20, 1)    21        
_________________________________________________________________
reshape_147 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 154
Trainable params: 154
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_271 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_813 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_272 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_569"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_271 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_815 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_272 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082438
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.0467015 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.0467015 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082438
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082438
Encoder Loss:  0.43716  || Decoder Loss:  0.0467015 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701506 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.0467015 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Encoder Loss:  0.43716  || Decoder Loss:  0.046701502 Validation Decoder Loss:  0.36082435
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36082435
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_395 (Conv3D (None, 205, 10, 20, 1)    159       
_________________________________________________________________
dropout_817 (Dropout)        (None, 205, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_396 (Conv3D (None, 220, 11, 20, 1)    33        
_________________________________________________________________
reshape_148 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_273 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_819 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_274 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_273 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_821 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_274 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04507768  || Decoder Loss:  0.04507768 Validation Decoder Loss:  0.3395984
Encoder Loss:  0.03691376  || Decoder Loss:  0.03691376 Validation Decoder Loss:  0.3389709
Encoder Loss:  0.035537735  || Decoder Loss:  0.035537735 Validation Decoder Loss:  0.33879292
Encoder Loss:  0.034765046  || Decoder Loss:  0.034765046 Validation Decoder Loss:  0.33818597
Encoder Loss:  0.03422092  || Decoder Loss:  0.03422092 Validation Decoder Loss:  0.33763283
Encoder Loss:  0.03378596  || Decoder Loss:  0.03378596 Validation Decoder Loss:  0.3371114
Encoder Loss:  0.033489823  || Decoder Loss:  0.033489823 Validation Decoder Loss:  0.33697015
Encoder Loss:  0.033326376  || Decoder Loss:  0.033326376 Validation Decoder Loss:  0.33720022
Encoder Loss:  0.0332232  || Decoder Loss:  0.0332232 Validation Decoder Loss:  0.33756608
Encoder Loss:  0.033145297  || Decoder Loss:  0.033145297 Validation Decoder Loss:  0.33786082
Encoder Loss:  0.033084147  || Decoder Loss:  0.033084147 Validation Decoder Loss:  0.3379872
Encoder Loss:  0.03303419  || Decoder Loss:  0.03303419 Validation Decoder Loss:  0.3380689
Encoder Loss:  0.032991756  || Decoder Loss:  0.032991756 Validation Decoder Loss:  0.33819103
Encoder Loss:  0.032953933  || Decoder Loss:  0.032953933 Validation Decoder Loss:  0.33834794
Encoder Loss:  0.032918442  || Decoder Loss:  0.032918442 Validation Decoder Loss:  0.33853245
Encoder Loss:  0.032883577  || Decoder Loss:  0.032883577 Validation Decoder Loss:  0.33873588
Encoder Loss:  0.03284896  || Decoder Loss:  0.03284896 Validation Decoder Loss:  0.33892244
Encoder Loss:  0.032815866  || Decoder Loss:  0.032815866 Validation Decoder Loss:  0.3390401
Encoder Loss:  0.03278532  || Decoder Loss:  0.03278532 Validation Decoder Loss:  0.33907425
Encoder Loss:  0.03275738  || Decoder Loss:  0.03275738 Validation Decoder Loss:  0.33905214
Encoder Loss:  0.032731764  || Decoder Loss:  0.032731764 Validation Decoder Loss:  0.33900487
Encoder Loss:  0.0327083  || Decoder Loss:  0.0327083 Validation Decoder Loss:  0.33895177
Encoder Loss:  0.03268675  || Decoder Loss:  0.03268675 Validation Decoder Loss:  0.33890224
Encoder Loss:  0.032667004  || Decoder Loss:  0.032667004 Validation Decoder Loss:  0.3388603
Encoder Loss:  0.03264901  || Decoder Loss:  0.03264901 Validation Decoder Loss:  0.33882755
Encoder Loss:  0.032632526  || Decoder Loss:  0.032632526 Validation Decoder Loss:  0.33880383
Encoder Loss:  0.03261744  || Decoder Loss:  0.03261744 Validation Decoder Loss:  0.3387878
Encoder Loss:  0.032603595  || Decoder Loss:  0.032603595 Validation Decoder Loss:  0.33877778
Encoder Loss:  0.03259079  || Decoder Loss:  0.03259079 Validation Decoder Loss:  0.33877242
Encoder Loss:  0.03257903  || Decoder Loss:  0.03257903 Validation Decoder Loss:  0.33877063
Encoder Loss:  0.032568052  || Decoder Loss:  0.032568052 Validation Decoder Loss:  0.33877176
Encoder Loss:  0.032557808  || Decoder Loss:  0.032557808 Validation Decoder Loss:  0.33877534
Encoder Loss:  0.032548264  || Decoder Loss:  0.032548264 Validation Decoder Loss:  0.33878085
Encoder Loss:  0.03253931  || Decoder Loss:  0.03253931 Validation Decoder Loss:  0.33878803
Encoder Loss:  0.032530885  || Decoder Loss:  0.032530885 Validation Decoder Loss:  0.33879668
Encoder Loss:  0.032522954  || Decoder Loss:  0.032522954 Validation Decoder Loss:  0.33880648
Encoder Loss:  0.032515477  || Decoder Loss:  0.032515477 Validation Decoder Loss:  0.33881724
Encoder Loss:  0.032508418  || Decoder Loss:  0.032508418 Validation Decoder Loss:  0.33882862
Encoder Loss:  0.03250176  || Decoder Loss:  0.03250176 Validation Decoder Loss:  0.3388405
Encoder Loss:  0.032495465  || Decoder Loss:  0.032495465 Validation Decoder Loss:  0.33885264
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33885264
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_398 (Conv3D (None, 150, 11, 20, 1)    262       
_________________________________________________________________
dropout_823 (Dropout)        (None, 150, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_399 (Conv3D (None, 220, 11, 20, 1)    72        
_________________________________________________________________
reshape_149 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 334
Trainable params: 334
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_275 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_825 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_276 (Conv2D)          (None, 2420, 20, 1)       12        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_275 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_827 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_276 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20417866  || Decoder Loss:  0.09487946 Validation Decoder Loss:  0.3717835
Encoder Loss:  0.20430742  || Decoder Loss:  0.09542456 Validation Decoder Loss:  0.37236935
Encoder Loss:  0.20445846  || Decoder Loss:  0.096080534 Validation Decoder Loss:  0.3730102
Encoder Loss:  0.20461616  || Decoder Loss:  0.09678642 Validation Decoder Loss:  0.37366173
Encoder Loss:  0.20477462  || Decoder Loss:  0.09752122 Validation Decoder Loss:  0.37431097
Encoder Loss:  0.204932  || Decoder Loss:  0.09828109 Validation Decoder Loss:  0.37496096
Encoder Loss:  0.20508757  || Decoder Loss:  0.09906732 Validation Decoder Loss:  0.37562004
Encoder Loss:  0.20524062  || Decoder Loss:  0.099882856 Validation Decoder Loss:  0.3762949
Encoder Loss:  0.20539035  || Decoder Loss:  0.10073136 Validation Decoder Loss:  0.37698972
Encoder Loss:  0.20553571  || Decoder Loss:  0.10161719 Validation Decoder Loss:  0.377707
Encoder Loss:  0.2056752  || Decoder Loss:  0.10254541 Validation Decoder Loss:  0.37844932
Encoder Loss:  0.20580684  || Decoder Loss:  0.10352194 Validation Decoder Loss:  0.37922025
Encoder Loss:  0.20592782  || Decoder Loss:  0.10455381 Validation Decoder Loss:  0.38002506
Encoder Loss:  0.20603442  || Decoder Loss:  0.105649486 Validation Decoder Loss:  0.38087055
Encoder Loss:  0.20612143  || Decoder Loss:  0.106819406 Validation Decoder Loss:  0.38176546
Encoder Loss:  0.20618178  || Decoder Loss:  0.10807671 Validation Decoder Loss:  0.38272083
Encoder Loss:  0.20620595  || Decoder Loss:  0.1094385 Validation Decoder Loss:  0.38375133
Encoder Loss:  0.20618103  || Decoder Loss:  0.11092781 Validation Decoder Loss:  0.38487747
Encoder Loss:  0.20609058  || Decoder Loss:  0.11257731 Validation Decoder Loss:  0.38612923
Encoder Loss:  0.2059145  || Decoder Loss:  0.11443511 Validation Decoder Loss:  0.38755244
Encoder Loss:  0.20562986  || Decoder Loss:  0.11657296 Validation Decoder Loss:  0.38921854
Encoder Loss:  0.20521072  || Decoder Loss:  0.119097315 Validation Decoder Loss:  0.39124018
Encoder Loss:  0.20462781  || Decoder Loss:  0.122166075 Validation Decoder Loss:  0.39379996
Encoder Loss:  0.20385095  || Decoder Loss:  0.1260205 Validation Decoder Loss:  0.39720893
Encoder Loss:  0.20286347  || Decoder Loss:  0.13105147 Validation Decoder Loss:  0.4020403
Encoder Loss:  0.20170659  || Decoder Loss:  0.13793594 Validation Decoder Loss:  0.40946198
Encoder Loss:  0.20060833  || Decoder Loss:  0.14793657 Validation Decoder Loss:  0.42208502
Encoder Loss:  0.20037982  || Decoder Loss:  0.16364726 Validation Decoder Loss:  0.44653672
Encoder Loss:  0.20368879  || Decoder Loss:  0.19108206 Validation Decoder Loss:  0.50298774
Encoder Loss:  0.21902853  || Decoder Loss:  0.24568814 Validation Decoder Loss:  0.6500288
Encoder Loss:  0.26416805  || Decoder Loss:  0.35537788 Validation Decoder Loss:  0.8597318
Encoder Loss:  0.27210575  || Decoder Loss:  0.37426335 Validation Decoder Loss:  0.6009936
Encoder Loss:  0.2081073  || Decoder Loss:  0.2769766 Validation Decoder Loss:  0.5682249
Encoder Loss:  0.19649485  || Decoder Loss:  0.26109454 Validation Decoder Loss:  0.53096944
Encoder Loss:  0.17788412  || Decoder Loss:  0.23198582 Validation Decoder Loss:  0.50208557
Encoder Loss:  0.16340677  || Decoder Loss:  0.20979306 Validation Decoder Loss:  0.47454387
Encoder Loss:  0.14310072  || Decoder Loss:  0.1781011 Validation Decoder Loss:  0.4501633
Encoder Loss:  0.1228512  || Decoder Loss:  0.14682306 Validation Decoder Loss:  0.45312887
Encoder Loss:  0.10755939  || Decoder Loss:  0.123001106 Validation Decoder Loss:  0.41275558
Encoder Loss:  0.096135244  || Decoder Loss:  0.10536483 Validation Decoder Loss:  0.3913046
Model: siamese_net_lr_0.0006421167013469268 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3913046
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_401 (Conv3D (None, 212, 10, 20, 1)    47        
_________________________________________________________________
dropout_829 (Dropout)        (None, 212, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_402 (Conv3D (None, 220, 11, 20, 1)    19        
_________________________________________________________________
reshape_150 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_277 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_831 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_278 (Conv2D)          (None, 2420, 20, 1)       12        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_277 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_833 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_278 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29489288  || Decoder Loss:  0.043528594 Validation Decoder Loss:  0.34451815
Encoder Loss:  0.05708163  || Decoder Loss:  0.03576781 Validation Decoder Loss:  0.33563837
Encoder Loss:  0.051460672  || Decoder Loss:  0.033945758 Validation Decoder Loss:  0.3361112
Encoder Loss:  0.05042842  || Decoder Loss:  0.033792697 Validation Decoder Loss:  0.33652112
Encoder Loss:  0.049678784  || Decoder Loss:  0.033680465 Validation Decoder Loss:  0.33607006
Encoder Loss:  0.04964651  || Decoder Loss:  0.0335219 Validation Decoder Loss:  0.3362417
Encoder Loss:  0.04942985  || Decoder Loss:  0.033458836 Validation Decoder Loss:  0.3362014
Encoder Loss:  0.049336303  || Decoder Loss:  0.033469785 Validation Decoder Loss:  0.33651882
Encoder Loss:  0.04921234  || Decoder Loss:  0.033506576 Validation Decoder Loss:  0.3366105
Encoder Loss:  0.049232565  || Decoder Loss:  0.033534173 Validation Decoder Loss:  0.33686495
Encoder Loss:  0.049245473  || Decoder Loss:  0.03352684 Validation Decoder Loss:  0.33694282
Encoder Loss:  0.049090765  || Decoder Loss:  0.033509992 Validation Decoder Loss:  0.33691978
Encoder Loss:  0.049513947  || Decoder Loss:  0.033487484 Validation Decoder Loss:  0.3367989
Encoder Loss:  0.04919871  || Decoder Loss:  0.03345619 Validation Decoder Loss:  0.33682215
Encoder Loss:  0.049105555  || Decoder Loss:  0.03342313 Validation Decoder Loss:  0.33686393
Encoder Loss:  0.049335383  || Decoder Loss:  0.033395983 Validation Decoder Loss:  0.33646217
Encoder Loss:  0.04913192  || Decoder Loss:  0.033364818 Validation Decoder Loss:  0.33658618
Encoder Loss:  0.049157087  || Decoder Loss:  0.03333947 Validation Decoder Loss:  0.33636567
Encoder Loss:  0.049318075  || Decoder Loss:  0.03331253 Validation Decoder Loss:  0.33641082
Encoder Loss:  0.049034595  || Decoder Loss:  0.033281475 Validation Decoder Loss:  0.3364413
Encoder Loss:  0.049113594  || Decoder Loss:  0.03324912 Validation Decoder Loss:  0.33634096
Encoder Loss:  0.049197175  || Decoder Loss:  0.03321703 Validation Decoder Loss:  0.33617473
Encoder Loss:  0.04903099  || Decoder Loss:  0.033183828 Validation Decoder Loss:  0.33628696
Encoder Loss:  0.049035136  || Decoder Loss:  0.033151116 Validation Decoder Loss:  0.33631808
Encoder Loss:  0.049062565  || Decoder Loss:  0.033118192 Validation Decoder Loss:  0.33642077
Encoder Loss:  0.049027376  || Decoder Loss:  0.03309199 Validation Decoder Loss:  0.33640116
Encoder Loss:  0.049076997  || Decoder Loss:  0.033070054 Validation Decoder Loss:  0.33651114
Encoder Loss:  0.049521208  || Decoder Loss:  0.03305092 Validation Decoder Loss:  0.33682498
Encoder Loss:  0.048991222  || Decoder Loss:  0.03303032 Validation Decoder Loss:  0.33692876
Encoder Loss:  0.04901752  || Decoder Loss:  0.03301152 Validation Decoder Loss:  0.33688208
Encoder Loss:  0.049067106  || Decoder Loss:  0.032993425 Validation Decoder Loss:  0.33691108
Encoder Loss:  0.049429603  || Decoder Loss:  0.032978512 Validation Decoder Loss:  0.33704096
Encoder Loss:  0.04897727  || Decoder Loss:  0.032966066 Validation Decoder Loss:  0.33714902
Encoder Loss:  0.0490927  || Decoder Loss:  0.032956373 Validation Decoder Loss:  0.33734864
Encoder Loss:  0.049022406  || Decoder Loss:  0.032945737 Validation Decoder Loss:  0.33721817
Encoder Loss:  0.04905113  || Decoder Loss:  0.03293827 Validation Decoder Loss:  0.33749086
Encoder Loss:  0.049201928  || Decoder Loss:  0.03293139 Validation Decoder Loss:  0.33747908
Encoder Loss:  0.049013566  || Decoder Loss:  0.032923415 Validation Decoder Loss:  0.33749443
Encoder Loss:  0.049034096  || Decoder Loss:  0.032916244 Validation Decoder Loss:  0.33748043
Encoder Loss:  0.04916959  || Decoder Loss:  0.032909825 Validation Decoder Loss:  0.33755493
Model: siamese_net_lr_0.0008067205251810151 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33755493
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_404 (Conv3D (None, 82, 10, 20, 1)     39        
_________________________________________________________________
dropout_835 (Dropout)        (None, 82, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_405 (Conv3D (None, 220, 11, 20, 1)    117       
_________________________________________________________________
reshape_151 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_279 (Conv2D)          (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_837 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_280 (Conv2D)          (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_585"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_279 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_839 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_280 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26779208  || Decoder Loss:  0.079179965 Validation Decoder Loss:  0.3730229
Encoder Loss:  0.26328528  || Decoder Loss:  0.081240274 Validation Decoder Loss:  0.37735412
Encoder Loss:  0.24087663  || Decoder Loss:  0.08185986 Validation Decoder Loss:  0.38417685
Encoder Loss:  0.21306038  || Decoder Loss:  0.08247965 Validation Decoder Loss:  0.39386728
Encoder Loss:  0.13124503  || Decoder Loss:  0.06958774 Validation Decoder Loss:  0.3167234
Encoder Loss:  0.051914696  || Decoder Loss:  0.05105722 Validation Decoder Loss:  0.32349047
Encoder Loss:  0.04780595  || Decoder Loss:  0.043175355 Validation Decoder Loss:  0.3307859
Encoder Loss:  0.044134073  || Decoder Loss:  0.036218792 Validation Decoder Loss:  0.33465427
Encoder Loss:  0.043307222  || Decoder Loss:  0.03446055 Validation Decoder Loss:  0.3365703
Encoder Loss:  0.043235525  || Decoder Loss:  0.034294408 Validation Decoder Loss:  0.33791763
Encoder Loss:  0.043201104  || Decoder Loss:  0.034217075 Validation Decoder Loss:  0.33874807
Encoder Loss:  0.04318194  || Decoder Loss:  0.03417087 Validation Decoder Loss:  0.33937752
Encoder Loss:  0.043171283  || Decoder Loss:  0.03414772 Validation Decoder Loss:  0.34027955
Encoder Loss:  0.04318729  || Decoder Loss:  0.034185924 Validation Decoder Loss:  0.3444423
Encoder Loss:  0.04318222  || Decoder Loss:  0.034173977 Validation Decoder Loss:  0.34008023
Encoder Loss:  0.043144673  || Decoder Loss:  0.03408814 Validation Decoder Loss:  0.34047157
Encoder Loss:  0.04315146  || Decoder Loss:  0.034103807 Validation Decoder Loss:  0.34464025
Encoder Loss:  0.043171797  || Decoder Loss:  0.034151815 Validation Decoder Loss:  0.3420901
Encoder Loss:  0.04313666  || Decoder Loss:  0.034070678 Validation Decoder Loss:  0.3421715
Encoder Loss:  0.04312495  || Decoder Loss:  0.034044378 Validation Decoder Loss:  0.342195
Encoder Loss:  0.04311562  || Decoder Loss:  0.034023188 Validation Decoder Loss:  0.3422163
Encoder Loss:  0.043107256  || Decoder Loss:  0.03400387 Validation Decoder Loss:  0.342256
Encoder Loss:  0.043098524  || Decoder Loss:  0.033984352 Validation Decoder Loss:  0.34227213
Encoder Loss:  0.04309072  || Decoder Loss:  0.033966314 Validation Decoder Loss:  0.3422955
Encoder Loss:  0.043082733  || Decoder Loss:  0.033948213 Validation Decoder Loss:  0.34231272
Encoder Loss:  0.043074597  || Decoder Loss:  0.03392948 Validation Decoder Loss:  0.3423139
Encoder Loss:  0.043070707  || Decoder Loss:  0.03391175 Validation Decoder Loss:  0.34230834
Encoder Loss:  0.043058664  || Decoder Loss:  0.03389336 Validation Decoder Loss:  0.3423102
Encoder Loss:  0.043050215  || Decoder Loss:  0.033874445 Validation Decoder Loss:  0.3423053
Encoder Loss:  0.043042146  || Decoder Loss:  0.033855382 Validation Decoder Loss:  0.34229273
Encoder Loss:  0.043038413  || Decoder Loss:  0.033837475 Validation Decoder Loss:  0.34226876
Encoder Loss:  0.04302598  || Decoder Loss:  0.03381884 Validation Decoder Loss:  0.34228373
Encoder Loss:  0.04301689  || Decoder Loss:  0.03379852 Validation Decoder Loss:  0.34226537
Encoder Loss:  0.04300749  || Decoder Loss:  0.03377737 Validation Decoder Loss:  0.34223044
Encoder Loss:  0.04299823  || Decoder Loss:  0.033756085 Validation Decoder Loss:  0.34219584
Encoder Loss:  0.042988755  || Decoder Loss:  0.033734623 Validation Decoder Loss:  0.3421588
Encoder Loss:  0.04297968  || Decoder Loss:  0.033712655 Validation Decoder Loss:  0.34210566
Encoder Loss:  0.0429706  || Decoder Loss:  0.03369153 Validation Decoder Loss:  0.34207004
Encoder Loss:  0.042964727  || Decoder Loss:  0.03367204 Validation Decoder Loss:  0.3420569
Encoder Loss:  0.042952966  || Decoder Loss:  0.03365303 Validation Decoder Loss:  0.34204125
Model: siamese_net_lr_0.000908085710782808 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34204125
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_407 (Conv3D (None, 209, 10, 20, 1)    41        
_________________________________________________________________
dropout_841 (Dropout)        (None, 209, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_408 (Conv3D (None, 220, 11, 20, 1)    25        
_________________________________________________________________
reshape_152 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_281 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_843 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_282 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_281 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_845 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_282 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26082548  || Decoder Loss:  0.04557805 Validation Decoder Loss:  0.3459115
Encoder Loss:  0.05598588  || Decoder Loss:  0.03983884 Validation Decoder Loss:  0.33652994
Encoder Loss:  0.051607724  || Decoder Loss:  0.03378714 Validation Decoder Loss:  0.33570623
Encoder Loss:  0.05075443  || Decoder Loss:  0.03354206 Validation Decoder Loss:  0.3355294
Encoder Loss:  0.050645243  || Decoder Loss:  0.033366002 Validation Decoder Loss:  0.33569372
Encoder Loss:  0.050268874  || Decoder Loss:  0.033283383 Validation Decoder Loss:  0.33566853
Encoder Loss:  0.05023854  || Decoder Loss:  0.033233248 Validation Decoder Loss:  0.33566996
Encoder Loss:  0.05032851  || Decoder Loss:  0.033174355 Validation Decoder Loss:  0.33567822
Encoder Loss:  0.050213695  || Decoder Loss:  0.033115603 Validation Decoder Loss:  0.33563972
Encoder Loss:  0.05028648  || Decoder Loss:  0.033063058 Validation Decoder Loss:  0.33569068
Encoder Loss:  0.050363842  || Decoder Loss:  0.033015836 Validation Decoder Loss:  0.33577344
Encoder Loss:  0.05084252  || Decoder Loss:  0.032972798 Validation Decoder Loss:  0.3358033
Encoder Loss:  0.050102655  || Decoder Loss:  0.032937158 Validation Decoder Loss:  0.33593613
Encoder Loss:  0.05015445  || Decoder Loss:  0.03290365 Validation Decoder Loss:  0.33579746
Encoder Loss:  0.050195165  || Decoder Loss:  0.032874733 Validation Decoder Loss:  0.33582217
Encoder Loss:  0.050262213  || Decoder Loss:  0.032851104 Validation Decoder Loss:  0.33594903
Encoder Loss:  0.050349906  || Decoder Loss:  0.032827437 Validation Decoder Loss:  0.3359049
Encoder Loss:  0.050913487  || Decoder Loss:  0.032807115 Validation Decoder Loss:  0.33583945
Encoder Loss:  0.05010531  || Decoder Loss:  0.032788195 Validation Decoder Loss:  0.33600727
Encoder Loss:  0.050274424  || Decoder Loss:  0.03277121 Validation Decoder Loss:  0.3358759
Encoder Loss:  0.050149694  || Decoder Loss:  0.03275704 Validation Decoder Loss:  0.33612883
Encoder Loss:  0.050262168  || Decoder Loss:  0.032742705 Validation Decoder Loss:  0.33601257
Encoder Loss:  0.050175007  || Decoder Loss:  0.032732032 Validation Decoder Loss:  0.33603096
Encoder Loss:  0.05187655  || Decoder Loss:  0.032719377 Validation Decoder Loss:  0.33619952
Encoder Loss:  0.050056413  || Decoder Loss:  0.032711122 Validation Decoder Loss:  0.33630946
Encoder Loss:  0.05008044  || Decoder Loss:  0.03270236 Validation Decoder Loss:  0.33636296
Encoder Loss:  0.050221134  || Decoder Loss:  0.03269466 Validation Decoder Loss:  0.3364933
Encoder Loss:  0.05038233  || Decoder Loss:  0.03268753 Validation Decoder Loss:  0.33637485
Encoder Loss:  0.050085038  || Decoder Loss:  0.032679163 Validation Decoder Loss:  0.3364038
Encoder Loss:  0.05191243  || Decoder Loss:  0.032670196 Validation Decoder Loss:  0.33650568
Encoder Loss:  0.050051972  || Decoder Loss:  0.032664694 Validation Decoder Loss:  0.33655268
Encoder Loss:  0.050072417  || Decoder Loss:  0.0326591 Validation Decoder Loss:  0.33671305
Encoder Loss:  0.05022384  || Decoder Loss:  0.032653797 Validation Decoder Loss:  0.3368066
Encoder Loss:  0.050090685  || Decoder Loss:  0.032646023 Validation Decoder Loss:  0.33671087
Encoder Loss:  0.050186425  || Decoder Loss:  0.03263903 Validation Decoder Loss:  0.3368804
Encoder Loss:  0.05010263  || Decoder Loss:  0.0326332 Validation Decoder Loss:  0.3369486
Encoder Loss:  0.05018748  || Decoder Loss:  0.03262541 Validation Decoder Loss:  0.33703274
Encoder Loss:  0.05015671  || Decoder Loss:  0.032620843 Validation Decoder Loss:  0.33706653
Encoder Loss:  0.05011713  || Decoder Loss:  0.03261519 Validation Decoder Loss:  0.3370474
Encoder Loss:  0.050134487  || Decoder Loss:  0.03260993 Validation Decoder Loss:  0.33720753
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33720753
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_410 (Conv3D (None, 190, 5, 20, 1)     128       
_________________________________________________________________
dropout_847 (Dropout)        (None, 190, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_411 (Conv3D (None, 220, 11, 20, 1)    218       
_________________________________________________________________
reshape_153 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_283 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_849 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_284 (Conv2D)          (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_283 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_851 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_284 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29088572  || Decoder Loss:  0.065441 Validation Decoder Loss:  0.36755985
Encoder Loss:  0.2900177  || Decoder Loss:  0.06573392 Validation Decoder Loss:  0.367804
Encoder Loss:  0.288956  || Decoder Loss:  0.0661007 Validation Decoder Loss:  0.36805677
Encoder Loss:  0.28779417  || Decoder Loss:  0.06652738 Validation Decoder Loss:  0.368285
Encoder Loss:  0.28656417  || Decoder Loss:  0.067015365 Validation Decoder Loss:  0.3684752
Encoder Loss:  0.28527132  || Decoder Loss:  0.0675749 Validation Decoder Loss:  0.36862177
Encoder Loss:  0.2839126  || Decoder Loss:  0.0682215 Validation Decoder Loss:  0.3687224
Encoder Loss:  0.28248176  || Decoder Loss:  0.06897589 Validation Decoder Loss:  0.36877525
Encoder Loss:  0.28097  || Decoder Loss:  0.06986558 Validation Decoder Loss:  0.36877915
Encoder Loss:  0.27936476  || Decoder Loss:  0.070927404 Validation Decoder Loss:  0.36873394
Encoder Loss:  0.27764755  || Decoder Loss:  0.072211 Validation Decoder Loss:  0.36864024
Encoder Loss:  0.27578905  || Decoder Loss:  0.07378273 Validation Decoder Loss:  0.36849767
Encoder Loss:  0.27373868  || Decoder Loss:  0.07572733 Validation Decoder Loss:  0.36829615
Encoder Loss:  0.27139875  || Decoder Loss:  0.07813157 Validation Decoder Loss:  0.3679713
Encoder Loss:  0.26854667  || Decoder Loss:  0.080970615 Validation Decoder Loss:  0.3671738
Encoder Loss:  0.2645052  || Decoder Loss:  0.08335398 Validation Decoder Loss:  0.36370665
Encoder Loss:  0.25527546  || Decoder Loss:  0.07513131 Validation Decoder Loss:  0.34308505
Encoder Loss:  0.23496287  || Decoder Loss:  0.04334756 Validation Decoder Loss:  0.34458268
Encoder Loss:  0.21501859  || Decoder Loss:  0.0392278 Validation Decoder Loss:  0.34531155
Encoder Loss:  0.17445156  || Decoder Loss:  0.038424753 Validation Decoder Loss:  0.34981441
Encoder Loss:  0.09148538  || Decoder Loss:  0.038079772 Validation Decoder Loss:  0.34999746
Encoder Loss:  0.08802629  || Decoder Loss:  0.037950296 Validation Decoder Loss:  0.3463978
Encoder Loss:  0.07499104  || Decoder Loss:  0.0378473 Validation Decoder Loss:  0.34654385
Encoder Loss:  0.069464535  || Decoder Loss:  0.03776958 Validation Decoder Loss:  0.34568182
Encoder Loss:  0.07059207  || Decoder Loss:  0.037708163 Validation Decoder Loss:  0.34484398
Encoder Loss:  0.07009091  || Decoder Loss:  0.037654907 Validation Decoder Loss:  0.3444616
Encoder Loss:  0.069748536  || Decoder Loss:  0.03760549 Validation Decoder Loss:  0.34402284
Encoder Loss:  0.069798596  || Decoder Loss:  0.0375614 Validation Decoder Loss:  0.3436899
Encoder Loss:  0.06942705  || Decoder Loss:  0.037520614 Validation Decoder Loss:  0.34345055
Encoder Loss:  0.06934477  || Decoder Loss:  0.037482813 Validation Decoder Loss:  0.34326726
Encoder Loss:  0.069090694  || Decoder Loss:  0.037447535 Validation Decoder Loss:  0.34312674
Encoder Loss:  0.06894369  || Decoder Loss:  0.037414238 Validation Decoder Loss:  0.34303123
Encoder Loss:  0.0686783  || Decoder Loss:  0.037382446 Validation Decoder Loss:  0.34296077
Encoder Loss:  0.06852695  || Decoder Loss:  0.03735167 Validation Decoder Loss:  0.3429109
Encoder Loss:  0.06830087  || Decoder Loss:  0.037321284 Validation Decoder Loss:  0.34287083
Encoder Loss:  0.06809394  || Decoder Loss:  0.037290983 Validation Decoder Loss:  0.3428375
Encoder Loss:  0.06787499  || Decoder Loss:  0.037260316 Validation Decoder Loss:  0.34280485
Encoder Loss:  0.06764897  || Decoder Loss:  0.037228983 Validation Decoder Loss:  0.3427716
Encoder Loss:  0.06741314  || Decoder Loss:  0.03719677 Validation Decoder Loss:  0.34273595
Encoder Loss:  0.06717624  || Decoder Loss:  0.037163477 Validation Decoder Loss:  0.34269667
Model: siamese_net_lr_0.0009023676172249934 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34269667
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_413 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_853 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_414 (Conv3D (None, 220, 11, 20, 1)    448       
_________________________________________________________________
reshape_154 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_285 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_855 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_286 (Conv2D)          (None, 2420, 20, 1)       62        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_597"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_285 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_857 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_286 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23190954  || Decoder Loss:  0.104763344 Validation Decoder Loss:  0.37502056
Encoder Loss:  0.058409624  || Decoder Loss:  0.071063705 Validation Decoder Loss:  0.3550301
Encoder Loss:  0.053195704  || Decoder Loss:  0.058498334 Validation Decoder Loss:  0.3475265
Encoder Loss:  0.050624732  || Decoder Loss:  0.05165148 Validation Decoder Loss:  0.34215188
Encoder Loss:  0.048142724  || Decoder Loss:  0.04502896 Validation Decoder Loss:  0.33646256
Encoder Loss:  0.04477255  || Decoder Loss:  0.036040854 Validation Decoder Loss:  0.3277228
Encoder Loss:  0.044142567  || Decoder Loss:  0.034354605 Validation Decoder Loss:  0.32679707
Encoder Loss:  0.044067677  || Decoder Loss:  0.034149062 Validation Decoder Loss:  0.3266161
Encoder Loss:  0.044035837  || Decoder Loss:  0.03405856 Validation Decoder Loss:  0.32668304
Encoder Loss:  0.04403179  || Decoder Loss:  0.034046084 Validation Decoder Loss:  0.3266416
Encoder Loss:  0.043999963  || Decoder Loss:  0.033967204 Validation Decoder Loss:  0.32689735
Encoder Loss:  0.044026755  || Decoder Loss:  0.03400664 Validation Decoder Loss:  0.32669818
Encoder Loss:  0.04402173  || Decoder Loss:  0.03402444 Validation Decoder Loss:  0.3265214
Encoder Loss:  0.044016752  || Decoder Loss:  0.034007296 Validation Decoder Loss:  0.3269234
Encoder Loss:  0.04398726  || Decoder Loss:  0.033933293 Validation Decoder Loss:  0.32640404
Encoder Loss:  0.044014636  || Decoder Loss:  0.033996716 Validation Decoder Loss:  0.32678905
Encoder Loss:  0.044006404  || Decoder Loss:  0.033990584 Validation Decoder Loss:  0.32642436
Encoder Loss:  0.044022623  || Decoder Loss:  0.034018554 Validation Decoder Loss:  0.3269825
Encoder Loss:  0.044024438  || Decoder Loss:  0.034006122 Validation Decoder Loss:  0.3267445
Encoder Loss:  0.043978848  || Decoder Loss:  0.033912368 Validation Decoder Loss:  0.3265707
Encoder Loss:  0.04399289  || Decoder Loss:  0.03394929 Validation Decoder Loss:  0.32646006
Encoder Loss:  0.043992262  || Decoder Loss:  0.033945564 Validation Decoder Loss:  0.326053
Encoder Loss:  0.043964237  || Decoder Loss:  0.033871718 Validation Decoder Loss:  0.3260632
Encoder Loss:  0.043976422  || Decoder Loss:  0.03390039 Validation Decoder Loss:  0.32634267
Encoder Loss:  0.043977357  || Decoder Loss:  0.03388857 Validation Decoder Loss:  0.32607776
Encoder Loss:  0.043926854  || Decoder Loss:  0.033768784 Validation Decoder Loss:  0.3257264
Encoder Loss:  0.0439212  || Decoder Loss:  0.03375164 Validation Decoder Loss:  0.32559282
Encoder Loss:  0.043964066  || Decoder Loss:  0.033858642 Validation Decoder Loss:  0.3255898
Encoder Loss:  0.043953203  || Decoder Loss:  0.03384077 Validation Decoder Loss:  0.32524696
Encoder Loss:  0.043952074  || Decoder Loss:  0.03384149 Validation Decoder Loss:  0.32551146
Encoder Loss:  0.04395502  || Decoder Loss:  0.033842772 Validation Decoder Loss:  0.32534963
Encoder Loss:  0.04394823  || Decoder Loss:  0.033810012 Validation Decoder Loss:  0.32557267
Encoder Loss:  0.04393537  || Decoder Loss:  0.033697296 Validation Decoder Loss:  0.3246914
Encoder Loss:  0.043918647  || Decoder Loss:  0.0337546 Validation Decoder Loss:  0.32541418
Encoder Loss:  0.04390449  || Decoder Loss:  0.03371321 Validation Decoder Loss:  0.32529047
Encoder Loss:  0.043875657  || Decoder Loss:  0.033632413 Validation Decoder Loss:  0.32498205
Encoder Loss:  0.043911595  || Decoder Loss:  0.033615533 Validation Decoder Loss:  0.32515752
Encoder Loss:  0.04388299  || Decoder Loss:  0.033659037 Validation Decoder Loss:  0.32551113
Encoder Loss:  0.043904286  || Decoder Loss:  0.033661854 Validation Decoder Loss:  0.32457674
Encoder Loss:  0.043882504  || Decoder Loss:  0.033659812 Validation Decoder Loss:  0.325123
Model: siamese_net_lr_0.000625988781617887 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.325123
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_416 (Conv3D (None, 180, 7, 20, 1)     352       
_________________________________________________________________
dropout_859 (Dropout)        (None, 180, 7, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_417 (Conv3D (None, 220, 11, 20, 1)    206       
_________________________________________________________________
reshape_155 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 558
Trainable params: 558
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_287 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_861 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_288 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_287 (Conv2D (None, 2580, 20, 1)       162       
_________________________________________________________________
dropout_863 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_288 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.071914405  || Decoder Loss:  0.071914405 Validation Decoder Loss:  0.34628996
Encoder Loss:  0.046214085  || Decoder Loss:  0.046214085 Validation Decoder Loss:  0.3387841
Encoder Loss:  0.036867805  || Decoder Loss:  0.036867805 Validation Decoder Loss:  0.33912104
Encoder Loss:  0.035145026  || Decoder Loss:  0.035145026 Validation Decoder Loss:  0.34066343
Encoder Loss:  0.034698725  || Decoder Loss:  0.034698725 Validation Decoder Loss:  0.3446255
Encoder Loss:  0.03445787  || Decoder Loss:  0.03445787 Validation Decoder Loss:  0.34600624
Encoder Loss:  0.034257866  || Decoder Loss:  0.034257866 Validation Decoder Loss:  0.34728634
Encoder Loss:  0.034059435  || Decoder Loss:  0.034059435 Validation Decoder Loss:  0.34964025
Encoder Loss:  0.0338871  || Decoder Loss:  0.0338871 Validation Decoder Loss:  0.35032475
Encoder Loss:  0.03380583  || Decoder Loss:  0.03380583 Validation Decoder Loss:  0.35014316
Encoder Loss:  0.03378372  || Decoder Loss:  0.03378372 Validation Decoder Loss:  0.3497874
Encoder Loss:  0.033776868  || Decoder Loss:  0.033776868 Validation Decoder Loss:  0.34979424
Encoder Loss:  0.033772774  || Decoder Loss:  0.033772774 Validation Decoder Loss:  0.34986338
Encoder Loss:  0.033768598  || Decoder Loss:  0.033768598 Validation Decoder Loss:  0.34996122
Encoder Loss:  0.033763774  || Decoder Loss:  0.033763774 Validation Decoder Loss:  0.35007483
Encoder Loss:  0.03375829  || Decoder Loss:  0.03375829 Validation Decoder Loss:  0.35019356
Encoder Loss:  0.03375224  || Decoder Loss:  0.03375224 Validation Decoder Loss:  0.35030824
Encoder Loss:  0.033745848  || Decoder Loss:  0.033745848 Validation Decoder Loss:  0.35041416
Encoder Loss:  0.03373909  || Decoder Loss:  0.03373909 Validation Decoder Loss:  0.35051602
Encoder Loss:  0.033731893  || Decoder Loss:  0.033731893 Validation Decoder Loss:  0.35063416
Encoder Loss:  0.033724144  || Decoder Loss:  0.033724144 Validation Decoder Loss:  0.35081485
Encoder Loss:  0.03371563  || Decoder Loss:  0.03371563 Validation Decoder Loss:  0.35113794
Encoder Loss:  0.033706482  || Decoder Loss:  0.033706482 Validation Decoder Loss:  0.35162327
Encoder Loss:  0.033696268  || Decoder Loss:  0.033696268 Validation Decoder Loss:  0.3515864
Encoder Loss:  0.033681475  || Decoder Loss:  0.033681475 Validation Decoder Loss:  0.35145724
Encoder Loss:  0.033664107  || Decoder Loss:  0.033664107 Validation Decoder Loss:  0.35170203
Encoder Loss:  0.033646356  || Decoder Loss:  0.033646356 Validation Decoder Loss:  0.3520754
Encoder Loss:  0.033629593  || Decoder Loss:  0.033629593 Validation Decoder Loss:  0.3523124
Encoder Loss:  0.03361503  || Decoder Loss:  0.03361503 Validation Decoder Loss:  0.35241932
Encoder Loss:  0.033602234  || Decoder Loss:  0.033602234 Validation Decoder Loss:  0.3525725
Encoder Loss:  0.033592008  || Decoder Loss:  0.033592008 Validation Decoder Loss:  0.3527143
Encoder Loss:  0.033584617  || Decoder Loss:  0.033584617 Validation Decoder Loss:  0.35280797
Encoder Loss:  0.033573616  || Decoder Loss:  0.033573616 Validation Decoder Loss:  0.35135245
Encoder Loss:  0.033555683  || Decoder Loss:  0.033555683 Validation Decoder Loss:  0.35100615
Encoder Loss:  0.03355153  || Decoder Loss:  0.03355153 Validation Decoder Loss:  0.35090476
Encoder Loss:  0.033548374  || Decoder Loss:  0.033548374 Validation Decoder Loss:  0.35086027
Encoder Loss:  0.033545278  || Decoder Loss:  0.033545278 Validation Decoder Loss:  0.35083616
Encoder Loss:  0.033542313  || Decoder Loss:  0.033542313 Validation Decoder Loss:  0.35082054
Encoder Loss:  0.033539575  || Decoder Loss:  0.033539575 Validation Decoder Loss:  0.35080928
Encoder Loss:  0.03353707  || Decoder Loss:  0.03353707 Validation Decoder Loss:  0.3508007
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3508007
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_419 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_865 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_420 (Conv3D (None, 220, 11, 20, 1)    218       
_________________________________________________________________
reshape_156 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 220
Trainable params: 220
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_289 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_867 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_290 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_289 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_869 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_290 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39059266  || Decoder Loss:  0.057278622 Validation Decoder Loss:  0.3700161
Encoder Loss:  0.38714263  || Decoder Loss:  0.05740043 Validation Decoder Loss:  0.37166756
Encoder Loss:  0.38308495  || Decoder Loss:  0.05750365 Validation Decoder Loss:  0.37327975
Encoder Loss:  0.37859753  || Decoder Loss:  0.057581708 Validation Decoder Loss:  0.37481797
Encoder Loss:  0.37352407  || Decoder Loss:  0.05763873 Validation Decoder Loss:  0.3762676
Encoder Loss:  0.3674453  || Decoder Loss:  0.057675395 Validation Decoder Loss:  0.3776148
Encoder Loss:  0.3594597  || Decoder Loss:  0.05768554 Validation Decoder Loss:  0.37886745
Encoder Loss:  0.34824088  || Decoder Loss:  0.0576656 Validation Decoder Loss:  0.38005555
Encoder Loss:  0.33277404  || Decoder Loss:  0.057627007 Validation Decoder Loss:  0.38129836
Encoder Loss:  0.3130642  || Decoder Loss:  0.057582706 Validation Decoder Loss:  0.38276654
Encoder Loss:  0.2899295  || Decoder Loss:  0.05752601 Validation Decoder Loss:  0.3843984
Encoder Loss:  0.26425084  || Decoder Loss:  0.05744317 Validation Decoder Loss:  0.38610548
Encoder Loss:  0.23622246  || Decoder Loss:  0.05729272 Validation Decoder Loss:  0.38837683
Encoder Loss:  0.20298427  || Decoder Loss:  0.056902636 Validation Decoder Loss:  0.39422226
Encoder Loss:  0.11539027  || Decoder Loss:  0.055451002 Validation Decoder Loss:  0.40122622
Encoder Loss:  0.056755565  || Decoder Loss:  0.049512006 Validation Decoder Loss:  0.35268867
Encoder Loss:  0.05386353  || Decoder Loss:  0.04273037 Validation Decoder Loss:  0.35407424
Encoder Loss:  0.05313663  || Decoder Loss:  0.040489096 Validation Decoder Loss:  0.34841132
Encoder Loss:  0.05288301  || Decoder Loss:  0.03933869 Validation Decoder Loss:  0.34773633
Encoder Loss:  0.052870985  || Decoder Loss:  0.038588062 Validation Decoder Loss:  0.34688026
Encoder Loss:  0.05285139  || Decoder Loss:  0.038059246 Validation Decoder Loss:  0.34621602
Encoder Loss:  0.052462243  || Decoder Loss:  0.03766792 Validation Decoder Loss:  0.34578532
Encoder Loss:  0.052337375  || Decoder Loss:  0.037368212 Validation Decoder Loss:  0.34543002
Encoder Loss:  0.05231786  || Decoder Loss:  0.037131496 Validation Decoder Loss:  0.34515175
Encoder Loss:  0.052067876  || Decoder Loss:  0.036940265 Validation Decoder Loss:  0.34492135
Encoder Loss:  0.052383825  || Decoder Loss:  0.036782462 Validation Decoder Loss:  0.3447284
Encoder Loss:  0.052148752  || Decoder Loss:  0.0366496 Validation Decoder Loss:  0.34457856
Encoder Loss:  0.051897235  || Decoder Loss:  0.03653709 Validation Decoder Loss:  0.34444052
Encoder Loss:  0.051903654  || Decoder Loss:  0.036440533 Validation Decoder Loss:  0.34431627
Encoder Loss:  0.051523972  || Decoder Loss:  0.036356725 Validation Decoder Loss:  0.34421194
Encoder Loss:  0.05138885  || Decoder Loss:  0.036283556 Validation Decoder Loss:  0.34411344
Encoder Loss:  0.051279176  || Decoder Loss:  0.036219154 Validation Decoder Loss:  0.3440233
Encoder Loss:  0.05164136  || Decoder Loss:  0.03616161 Validation Decoder Loss:  0.34395018
Encoder Loss:  0.051223036  || Decoder Loss:  0.03610991 Validation Decoder Loss:  0.34388846
Encoder Loss:  0.051043183  || Decoder Loss:  0.036063578 Validation Decoder Loss:  0.34382793
Encoder Loss:  0.051095262  || Decoder Loss:  0.03602172 Validation Decoder Loss:  0.34377104
Encoder Loss:  0.050720524  || Decoder Loss:  0.035983596 Validation Decoder Loss:  0.3437271
Encoder Loss:  0.050602894  || Decoder Loss:  0.035948858 Validation Decoder Loss:  0.34367615
Encoder Loss:  0.05055955  || Decoder Loss:  0.03591682 Validation Decoder Loss:  0.34363538
Encoder Loss:  0.050584916  || Decoder Loss:  0.035887107 Validation Decoder Loss:  0.34359908
Model: siamese_net_lr_0.000979175237686455 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34359908
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_422 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_871 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_423 (Conv3D (None, 220, 11, 20, 1)    466       
_________________________________________________________________
reshape_157 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_608"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_291 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_873 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_292 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_291 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_875 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_292 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08287682  || Decoder Loss:  0.08287682 Validation Decoder Loss:  0.3685509
Encoder Loss:  0.08285015  || Decoder Loss:  0.08285015 Validation Decoder Loss:  0.3689737
Encoder Loss:  0.08282613  || Decoder Loss:  0.08282613 Validation Decoder Loss:  0.36936405
Encoder Loss:  0.08280343  || Decoder Loss:  0.08280343 Validation Decoder Loss:  0.36973816
Encoder Loss:  0.082781315  || Decoder Loss:  0.082781315 Validation Decoder Loss:  0.37010357
Encoder Loss:  0.082759626  || Decoder Loss:  0.082759626 Validation Decoder Loss:  0.3704638
Encoder Loss:  0.08273792  || Decoder Loss:  0.08273792 Validation Decoder Loss:  0.37082028
Encoder Loss:  0.08271653  || Decoder Loss:  0.08271653 Validation Decoder Loss:  0.3711736
Encoder Loss:  0.08269497  || Decoder Loss:  0.08269497 Validation Decoder Loss:  0.37152392
Encoder Loss:  0.08267353  || Decoder Loss:  0.08267353 Validation Decoder Loss:  0.37187138
Encoder Loss:  0.08265212  || Decoder Loss:  0.08265212 Validation Decoder Loss:  0.37221587
Encoder Loss:  0.0826306  || Decoder Loss:  0.0826306 Validation Decoder Loss:  0.37255734
Encoder Loss:  0.08260907  || Decoder Loss:  0.08260907 Validation Decoder Loss:  0.3728958
Encoder Loss:  0.082587376  || Decoder Loss:  0.082587376 Validation Decoder Loss:  0.3732311
Encoder Loss:  0.08256567  || Decoder Loss:  0.08256567 Validation Decoder Loss:  0.3735633
Encoder Loss:  0.082543805  || Decoder Loss:  0.082543805 Validation Decoder Loss:  0.37389213
Encoder Loss:  0.08252177  || Decoder Loss:  0.08252177 Validation Decoder Loss:  0.3742176
Encoder Loss:  0.0824996  || Decoder Loss:  0.0824996 Validation Decoder Loss:  0.37453967
Encoder Loss:  0.0824772  || Decoder Loss:  0.0824772 Validation Decoder Loss:  0.37485823
Encoder Loss:  0.08245457  || Decoder Loss:  0.08245457 Validation Decoder Loss:  0.37517336
Encoder Loss:  0.08243167  || Decoder Loss:  0.08243167 Validation Decoder Loss:  0.37548515
Encoder Loss:  0.08240842  || Decoder Loss:  0.08240842 Validation Decoder Loss:  0.37579376
Encoder Loss:  0.08238485  || Decoder Loss:  0.08238485 Validation Decoder Loss:  0.3760994
Encoder Loss:  0.08236092  || Decoder Loss:  0.08236092 Validation Decoder Loss:  0.37640223
Encoder Loss:  0.082336575  || Decoder Loss:  0.082336575 Validation Decoder Loss:  0.37670252
Encoder Loss:  0.08231176  || Decoder Loss:  0.08231176 Validation Decoder Loss:  0.3770004
Encoder Loss:  0.082286425  || Decoder Loss:  0.082286425 Validation Decoder Loss:  0.3772961
Encoder Loss:  0.08226059  || Decoder Loss:  0.08226059 Validation Decoder Loss:  0.37758985
Encoder Loss:  0.082234144  || Decoder Loss:  0.082234144 Validation Decoder Loss:  0.37788194
Encoder Loss:  0.082206994  || Decoder Loss:  0.082206994 Validation Decoder Loss:  0.3781726
Encoder Loss:  0.08217926  || Decoder Loss:  0.08217926 Validation Decoder Loss:  0.37846202
Encoder Loss:  0.08215066  || Decoder Loss:  0.08215066 Validation Decoder Loss:  0.37875047
Encoder Loss:  0.08212134  || Decoder Loss:  0.08212134 Validation Decoder Loss:  0.37903804
Encoder Loss:  0.082091086  || Decoder Loss:  0.082091086 Validation Decoder Loss:  0.3793248
Encoder Loss:  0.082059935  || Decoder Loss:  0.082059935 Validation Decoder Loss:  0.37961033
Encoder Loss:  0.08202768  || Decoder Loss:  0.08202768 Validation Decoder Loss:  0.3798941
Encoder Loss:  0.08199427  || Decoder Loss:  0.08199427 Validation Decoder Loss:  0.38017553
Encoder Loss:  0.08195948  || Decoder Loss:  0.08195948 Validation Decoder Loss:  0.3804568
Encoder Loss:  0.081923045  || Decoder Loss:  0.081923045 Validation Decoder Loss:  0.38074
Encoder Loss:  0.081884906  || Decoder Loss:  0.081884906 Validation Decoder Loss:  0.38102576
Model: siamese_net_lr_1.4388136119352304e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38102576
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_425 (Conv3D (None, 82, 5, 20, 1)      20        
_________________________________________________________________
dropout_877 (Dropout)        (None, 82, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_426 (Conv3D (None, 220, 11, 20, 1)    974       
_________________________________________________________________
reshape_158 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 994
Trainable params: 994
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_612"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_293 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_879 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_294 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_293 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_881 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_294 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.371687
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271794 Validation Decoder Loss:  0.371687
Encoder Loss:  0.3734067  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168705
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168705
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.3734067  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.371687
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427177 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.3734067  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.3734067  || Decoder Loss:  0.09427177 Validation Decoder Loss:  0.371687
Encoder Loss:  0.3734067  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427177 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.3734067  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271794 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.371687
Encoder Loss:  0.3734067  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.371687
Encoder Loss:  0.37340677  || Decoder Loss:  0.094271764 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168705
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Encoder Loss:  0.37340677  || Decoder Loss:  0.09427179 Validation Decoder Loss:  0.37168702
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37168702
Model: "sequential_614"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_428 (Conv3D (None, 210, 6, 20, 1)     295       
_________________________________________________________________
dropout_883 (Dropout)        (None, 210, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_429 (Conv3D (None, 220, 11, 20, 1)    67        
_________________________________________________________________
reshape_159 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 362
Trainable params: 362
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_295 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_885 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_296 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_295 (Conv2D (None, 2480, 20, 1)       62        
_________________________________________________________________
dropout_887 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_296 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.052686922  || Decoder Loss:  0.052686922 Validation Decoder Loss:  0.35614288
Encoder Loss:  0.05266202  || Decoder Loss:  0.05266202 Validation Decoder Loss:  0.35674825
Encoder Loss:  0.05263338  || Decoder Loss:  0.05263338 Validation Decoder Loss:  0.3573478
Encoder Loss:  0.05260412  || Decoder Loss:  0.05260412 Validation Decoder Loss:  0.35789266
Encoder Loss:  0.052575134  || Decoder Loss:  0.052575134 Validation Decoder Loss:  0.35838234
Encoder Loss:  0.05254648  || Decoder Loss:  0.05254648 Validation Decoder Loss:  0.35882583
Encoder Loss:  0.052517965  || Decoder Loss:  0.052517965 Validation Decoder Loss:  0.35923135
Encoder Loss:  0.052489396  || Decoder Loss:  0.052489396 Validation Decoder Loss:  0.35960555
Encoder Loss:  0.052460544  || Decoder Loss:  0.052460544 Validation Decoder Loss:  0.35995376
Encoder Loss:  0.052431203  || Decoder Loss:  0.052431203 Validation Decoder Loss:  0.36028063
Encoder Loss:  0.052401163  || Decoder Loss:  0.052401163 Validation Decoder Loss:  0.36058998
Encoder Loss:  0.052370198  || Decoder Loss:  0.052370198 Validation Decoder Loss:  0.360885
Encoder Loss:  0.05233807  || Decoder Loss:  0.05233807 Validation Decoder Loss:  0.36116838
Encoder Loss:  0.0523045  || Decoder Loss:  0.0523045 Validation Decoder Loss:  0.36144286
Encoder Loss:  0.052269157  || Decoder Loss:  0.052269157 Validation Decoder Loss:  0.361711
Encoder Loss:  0.052231636  || Decoder Loss:  0.052231636 Validation Decoder Loss:  0.36197588
Encoder Loss:  0.05219147  || Decoder Loss:  0.05219147 Validation Decoder Loss:  0.36224085
Encoder Loss:  0.05214801  || Decoder Loss:  0.05214801 Validation Decoder Loss:  0.3625101
Encoder Loss:  0.052100424  || Decoder Loss:  0.052100424 Validation Decoder Loss:  0.36278853
Encoder Loss:  0.052047577  || Decoder Loss:  0.052047577 Validation Decoder Loss:  0.363083
Encoder Loss:  0.051987763  || Decoder Loss:  0.051987763 Validation Decoder Loss:  0.36340386
Encoder Loss:  0.05191839  || Decoder Loss:  0.05191839 Validation Decoder Loss:  0.36376947
Encoder Loss:  0.051835112  || Decoder Loss:  0.051835112 Validation Decoder Loss:  0.364217
Encoder Loss:  0.051729973  || Decoder Loss:  0.051729973 Validation Decoder Loss:  0.36483213
Encoder Loss:  0.05158641  || Decoder Loss:  0.05158641 Validation Decoder Loss:  0.36584628
Encoder Loss:  0.051362637  || Decoder Loss:  0.051362637 Validation Decoder Loss:  0.36801937
Encoder Loss:  0.050923128  || Decoder Loss:  0.050923128 Validation Decoder Loss:  0.37394643
Encoder Loss:  0.049773257  || Decoder Loss:  0.049773257 Validation Decoder Loss:  0.37944588
Encoder Loss:  0.04710928  || Decoder Loss:  0.04710928 Validation Decoder Loss:  0.34618428
Encoder Loss:  0.045246363  || Decoder Loss:  0.045246363 Validation Decoder Loss:  0.3524412
Encoder Loss:  0.043606542  || Decoder Loss:  0.043606542 Validation Decoder Loss:  0.34841332
Encoder Loss:  0.04229695  || Decoder Loss:  0.04229695 Validation Decoder Loss:  0.34380165
Encoder Loss:  0.041432664  || Decoder Loss:  0.041432664 Validation Decoder Loss:  0.34464562
Encoder Loss:  0.040733535  || Decoder Loss:  0.040733535 Validation Decoder Loss:  0.34152505
Encoder Loss:  0.040068984  || Decoder Loss:  0.040068984 Validation Decoder Loss:  0.34064105
Encoder Loss:  0.03967961  || Decoder Loss:  0.03967961 Validation Decoder Loss:  0.33981204
Encoder Loss:  0.039314196  || Decoder Loss:  0.039314196 Validation Decoder Loss:  0.33947113
Encoder Loss:  0.039035797  || Decoder Loss:  0.039035797 Validation Decoder Loss:  0.3391747
Encoder Loss:  0.0387945  || Decoder Loss:  0.0387945 Validation Decoder Loss:  0.33892572
Encoder Loss:  0.038569648  || Decoder Loss:  0.038569648 Validation Decoder Loss:  0.3387451
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3387451
Model: "sequential_618"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_431 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_889 (Dropout)        (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_432 (Conv3D (None, 220, 11, 20, 1)    519       
_________________________________________________________________
reshape_160 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 531
Trainable params: 531
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_297 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_891 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_298 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_621"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_297 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_893 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_298 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13837926  || Decoder Loss:  0.0778563 Validation Decoder Loss:  0.326754
Encoder Loss:  0.053036474  || Decoder Loss:  0.054573644 Validation Decoder Loss:  0.3350948
Encoder Loss:  0.04237923  || Decoder Loss:  0.036798336 Validation Decoder Loss:  0.33528933
Encoder Loss:  0.040275503  || Decoder Loss:  0.03341582 Validation Decoder Loss:  0.33468354
Encoder Loss:  0.040149927  || Decoder Loss:  0.033202395 Validation Decoder Loss:  0.33487433
Encoder Loss:  0.04009707  || Decoder Loss:  0.03310035 Validation Decoder Loss:  0.335152
Encoder Loss:  0.040064372  || Decoder Loss:  0.033045225 Validation Decoder Loss:  0.3355667
Encoder Loss:  0.040043797  || Decoder Loss:  0.033020608 Validation Decoder Loss:  0.3363406
Encoder Loss:  0.040041104  || Decoder Loss:  0.033008423 Validation Decoder Loss:  0.33682418
Encoder Loss:  0.04008008  || Decoder Loss:  0.032966457 Validation Decoder Loss:  0.3374359
Encoder Loss:  0.040009513  || Decoder Loss:  0.03295528 Validation Decoder Loss:  0.33791038
Encoder Loss:  0.04000535  || Decoder Loss:  0.032945737 Validation Decoder Loss:  0.33820945
Encoder Loss:  0.039992675  || Decoder Loss:  0.032930523 Validation Decoder Loss:  0.33852684
Encoder Loss:  0.03998932  || Decoder Loss:  0.032925364 Validation Decoder Loss:  0.33918288
Encoder Loss:  0.039990354  || Decoder Loss:  0.03292629 Validation Decoder Loss:  0.33977646
Encoder Loss:  0.040014524  || Decoder Loss:  0.032946818 Validation Decoder Loss:  0.3397581
Encoder Loss:  0.03999926  || Decoder Loss:  0.03294604 Validation Decoder Loss:  0.34018487
Encoder Loss:  0.04001125  || Decoder Loss:  0.03295411 Validation Decoder Loss:  0.34017783
Encoder Loss:  0.040006943  || Decoder Loss:  0.032949027 Validation Decoder Loss:  0.34020334
Encoder Loss:  0.03999724  || Decoder Loss:  0.032938093 Validation Decoder Loss:  0.34061396
Encoder Loss:  0.040008243  || Decoder Loss:  0.032927103 Validation Decoder Loss:  0.3407663
Encoder Loss:  0.03999284  || Decoder Loss:  0.03292671 Validation Decoder Loss:  0.3410017
Encoder Loss:  0.039990984  || Decoder Loss:  0.03292894 Validation Decoder Loss:  0.34100884
Encoder Loss:  0.039987974  || Decoder Loss:  0.03293714 Validation Decoder Loss:  0.34118965
Encoder Loss:  0.040005583  || Decoder Loss:  0.032951012 Validation Decoder Loss:  0.3411649
Encoder Loss:  0.04001272  || Decoder Loss:  0.032936893 Validation Decoder Loss:  0.34125492
Encoder Loss:  0.039992593  || Decoder Loss:  0.03293083 Validation Decoder Loss:  0.34128025
Encoder Loss:  0.040000886  || Decoder Loss:  0.032931484 Validation Decoder Loss:  0.34127718
Encoder Loss:  0.04000648  || Decoder Loss:  0.032947805 Validation Decoder Loss:  0.34112677
Encoder Loss:  0.039997887  || Decoder Loss:  0.03294112 Validation Decoder Loss:  0.34097648
Encoder Loss:  0.03999553  || Decoder Loss:  0.032939285 Validation Decoder Loss:  0.34095448
Encoder Loss:  0.03999032  || Decoder Loss:  0.032926027 Validation Decoder Loss:  0.34143573
Encoder Loss:  0.040018603  || Decoder Loss:  0.032955084 Validation Decoder Loss:  0.3408491
Encoder Loss:  0.040000297  || Decoder Loss:  0.03293742 Validation Decoder Loss:  0.34074268
Encoder Loss:  0.03999974  || Decoder Loss:  0.032932416 Validation Decoder Loss:  0.34088874
Encoder Loss:  0.039999243  || Decoder Loss:  0.03293998 Validation Decoder Loss:  0.3407935
Encoder Loss:  0.03999696  || Decoder Loss:  0.03294657 Validation Decoder Loss:  0.34093827
Encoder Loss:  0.040000714  || Decoder Loss:  0.03295232 Validation Decoder Loss:  0.34086758
Encoder Loss:  0.039993867  || Decoder Loss:  0.03294314 Validation Decoder Loss:  0.34061348
Encoder Loss:  0.040085264  || Decoder Loss:  0.0329669 Validation Decoder Loss:  0.34086284
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34086284
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_434 (Conv3D (None, 100, 5, 20, 1)     38        
_________________________________________________________________
dropout_895 (Dropout)        (None, 100, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_435 (Conv3D (None, 220, 11, 20, 1)    155       
_________________________________________________________________
reshape_161 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_624"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_299 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_897 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_300 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_299 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_899 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_300 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22296208  || Decoder Loss:  0.039987873 Validation Decoder Loss:  0.33773646
Encoder Loss:  0.050942186  || Decoder Loss:  0.034286916 Validation Decoder Loss:  0.32990003
Encoder Loss:  0.05003491  || Decoder Loss:  0.03354359 Validation Decoder Loss:  0.32988453
Encoder Loss:  0.05003767  || Decoder Loss:  0.033408895 Validation Decoder Loss:  0.32972956
Encoder Loss:  0.05004709  || Decoder Loss:  0.03328591 Validation Decoder Loss:  0.32970262
Encoder Loss:  0.050045237  || Decoder Loss:  0.0331886 Validation Decoder Loss:  0.3297475
Encoder Loss:  0.050050545  || Decoder Loss:  0.033123266 Validation Decoder Loss:  0.32961434
Encoder Loss:  0.050084416  || Decoder Loss:  0.03308305 Validation Decoder Loss:  0.32972753
Encoder Loss:  0.050066244  || Decoder Loss:  0.03304918 Validation Decoder Loss:  0.32998025
Encoder Loss:  0.050093956  || Decoder Loss:  0.03302555 Validation Decoder Loss:  0.33000165
Encoder Loss:  0.05006579  || Decoder Loss:  0.033004347 Validation Decoder Loss:  0.32985628
Encoder Loss:  0.05005245  || Decoder Loss:  0.032986306 Validation Decoder Loss:  0.33014244
Encoder Loss:  0.050064772  || Decoder Loss:  0.03296533 Validation Decoder Loss:  0.33036444
Encoder Loss:  0.050112873  || Decoder Loss:  0.032954913 Validation Decoder Loss:  0.3302356
Encoder Loss:  0.050046  || Decoder Loss:  0.032940313 Validation Decoder Loss:  0.33046407
Encoder Loss:  0.05010943  || Decoder Loss:  0.032926857 Validation Decoder Loss:  0.33047378
Encoder Loss:  0.050076507  || Decoder Loss:  0.032915767 Validation Decoder Loss:  0.33029762
Encoder Loss:  0.050060734  || Decoder Loss:  0.03290484 Validation Decoder Loss:  0.3305028
Encoder Loss:  0.050052714  || Decoder Loss:  0.032899927 Validation Decoder Loss:  0.33043933
Encoder Loss:  0.050199218  || Decoder Loss:  0.032891944 Validation Decoder Loss:  0.33046603
Encoder Loss:  0.050029617  || Decoder Loss:  0.0328794 Validation Decoder Loss:  0.33041453
Encoder Loss:  0.05004403  || Decoder Loss:  0.032875217 Validation Decoder Loss:  0.33076465
Encoder Loss:  0.050298233  || Decoder Loss:  0.032868322 Validation Decoder Loss:  0.33069116
Encoder Loss:  0.05002507  || Decoder Loss:  0.03285801 Validation Decoder Loss:  0.3303806
Encoder Loss:  0.0500757  || Decoder Loss:  0.03285246 Validation Decoder Loss:  0.3305478
Encoder Loss:  0.05005348  || Decoder Loss:  0.032851286 Validation Decoder Loss:  0.3308019
Encoder Loss:  0.050047517  || Decoder Loss:  0.032843627 Validation Decoder Loss:  0.3304794
Encoder Loss:  0.050156638  || Decoder Loss:  0.032847 Validation Decoder Loss:  0.33079547
Encoder Loss:  0.050035283  || Decoder Loss:  0.032832347 Validation Decoder Loss:  0.33082655
Encoder Loss:  0.050060764  || Decoder Loss:  0.032827485 Validation Decoder Loss:  0.3304334
Encoder Loss:  0.05007707  || Decoder Loss:  0.032814924 Validation Decoder Loss:  0.33056223
Encoder Loss:  0.0500706  || Decoder Loss:  0.032816492 Validation Decoder Loss:  0.330436
Encoder Loss:  0.050386637  || Decoder Loss:  0.03281777 Validation Decoder Loss:  0.33023706
Encoder Loss:  0.050020017  || Decoder Loss:  0.032809313 Validation Decoder Loss:  0.33067548
Encoder Loss:  0.050031614  || Decoder Loss:  0.03280742 Validation Decoder Loss:  0.33050263
Encoder Loss:  0.05004471  || Decoder Loss:  0.03280371 Validation Decoder Loss:  0.33083352
Encoder Loss:  0.05005133  || Decoder Loss:  0.032792047 Validation Decoder Loss:  0.33018872
Encoder Loss:  0.050132766  || Decoder Loss:  0.03279594 Validation Decoder Loss:  0.33039442
Encoder Loss:  0.05008607  || Decoder Loss:  0.03279072 Validation Decoder Loss:  0.3300564
Encoder Loss:  0.050056625  || Decoder Loss:  0.03278095 Validation Decoder Loss:  0.3298511
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3298511
Model: "sequential_627"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_301 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_901 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_302 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_301 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_903 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_302 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_437 (Conv3D (None, 210, 10, 20, 1)    883       
_________________________________________________________________
dropout_905 (Dropout)        (None, 210, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_438 (Conv3D (None, 220, 11, 20, 1)    23        
_________________________________________________________________
reshape_162 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 906
Trainable params: 906
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_631"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_303 (Conv2D)          (None, 2450, 20, 1)       159       
_________________________________________________________________
dropout_907 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_304 (Conv2D)          (None, 2420, 20, 1)       32        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_303 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_909 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_304 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901313 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901313 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901332 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901336 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901336 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901325 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901317 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.056901332 Validation Decoder Loss:  0.35502282
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502285
Encoder Loss:  0.42076904  || Decoder Loss:  0.05690132 Validation Decoder Loss:  0.35502282
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35502282
Model: "sequential_633"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_440 (Conv3D (None, 213, 10, 20, 1)    175       
_________________________________________________________________
dropout_911 (Dropout)        (None, 213, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_441 (Conv3D (None, 220, 11, 20, 1)    17        
_________________________________________________________________
reshape_163 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_635"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_305 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_913 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_306 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_636"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_305 (Conv2D (None, 2450, 20, 1)       32        
_________________________________________________________________
dropout_915 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_306 (Conv2D (None, 2607, 20, 1)       159       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22306089  || Decoder Loss:  0.040459476 Validation Decoder Loss:  0.3395685
Encoder Loss:  0.050524026  || Decoder Loss:  0.036051344 Validation Decoder Loss:  0.33019853
Encoder Loss:  0.050302006  || Decoder Loss:  0.033816542 Validation Decoder Loss:  0.32736614
Encoder Loss:  0.05024362  || Decoder Loss:  0.033556033 Validation Decoder Loss:  0.32704908
Encoder Loss:  0.050184116  || Decoder Loss:  0.033476602 Validation Decoder Loss:  0.32673258
Encoder Loss:  0.050159995  || Decoder Loss:  0.03340849 Validation Decoder Loss:  0.32634842
Encoder Loss:  0.050146136  || Decoder Loss:  0.033350803 Validation Decoder Loss:  0.3259606
Encoder Loss:  0.05012425  || Decoder Loss:  0.033309232 Validation Decoder Loss:  0.32565314
Encoder Loss:  0.05013475  || Decoder Loss:  0.033275437 Validation Decoder Loss:  0.32542282
Encoder Loss:  0.05016475  || Decoder Loss:  0.033229474 Validation Decoder Loss:  0.32529205
Encoder Loss:  0.05007838  || Decoder Loss:  0.033197228 Validation Decoder Loss:  0.32536256
Encoder Loss:  0.050052643  || Decoder Loss:  0.033163063 Validation Decoder Loss:  0.325696
Encoder Loss:  0.050058547  || Decoder Loss:  0.033125706 Validation Decoder Loss:  0.3260906
Encoder Loss:  0.050046306  || Decoder Loss:  0.033092536 Validation Decoder Loss:  0.326406
Encoder Loss:  0.05006454  || Decoder Loss:  0.03306603 Validation Decoder Loss:  0.32668233
Encoder Loss:  0.05006417  || Decoder Loss:  0.03304602 Validation Decoder Loss:  0.3269124
Encoder Loss:  0.050056133  || Decoder Loss:  0.03302938 Validation Decoder Loss:  0.3270707
Encoder Loss:  0.05005675  || Decoder Loss:  0.033015836 Validation Decoder Loss:  0.32726312
Encoder Loss:  0.050055653  || Decoder Loss:  0.03300423 Validation Decoder Loss:  0.3273651
Encoder Loss:  0.05005698  || Decoder Loss:  0.032995224 Validation Decoder Loss:  0.32744667
Encoder Loss:  0.050079074  || Decoder Loss:  0.03298738 Validation Decoder Loss:  0.32750678
Encoder Loss:  0.050136298  || Decoder Loss:  0.03298573 Validation Decoder Loss:  0.32757103
Encoder Loss:  0.05003433  || Decoder Loss:  0.032975305 Validation Decoder Loss:  0.32768714
Encoder Loss:  0.05005407  || Decoder Loss:  0.032969385 Validation Decoder Loss:  0.32772097
Encoder Loss:  0.050051127  || Decoder Loss:  0.032964353 Validation Decoder Loss:  0.3277118
Encoder Loss:  0.050047025  || Decoder Loss:  0.03295937 Validation Decoder Loss:  0.32792532
Encoder Loss:  0.050057326  || Decoder Loss:  0.032955993 Validation Decoder Loss:  0.32788134
Encoder Loss:  0.05003177  || Decoder Loss:  0.032951247 Validation Decoder Loss:  0.32780743
Encoder Loss:  0.0508088  || Decoder Loss:  0.03299116 Validation Decoder Loss:  0.3270865
Encoder Loss:  0.050043277  || Decoder Loss:  0.03296408 Validation Decoder Loss:  0.3272683
Encoder Loss:  0.05004271  || Decoder Loss:  0.032944836 Validation Decoder Loss:  0.32738495
Encoder Loss:  0.050052717  || Decoder Loss:  0.03293461 Validation Decoder Loss:  0.32758766
Encoder Loss:  0.050043892  || Decoder Loss:  0.032928687 Validation Decoder Loss:  0.32764584
Encoder Loss:  0.050048728  || Decoder Loss:  0.032925032 Validation Decoder Loss:  0.32766593
Encoder Loss:  0.05011536  || Decoder Loss:  0.032927655 Validation Decoder Loss:  0.32774922
Encoder Loss:  0.05003955  || Decoder Loss:  0.032922734 Validation Decoder Loss:  0.32788408
Encoder Loss:  0.05004833  || Decoder Loss:  0.03291992 Validation Decoder Loss:  0.32784888
Encoder Loss:  0.050049447  || Decoder Loss:  0.03291781 Validation Decoder Loss:  0.3279752
Encoder Loss:  0.05004224  || Decoder Loss:  0.032916788 Validation Decoder Loss:  0.32799804
Encoder Loss:  0.050052956  || Decoder Loss:  0.03291494 Validation Decoder Loss:  0.3279383
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3279383
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_443 (Conv3D (None, 210, 10, 20, 1)    295       
_________________________________________________________________
dropout_917 (Dropout)        (None, 210, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_444 (Conv3D (None, 220, 11, 20, 1)    23        
_________________________________________________________________
reshape_164 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_639"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_307 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_919 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_308 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_640"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_307 (Conv2D (None, 2560, 20, 1)       142       
_________________________________________________________________
dropout_921 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_308 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4302826  || Decoder Loss:  0.05454692 Validation Decoder Loss:  0.35074335
Encoder Loss:  0.20701924  || Decoder Loss:  0.18743311 Validation Decoder Loss:  0.36572242
Encoder Loss:  0.08665779  || Decoder Loss:  0.045336667 Validation Decoder Loss:  0.33874422
Encoder Loss:  0.075595714  || Decoder Loss:  0.036107425 Validation Decoder Loss:  0.33436656
Encoder Loss:  0.05284962  || Decoder Loss:  0.035114855 Validation Decoder Loss:  0.33371818
Encoder Loss:  0.051288214  || Decoder Loss:  0.034966048 Validation Decoder Loss:  0.33339447
Encoder Loss:  0.05095044  || Decoder Loss:  0.03490739 Validation Decoder Loss:  0.3331688
Encoder Loss:  0.050723787  || Decoder Loss:  0.034881834 Validation Decoder Loss:  0.33296168
Encoder Loss:  0.050571732  || Decoder Loss:  0.03486295 Validation Decoder Loss:  0.3327299
Encoder Loss:  0.050368775  || Decoder Loss:  0.034833726 Validation Decoder Loss:  0.3327464
Encoder Loss:  0.050252084  || Decoder Loss:  0.034789644 Validation Decoder Loss:  0.33295274
Encoder Loss:  0.050192285  || Decoder Loss:  0.034747727 Validation Decoder Loss:  0.33315766
Encoder Loss:  0.05016198  || Decoder Loss:  0.03471606 Validation Decoder Loss:  0.33325055
Encoder Loss:  0.050138086  || Decoder Loss:  0.034689777 Validation Decoder Loss:  0.33329087
Encoder Loss:  0.050127808  || Decoder Loss:  0.0346637 Validation Decoder Loss:  0.33331364
Encoder Loss:  0.05015038  || Decoder Loss:  0.034640323 Validation Decoder Loss:  0.33329886
Encoder Loss:  0.050141882  || Decoder Loss:  0.03461764 Validation Decoder Loss:  0.3332958
Encoder Loss:  0.05010048  || Decoder Loss:  0.034590397 Validation Decoder Loss:  0.33334348
Encoder Loss:  0.05010076  || Decoder Loss:  0.03456075 Validation Decoder Loss:  0.3333571
Encoder Loss:  0.050097853  || Decoder Loss:  0.03453016 Validation Decoder Loss:  0.33336052
Encoder Loss:  0.05008784  || Decoder Loss:  0.03449732 Validation Decoder Loss:  0.3333581
Encoder Loss:  0.05008701  || Decoder Loss:  0.03446171 Validation Decoder Loss:  0.3333557
Encoder Loss:  0.050091825  || Decoder Loss:  0.03442745 Validation Decoder Loss:  0.33333015
Encoder Loss:  0.05009275  || Decoder Loss:  0.034393687 Validation Decoder Loss:  0.33329603
Encoder Loss:  0.050091386  || Decoder Loss:  0.034358677 Validation Decoder Loss:  0.3332532
Encoder Loss:  0.050083537  || Decoder Loss:  0.034322176 Validation Decoder Loss:  0.33322036
Encoder Loss:  0.050089683  || Decoder Loss:  0.034287095 Validation Decoder Loss:  0.33320644
Encoder Loss:  0.050097078  || Decoder Loss:  0.03425292 Validation Decoder Loss:  0.33316272
Encoder Loss:  0.05007839  || Decoder Loss:  0.03421445 Validation Decoder Loss:  0.33318004
Encoder Loss:  0.050091535  || Decoder Loss:  0.03417646 Validation Decoder Loss:  0.33320618
Encoder Loss:  0.050075375  || Decoder Loss:  0.034132347 Validation Decoder Loss:  0.3332283
Encoder Loss:  0.050092123  || Decoder Loss:  0.034094695 Validation Decoder Loss:  0.33324197
Encoder Loss:  0.050083652  || Decoder Loss:  0.034052536 Validation Decoder Loss:  0.33323997
Encoder Loss:  0.050081655  || Decoder Loss:  0.034008276 Validation Decoder Loss:  0.33321673
Encoder Loss:  0.050079823  || Decoder Loss:  0.033967745 Validation Decoder Loss:  0.33315015
Encoder Loss:  0.05006373  || Decoder Loss:  0.033920635 Validation Decoder Loss:  0.33313492
Encoder Loss:  0.050061442  || Decoder Loss:  0.0338765 Validation Decoder Loss:  0.33331114
Encoder Loss:  0.050064173  || Decoder Loss:  0.033837408 Validation Decoder Loss:  0.33338577
Encoder Loss:  0.05006727  || Decoder Loss:  0.033804998 Validation Decoder Loss:  0.33341786
Encoder Loss:  0.05006588  || Decoder Loss:  0.033772558 Validation Decoder Loss:  0.33346897
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33346897
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_446 (Conv3D (None, 199, 10, 20, 1)    439       
_________________________________________________________________
dropout_923 (Dropout)        (None, 199, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_447 (Conv3D (None, 220, 11, 20, 1)    45        
_________________________________________________________________
reshape_165 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 484
Trainable params: 484
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_643"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_309 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_925 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_310 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_309 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_927 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_310 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.055165984  || Decoder Loss:  0.055165984 Validation Decoder Loss:  0.34245318
Encoder Loss:  0.041215304  || Decoder Loss:  0.041215304 Validation Decoder Loss:  0.33985716
Encoder Loss:  0.03529089  || Decoder Loss:  0.03529089 Validation Decoder Loss:  0.3380165
Encoder Loss:  0.034056738  || Decoder Loss:  0.034056738 Validation Decoder Loss:  0.34157825
Encoder Loss:  0.033760056  || Decoder Loss:  0.033760056 Validation Decoder Loss:  0.34370434
Encoder Loss:  0.033534925  || Decoder Loss:  0.033534925 Validation Decoder Loss:  0.34598202
Encoder Loss:  0.03337339  || Decoder Loss:  0.03337339 Validation Decoder Loss:  0.34712803
Encoder Loss:  0.03326715  || Decoder Loss:  0.03326715 Validation Decoder Loss:  0.347417
Encoder Loss:  0.03318689  || Decoder Loss:  0.03318689 Validation Decoder Loss:  0.34759104
Encoder Loss:  0.03311309  || Decoder Loss:  0.03311309 Validation Decoder Loss:  0.3470959
Encoder Loss:  0.03302507  || Decoder Loss:  0.03302507 Validation Decoder Loss:  0.34700942
Encoder Loss:  0.03288727  || Decoder Loss:  0.03288727 Validation Decoder Loss:  0.34659973
Encoder Loss:  0.032710746  || Decoder Loss:  0.032710746 Validation Decoder Loss:  0.34231758
Encoder Loss:  0.03264758  || Decoder Loss:  0.03264758 Validation Decoder Loss:  0.34361878
Encoder Loss:  0.03260328  || Decoder Loss:  0.03260328 Validation Decoder Loss:  0.34344006
Encoder Loss:  0.032570254  || Decoder Loss:  0.032570254 Validation Decoder Loss:  0.34300807
Encoder Loss:  0.032541025  || Decoder Loss:  0.032541025 Validation Decoder Loss:  0.34228408
Encoder Loss:  0.03251424  || Decoder Loss:  0.03251424 Validation Decoder Loss:  0.34157887
Encoder Loss:  0.03248899  || Decoder Loss:  0.03248899 Validation Decoder Loss:  0.34104222
Encoder Loss:  0.032466017  || Decoder Loss:  0.032466017 Validation Decoder Loss:  0.34068847
Encoder Loss:  0.032445796  || Decoder Loss:  0.032445796 Validation Decoder Loss:  0.3404966
Encoder Loss:  0.032427937  || Decoder Loss:  0.032427937 Validation Decoder Loss:  0.34039238
Encoder Loss:  0.032412052  || Decoder Loss:  0.032412052 Validation Decoder Loss:  0.34033144
Encoder Loss:  0.032397676  || Decoder Loss:  0.032397676 Validation Decoder Loss:  0.34029517
Encoder Loss:  0.03238443  || Decoder Loss:  0.03238443 Validation Decoder Loss:  0.34027475
Encoder Loss:  0.032371867  || Decoder Loss:  0.032371867 Validation Decoder Loss:  0.3402656
Encoder Loss:  0.032359727  || Decoder Loss:  0.032359727 Validation Decoder Loss:  0.34026662
Encoder Loss:  0.03234787  || Decoder Loss:  0.03234787 Validation Decoder Loss:  0.34027642
Encoder Loss:  0.032336432  || Decoder Loss:  0.032336432 Validation Decoder Loss:  0.34028992
Encoder Loss:  0.032325685  || Decoder Loss:  0.032325685 Validation Decoder Loss:  0.34030226
Encoder Loss:  0.032315977  || Decoder Loss:  0.032315977 Validation Decoder Loss:  0.34031257
Encoder Loss:  0.032307304  || Decoder Loss:  0.032307304 Validation Decoder Loss:  0.34032196
Encoder Loss:  0.03229962  || Decoder Loss:  0.03229962 Validation Decoder Loss:  0.34033096
Encoder Loss:  0.032292686  || Decoder Loss:  0.032292686 Validation Decoder Loss:  0.34033948
Encoder Loss:  0.03228631  || Decoder Loss:  0.03228631 Validation Decoder Loss:  0.34034753
Encoder Loss:  0.032280356  || Decoder Loss:  0.032280356 Validation Decoder Loss:  0.34035534
Encoder Loss:  0.03227471  || Decoder Loss:  0.03227471 Validation Decoder Loss:  0.3403631
Encoder Loss:  0.03226931  || Decoder Loss:  0.03226931 Validation Decoder Loss:  0.340371
Encoder Loss:  0.032264087  || Decoder Loss:  0.032264087 Validation Decoder Loss:  0.340379
Encoder Loss:  0.03225909  || Decoder Loss:  0.03225909 Validation Decoder Loss:  0.340387
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.340387
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_449 (Conv3D (None, 219, 10, 20, 1)    559       
_________________________________________________________________
dropout_929 (Dropout)        (None, 219, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_450 (Conv3D (None, 220, 11, 20, 1)    5         
_________________________________________________________________
reshape_166 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 564
Trainable params: 564
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_647"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_311 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_931 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_312 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_311 (Conv2D (None, 2460, 20, 1)       42        
_________________________________________________________________
dropout_933 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_312 (Conv2D (None, 2607, 20, 1)       149       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03864884  || Decoder Loss:  0.03864884 Validation Decoder Loss:  0.3420487
Encoder Loss:  0.034762193  || Decoder Loss:  0.034762193 Validation Decoder Loss:  0.3365283
Encoder Loss:  0.033532653  || Decoder Loss:  0.033532653 Validation Decoder Loss:  0.33163482
Encoder Loss:  0.033228524  || Decoder Loss:  0.033228524 Validation Decoder Loss:  0.3312624
Encoder Loss:  0.033105727  || Decoder Loss:  0.033105727 Validation Decoder Loss:  0.33098406
Encoder Loss:  0.032991543  || Decoder Loss:  0.032991543 Validation Decoder Loss:  0.33086318
Encoder Loss:  0.03290324  || Decoder Loss:  0.03290324 Validation Decoder Loss:  0.33080864
Encoder Loss:  0.032839365  || Decoder Loss:  0.032839365 Validation Decoder Loss:  0.33078724
Encoder Loss:  0.03279083  || Decoder Loss:  0.03279083 Validation Decoder Loss:  0.33080798
Encoder Loss:  0.032752033  || Decoder Loss:  0.032752033 Validation Decoder Loss:  0.33085
Encoder Loss:  0.032719113  || Decoder Loss:  0.032719113 Validation Decoder Loss:  0.3308977
Encoder Loss:  0.032690052  || Decoder Loss:  0.032690052 Validation Decoder Loss:  0.33094606
Encoder Loss:  0.032664116  || Decoder Loss:  0.032664116 Validation Decoder Loss:  0.33099467
Encoder Loss:  0.032640785  || Decoder Loss:  0.032640785 Validation Decoder Loss:  0.33104354
Encoder Loss:  0.032619935  || Decoder Loss:  0.032619935 Validation Decoder Loss:  0.3310923
Encoder Loss:  0.03260126  || Decoder Loss:  0.03260126 Validation Decoder Loss:  0.33113998
Encoder Loss:  0.03258451  || Decoder Loss:  0.03258451 Validation Decoder Loss:  0.33118552
Encoder Loss:  0.032569516  || Decoder Loss:  0.032569516 Validation Decoder Loss:  0.3312279
Encoder Loss:  0.032556027  || Decoder Loss:  0.032556027 Validation Decoder Loss:  0.33126634
Encoder Loss:  0.032543804  || Decoder Loss:  0.032543804 Validation Decoder Loss:  0.33130044
Encoder Loss:  0.032532718  || Decoder Loss:  0.032532718 Validation Decoder Loss:  0.33132988
Encoder Loss:  0.032522507  || Decoder Loss:  0.032522507 Validation Decoder Loss:  0.33135462
Encoder Loss:  0.032513134  || Decoder Loss:  0.032513134 Validation Decoder Loss:  0.3313746
Encoder Loss:  0.032504432  || Decoder Loss:  0.032504432 Validation Decoder Loss:  0.33138984
Encoder Loss:  0.03249622  || Decoder Loss:  0.03249622 Validation Decoder Loss:  0.33140045
Encoder Loss:  0.032488547  || Decoder Loss:  0.032488547 Validation Decoder Loss:  0.3314066
Encoder Loss:  0.032481246  || Decoder Loss:  0.032481246 Validation Decoder Loss:  0.33140832
Encoder Loss:  0.03247423  || Decoder Loss:  0.03247423 Validation Decoder Loss:  0.3314057
Encoder Loss:  0.03246751  || Decoder Loss:  0.03246751 Validation Decoder Loss:  0.33139881
Encoder Loss:  0.03246101  || Decoder Loss:  0.03246101 Validation Decoder Loss:  0.33138782
Encoder Loss:  0.03245474  || Decoder Loss:  0.03245474 Validation Decoder Loss:  0.33137286
Encoder Loss:  0.03244866  || Decoder Loss:  0.03244866 Validation Decoder Loss:  0.3313543
Encoder Loss:  0.03244283  || Decoder Loss:  0.03244283 Validation Decoder Loss:  0.33133253
Encoder Loss:  0.03243723  || Decoder Loss:  0.03243723 Validation Decoder Loss:  0.33130834
Encoder Loss:  0.032431897  || Decoder Loss:  0.032431897 Validation Decoder Loss:  0.33128253
Encoder Loss:  0.032426894  || Decoder Loss:  0.032426894 Validation Decoder Loss:  0.33125606
Encoder Loss:  0.032422274  || Decoder Loss:  0.032422274 Validation Decoder Loss:  0.33122995
Encoder Loss:  0.032418013  || Decoder Loss:  0.032418013 Validation Decoder Loss:  0.33120507
Encoder Loss:  0.03241405  || Decoder Loss:  0.03241405 Validation Decoder Loss:  0.331182
Encoder Loss:  0.032410413  || Decoder Loss:  0.032410413 Validation Decoder Loss:  0.33116123
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33116126
Model: "sequential_649"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_452 (Conv3D (None, 214, 10, 20, 1)    907       
_________________________________________________________________
dropout_935 (Dropout)        (None, 214, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_453 (Conv3D (None, 220, 11, 20, 1)    15        
_________________________________________________________________
reshape_167 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 922
Trainable params: 922
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_651"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_313 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_937 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_314 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_652"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_313 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_939 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_314 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4236502  || Decoder Loss:  0.05335946 Validation Decoder Loss:  0.3497245
Encoder Loss:  0.42087027  || Decoder Loss:  0.055101406 Validation Decoder Loss:  0.34969473
Encoder Loss:  0.41732574  || Decoder Loss:  0.05741703 Validation Decoder Loss:  0.3496529
Encoder Loss:  0.4130118  || Decoder Loss:  0.06035818 Validation Decoder Loss:  0.34981948
Encoder Loss:  0.40767848  || Decoder Loss:  0.06414553 Validation Decoder Loss:  0.3504672
Encoder Loss:  0.40094277  || Decoder Loss:  0.069124185 Validation Decoder Loss:  0.35197526
Encoder Loss:  0.39222625  || Decoder Loss:  0.075836115 Validation Decoder Loss:  0.35497615
Encoder Loss:  0.38061464  || Decoder Loss:  0.08516743 Validation Decoder Loss:  0.36069572
Encoder Loss:  0.36459565  || Decoder Loss:  0.09860939 Validation Decoder Loss:  0.37173423
Encoder Loss:  0.34153926  || Decoder Loss:  0.11843797 Validation Decoder Loss:  0.39274174
Encoder Loss:  0.3065267  || Decoder Loss:  0.115457624 Validation Decoder Loss:  0.38122275
Encoder Loss:  0.24944054  || Decoder Loss:  0.086732015 Validation Decoder Loss:  0.38949698
Encoder Loss:  0.15057369  || Decoder Loss:  0.06487485 Validation Decoder Loss:  0.35188115
Encoder Loss:  0.076054156  || Decoder Loss:  0.061553393 Validation Decoder Loss:  0.34471554
Encoder Loss:  0.06358067  || Decoder Loss:  0.057725176 Validation Decoder Loss:  0.3438201
Encoder Loss:  0.0559756  || Decoder Loss:  0.054827653 Validation Decoder Loss:  0.3426968
Encoder Loss:  0.053113796  || Decoder Loss:  0.05277193 Validation Decoder Loss:  0.3414076
Encoder Loss:  0.05207736  || Decoder Loss:  0.051186956 Validation Decoder Loss:  0.3396875
Encoder Loss:  0.05147113  || Decoder Loss:  0.049737323 Validation Decoder Loss:  0.3379739
Encoder Loss:  0.05138898  || Decoder Loss:  0.048353516 Validation Decoder Loss:  0.3372879
Encoder Loss:  0.051356148  || Decoder Loss:  0.047027472 Validation Decoder Loss:  0.33800527
Encoder Loss:  0.051309574  || Decoder Loss:  0.045849513 Validation Decoder Loss:  0.3386579
Encoder Loss:  0.051255383  || Decoder Loss:  0.044839144 Validation Decoder Loss:  0.3385784
Encoder Loss:  0.051220037  || Decoder Loss:  0.04395887 Validation Decoder Loss:  0.33850312
Encoder Loss:  0.051167473  || Decoder Loss:  0.04316989 Validation Decoder Loss:  0.33837783
Encoder Loss:  0.0511062  || Decoder Loss:  0.04248604 Validation Decoder Loss:  0.33823478
Encoder Loss:  0.051055267  || Decoder Loss:  0.04189042 Validation Decoder Loss:  0.33805537
Encoder Loss:  0.050996665  || Decoder Loss:  0.041357964 Validation Decoder Loss:  0.3378301
Encoder Loss:  0.050934907  || Decoder Loss:  0.040881056 Validation Decoder Loss:  0.3375574
Encoder Loss:  0.050864086  || Decoder Loss:  0.04045354 Validation Decoder Loss:  0.3372519
Encoder Loss:  0.050782215  || Decoder Loss:  0.040069766 Validation Decoder Loss:  0.33694822
Encoder Loss:  0.05068301  || Decoder Loss:  0.039710388 Validation Decoder Loss:  0.336694
Encoder Loss:  0.050535455  || Decoder Loss:  0.039356064 Validation Decoder Loss:  0.33654392
Encoder Loss:  0.050288  || Decoder Loss:  0.039000366 Validation Decoder Loss:  0.33646032
Encoder Loss:  0.05018926  || Decoder Loss:  0.038711287 Validation Decoder Loss:  0.33653295
Encoder Loss:  0.05017204  || Decoder Loss:  0.03848868 Validation Decoder Loss:  0.3365465
Encoder Loss:  0.050161015  || Decoder Loss:  0.038280822 Validation Decoder Loss:  0.33655426
Encoder Loss:  0.050154794  || Decoder Loss:  0.038094554 Validation Decoder Loss:  0.33651847
Encoder Loss:  0.05015028  || Decoder Loss:  0.03792177 Validation Decoder Loss:  0.33647722
Encoder Loss:  0.050151482  || Decoder Loss:  0.037766505 Validation Decoder Loss:  0.33641827
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33641827
Model: "sequential_653"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_455 (Conv3D (None, 201, 10, 20, 1)    73        
_________________________________________________________________
dropout_941 (Dropout)        (None, 201, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_456 (Conv3D (None, 220, 11, 20, 1)    41        
_________________________________________________________________
reshape_168 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 114
Trainable params: 114
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_655"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_315 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_943 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_316 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_656"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_315 (Conv2D (None, 2470, 20, 1)       52        
_________________________________________________________________
dropout_945 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_316 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0436252  || Decoder Loss:  0.0436252 Validation Decoder Loss:  0.34289864
Encoder Loss:  0.035401832  || Decoder Loss:  0.035401832 Validation Decoder Loss:  0.34252208
Encoder Loss:  0.03498255  || Decoder Loss:  0.03498255 Validation Decoder Loss:  0.3423276
Encoder Loss:  0.034540173  || Decoder Loss:  0.034540173 Validation Decoder Loss:  0.34115785
Encoder Loss:  0.033933684  || Decoder Loss:  0.033933684 Validation Decoder Loss:  0.33925983
Encoder Loss:  0.033357646  || Decoder Loss:  0.033357646 Validation Decoder Loss:  0.3391257
Encoder Loss:  0.033051886  || Decoder Loss:  0.033051886 Validation Decoder Loss:  0.33966628
Encoder Loss:  0.03289772  || Decoder Loss:  0.03289772 Validation Decoder Loss:  0.34020895
Encoder Loss:  0.03279215  || Decoder Loss:  0.03279215 Validation Decoder Loss:  0.3406045
Encoder Loss:  0.032705203  || Decoder Loss:  0.032705203 Validation Decoder Loss:  0.3408526
Encoder Loss:  0.032632276  || Decoder Loss:  0.032632276 Validation Decoder Loss:  0.34100547
Encoder Loss:  0.032576844  || Decoder Loss:  0.032576844 Validation Decoder Loss:  0.34103236
Encoder Loss:  0.032537077  || Decoder Loss:  0.032537077 Validation Decoder Loss:  0.3410265
Encoder Loss:  0.032506578  || Decoder Loss:  0.032506578 Validation Decoder Loss:  0.34103566
Encoder Loss:  0.032480992  || Decoder Loss:  0.032480992 Validation Decoder Loss:  0.34105295
Encoder Loss:  0.03245827  || Decoder Loss:  0.03245827 Validation Decoder Loss:  0.34106857
Encoder Loss:  0.032437477  || Decoder Loss:  0.032437477 Validation Decoder Loss:  0.34108013
Encoder Loss:  0.03241811  || Decoder Loss:  0.03241811 Validation Decoder Loss:  0.34108818
Encoder Loss:  0.032399975  || Decoder Loss:  0.032399975 Validation Decoder Loss:  0.34109288
Encoder Loss:  0.032382913  || Decoder Loss:  0.032382913 Validation Decoder Loss:  0.34109408
Encoder Loss:  0.032366864  || Decoder Loss:  0.032366864 Validation Decoder Loss:  0.34109154
Encoder Loss:  0.032351676  || Decoder Loss:  0.032351676 Validation Decoder Loss:  0.34108552
Encoder Loss:  0.032337345  || Decoder Loss:  0.032337345 Validation Decoder Loss:  0.34107643
Encoder Loss:  0.03232373  || Decoder Loss:  0.03232373 Validation Decoder Loss:  0.34106478
Encoder Loss:  0.032310847  || Decoder Loss:  0.032310847 Validation Decoder Loss:  0.34105113
Encoder Loss:  0.03229859  || Decoder Loss:  0.03229859 Validation Decoder Loss:  0.34103605
Encoder Loss:  0.03228699  || Decoder Loss:  0.03228699 Validation Decoder Loss:  0.34102023
Encoder Loss:  0.032275982  || Decoder Loss:  0.032275982 Validation Decoder Loss:  0.341004
Encoder Loss:  0.032265548  || Decoder Loss:  0.032265548 Validation Decoder Loss:  0.340988
Encoder Loss:  0.032255612  || Decoder Loss:  0.032255612 Validation Decoder Loss:  0.34097254
Encoder Loss:  0.032246247  || Decoder Loss:  0.032246247 Validation Decoder Loss:  0.34095776
Encoder Loss:  0.032237396  || Decoder Loss:  0.032237396 Validation Decoder Loss:  0.34094393
Encoder Loss:  0.03222901  || Decoder Loss:  0.03222901 Validation Decoder Loss:  0.34093112
Encoder Loss:  0.032221086  || Decoder Loss:  0.032221086 Validation Decoder Loss:  0.34091926
Encoder Loss:  0.032213647  || Decoder Loss:  0.032213647 Validation Decoder Loss:  0.34090847
Encoder Loss:  0.03220663  || Decoder Loss:  0.03220663 Validation Decoder Loss:  0.3408988
Encoder Loss:  0.032199975  || Decoder Loss:  0.032199975 Validation Decoder Loss:  0.3408903
Encoder Loss:  0.032193743  || Decoder Loss:  0.032193743 Validation Decoder Loss:  0.34088287
Encoder Loss:  0.032187887  || Decoder Loss:  0.032187887 Validation Decoder Loss:  0.34087652
Encoder Loss:  0.032182347  || Decoder Loss:  0.032182347 Validation Decoder Loss:  0.3408711
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3408711
Model: "sequential_657"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_458 (Conv3D (None, 216, 10, 20, 1)    919       
_________________________________________________________________
dropout_947 (Dropout)        (None, 216, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_459 (Conv3D (None, 220, 11, 20, 1)    11        
_________________________________________________________________
reshape_169 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 930
Trainable params: 930
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_659"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_317 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_949 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_318 (Conv2D)          (None, 2420, 20, 1)       172       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_660"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_317 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_951 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_318 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.34897473
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Encoder Loss:  0.42709225  || Decoder Loss:  0.05101861 Validation Decoder Loss:  0.34897467
Encoder Loss:  0.42709225  || Decoder Loss:  0.051018614 Validation Decoder Loss:  0.3489747
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3489747
Model: "sequential_661"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_461 (Conv3D (None, 150, 5, 20, 1)     88        
_________________________________________________________________
dropout_953 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_462 (Conv3D (None, 220, 11, 20, 1)    498       
_________________________________________________________________
reshape_170 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 586
Trainable params: 586
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_663"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_319 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_955 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_320 (Conv2D)          (None, 2420, 20, 1)       92        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_664"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_319 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_957 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_320 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36088917  || Decoder Loss:  0.09945389 Validation Decoder Loss:  0.3863397
Encoder Loss:  0.21336213  || Decoder Loss:  0.24789208 Validation Decoder Loss:  0.53456736
Encoder Loss:  0.08464298  || Decoder Loss:  0.05888989 Validation Decoder Loss:  0.34490454
Encoder Loss:  0.06925731  || Decoder Loss:  0.037889373 Validation Decoder Loss:  0.3378551
Encoder Loss:  0.05031753  || Decoder Loss:  0.036985528 Validation Decoder Loss:  0.33745265
Encoder Loss:  0.050025653  || Decoder Loss:  0.036897082 Validation Decoder Loss:  0.33694947
Encoder Loss:  0.05001898  || Decoder Loss:  0.036647897 Validation Decoder Loss:  0.33645833
Encoder Loss:  0.050016474  || Decoder Loss:  0.0363415 Validation Decoder Loss:  0.3357303
Encoder Loss:  0.05001961  || Decoder Loss:  0.035932407 Validation Decoder Loss:  0.3346867
Encoder Loss:  0.050020657  || Decoder Loss:  0.03529489 Validation Decoder Loss:  0.33267355
Encoder Loss:  0.050018463  || Decoder Loss:  0.034759518 Validation Decoder Loss:  0.33203784
Encoder Loss:  0.050020114  || Decoder Loss:  0.034601998 Validation Decoder Loss:  0.33200872
Encoder Loss:  0.050020624  || Decoder Loss:  0.03453046 Validation Decoder Loss:  0.33202675
Encoder Loss:  0.050023198  || Decoder Loss:  0.0344851 Validation Decoder Loss:  0.3320548
Encoder Loss:  0.050020546  || Decoder Loss:  0.034446124 Validation Decoder Loss:  0.3320799
Encoder Loss:  0.050017495  || Decoder Loss:  0.03441878 Validation Decoder Loss:  0.3320708
Encoder Loss:  0.050019577  || Decoder Loss:  0.034400616 Validation Decoder Loss:  0.33207363
Encoder Loss:  0.05002613  || Decoder Loss:  0.03438289 Validation Decoder Loss:  0.33204365
Encoder Loss:  0.050021745  || Decoder Loss:  0.034355536 Validation Decoder Loss:  0.33200768
Encoder Loss:  0.050015226  || Decoder Loss:  0.034335457 Validation Decoder Loss:  0.33195335
Encoder Loss:  0.050019618  || Decoder Loss:  0.034320932 Validation Decoder Loss:  0.3319028
Encoder Loss:  0.050019365  || Decoder Loss:  0.034302652 Validation Decoder Loss:  0.3318346
Encoder Loss:  0.050011005  || Decoder Loss:  0.034287483 Validation Decoder Loss:  0.331773
Encoder Loss:  0.050010942  || Decoder Loss:  0.034274515 Validation Decoder Loss:  0.33170253
Encoder Loss:  0.050011124  || Decoder Loss:  0.034261875 Validation Decoder Loss:  0.33163297
Encoder Loss:  0.050015174  || Decoder Loss:  0.034251023 Validation Decoder Loss:  0.33151808
Encoder Loss:  0.05001273  || Decoder Loss:  0.03424145 Validation Decoder Loss:  0.33144265
Encoder Loss:  0.05001887  || Decoder Loss:  0.03422697 Validation Decoder Loss:  0.33135685
Encoder Loss:  0.0500101  || Decoder Loss:  0.034211267 Validation Decoder Loss:  0.3312498
Encoder Loss:  0.05000821  || Decoder Loss:  0.034204304 Validation Decoder Loss:  0.33113992
Encoder Loss:  0.050013103  || Decoder Loss:  0.034194008 Validation Decoder Loss:  0.33112612
Encoder Loss:  0.05001144  || Decoder Loss:  0.034181856 Validation Decoder Loss:  0.33098722
Encoder Loss:  0.05000942  || Decoder Loss:  0.034168962 Validation Decoder Loss:  0.3309096
Encoder Loss:  0.050008155  || Decoder Loss:  0.03415595 Validation Decoder Loss:  0.33078992
Encoder Loss:  0.050006665  || Decoder Loss:  0.034146186 Validation Decoder Loss:  0.33068973
Encoder Loss:  0.05001056  || Decoder Loss:  0.03413067 Validation Decoder Loss:  0.3306726
Encoder Loss:  0.050007842  || Decoder Loss:  0.03411692 Validation Decoder Loss:  0.3305927
Encoder Loss:  0.05000663  || Decoder Loss:  0.03410759 Validation Decoder Loss:  0.33054054
Encoder Loss:  0.050006863  || Decoder Loss:  0.034095895 Validation Decoder Loss:  0.33050013
Encoder Loss:  0.050006725  || Decoder Loss:  0.03408313 Validation Decoder Loss:  0.33045575
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33045575
Model: "sequential_665"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_464 (Conv3D (None, 211, 10, 20, 1)    511       
_________________________________________________________________
dropout_959 (Dropout)        (None, 211, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_465 (Conv3D (None, 220, 11, 20, 1)    21        
_________________________________________________________________
reshape_171 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 532
Trainable params: 532
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_667"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_321 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_961 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_322 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_668"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_321 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_963 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_322 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.276927  || Decoder Loss:  0.052921806 Validation Decoder Loss:  0.35023412
Encoder Loss:  0.27624518  || Decoder Loss:  0.053989425 Validation Decoder Loss:  0.3505436
Encoder Loss:  0.27540007  || Decoder Loss:  0.05534407 Validation Decoder Loss:  0.35089278
Encoder Loss:  0.27440283  || Decoder Loss:  0.056976978 Validation Decoder Loss:  0.35135266
Encoder Loss:  0.2732073  || Decoder Loss:  0.05896966 Validation Decoder Loss:  0.35201794
Encoder Loss:  0.2717417  || Decoder Loss:  0.06144982 Validation Decoder Loss:  0.35302117
Encoder Loss:  0.26989728  || Decoder Loss:  0.064612485 Validation Decoder Loss:  0.35457698
Encoder Loss:  0.26750106  || Decoder Loss:  0.068771996 Validation Decoder Loss:  0.35706526
Encoder Loss:  0.26425886  || Decoder Loss:  0.07447615 Validation Decoder Loss:  0.36124045
Encoder Loss:  0.2596288  || Decoder Loss:  0.08279748 Validation Decoder Loss:  0.36887544
Encoder Loss:  0.25251552  || Decoder Loss:  0.096187495 Validation Decoder Loss:  0.3851055
Encoder Loss:  0.24550481  || Decoder Loss:  0.13406631 Validation Decoder Loss:  0.5974979
Encoder Loss:  0.2122135  || Decoder Loss:  0.17158578 Validation Decoder Loss:  0.6028073
Encoder Loss:  0.20605491  || Decoder Loss:  0.36132753 Validation Decoder Loss:  0.7721946
Encoder Loss:  0.13461265  || Decoder Loss:  0.19284396 Validation Decoder Loss:  0.37216872
Encoder Loss:  0.086550295  || Decoder Loss:  0.07719052 Validation Decoder Loss:  0.34857428
Encoder Loss:  0.080009766  || Decoder Loss:  0.0640913 Validation Decoder Loss:  0.34902555
Encoder Loss:  0.07839531  || Decoder Loss:  0.060426712 Validation Decoder Loss:  0.34942666
Encoder Loss:  0.07393777  || Decoder Loss:  0.05813372 Validation Decoder Loss:  0.34914243
Encoder Loss:  0.05869548  || Decoder Loss:  0.056371976 Validation Decoder Loss:  0.3489
Encoder Loss:  0.05362809  || Decoder Loss:  0.05476863 Validation Decoder Loss:  0.34830177
Encoder Loss:  0.052886974  || Decoder Loss:  0.05342723 Validation Decoder Loss:  0.34779888
Encoder Loss:  0.052265417  || Decoder Loss:  0.052204452 Validation Decoder Loss:  0.3474166
Encoder Loss:  0.051671676  || Decoder Loss:  0.051108908 Validation Decoder Loss:  0.3470676
Encoder Loss:  0.05114373  || Decoder Loss:  0.050129652 Validation Decoder Loss:  0.34676108
Encoder Loss:  0.050641373  || Decoder Loss:  0.049252152 Validation Decoder Loss:  0.34647307
Encoder Loss:  0.050211076  || Decoder Loss:  0.04846512 Validation Decoder Loss:  0.34625503
Encoder Loss:  0.049788088  || Decoder Loss:  0.047750644 Validation Decoder Loss:  0.34606025
Encoder Loss:  0.049422245  || Decoder Loss:  0.047109693 Validation Decoder Loss:  0.3458858
Encoder Loss:  0.04908136  || Decoder Loss:  0.046535447 Validation Decoder Loss:  0.34569296
Encoder Loss:  0.048782516  || Decoder Loss:  0.04602035 Validation Decoder Loss:  0.3454566
Encoder Loss:  0.048515663  || Decoder Loss:  0.045552038 Validation Decoder Loss:  0.3451904
Encoder Loss:  0.048299022  || Decoder Loss:  0.045122072 Validation Decoder Loss:  0.34488812
Encoder Loss:  0.04810682  || Decoder Loss:  0.04472129 Validation Decoder Loss:  0.34455934
Encoder Loss:  0.047915913  || Decoder Loss:  0.04433868 Validation Decoder Loss:  0.34422278
Encoder Loss:  0.047753867  || Decoder Loss:  0.04397353 Validation Decoder Loss:  0.34387124
Encoder Loss:  0.047602247  || Decoder Loss:  0.04361831 Validation Decoder Loss:  0.34350866
Encoder Loss:  0.047461852  || Decoder Loss:  0.04327701 Validation Decoder Loss:  0.34314004
Encoder Loss:  0.04733283  || Decoder Loss:  0.042951297 Validation Decoder Loss:  0.34277463
Encoder Loss:  0.047211036  || Decoder Loss:  0.042648457 Validation Decoder Loss:  0.3424246
Model: siamese_net_lr_0.0009094713644322086 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3424246
Model: "sequential_669"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_467 (Conv3D (None, 164, 5, 20, 1)     39        
_________________________________________________________________
dropout_965 (Dropout)        (None, 164, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_468 (Conv3D (None, 220, 11, 20, 1)    400       
_________________________________________________________________
reshape_172 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_671"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_323 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_967 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_324 (Conv2D)          (None, 2420, 20, 1)       162       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_672"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_323 (Conv2D (None, 2530, 20, 1)       112       
_________________________________________________________________
dropout_969 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_324 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0804977  || Decoder Loss:  0.0804977 Validation Decoder Loss:  0.37449044
Encoder Loss:  0.0803798  || Decoder Loss:  0.0803798 Validation Decoder Loss:  0.37697506
Encoder Loss:  0.080264784  || Decoder Loss:  0.080264784 Validation Decoder Loss:  0.379502
Encoder Loss:  0.08015346  || Decoder Loss:  0.08015346 Validation Decoder Loss:  0.38215107
Encoder Loss:  0.08004376  || Decoder Loss:  0.08004376 Validation Decoder Loss:  0.38499093
Encoder Loss:  0.079934485  || Decoder Loss:  0.079934485 Validation Decoder Loss:  0.38805932
Encoder Loss:  0.07982442  || Decoder Loss:  0.07982442 Validation Decoder Loss:  0.39131564
Encoder Loss:  0.07970971  || Decoder Loss:  0.07970971 Validation Decoder Loss:  0.39454126
Encoder Loss:  0.07957598  || Decoder Loss:  0.07957598 Validation Decoder Loss:  0.39733738
Encoder Loss:  0.07937251  || Decoder Loss:  0.07937251 Validation Decoder Loss:  0.39970136
Encoder Loss:  0.078766726  || Decoder Loss:  0.078766726 Validation Decoder Loss:  0.40775758
Encoder Loss:  0.06905868  || Decoder Loss:  0.06905868 Validation Decoder Loss:  0.34384722
Encoder Loss:  0.06259671  || Decoder Loss:  0.06259671 Validation Decoder Loss:  0.34371215
Encoder Loss:  0.061916202  || Decoder Loss:  0.061916202 Validation Decoder Loss:  0.34256333
Encoder Loss:  0.061322417  || Decoder Loss:  0.061322417 Validation Decoder Loss:  0.3419928
Encoder Loss:  0.060746435  || Decoder Loss:  0.060746435 Validation Decoder Loss:  0.3414344
Encoder Loss:  0.060173564  || Decoder Loss:  0.060173564 Validation Decoder Loss:  0.3409071
Encoder Loss:  0.059595793  || Decoder Loss:  0.059595793 Validation Decoder Loss:  0.3403914
Encoder Loss:  0.059001934  || Decoder Loss:  0.059001934 Validation Decoder Loss:  0.33986455
Encoder Loss:  0.058380574  || Decoder Loss:  0.058380574 Validation Decoder Loss:  0.33934116
Encoder Loss:  0.057715643  || Decoder Loss:  0.057715643 Validation Decoder Loss:  0.3388268
Encoder Loss:  0.05697815  || Decoder Loss:  0.05697815 Validation Decoder Loss:  0.3382975
Encoder Loss:  0.05609689  || Decoder Loss:  0.05609689 Validation Decoder Loss:  0.33772138
Encoder Loss:  0.054850105  || Decoder Loss:  0.054850105 Validation Decoder Loss:  0.3372606
Encoder Loss:  0.0525462  || Decoder Loss:  0.0525462 Validation Decoder Loss:  0.33833987
Encoder Loss:  0.048787583  || Decoder Loss:  0.048787583 Validation Decoder Loss:  0.33970758
Encoder Loss:  0.042319518  || Decoder Loss:  0.042319518 Validation Decoder Loss:  0.33991957
Encoder Loss:  0.036131993  || Decoder Loss:  0.036131993 Validation Decoder Loss:  0.33602592
Encoder Loss:  0.03474747  || Decoder Loss:  0.03474747 Validation Decoder Loss:  0.33649886
Encoder Loss:  0.034488093  || Decoder Loss:  0.034488093 Validation Decoder Loss:  0.33776724
Encoder Loss:  0.034344655  || Decoder Loss:  0.034344655 Validation Decoder Loss:  0.33891028
Encoder Loss:  0.03425026  || Decoder Loss:  0.03425026 Validation Decoder Loss:  0.34057093
Encoder Loss:  0.034176018  || Decoder Loss:  0.034176018 Validation Decoder Loss:  0.33979303
Encoder Loss:  0.034107998  || Decoder Loss:  0.034107998 Validation Decoder Loss:  0.34053862
Encoder Loss:  0.03406117  || Decoder Loss:  0.03406117 Validation Decoder Loss:  0.34138292
Encoder Loss:  0.03402174  || Decoder Loss:  0.03402174 Validation Decoder Loss:  0.34155703
Encoder Loss:  0.033982724  || Decoder Loss:  0.033982724 Validation Decoder Loss:  0.34172317
Encoder Loss:  0.033950236  || Decoder Loss:  0.033950236 Validation Decoder Loss:  0.3421117
Encoder Loss:  0.033922363  || Decoder Loss:  0.033922363 Validation Decoder Loss:  0.34247902
Encoder Loss:  0.033897206  || Decoder Loss:  0.033897206 Validation Decoder Loss:  0.34275103
Model: siamese_net_lr_0.0008126310314034925 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34275103
Model: "sequential_673"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_470 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_971 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_471 (Conv3D (None, 220, 11, 20, 1)    323       
_________________________________________________________________
reshape_173 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_675"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_325 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_973 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_326 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_676"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_325 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_975 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_326 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06826502  || Decoder Loss:  0.06826502 Validation Decoder Loss:  0.36752564
Encoder Loss:  0.06811673  || Decoder Loss:  0.06811673 Validation Decoder Loss:  0.36784607
Encoder Loss:  0.06794695  || Decoder Loss:  0.06794695 Validation Decoder Loss:  0.3681666
Encoder Loss:  0.06776729  || Decoder Loss:  0.06776729 Validation Decoder Loss:  0.3684684
Encoder Loss:  0.06757789  || Decoder Loss:  0.06757789 Validation Decoder Loss:  0.368747
Encoder Loss:  0.0673775  || Decoder Loss:  0.0673775 Validation Decoder Loss:  0.36900023
Encoder Loss:  0.06716456  || Decoder Loss:  0.06716456 Validation Decoder Loss:  0.36922574
Encoder Loss:  0.06693723  || Decoder Loss:  0.06693723 Validation Decoder Loss:  0.3694209
Encoder Loss:  0.06669327  || Decoder Loss:  0.06669327 Validation Decoder Loss:  0.36958265
Encoder Loss:  0.066429995  || Decoder Loss:  0.066429995 Validation Decoder Loss:  0.36970767
Encoder Loss:  0.06614419  || Decoder Loss:  0.06614419 Validation Decoder Loss:  0.36979195
Encoder Loss:  0.06583184  || Decoder Loss:  0.06583184 Validation Decoder Loss:  0.36983058
Encoder Loss:  0.06548799  || Decoder Loss:  0.06548799 Validation Decoder Loss:  0.3698175
Encoder Loss:  0.06510633  || Decoder Loss:  0.06510633 Validation Decoder Loss:  0.36974493
Encoder Loss:  0.06467875  || Decoder Loss:  0.06467875 Validation Decoder Loss:  0.36960316
Encoder Loss:  0.064194605  || Decoder Loss:  0.064194605 Validation Decoder Loss:  0.3693792
Encoder Loss:  0.063639544  || Decoder Loss:  0.063639544 Validation Decoder Loss:  0.3690555
Encoder Loss:  0.06299379  || Decoder Loss:  0.06299379 Validation Decoder Loss:  0.3686077
Encoder Loss:  0.0622292  || Decoder Loss:  0.0622292 Validation Decoder Loss:  0.36800048
Encoder Loss:  0.061304107  || Decoder Loss:  0.061304107 Validation Decoder Loss:  0.36718094
Encoder Loss:  0.060154177  || Decoder Loss:  0.060154177 Validation Decoder Loss:  0.36606658
Encoder Loss:  0.05867412  || Decoder Loss:  0.05867412 Validation Decoder Loss:  0.3645221
Encoder Loss:  0.05667962  || Decoder Loss:  0.05667962 Validation Decoder Loss:  0.36231485
Encoder Loss:  0.053820513  || Decoder Loss:  0.053820513 Validation Decoder Loss:  0.3590376
Encoder Loss:  0.04938717  || Decoder Loss:  0.04938717 Validation Decoder Loss:  0.35417193
Encoder Loss:  0.04242976  || Decoder Loss:  0.04242976 Validation Decoder Loss:  0.35107744
Encoder Loss:  0.03813728  || Decoder Loss:  0.03813728 Validation Decoder Loss:  0.3508808
Encoder Loss:  0.037806854  || Decoder Loss:  0.037806854 Validation Decoder Loss:  0.34924573
Encoder Loss:  0.03766496  || Decoder Loss:  0.03766496 Validation Decoder Loss:  0.34787148
Encoder Loss:  0.037568174  || Decoder Loss:  0.037568174 Validation Decoder Loss:  0.3470317
Encoder Loss:  0.037490636  || Decoder Loss:  0.037490636 Validation Decoder Loss:  0.34628385
Encoder Loss:  0.037425715  || Decoder Loss:  0.037425715 Validation Decoder Loss:  0.34572768
Encoder Loss:  0.03736872  || Decoder Loss:  0.03736872 Validation Decoder Loss:  0.3452812
Encoder Loss:  0.037317522  || Decoder Loss:  0.037317522 Validation Decoder Loss:  0.34492737
Encoder Loss:  0.037270695  || Decoder Loss:  0.037270695 Validation Decoder Loss:  0.34464464
Encoder Loss:  0.037227355  || Decoder Loss:  0.037227355 Validation Decoder Loss:  0.3444164
Encoder Loss:  0.0371869  || Decoder Loss:  0.0371869 Validation Decoder Loss:  0.34422994
Encoder Loss:  0.037148856  || Decoder Loss:  0.037148856 Validation Decoder Loss:  0.34407505
Encoder Loss:  0.03711283  || Decoder Loss:  0.03711283 Validation Decoder Loss:  0.34394392
Encoder Loss:  0.037078425  || Decoder Loss:  0.037078425 Validation Decoder Loss:  0.3438307
Model: siamese_net_lr_0.00035013232020910084 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3438307
Model: "sequential_677"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_473 (Conv3D (None, 140, 5, 20, 1)     15        
_________________________________________________________________
dropout_977 (Dropout)        (None, 140, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_474 (Conv3D (None, 220, 11, 20, 1)    244       
_________________________________________________________________
reshape_174 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 259
Trainable params: 259
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_679"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_327 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_979 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_328 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_680"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_327 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_981 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_328 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17067757  || Decoder Loss:  0.082042724 Validation Decoder Loss:  0.35122913
Encoder Loss:  0.046177775  || Decoder Loss:  0.038812768 Validation Decoder Loss:  0.3458156
Encoder Loss:  0.045805857  || Decoder Loss:  0.037970386 Validation Decoder Loss:  0.3463631
Encoder Loss:  0.04550212  || Decoder Loss:  0.037089366 Validation Decoder Loss:  0.34829015
Encoder Loss:  0.04534771  || Decoder Loss:  0.03665955 Validation Decoder Loss:  0.34892935
Encoder Loss:  0.0452343  || Decoder Loss:  0.0363221 Validation Decoder Loss:  0.349118
Encoder Loss:  0.04513826  || Decoder Loss:  0.03601764 Validation Decoder Loss:  0.34923017
Encoder Loss:  0.045047935  || Decoder Loss:  0.035791818 Validation Decoder Loss:  0.34930155
Encoder Loss:  0.04498363  || Decoder Loss:  0.035563827 Validation Decoder Loss:  0.34933472
Encoder Loss:  0.044912685  || Decoder Loss:  0.035409097 Validation Decoder Loss:  0.3492844
Encoder Loss:  0.044866662  || Decoder Loss:  0.03528041 Validation Decoder Loss:  0.34906983
Encoder Loss:  0.045014225  || Decoder Loss:  0.035048265 Validation Decoder Loss:  0.34883142
Encoder Loss:  0.044746995  || Decoder Loss:  0.03494501 Validation Decoder Loss:  0.34867138
Encoder Loss:  0.04472136  || Decoder Loss:  0.034821548 Validation Decoder Loss:  0.3483526
Encoder Loss:  0.0446572  || Decoder Loss:  0.034690727 Validation Decoder Loss:  0.3479417
Encoder Loss:  0.044611458  || Decoder Loss:  0.034511555 Validation Decoder Loss:  0.3471158
Encoder Loss:  0.044530306  || Decoder Loss:  0.0342841 Validation Decoder Loss:  0.3458187
Encoder Loss:  0.044428617  || Decoder Loss:  0.03399135 Validation Decoder Loss:  0.3439306
Encoder Loss:  0.044386  || Decoder Loss:  0.033754945 Validation Decoder Loss:  0.34212038
Encoder Loss:  0.044300895  || Decoder Loss:  0.03365476 Validation Decoder Loss:  0.3410314
Encoder Loss:  0.04430977  || Decoder Loss:  0.03357972 Validation Decoder Loss:  0.34098423
Encoder Loss:  0.044337593  || Decoder Loss:  0.033498827 Validation Decoder Loss:  0.3406753
Encoder Loss:  0.04421649  || Decoder Loss:  0.033440564 Validation Decoder Loss:  0.34073755
Encoder Loss:  0.044203423  || Decoder Loss:  0.033392005 Validation Decoder Loss:  0.34042823
Encoder Loss:  0.044198632  || Decoder Loss:  0.03333797 Validation Decoder Loss:  0.34043682
Encoder Loss:  0.044257797  || Decoder Loss:  0.033273026 Validation Decoder Loss:  0.34010687
Encoder Loss:  0.0441456  || Decoder Loss:  0.03323698 Validation Decoder Loss:  0.3401125
Encoder Loss:  0.044139765  || Decoder Loss:  0.033200763 Validation Decoder Loss:  0.33972016
Encoder Loss:  0.04413825  || Decoder Loss:  0.033168297 Validation Decoder Loss:  0.33981746
Encoder Loss:  0.04411781  || Decoder Loss:  0.0331372 Validation Decoder Loss:  0.33954188
Encoder Loss:  0.04410511  || Decoder Loss:  0.033112735 Validation Decoder Loss:  0.34148028
Encoder Loss:  0.044103593  || Decoder Loss:  0.033094637 Validation Decoder Loss:  0.34195912
Encoder Loss:  0.04419736  || Decoder Loss:  0.03306234 Validation Decoder Loss:  0.34055588
Encoder Loss:  0.044077385  || Decoder Loss:  0.03304541 Validation Decoder Loss:  0.3411836
Encoder Loss:  0.0440746  || Decoder Loss:  0.03302435 Validation Decoder Loss:  0.3409704
Encoder Loss:  0.044090223  || Decoder Loss:  0.03301791 Validation Decoder Loss:  0.34026057
Encoder Loss:  0.04406486  || Decoder Loss:  0.033006586 Validation Decoder Loss:  0.33976084
Encoder Loss:  0.044136256  || Decoder Loss:  0.033033863 Validation Decoder Loss:  0.33948714
Encoder Loss:  0.044062052  || Decoder Loss:  0.03300601 Validation Decoder Loss:  0.33969837
Encoder Loss:  0.0440925  || Decoder Loss:  0.0330146 Validation Decoder Loss:  0.33899722
Model: siamese_net_lr_0.0009700495224976541 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33899724
Model: "sequential_681"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_476 (Conv3D (None, 79, 10, 20, 1)     33        
_________________________________________________________________
dropout_983 (Dropout)        (None, 79, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_477 (Conv3D (None, 220, 11, 20, 1)    285       
_________________________________________________________________
reshape_175 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_683"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_329 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_985 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_330 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_684"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_329 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_987 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_330 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1479971  || Decoder Loss:  0.09878992 Validation Decoder Loss:  0.3804041
Encoder Loss:  0.15588337  || Decoder Loss:  0.1118362 Validation Decoder Loss:  0.35859615
Encoder Loss:  0.09466638  || Decoder Loss:  0.04305666 Validation Decoder Loss:  0.343123
Encoder Loss:  0.0839966  || Decoder Loss:  0.037408646 Validation Decoder Loss:  0.34304106
Encoder Loss:  0.05969609  || Decoder Loss:  0.037200958 Validation Decoder Loss:  0.34267476
Encoder Loss:  0.03918615  || Decoder Loss:  0.036982585 Validation Decoder Loss:  0.34265524
Encoder Loss:  0.038955156  || Decoder Loss:  0.036715627 Validation Decoder Loss:  0.34236836
Encoder Loss:  0.038678095  || Decoder Loss:  0.03639344 Validation Decoder Loss:  0.3418423
Encoder Loss:  0.03836154  || Decoder Loss:  0.03602008 Validation Decoder Loss:  0.34123468
Encoder Loss:  0.038017724  || Decoder Loss:  0.035609946 Validation Decoder Loss:  0.3406399
Encoder Loss:  0.037632335  || Decoder Loss:  0.035147253 Validation Decoder Loss:  0.3397614
Encoder Loss:  0.03719188  || Decoder Loss:  0.034618314 Validation Decoder Loss:  0.33830988
Encoder Loss:  0.036749613  || Decoder Loss:  0.034087017 Validation Decoder Loss:  0.33640015
Encoder Loss:  0.0364073  || Decoder Loss:  0.033675995 Validation Decoder Loss:  0.33461756
Encoder Loss:  0.036200043  || Decoder Loss:  0.03342738 Validation Decoder Loss:  0.33346146
Encoder Loss:  0.03608538  || Decoder Loss:  0.033289704 Validation Decoder Loss:  0.332839
Encoder Loss:  0.036019124  || Decoder Loss:  0.033210147 Validation Decoder Loss:  0.33249518
Encoder Loss:  0.03597697  || Decoder Loss:  0.03315958 Validation Decoder Loss:  0.3323189
Encoder Loss:  0.035947137  || Decoder Loss:  0.033123743 Validation Decoder Loss:  0.3322692
Encoder Loss:  0.035923854  || Decoder Loss:  0.033095777 Validation Decoder Loss:  0.332307
Encoder Loss:  0.035904426  || Decoder Loss:  0.033072364 Validation Decoder Loss:  0.3323838
Encoder Loss:  0.035887443  || Decoder Loss:  0.03305201 Validation Decoder Loss:  0.3324617
Encoder Loss:  0.035872187  || Decoder Loss:  0.033033837 Validation Decoder Loss:  0.3325255
Encoder Loss:  0.035858523  || Decoder Loss:  0.033017326 Validation Decoder Loss:  0.3325679
Encoder Loss:  0.035845567  || Decoder Loss:  0.033002086 Validation Decoder Loss:  0.33259362
Encoder Loss:  0.0358337  || Decoder Loss:  0.032987855 Validation Decoder Loss:  0.33260375
Encoder Loss:  0.035822485  || Decoder Loss:  0.032974485 Validation Decoder Loss:  0.33259958
Encoder Loss:  0.035811957  || Decoder Loss:  0.03296185 Validation Decoder Loss:  0.33258235
Encoder Loss:  0.03580207  || Decoder Loss:  0.032949843 Validation Decoder Loss:  0.33255243
Encoder Loss:  0.0357925  || Decoder Loss:  0.03293841 Validation Decoder Loss:  0.33250624
Encoder Loss:  0.03578336  || Decoder Loss:  0.032927558 Validation Decoder Loss:  0.33244365
Encoder Loss:  0.035774756  || Decoder Loss:  0.03291724 Validation Decoder Loss:  0.33235642
Encoder Loss:  0.035766855  || Decoder Loss:  0.032907475 Validation Decoder Loss:  0.33224565
Encoder Loss:  0.035759047  || Decoder Loss:  0.03289827 Validation Decoder Loss:  0.3321032
Encoder Loss:  0.03575228  || Decoder Loss:  0.032889646 Validation Decoder Loss:  0.3319416
Encoder Loss:  0.035745148  || Decoder Loss:  0.032881487 Validation Decoder Loss:  0.33176938
Encoder Loss:  0.035738725  || Decoder Loss:  0.032873724 Validation Decoder Loss:  0.3316061
Encoder Loss:  0.03573326  || Decoder Loss:  0.032866146 Validation Decoder Loss:  0.33148497
Encoder Loss:  0.0357264  || Decoder Loss:  0.032858714 Validation Decoder Loss:  0.3313842
Encoder Loss:  0.03572055  || Decoder Loss:  0.032851342 Validation Decoder Loss:  0.33132017
Model: siamese_net_lr_0.0005376755516824771 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33132017
Model: "sequential_685"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_479 (Conv3D (None, 154, 5, 20, 1)     29        
_________________________________________________________________
dropout_989 (Dropout)        (None, 154, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_480 (Conv3D (None, 220, 11, 20, 1)    470       
_________________________________________________________________
reshape_176 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 499
Trainable params: 499
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_687"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_331 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_991 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_332 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_688"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_331 (Conv2D (None, 2460, 20, 1)       42        
_________________________________________________________________
dropout_993 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_332 (Conv2D (None, 2607, 20, 1)       149       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3777157  || Decoder Loss:  0.086484574 Validation Decoder Loss:  0.37262014
Encoder Loss:  0.37152272  || Decoder Loss:  0.08686273 Validation Decoder Loss:  0.37553978
Encoder Loss:  0.3644142  || Decoder Loss:  0.086977765 Validation Decoder Loss:  0.37824744
Encoder Loss:  0.3558771  || Decoder Loss:  0.08694423 Validation Decoder Loss:  0.38080412
Encoder Loss:  0.34530395  || Decoder Loss:  0.08694097 Validation Decoder Loss:  0.38336158
Encoder Loss:  0.33143982  || Decoder Loss:  0.087032855 Validation Decoder Loss:  0.38760424
Encoder Loss:  0.30692443  || Decoder Loss:  0.08671199 Validation Decoder Loss:  0.42028993
Encoder Loss:  0.11463955  || Decoder Loss:  0.07790476 Validation Decoder Loss:  0.4330219
Encoder Loss:  0.054497186  || Decoder Loss:  0.07696958 Validation Decoder Loss:  0.38742256
Encoder Loss:  0.052128304  || Decoder Loss:  0.06250357 Validation Decoder Loss:  0.46890992
Encoder Loss:  0.053191934  || Decoder Loss:  0.047451083 Validation Decoder Loss:  0.42069733
Encoder Loss:  0.052879658  || Decoder Loss:  0.039710417 Validation Decoder Loss:  0.3889066
Encoder Loss:  0.05213898  || Decoder Loss:  0.036526214 Validation Decoder Loss:  0.37013727
Encoder Loss:  0.051778067  || Decoder Loss:  0.035739765 Validation Decoder Loss:  0.36262524
Encoder Loss:  0.050496172  || Decoder Loss:  0.03554022 Validation Decoder Loss:  0.3598788
Encoder Loss:  0.05018394  || Decoder Loss:  0.03542732 Validation Decoder Loss:  0.35862726
Encoder Loss:  0.05007056  || Decoder Loss:  0.03536459 Validation Decoder Loss:  0.35782212
Encoder Loss:  0.050031394  || Decoder Loss:  0.035312153 Validation Decoder Loss:  0.35722578
Encoder Loss:  0.050033353  || Decoder Loss:  0.035268437 Validation Decoder Loss:  0.35681808
Encoder Loss:  0.050042752  || Decoder Loss:  0.035233412 Validation Decoder Loss:  0.3564157
Encoder Loss:  0.050142966  || Decoder Loss:  0.035210263 Validation Decoder Loss:  0.3560099
Encoder Loss:  0.050120044  || Decoder Loss:  0.035198033 Validation Decoder Loss:  0.35570204
Encoder Loss:  0.050101433  || Decoder Loss:  0.035187956 Validation Decoder Loss:  0.35541072
Encoder Loss:  0.050095502  || Decoder Loss:  0.035180736 Validation Decoder Loss:  0.3550967
Encoder Loss:  0.05006746  || Decoder Loss:  0.035165317 Validation Decoder Loss:  0.3548456
Encoder Loss:  0.050096393  || Decoder Loss:  0.035160493 Validation Decoder Loss:  0.35462
Encoder Loss:  0.05005055  || Decoder Loss:  0.035150792 Validation Decoder Loss:  0.35440287
Encoder Loss:  0.050029486  || Decoder Loss:  0.03513919 Validation Decoder Loss:  0.35430473
Encoder Loss:  0.050067768  || Decoder Loss:  0.035133883 Validation Decoder Loss:  0.35414994
Encoder Loss:  0.050038155  || Decoder Loss:  0.035122808 Validation Decoder Loss:  0.3540424
Encoder Loss:  0.050081894  || Decoder Loss:  0.035120454 Validation Decoder Loss:  0.35403806
Encoder Loss:  0.05007166  || Decoder Loss:  0.03512204 Validation Decoder Loss:  0.3539271
Encoder Loss:  0.050063815  || Decoder Loss:  0.035121236 Validation Decoder Loss:  0.3540125
Encoder Loss:  0.050040197  || Decoder Loss:  0.03511912 Validation Decoder Loss:  0.35421616
Encoder Loss:  0.050029892  || Decoder Loss:  0.035117466 Validation Decoder Loss:  0.354416
Encoder Loss:  0.050035544  || Decoder Loss:  0.035115823 Validation Decoder Loss:  0.35464197
Encoder Loss:  0.05006102  || Decoder Loss:  0.03511955 Validation Decoder Loss:  0.35465693
Encoder Loss:  0.050041355  || Decoder Loss:  0.03512044 Validation Decoder Loss:  0.35456407
Encoder Loss:  0.050031208  || Decoder Loss:  0.03511725 Validation Decoder Loss:  0.35446292
Encoder Loss:  0.05002689  || Decoder Loss:  0.035113044 Validation Decoder Loss:  0.35433817
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35433817
Model: "sequential_689"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_482 (Conv3D (None, 64, 5, 20, 1)      2         
_________________________________________________________________
dropout_995 (Dropout)        (None, 64, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_483 (Conv3D (None, 220, 11, 20, 1)    1100      
_________________________________________________________________
reshape_177 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 1,102
Trainable params: 1,102
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_691"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_333 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_997 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_334 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_692"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_333 (Conv2D (None, 2470, 20, 1)       52        
_________________________________________________________________
dropout_999 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_334 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.36996052
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.36996046
Encoder Loss:  0.083077595  || Decoder Loss:  0.083077595 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.36996052
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077595  || Decoder Loss:  0.083077595 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307757  || Decoder Loss:  0.08307757 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.08307758  || Decoder Loss:  0.08307758 Validation Decoder Loss:  0.3699605
Encoder Loss:  0.083077565  || Decoder Loss:  0.083077565 Validation Decoder Loss:  0.36996052
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3699605
Model: "sequential_693"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_485 (Conv3D (None, 178, 5, 20, 1)     116       
_________________________________________________________________
dropout_1001 (Dropout)       (None, 178, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_486 (Conv3D (None, 220, 11, 20, 1)    302       
_________________________________________________________________
reshape_178 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 418
Trainable params: 418
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_695"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_335 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_1003 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_336 (Conv2D)          (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_696"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_335 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1005 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_336 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24444693  || Decoder Loss:  0.0730653 Validation Decoder Loss:  0.36896634
Encoder Loss:  0.2442697  || Decoder Loss:  0.07311609 Validation Decoder Loss:  0.36902994
Encoder Loss:  0.24410734  || Decoder Loss:  0.07316014 Validation Decoder Loss:  0.3690898
Encoder Loss:  0.24395242  || Decoder Loss:  0.07320135 Validation Decoder Loss:  0.3691478
Encoder Loss:  0.24379967  || Decoder Loss:  0.07324079 Validation Decoder Loss:  0.36920488
Encoder Loss:  0.24364804  || Decoder Loss:  0.073279105 Validation Decoder Loss:  0.36926147
Encoder Loss:  0.24349603  || Decoder Loss:  0.07331641 Validation Decoder Loss:  0.36931786
Encoder Loss:  0.24334297  || Decoder Loss:  0.07335255 Validation Decoder Loss:  0.3693742
Encoder Loss:  0.2431888  || Decoder Loss:  0.07338752 Validation Decoder Loss:  0.3694306
Encoder Loss:  0.24303341  || Decoder Loss:  0.07342107 Validation Decoder Loss:  0.36948732
Encoder Loss:  0.24287653  || Decoder Loss:  0.073453106 Validation Decoder Loss:  0.3695442
Encoder Loss:  0.24271786  || Decoder Loss:  0.07348424 Validation Decoder Loss:  0.36960095
Encoder Loss:  0.24255861  || Decoder Loss:  0.07351515 Validation Decoder Loss:  0.369657
Encoder Loss:  0.24239852  || Decoder Loss:  0.0735462 Validation Decoder Loss:  0.3697124
Encoder Loss:  0.24223703  || Decoder Loss:  0.0735775 Validation Decoder Loss:  0.36976692
Encoder Loss:  0.24207497  || Decoder Loss:  0.07360874 Validation Decoder Loss:  0.3698206
Encoder Loss:  0.2419118  || Decoder Loss:  0.07364014 Validation Decoder Loss:  0.36987334
Encoder Loss:  0.24174786  || Decoder Loss:  0.07367158 Validation Decoder Loss:  0.36992505
Encoder Loss:  0.24158274  || Decoder Loss:  0.07370302 Validation Decoder Loss:  0.36997575
Encoder Loss:  0.24141707  || Decoder Loss:  0.07373442 Validation Decoder Loss:  0.37002522
Encoder Loss:  0.24125023  || Decoder Loss:  0.073765896 Validation Decoder Loss:  0.3700734
Encoder Loss:  0.24108253  || Decoder Loss:  0.07379723 Validation Decoder Loss:  0.37012017
Encoder Loss:  0.24091364  || Decoder Loss:  0.073828496 Validation Decoder Loss:  0.3701655
Encoder Loss:  0.24074377  || Decoder Loss:  0.07385966 Validation Decoder Loss:  0.3702093
Encoder Loss:  0.24057291  || Decoder Loss:  0.073890634 Validation Decoder Loss:  0.37025166
Encoder Loss:  0.24040098  || Decoder Loss:  0.073921524 Validation Decoder Loss:  0.37029266
Encoder Loss:  0.24022779  || Decoder Loss:  0.073952295 Validation Decoder Loss:  0.37033218
Encoder Loss:  0.24005395  || Decoder Loss:  0.073982805 Validation Decoder Loss:  0.37037027
Encoder Loss:  0.2398787  || Decoder Loss:  0.074013054 Validation Decoder Loss:  0.3704069
Encoder Loss:  0.23970263  || Decoder Loss:  0.074043095 Validation Decoder Loss:  0.37044197
Encoder Loss:  0.23952517  || Decoder Loss:  0.07407286 Validation Decoder Loss:  0.3704754
Encoder Loss:  0.2393463  || Decoder Loss:  0.074102335 Validation Decoder Loss:  0.37050724
Encoder Loss:  0.23916678  || Decoder Loss:  0.07413146 Validation Decoder Loss:  0.3705374
Encoder Loss:  0.23898579  || Decoder Loss:  0.07416017 Validation Decoder Loss:  0.37056568
Encoder Loss:  0.23880371  || Decoder Loss:  0.074188545 Validation Decoder Loss:  0.37059224
Encoder Loss:  0.23862028  || Decoder Loss:  0.074216485 Validation Decoder Loss:  0.3706168
Encoder Loss:  0.23843563  || Decoder Loss:  0.07424386 Validation Decoder Loss:  0.37063944
Encoder Loss:  0.23824976  || Decoder Loss:  0.074270815 Validation Decoder Loss:  0.37066
Encoder Loss:  0.2380624  || Decoder Loss:  0.07429709 Validation Decoder Loss:  0.37067837
Encoder Loss:  0.23787375  || Decoder Loss:  0.07432291 Validation Decoder Loss:  0.37069464
Model: siamese_net_lr_4.3295791930515846e-06 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3706946
Model: "sequential_697"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_488 (Conv3D (None, 76, 10, 20, 1)     27        
_________________________________________________________________
dropout_1007 (Dropout)       (None, 76, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_489 (Conv3D (None, 220, 11, 20, 1)    291       
_________________________________________________________________
reshape_179 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_699"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_337 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_1009 (Dropout)       (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_338 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_700"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_337 (Conv2D (None, 2460, 20, 1)       42        
_________________________________________________________________
dropout_1011 (Dropout)       (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_338 (Conv2D (None, 2607, 20, 1)       149       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.305528  || Decoder Loss:  0.090940855 Validation Decoder Loss:  0.37099534
Encoder Loss:  0.3046192  || Decoder Loss:  0.093798324 Validation Decoder Loss:  0.37320596
Encoder Loss:  0.30357385  || Decoder Loss:  0.097092964 Validation Decoder Loss:  0.37561113
Encoder Loss:  0.3024595  || Decoder Loss:  0.10060701 Validation Decoder Loss:  0.37819415
Encoder Loss:  0.3012772  || Decoder Loss:  0.10433239 Validation Decoder Loss:  0.38097483
Encoder Loss:  0.30002207  || Decoder Loss:  0.10827939 Validation Decoder Loss:  0.38397634
Encoder Loss:  0.29868853  || Decoder Loss:  0.11245981 Validation Decoder Loss:  0.38722506
Encoder Loss:  0.29727012  || Decoder Loss:  0.11688672 Validation Decoder Loss:  0.3907515
Encoder Loss:  0.29575852  || Decoder Loss:  0.12157536 Validation Decoder Loss:  0.3945912
Encoder Loss:  0.29414317  || Decoder Loss:  0.12654375 Validation Decoder Loss:  0.39878583
Encoder Loss:  0.29240984  || Decoder Loss:  0.13181233 Validation Decoder Loss:  0.40338668
Encoder Loss:  0.29053828  || Decoder Loss:  0.13740166 Validation Decoder Loss:  0.4084649
Encoder Loss:  0.28849632  || Decoder Loss:  0.14331996 Validation Decoder Loss:  0.41414988
Encoder Loss:  0.28621566  || Decoder Loss:  0.14949606 Validation Decoder Loss:  0.42082798
Encoder Loss:  0.28327054  || Decoder Loss:  0.15475184 Validation Decoder Loss:  0.44083032
Encoder Loss:  0.2775666  || Decoder Loss:  0.15256752 Validation Decoder Loss:  0.4655536
Encoder Loss:  0.2634292  || Decoder Loss:  0.12492367 Validation Decoder Loss:  0.5094626
Encoder Loss:  0.25992572  || Decoder Loss:  0.13460001 Validation Decoder Loss:  0.42946512
Encoder Loss:  0.2617062  || Decoder Loss:  0.16564608 Validation Decoder Loss:  0.43613333
Encoder Loss:  0.24928762  || Decoder Loss:  0.15878874 Validation Decoder Loss:  0.41425505
Encoder Loss:  0.20853981  || Decoder Loss:  0.08887365 Validation Decoder Loss:  0.4018829
Encoder Loss:  0.13465546  || Decoder Loss:  0.06485186 Validation Decoder Loss:  0.3869327
Encoder Loss:  0.058288917  || Decoder Loss:  0.055561695 Validation Decoder Loss:  0.37756345
Encoder Loss:  0.051262178  || Decoder Loss:  0.048995394 Validation Decoder Loss:  0.36803105
Encoder Loss:  0.048673123  || Decoder Loss:  0.04443887 Validation Decoder Loss:  0.36158362
Encoder Loss:  0.047536198  || Decoder Loss:  0.041345153 Validation Decoder Loss:  0.35715687
Encoder Loss:  0.04687185  || Decoder Loss:  0.0393303 Validation Decoder Loss:  0.35388437
Encoder Loss:  0.04646787  || Decoder Loss:  0.03806319 Validation Decoder Loss:  0.35151425
Encoder Loss:  0.04621572  || Decoder Loss:  0.037272748 Validation Decoder Loss:  0.3497761
Encoder Loss:  0.04606325  || Decoder Loss:  0.03677317 Validation Decoder Loss:  0.34846282
Encoder Loss:  0.045992702  || Decoder Loss:  0.03644607 Validation Decoder Loss:  0.34744504
Encoder Loss:  0.04591674  || Decoder Loss:  0.03621746 Validation Decoder Loss:  0.34663686
Encoder Loss:  0.04583442  || Decoder Loss:  0.036045156 Validation Decoder Loss:  0.3459707
Encoder Loss:  0.04578326  || Decoder Loss:  0.035906777 Validation Decoder Loss:  0.34540772
Encoder Loss:  0.045741383  || Decoder Loss:  0.035788454 Validation Decoder Loss:  0.34494144
Encoder Loss:  0.045714997  || Decoder Loss:  0.035682786 Validation Decoder Loss:  0.3445291
Encoder Loss:  0.04566927  || Decoder Loss:  0.03558276 Validation Decoder Loss:  0.34417188
Encoder Loss:  0.045629002  || Decoder Loss:  0.035489574 Validation Decoder Loss:  0.343853
Encoder Loss:  0.04561705  || Decoder Loss:  0.03539987 Validation Decoder Loss:  0.34355676
Encoder Loss:  0.04557543  || Decoder Loss:  0.03531524 Validation Decoder Loss:  0.3432843
Model: siamese_net_lr_0.0006902531126708342 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34328428
Model: "sequential_701"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_491 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_1013 (Dropout)       (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_492 (Conv3D (None, 220, 11, 20, 1)    1030      
_________________________________________________________________
reshape_180 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 1,042
Trainable params: 1,042
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_703"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_339 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_1015 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_340 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_704"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_339 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_1017 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_340 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37574753  || Decoder Loss:  0.09052696 Validation Decoder Loss:  0.37176257
Encoder Loss:  0.3713067  || Decoder Loss:  0.09328409 Validation Decoder Loss:  0.3742961
Encoder Loss:  0.36618915  || Decoder Loss:  0.09659863 Validation Decoder Loss:  0.37713555
Encoder Loss:  0.36068633  || Decoder Loss:  0.100323275 Validation Decoder Loss:  0.38031423
Encoder Loss:  0.3547498  || Decoder Loss:  0.10451154 Validation Decoder Loss:  0.38390473
Encoder Loss:  0.34828854  || Decoder Loss:  0.10925072 Validation Decoder Loss:  0.38798183
Encoder Loss:  0.34118867  || Decoder Loss:  0.11465273 Validation Decoder Loss:  0.39264202
Encoder Loss:  0.33330306  || Decoder Loss:  0.12086358 Validation Decoder Loss:  0.39804035
Encoder Loss:  0.3244343  || Decoder Loss:  0.12808125 Validation Decoder Loss:  0.40443024
Encoder Loss:  0.31430504  || Decoder Loss:  0.1365858 Validation Decoder Loss:  0.4122115
Encoder Loss:  0.30250514  || Decoder Loss:  0.14679316 Validation Decoder Loss:  0.42202637
Encoder Loss:  0.28838092  || Decoder Loss:  0.15935647 Validation Decoder Loss:  0.43495762
Encoder Loss:  0.27076378  || Decoder Loss:  0.17536715 Validation Decoder Loss:  0.45293093
Encoder Loss:  0.24702616  || Decoder Loss:  0.19666575 Validation Decoder Loss:  0.47930178
Encoder Loss:  0.20598906  || Decoder Loss:  0.2197171 Validation Decoder Loss:  0.5087333
Encoder Loss:  0.09591761  || Decoder Loss:  0.18672377 Validation Decoder Loss:  0.4769452
Encoder Loss:  0.05311774  || Decoder Loss:  0.17786841 Validation Decoder Loss:  0.48048833
Encoder Loss:  0.050558686  || Decoder Loss:  0.17389742 Validation Decoder Loss:  0.4759806
Encoder Loss:  0.050233774  || Decoder Loss:  0.1706174 Validation Decoder Loss:  0.47355577
Encoder Loss:  0.050153427  || Decoder Loss:  0.16744068 Validation Decoder Loss:  0.4716476
Encoder Loss:  0.050126582  || Decoder Loss:  0.16422278 Validation Decoder Loss:  0.46846777
Encoder Loss:  0.050111044  || Decoder Loss:  0.16073851 Validation Decoder Loss:  0.46512508
Encoder Loss:  0.050096285  || Decoder Loss:  0.1565786 Validation Decoder Loss:  0.4609201
Encoder Loss:  0.0500825  || Decoder Loss:  0.15067221 Validation Decoder Loss:  0.45415643
Encoder Loss:  0.050067957  || Decoder Loss:  0.13860609 Validation Decoder Loss:  0.43575343
Encoder Loss:  0.050053257  || Decoder Loss:  0.09690799 Validation Decoder Loss:  0.3613096
Encoder Loss:  0.05003798  || Decoder Loss:  0.039752446 Validation Decoder Loss:  0.33493042
Encoder Loss:  0.050023567  || Decoder Loss:  0.035122834 Validation Decoder Loss:  0.33516723
Encoder Loss:  0.05001277  || Decoder Loss:  0.03435278 Validation Decoder Loss:  0.33475834
Encoder Loss:  0.050020054  || Decoder Loss:  0.034037862 Validation Decoder Loss:  0.33418345
Encoder Loss:  0.050015964  || Decoder Loss:  0.03386135 Validation Decoder Loss:  0.3337859
Encoder Loss:  0.050010975  || Decoder Loss:  0.03373635 Validation Decoder Loss:  0.33348608
Encoder Loss:  0.050018333  || Decoder Loss:  0.033609167 Validation Decoder Loss:  0.3332097
Encoder Loss:  0.05001879  || Decoder Loss:  0.033511132 Validation Decoder Loss:  0.33298695
Encoder Loss:  0.050010208  || Decoder Loss:  0.03344221 Validation Decoder Loss:  0.33275077
Encoder Loss:  0.050011788  || Decoder Loss:  0.03336866 Validation Decoder Loss:  0.33257997
Encoder Loss:  0.05001141  || Decoder Loss:  0.033300262 Validation Decoder Loss:  0.33241922
Encoder Loss:  0.050011136  || Decoder Loss:  0.033238415 Validation Decoder Loss:  0.33226517
Encoder Loss:  0.05001104  || Decoder Loss:  0.03318693 Validation Decoder Loss:  0.3321378
Encoder Loss:  0.0500103  || Decoder Loss:  0.033133946 Validation Decoder Loss:  0.33203256
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33203256
Model: "sequential_705"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_494 (Conv3D (None, 202, 10, 20, 1)    835       
_________________________________________________________________
dropout_1019 (Dropout)       (None, 202, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_495 (Conv3D (None, 220, 11, 20, 1)    39        
_________________________________________________________________
reshape_181 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 874
Trainable params: 874
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_707"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_341 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1021 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_342 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_708"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_341 (Conv2D (None, 2480, 20, 1)       62        
_________________________________________________________________
dropout_1023 (Dropout)       (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_342 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06412495  || Decoder Loss:  0.06412495 Validation Decoder Loss:  0.36197522
Encoder Loss:  0.0640646  || Decoder Loss:  0.0640646 Validation Decoder Loss:  0.36339408
Encoder Loss:  0.064001106  || Decoder Loss:  0.064001106 Validation Decoder Loss:  0.3647943
Encoder Loss:  0.063939296  || Decoder Loss:  0.063939296 Validation Decoder Loss:  0.36614814
Encoder Loss:  0.06387814  || Decoder Loss:  0.06387814 Validation Decoder Loss:  0.3674648
Encoder Loss:  0.063816115  || Decoder Loss:  0.063816115 Validation Decoder Loss:  0.36875138
Encoder Loss:  0.063751325  || Decoder Loss:  0.063751325 Validation Decoder Loss:  0.3700112
Encoder Loss:  0.06368122  || Decoder Loss:  0.06368122 Validation Decoder Loss:  0.37125364
Encoder Loss:  0.06360196  || Decoder Loss:  0.06360196 Validation Decoder Loss:  0.37251097
Encoder Loss:  0.0635073  || Decoder Loss:  0.0635073 Validation Decoder Loss:  0.37386864
Encoder Loss:  0.063385345  || Decoder Loss:  0.063385345 Validation Decoder Loss:  0.3755431
Encoder Loss:  0.0632073  || Decoder Loss:  0.0632073 Validation Decoder Loss:  0.37824607
Encoder Loss:  0.06287735  || Decoder Loss:  0.06287735 Validation Decoder Loss:  0.38609236
Encoder Loss:  0.062040035  || Decoder Loss:  0.062040035 Validation Decoder Loss:  0.39888448
Encoder Loss:  0.05607562  || Decoder Loss:  0.05607562 Validation Decoder Loss:  0.37003142
Encoder Loss:  0.048287358  || Decoder Loss:  0.048287358 Validation Decoder Loss:  0.35353002
Encoder Loss:  0.043990448  || Decoder Loss:  0.043990448 Validation Decoder Loss:  0.3599695
Encoder Loss:  0.040228873  || Decoder Loss:  0.040228873 Validation Decoder Loss:  0.34846374
Encoder Loss:  0.038977694  || Decoder Loss:  0.038977694 Validation Decoder Loss:  0.34508666
Encoder Loss:  0.038328644  || Decoder Loss:  0.038328644 Validation Decoder Loss:  0.34321755
Encoder Loss:  0.037928477  || Decoder Loss:  0.037928477 Validation Decoder Loss:  0.34247234
Encoder Loss:  0.037657063  || Decoder Loss:  0.037657063 Validation Decoder Loss:  0.3419967
Encoder Loss:  0.03745935  || Decoder Loss:  0.03745935 Validation Decoder Loss:  0.34167206
Encoder Loss:  0.03730588  || Decoder Loss:  0.03730588 Validation Decoder Loss:  0.34146267
Encoder Loss:  0.03717934  || Decoder Loss:  0.03717934 Validation Decoder Loss:  0.34133857
Encoder Loss:  0.037069708  || Decoder Loss:  0.037069708 Validation Decoder Loss:  0.34127456
Encoder Loss:  0.036971245  || Decoder Loss:  0.036971245 Validation Decoder Loss:  0.34125227
Encoder Loss:  0.0368807  || Decoder Loss:  0.0368807 Validation Decoder Loss:  0.3412586
Encoder Loss:  0.036796242  || Decoder Loss:  0.036796242 Validation Decoder Loss:  0.3412844
Encoder Loss:  0.036716774  || Decoder Loss:  0.036716774 Validation Decoder Loss:  0.34132296
Encoder Loss:  0.036641583  || Decoder Loss:  0.036641583 Validation Decoder Loss:  0.34136957
Encoder Loss:  0.036570176  || Decoder Loss:  0.036570176 Validation Decoder Loss:  0.34142077
Encoder Loss:  0.036502153  || Decoder Loss:  0.036502153 Validation Decoder Loss:  0.34147447
Encoder Loss:  0.036437172  || Decoder Loss:  0.036437172 Validation Decoder Loss:  0.34152928
Encoder Loss:  0.03637495  || Decoder Loss:  0.03637495 Validation Decoder Loss:  0.34158438
Encoder Loss:  0.036315203  || Decoder Loss:  0.036315203 Validation Decoder Loss:  0.34163928
Encoder Loss:  0.03625768  || Decoder Loss:  0.03625768 Validation Decoder Loss:  0.3416937
Encoder Loss:  0.03620216  || Decoder Loss:  0.03620216 Validation Decoder Loss:  0.34174752
Encoder Loss:  0.036148407  || Decoder Loss:  0.036148407 Validation Decoder Loss:  0.34180066
Encoder Loss:  0.03609623  || Decoder Loss:  0.03609623 Validation Decoder Loss:  0.34185305
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34185308
Model: "sequential_709"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_497 (Conv3D (None, 70, 11, 20, 1)     22        
_________________________________________________________________
dropout_1025 (Dropout)       (None, 70, 11, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_498 (Conv3D (None, 220, 11, 20, 1)    14        
_________________________________________________________________
reshape_182 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 36
Trainable params: 36
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_711"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_343 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_1027 (Dropout)       (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_344 (Conv2D)          (None, 2420, 20, 1)       102       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_712"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_343 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1029 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_344 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.04363831  || Decoder Loss:  0.04363831 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453424
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.0436383  || Decoder Loss:  0.0436383 Validation Decoder Loss:  0.35453427
Encoder Loss:  0.043638304  || Decoder Loss:  0.043638304 Validation Decoder Loss:  0.35453427
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35453427
Model: "sequential_713"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_500 (Conv3D (None, 85, 6, 20, 1)      45        
_________________________________________________________________
dropout_1031 (Dropout)       (None, 85, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_501 (Conv3D (None, 220, 11, 20, 1)    817       
_________________________________________________________________
reshape_183 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 862
Trainable params: 862
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_715"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_345 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_1033 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_346 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_716"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_345 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_1035 (Dropout)       (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_346 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36185405  || Decoder Loss:  0.10189403 Validation Decoder Loss:  0.3838884
Encoder Loss:  0.34577042  || Decoder Loss:  0.11734624 Validation Decoder Loss:  0.3992291
Encoder Loss:  0.27091968  || Decoder Loss:  0.2244459 Validation Decoder Loss:  1.2555609
Encoder Loss:  0.11312675  || Decoder Loss:  0.2607604 Validation Decoder Loss:  0.39320844
Encoder Loss:  0.09952449  || Decoder Loss:  0.053832226 Validation Decoder Loss:  0.33889806
Encoder Loss:  0.08530675  || Decoder Loss:  0.04210618 Validation Decoder Loss:  0.33624345
Encoder Loss:  0.05547689  || Decoder Loss:  0.03953538 Validation Decoder Loss:  0.3335964
Encoder Loss:  0.050134372  || Decoder Loss:  0.036856245 Validation Decoder Loss:  0.3323899
Encoder Loss:  0.05006153  || Decoder Loss:  0.03589732 Validation Decoder Loss:  0.33215088
Encoder Loss:  0.050065584  || Decoder Loss:  0.0355472 Validation Decoder Loss:  0.33213532
Encoder Loss:  0.050057627  || Decoder Loss:  0.03538705 Validation Decoder Loss:  0.33204144
Encoder Loss:  0.050060958  || Decoder Loss:  0.035294976 Validation Decoder Loss:  0.33203512
Encoder Loss:  0.050056443  || Decoder Loss:  0.035236355 Validation Decoder Loss:  0.33206314
Encoder Loss:  0.050052647  || Decoder Loss:  0.035198744 Validation Decoder Loss:  0.332033
Encoder Loss:  0.050058194  || Decoder Loss:  0.035176493 Validation Decoder Loss:  0.33203524
Encoder Loss:  0.050054714  || Decoder Loss:  0.0351441 Validation Decoder Loss:  0.3320104
Encoder Loss:  0.050057314  || Decoder Loss:  0.035125412 Validation Decoder Loss:  0.33200932
Encoder Loss:  0.05004605  || Decoder Loss:  0.035100505 Validation Decoder Loss:  0.3319463
Encoder Loss:  0.050049182  || Decoder Loss:  0.035102155 Validation Decoder Loss:  0.33196047
Encoder Loss:  0.050053686  || Decoder Loss:  0.035084322 Validation Decoder Loss:  0.33194372
Encoder Loss:  0.050045684  || Decoder Loss:  0.035051033 Validation Decoder Loss:  0.33194202
Encoder Loss:  0.050045457  || Decoder Loss:  0.035054084 Validation Decoder Loss:  0.33192015
Encoder Loss:  0.05005403  || Decoder Loss:  0.035078313 Validation Decoder Loss:  0.33190942
Encoder Loss:  0.050044566  || Decoder Loss:  0.035054397 Validation Decoder Loss:  0.3319478
Encoder Loss:  0.05004546  || Decoder Loss:  0.035052475 Validation Decoder Loss:  0.33192387
Encoder Loss:  0.050045803  || Decoder Loss:  0.035073236 Validation Decoder Loss:  0.3319022
Encoder Loss:  0.05004454  || Decoder Loss:  0.035074845 Validation Decoder Loss:  0.33191523
Encoder Loss:  0.050048593  || Decoder Loss:  0.035066947 Validation Decoder Loss:  0.33193752
Encoder Loss:  0.050039764  || Decoder Loss:  0.035056017 Validation Decoder Loss:  0.3319129
Encoder Loss:  0.050039977  || Decoder Loss:  0.035073183 Validation Decoder Loss:  0.33188522
Encoder Loss:  0.050054334  || Decoder Loss:  0.0350901 Validation Decoder Loss:  0.33191207
Encoder Loss:  0.050034706  || Decoder Loss:  0.035095245 Validation Decoder Loss:  0.33190882
Encoder Loss:  0.050053984  || Decoder Loss:  0.035105392 Validation Decoder Loss:  0.33195955
Encoder Loss:  0.050040636  || Decoder Loss:  0.03510169 Validation Decoder Loss:  0.33191615
Encoder Loss:  0.050038747  || Decoder Loss:  0.03511184 Validation Decoder Loss:  0.3319735
Encoder Loss:  0.05003929  || Decoder Loss:  0.035102107 Validation Decoder Loss:  0.33194005
Encoder Loss:  0.050048284  || Decoder Loss:  0.035111602 Validation Decoder Loss:  0.3319373
Encoder Loss:  0.05003701  || Decoder Loss:  0.03512707 Validation Decoder Loss:  0.33190632
Encoder Loss:  0.050041676  || Decoder Loss:  0.035148717 Validation Decoder Loss:  0.3319099
Encoder Loss:  0.05003789  || Decoder Loss:  0.035161663 Validation Decoder Loss:  0.33192068
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33192065
Model: "sequential_717"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_503 (Conv3D (None, 180, 8, 20, 1)     469       
_________________________________________________________________
dropout_1037 (Dropout)       (None, 180, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_504 (Conv3D (None, 220, 11, 20, 1)    165       
_________________________________________________________________
reshape_184 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 634
Trainable params: 634
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_719"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_347 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_1039 (Dropout)       (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_348 (Conv2D)          (None, 2420, 20, 1)       12        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_720"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_347 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1041 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_348 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16511598  || Decoder Loss:  0.081074834 Validation Decoder Loss:  0.37068912
Encoder Loss:  0.16517106  || Decoder Loss:  0.08132699 Validation Decoder Loss:  0.3708902
Encoder Loss:  0.16523816  || Decoder Loss:  0.081631675 Validation Decoder Loss:  0.37111247
Encoder Loss:  0.16531156  || Decoder Loss:  0.081960216 Validation Decoder Loss:  0.37134114
Encoder Loss:  0.1653893  || Decoder Loss:  0.082302324 Validation Decoder Loss:  0.37157163
Encoder Loss:  0.16547102  || Decoder Loss:  0.08265536 Validation Decoder Loss:  0.3718027
Encoder Loss:  0.16555677  || Decoder Loss:  0.08301902 Validation Decoder Loss:  0.37203404
Encoder Loss:  0.16564676  || Decoder Loss:  0.08339356 Validation Decoder Loss:  0.3722657
Encoder Loss:  0.16574119  || Decoder Loss:  0.08377946 Validation Decoder Loss:  0.37249783
Encoder Loss:  0.16584036  || Decoder Loss:  0.08417726 Validation Decoder Loss:  0.3727308
Encoder Loss:  0.1659445  || Decoder Loss:  0.084587574 Validation Decoder Loss:  0.37296498
Encoder Loss:  0.16605388  || Decoder Loss:  0.08501097 Validation Decoder Loss:  0.37320083
Encoder Loss:  0.16616882  || Decoder Loss:  0.08544814 Validation Decoder Loss:  0.37343872
Encoder Loss:  0.16628958  || Decoder Loss:  0.085899755 Validation Decoder Loss:  0.37367913
Encoder Loss:  0.16641657  || Decoder Loss:  0.08636657 Validation Decoder Loss:  0.3739224
Encoder Loss:  0.16655008  || Decoder Loss:  0.08684937 Validation Decoder Loss:  0.37416905
Encoder Loss:  0.1666905  || Decoder Loss:  0.08734899 Validation Decoder Loss:  0.37441954
Encoder Loss:  0.16683824  || Decoder Loss:  0.08786636 Validation Decoder Loss:  0.37467444
Encoder Loss:  0.16699372  || Decoder Loss:  0.088402435 Validation Decoder Loss:  0.37493426
Encoder Loss:  0.16715747  || Decoder Loss:  0.08895825 Validation Decoder Loss:  0.37519965
Encoder Loss:  0.16732994  || Decoder Loss:  0.08953492 Validation Decoder Loss:  0.37547117
Encoder Loss:  0.16751163  || Decoder Loss:  0.09013365 Validation Decoder Loss:  0.3757496
Encoder Loss:  0.16770315  || Decoder Loss:  0.090755686 Validation Decoder Loss:  0.37603554
Encoder Loss:  0.16790518  || Decoder Loss:  0.09140244 Validation Decoder Loss:  0.3763299
Encoder Loss:  0.16811831  || Decoder Loss:  0.09207539 Validation Decoder Loss:  0.37663352
Encoder Loss:  0.16834334  || Decoder Loss:  0.092776164 Validation Decoder Loss:  0.37694734
Encoder Loss:  0.16858098  || Decoder Loss:  0.09350644 Validation Decoder Loss:  0.37727264
Encoder Loss:  0.16883214  || Decoder Loss:  0.09426812 Validation Decoder Loss:  0.37761062
Encoder Loss:  0.16909769  || Decoder Loss:  0.09506322 Validation Decoder Loss:  0.3779628
Encoder Loss:  0.16937865  || Decoder Loss:  0.09589393 Validation Decoder Loss:  0.37833104
Encoder Loss:  0.16967613  || Decoder Loss:  0.09676262 Validation Decoder Loss:  0.37871733
Encoder Loss:  0.16999123  || Decoder Loss:  0.097671896 Validation Decoder Loss:  0.3791241
Encoder Loss:  0.17032526  || Decoder Loss:  0.09862456 Validation Decoder Loss:  0.37955397
Encoder Loss:  0.1706797  || Decoder Loss:  0.09962373 Validation Decoder Loss:  0.38001007
Encoder Loss:  0.17105605  || Decoder Loss:  0.10067284 Validation Decoder Loss:  0.38049585
Encoder Loss:  0.17145607  || Decoder Loss:  0.1017756 Validation Decoder Loss:  0.38101524
Encoder Loss:  0.17188166  || Decoder Loss:  0.10293615 Validation Decoder Loss:  0.3815728
Encoder Loss:  0.17233497  || Decoder Loss:  0.1041591 Validation Decoder Loss:  0.3821735
Encoder Loss:  0.17281832  || Decoder Loss:  0.10544952 Validation Decoder Loss:  0.38282308
Encoder Loss:  0.17333442  || Decoder Loss:  0.10681309 Validation Decoder Loss:  0.38352814
Model: siamese_net_lr_0.0003440226776665108 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38352814
Model: "sequential_721"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_506 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_1043 (Dropout)       (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_507 (Conv3D (None, 220, 11, 20, 1)    267       
_________________________________________________________________
reshape_185 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 297
Trainable params: 297
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_723"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_349 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_1045 (Dropout)       (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_350 (Conv2D)          (None, 2420, 20, 1)       172       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_724"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_349 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1047 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_350 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21650212  || Decoder Loss:  0.058220193 Validation Decoder Loss:  0.38551772
Encoder Loss:  0.05032471  || Decoder Loss:  0.03611881 Validation Decoder Loss:  0.34797212
Encoder Loss:  0.050059535  || Decoder Loss:  0.034808658 Validation Decoder Loss:  0.34166002
Encoder Loss:  0.050034966  || Decoder Loss:  0.034682028 Validation Decoder Loss:  0.33991727
Encoder Loss:  0.050046574  || Decoder Loss:  0.034618884 Validation Decoder Loss:  0.3395481
Encoder Loss:  0.05004213  || Decoder Loss:  0.034569427 Validation Decoder Loss:  0.33961296
Encoder Loss:  0.050079003  || Decoder Loss:  0.034525484 Validation Decoder Loss:  0.3394552
Encoder Loss:  0.05004746  || Decoder Loss:  0.034486093 Validation Decoder Loss:  0.33934936
Encoder Loss:  0.05009575  || Decoder Loss:  0.03444325 Validation Decoder Loss:  0.3392154
Encoder Loss:  0.050064255  || Decoder Loss:  0.034401156 Validation Decoder Loss:  0.339724
Encoder Loss:  0.050089907  || Decoder Loss:  0.034358658 Validation Decoder Loss:  0.33913264
Encoder Loss:  0.05005993  || Decoder Loss:  0.03431948 Validation Decoder Loss:  0.3394631
Encoder Loss:  0.050057326  || Decoder Loss:  0.034316994 Validation Decoder Loss:  0.33881414
Encoder Loss:  0.05005497  || Decoder Loss:  0.03428021 Validation Decoder Loss:  0.3382048
Encoder Loss:  0.05005806  || Decoder Loss:  0.034266878 Validation Decoder Loss:  0.3331552
Encoder Loss:  0.050048936  || Decoder Loss:  0.03440449 Validation Decoder Loss:  0.33252272
Encoder Loss:  0.050041627  || Decoder Loss:  0.034387708 Validation Decoder Loss:  0.3325667
Encoder Loss:  0.05004597  || Decoder Loss:  0.03452969 Validation Decoder Loss:  0.3286497
Encoder Loss:  0.05004054  || Decoder Loss:  0.034666892 Validation Decoder Loss:  0.32840696
Encoder Loss:  0.050037622  || Decoder Loss:  0.03467417 Validation Decoder Loss:  0.3286
Encoder Loss:  0.05003573  || Decoder Loss:  0.03467338 Validation Decoder Loss:  0.32874867
Encoder Loss:  0.0500288  || Decoder Loss:  0.034664404 Validation Decoder Loss:  0.32894644
Encoder Loss:  0.05002458  || Decoder Loss:  0.03467556 Validation Decoder Loss:  0.3284763
Encoder Loss:  0.050023645  || Decoder Loss:  0.034671657 Validation Decoder Loss:  0.32867798
Encoder Loss:  0.050026298  || Decoder Loss:  0.034864098 Validation Decoder Loss:  0.338122
Encoder Loss:  0.05002177  || Decoder Loss:  0.034829386 Validation Decoder Loss:  0.33232164
Encoder Loss:  0.050019737  || Decoder Loss:  0.034707744 Validation Decoder Loss:  0.3293714
Encoder Loss:  0.050020713  || Decoder Loss:  0.03478455 Validation Decoder Loss:  0.32902855
Encoder Loss:  0.050017595  || Decoder Loss:  0.03483579 Validation Decoder Loss:  0.3313877
Encoder Loss:  0.05001832  || Decoder Loss:  0.03490539 Validation Decoder Loss:  0.32822582
Encoder Loss:  0.05001777  || Decoder Loss:  0.034912013 Validation Decoder Loss:  0.32847825
Encoder Loss:  0.050015308  || Decoder Loss:  0.03489691 Validation Decoder Loss:  0.32880715
Encoder Loss:  0.05001623  || Decoder Loss:  0.034895696 Validation Decoder Loss:  0.33071053
Encoder Loss:  0.05001379  || Decoder Loss:  0.03491671 Validation Decoder Loss:  0.3313104
Encoder Loss:  0.050014425  || Decoder Loss:  0.03501524 Validation Decoder Loss:  0.3318603
Encoder Loss:  0.05001283  || Decoder Loss:  0.034997 Validation Decoder Loss:  0.3326589
Encoder Loss:  0.050015498  || Decoder Loss:  0.035042193 Validation Decoder Loss:  0.3308587
Encoder Loss:  0.050013736  || Decoder Loss:  0.03502701 Validation Decoder Loss:  0.33036894
Encoder Loss:  0.050012678  || Decoder Loss:  0.035067216 Validation Decoder Loss:  0.331604
Encoder Loss:  0.05001174  || Decoder Loss:  0.035085145 Validation Decoder Loss:  0.33087915
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33087915
Model: "sequential_725"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_509 (Conv3D (None, 137, 10, 20, 1)    23        
_________________________________________________________________
dropout_1049 (Dropout)       (None, 137, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_510 (Conv3D (None, 220, 11, 20, 1)    169       
_________________________________________________________________
reshape_186 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_727"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_351 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_1051 (Dropout)       (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_352 (Conv2D)          (None, 2420, 20, 1)       12        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_728"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_351 (Conv2D (None, 2440, 20, 1)       22        
_________________________________________________________________
dropout_1053 (Dropout)       (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_352 (Conv2D (None, 2607, 20, 1)       169       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1878135  || Decoder Loss:  0.09385227 Validation Decoder Loss:  0.37079477
Encoder Loss:  0.18792166  || Decoder Loss:  0.09412764 Validation Decoder Loss:  0.37111878
Encoder Loss:  0.1880487  || Decoder Loss:  0.09445259 Validation Decoder Loss:  0.3714624
Encoder Loss:  0.18818131  || Decoder Loss:  0.09479315 Validation Decoder Loss:  0.37179565
Encoder Loss:  0.1883147  || Decoder Loss:  0.095137045 Validation Decoder Loss:  0.37211287
Encoder Loss:  0.18844764  || Decoder Loss:  0.09548105 Validation Decoder Loss:  0.3724156
Encoder Loss:  0.1885798  || Decoder Loss:  0.095824584 Validation Decoder Loss:  0.372705
Encoder Loss:  0.18871117  || Decoder Loss:  0.096167654 Validation Decoder Loss:  0.37298164
Encoder Loss:  0.18884183  || Decoder Loss:  0.09651057 Validation Decoder Loss:  0.37324604
Encoder Loss:  0.18897186  || Decoder Loss:  0.09685357 Validation Decoder Loss:  0.37349916
Encoder Loss:  0.18910132  || Decoder Loss:  0.09719699 Validation Decoder Loss:  0.37374234
Encoder Loss:  0.18923031  || Decoder Loss:  0.09754111 Validation Decoder Loss:  0.37397695
Encoder Loss:  0.18935885  || Decoder Loss:  0.0978862 Validation Decoder Loss:  0.37420392
Encoder Loss:  0.18948698  || Decoder Loss:  0.09823246 Validation Decoder Loss:  0.37442368
Encoder Loss:  0.1896147  || Decoder Loss:  0.09858014 Validation Decoder Loss:  0.37463635
Encoder Loss:  0.18974206  || Decoder Loss:  0.098929435 Validation Decoder Loss:  0.37484157
Encoder Loss:  0.18986899  || Decoder Loss:  0.099280484 Validation Decoder Loss:  0.37503928
Encoder Loss:  0.1899955  || Decoder Loss:  0.099633455 Validation Decoder Loss:  0.37522948
Encoder Loss:  0.1901215  || Decoder Loss:  0.099988475 Validation Decoder Loss:  0.37541208
Encoder Loss:  0.19024692  || Decoder Loss:  0.10034561 Validation Decoder Loss:  0.37558722
Encoder Loss:  0.19037165  || Decoder Loss:  0.10070492 Validation Decoder Loss:  0.37575504
Encoder Loss:  0.19049546  || Decoder Loss:  0.10106642 Validation Decoder Loss:  0.37591547
Encoder Loss:  0.19061813  || Decoder Loss:  0.10142998 Validation Decoder Loss:  0.37606832
Encoder Loss:  0.1907394  || Decoder Loss:  0.10179544 Validation Decoder Loss:  0.37621337
Encoder Loss:  0.19085874  || Decoder Loss:  0.10216248 Validation Decoder Loss:  0.37635005
Encoder Loss:  0.19097559  || Decoder Loss:  0.10253052 Validation Decoder Loss:  0.37647724
Encoder Loss:  0.19108906  || Decoder Loss:  0.10289867 Validation Decoder Loss:  0.37659338
Encoder Loss:  0.19119787  || Decoder Loss:  0.10326549 Validation Decoder Loss:  0.37669578
Encoder Loss:  0.19130017  || Decoder Loss:  0.10362868 Validation Decoder Loss:  0.37678045
Encoder Loss:  0.191393  || Decoder Loss:  0.10398449 Validation Decoder Loss:  0.37684053
Encoder Loss:  0.19147147  || Decoder Loss:  0.1043264 Validation Decoder Loss:  0.37686396
Encoder Loss:  0.19152692  || Decoder Loss:  0.104642406 Validation Decoder Loss:  0.376828
Encoder Loss:  0.19154216  || Decoder Loss:  0.104908235 Validation Decoder Loss:  0.37668392
Encoder Loss:  0.19147713  || Decoder Loss:  0.105066605 Validation Decoder Loss:  0.37630582
Encoder Loss:  0.19121161  || Decoder Loss:  0.104943976 Validation Decoder Loss:  0.37524778
Encoder Loss:  0.19013555  || Decoder Loss:  0.103656024 Validation Decoder Loss:  0.37026596
Encoder Loss:  0.17307863  || Decoder Loss:  0.07918883 Validation Decoder Loss:  0.30811253
Encoder Loss:  0.15070674  || Decoder Loss:  0.04702222 Validation Decoder Loss:  0.31790346
Encoder Loss:  0.1491939  || Decoder Loss:  0.045141876 Validation Decoder Loss:  0.3134281
Encoder Loss:  0.14824045  || Decoder Loss:  0.04409099 Validation Decoder Loss:  0.31349203
Model: siamese_net_lr_0.0004384265768047451 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.313492
Model: "sequential_729"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_512 (Conv3D (None, 138, 10, 20, 1)    151       
_________________________________________________________________
dropout_1055 (Dropout)       (None, 138, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_513 (Conv3D (None, 220, 11, 20, 1)    167       
_________________________________________________________________
reshape_187 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_731"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_353 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_1057 (Dropout)       (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_354 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_732"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_353 (Conv2D (None, 2440, 20, 1)       22        
_________________________________________________________________
dropout_1059 (Dropout)       (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_354 (Conv2D (None, 2607, 20, 1)       169       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12840153  || Decoder Loss:  0.09959543 Validation Decoder Loss:  0.3739186
Encoder Loss:  0.1287077  || Decoder Loss:  0.09997496 Validation Decoder Loss:  0.37427014
Encoder Loss:  0.12907532  || Decoder Loss:  0.10043102 Validation Decoder Loss:  0.3746508
Encoder Loss:  0.12946756  || Decoder Loss:  0.1009179 Validation Decoder Loss:  0.37503394
Encoder Loss:  0.12987114  || Decoder Loss:  0.10141916 Validation Decoder Loss:  0.37541157
Encoder Loss:  0.13028264  || Decoder Loss:  0.101930544 Validation Decoder Loss:  0.37578225
Encoder Loss:  0.13070163  || Decoder Loss:  0.10245158 Validation Decoder Loss:  0.37614724
Encoder Loss:  0.13112849  || Decoder Loss:  0.102982745 Validation Decoder Loss:  0.37650886
Encoder Loss:  0.13156389  || Decoder Loss:  0.10352487 Validation Decoder Loss:  0.37686956
Encoder Loss:  0.1320085  || Decoder Loss:  0.104078904 Validation Decoder Loss:  0.37723076
Encoder Loss:  0.13246316  || Decoder Loss:  0.1046459 Validation Decoder Loss:  0.37759346
Encoder Loss:  0.13292874  || Decoder Loss:  0.10522702 Validation Decoder Loss:  0.3779581
Encoder Loss:  0.13340618  || Decoder Loss:  0.10582352 Validation Decoder Loss:  0.3783251
Encoder Loss:  0.13389656  || Decoder Loss:  0.10643676 Validation Decoder Loss:  0.37869534
Encoder Loss:  0.13440104  || Decoder Loss:  0.10706834 Validation Decoder Loss:  0.3790698
Encoder Loss:  0.13492085  || Decoder Loss:  0.10771994 Validation Decoder Loss:  0.37944975
Encoder Loss:  0.13545753  || Decoder Loss:  0.10839356 Validation Decoder Loss:  0.37983674
Encoder Loss:  0.13601257  || Decoder Loss:  0.10909129 Validation Decoder Loss:  0.38023227
Encoder Loss:  0.13658771  || Decoder Loss:  0.10981551 Validation Decoder Loss:  0.38063794
Encoder Loss:  0.13718477  || Decoder Loss:  0.11056881 Validation Decoder Loss:  0.38105518
Encoder Loss:  0.13780577  || Decoder Loss:  0.11135403 Validation Decoder Loss:  0.38148546
Encoder Loss:  0.13845274  || Decoder Loss:  0.112174205 Validation Decoder Loss:  0.3819298
Encoder Loss:  0.13912758  || Decoder Loss:  0.11303245 Validation Decoder Loss:  0.38238895
Encoder Loss:  0.13983196  || Decoder Loss:  0.113931656 Validation Decoder Loss:  0.38286263
Encoder Loss:  0.14056656  || Decoder Loss:  0.114874 Validation Decoder Loss:  0.38334873
Encoder Loss:  0.1413299  || Decoder Loss:  0.1158596 Validation Decoder Loss:  0.38384104
Encoder Loss:  0.14211604  || Decoder Loss:  0.11688401 Validation Decoder Loss:  0.3843248
Encoder Loss:  0.14290869  || Decoder Loss:  0.117932074 Validation Decoder Loss:  0.38476592
Encoder Loss:  0.14366744  || Decoder Loss:  0.1189625 Validation Decoder Loss:  0.38508353
Encoder Loss:  0.14428808  || Decoder Loss:  0.11986459 Validation Decoder Loss:  0.38506603
Encoder Loss:  0.14446564  || Decoder Loss:  0.12030651 Validation Decoder Loss:  0.384045
Encoder Loss:  0.14300436  || Decoder Loss:  0.118970394 Validation Decoder Loss:  0.37889344
Encoder Loss:  0.1288783  || Decoder Loss:  0.1036331 Validation Decoder Loss:  0.33057076
Encoder Loss:  0.08980052  || Decoder Loss:  0.06067825 Validation Decoder Loss:  0.33530772
Encoder Loss:  0.084951  || Decoder Loss:  0.055812523 Validation Decoder Loss:  0.34591934
Encoder Loss:  0.07241913  || Decoder Loss:  0.042572554 Validation Decoder Loss:  0.33119208
Encoder Loss:  0.06893391  || Decoder Loss:  0.03960592 Validation Decoder Loss:  0.34408674
Encoder Loss:  0.06655274  || Decoder Loss:  0.03824781 Validation Decoder Loss:  0.34339637
Encoder Loss:  0.064554706  || Decoder Loss:  0.037994895 Validation Decoder Loss:  0.34180063
Encoder Loss:  0.06143278  || Decoder Loss:  0.037820995 Validation Decoder Loss:  0.3446545
Model: siamese_net_lr_0.00044408724018332615 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3446545
Model: "sequential_733"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_515 (Conv3D (None, 139, 10, 20, 1)    153       
_________________________________________________________________
dropout_1061 (Dropout)       (None, 139, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_516 (Conv3D (None, 220, 11, 20, 1)    165       
_________________________________________________________________
reshape_188 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_735"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_355 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1063 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_356 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_736"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_355 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1065 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_356 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30032986  || Decoder Loss:  0.096292295 Validation Decoder Loss:  0.37094635
Encoder Loss:  0.29967827  || Decoder Loss:  0.09721886 Validation Decoder Loss:  0.37157154
Encoder Loss:  0.29887795  || Decoder Loss:  0.09817008 Validation Decoder Loss:  0.37202382
Encoder Loss:  0.2979407  || Decoder Loss:  0.09902522 Validation Decoder Loss:  0.37222087
Encoder Loss:  0.29681554  || Decoder Loss:  0.09970887 Validation Decoder Loss:  0.37208262
Encoder Loss:  0.29541314  || Decoder Loss:  0.10009081 Validation Decoder Loss:  0.37144336
Encoder Loss:  0.29357815  || Decoder Loss:  0.09991359 Validation Decoder Loss:  0.36996555
Encoder Loss:  0.29101622  || Decoder Loss:  0.09863037 Validation Decoder Loss:  0.3669504
Encoder Loss:  0.28710815  || Decoder Loss:  0.09496704 Validation Decoder Loss:  0.36088258
Encoder Loss:  0.28038722  || Decoder Loss:  0.08564802 Validation Decoder Loss:  0.34893504
Encoder Loss:  0.2674227  || Decoder Loss:  0.063003324 Validation Decoder Loss:  0.33822745
Encoder Loss:  0.24911161  || Decoder Loss:  0.03956731 Validation Decoder Loss:  0.35041237
Encoder Loss:  0.21952318  || Decoder Loss:  0.038041774 Validation Decoder Loss:  0.34465402
Encoder Loss:  0.113541886  || Decoder Loss:  0.038054433 Validation Decoder Loss:  0.3432814
Encoder Loss:  0.08873592  || Decoder Loss:  0.0379849 Validation Decoder Loss:  0.3427249
Encoder Loss:  0.07598809  || Decoder Loss:  0.037894167 Validation Decoder Loss:  0.34253114
Encoder Loss:  0.07592769  || Decoder Loss:  0.03781278 Validation Decoder Loss:  0.34238535
Encoder Loss:  0.07553076  || Decoder Loss:  0.037735894 Validation Decoder Loss:  0.34221488
Encoder Loss:  0.07496249  || Decoder Loss:  0.03766022 Validation Decoder Loss:  0.34204602
Encoder Loss:  0.0741863  || Decoder Loss:  0.037583433 Validation Decoder Loss:  0.34188715
Encoder Loss:  0.07364403  || Decoder Loss:  0.037503127 Validation Decoder Loss:  0.34173697
Encoder Loss:  0.073027365  || Decoder Loss:  0.0374169 Validation Decoder Loss:  0.3415878
Encoder Loss:  0.07226085  || Decoder Loss:  0.03732312 Validation Decoder Loss:  0.34142274
Encoder Loss:  0.07146545  || Decoder Loss:  0.037219588 Validation Decoder Loss:  0.34122837
Encoder Loss:  0.07065867  || Decoder Loss:  0.03710411 Validation Decoder Loss:  0.3409971
Encoder Loss:  0.06964116  || Decoder Loss:  0.036974758 Validation Decoder Loss:  0.34071934
Encoder Loss:  0.068422616  || Decoder Loss:  0.0368306 Validation Decoder Loss:  0.34038773
Encoder Loss:  0.06681278  || Decoder Loss:  0.036673322 Validation Decoder Loss:  0.34000134
Encoder Loss:  0.064341895  || Decoder Loss:  0.03650697 Validation Decoder Loss:  0.33958328
Encoder Loss:  0.054556035  || Decoder Loss:  0.036336564 Validation Decoder Loss:  0.3391834
Encoder Loss:  0.05039282  || Decoder Loss:  0.03615935 Validation Decoder Loss:  0.33886182
Encoder Loss:  0.0490442  || Decoder Loss:  0.035968937 Validation Decoder Loss:  0.33858538
Encoder Loss:  0.048385438  || Decoder Loss:  0.03575505 Validation Decoder Loss:  0.33826745
Encoder Loss:  0.047696866  || Decoder Loss:  0.03550698 Validation Decoder Loss:  0.3378206
Encoder Loss:  0.047116045  || Decoder Loss:  0.0352175 Validation Decoder Loss:  0.33718306
Encoder Loss:  0.046573184  || Decoder Loss:  0.0348867 Validation Decoder Loss:  0.3363245
Encoder Loss:  0.04602079  || Decoder Loss:  0.03452965 Validation Decoder Loss:  0.33527738
Encoder Loss:  0.045524854  || Decoder Loss:  0.034183025 Validation Decoder Loss:  0.3341871
Encoder Loss:  0.045259565  || Decoder Loss:  0.033893805 Validation Decoder Loss:  0.33328485
Encoder Loss:  0.04511328  || Decoder Loss:  0.03368547 Validation Decoder Loss:  0.33268028
Model: siamese_net_lr_0.0007421820966466386 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33268028
Model: "sequential_737"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_518 (Conv3D (None, 170, 8, 20, 1)     177       
_________________________________________________________________
dropout_1067 (Dropout)       (None, 170, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_519 (Conv3D (None, 220, 11, 20, 1)    205       
_________________________________________________________________
reshape_189 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_739"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_357 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1069 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_358 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_740"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_357 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_1071 (Dropout)       (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_358 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38608745  || Decoder Loss:  0.08004913 Validation Decoder Loss:  0.3736539
Encoder Loss:  0.38523775  || Decoder Loss:  0.08037387 Validation Decoder Loss:  0.37414208
Encoder Loss:  0.38418347  || Decoder Loss:  0.08077969 Validation Decoder Loss:  0.3746608
Encoder Loss:  0.3830058  || Decoder Loss:  0.08124026 Validation Decoder Loss:  0.37516242
Encoder Loss:  0.38172784  || Decoder Loss:  0.0817513 Validation Decoder Loss:  0.37563306
Encoder Loss:  0.38034612  || Decoder Loss:  0.08231763 Validation Decoder Loss:  0.37607926
Encoder Loss:  0.3788471  || Decoder Loss:  0.08294768 Validation Decoder Loss:  0.376512
Encoder Loss:  0.3772114  || Decoder Loss:  0.08365378 Validation Decoder Loss:  0.3769402
Encoder Loss:  0.37541354  || Decoder Loss:  0.08445286 Validation Decoder Loss:  0.3773722
Encoder Loss:  0.37341997  || Decoder Loss:  0.08536753 Validation Decoder Loss:  0.37781885
Encoder Loss:  0.37118524  || Decoder Loss:  0.0864282 Validation Decoder Loss:  0.3782968
Encoder Loss:  0.36864698  || Decoder Loss:  0.08767705 Validation Decoder Loss:  0.3788314
Encoder Loss:  0.3657157  || Decoder Loss:  0.08917495 Validation Decoder Loss:  0.379462
Encoder Loss:  0.3622581  || Decoder Loss:  0.09101386 Validation Decoder Loss:  0.3802544
Encoder Loss:  0.3580654  || Decoder Loss:  0.093339965 Validation Decoder Loss:  0.38132748
Encoder Loss:  0.35278952  || Decoder Loss:  0.09640147 Validation Decoder Loss:  0.38291734
Encoder Loss:  0.34580025  || Decoder Loss:  0.10065859 Validation Decoder Loss:  0.38555175
Encoder Loss:  0.33582222  || Decoder Loss:  0.10707745 Validation Decoder Loss:  0.3906437
Encoder Loss:  0.31981108  || Decoder Loss:  0.11811761 Validation Decoder Loss:  0.4033108
Encoder Loss:  0.28843337  || Decoder Loss:  0.14256942 Validation Decoder Loss:  0.45687658
Encoder Loss:  0.20401989  || Decoder Loss:  0.23644702 Validation Decoder Loss:  0.8630371
Encoder Loss:  0.10168878  || Decoder Loss:  0.465127 Validation Decoder Loss:  0.92646056
Encoder Loss:  0.101214156  || Decoder Loss:  0.38196036 Validation Decoder Loss:  0.6987303
Encoder Loss:  0.097904235  || Decoder Loss:  0.30114472 Validation Decoder Loss:  0.6039497
Encoder Loss:  0.09688042  || Decoder Loss:  0.26910976 Validation Decoder Loss:  0.55802625
Encoder Loss:  0.09642796  || Decoder Loss:  0.23887113 Validation Decoder Loss:  0.5405586
Encoder Loss:  0.09571847  || Decoder Loss:  0.2233115 Validation Decoder Loss:  0.50613546
Encoder Loss:  0.09482114  || Decoder Loss:  0.19355339 Validation Decoder Loss:  0.4792756
Encoder Loss:  0.09377393  || Decoder Loss:  0.17477658 Validation Decoder Loss:  0.44425327
Encoder Loss:  0.091782674  || Decoder Loss:  0.15597032 Validation Decoder Loss:  0.419272
Encoder Loss:  0.08608321  || Decoder Loss:  0.14094393 Validation Decoder Loss:  0.40566513
Encoder Loss:  0.06270947  || Decoder Loss:  0.127128 Validation Decoder Loss:  0.39253366
Encoder Loss:  0.0646462  || Decoder Loss:  0.114895806 Validation Decoder Loss:  0.38145664
Encoder Loss:  0.059786387  || Decoder Loss:  0.10490258 Validation Decoder Loss:  0.37213704
Encoder Loss:  0.05769336  || Decoder Loss:  0.09573683 Validation Decoder Loss:  0.3653467
Encoder Loss:  0.058015924  || Decoder Loss:  0.086328514 Validation Decoder Loss:  0.36044487
Encoder Loss:  0.05848337  || Decoder Loss:  0.07530499 Validation Decoder Loss:  0.3575409
Encoder Loss:  0.05697665  || Decoder Loss:  0.062392157 Validation Decoder Loss:  0.35087737
Encoder Loss:  0.05613968  || Decoder Loss:  0.049107008 Validation Decoder Loss:  0.33906257
Encoder Loss:  0.05589115  || Decoder Loss:  0.0421964 Validation Decoder Loss:  0.3403232
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3403232
Model: "sequential_741"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_521 (Conv3D (None, 201, 10, 20, 1)    829       
_________________________________________________________________
dropout_1073 (Dropout)       (None, 201, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_522 (Conv3D (None, 220, 11, 20, 1)    41        
_________________________________________________________________
reshape_190 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 870
Trainable params: 870
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_743"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_359 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_1075 (Dropout)       (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_360 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_744"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_359 (Conv2D (None, 2520, 20, 1)       102       
_________________________________________________________________
dropout_1077 (Dropout)       (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_360 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4086322  || Decoder Loss:  0.06837284 Validation Decoder Loss:  0.3629521
Encoder Loss:  0.3923043  || Decoder Loss:  0.08021097 Validation Decoder Loss:  0.36950392
Encoder Loss:  0.35656512  || Decoder Loss:  0.11008137 Validation Decoder Loss:  0.40764514
Encoder Loss:  0.22839029  || Decoder Loss:  0.13735004 Validation Decoder Loss:  0.44842267
Encoder Loss:  0.07533316  || Decoder Loss:  0.085998625 Validation Decoder Loss:  0.40922034
Encoder Loss:  0.055509042  || Decoder Loss:  0.05374289 Validation Decoder Loss:  0.3399272
Encoder Loss:  0.050873704  || Decoder Loss:  0.039540127 Validation Decoder Loss:  0.33612812
Encoder Loss:  0.050557703  || Decoder Loss:  0.037027348 Validation Decoder Loss:  0.33446646
Encoder Loss:  0.05048319  || Decoder Loss:  0.03550692 Validation Decoder Loss:  0.33400124
Encoder Loss:  0.05030418  || Decoder Loss:  0.03463746 Validation Decoder Loss:  0.3337649
Encoder Loss:  0.05021329  || Decoder Loss:  0.034146465 Validation Decoder Loss:  0.33384466
Encoder Loss:  0.05012821  || Decoder Loss:  0.033936292 Validation Decoder Loss:  0.33404654
Encoder Loss:  0.050094746  || Decoder Loss:  0.033839628 Validation Decoder Loss:  0.33417633
Encoder Loss:  0.05007192  || Decoder Loss:  0.033792235 Validation Decoder Loss:  0.33435577
Encoder Loss:  0.050052628  || Decoder Loss:  0.03376138 Validation Decoder Loss:  0.3346066
Encoder Loss:  0.050037134  || Decoder Loss:  0.03374114 Validation Decoder Loss:  0.3347862
Encoder Loss:  0.05003158  || Decoder Loss:  0.03371739 Validation Decoder Loss:  0.3346353
Encoder Loss:  0.05002861  || Decoder Loss:  0.033692177 Validation Decoder Loss:  0.3346963
Encoder Loss:  0.050026704  || Decoder Loss:  0.033676982 Validation Decoder Loss:  0.33484003
Encoder Loss:  0.05002505  || Decoder Loss:  0.03365799 Validation Decoder Loss:  0.33470297
Encoder Loss:  0.05002325  || Decoder Loss:  0.033642195 Validation Decoder Loss:  0.3347385
Encoder Loss:  0.050021682  || Decoder Loss:  0.03363206 Validation Decoder Loss:  0.3347655
Encoder Loss:  0.050021056  || Decoder Loss:  0.03362803 Validation Decoder Loss:  0.3348761
Encoder Loss:  0.050019603  || Decoder Loss:  0.03361929 Validation Decoder Loss:  0.3347471
Encoder Loss:  0.050018925  || Decoder Loss:  0.033614885 Validation Decoder Loss:  0.33476454
Encoder Loss:  0.050018378  || Decoder Loss:  0.033613797 Validation Decoder Loss:  0.3347835
Encoder Loss:  0.050017565  || Decoder Loss:  0.033617873 Validation Decoder Loss:  0.33484173
Encoder Loss:  0.050017033  || Decoder Loss:  0.033618394 Validation Decoder Loss:  0.3347449
Encoder Loss:  0.05001657  || Decoder Loss:  0.03362417 Validation Decoder Loss:  0.33476797
Encoder Loss:  0.05001612  || Decoder Loss:  0.03363333 Validation Decoder Loss:  0.33478913
Encoder Loss:  0.050015744  || Decoder Loss:  0.03364221 Validation Decoder Loss:  0.3348307
Encoder Loss:  0.050015125  || Decoder Loss:  0.03364959 Validation Decoder Loss:  0.3347398
Encoder Loss:  0.050014865  || Decoder Loss:  0.033660755 Validation Decoder Loss:  0.33474475
Encoder Loss:  0.05001434  || Decoder Loss:  0.033673495 Validation Decoder Loss:  0.33476865
Encoder Loss:  0.050014105  || Decoder Loss:  0.033684596 Validation Decoder Loss:  0.3346671
Encoder Loss:  0.05001426  || Decoder Loss:  0.033694398 Validation Decoder Loss:  0.33466706
Encoder Loss:  0.050014008  || Decoder Loss:  0.0337076 Validation Decoder Loss:  0.33471018
Encoder Loss:  0.05001311  || Decoder Loss:  0.033724174 Validation Decoder Loss:  0.33466005
Encoder Loss:  0.05001403  || Decoder Loss:  0.03373441 Validation Decoder Loss:  0.334684
Encoder Loss:  0.050014246  || Decoder Loss:  0.03374014 Validation Decoder Loss:  0.33459136
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33459136
Model: "sequential_745"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_524 (Conv3D (None, 118, 5, 20, 1)     56        
_________________________________________________________________
dropout_1079 (Dropout)       (None, 118, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_525 (Conv3D (None, 220, 11, 20, 1)    310       
_________________________________________________________________
reshape_191 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 366
Trainable params: 366
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_747"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_361 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1081 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_362 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_748"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_361 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1083 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_362 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17199226  || Decoder Loss:  0.051630672 Validation Decoder Loss:  0.337553
Encoder Loss:  0.052119404  || Decoder Loss:  0.03427347 Validation Decoder Loss:  0.32899532
Encoder Loss:  0.050910953  || Decoder Loss:  0.033248723 Validation Decoder Loss:  0.3289985
Encoder Loss:  0.050787613  || Decoder Loss:  0.033141125 Validation Decoder Loss:  0.32900542
Encoder Loss:  0.05074671  || Decoder Loss:  0.033064686 Validation Decoder Loss:  0.3290138
Encoder Loss:  0.05044763  || Decoder Loss:  0.033006188 Validation Decoder Loss:  0.32902592
Encoder Loss:  0.050427027  || Decoder Loss:  0.03295853 Validation Decoder Loss:  0.32896152
Encoder Loss:  0.050259117  || Decoder Loss:  0.032919887 Validation Decoder Loss:  0.32893804
Encoder Loss:  0.050182767  || Decoder Loss:  0.032888725 Validation Decoder Loss:  0.32896817
Encoder Loss:  0.050096773  || Decoder Loss:  0.03286166 Validation Decoder Loss:  0.32889935
Encoder Loss:  0.050029248  || Decoder Loss:  0.032841235 Validation Decoder Loss:  0.32888106
Encoder Loss:  0.050011374  || Decoder Loss:  0.03282397 Validation Decoder Loss:  0.32902348
Encoder Loss:  0.050006043  || Decoder Loss:  0.03280748 Validation Decoder Loss:  0.3288799
Encoder Loss:  0.049997017  || Decoder Loss:  0.032796253 Validation Decoder Loss:  0.32901233
Encoder Loss:  0.050027456  || Decoder Loss:  0.032785285 Validation Decoder Loss:  0.32890388
Encoder Loss:  0.050000258  || Decoder Loss:  0.032776736 Validation Decoder Loss:  0.3290188
Encoder Loss:  0.050011855  || Decoder Loss:  0.032769665 Validation Decoder Loss:  0.3289206
Encoder Loss:  0.04997046  || Decoder Loss:  0.0327602 Validation Decoder Loss:  0.32898504
Encoder Loss:  0.05006299  || Decoder Loss:  0.032755908 Validation Decoder Loss:  0.32895005
Encoder Loss:  0.04998038  || Decoder Loss:  0.032750484 Validation Decoder Loss:  0.32896298
Encoder Loss:  0.049972687  || Decoder Loss:  0.032745253 Validation Decoder Loss:  0.3289941
Encoder Loss:  0.04996046  || Decoder Loss:  0.032739446 Validation Decoder Loss:  0.3291503
Encoder Loss:  0.049946893  || Decoder Loss:  0.03273577 Validation Decoder Loss:  0.32907903
Encoder Loss:  0.049940586  || Decoder Loss:  0.03273139 Validation Decoder Loss:  0.32910556
Encoder Loss:  0.049935736  || Decoder Loss:  0.032727867 Validation Decoder Loss:  0.3290982
Encoder Loss:  0.04994079  || Decoder Loss:  0.032724917 Validation Decoder Loss:  0.32905334
Encoder Loss:  0.049937643  || Decoder Loss:  0.03272153 Validation Decoder Loss:  0.32906428
Encoder Loss:  0.049951464  || Decoder Loss:  0.032719627 Validation Decoder Loss:  0.3290478
Encoder Loss:  0.049923476  || Decoder Loss:  0.03271653 Validation Decoder Loss:  0.3290657
Encoder Loss:  0.049929246  || Decoder Loss:  0.032715093 Validation Decoder Loss:  0.32905984
Encoder Loss:  0.049922332  || Decoder Loss:  0.03271312 Validation Decoder Loss:  0.32906175
Encoder Loss:  0.049911156  || Decoder Loss:  0.0327109 Validation Decoder Loss:  0.32907987
Encoder Loss:  0.049915075  || Decoder Loss:  0.032709956 Validation Decoder Loss:  0.32907194
Encoder Loss:  0.04992379  || Decoder Loss:  0.03270772 Validation Decoder Loss:  0.32910597
Encoder Loss:  0.049896035  || Decoder Loss:  0.032706987 Validation Decoder Loss:  0.32907325
Encoder Loss:  0.049899377  || Decoder Loss:  0.03270505 Validation Decoder Loss:  0.32913798
Encoder Loss:  0.04989575  || Decoder Loss:  0.032704704 Validation Decoder Loss:  0.32908583
Encoder Loss:  0.04989598  || Decoder Loss:  0.032703403 Validation Decoder Loss:  0.32907528
Encoder Loss:  0.049892206  || Decoder Loss:  0.032702077 Validation Decoder Loss:  0.32908174
Encoder Loss:  0.049902596  || Decoder Loss:  0.032701205 Validation Decoder Loss:  0.32906455
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32906455
Model: "sequential_749"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_527 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_1085 (Dropout)       (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_528 (Conv3D (None, 220, 11, 20, 1)    946       
_________________________________________________________________
reshape_192 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 970
Trainable params: 970
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_751"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_363 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_1087 (Dropout)       (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_364 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_752"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_363 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1089 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_364 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3703392  || Decoder Loss:  0.09708559 Validation Decoder Loss:  0.37447792
Encoder Loss:  0.3661041  || Decoder Loss:  0.099657446 Validation Decoder Loss:  0.37696874
Encoder Loss:  0.36129227  || Decoder Loss:  0.102651745 Validation Decoder Loss:  0.37954813
Encoder Loss:  0.35620263  || Decoder Loss:  0.105900824 Validation Decoder Loss:  0.38222486
Encoder Loss:  0.35080272  || Decoder Loss:  0.10943509 Validation Decoder Loss:  0.38506705
Encoder Loss:  0.34501892  || Decoder Loss:  0.113313235 Validation Decoder Loss:  0.3881566
Encoder Loss:  0.3387566  || Decoder Loss:  0.117611386 Validation Decoder Loss:  0.39159793
Encoder Loss:  0.33189103  || Decoder Loss:  0.12243042 Validation Decoder Loss:  0.39552954
Encoder Loss:  0.32424968  || Decoder Loss:  0.12790933 Validation Decoder Loss:  0.40014592
Encoder Loss:  0.31558138  || Decoder Loss:  0.13424799 Validation Decoder Loss:  0.40573293
Encoder Loss:  0.30549714  || Decoder Loss:  0.14174704 Validation Decoder Loss:  0.41273707
Encoder Loss:  0.29334316  || Decoder Loss:  0.15087783 Validation Decoder Loss:  0.42192057
Encoder Loss:  0.27787438  || Decoder Loss:  0.16236961 Validation Decoder Loss:  0.4346521
Encoder Loss:  0.25597396  || Decoder Loss:  0.17644584 Validation Decoder Loss:  0.45298234
Encoder Loss:  0.21173704  || Decoder Loss:  0.17928211 Validation Decoder Loss:  0.46202555
Encoder Loss:  0.08976106  || Decoder Loss:  0.17239729 Validation Decoder Loss:  0.46148157
Encoder Loss:  0.052489802  || Decoder Loss:  0.1588727 Validation Decoder Loss:  0.44754595
Encoder Loss:  0.050366964  || Decoder Loss:  0.12559849 Validation Decoder Loss:  0.42811334
Encoder Loss:  0.050119575  || Decoder Loss:  0.10431871 Validation Decoder Loss:  0.41491568
Encoder Loss:  0.050066926  || Decoder Loss:  0.09144892 Validation Decoder Loss:  0.4018865
Encoder Loss:  0.050054897  || Decoder Loss:  0.08125234 Validation Decoder Loss:  0.39216757
Encoder Loss:  0.05004583  || Decoder Loss:  0.072843984 Validation Decoder Loss:  0.38314372
Encoder Loss:  0.05003801  || Decoder Loss:  0.0660408 Validation Decoder Loss:  0.37589696
Encoder Loss:  0.05003047  || Decoder Loss:  0.06069216 Validation Decoder Loss:  0.3699169
Encoder Loss:  0.050024077  || Decoder Loss:  0.056421347 Validation Decoder Loss:  0.3650514
Encoder Loss:  0.05001863  || Decoder Loss:  0.052993417 Validation Decoder Loss:  0.3609507
Encoder Loss:  0.050014526  || Decoder Loss:  0.050217796 Validation Decoder Loss:  0.35749894
Encoder Loss:  0.05001473  || Decoder Loss:  0.04795058 Validation Decoder Loss:  0.35446244
Encoder Loss:  0.050014757  || Decoder Loss:  0.046085812 Validation Decoder Loss:  0.3517871
Encoder Loss:  0.050012745  || Decoder Loss:  0.044544835 Validation Decoder Loss:  0.34952766
Encoder Loss:  0.050011527  || Decoder Loss:  0.043263007 Validation Decoder Loss:  0.3475867
Encoder Loss:  0.05001467  || Decoder Loss:  0.04219104 Validation Decoder Loss:  0.34586555
Encoder Loss:  0.050013393  || Decoder Loss:  0.041288204 Validation Decoder Loss:  0.34436005
Encoder Loss:  0.050010312  || Decoder Loss:  0.0405212 Validation Decoder Loss:  0.34306568
Encoder Loss:  0.050011776  || Decoder Loss:  0.039868683 Validation Decoder Loss:  0.34190685
Encoder Loss:  0.050013352  || Decoder Loss:  0.039313126 Validation Decoder Loss:  0.34087962
Encoder Loss:  0.050012864  || Decoder Loss:  0.03883576 Validation Decoder Loss:  0.33998123
Encoder Loss:  0.05001232  || Decoder Loss:  0.03842345 Validation Decoder Loss:  0.33918342
Encoder Loss:  0.050011624  || Decoder Loss:  0.038067054 Validation Decoder Loss:  0.33845907
Encoder Loss:  0.050010823  || Decoder Loss:  0.03775826 Validation Decoder Loss:  0.33780453
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33780453
Model: "sequential_753"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_530 (Conv3D (None, 130, 11, 20, 1)    13        
_________________________________________________________________
dropout_1091 (Dropout)       (None, 130, 11, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_531 (Conv3D (None, 220, 11, 20, 1)    92        
_________________________________________________________________
reshape_193 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 105
Trainable params: 105
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_755"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_365 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1093 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_366 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_756"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_365 (Conv2D (None, 2430, 20, 1)       12        
_________________________________________________________________
dropout_1095 (Dropout)       (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_366 (Conv2D (None, 2607, 20, 1)       179       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474438  || Decoder Loss:  0.09474438 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080705
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080705
Encoder Loss:  0.09474438  || Decoder Loss:  0.09474438 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474438  || Decoder Loss:  0.09474438 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Encoder Loss:  0.09474437  || Decoder Loss:  0.09474437 Validation Decoder Loss:  0.37080702
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37080702
Model: "sequential_757"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_533 (Conv3D (None, 220, 6, 20, 1)     189       
_________________________________________________________________
dropout_1097 (Dropout)       (None, 220, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_534 (Conv3D (None, 220, 11, 20, 1)    7         
_________________________________________________________________
reshape_194 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 196
Trainable params: 196
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_759"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_367 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1099 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_368 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_760"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_367 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1101 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_368 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302515
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302515
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.34302518
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Encoder Loss:  0.040365882  || Decoder Loss:  0.040365882 Validation Decoder Loss:  0.3430252
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34302518
Model: "sequential_761"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_536 (Conv3D (None, 124, 5, 20, 1)     62        
_________________________________________________________________
dropout_1103 (Dropout)       (None, 124, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_537 (Conv3D (None, 220, 11, 20, 1)    292       
_________________________________________________________________
reshape_195 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 354
Trainable params: 354
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_763"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_369 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1105 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_370 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_764"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_369 (Conv2D (None, 2470, 20, 1)       52        
_________________________________________________________________
dropout_1107 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_370 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3771192  || Decoder Loss:  0.10379843 Validation Decoder Loss:  0.3782691
Encoder Loss:  0.37163684  || Decoder Loss:  0.10470154 Validation Decoder Loss:  0.37924162
Encoder Loss:  0.36503515  || Decoder Loss:  0.1057497 Validation Decoder Loss:  0.38012224
Encoder Loss:  0.35785538  || Decoder Loss:  0.107023604 Validation Decoder Loss:  0.38097838
Encoder Loss:  0.35021928  || Decoder Loss:  0.10869957 Validation Decoder Loss:  0.38200414
Encoder Loss:  0.34206674  || Decoder Loss:  0.11101417 Validation Decoder Loss:  0.3834448
Encoder Loss:  0.33306038  || Decoder Loss:  0.11436664 Validation Decoder Loss:  0.38569975
Encoder Loss:  0.32212105  || Decoder Loss:  0.11972267 Validation Decoder Loss:  0.39006358
Encoder Loss:  0.30472168  || Decoder Loss:  0.13029073 Validation Decoder Loss:  0.4027782
Encoder Loss:  0.23176216  || Decoder Loss:  0.14519608 Validation Decoder Loss:  0.35964483
Encoder Loss:  0.10359108  || Decoder Loss:  0.07887834 Validation Decoder Loss:  0.33208153
Encoder Loss:  0.10099781  || Decoder Loss:  0.05900494 Validation Decoder Loss:  0.3290996
Encoder Loss:  0.098677665  || Decoder Loss:  0.054989632 Validation Decoder Loss:  0.33035827
Encoder Loss:  0.095954  || Decoder Loss:  0.05158417 Validation Decoder Loss:  0.33050227
Encoder Loss:  0.09414711  || Decoder Loss:  0.049123004 Validation Decoder Loss:  0.33012936
Encoder Loss:  0.09288681  || Decoder Loss:  0.047059692 Validation Decoder Loss:  0.3302397
Encoder Loss:  0.09156606  || Decoder Loss:  0.045356225 Validation Decoder Loss:  0.32997835
Encoder Loss:  0.088618964  || Decoder Loss:  0.043842744 Validation Decoder Loss:  0.3302925
Encoder Loss:  0.060711857  || Decoder Loss:  0.042422943 Validation Decoder Loss:  0.33192253
Encoder Loss:  0.055185568  || Decoder Loss:  0.04125059 Validation Decoder Loss:  0.33357033
Encoder Loss:  0.05428128  || Decoder Loss:  0.040136613 Validation Decoder Loss:  0.33426923
Encoder Loss:  0.053363543  || Decoder Loss:  0.039144736 Validation Decoder Loss:  0.33510077
Encoder Loss:  0.053226985  || Decoder Loss:  0.03828275 Validation Decoder Loss:  0.33574158
Encoder Loss:  0.052837394  || Decoder Loss:  0.03755224 Validation Decoder Loss:  0.33640996
Encoder Loss:  0.05284306  || Decoder Loss:  0.036945466 Validation Decoder Loss:  0.33695412
Encoder Loss:  0.05243576  || Decoder Loss:  0.036444806 Validation Decoder Loss:  0.33734843
Encoder Loss:  0.05263638  || Decoder Loss:  0.036031555 Validation Decoder Loss:  0.33746058
Encoder Loss:  0.05199236  || Decoder Loss:  0.03569265 Validation Decoder Loss:  0.33747026
Encoder Loss:  0.052174345  || Decoder Loss:  0.035415575 Validation Decoder Loss:  0.33732778
Encoder Loss:  0.05218439  || Decoder Loss:  0.03518872 Validation Decoder Loss:  0.3371033
Encoder Loss:  0.051811825  || Decoder Loss:  0.03499928 Validation Decoder Loss:  0.33688045
Encoder Loss:  0.05160907  || Decoder Loss:  0.034835257 Validation Decoder Loss:  0.33661777
Encoder Loss:  0.050848342  || Decoder Loss:  0.03468802 Validation Decoder Loss:  0.3363228
Encoder Loss:  0.05064638  || Decoder Loss:  0.034551773 Validation Decoder Loss:  0.33598143
Encoder Loss:  0.05057502  || Decoder Loss:  0.0344212 Validation Decoder Loss:  0.33555803
Encoder Loss:  0.050579157  || Decoder Loss:  0.034292046 Validation Decoder Loss:  0.33501974
Encoder Loss:  0.05062969  || Decoder Loss:  0.034162566 Validation Decoder Loss:  0.3343523
Encoder Loss:  0.050610878  || Decoder Loss:  0.03403604 Validation Decoder Loss:  0.33364642
Encoder Loss:  0.05059728  || Decoder Loss:  0.033918146 Validation Decoder Loss:  0.33305514
Encoder Loss:  0.050551344  || Decoder Loss:  0.033815432 Validation Decoder Loss:  0.33268422
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33268422
Model: "sequential_765"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_539 (Conv3D (None, 110, 5, 20, 1)     48        
_________________________________________________________________
dropout_1109 (Dropout)       (None, 110, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_540 (Conv3D (None, 220, 11, 20, 1)    778       
_________________________________________________________________
reshape_196 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 826
Trainable params: 826
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_767"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_371 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1111 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_372 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_768"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_371 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1113 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_372 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21667448  || Decoder Loss:  0.10349825 Validation Decoder Loss:  0.37870434
Encoder Loss:  0.21589994  || Decoder Loss:  0.10487144 Validation Decoder Loss:  0.37985188
Encoder Loss:  0.21496686  || Decoder Loss:  0.10633326 Validation Decoder Loss:  0.38071525
Encoder Loss:  0.21384649  || Decoder Loss:  0.10765379 Validation Decoder Loss:  0.38109756
Encoder Loss:  0.21234389  || Decoder Loss:  0.108544566 Validation Decoder Loss:  0.3805462
Encoder Loss:  0.20995058  || Decoder Loss:  0.10822725 Validation Decoder Loss:  0.37775135
Encoder Loss:  0.20506598  || Decoder Loss:  0.10410548 Validation Decoder Loss:  0.36831963
Encoder Loss:  0.1911697  || Decoder Loss:  0.08524547 Validation Decoder Loss:  0.34132737
Encoder Loss:  0.1622018  || Decoder Loss:  0.04356725 Validation Decoder Loss:  0.34847465
Encoder Loss:  0.12066443  || Decoder Loss:  0.038306974 Validation Decoder Loss:  0.34308827
Encoder Loss:  0.0805626  || Decoder Loss:  0.038110286 Validation Decoder Loss:  0.34249744
Encoder Loss:  0.07280641  || Decoder Loss:  0.03800741 Validation Decoder Loss:  0.34220684
Encoder Loss:  0.06817422  || Decoder Loss:  0.037912175 Validation Decoder Loss:  0.34202382
Encoder Loss:  0.06563105  || Decoder Loss:  0.037823025 Validation Decoder Loss:  0.3418573
Encoder Loss:  0.06363738  || Decoder Loss:  0.037735566 Validation Decoder Loss:  0.34167755
Encoder Loss:  0.06210762  || Decoder Loss:  0.037646484 Validation Decoder Loss:  0.34150052
Encoder Loss:  0.060327068  || Decoder Loss:  0.037551332 Validation Decoder Loss:  0.34132344
Encoder Loss:  0.058341295  || Decoder Loss:  0.037446786 Validation Decoder Loss:  0.34113008
Encoder Loss:  0.052163564  || Decoder Loss:  0.037329268 Validation Decoder Loss:  0.34091565
Encoder Loss:  0.04598961  || Decoder Loss:  0.037191175 Validation Decoder Loss:  0.34070253
Encoder Loss:  0.044208746  || Decoder Loss:  0.037029803 Validation Decoder Loss:  0.34046298
Encoder Loss:  0.043306317  || Decoder Loss:  0.036845986 Validation Decoder Loss:  0.34014142
Encoder Loss:  0.04300305  || Decoder Loss:  0.036641218 Validation Decoder Loss:  0.33973825
Encoder Loss:  0.042573348  || Decoder Loss:  0.03642425 Validation Decoder Loss:  0.33933693
Encoder Loss:  0.04243182  || Decoder Loss:  0.036199283 Validation Decoder Loss:  0.33901262
Encoder Loss:  0.042331174  || Decoder Loss:  0.035953127 Validation Decoder Loss:  0.33870637
Encoder Loss:  0.042177897  || Decoder Loss:  0.035660658 Validation Decoder Loss:  0.33824486
Encoder Loss:  0.041968707  || Decoder Loss:  0.035298277 Validation Decoder Loss:  0.3374781
Encoder Loss:  0.04176135  || Decoder Loss:  0.03485765 Validation Decoder Loss:  0.3363236
Encoder Loss:  0.041409463  || Decoder Loss:  0.034372818 Validation Decoder Loss:  0.33487076
Encoder Loss:  0.041134015  || Decoder Loss:  0.033943675 Validation Decoder Loss:  0.33357397
Encoder Loss:  0.040989097  || Decoder Loss:  0.033658355 Validation Decoder Loss:  0.33280504
Encoder Loss:  0.04088039  || Decoder Loss:  0.033495065 Validation Decoder Loss:  0.3324501
Encoder Loss:  0.040819522  || Decoder Loss:  0.0333976 Validation Decoder Loss:  0.33224165
Encoder Loss:  0.04076405  || Decoder Loss:  0.033334687 Validation Decoder Loss:  0.33209592
Encoder Loss:  0.04074137  || Decoder Loss:  0.033290774 Validation Decoder Loss:  0.33198833
Encoder Loss:  0.040706612  || Decoder Loss:  0.033257578 Validation Decoder Loss:  0.33190227
Encoder Loss:  0.04066592  || Decoder Loss:  0.033230364 Validation Decoder Loss:  0.3318259
Encoder Loss:  0.040647887  || Decoder Loss:  0.03320618 Validation Decoder Loss:  0.3317557
Encoder Loss:  0.04063172  || Decoder Loss:  0.033183377 Validation Decoder Loss:  0.33169857
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33169857
Model: "sequential_769"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_542 (Conv3D (None, 122, 5, 20, 1)     60        
_________________________________________________________________
dropout_1115 (Dropout)       (None, 122, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_543 (Conv3D (None, 220, 11, 20, 1)    298       
_________________________________________________________________
reshape_197 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 358
Trainable params: 358
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_771"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_373 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_1117 (Dropout)       (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_374 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_772"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_373 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1119 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_374 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13200268  || Decoder Loss:  0.09933401 Validation Decoder Loss:  0.3733958
Encoder Loss:  0.13181372  || Decoder Loss:  0.09943698 Validation Decoder Loss:  0.37335706
Encoder Loss:  0.13153206  || Decoder Loss:  0.099514484 Validation Decoder Loss:  0.3732493
Encoder Loss:  0.1311585  || Decoder Loss:  0.099532366 Validation Decoder Loss:  0.3730293
Encoder Loss:  0.13069321  || Decoder Loss:  0.09947518 Validation Decoder Loss:  0.37266088
Encoder Loss:  0.13012853  || Decoder Loss:  0.0993276 Validation Decoder Loss:  0.37211743
Encoder Loss:  0.1294437  || Decoder Loss:  0.09906258 Validation Decoder Loss:  0.37137085
Encoder Loss:  0.12859903  || Decoder Loss:  0.09863358 Validation Decoder Loss:  0.3703746
Encoder Loss:  0.1275253  || Decoder Loss:  0.09796215 Validation Decoder Loss:  0.3690505
Encoder Loss:  0.12610444  || Decoder Loss:  0.09691651 Validation Decoder Loss:  0.3672644
Encoder Loss:  0.12413953  || Decoder Loss:  0.09527806 Validation Decoder Loss:  0.36478624
Encoder Loss:  0.12130233  || Decoder Loss:  0.09268359 Validation Decoder Loss:  0.36125952
Encoder Loss:  0.117044926  || Decoder Loss:  0.088527955 Validation Decoder Loss:  0.35619724
Encoder Loss:  0.110480376  || Decoder Loss:  0.081836104 Validation Decoder Loss:  0.3491786
Encoder Loss:  0.10040993  || Decoder Loss:  0.07131206 Validation Decoder Loss:  0.34099847
Encoder Loss:  0.08642411  || Decoder Loss:  0.056643005 Validation Decoder Loss:  0.33695713
Encoder Loss:  0.07255842  || Decoder Loss:  0.04285965 Validation Decoder Loss:  0.34397757
Encoder Loss:  0.064350314  || Decoder Loss:  0.038270358 Validation Decoder Loss:  0.34811497
Encoder Loss:  0.049705762  || Decoder Loss:  0.038272742 Validation Decoder Loss:  0.34463513
Encoder Loss:  0.04870946  || Decoder Loss:  0.03817398 Validation Decoder Loss:  0.3440091
Encoder Loss:  0.04486487  || Decoder Loss:  0.037983805 Validation Decoder Loss:  0.34290272
Encoder Loss:  0.04545646  || Decoder Loss:  0.03791575 Validation Decoder Loss:  0.3426168
Encoder Loss:  0.044454873  || Decoder Loss:  0.03784487 Validation Decoder Loss:  0.34243092
Encoder Loss:  0.044887204  || Decoder Loss:  0.037784185 Validation Decoder Loss:  0.34241977
Encoder Loss:  0.044340305  || Decoder Loss:  0.037725363 Validation Decoder Loss:  0.34233782
Encoder Loss:  0.04454963  || Decoder Loss:  0.037666798 Validation Decoder Loss:  0.34227887
Encoder Loss:  0.044242814  || Decoder Loss:  0.03761071 Validation Decoder Loss:  0.34216338
Encoder Loss:  0.044302322  || Decoder Loss:  0.03755286 Validation Decoder Loss:  0.3420714
Encoder Loss:  0.044062536  || Decoder Loss:  0.03749427 Validation Decoder Loss:  0.3419568
Encoder Loss:  0.04412582  || Decoder Loss:  0.03743172 Validation Decoder Loss:  0.3418815
Encoder Loss:  0.043821096  || Decoder Loss:  0.03736637 Validation Decoder Loss:  0.34177276
Encoder Loss:  0.043901224  || Decoder Loss:  0.037295558 Validation Decoder Loss:  0.3416959
Encoder Loss:  0.043618873  || Decoder Loss:  0.037220046 Validation Decoder Loss:  0.34157795
Encoder Loss:  0.043659505  || Decoder Loss:  0.037136275 Validation Decoder Loss:  0.34147608
Encoder Loss:  0.043342415  || Decoder Loss:  0.037045795 Validation Decoder Loss:  0.34131992
Encoder Loss:  0.04337775  || Decoder Loss:  0.03694506 Validation Decoder Loss:  0.34117383
Encoder Loss:  0.043040596  || Decoder Loss:  0.03683533 Validation Decoder Loss:  0.34096396
Encoder Loss:  0.043022994  || Decoder Loss:  0.036714766 Validation Decoder Loss:  0.34074983
Encoder Loss:  0.042667028  || Decoder Loss:  0.03658609 Validation Decoder Loss:  0.34047064
Encoder Loss:  0.04249892  || Decoder Loss:  0.036450554 Validation Decoder Loss:  0.3401881
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34018812
Model: "sequential_773"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_545 (Conv3D (None, 90, 6, 20, 1)      55        
_________________________________________________________________
dropout_1121 (Dropout)       (None, 90, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_546 (Conv3D (None, 220, 11, 20, 1)    253       
_________________________________________________________________
reshape_198 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 308
Trainable params: 308
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_775"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_375 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_1123 (Dropout)       (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_376 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_776"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_375 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1125 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_376 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04402431  || Decoder Loss:  0.04402431 Validation Decoder Loss:  0.33838755
Encoder Loss:  0.03423468  || Decoder Loss:  0.03423468 Validation Decoder Loss:  0.33053392
Encoder Loss:  0.03338693  || Decoder Loss:  0.03338693 Validation Decoder Loss:  0.3299595
Encoder Loss:  0.033240225  || Decoder Loss:  0.033240225 Validation Decoder Loss:  0.32980993
Encoder Loss:  0.033146515  || Decoder Loss:  0.033146515 Validation Decoder Loss:  0.3298033
Encoder Loss:  0.033077985  || Decoder Loss:  0.033077985 Validation Decoder Loss:  0.32979727
Encoder Loss:  0.03302344  || Decoder Loss:  0.03302344 Validation Decoder Loss:  0.32977477
Encoder Loss:  0.03297872  || Decoder Loss:  0.03297872 Validation Decoder Loss:  0.32974583
Encoder Loss:  0.03294159  || Decoder Loss:  0.03294159 Validation Decoder Loss:  0.329718
Encoder Loss:  0.032910395  || Decoder Loss:  0.032910395 Validation Decoder Loss:  0.32969505
Encoder Loss:  0.03288398  || Decoder Loss:  0.03288398 Validation Decoder Loss:  0.32967806
Encoder Loss:  0.03286144  || Decoder Loss:  0.03286144 Validation Decoder Loss:  0.32966706
Encoder Loss:  0.03284217  || Decoder Loss:  0.03284217 Validation Decoder Loss:  0.32966122
Encoder Loss:  0.03282561  || Decoder Loss:  0.03282561 Validation Decoder Loss:  0.32965976
Encoder Loss:  0.032811254  || Decoder Loss:  0.032811254 Validation Decoder Loss:  0.32966167
Encoder Loss:  0.032798827  || Decoder Loss:  0.032798827 Validation Decoder Loss:  0.329666
Encoder Loss:  0.03278802  || Decoder Loss:  0.03278802 Validation Decoder Loss:  0.3296721
Encoder Loss:  0.032778457  || Decoder Loss:  0.032778457 Validation Decoder Loss:  0.3296793
Encoder Loss:  0.032770023  || Decoder Loss:  0.032770023 Validation Decoder Loss:  0.3296871
Encoder Loss:  0.032762527  || Decoder Loss:  0.032762527 Validation Decoder Loss:  0.32969505
Encoder Loss:  0.032755814  || Decoder Loss:  0.032755814 Validation Decoder Loss:  0.32970294
Encoder Loss:  0.032749824  || Decoder Loss:  0.032749824 Validation Decoder Loss:  0.32971066
Encoder Loss:  0.03274435  || Decoder Loss:  0.03274435 Validation Decoder Loss:  0.329718
Encoder Loss:  0.032739416  || Decoder Loss:  0.032739416 Validation Decoder Loss:  0.32972503
Encoder Loss:  0.0327349  || Decoder Loss:  0.0327349 Validation Decoder Loss:  0.32973158
Encoder Loss:  0.032730795  || Decoder Loss:  0.032730795 Validation Decoder Loss:  0.32973772
Encoder Loss:  0.032727007  || Decoder Loss:  0.032727007 Validation Decoder Loss:  0.3297435
Encoder Loss:  0.032723546  || Decoder Loss:  0.032723546 Validation Decoder Loss:  0.32974896
Encoder Loss:  0.032720346  || Decoder Loss:  0.032720346 Validation Decoder Loss:  0.32975405
Encoder Loss:  0.032717403  || Decoder Loss:  0.032717403 Validation Decoder Loss:  0.32975882
Encoder Loss:  0.03271468  || Decoder Loss:  0.03271468 Validation Decoder Loss:  0.32976335
Encoder Loss:  0.032712154  || Decoder Loss:  0.032712154 Validation Decoder Loss:  0.3297677
Encoder Loss:  0.032709807  || Decoder Loss:  0.032709807 Validation Decoder Loss:  0.32977182
Encoder Loss:  0.032707646  || Decoder Loss:  0.032707646 Validation Decoder Loss:  0.32977575
Encoder Loss:  0.03270564  || Decoder Loss:  0.03270564 Validation Decoder Loss:  0.32977954
Encoder Loss:  0.03270374  || Decoder Loss:  0.03270374 Validation Decoder Loss:  0.32978317
Encoder Loss:  0.03270199  || Decoder Loss:  0.03270199 Validation Decoder Loss:  0.32978672
Encoder Loss:  0.032700356  || Decoder Loss:  0.032700356 Validation Decoder Loss:  0.32979017
Encoder Loss:  0.032698832  || Decoder Loss:  0.032698832 Validation Decoder Loss:  0.32979354
Encoder Loss:  0.032697372  || Decoder Loss:  0.032697372 Validation Decoder Loss:  0.3297968
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3297968
Model: "sequential_777"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_548 (Conv3D (None, 102, 10, 20, 1)    79        
_________________________________________________________________
dropout_1127 (Dropout)       (None, 102, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_549 (Conv3D (None, 220, 11, 20, 1)    37        
_________________________________________________________________
reshape_199 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_779"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_377 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_1129 (Dropout)       (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_378 (Conv2D)          (None, 2420, 20, 1)       22        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_780"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_377 (Conv2D (None, 2480, 20, 1)       62        
_________________________________________________________________
dropout_1131 (Dropout)       (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_378 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42623454  || Decoder Loss:  0.051466797 Validation Decoder Loss:  0.36003137
Encoder Loss:  0.42601615  || Decoder Loss:  0.05158431 Validation Decoder Loss:  0.360371
Encoder Loss:  0.42576396  || Decoder Loss:  0.051718708 Validation Decoder Loss:  0.360691
Encoder Loss:  0.42550275  || Decoder Loss:  0.051859103 Validation Decoder Loss:  0.36094576
Encoder Loss:  0.42523605  || Decoder Loss:  0.052007005 Validation Decoder Loss:  0.36111528
Encoder Loss:  0.42494863  || Decoder Loss:  0.052168604 Validation Decoder Loss:  0.36121333
Encoder Loss:  0.42451322  || Decoder Loss:  0.052342534 Validation Decoder Loss:  0.36132956
Encoder Loss:  0.4234489  || Decoder Loss:  0.052521013 Validation Decoder Loss:  0.36141154
Encoder Loss:  0.42131168  || Decoder Loss:  0.052719295 Validation Decoder Loss:  0.36145848
Encoder Loss:  0.41808563  || Decoder Loss:  0.052948598 Validation Decoder Loss:  0.36149883
Encoder Loss:  0.413914  || Decoder Loss:  0.0532107 Validation Decoder Loss:  0.36155397
Encoder Loss:  0.40895796  || Decoder Loss:  0.053506352 Validation Decoder Loss:  0.36163527
Encoder Loss:  0.40336263  || Decoder Loss:  0.053839162 Validation Decoder Loss:  0.36174333
Encoder Loss:  0.3972488  || Decoder Loss:  0.054220755 Validation Decoder Loss:  0.36186808
Encoder Loss:  0.39070973  || Decoder Loss:  0.054677375 Validation Decoder Loss:  0.36199158
Encoder Loss:  0.3838038  || Decoder Loss:  0.055256706 Validation Decoder Loss:  0.36209702
Encoder Loss:  0.37654063  || Decoder Loss:  0.056032173 Validation Decoder Loss:  0.3621854
Encoder Loss:  0.36886123  || Decoder Loss:  0.057105344 Validation Decoder Loss:  0.36229575
Encoder Loss:  0.36060902  || Decoder Loss:  0.05861887 Validation Decoder Loss:  0.36252576
Encoder Loss:  0.3514648  || Decoder Loss:  0.060797215 Validation Decoder Loss:  0.36307937
Encoder Loss:  0.34078664  || Decoder Loss:  0.0640239 Validation Decoder Loss:  0.36439037
Encoder Loss:  0.32717812  || Decoder Loss:  0.06893382 Validation Decoder Loss:  0.36726877
Encoder Loss:  0.30715767  || Decoder Loss:  0.07597962 Validation Decoder Loss:  0.37165713
Encoder Loss:  0.26999938  || Decoder Loss:  0.076413766 Validation Decoder Loss:  0.3596913
Encoder Loss:  0.17595527  || Decoder Loss:  0.05057899 Validation Decoder Loss:  0.34075996
Encoder Loss:  0.094283596  || Decoder Loss:  0.04909324 Validation Decoder Loss:  0.3518031
Encoder Loss:  0.089219294  || Decoder Loss:  0.04588394 Validation Decoder Loss:  0.34066203
Encoder Loss:  0.0885934  || Decoder Loss:  0.044955693 Validation Decoder Loss:  0.34547377
Encoder Loss:  0.08560652  || Decoder Loss:  0.043753162 Validation Decoder Loss:  0.3410117
Encoder Loss:  0.08791753  || Decoder Loss:  0.04304113 Validation Decoder Loss:  0.3426301
Encoder Loss:  0.085521065  || Decoder Loss:  0.042296648 Validation Decoder Loss:  0.34098053
Encoder Loss:  0.08672936  || Decoder Loss:  0.041729033 Validation Decoder Loss:  0.34146506
Encoder Loss:  0.08464469  || Decoder Loss:  0.041177146 Validation Decoder Loss:  0.34051216
Encoder Loss:  0.085918024  || Decoder Loss:  0.040716078 Validation Decoder Loss:  0.34076118
Encoder Loss:  0.083616205  || Decoder Loss:  0.040273096 Validation Decoder Loss:  0.34003806
Encoder Loss:  0.084272414  || Decoder Loss:  0.03989726 Validation Decoder Loss:  0.34015977
Encoder Loss:  0.08067021  || Decoder Loss:  0.039526444 Validation Decoder Loss:  0.33962923
Encoder Loss:  0.071249  || Decoder Loss:  0.03922109 Validation Decoder Loss:  0.33969727
Encoder Loss:  0.056748204  || Decoder Loss:  0.03892577 Validation Decoder Loss:  0.33932793
Encoder Loss:  0.055671234  || Decoder Loss:  0.038678404 Validation Decoder Loss:  0.3389379
Model: siamese_net_lr_0.0008319167827188819 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3389379
Model: "sequential_781"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_551 (Conv3D (None, 182, 5, 20, 1)     57        
_________________________________________________________________
dropout_1133 (Dropout)       (None, 182, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_552 (Conv3D (None, 220, 11, 20, 1)    274       
_________________________________________________________________
reshape_200 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 331
Trainable params: 331
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_783"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_379 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_1135 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_380 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_784"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_379 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_1137 (Dropout)       (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_380 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17284146  || Decoder Loss:  0.068676285 Validation Decoder Loss:  0.37271768
Encoder Loss:  0.17252561  || Decoder Loss:  0.06881521 Validation Decoder Loss:  0.37326217
Encoder Loss:  0.17214102  || Decoder Loss:  0.06898009 Validation Decoder Loss:  0.3738636
Encoder Loss:  0.17171901  || Decoder Loss:  0.06915473 Validation Decoder Loss:  0.37448
Encoder Loss:  0.17127673  || Decoder Loss:  0.06934634 Validation Decoder Loss:  0.37509197
Encoder Loss:  0.1708239  || Decoder Loss:  0.06956686 Validation Decoder Loss:  0.3756923
Encoder Loss:  0.17036599  || Decoder Loss:  0.06982654 Validation Decoder Loss:  0.37627888
Encoder Loss:  0.16990827  || Decoder Loss:  0.07013663 Validation Decoder Loss:  0.37685055
Encoder Loss:  0.16945729  || Decoder Loss:  0.070511945 Validation Decoder Loss:  0.37740695
Encoder Loss:  0.16902278  || Decoder Loss:  0.070973486 Validation Decoder Loss:  0.37794802
Encoder Loss:  0.16861936  || Decoder Loss:  0.07155236 Validation Decoder Loss:  0.378475
Encoder Loss:  0.16826995  || Decoder Loss:  0.07229681 Validation Decoder Loss:  0.37899262
Encoder Loss:  0.1680122  || Decoder Loss:  0.07328575 Validation Decoder Loss:  0.37951404
Encoder Loss:  0.16791162  || Decoder Loss:  0.07465686 Validation Decoder Loss:  0.38007605
Encoder Loss:  0.16809161  || Decoder Loss:  0.07667226 Validation Decoder Loss:  0.38078538
Encoder Loss:  0.16881059  || Decoder Loss:  0.07989275 Validation Decoder Loss:  0.38198864
Encoder Loss:  0.17070323  || Decoder Loss:  0.08574057 Validation Decoder Loss:  0.38507682
Encoder Loss:  0.17579044  || Decoder Loss:  0.09895122 Validation Decoder Loss:  0.3985201
Encoder Loss:  0.19529286  || Decoder Loss:  0.14665772 Validation Decoder Loss:  0.56697917
Encoder Loss:  0.33680266  || Decoder Loss:  0.43165034 Validation Decoder Loss:  1.1384178
Encoder Loss:  0.37876832  || Decoder Loss:  0.49552473 Validation Decoder Loss:  0.84262437
Encoder Loss:  0.32458976  || Decoder Loss:  0.4315375 Validation Decoder Loss:  0.9378304
Encoder Loss:  0.31865728  || Decoder Loss:  0.41983646 Validation Decoder Loss:  0.86435664
Encoder Loss:  0.2884653  || Decoder Loss:  0.37704235 Validation Decoder Loss:  0.6708
Encoder Loss:  0.21318206  || Decoder Loss:  0.26616028 Validation Decoder Loss:  0.5740073
Encoder Loss:  0.18355942  || Decoder Loss:  0.22273716 Validation Decoder Loss:  0.5568639
Encoder Loss:  0.1677523  || Decoder Loss:  0.19978143 Validation Decoder Loss:  0.53329337
Encoder Loss:  0.15351416  || Decoder Loss:  0.17907009 Validation Decoder Loss:  0.5110077
Encoder Loss:  0.13780874  || Decoder Loss:  0.15629123 Validation Decoder Loss:  0.47822016
Encoder Loss:  0.12451089  || Decoder Loss:  0.13688509 Validation Decoder Loss:  0.44961637
Encoder Loss:  0.11246962  || Decoder Loss:  0.119536705 Validation Decoder Loss:  0.42623597
Encoder Loss:  0.10253085  || Decoder Loss:  0.10511294 Validation Decoder Loss:  0.41097373
Encoder Loss:  0.09300889  || Decoder Loss:  0.09157706 Validation Decoder Loss:  0.39951855
Encoder Loss:  0.0844229  || Decoder Loss:  0.07922188 Validation Decoder Loss:  0.38884848
Encoder Loss:  0.07655586  || Decoder Loss:  0.06814157 Validation Decoder Loss:  0.3779282
Encoder Loss:  0.06979428  || Decoder Loss:  0.058546565 Validation Decoder Loss:  0.36547333
Encoder Loss:  0.064017534  || Decoder Loss:  0.05064387 Validation Decoder Loss:  0.35374263
Encoder Loss:  0.05970457  || Decoder Loss:  0.044686016 Validation Decoder Loss:  0.3465489
Encoder Loss:  0.056405544  || Decoder Loss:  0.040629957 Validation Decoder Loss:  0.34358257
Encoder Loss:  0.054445304  || Decoder Loss:  0.038245894 Validation Decoder Loss:  0.3411888
Model: siamese_net_lr_0.000906409865444621 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3411888
Model: "sequential_785"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_554 (Conv3D (None, 124, 5, 20, 1)     62        
_________________________________________________________________
dropout_1139 (Dropout)       (None, 124, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_555 (Conv3D (None, 220, 11, 20, 1)    292       
_________________________________________________________________
reshape_201 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 354
Trainable params: 354
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_787"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_381 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_1141 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_382 (Conv2D)          (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_788"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_381 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1143 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_382 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3745003  || Decoder Loss:  0.099091604 Validation Decoder Loss:  0.37254384
Encoder Loss:  0.36249095  || Decoder Loss:  0.09864061 Validation Decoder Loss:  0.37042046
Encoder Loss:  0.34841892  || Decoder Loss:  0.09592951 Validation Decoder Loss:  0.3637362
Encoder Loss:  0.3320336  || Decoder Loss:  0.0821247 Validation Decoder Loss:  0.34150794
Encoder Loss:  0.30209884  || Decoder Loss:  0.043094497 Validation Decoder Loss:  0.34510127
Encoder Loss:  0.124586314  || Decoder Loss:  0.038024988 Validation Decoder Loss:  0.34252286
Encoder Loss:  0.09379006  || Decoder Loss:  0.037810773 Validation Decoder Loss:  0.3422283
Encoder Loss:  0.09246305  || Decoder Loss:  0.037616014 Validation Decoder Loss:  0.3418795
Encoder Loss:  0.09103244  || Decoder Loss:  0.037410382 Validation Decoder Loss:  0.3415847
Encoder Loss:  0.08982464  || Decoder Loss:  0.037163142 Validation Decoder Loss:  0.3411886
Encoder Loss:  0.0876473  || Decoder Loss:  0.036852665 Validation Decoder Loss:  0.34061188
Encoder Loss:  0.07660746  || Decoder Loss:  0.03648653 Validation Decoder Loss:  0.33995965
Encoder Loss:  0.050443396  || Decoder Loss:  0.036097992 Validation Decoder Loss:  0.33938682
Encoder Loss:  0.050089393  || Decoder Loss:  0.035619054 Validation Decoder Loss:  0.33837134
Encoder Loss:  0.050076198  || Decoder Loss:  0.034952868 Validation Decoder Loss:  0.33629835
Encoder Loss:  0.050068364  || Decoder Loss:  0.03415949 Validation Decoder Loss:  0.33370513
Encoder Loss:  0.050058484  || Decoder Loss:  0.033616114 Validation Decoder Loss:  0.33250576
Encoder Loss:  0.050048757  || Decoder Loss:  0.033394065 Validation Decoder Loss:  0.3321628
Encoder Loss:  0.05003863  || Decoder Loss:  0.03329567 Validation Decoder Loss:  0.3320086
Encoder Loss:  0.05002923  || Decoder Loss:  0.033240262 Validation Decoder Loss:  0.3319317
Encoder Loss:  0.05002267  || Decoder Loss:  0.033203088 Validation Decoder Loss:  0.33189058
Encoder Loss:  0.050018214  || Decoder Loss:  0.033175062 Validation Decoder Loss:  0.33186787
Encoder Loss:  0.05001666  || Decoder Loss:  0.03315223 Validation Decoder Loss:  0.33185518
Encoder Loss:  0.050016526  || Decoder Loss:  0.033132643 Validation Decoder Loss:  0.33184806
Encoder Loss:  0.050016355  || Decoder Loss:  0.033115223 Validation Decoder Loss:  0.33184364
Encoder Loss:  0.05001636  || Decoder Loss:  0.033099357 Validation Decoder Loss:  0.33184066
Encoder Loss:  0.050016165  || Decoder Loss:  0.033084642 Validation Decoder Loss:  0.3318388
Encoder Loss:  0.050016027  || Decoder Loss:  0.03307084 Validation Decoder Loss:  0.33183813
Encoder Loss:  0.050015945  || Decoder Loss:  0.03305777 Validation Decoder Loss:  0.33183908
Encoder Loss:  0.050015643  || Decoder Loss:  0.03304532 Validation Decoder Loss:  0.33184183
Encoder Loss:  0.050015472  || Decoder Loss:  0.0330334 Validation Decoder Loss:  0.3318465
Encoder Loss:  0.050015282  || Decoder Loss:  0.033021964 Validation Decoder Loss:  0.33185297
Encoder Loss:  0.05001506  || Decoder Loss:  0.03301094 Validation Decoder Loss:  0.33186108
Encoder Loss:  0.0500149  || Decoder Loss:  0.033000305 Validation Decoder Loss:  0.33187062
Encoder Loss:  0.050014637  || Decoder Loss:  0.032990035 Validation Decoder Loss:  0.33188123
Encoder Loss:  0.050014447  || Decoder Loss:  0.032980084 Validation Decoder Loss:  0.33189225
Encoder Loss:  0.050014287  || Decoder Loss:  0.032970455 Validation Decoder Loss:  0.3319028
Encoder Loss:  0.050014142  || Decoder Loss:  0.03296112 Validation Decoder Loss:  0.33191204
Encoder Loss:  0.050014094  || Decoder Loss:  0.032952063 Validation Decoder Loss:  0.3319198
Encoder Loss:  0.05001392  || Decoder Loss:  0.03294327 Validation Decoder Loss:  0.33192706
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33192706
Model: "sequential_789"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_557 (Conv3D (None, 110, 5, 20, 1)     48        
_________________________________________________________________
dropout_1145 (Dropout)       (None, 110, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_558 (Conv3D (None, 220, 11, 20, 1)    15        
_________________________________________________________________
reshape_202 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_791"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_383 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1147 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_384 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_792"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_383 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_1149 (Dropout)       (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_384 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499496  || Decoder Loss:  0.041499496 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.041499488  || Decoder Loss:  0.041499488 Validation Decoder Loss:  0.34479666
Encoder Loss:  0.04149949  || Decoder Loss:  0.04149949 Validation Decoder Loss:  0.34479666
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34479666
Model: "sequential_793"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_560 (Conv3D (None, 110, 5, 20, 1)     48        
_________________________________________________________________
dropout_1151 (Dropout)       (None, 110, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_561 (Conv3D (None, 220, 11, 20, 1)    15        
_________________________________________________________________
reshape_203 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_795"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_385 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1153 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_386 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_796"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_385 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_1155 (Dropout)       (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_386 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.041477762  || Decoder Loss:  0.041477762 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147778  || Decoder Loss:  0.04147778 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477777  || Decoder Loss:  0.041477777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.041477762  || Decoder Loss:  0.041477762 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477762  || Decoder Loss:  0.041477762 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477766  || Decoder Loss:  0.041477766 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147778  || Decoder Loss:  0.04147778 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.041477766  || Decoder Loss:  0.041477766 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477777  || Decoder Loss:  0.041477777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477777  || Decoder Loss:  0.041477777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.041477762  || Decoder Loss:  0.041477762 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.041477777  || Decoder Loss:  0.041477777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.041477766  || Decoder Loss:  0.041477766 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Encoder Loss:  0.04147778  || Decoder Loss:  0.04147778 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147778  || Decoder Loss:  0.04147778 Validation Decoder Loss:  0.34473568
Encoder Loss:  0.04147777  || Decoder Loss:  0.04147777 Validation Decoder Loss:  0.34473565
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34473568
Model: "sequential_797"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_563 (Conv3D (None, 195, 6, 20, 1)     139       
_________________________________________________________________
dropout_1157 (Dropout)       (None, 195, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_564 (Conv3D (None, 220, 11, 20, 1)    157       
_________________________________________________________________
reshape_204 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 296
Trainable params: 296
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_799"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_387 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1159 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_388 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_800"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_387 (Conv2D (None, 2440, 20, 1)       22        
_________________________________________________________________
dropout_1161 (Dropout)       (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_388 (Conv2D (None, 2607, 20, 1)       169       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.061158  || Decoder Loss:  0.061158 Validation Decoder Loss:  0.36604467
Encoder Loss:  0.061121102  || Decoder Loss:  0.061121102 Validation Decoder Loss:  0.36668402
Encoder Loss:  0.061078098  || Decoder Loss:  0.061078098 Validation Decoder Loss:  0.36736763
Encoder Loss:  0.06103367  || Decoder Loss:  0.06103367 Validation Decoder Loss:  0.36804095
Encoder Loss:  0.0609894  || Decoder Loss:  0.0609894 Validation Decoder Loss:  0.36868367
Encoder Loss:  0.06094543  || Decoder Loss:  0.06094543 Validation Decoder Loss:  0.3692872
Encoder Loss:  0.060901485  || Decoder Loss:  0.060901485 Validation Decoder Loss:  0.36984837
Encoder Loss:  0.06085709  || Decoder Loss:  0.06085709 Validation Decoder Loss:  0.37036818
Encoder Loss:  0.060811702  || Decoder Loss:  0.060811702 Validation Decoder Loss:  0.37085113
Encoder Loss:  0.06076477  || Decoder Loss:  0.06076477 Validation Decoder Loss:  0.37130278
Encoder Loss:  0.06071563  || Decoder Loss:  0.06071563 Validation Decoder Loss:  0.37172827
Encoder Loss:  0.06066346  || Decoder Loss:  0.06066346 Validation Decoder Loss:  0.37213188
Encoder Loss:  0.060607135  || Decoder Loss:  0.060607135 Validation Decoder Loss:  0.372517
Encoder Loss:  0.06054497  || Decoder Loss:  0.06054497 Validation Decoder Loss:  0.37288713
Encoder Loss:  0.060474165  || Decoder Loss:  0.060474165 Validation Decoder Loss:  0.3732476
Encoder Loss:  0.06038968  || Decoder Loss:  0.06038968 Validation Decoder Loss:  0.37361032
Encoder Loss:  0.060281176  || Decoder Loss:  0.060281176 Validation Decoder Loss:  0.37400758
Encoder Loss:  0.060123537  || Decoder Loss:  0.060123537 Validation Decoder Loss:  0.37453645
Encoder Loss:  0.059832733  || Decoder Loss:  0.059832733 Validation Decoder Loss:  0.3756078
Encoder Loss:  0.0588252  || Decoder Loss:  0.0588252 Validation Decoder Loss:  0.38285762
Encoder Loss:  0.052682582  || Decoder Loss:  0.052682582 Validation Decoder Loss:  0.42740995
Encoder Loss:  0.050021686  || Decoder Loss:  0.050021686 Validation Decoder Loss:  0.4278684
Encoder Loss:  0.04791326  || Decoder Loss:  0.04791326 Validation Decoder Loss:  0.41993773
Encoder Loss:  0.045466304  || Decoder Loss:  0.045466304 Validation Decoder Loss:  0.41517875
Encoder Loss:  0.042742696  || Decoder Loss:  0.042742696 Validation Decoder Loss:  0.40383
Encoder Loss:  0.040071763  || Decoder Loss:  0.040071763 Validation Decoder Loss:  0.3926723
Encoder Loss:  0.038140126  || Decoder Loss:  0.038140126 Validation Decoder Loss:  0.3806646
Encoder Loss:  0.039610557  || Decoder Loss:  0.039610557 Validation Decoder Loss:  0.36155552
Encoder Loss:  0.043082613  || Decoder Loss:  0.043082613 Validation Decoder Loss:  0.36160025
Encoder Loss:  0.040852625  || Decoder Loss:  0.040852625 Validation Decoder Loss:  0.36493948
Encoder Loss:  0.03792194  || Decoder Loss:  0.03792194 Validation Decoder Loss:  0.36420062
Encoder Loss:  0.036876954  || Decoder Loss:  0.036876954 Validation Decoder Loss:  0.3728626
Encoder Loss:  0.036478795  || Decoder Loss:  0.036478795 Validation Decoder Loss:  0.36634016
Encoder Loss:  0.036366776  || Decoder Loss:  0.036366776 Validation Decoder Loss:  0.36739677
Encoder Loss:  0.036259387  || Decoder Loss:  0.036259387 Validation Decoder Loss:  0.36511284
Encoder Loss:  0.03619257  || Decoder Loss:  0.03619257 Validation Decoder Loss:  0.36464387
Encoder Loss:  0.03612539  || Decoder Loss:  0.03612539 Validation Decoder Loss:  0.36332873
Encoder Loss:  0.036073986  || Decoder Loss:  0.036073986 Validation Decoder Loss:  0.36255968
Encoder Loss:  0.03602482  || Decoder Loss:  0.03602482 Validation Decoder Loss:  0.36163425
Encoder Loss:  0.035983894  || Decoder Loss:  0.035983894 Validation Decoder Loss:  0.36085138
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3608514
Model: "sequential_801"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_566 (Conv3D (None, 202, 5, 20, 1)     140       
_________________________________________________________________
dropout_1163 (Dropout)       (None, 202, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_567 (Conv3D (None, 220, 11, 20, 1)    58        
_________________________________________________________________
reshape_205 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 198
Trainable params: 198
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_803"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_389 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_1165 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_390 (Conv2D)          (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_804"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_389 (Conv2D (None, 2570, 20, 1)       152       
_________________________________________________________________
dropout_1167 (Dropout)       (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_390 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39127225  || Decoder Loss:  0.055319037 Validation Decoder Loss:  0.3613999
Encoder Loss:  0.39002556  || Decoder Loss:  0.055467788 Validation Decoder Loss:  0.36152065
Encoder Loss:  0.38849375  || Decoder Loss:  0.05565436 Validation Decoder Loss:  0.3616361
Encoder Loss:  0.38681462  || Decoder Loss:  0.055864636 Validation Decoder Loss:  0.36172897
Encoder Loss:  0.3850439  || Decoder Loss:  0.056095626 Validation Decoder Loss:  0.36179265
Encoder Loss:  0.38320127  || Decoder Loss:  0.056348883 Validation Decoder Loss:  0.36182472
Encoder Loss:  0.38129523  || Decoder Loss:  0.056627683 Validation Decoder Loss:  0.36182395
Encoder Loss:  0.3793311  || Decoder Loss:  0.05693627 Validation Decoder Loss:  0.3617899
Encoder Loss:  0.37731245  || Decoder Loss:  0.057279788 Validation Decoder Loss:  0.36172268
Encoder Loss:  0.37524164  || Decoder Loss:  0.05766442 Validation Decoder Loss:  0.3616224
Encoder Loss:  0.37311968  || Decoder Loss:  0.058097526 Validation Decoder Loss:  0.36148947
Encoder Loss:  0.37094596  || Decoder Loss:  0.058588073 Validation Decoder Loss:  0.36132464
Encoder Loss:  0.36871803  || Decoder Loss:  0.059146997 Validation Decoder Loss:  0.36112928
Encoder Loss:  0.36643118  || Decoder Loss:  0.05978775 Validation Decoder Loss:  0.36090562
Encoder Loss:  0.36407754  || Decoder Loss:  0.06052731 Validation Decoder Loss:  0.36065704
Encoder Loss:  0.36164558  || Decoder Loss:  0.0613872 Validation Decoder Loss:  0.36038893
Encoder Loss:  0.35911897  || Decoder Loss:  0.06239524 Validation Decoder Loss:  0.36010957
Encoder Loss:  0.35647452  || Decoder Loss:  0.06358804 Validation Decoder Loss:  0.3598322
Encoder Loss:  0.35367972  || Decoder Loss:  0.06501464 Validation Decoder Loss:  0.3595776
Encoder Loss:  0.35068887  || Decoder Loss:  0.06674204 Validation Decoder Loss:  0.35937923
Encoder Loss:  0.34743622  || Decoder Loss:  0.068864174 Validation Decoder Loss:  0.3592919
Encoder Loss:  0.34382612  || Decoder Loss:  0.07151607 Validation Decoder Loss:  0.35940772
Encoder Loss:  0.33971533  || Decoder Loss:  0.07489806 Validation Decoder Loss:  0.35988587
Encoder Loss:  0.3348827  || Decoder Loss:  0.07931823 Validation Decoder Loss:  0.3610137
Encoder Loss:  0.32897398  || Decoder Loss:  0.08527077 Validation Decoder Loss:  0.36333472
Encoder Loss:  0.32139772  || Decoder Loss:  0.09358844 Validation Decoder Loss:  0.36794126
Encoder Loss:  0.31111938  || Decoder Loss:  0.10575775 Validation Decoder Loss:  0.37719765
Encoder Loss:  0.2962475  || Decoder Loss:  0.124612406 Validation Decoder Loss:  0.39669645
Encoder Loss:  0.27322218  || Decoder Loss:  0.15593682 Validation Decoder Loss:  0.44092318
Encoder Loss:  0.23554274  || Decoder Loss:  0.21209541 Validation Decoder Loss:  0.54747975
Encoder Loss:  0.17403334  || Decoder Loss:  0.31673437 Validation Decoder Loss:  0.76954305
Encoder Loss:  0.11417147  || Decoder Loss:  0.46423736 Validation Decoder Loss:  0.93087363
Encoder Loss:  0.12274229  || Decoder Loss:  0.48778167 Validation Decoder Loss:  0.8477582
Encoder Loss:  0.11199375  || Decoder Loss:  0.4417357 Validation Decoder Loss:  0.83020633
Encoder Loss:  0.11025209  || Decoder Loss:  0.4458196 Validation Decoder Loss:  0.8237721
Encoder Loss:  0.10978197  || Decoder Loss:  0.4305369 Validation Decoder Loss:  0.7821145
Encoder Loss:  0.10676905  || Decoder Loss:  0.3920925 Validation Decoder Loss:  0.65756917
Encoder Loss:  0.10126769  || Decoder Loss:  0.31607357 Validation Decoder Loss:  0.63652635
Encoder Loss:  0.09759987  || Decoder Loss:  0.26454878 Validation Decoder Loss:  0.5673573
Encoder Loss:  0.093611225  || Decoder Loss:  0.21104583 Validation Decoder Loss:  0.52601314
Model: siamese_net_lr_0.0005458036951055741 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.52601314
Model: "sequential_805"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_569 (Conv3D (None, 150, 9, 20, 1)     121       
_________________________________________________________________
dropout_1169 (Dropout)       (None, 150, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_570 (Conv3D (None, 220, 11, 20, 1)    214       
_________________________________________________________________
reshape_206 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 335
Trainable params: 335
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_807"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_391 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_1171 (Dropout)       (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_392 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_808"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_391 (Conv2D (None, 2450, 20, 1)       32        
_________________________________________________________________
dropout_1173 (Dropout)       (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_392 (Conv2D (None, 2607, 20, 1)       159       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08984627  || Decoder Loss:  0.08984627 Validation Decoder Loss:  0.3713379
Encoder Loss:  0.0897863  || Decoder Loss:  0.0897863 Validation Decoder Loss:  0.37257662
Encoder Loss:  0.08972144  || Decoder Loss:  0.08972144 Validation Decoder Loss:  0.37378073
Encoder Loss:  0.08965583  || Decoder Loss:  0.08965583 Validation Decoder Loss:  0.37492046
Encoder Loss:  0.08958762  || Decoder Loss:  0.08958762 Validation Decoder Loss:  0.37600553
Encoder Loss:  0.08951393  || Decoder Loss:  0.08951393 Validation Decoder Loss:  0.37705025
Encoder Loss:  0.08943029  || Decoder Loss:  0.08943029 Validation Decoder Loss:  0.37807444
Encoder Loss:  0.08932811  || Decoder Loss:  0.08932811 Validation Decoder Loss:  0.3791207
Encoder Loss:  0.08918582  || Decoder Loss:  0.08918582 Validation Decoder Loss:  0.38032165
Encoder Loss:  0.08891856  || Decoder Loss:  0.08891856 Validation Decoder Loss:  0.38248965
Encoder Loss:  0.08722611  || Decoder Loss:  0.08722611 Validation Decoder Loss:  0.43529537
Encoder Loss:  0.08181497  || Decoder Loss:  0.08181497 Validation Decoder Loss:  0.45504615
Encoder Loss:  0.07323402  || Decoder Loss:  0.07323402 Validation Decoder Loss:  0.4031241
Encoder Loss:  0.078933224  || Decoder Loss:  0.078933224 Validation Decoder Loss:  0.38995463
Encoder Loss:  0.064856485  || Decoder Loss:  0.064856485 Validation Decoder Loss:  0.48739046
Encoder Loss:  0.055821996  || Decoder Loss:  0.055821996 Validation Decoder Loss:  0.45138642
Encoder Loss:  0.050030295  || Decoder Loss:  0.050030295 Validation Decoder Loss:  0.43314716
Encoder Loss:  0.04461108  || Decoder Loss:  0.04461108 Validation Decoder Loss:  0.4151215
Encoder Loss:  0.040307876  || Decoder Loss:  0.040307876 Validation Decoder Loss:  0.3965267
Encoder Loss:  0.03764404  || Decoder Loss:  0.03764404 Validation Decoder Loss:  0.38022
Encoder Loss:  0.03636244  || Decoder Loss:  0.03636244 Validation Decoder Loss:  0.36888772
Encoder Loss:  0.035841193  || Decoder Loss:  0.035841193 Validation Decoder Loss:  0.3618778
Encoder Loss:  0.035653766  || Decoder Loss:  0.035653766 Validation Decoder Loss:  0.35836458
Encoder Loss:  0.03557731  || Decoder Loss:  0.03557731 Validation Decoder Loss:  0.3562263
Encoder Loss:  0.03554324  || Decoder Loss:  0.03554324 Validation Decoder Loss:  0.35492498
Encoder Loss:  0.03552477  || Decoder Loss:  0.03552477 Validation Decoder Loss:  0.35402268
Encoder Loss:  0.035512164  || Decoder Loss:  0.035512164 Validation Decoder Loss:  0.3533313
Encoder Loss:  0.035499178  || Decoder Loss:  0.035499178 Validation Decoder Loss:  0.35290533
Encoder Loss:  0.035484843  || Decoder Loss:  0.035484843 Validation Decoder Loss:  0.3527961
Encoder Loss:  0.03546876  || Decoder Loss:  0.03546876 Validation Decoder Loss:  0.35284764
Encoder Loss:  0.035451844  || Decoder Loss:  0.035451844 Validation Decoder Loss:  0.3528973
Encoder Loss:  0.035435352  || Decoder Loss:  0.035435352 Validation Decoder Loss:  0.35290536
Encoder Loss:  0.035419572  || Decoder Loss:  0.035419572 Validation Decoder Loss:  0.35289356
Encoder Loss:  0.0354043  || Decoder Loss:  0.0354043 Validation Decoder Loss:  0.3528772
Encoder Loss:  0.035389345  || Decoder Loss:  0.035389345 Validation Decoder Loss:  0.35286182
Encoder Loss:  0.03537456  || Decoder Loss:  0.03537456 Validation Decoder Loss:  0.35284442
Encoder Loss:  0.035359923  || Decoder Loss:  0.035359923 Validation Decoder Loss:  0.35282153
Encoder Loss:  0.035345398  || Decoder Loss:  0.035345398 Validation Decoder Loss:  0.3527943
Encoder Loss:  0.035330947  || Decoder Loss:  0.035330947 Validation Decoder Loss:  0.35276157
Encoder Loss:  0.035316538  || Decoder Loss:  0.035316538 Validation Decoder Loss:  0.35272184
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3527218
Model: "sequential_809"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_572 (Conv3D (None, 66, 10, 20, 1)     19        
_________________________________________________________________
dropout_1175 (Dropout)       (None, 66, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_573 (Conv3D (None, 220, 11, 20, 1)    311       
_________________________________________________________________
reshape_207 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 330
Trainable params: 330
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_811"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_393 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1177 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_394 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_812"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_393 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1179 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_394 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2260166  || Decoder Loss:  0.08830776 Validation Decoder Loss:  0.3535313
Encoder Loss:  0.05326325  || Decoder Loss:  0.04257348 Validation Decoder Loss:  0.34491193
Encoder Loss:  0.050565515  || Decoder Loss:  0.036992326 Validation Decoder Loss:  0.33364695
Encoder Loss:  0.050483402  || Decoder Loss:  0.03310271 Validation Decoder Loss:  0.33255586
Encoder Loss:  0.05027579  || Decoder Loss:  0.032619275 Validation Decoder Loss:  0.33272555
Encoder Loss:  0.05020504  || Decoder Loss:  0.032225844 Validation Decoder Loss:  0.3346277
Encoder Loss:  0.050144576  || Decoder Loss:  0.032077312 Validation Decoder Loss:  0.3355241
Encoder Loss:  0.05013347  || Decoder Loss:  0.032009155 Validation Decoder Loss:  0.33591264
Encoder Loss:  0.050133467  || Decoder Loss:  0.031967305 Validation Decoder Loss:  0.33625916
Encoder Loss:  0.05013962  || Decoder Loss:  0.031936698 Validation Decoder Loss:  0.33344448
Encoder Loss:  0.05012924  || Decoder Loss:  0.031903096 Validation Decoder Loss:  0.33344543
Encoder Loss:  0.050161824  || Decoder Loss:  0.031900987 Validation Decoder Loss:  0.33443892
Encoder Loss:  0.05012967  || Decoder Loss:  0.03189576 Validation Decoder Loss:  0.334742
Encoder Loss:  0.05014055  || Decoder Loss:  0.03187862 Validation Decoder Loss:  0.33458963
Encoder Loss:  0.05015101  || Decoder Loss:  0.03191357 Validation Decoder Loss:  0.33503
Encoder Loss:  0.050122432  || Decoder Loss:  0.031901263 Validation Decoder Loss:  0.33455974
Encoder Loss:  0.050137572  || Decoder Loss:  0.03191195 Validation Decoder Loss:  0.33449084
Encoder Loss:  0.050111596  || Decoder Loss:  0.031931173 Validation Decoder Loss:  0.33406952
Encoder Loss:  0.05011953  || Decoder Loss:  0.031964786 Validation Decoder Loss:  0.33374506
Encoder Loss:  0.050132394  || Decoder Loss:  0.031985085 Validation Decoder Loss:  0.33396086
Encoder Loss:  0.050139718  || Decoder Loss:  0.03200469 Validation Decoder Loss:  0.33341414
Encoder Loss:  0.050121803  || Decoder Loss:  0.03202632 Validation Decoder Loss:  0.33364403
Encoder Loss:  0.050131112  || Decoder Loss:  0.032068823 Validation Decoder Loss:  0.3334939
Encoder Loss:  0.050117966  || Decoder Loss:  0.03209281 Validation Decoder Loss:  0.33387005
Encoder Loss:  0.050094213  || Decoder Loss:  0.032118972 Validation Decoder Loss:  0.33385575
Encoder Loss:  0.050114665  || Decoder Loss:  0.032158554 Validation Decoder Loss:  0.3339073
Encoder Loss:  0.050127793  || Decoder Loss:  0.032182544 Validation Decoder Loss:  0.3339032
Encoder Loss:  0.050119318  || Decoder Loss:  0.032213937 Validation Decoder Loss:  0.3340156
Encoder Loss:  0.050113462  || Decoder Loss:  0.03226038 Validation Decoder Loss:  0.33396578
Encoder Loss:  0.05011363  || Decoder Loss:  0.03228071 Validation Decoder Loss:  0.33395234
Encoder Loss:  0.05011352  || Decoder Loss:  0.0323198 Validation Decoder Loss:  0.33405244
Encoder Loss:  0.050089885  || Decoder Loss:  0.03237076 Validation Decoder Loss:  0.3341604
Encoder Loss:  0.050095897  || Decoder Loss:  0.03239988 Validation Decoder Loss:  0.33438605
Encoder Loss:  0.050113786  || Decoder Loss:  0.03242122 Validation Decoder Loss:  0.33462107
Encoder Loss:  0.050126772  || Decoder Loss:  0.0324575 Validation Decoder Loss:  0.33445528
Encoder Loss:  0.050131112  || Decoder Loss:  0.03250238 Validation Decoder Loss:  0.33537918
Encoder Loss:  0.050081342  || Decoder Loss:  0.032531872 Validation Decoder Loss:  0.33555633
Encoder Loss:  0.05008991  || Decoder Loss:  0.03256516 Validation Decoder Loss:  0.33562762
Encoder Loss:  0.050079178  || Decoder Loss:  0.032603424 Validation Decoder Loss:  0.33578292
Encoder Loss:  0.05013246  || Decoder Loss:  0.03262862 Validation Decoder Loss:  0.33595967
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33595964
Model: "sequential_813"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_575 (Conv3D (None, 188, 5, 20, 1)     63        
_________________________________________________________________
dropout_1181 (Dropout)       (None, 188, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_576 (Conv3D (None, 220, 11, 20, 1)    100       
_________________________________________________________________
reshape_208 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 163
Trainable params: 163
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_815"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_395 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1183 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_396 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_816"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_395 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1185 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_396 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.069308944  || Decoder Loss:  0.059925858 Validation Decoder Loss:  0.3650431
Encoder Loss:  0.069220304  || Decoder Loss:  0.059902087 Validation Decoder Loss:  0.36560887
Encoder Loss:  0.06910224  || Decoder Loss:  0.059865575 Validation Decoder Loss:  0.3662061
Encoder Loss:  0.068956584  || Decoder Loss:  0.0598105 Validation Decoder Loss:  0.3667773
Encoder Loss:  0.068783656  || Decoder Loss:  0.059733465 Validation Decoder Loss:  0.36729425
Encoder Loss:  0.06858197  || Decoder Loss:  0.05963097 Validation Decoder Loss:  0.3677423
Encoder Loss:  0.06834855  || Decoder Loss:  0.059498727 Validation Decoder Loss:  0.36811247
Encoder Loss:  0.06807892  || Decoder Loss:  0.059331074 Validation Decoder Loss:  0.36839724
Encoder Loss:  0.06776635  || Decoder Loss:  0.059120294 Validation Decoder Loss:  0.3685876
Encoder Loss:  0.06740096  || Decoder Loss:  0.05885551 Validation Decoder Loss:  0.36867124
Encoder Loss:  0.06696801  || Decoder Loss:  0.058521114 Validation Decoder Loss:  0.36862904
Encoder Loss:  0.066445015  || Decoder Loss:  0.05809359 Validation Decoder Loss:  0.36842978
Encoder Loss:  0.06579637  || Decoder Loss:  0.057536088 Validation Decoder Loss:  0.36802027
Encoder Loss:  0.064962715  || Decoder Loss:  0.0567875 Validation Decoder Loss:  0.36730736
Encoder Loss:  0.06383819  || Decoder Loss:  0.055738933 Validation Decoder Loss:  0.3661182
Encoder Loss:  0.06221509  || Decoder Loss:  0.05417703 Validation Decoder Loss:  0.36410248
Encoder Loss:  0.059630774  || Decoder Loss:  0.051626496 Validation Decoder Loss:  0.36047453
Encoder Loss:  0.054895654  || Decoder Loss:  0.046865113 Validation Decoder Loss:  0.35369992
Encoder Loss:  0.047650456  || Decoder Loss:  0.039523974 Validation Decoder Loss:  0.35435992
Encoder Loss:  0.0457966  || Decoder Loss:  0.03772268 Validation Decoder Loss:  0.34648198
Encoder Loss:  0.04535354  || Decoder Loss:  0.037371393 Validation Decoder Loss:  0.34611276
Encoder Loss:  0.045047723  || Decoder Loss:  0.03716202 Validation Decoder Loss:  0.34371153
Encoder Loss:  0.044856265  || Decoder Loss:  0.037071828 Validation Decoder Loss:  0.343324
Encoder Loss:  0.044674378  || Decoder Loss:  0.036994226 Validation Decoder Loss:  0.3426488
Encoder Loss:  0.044510268  || Decoder Loss:  0.036939275 Validation Decoder Loss:  0.34251696
Encoder Loss:  0.04434359  || Decoder Loss:  0.036888685 Validation Decoder Loss:  0.34239078
Encoder Loss:  0.04417264  || Decoder Loss:  0.03684542 Validation Decoder Loss:  0.34238136
Encoder Loss:  0.043983933  || Decoder Loss:  0.036805954 Validation Decoder Loss:  0.34240887
Encoder Loss:  0.043748192  || Decoder Loss:  0.03677029 Validation Decoder Loss:  0.34244788
Encoder Loss:  0.04333541  || Decoder Loss:  0.036738742 Validation Decoder Loss:  0.3425122
Encoder Loss:  0.041697357  || Decoder Loss:  0.036711045 Validation Decoder Loss:  0.34258816
Encoder Loss:  0.03797545  || Decoder Loss:  0.0366819 Validation Decoder Loss:  0.34268
Encoder Loss:  0.03743442  || Decoder Loss:  0.03664171 Validation Decoder Loss:  0.34267688
Encoder Loss:  0.037214592  || Decoder Loss:  0.036594175 Validation Decoder Loss:  0.3426056
Encoder Loss:  0.037048128  || Decoder Loss:  0.036542498 Validation Decoder Loss:  0.34253323
Encoder Loss:  0.036972865  || Decoder Loss:  0.036486678 Validation Decoder Loss:  0.34245014
Encoder Loss:  0.03690487  || Decoder Loss:  0.03642737 Validation Decoder Loss:  0.3423492
Encoder Loss:  0.0368562  || Decoder Loss:  0.036364987 Validation Decoder Loss:  0.34223706
Encoder Loss:  0.03680359  || Decoder Loss:  0.036299832 Validation Decoder Loss:  0.3421179
Encoder Loss:  0.036734432  || Decoder Loss:  0.036231674 Validation Decoder Loss:  0.3419891
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3419891
Model: "sequential_817"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_578 (Conv3D (None, 210, 6, 20, 1)     169       
_________________________________________________________________
dropout_1187 (Dropout)       (None, 210, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_579 (Conv3D (None, 220, 11, 20, 1)    67        
_________________________________________________________________
reshape_209 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 236
Trainable params: 236
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_819"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_397 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_1189 (Dropout)       (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_398 (Conv2D)          (None, 2420, 20, 1)       82        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_820"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_397 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1191 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_398 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.050037604  || Decoder Loss:  0.050037604 Validation Decoder Loss:  0.35410777
Encoder Loss:  0.04988752  || Decoder Loss:  0.04988752 Validation Decoder Loss:  0.35469317
Encoder Loss:  0.049727216  || Decoder Loss:  0.049727216 Validation Decoder Loss:  0.3550154
Encoder Loss:  0.04955014  || Decoder Loss:  0.04955014 Validation Decoder Loss:  0.35519713
Encoder Loss:  0.04934157  || Decoder Loss:  0.04934157 Validation Decoder Loss:  0.35529932
Encoder Loss:  0.049071398  || Decoder Loss:  0.049071398 Validation Decoder Loss:  0.35539293
Encoder Loss:  0.048621215  || Decoder Loss:  0.048621215 Validation Decoder Loss:  0.36058414
Encoder Loss:  0.04766865  || Decoder Loss:  0.04766865 Validation Decoder Loss:  0.3636911
Encoder Loss:  0.046323627  || Decoder Loss:  0.046323627 Validation Decoder Loss:  0.3638128
Encoder Loss:  0.043880433  || Decoder Loss:  0.043880433 Validation Decoder Loss:  0.3600638
Encoder Loss:  0.04111053  || Decoder Loss:  0.04111053 Validation Decoder Loss:  0.35914472
Encoder Loss:  0.038742956  || Decoder Loss:  0.038742956 Validation Decoder Loss:  0.3516477
Encoder Loss:  0.037312057  || Decoder Loss:  0.037312057 Validation Decoder Loss:  0.34804136
Encoder Loss:  0.036343936  || Decoder Loss:  0.036343936 Validation Decoder Loss:  0.3434416
Encoder Loss:  0.03581111  || Decoder Loss:  0.03581111 Validation Decoder Loss:  0.34136662
Encoder Loss:  0.035482004  || Decoder Loss:  0.035482004 Validation Decoder Loss:  0.3394183
Encoder Loss:  0.035295602  || Decoder Loss:  0.035295602 Validation Decoder Loss:  0.3376829
Encoder Loss:  0.035175644  || Decoder Loss:  0.035175644 Validation Decoder Loss:  0.33660263
Encoder Loss:  0.035088032  || Decoder Loss:  0.035088032 Validation Decoder Loss:  0.33564454
Encoder Loss:  0.03503443  || Decoder Loss:  0.03503443 Validation Decoder Loss:  0.33492792
Encoder Loss:  0.0349965  || Decoder Loss:  0.0349965 Validation Decoder Loss:  0.33438432
Encoder Loss:  0.034967773  || Decoder Loss:  0.034967773 Validation Decoder Loss:  0.3339737
Encoder Loss:  0.03494488  || Decoder Loss:  0.03494488 Validation Decoder Loss:  0.33366507
Encoder Loss:  0.034925748  || Decoder Loss:  0.034925748 Validation Decoder Loss:  0.3334344
Encoder Loss:  0.034909096  || Decoder Loss:  0.034909096 Validation Decoder Loss:  0.3332629
Encoder Loss:  0.034894176  || Decoder Loss:  0.034894176 Validation Decoder Loss:  0.3331362
Encoder Loss:  0.034880508  || Decoder Loss:  0.034880508 Validation Decoder Loss:  0.3330437
Encoder Loss:  0.034867812  || Decoder Loss:  0.034867812 Validation Decoder Loss:  0.332976
Encoder Loss:  0.03485581  || Decoder Loss:  0.03485581 Validation Decoder Loss:  0.3329272
Encoder Loss:  0.034844317  || Decoder Loss:  0.034844317 Validation Decoder Loss:  0.3328936
Encoder Loss:  0.034833495  || Decoder Loss:  0.034833495 Validation Decoder Loss:  0.33286992
Encoder Loss:  0.034823183  || Decoder Loss:  0.034823183 Validation Decoder Loss:  0.33285594
Encoder Loss:  0.034813102  || Decoder Loss:  0.034813102 Validation Decoder Loss:  0.33284804
Encoder Loss:  0.034803256  || Decoder Loss:  0.034803256 Validation Decoder Loss:  0.3328467
Encoder Loss:  0.034793936  || Decoder Loss:  0.034793936 Validation Decoder Loss:  0.33284628
Encoder Loss:  0.034784734  || Decoder Loss:  0.034784734 Validation Decoder Loss:  0.3328533
Encoder Loss:  0.03477619  || Decoder Loss:  0.03477619 Validation Decoder Loss:  0.3328557
Encoder Loss:  0.03476774  || Decoder Loss:  0.03476774 Validation Decoder Loss:  0.3328684
Encoder Loss:  0.034759175  || Decoder Loss:  0.034759175 Validation Decoder Loss:  0.33287647
Encoder Loss:  0.034751453  || Decoder Loss:  0.034751453 Validation Decoder Loss:  0.33289006
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33289006
Model: "sequential_821"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_581 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_1193 (Dropout)       (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_582 (Conv3D (None, 220, 11, 20, 1)    946       
_________________________________________________________________
reshape_210 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 970
Trainable params: 970
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_823"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_399 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1195 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_400 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_824"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_399 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1197 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_400 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09412599  || Decoder Loss:  0.09412599 Validation Decoder Loss:  0.37112755
Encoder Loss:  0.09381175  || Decoder Loss:  0.09381175 Validation Decoder Loss:  0.37170517
Encoder Loss:  0.09340307  || Decoder Loss:  0.09340307 Validation Decoder Loss:  0.37215006
Encoder Loss:  0.09288574  || Decoder Loss:  0.09288574 Validation Decoder Loss:  0.3724016
Encoder Loss:  0.09219491  || Decoder Loss:  0.09219491 Validation Decoder Loss:  0.37238583
Encoder Loss:  0.09119014  || Decoder Loss:  0.09119014 Validation Decoder Loss:  0.37193155
Encoder Loss:  0.08951094  || Decoder Loss:  0.08951094 Validation Decoder Loss:  0.37052763
Encoder Loss:  0.08582196  || Decoder Loss:  0.08582196 Validation Decoder Loss:  0.36582378
Encoder Loss:  0.067210265  || Decoder Loss:  0.067210265 Validation Decoder Loss:  0.38889325
Encoder Loss:  0.039498284  || Decoder Loss:  0.039498284 Validation Decoder Loss:  0.34917197
Encoder Loss:  0.037859306  || Decoder Loss:  0.037859306 Validation Decoder Loss:  0.34815425
Encoder Loss:  0.037572622  || Decoder Loss:  0.037572622 Validation Decoder Loss:  0.34767163
Encoder Loss:  0.037445158  || Decoder Loss:  0.037445158 Validation Decoder Loss:  0.34656495
Encoder Loss:  0.037347604  || Decoder Loss:  0.037347604 Validation Decoder Loss:  0.34645587
Encoder Loss:  0.03725995  || Decoder Loss:  0.03725995 Validation Decoder Loss:  0.34628662
Encoder Loss:  0.037174806  || Decoder Loss:  0.037174806 Validation Decoder Loss:  0.34618595
Encoder Loss:  0.037087087  || Decoder Loss:  0.037087087 Validation Decoder Loss:  0.34607136
Encoder Loss:  0.036994506  || Decoder Loss:  0.036994506 Validation Decoder Loss:  0.34594828
Encoder Loss:  0.03689531  || Decoder Loss:  0.03689531 Validation Decoder Loss:  0.34580225
Encoder Loss:  0.036787637  || Decoder Loss:  0.036787637 Validation Decoder Loss:  0.34562534
Encoder Loss:  0.036669303  || Decoder Loss:  0.036669303 Validation Decoder Loss:  0.34541
Encoder Loss:  0.03653795  || Decoder Loss:  0.03653795 Validation Decoder Loss:  0.34514713
Encoder Loss:  0.036391433  || Decoder Loss:  0.036391433 Validation Decoder Loss:  0.34482634
Encoder Loss:  0.036228966  || Decoder Loss:  0.036228966 Validation Decoder Loss:  0.3444398
Encoder Loss:  0.03605281  || Decoder Loss:  0.03605281 Validation Decoder Loss:  0.34399277
Encoder Loss:  0.03586913  || Decoder Loss:  0.03586913 Validation Decoder Loss:  0.3435184
Encoder Loss:  0.035683952  || Decoder Loss:  0.035683952 Validation Decoder Loss:  0.3430688
Encoder Loss:  0.03549515  || Decoder Loss:  0.03549515 Validation Decoder Loss:  0.34264743
Encoder Loss:  0.035292204  || Decoder Loss:  0.035292204 Validation Decoder Loss:  0.34217286
Encoder Loss:  0.03506423  || Decoder Loss:  0.03506423 Validation Decoder Loss:  0.34154692
Encoder Loss:  0.03480562  || Decoder Loss:  0.03480562 Validation Decoder Loss:  0.34070337
Encoder Loss:  0.03451929  || Decoder Loss:  0.03451929 Validation Decoder Loss:  0.33960968
Encoder Loss:  0.03422082  || Decoder Loss:  0.03422082 Validation Decoder Loss:  0.33830112
Encoder Loss:  0.033940442  || Decoder Loss:  0.033940442 Validation Decoder Loss:  0.3369349
Encoder Loss:  0.03371144  || Decoder Loss:  0.03371144 Validation Decoder Loss:  0.33576488
Encoder Loss:  0.033547204  || Decoder Loss:  0.033547204 Validation Decoder Loss:  0.33492637
Encoder Loss:  0.033436175  || Decoder Loss:  0.033436175 Validation Decoder Loss:  0.33438787
Encoder Loss:  0.03335987  || Decoder Loss:  0.03335987 Validation Decoder Loss:  0.33404422
Encoder Loss:  0.033305064  || Decoder Loss:  0.033305064 Validation Decoder Loss:  0.3338135
Encoder Loss:  0.033263925  || Decoder Loss:  0.033263925 Validation Decoder Loss:  0.3336507
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3336507
Model: "sequential_825"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_584 (Conv3D (None, 212, 10, 20, 1)    517       
_________________________________________________________________
dropout_1199 (Dropout)       (None, 212, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_585 (Conv3D (None, 220, 11, 20, 1)    19        
_________________________________________________________________
reshape_211 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 536
Trainable params: 536
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_827"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_401 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_1201 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_402 (Conv2D)          (None, 2420, 20, 1)       122       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_828"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_401 (Conv2D (None, 2510, 20, 1)       92        
_________________________________________________________________
dropout_1203 (Dropout)       (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_402 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.046234235  || Decoder Loss:  0.046234235 Validation Decoder Loss:  0.33664316
Encoder Loss:  0.03605626  || Decoder Loss:  0.03605626 Validation Decoder Loss:  0.3350966
Encoder Loss:  0.034429394  || Decoder Loss:  0.034429394 Validation Decoder Loss:  0.33573365
Encoder Loss:  0.03411628  || Decoder Loss:  0.03411628 Validation Decoder Loss:  0.33555835
Encoder Loss:  0.03392635  || Decoder Loss:  0.03392635 Validation Decoder Loss:  0.33520746
Encoder Loss:  0.03377914  || Decoder Loss:  0.03377914 Validation Decoder Loss:  0.33490852
Encoder Loss:  0.033670735  || Decoder Loss:  0.033670735 Validation Decoder Loss:  0.3347546
Encoder Loss:  0.03359256  || Decoder Loss:  0.03359256 Validation Decoder Loss:  0.33482504
Encoder Loss:  0.033531748  || Decoder Loss:  0.033531748 Validation Decoder Loss:  0.33532146
Encoder Loss:  0.033480283  || Decoder Loss:  0.033480283 Validation Decoder Loss:  0.33581346
Encoder Loss:  0.033434413  || Decoder Loss:  0.033434413 Validation Decoder Loss:  0.33615947
Encoder Loss:  0.033392698  || Decoder Loss:  0.033392698 Validation Decoder Loss:  0.33620238
Encoder Loss:  0.03335406  || Decoder Loss:  0.03335406 Validation Decoder Loss:  0.3361451
Encoder Loss:  0.03331748  || Decoder Loss:  0.03331748 Validation Decoder Loss:  0.3360844
Encoder Loss:  0.03328196  || Decoder Loss:  0.03328196 Validation Decoder Loss:  0.33604392
Encoder Loss:  0.033245385  || Decoder Loss:  0.033245385 Validation Decoder Loss:  0.33596483
Encoder Loss:  0.03320462  || Decoder Loss:  0.03320462 Validation Decoder Loss:  0.3357659
Encoder Loss:  0.03315243  || Decoder Loss:  0.03315243 Validation Decoder Loss:  0.33538607
Encoder Loss:  0.033065747  || Decoder Loss:  0.033065747 Validation Decoder Loss:  0.3349812
Encoder Loss:  0.032952257  || Decoder Loss:  0.032952257 Validation Decoder Loss:  0.33479577
Encoder Loss:  0.032880105  || Decoder Loss:  0.032880105 Validation Decoder Loss:  0.33467072
Encoder Loss:  0.032833215  || Decoder Loss:  0.032833215 Validation Decoder Loss:  0.33459437
Encoder Loss:  0.032795876  || Decoder Loss:  0.032795876 Validation Decoder Loss:  0.33454728
Encoder Loss:  0.03276406  || Decoder Loss:  0.03276406 Validation Decoder Loss:  0.33451694
Encoder Loss:  0.03273597  || Decoder Loss:  0.03273597 Validation Decoder Loss:  0.33450174
Encoder Loss:  0.03271025  || Decoder Loss:  0.03271025 Validation Decoder Loss:  0.33456954
Encoder Loss:  0.03268677  || Decoder Loss:  0.03268677 Validation Decoder Loss:  0.33468014
Encoder Loss:  0.032665204  || Decoder Loss:  0.032665204 Validation Decoder Loss:  0.33479413
Encoder Loss:  0.032645643  || Decoder Loss:  0.032645643 Validation Decoder Loss:  0.33491138
Encoder Loss:  0.03262827  || Decoder Loss:  0.03262827 Validation Decoder Loss:  0.33502984
Encoder Loss:  0.03261308  || Decoder Loss:  0.03261308 Validation Decoder Loss:  0.33514595
Encoder Loss:  0.032599684  || Decoder Loss:  0.032599684 Validation Decoder Loss:  0.33525538
Encoder Loss:  0.032587703  || Decoder Loss:  0.032587703 Validation Decoder Loss:  0.33535576
Encoder Loss:  0.032576844  || Decoder Loss:  0.032576844 Validation Decoder Loss:  0.33544648
Encoder Loss:  0.03256691  || Decoder Loss:  0.03256691 Validation Decoder Loss:  0.3355279
Encoder Loss:  0.03255775  || Decoder Loss:  0.03255775 Validation Decoder Loss:  0.33560073
Encoder Loss:  0.03254927  || Decoder Loss:  0.03254927 Validation Decoder Loss:  0.33566564
Encoder Loss:  0.032541353  || Decoder Loss:  0.032541353 Validation Decoder Loss:  0.33572364
Encoder Loss:  0.032533973  || Decoder Loss:  0.032533973 Validation Decoder Loss:  0.33577526
Encoder Loss:  0.03252707  || Decoder Loss:  0.03252707 Validation Decoder Loss:  0.33582118
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3358212
Model: "sequential_829"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_587 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_1205 (Dropout)       (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_588 (Conv3D (None, 220, 11, 20, 1)    239       
_________________________________________________________________
reshape_212 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 271
Trainable params: 271
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_831"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_403 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_1207 (Dropout)       (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_404 (Conv2D)          (None, 2420, 20, 1)       42        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_832"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_403 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1209 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_404 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07585579  || Decoder Loss:  0.0554811 Validation Decoder Loss:  0.34762838
Encoder Loss:  0.054657478  || Decoder Loss:  0.03691547 Validation Decoder Loss:  0.341779
Encoder Loss:  0.03749503  || Decoder Loss:  0.036208905 Validation Decoder Loss:  0.34096467
Encoder Loss:  0.036478516  || Decoder Loss:  0.035481595 Validation Decoder Loss:  0.33919722
Encoder Loss:  0.035602465  || Decoder Loss:  0.034622043 Validation Decoder Loss:  0.3356514
Encoder Loss:  0.03483943  || Decoder Loss:  0.03383067 Validation Decoder Loss:  0.33229226
Encoder Loss:  0.03467089  || Decoder Loss:  0.03365216 Validation Decoder Loss:  0.33198142
Encoder Loss:  0.034619268  || Decoder Loss:  0.03359725 Validation Decoder Loss:  0.33201224
Encoder Loss:  0.034572873  || Decoder Loss:  0.033548497 Validation Decoder Loss:  0.33206433
Encoder Loss:  0.034527604  || Decoder Loss:  0.033501256 Validation Decoder Loss:  0.3320427
Encoder Loss:  0.034485  || Decoder Loss:  0.033456527 Validation Decoder Loss:  0.33189768
Encoder Loss:  0.034443658  || Decoder Loss:  0.03341251 Validation Decoder Loss:  0.33173725
Encoder Loss:  0.034402214  || Decoder Loss:  0.03336837 Validation Decoder Loss:  0.3315494
Encoder Loss:  0.03436269  || Decoder Loss:  0.033326127 Validation Decoder Loss:  0.33136424
Encoder Loss:  0.034326658  || Decoder Loss:  0.03328768 Validation Decoder Loss:  0.33121222
Encoder Loss:  0.03429513  || Decoder Loss:  0.03325421 Validation Decoder Loss:  0.33110505
Encoder Loss:  0.034268595  || Decoder Loss:  0.03322572 Validation Decoder Loss:  0.33102793
Encoder Loss:  0.0342456  || Decoder Loss:  0.033201315 Validation Decoder Loss:  0.3309843
Encoder Loss:  0.034225803  || Decoder Loss:  0.033180136 Validation Decoder Loss:  0.33096284
Encoder Loss:  0.034208003  || Decoder Loss:  0.03316108 Validation Decoder Loss:  0.3309291
Encoder Loss:  0.034192022  || Decoder Loss:  0.033144034 Validation Decoder Loss:  0.33091182
Encoder Loss:  0.0341768  || Decoder Loss:  0.0331278 Validation Decoder Loss:  0.33089754
Encoder Loss:  0.0341623  || Decoder Loss:  0.03311264 Validation Decoder Loss:  0.33086362
Encoder Loss:  0.034149718  || Decoder Loss:  0.033098426 Validation Decoder Loss:  0.3308464
Encoder Loss:  0.03413598  || Decoder Loss:  0.033084515 Validation Decoder Loss:  0.33082026
Encoder Loss:  0.03412408  || Decoder Loss:  0.033071164 Validation Decoder Loss:  0.3308038
Encoder Loss:  0.034111686  || Decoder Loss:  0.033058215 Validation Decoder Loss:  0.33079314
Encoder Loss:  0.034099627  || Decoder Loss:  0.033045698 Validation Decoder Loss:  0.33077472
Encoder Loss:  0.03408816  || Decoder Loss:  0.033033423 Validation Decoder Loss:  0.3307608
Encoder Loss:  0.03407724  || Decoder Loss:  0.033021607 Validation Decoder Loss:  0.33074087
Encoder Loss:  0.034066398  || Decoder Loss:  0.0330103 Validation Decoder Loss:  0.33072674
Encoder Loss:  0.03405618  || Decoder Loss:  0.03299934 Validation Decoder Loss:  0.33071214
Encoder Loss:  0.03404646  || Decoder Loss:  0.032988798 Validation Decoder Loss:  0.33069637
Encoder Loss:  0.034036756  || Decoder Loss:  0.032978445 Validation Decoder Loss:  0.3306819
Encoder Loss:  0.034026984  || Decoder Loss:  0.03296834 Validation Decoder Loss:  0.33067474
Encoder Loss:  0.034018785  || Decoder Loss:  0.032958835 Validation Decoder Loss:  0.33066273
Encoder Loss:  0.034009267  || Decoder Loss:  0.032949425 Validation Decoder Loss:  0.3306569
Encoder Loss:  0.034000672  || Decoder Loss:  0.032940213 Validation Decoder Loss:  0.33064884
Encoder Loss:  0.03399287  || Decoder Loss:  0.03293163 Validation Decoder Loss:  0.33063948
Encoder Loss:  0.033984553  || Decoder Loss:  0.0329231 Validation Decoder Loss:  0.33063215
Model: siamese_net_lr_0.0003104621436890182 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33063215
Model: "sequential_833"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_590 (Conv3D (None, 102, 10, 20, 1)    235       
_________________________________________________________________
dropout_1211 (Dropout)       (None, 102, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_591 (Conv3D (None, 220, 11, 20, 1)    37        
_________________________________________________________________
reshape_213 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 272
Trainable params: 272
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_835"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_405 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1213 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_406 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_836"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_405 (Conv2D (None, 2440, 20, 1)       22        
_________________________________________________________________
dropout_1215 (Dropout)       (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_406 (Conv2D (None, 2607, 20, 1)       169       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32649413  || Decoder Loss:  0.057385135 Validation Decoder Loss:  0.3568894
Encoder Loss:  0.3236737  || Decoder Loss:  0.06006934 Validation Decoder Loss:  0.35780954
Encoder Loss:  0.318299  || Decoder Loss:  0.063788064 Validation Decoder Loss:  0.35822463
Encoder Loss:  0.30179265  || Decoder Loss:  0.067568086 Validation Decoder Loss:  0.35326678
Encoder Loss:  0.26562035  || Decoder Loss:  0.04279157 Validation Decoder Loss:  0.34344825
Encoder Loss:  0.21596201  || Decoder Loss:  0.037491284 Validation Decoder Loss:  0.3422673
Encoder Loss:  0.10007202  || Decoder Loss:  0.037221823 Validation Decoder Loss:  0.34174958
Encoder Loss:  0.06909294  || Decoder Loss:  0.037065323 Validation Decoder Loss:  0.34129888
Encoder Loss:  0.068434685  || Decoder Loss:  0.036945265 Validation Decoder Loss:  0.34117818
Encoder Loss:  0.06751356  || Decoder Loss:  0.036831234 Validation Decoder Loss:  0.34104827
Encoder Loss:  0.057146452  || Decoder Loss:  0.036704723 Validation Decoder Loss:  0.3408394
Encoder Loss:  0.048126575  || Decoder Loss:  0.036560163 Validation Decoder Loss:  0.34052002
Encoder Loss:  0.047664076  || Decoder Loss:  0.036379777 Validation Decoder Loss:  0.3400742
Encoder Loss:  0.047453795  || Decoder Loss:  0.036145274 Validation Decoder Loss:  0.33936942
Encoder Loss:  0.047226552  || Decoder Loss:  0.035828616 Validation Decoder Loss:  0.3382575
Encoder Loss:  0.04691279  || Decoder Loss:  0.035409633 Validation Decoder Loss:  0.33670968
Encoder Loss:  0.046720505  || Decoder Loss:  0.034922194 Validation Decoder Loss:  0.33510697
Encoder Loss:  0.046602562  || Decoder Loss:  0.034432948 Validation Decoder Loss:  0.3335567
Encoder Loss:  0.0463009  || Decoder Loss:  0.034016374 Validation Decoder Loss:  0.3324346
Encoder Loss:  0.046290927  || Decoder Loss:  0.033738166 Validation Decoder Loss:  0.3317246
Encoder Loss:  0.04615756  || Decoder Loss:  0.033578686 Validation Decoder Loss:  0.33124825
Encoder Loss:  0.04597116  || Decoder Loss:  0.033486713 Validation Decoder Loss:  0.33094975
Encoder Loss:  0.04595254  || Decoder Loss:  0.033428784 Validation Decoder Loss:  0.3307601
Encoder Loss:  0.045853876  || Decoder Loss:  0.033388603 Validation Decoder Loss:  0.33064258
Encoder Loss:  0.04580533  || Decoder Loss:  0.033358205 Validation Decoder Loss:  0.3305722
Encoder Loss:  0.04578786  || Decoder Loss:  0.03333392 Validation Decoder Loss:  0.33052433
Encoder Loss:  0.0457702  || Decoder Loss:  0.03331374 Validation Decoder Loss:  0.33048636
Encoder Loss:  0.045739494  || Decoder Loss:  0.03329624 Validation Decoder Loss:  0.3304543
Encoder Loss:  0.045723155  || Decoder Loss:  0.033280533 Validation Decoder Loss:  0.33042765
Encoder Loss:  0.045707904  || Decoder Loss:  0.033266064 Validation Decoder Loss:  0.33040684
Encoder Loss:  0.045723025  || Decoder Loss:  0.033252582 Validation Decoder Loss:  0.33038676
Encoder Loss:  0.045708343  || Decoder Loss:  0.033239894 Validation Decoder Loss:  0.33036768
Encoder Loss:  0.04569345  || Decoder Loss:  0.033227783 Validation Decoder Loss:  0.33034974
Encoder Loss:  0.045698643  || Decoder Loss:  0.033216096 Validation Decoder Loss:  0.3303322
Encoder Loss:  0.045691043  || Decoder Loss:  0.033204827 Validation Decoder Loss:  0.33031422
Encoder Loss:  0.04569468  || Decoder Loss:  0.033193935 Validation Decoder Loss:  0.33029628
Encoder Loss:  0.045678988  || Decoder Loss:  0.03318331 Validation Decoder Loss:  0.33027947
Encoder Loss:  0.04567805  || Decoder Loss:  0.033172864 Validation Decoder Loss:  0.33026308
Encoder Loss:  0.045671467  || Decoder Loss:  0.033162653 Validation Decoder Loss:  0.3302468
Encoder Loss:  0.045677572  || Decoder Loss:  0.03315261 Validation Decoder Loss:  0.3302304
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3302304
Model: "sequential_837"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_593 (Conv3D (None, 106, 10, 20, 1)    259       
_________________________________________________________________
dropout_1217 (Dropout)       (None, 106, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_594 (Conv3D (None, 220, 11, 20, 1)    231       
_________________________________________________________________
reshape_214 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_839"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_407 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_1219 (Dropout)       (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_408 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_840"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_407 (Conv2D (None, 2470, 20, 1)       52        
_________________________________________________________________
dropout_1221 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_408 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09865752  || Decoder Loss:  0.09865752 Validation Decoder Loss:  0.3719464
Encoder Loss:  0.03691822  || Decoder Loss:  0.03691822 Validation Decoder Loss:  0.35050792
Encoder Loss:  0.035791192  || Decoder Loss:  0.035791192 Validation Decoder Loss:  0.34968323
Encoder Loss:  0.035666518  || Decoder Loss:  0.035666518 Validation Decoder Loss:  0.34926137
Encoder Loss:  0.035547458  || Decoder Loss:  0.035547458 Validation Decoder Loss:  0.34889114
Encoder Loss:  0.035403725  || Decoder Loss:  0.035403725 Validation Decoder Loss:  0.3484834
Encoder Loss:  0.035219993  || Decoder Loss:  0.035219993 Validation Decoder Loss:  0.34789503
Encoder Loss:  0.034968827  || Decoder Loss:  0.034968827 Validation Decoder Loss:  0.3468793
Encoder Loss:  0.03461789  || Decoder Loss:  0.03461789 Validation Decoder Loss:  0.34519875
Encoder Loss:  0.034213446  || Decoder Loss:  0.034213446 Validation Decoder Loss:  0.3428136
Encoder Loss:  0.03391394  || Decoder Loss:  0.03391394 Validation Decoder Loss:  0.34104198
Encoder Loss:  0.03375425  || Decoder Loss:  0.03375425 Validation Decoder Loss:  0.34024018
Encoder Loss:  0.033666596  || Decoder Loss:  0.033666596 Validation Decoder Loss:  0.3398568
Encoder Loss:  0.03360676  || Decoder Loss:  0.03360676 Validation Decoder Loss:  0.3394531
Encoder Loss:  0.033557788  || Decoder Loss:  0.033557788 Validation Decoder Loss:  0.33903074
Encoder Loss:  0.03351362  || Decoder Loss:  0.03351362 Validation Decoder Loss:  0.3385873
Encoder Loss:  0.033472236  || Decoder Loss:  0.033472236 Validation Decoder Loss:  0.33811718
Encoder Loss:  0.03343304  || Decoder Loss:  0.03343304 Validation Decoder Loss:  0.33766174
Encoder Loss:  0.033395607  || Decoder Loss:  0.033395607 Validation Decoder Loss:  0.33726788
Encoder Loss:  0.03335962  || Decoder Loss:  0.03335962 Validation Decoder Loss:  0.33697337
Encoder Loss:  0.033324577  || Decoder Loss:  0.033324577 Validation Decoder Loss:  0.33675855
Encoder Loss:  0.033290062  || Decoder Loss:  0.033290062 Validation Decoder Loss:  0.33659428
Encoder Loss:  0.033255905  || Decoder Loss:  0.033255905 Validation Decoder Loss:  0.33647534
Encoder Loss:  0.033222154  || Decoder Loss:  0.033222154 Validation Decoder Loss:  0.33637
Encoder Loss:  0.033188622  || Decoder Loss:  0.033188622 Validation Decoder Loss:  0.3362409
Encoder Loss:  0.03315542  || Decoder Loss:  0.03315542 Validation Decoder Loss:  0.33608687
Encoder Loss:  0.033122763  || Decoder Loss:  0.033122763 Validation Decoder Loss:  0.3359454
Encoder Loss:  0.033090834  || Decoder Loss:  0.033090834 Validation Decoder Loss:  0.33583128
Encoder Loss:  0.033060107  || Decoder Loss:  0.033060107 Validation Decoder Loss:  0.33573246
Encoder Loss:  0.0330309  || Decoder Loss:  0.0330309 Validation Decoder Loss:  0.33568522
Encoder Loss:  0.033003155  || Decoder Loss:  0.033003155 Validation Decoder Loss:  0.33583286
Encoder Loss:  0.032977212  || Decoder Loss:  0.032977212 Validation Decoder Loss:  0.33612812
Encoder Loss:  0.03295325  || Decoder Loss:  0.03295325 Validation Decoder Loss:  0.33601737
Encoder Loss:  0.032931205  || Decoder Loss:  0.032931205 Validation Decoder Loss:  0.3357172
Encoder Loss:  0.032911696  || Decoder Loss:  0.032911696 Validation Decoder Loss:  0.33574232
Encoder Loss:  0.032931656  || Decoder Loss:  0.032931656 Validation Decoder Loss:  0.3317488
Encoder Loss:  0.032904137  || Decoder Loss:  0.032904137 Validation Decoder Loss:  0.332466
Encoder Loss:  0.032884143  || Decoder Loss:  0.032884143 Validation Decoder Loss:  0.33257073
Encoder Loss:  0.032870114  || Decoder Loss:  0.032870114 Validation Decoder Loss:  0.33262986
Encoder Loss:  0.03285727  || Decoder Loss:  0.03285727 Validation Decoder Loss:  0.33268115
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33268115
Model: "sequential_841"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_596 (Conv3D (None, 130, 8, 20, 1)     17        
_________________________________________________________________
dropout_1223 (Dropout)       (None, 130, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_597 (Conv3D (None, 220, 11, 20, 1)    365       
_________________________________________________________________
reshape_215 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_843"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_409 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_1225 (Dropout)       (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_410 (Conv2D)          (None, 2420, 20, 1)       72        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_844"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_409 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1227 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_410 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.095077895  || Decoder Loss:  0.095077895 Validation Decoder Loss:  0.3715243
Encoder Loss:  0.09472264  || Decoder Loss:  0.09472264 Validation Decoder Loss:  0.3719965
Encoder Loss:  0.09425991  || Decoder Loss:  0.09425991 Validation Decoder Loss:  0.37233776
Encoder Loss:  0.093673706  || Decoder Loss:  0.093673706 Validation Decoder Loss:  0.3724839
Encoder Loss:  0.09289092  || Decoder Loss:  0.09289092 Validation Decoder Loss:  0.3723504
Encoder Loss:  0.091754615  || Decoder Loss:  0.091754615 Validation Decoder Loss:  0.37174174
Encoder Loss:  0.089866504  || Decoder Loss:  0.089866504 Validation Decoder Loss:  0.37009537
Encoder Loss:  0.08578834  || Decoder Loss:  0.08578834 Validation Decoder Loss:  0.36494827
Encoder Loss:  0.066904165  || Decoder Loss:  0.066904165 Validation Decoder Loss:  0.3832031
Encoder Loss:  0.039674815  || Decoder Loss:  0.039674815 Validation Decoder Loss:  0.35379106
Encoder Loss:  0.037832286  || Decoder Loss:  0.037832286 Validation Decoder Loss:  0.34723628
Encoder Loss:  0.037579  || Decoder Loss:  0.037579 Validation Decoder Loss:  0.3471965
Encoder Loss:  0.037451014  || Decoder Loss:  0.037451014 Validation Decoder Loss:  0.34682232
Encoder Loss:  0.03735212  || Decoder Loss:  0.03735212 Validation Decoder Loss:  0.34646547
Encoder Loss:  0.037263185  || Decoder Loss:  0.037263185 Validation Decoder Loss:  0.34636763
Encoder Loss:  0.03717592  || Decoder Loss:  0.03717592 Validation Decoder Loss:  0.34625545
Encoder Loss:  0.037085593  || Decoder Loss:  0.037085593 Validation Decoder Loss:  0.34614143
Encoder Loss:  0.036989775  || Decoder Loss:  0.036989775 Validation Decoder Loss:  0.3460182
Encoder Loss:  0.036886573  || Decoder Loss:  0.036886573 Validation Decoder Loss:  0.34586984
Encoder Loss:  0.036773868  || Decoder Loss:  0.036773868 Validation Decoder Loss:  0.3456878
Encoder Loss:  0.036649205  || Decoder Loss:  0.036649205 Validation Decoder Loss:  0.34546304
Encoder Loss:  0.036510054  || Decoder Loss:  0.036510054 Validation Decoder Loss:  0.3451846
Encoder Loss:  0.036354493  || Decoder Loss:  0.036354493 Validation Decoder Loss:  0.34484023
Encoder Loss:  0.036182698  || Decoder Loss:  0.036182698 Validation Decoder Loss:  0.34442332
Encoder Loss:  0.035998926  || Decoder Loss:  0.035998926 Validation Decoder Loss:  0.34394833
Encoder Loss:  0.03581053  || Decoder Loss:  0.03581053 Validation Decoder Loss:  0.34346473
Encoder Loss:  0.035620645  || Decoder Loss:  0.035620645 Validation Decoder Loss:  0.34301883
Encoder Loss:  0.03542177  || Decoder Loss:  0.03542177 Validation Decoder Loss:  0.3425689
Encoder Loss:  0.03520116  || Decoder Loss:  0.03520116 Validation Decoder Loss:  0.3420025
Encoder Loss:  0.034948844  || Decoder Loss:  0.034948844 Validation Decoder Loss:  0.34122407
Encoder Loss:  0.03466216  || Decoder Loss:  0.03466216 Validation Decoder Loss:  0.34017664
Encoder Loss:  0.03435037  || Decoder Loss:  0.03435037 Validation Decoder Loss:  0.33885244
Encoder Loss:  0.03404052  || Decoder Loss:  0.03404052 Validation Decoder Loss:  0.3373658
Encoder Loss:  0.03377324  || Decoder Loss:  0.03377324 Validation Decoder Loss:  0.3359846
Encoder Loss:  0.03357675  || Decoder Loss:  0.03357675 Validation Decoder Loss:  0.33495253
Encoder Loss:  0.03344641  || Decoder Loss:  0.03344641 Validation Decoder Loss:  0.3342933
Encoder Loss:  0.03336035  || Decoder Loss:  0.03336035 Validation Decoder Loss:  0.33388704
Encoder Loss:  0.033300906  || Decoder Loss:  0.033300906 Validation Decoder Loss:  0.3336219
Encoder Loss:  0.03325778  || Decoder Loss:  0.03325778 Validation Decoder Loss:  0.33343723
Encoder Loss:  0.033225052  || Decoder Loss:  0.033225052 Validation Decoder Loss:  0.33330372
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3333037
Model: "sequential_845"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_599 (Conv3D (None, 211, 10, 20, 1)    133       
_________________________________________________________________
dropout_1229 (Dropout)       (None, 211, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_600 (Conv3D (None, 220, 11, 20, 1)    21        
_________________________________________________________________
reshape_216 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 154
Trainable params: 154
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_847"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_411 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_1231 (Dropout)       (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_412 (Conv2D)          (None, 2420, 20, 1)       142       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_848"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_411 (Conv2D (None, 2600, 20, 1)       182       
_________________________________________________________________
dropout_1233 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_412 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959733 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959733 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595975 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.4374136  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.4374136  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959733 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959733 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959733 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.045959745 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855445
Encoder Loss:  0.43741357  || Decoder Loss:  0.04595974 Validation Decoder Loss:  0.35855448
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35855448
Model: "sequential_849"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_602 (Conv3D (None, 95, 10, 20, 1)     193       
_________________________________________________________________
dropout_1235 (Dropout)       (None, 95, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_603 (Conv3D (None, 220, 11, 20, 1)    65        
_________________________________________________________________
reshape_217 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 258
Trainable params: 258
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_851"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_413 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_1237 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_414 (Conv2D)          (None, 2420, 20, 1)       2         
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_852"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_413 (Conv2D (None, 2490, 20, 1)       72        
_________________________________________________________________
dropout_1239 (Dropout)       (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_414 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17550117  || Decoder Loss:  0.06703827 Validation Decoder Loss:  0.3654651
Encoder Loss:  0.17574137  || Decoder Loss:  0.06826832 Validation Decoder Loss:  0.365502
Encoder Loss:  0.17602314  || Decoder Loss:  0.06978164 Validation Decoder Loss:  0.3655439
Encoder Loss:  0.17628513  || Decoder Loss:  0.071540765 Validation Decoder Loss:  0.36630762
Encoder Loss:  0.17589208  || Decoder Loss:  0.073525555 Validation Decoder Loss:  0.36815873
Encoder Loss:  0.17401409  || Decoder Loss:  0.075939484 Validation Decoder Loss:  0.370391
Encoder Loss:  0.17110388  || Decoder Loss:  0.079135634 Validation Decoder Loss:  0.37310907
Encoder Loss:  0.1679319  || Decoder Loss:  0.08356272 Validation Decoder Loss:  0.3768042
Encoder Loss:  0.16519356  || Decoder Loss:  0.090115786 Validation Decoder Loss:  0.38276076
Encoder Loss:  0.16373053  || Decoder Loss:  0.1009093 Validation Decoder Loss:  0.39549136
Encoder Loss:  0.1638943  || Decoder Loss:  0.11994586 Validation Decoder Loss:  0.42941537
Encoder Loss:  0.13876942  || Decoder Loss:  0.12288985 Validation Decoder Loss:  0.42584878
Encoder Loss:  0.102632396  || Decoder Loss:  0.111622356 Validation Decoder Loss:  0.38751015
Encoder Loss:  0.08203461  || Decoder Loss:  0.08232362 Validation Decoder Loss:  0.3692444
Encoder Loss:  0.06994745  || Decoder Loss:  0.063959554 Validation Decoder Loss:  0.36016783
Encoder Loss:  0.061954223  || Decoder Loss:  0.053447798 Validation Decoder Loss:  0.34679353
Encoder Loss:  0.057518136  || Decoder Loss:  0.047173556 Validation Decoder Loss:  0.3429306
Encoder Loss:  0.054410506  || Decoder Loss:  0.04297198 Validation Decoder Loss:  0.3401473
Encoder Loss:  0.051996235  || Decoder Loss:  0.0401502 Validation Decoder Loss:  0.3381589
Encoder Loss:  0.048131846  || Decoder Loss:  0.0382773 Validation Decoder Loss:  0.3373591
Encoder Loss:  0.043260213  || Decoder Loss:  0.0370458 Validation Decoder Loss:  0.33706352
Encoder Loss:  0.041675005  || Decoder Loss:  0.036222182 Validation Decoder Loss:  0.3368367
Encoder Loss:  0.040951613  || Decoder Loss:  0.03569773 Validation Decoder Loss:  0.33669853
Encoder Loss:  0.0406066  || Decoder Loss:  0.035356272 Validation Decoder Loss:  0.3365795
Encoder Loss:  0.040318646  || Decoder Loss:  0.03512375 Validation Decoder Loss:  0.3364506
Encoder Loss:  0.040132303  || Decoder Loss:  0.03495386 Validation Decoder Loss:  0.33630148
Encoder Loss:  0.039970446  || Decoder Loss:  0.03481754 Validation Decoder Loss:  0.3361156
Encoder Loss:  0.03981678  || Decoder Loss:  0.034695074 Validation Decoder Loss:  0.335877
Encoder Loss:  0.0397001  || Decoder Loss:  0.03457633 Validation Decoder Loss:  0.33558762
Encoder Loss:  0.039552655  || Decoder Loss:  0.034455393 Validation Decoder Loss:  0.33524382
Encoder Loss:  0.039414342  || Decoder Loss:  0.034328904 Validation Decoder Loss:  0.33485502
Encoder Loss:  0.039283074  || Decoder Loss:  0.034192614 Validation Decoder Loss:  0.33442715
Encoder Loss:  0.039138567  || Decoder Loss:  0.034045264 Validation Decoder Loss:  0.33400187
Encoder Loss:  0.03902277  || Decoder Loss:  0.033889517 Validation Decoder Loss:  0.3336135
Encoder Loss:  0.03889471  || Decoder Loss:  0.0337356 Validation Decoder Loss:  0.33324146
Encoder Loss:  0.03882676  || Decoder Loss:  0.033598647 Validation Decoder Loss:  0.33282536
Encoder Loss:  0.03871304  || Decoder Loss:  0.033495802 Validation Decoder Loss:  0.33243302
Encoder Loss:  0.038674086  || Decoder Loss:  0.033426195 Validation Decoder Loss:  0.3321289
Encoder Loss:  0.03865798  || Decoder Loss:  0.033384595 Validation Decoder Loss:  0.3319373
Encoder Loss:  0.038617723  || Decoder Loss:  0.033358086 Validation Decoder Loss:  0.3318331
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33183312
Model: "sequential_853"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_605 (Conv3D (None, 215, 10, 20, 1)    157       
_________________________________________________________________
dropout_1241 (Dropout)       (None, 215, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_606 (Conv3D (None, 220, 11, 20, 1)    13        
_________________________________________________________________
reshape_218 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_855"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_415 (Conv2D)          (None, 2470, 20, 1)       139       
_________________________________________________________________
dropout_1243 (Dropout)       (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_416 (Conv2D)          (None, 2420, 20, 1)       52        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_856"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_415 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1245 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_416 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23287825  || Decoder Loss:  0.03799093 Validation Decoder Loss:  0.33080143
Encoder Loss:  0.051584788  || Decoder Loss:  0.03375346 Validation Decoder Loss:  0.33065447
Encoder Loss:  0.05093657  || Decoder Loss:  0.033588503 Validation Decoder Loss:  0.3303095
Encoder Loss:  0.050444685  || Decoder Loss:  0.033409372 Validation Decoder Loss:  0.32985365
Encoder Loss:  0.05032662  || Decoder Loss:  0.033255503 Validation Decoder Loss:  0.32979617
Encoder Loss:  0.0502993  || Decoder Loss:  0.033172365 Validation Decoder Loss:  0.3298853
Encoder Loss:  0.05028517  || Decoder Loss:  0.03311442 Validation Decoder Loss:  0.32990107
Encoder Loss:  0.050256886  || Decoder Loss:  0.03306675 Validation Decoder Loss:  0.32987213
Encoder Loss:  0.050267413  || Decoder Loss:  0.033025984 Validation Decoder Loss:  0.32982248
Encoder Loss:  0.050243855  || Decoder Loss:  0.032990653 Validation Decoder Loss:  0.32976645
Encoder Loss:  0.05025222  || Decoder Loss:  0.03295991 Validation Decoder Loss:  0.3297122
Encoder Loss:  0.05022891  || Decoder Loss:  0.032932747 Validation Decoder Loss:  0.32966465
Encoder Loss:  0.0502913  || Decoder Loss:  0.03290894 Validation Decoder Loss:  0.3296247
Encoder Loss:  0.050221693  || Decoder Loss:  0.03288802 Validation Decoder Loss:  0.32959318
Encoder Loss:  0.05034965  || Decoder Loss:  0.032869276 Validation Decoder Loss:  0.32956916
Encoder Loss:  0.050210003  || Decoder Loss:  0.032853093 Validation Decoder Loss:  0.3295522
Encoder Loss:  0.05020412  || Decoder Loss:  0.032838594 Validation Decoder Loss:  0.32954127
Encoder Loss:  0.050204538  || Decoder Loss:  0.03282575 Validation Decoder Loss:  0.32953557
Encoder Loss:  0.050180517  || Decoder Loss:  0.032814328 Validation Decoder Loss:  0.32953334
Encoder Loss:  0.050176606  || Decoder Loss:  0.0328041 Validation Decoder Loss:  0.32953465
Encoder Loss:  0.05017814  || Decoder Loss:  0.03279495 Validation Decoder Loss:  0.32953864
Encoder Loss:  0.05018736  || Decoder Loss:  0.032786764 Validation Decoder Loss:  0.32954428
Encoder Loss:  0.05022385  || Decoder Loss:  0.0327793 Validation Decoder Loss:  0.32955056
Encoder Loss:  0.050160836  || Decoder Loss:  0.032772668 Validation Decoder Loss:  0.3295586
Encoder Loss:  0.050311323  || Decoder Loss:  0.03276647 Validation Decoder Loss:  0.32956594
Encoder Loss:  0.050147127  || Decoder Loss:  0.032761015 Validation Decoder Loss:  0.32957458
Encoder Loss:  0.05021935  || Decoder Loss:  0.032755908 Validation Decoder Loss:  0.32958263
Encoder Loss:  0.050150957  || Decoder Loss:  0.03275126 Validation Decoder Loss:  0.3295911
Encoder Loss:  0.050181  || Decoder Loss:  0.03274696 Validation Decoder Loss:  0.32959837
Encoder Loss:  0.050137065  || Decoder Loss:  0.032742962 Validation Decoder Loss:  0.3296062
Encoder Loss:  0.050157465  || Decoder Loss:  0.032739267 Validation Decoder Loss:  0.32961303
Encoder Loss:  0.050161544  || Decoder Loss:  0.032735847 Validation Decoder Loss:  0.32961968
Encoder Loss:  0.05015114  || Decoder Loss:  0.032732695 Validation Decoder Loss:  0.3296258
Encoder Loss:  0.050136786  || Decoder Loss:  0.032729696 Validation Decoder Loss:  0.32963145
Encoder Loss:  0.050228138  || Decoder Loss:  0.03272698 Validation Decoder Loss:  0.32963586
Encoder Loss:  0.050121527  || Decoder Loss:  0.032724373 Validation Decoder Loss:  0.3296408
Encoder Loss:  0.05012122  || Decoder Loss:  0.032721948 Validation Decoder Loss:  0.32964528
Encoder Loss:  0.05013895  || Decoder Loss:  0.032719646 Validation Decoder Loss:  0.3296492
Encoder Loss:  0.050100412  || Decoder Loss:  0.032717522 Validation Decoder Loss:  0.32965308
Encoder Loss:  0.05011747  || Decoder Loss:  0.032715503 Validation Decoder Loss:  0.32965627
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32965627
Model: "sequential_857"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_608 (Conv3D (None, 175, 6, 20, 1)     99        
_________________________________________________________________
dropout_1247 (Dropout)       (None, 175, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_609 (Conv3D (None, 220, 11, 20, 1)    277       
_________________________________________________________________
reshape_219 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 376
Trainable params: 376
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_859"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_417 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_1249 (Dropout)       (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_418 (Conv2D)          (None, 2420, 20, 1)       162       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_860"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_417 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1251 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_418 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05688286  || Decoder Loss:  0.05688286 Validation Decoder Loss:  0.34407824
Encoder Loss:  0.036673557  || Decoder Loss:  0.036673557 Validation Decoder Loss:  0.3412099
Encoder Loss:  0.03528498  || Decoder Loss:  0.03528498 Validation Decoder Loss:  0.3366363
Encoder Loss:  0.03393854  || Decoder Loss:  0.03393854 Validation Decoder Loss:  0.33216435
Encoder Loss:  0.033525124  || Decoder Loss:  0.033525124 Validation Decoder Loss:  0.33147717
Encoder Loss:  0.03341493  || Decoder Loss:  0.03341493 Validation Decoder Loss:  0.33112726
Encoder Loss:  0.03333328  || Decoder Loss:  0.03333328 Validation Decoder Loss:  0.33082533
Encoder Loss:  0.033267368  || Decoder Loss:  0.033267368 Validation Decoder Loss:  0.33064193
Encoder Loss:  0.033215206  || Decoder Loss:  0.033215206 Validation Decoder Loss:  0.33056384
Encoder Loss:  0.03317344  || Decoder Loss:  0.03317344 Validation Decoder Loss:  0.33053637
Encoder Loss:  0.033138655  || Decoder Loss:  0.033138655 Validation Decoder Loss:  0.33052176
Encoder Loss:  0.03310851  || Decoder Loss:  0.03310851 Validation Decoder Loss:  0.3305044
Encoder Loss:  0.033081673  || Decoder Loss:  0.033081673 Validation Decoder Loss:  0.33048055
Encoder Loss:  0.033057414  || Decoder Loss:  0.033057414 Validation Decoder Loss:  0.33045146
Encoder Loss:  0.033035267  || Decoder Loss:  0.033035267 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03301494  || Decoder Loss:  0.03301494 Validation Decoder Loss:  0.3303873
Encoder Loss:  0.032996133  || Decoder Loss:  0.032996133 Validation Decoder Loss:  0.33035666
Encoder Loss:  0.032978714  || Decoder Loss:  0.032978714 Validation Decoder Loss:  0.33032888
Encoder Loss:  0.03296252  || Decoder Loss:  0.03296252 Validation Decoder Loss:  0.33030492
Encoder Loss:  0.03294739  || Decoder Loss:  0.03294739 Validation Decoder Loss:  0.33028507
Encoder Loss:  0.03293325  || Decoder Loss:  0.03293325 Validation Decoder Loss:  0.3302694
Encoder Loss:  0.03292  || Decoder Loss:  0.03292 Validation Decoder Loss:  0.33025774
Encoder Loss:  0.03290753  || Decoder Loss:  0.03290753 Validation Decoder Loss:  0.3302498
Encoder Loss:  0.03289583  || Decoder Loss:  0.03289583 Validation Decoder Loss:  0.3302451
Encoder Loss:  0.032884788  || Decoder Loss:  0.032884788 Validation Decoder Loss:  0.33024344
Encoder Loss:  0.03287442  || Decoder Loss:  0.03287442 Validation Decoder Loss:  0.3302443
Encoder Loss:  0.032864615  || Decoder Loss:  0.032864615 Validation Decoder Loss:  0.33024734
Encoder Loss:  0.032855414  || Decoder Loss:  0.032855414 Validation Decoder Loss:  0.3302524
Encoder Loss:  0.03284672  || Decoder Loss:  0.03284672 Validation Decoder Loss:  0.33025914
Encoder Loss:  0.032838523  || Decoder Loss:  0.032838523 Validation Decoder Loss:  0.33026743
Encoder Loss:  0.032830805  || Decoder Loss:  0.032830805 Validation Decoder Loss:  0.33027714
Encoder Loss:  0.032823525  || Decoder Loss:  0.032823525 Validation Decoder Loss:  0.3302881
Encoder Loss:  0.032816675  || Decoder Loss:  0.032816675 Validation Decoder Loss:  0.3303002
Encoder Loss:  0.03281017  || Decoder Loss:  0.03281017 Validation Decoder Loss:  0.33031332
Encoder Loss:  0.032804042  || Decoder Loss:  0.032804042 Validation Decoder Loss:  0.33032727
Encoder Loss:  0.03279825  || Decoder Loss:  0.03279825 Validation Decoder Loss:  0.330342
Encoder Loss:  0.032792762  || Decoder Loss:  0.032792762 Validation Decoder Loss:  0.3303573
Encoder Loss:  0.03278759  || Decoder Loss:  0.03278759 Validation Decoder Loss:  0.3303731
Encoder Loss:  0.03278267  || Decoder Loss:  0.03278267 Validation Decoder Loss:  0.33038926
Encoder Loss:  0.03277801  || Decoder Loss:  0.03277801 Validation Decoder Loss:  0.3304057
Model: siamese_net_lr_0.0009170282685631398 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3304057
Model: "sequential_861"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_611 (Conv3D (None, 169, 10, 20, 1)    259       
_________________________________________________________________
dropout_1253 (Dropout)       (None, 169, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_612 (Conv3D (None, 220, 11, 20, 1)    105       
_________________________________________________________________
reshape_220 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 364
Trainable params: 364
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_863"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_419 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1255 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_420 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_864"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_419 (Conv2D (None, 2460, 20, 1)       42        
_________________________________________________________________
dropout_1257 (Dropout)       (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_420 (Conv2D (None, 2607, 20, 1)       149       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19394523  || Decoder Loss:  0.08416874 Validation Decoder Loss:  0.3766498
Encoder Loss:  0.19185415  || Decoder Loss:  0.094662145 Validation Decoder Loss:  0.44739243
Encoder Loss:  0.085568555  || Decoder Loss:  0.060075097 Validation Decoder Loss:  0.34099352
Encoder Loss:  0.05821337  || Decoder Loss:  0.040895507 Validation Decoder Loss:  0.33883777
Encoder Loss:  0.04590624  || Decoder Loss:  0.03694475 Validation Decoder Loss:  0.33970934
Encoder Loss:  0.04195583  || Decoder Loss:  0.036021747 Validation Decoder Loss:  0.33887
Encoder Loss:  0.040986165  || Decoder Loss:  0.03580905 Validation Decoder Loss:  0.33835393
Encoder Loss:  0.040980052  || Decoder Loss:  0.03572305 Validation Decoder Loss:  0.33785844
Encoder Loss:  0.040838763  || Decoder Loss:  0.035627253 Validation Decoder Loss:  0.3373729
Encoder Loss:  0.040749818  || Decoder Loss:  0.035495922 Validation Decoder Loss:  0.33676845
Encoder Loss:  0.04064639  || Decoder Loss:  0.03531062 Validation Decoder Loss:  0.33588398
Encoder Loss:  0.04040241  || Decoder Loss:  0.03501239 Validation Decoder Loss:  0.33437976
Encoder Loss:  0.040114712  || Decoder Loss:  0.034493163 Validation Decoder Loss:  0.33154967
Encoder Loss:  0.039745063  || Decoder Loss:  0.03388828 Validation Decoder Loss:  0.32980618
Encoder Loss:  0.039558083  || Decoder Loss:  0.033644885 Validation Decoder Loss:  0.3296302
Encoder Loss:  0.039482307  || Decoder Loss:  0.0335666 Validation Decoder Loss:  0.32958132
Encoder Loss:  0.039462533  || Decoder Loss:  0.033525363 Validation Decoder Loss:  0.32957965
Encoder Loss:  0.03946456  || Decoder Loss:  0.033500038 Validation Decoder Loss:  0.3295316
Encoder Loss:  0.039389476  || Decoder Loss:  0.033481024 Validation Decoder Loss:  0.32945463
Encoder Loss:  0.03936936  || Decoder Loss:  0.033463567 Validation Decoder Loss:  0.32940388
Encoder Loss:  0.039366342  || Decoder Loss:  0.03344834 Validation Decoder Loss:  0.32936344
Encoder Loss:  0.039394394  || Decoder Loss:  0.033434123 Validation Decoder Loss:  0.3293225
Encoder Loss:  0.03938276  || Decoder Loss:  0.03342119 Validation Decoder Loss:  0.32930407
Encoder Loss:  0.03935896  || Decoder Loss:  0.033408858 Validation Decoder Loss:  0.3292802
Encoder Loss:  0.039362106  || Decoder Loss:  0.033396702 Validation Decoder Loss:  0.3292615
Encoder Loss:  0.039373852  || Decoder Loss:  0.033385858 Validation Decoder Loss:  0.3292731
Encoder Loss:  0.039320752  || Decoder Loss:  0.033373445 Validation Decoder Loss:  0.32924348
Encoder Loss:  0.039281223  || Decoder Loss:  0.033360966 Validation Decoder Loss:  0.32918733
Encoder Loss:  0.039317057  || Decoder Loss:  0.033348795 Validation Decoder Loss:  0.32917643
Encoder Loss:  0.039350856  || Decoder Loss:  0.033337165 Validation Decoder Loss:  0.32916662
Encoder Loss:  0.03926968  || Decoder Loss:  0.033323936 Validation Decoder Loss:  0.3291015
Encoder Loss:  0.03928947  || Decoder Loss:  0.033312615 Validation Decoder Loss:  0.32906118
Encoder Loss:  0.039303347  || Decoder Loss:  0.03330524 Validation Decoder Loss:  0.32904255
Encoder Loss:  0.03922603  || Decoder Loss:  0.033293076 Validation Decoder Loss:  0.3289526
Encoder Loss:  0.039202236  || Decoder Loss:  0.033284955 Validation Decoder Loss:  0.32888398
Encoder Loss:  0.03918499  || Decoder Loss:  0.033274602 Validation Decoder Loss:  0.3288372
Encoder Loss:  0.039170023  || Decoder Loss:  0.033266183 Validation Decoder Loss:  0.32879066
Encoder Loss:  0.03915931  || Decoder Loss:  0.033257887 Validation Decoder Loss:  0.32872975
Encoder Loss:  0.039152525  || Decoder Loss:  0.033249367 Validation Decoder Loss:  0.32872933
Encoder Loss:  0.039133802  || Decoder Loss:  0.033233475 Validation Decoder Loss:  0.32879642
Model: siamese_net_lr_0.0007270788471170451 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32879642
Model: "sequential_865"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_614 (Conv3D (None, 175, 10, 20, 1)    99        
_________________________________________________________________
dropout_1259 (Dropout)       (None, 175, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_615 (Conv3D (None, 220, 11, 20, 1)    93        
_________________________________________________________________
reshape_221 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_867"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_421 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_1261 (Dropout)       (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_422 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_868"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_421 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1263 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_422 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23135048  || Decoder Loss:  0.04647244 Validation Decoder Loss:  0.33920285
Encoder Loss:  0.055823296  || Decoder Loss:  0.034839693 Validation Decoder Loss:  0.3297985
Encoder Loss:  0.050076146  || Decoder Loss:  0.03337209 Validation Decoder Loss:  0.3295626
Encoder Loss:  0.050073925  || Decoder Loss:  0.033234965 Validation Decoder Loss:  0.3293383
Encoder Loss:  0.050066877  || Decoder Loss:  0.033144657 Validation Decoder Loss:  0.32917398
Encoder Loss:  0.05006913  || Decoder Loss:  0.03307549 Validation Decoder Loss:  0.32911268
Encoder Loss:  0.050072327  || Decoder Loss:  0.033021428 Validation Decoder Loss:  0.32907045
Encoder Loss:  0.050066732  || Decoder Loss:  0.032977484 Validation Decoder Loss:  0.329033
Encoder Loss:  0.050053515  || Decoder Loss:  0.032940935 Validation Decoder Loss:  0.3290028
Encoder Loss:  0.050057128  || Decoder Loss:  0.03291007 Validation Decoder Loss:  0.32898176
Encoder Loss:  0.0500525  || Decoder Loss:  0.03288374 Validation Decoder Loss:  0.32896987
Encoder Loss:  0.050045624  || Decoder Loss:  0.032861255 Validation Decoder Loss:  0.32896698
Encoder Loss:  0.05003592  || Decoder Loss:  0.032842025 Validation Decoder Loss:  0.3289706
Encoder Loss:  0.05003904  || Decoder Loss:  0.03282548 Validation Decoder Loss:  0.32897976
Encoder Loss:  0.050033838  || Decoder Loss:  0.032811217 Validation Decoder Loss:  0.32899293
Encoder Loss:  0.05003221  || Decoder Loss:  0.032798875 Validation Decoder Loss:  0.3290087
Encoder Loss:  0.050037406  || Decoder Loss:  0.03278819 Validation Decoder Loss:  0.32902652
Encoder Loss:  0.05002947  || Decoder Loss:  0.032778785 Validation Decoder Loss:  0.3290445
Encoder Loss:  0.050033737  || Decoder Loss:  0.03277059 Validation Decoder Loss:  0.32906318
Encoder Loss:  0.050029278  || Decoder Loss:  0.032763306 Validation Decoder Loss:  0.32908082
Encoder Loss:  0.050026406  || Decoder Loss:  0.032756843 Validation Decoder Loss:  0.32909846
Encoder Loss:  0.050026465  || Decoder Loss:  0.032751206 Validation Decoder Loss:  0.32911587
Encoder Loss:  0.05002739  || Decoder Loss:  0.032745965 Validation Decoder Loss:  0.3291351
Encoder Loss:  0.05003098  || Decoder Loss:  0.03274126 Validation Decoder Loss:  0.3291486
Encoder Loss:  0.05001829  || Decoder Loss:  0.03273706 Validation Decoder Loss:  0.32916418
Encoder Loss:  0.050097074  || Decoder Loss:  0.032733053 Validation Decoder Loss:  0.32917076
Encoder Loss:  0.050014663  || Decoder Loss:  0.032729536 Validation Decoder Loss:  0.32918462
Encoder Loss:  0.050050747  || Decoder Loss:  0.032726265 Validation Decoder Loss:  0.32919186
Encoder Loss:  0.05001574  || Decoder Loss:  0.032723274 Validation Decoder Loss:  0.32920402
Encoder Loss:  0.05002056  || Decoder Loss:  0.03272057 Validation Decoder Loss:  0.32921153
Encoder Loss:  0.050016597  || Decoder Loss:  0.032717995 Validation Decoder Loss:  0.32922024
Encoder Loss:  0.050024282  || Decoder Loss:  0.03271563 Validation Decoder Loss:  0.32922202
Encoder Loss:  0.050034232  || Decoder Loss:  0.032713454 Validation Decoder Loss:  0.32923073
Encoder Loss:  0.050021697  || Decoder Loss:  0.03271141 Validation Decoder Loss:  0.32923767
Encoder Loss:  0.050015107  || Decoder Loss:  0.03270954 Validation Decoder Loss:  0.32924312
Encoder Loss:  0.050026055  || Decoder Loss:  0.032707736 Validation Decoder Loss:  0.3292454
Encoder Loss:  0.05002236  || Decoder Loss:  0.032706086 Validation Decoder Loss:  0.3292489
Encoder Loss:  0.050026223  || Decoder Loss:  0.032704722 Validation Decoder Loss:  0.32925588
Encoder Loss:  0.050023984  || Decoder Loss:  0.03270335 Validation Decoder Loss:  0.32925946
Encoder Loss:  0.05002536  || Decoder Loss:  0.032701906 Validation Decoder Loss:  0.3292615
Model: siamese_net_lr_0.0008097188338889039 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32926154
Model: "sequential_869"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_617 (Conv3D (None, 166, 10, 20, 1)    619       
_________________________________________________________________
dropout_1265 (Dropout)       (None, 166, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_618 (Conv3D (None, 220, 11, 20, 1)    111       
_________________________________________________________________
reshape_222 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 730
Trainable params: 730
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_871"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_423 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_1267 (Dropout)       (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_424 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_872"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_423 (Conv2D (None, 2420, 20, 1)       2         
_________________________________________________________________
dropout_1269 (Dropout)       (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_424 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23205921  || Decoder Loss:  0.09314224 Validation Decoder Loss:  0.37272313
Encoder Loss:  0.22921291  || Decoder Loss:  0.096848466 Validation Decoder Loss:  0.3709155
Encoder Loss:  0.21882269  || Decoder Loss:  0.0881631 Validation Decoder Loss:  0.34133914
Encoder Loss:  0.18507297  || Decoder Loss:  0.038550302 Validation Decoder Loss:  0.34779036
Encoder Loss:  0.17338304  || Decoder Loss:  0.037837725 Validation Decoder Loss:  0.345481
Encoder Loss:  0.15426902  || Decoder Loss:  0.03770952 Validation Decoder Loss:  0.3439447
Encoder Loss:  0.11299879  || Decoder Loss:  0.03765607 Validation Decoder Loss:  0.34242237
Encoder Loss:  0.057607055  || Decoder Loss:  0.037583195 Validation Decoder Loss:  0.34162766
Encoder Loss:  0.056172706  || Decoder Loss:  0.037405223 Validation Decoder Loss:  0.34113765
Encoder Loss:  0.055715423  || Decoder Loss:  0.03718946 Validation Decoder Loss:  0.34052688
Encoder Loss:  0.055063058  || Decoder Loss:  0.03692063 Validation Decoder Loss:  0.33976978
Encoder Loss:  0.053672567  || Decoder Loss:  0.036568012 Validation Decoder Loss:  0.33880734
Encoder Loss:  0.0484845  || Decoder Loss:  0.03609468 Validation Decoder Loss:  0.337583
Encoder Loss:  0.043116394  || Decoder Loss:  0.035482608 Validation Decoder Loss:  0.33605474
Encoder Loss:  0.042295355  || Decoder Loss:  0.03479215 Validation Decoder Loss:  0.33426893
Encoder Loss:  0.041816145  || Decoder Loss:  0.0342149 Validation Decoder Loss:  0.33270448
Encoder Loss:  0.041634645  || Decoder Loss:  0.03390613 Validation Decoder Loss:  0.331785
Encoder Loss:  0.041563116  || Decoder Loss:  0.033799823 Validation Decoder Loss:  0.33144742
Encoder Loss:  0.041527852  || Decoder Loss:  0.03376012 Validation Decoder Loss:  0.3314405
Encoder Loss:  0.04150301  || Decoder Loss:  0.03373251 Validation Decoder Loss:  0.3315578
Encoder Loss:  0.041488666  || Decoder Loss:  0.033708982 Validation Decoder Loss:  0.33168614
Encoder Loss:  0.041475892  || Decoder Loss:  0.03368828 Validation Decoder Loss:  0.33179653
Encoder Loss:  0.041464817  || Decoder Loss:  0.03366961 Validation Decoder Loss:  0.33188716
Encoder Loss:  0.04145563  || Decoder Loss:  0.033652302 Validation Decoder Loss:  0.33196205
Encoder Loss:  0.04144545  || Decoder Loss:  0.033635877 Validation Decoder Loss:  0.33202586
Encoder Loss:  0.041437045  || Decoder Loss:  0.03361988 Validation Decoder Loss:  0.33208317
Encoder Loss:  0.041428007  || Decoder Loss:  0.03360411 Validation Decoder Loss:  0.33213663
Encoder Loss:  0.041419152  || Decoder Loss:  0.033588357 Validation Decoder Loss:  0.33218247
Encoder Loss:  0.041410375  || Decoder Loss:  0.03357268 Validation Decoder Loss:  0.33222032
Encoder Loss:  0.041400947  || Decoder Loss:  0.033556968 Validation Decoder Loss:  0.33225226
Encoder Loss:  0.04139256  || Decoder Loss:  0.03354109 Validation Decoder Loss:  0.33227628
Encoder Loss:  0.041383874  || Decoder Loss:  0.03352506 Validation Decoder Loss:  0.33229655
Encoder Loss:  0.041374877  || Decoder Loss:  0.03350874 Validation Decoder Loss:  0.3323077
Encoder Loss:  0.041365646  || Decoder Loss:  0.03349224 Validation Decoder Loss:  0.3323154
Encoder Loss:  0.04135668  || Decoder Loss:  0.03347538 Validation Decoder Loss:  0.33232224
Encoder Loss:  0.04134742  || Decoder Loss:  0.033458184 Validation Decoder Loss:  0.33232328
Encoder Loss:  0.041337837  || Decoder Loss:  0.03344075 Validation Decoder Loss:  0.33232144
Encoder Loss:  0.041328546  || Decoder Loss:  0.033423256 Validation Decoder Loss:  0.33231536
Encoder Loss:  0.041319255  || Decoder Loss:  0.03340571 Validation Decoder Loss:  0.3323086
Encoder Loss:  0.04130926  || Decoder Loss:  0.03338815 Validation Decoder Loss:  0.33230236
Model: siamese_net_lr_0.0001026027795794682 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3323024
Model: "sequential_873"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_620 (Conv3D (None, 171, 10, 20, 1)    217       
_________________________________________________________________
dropout_1271 (Dropout)       (None, 171, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_621 (Conv3D (None, 220, 11, 20, 1)    101       
_________________________________________________________________
reshape_223 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_875"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_425 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_1273 (Dropout)       (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_426 (Conv2D)          (None, 2420, 20, 1)       112       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_876"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_425 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_1275 (Dropout)       (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_426 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34544986  || Decoder Loss:  0.09213435 Validation Decoder Loss:  0.39591444
Encoder Loss:  0.13300641  || Decoder Loss:  0.17438385 Validation Decoder Loss:  0.36096936
Encoder Loss:  0.07937756  || Decoder Loss:  0.044799022 Validation Decoder Loss:  0.34110025
Encoder Loss:  0.07458433  || Decoder Loss:  0.037462864 Validation Decoder Loss:  0.33768398
Encoder Loss:  0.0516792  || Decoder Loss:  0.036840033 Validation Decoder Loss:  0.33709905
Encoder Loss:  0.048047323  || Decoder Loss:  0.036072455 Validation Decoder Loss:  0.3345402
Encoder Loss:  0.047825716  || Decoder Loss:  0.034876615 Validation Decoder Loss:  0.33023918
Encoder Loss:  0.047743745  || Decoder Loss:  0.034369234 Validation Decoder Loss:  0.32988515
Encoder Loss:  0.047671437  || Decoder Loss:  0.0341737 Validation Decoder Loss:  0.3298651
Encoder Loss:  0.04766347  || Decoder Loss:  0.034064487 Validation Decoder Loss:  0.3298796
Encoder Loss:  0.047647376  || Decoder Loss:  0.033968844 Validation Decoder Loss:  0.32990384
Encoder Loss:  0.047608137  || Decoder Loss:  0.03388528 Validation Decoder Loss:  0.32990354
Encoder Loss:  0.047597874  || Decoder Loss:  0.033807237 Validation Decoder Loss:  0.3298652
Encoder Loss:  0.04758756  || Decoder Loss:  0.0337324 Validation Decoder Loss:  0.32980043
Encoder Loss:  0.04757155  || Decoder Loss:  0.033662822 Validation Decoder Loss:  0.32973957
Encoder Loss:  0.047546197  || Decoder Loss:  0.03360091 Validation Decoder Loss:  0.32967567
Encoder Loss:  0.047503762  || Decoder Loss:  0.03354627 Validation Decoder Loss:  0.3295917
Encoder Loss:  0.047496434  || Decoder Loss:  0.033500113 Validation Decoder Loss:  0.3295461
Encoder Loss:  0.04749496  || Decoder Loss:  0.033462267 Validation Decoder Loss:  0.32950586
Encoder Loss:  0.047445964  || Decoder Loss:  0.033429038 Validation Decoder Loss:  0.3295128
Encoder Loss:  0.047430478  || Decoder Loss:  0.033401527 Validation Decoder Loss:  0.32946277
Encoder Loss:  0.047401924  || Decoder Loss:  0.0333793 Validation Decoder Loss:  0.32947075
Encoder Loss:  0.04735497  || Decoder Loss:  0.033358544 Validation Decoder Loss:  0.32947305
Encoder Loss:  0.047345027  || Decoder Loss:  0.03334086 Validation Decoder Loss:  0.3294769
Encoder Loss:  0.04730492  || Decoder Loss:  0.033322122 Validation Decoder Loss:  0.32945046
Encoder Loss:  0.047278587  || Decoder Loss:  0.033309463 Validation Decoder Loss:  0.3294387
Encoder Loss:  0.047254853  || Decoder Loss:  0.033298496 Validation Decoder Loss:  0.32944268
Encoder Loss:  0.047245413  || Decoder Loss:  0.03329055 Validation Decoder Loss:  0.32942915
Encoder Loss:  0.04724039  || Decoder Loss:  0.033283837 Validation Decoder Loss:  0.32942137
Encoder Loss:  0.047235984  || Decoder Loss:  0.033278063 Validation Decoder Loss:  0.3293854
Encoder Loss:  0.04723395  || Decoder Loss:  0.033273235 Validation Decoder Loss:  0.32939827
Encoder Loss:  0.04723309  || Decoder Loss:  0.03326837 Validation Decoder Loss:  0.3293717
Encoder Loss:  0.047230646  || Decoder Loss:  0.033263512 Validation Decoder Loss:  0.32937264
Encoder Loss:  0.0472264  || Decoder Loss:  0.03325895 Validation Decoder Loss:  0.32936388
Encoder Loss:  0.04722553  || Decoder Loss:  0.03325551 Validation Decoder Loss:  0.32934552
Encoder Loss:  0.04722261  || Decoder Loss:  0.03325256 Validation Decoder Loss:  0.32932058
Encoder Loss:  0.047217134  || Decoder Loss:  0.033249747 Validation Decoder Loss:  0.32929677
Encoder Loss:  0.047214545  || Decoder Loss:  0.033247218 Validation Decoder Loss:  0.32928705
Encoder Loss:  0.047210086  || Decoder Loss:  0.033245265 Validation Decoder Loss:  0.32927537
Encoder Loss:  0.04720731  || Decoder Loss:  0.03324417 Validation Decoder Loss:  0.3292506
Model: siamese_net_lr_0.0003247441113043252 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32925057
Model: "sequential_877"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_623 (Conv3D (None, 190, 9, 20, 1)     636       
_________________________________________________________________
dropout_1277 (Dropout)       (None, 190, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_624 (Conv3D (None, 220, 11, 20, 1)    94        
_________________________________________________________________
reshape_224 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 730
Trainable params: 730
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_879"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_427 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_1279 (Dropout)       (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_428 (Conv2D)          (None, 2420, 20, 1)       132       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_880"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_427 (Conv2D (None, 2450, 20, 1)       32        
_________________________________________________________________
dropout_1281 (Dropout)       (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_428 (Conv2D (None, 2607, 20, 1)       159       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.0739249 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.3669939
Encoder Loss:  0.36531895  || Decoder Loss:  0.07392489 Validation Decoder Loss:  0.36699387
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36699387
Model: "sequential_881"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_626 (Conv3D (None, 163, 10, 20, 1)    75        
_________________________________________________________________
dropout_1283 (Dropout)       (None, 163, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_627 (Conv3D (None, 220, 11, 20, 1)    117       
_________________________________________________________________
reshape_225 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_883"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_429 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_1285 (Dropout)       (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_430 (Conv2D)          (None, 2420, 20, 1)       152       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_884"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_429 (Conv2D (None, 2500, 20, 1)       82        
_________________________________________________________________
dropout_1287 (Dropout)       (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_430 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06778051  || Decoder Loss:  0.06778051 Validation Decoder Loss:  0.3372169
Encoder Loss:  0.03936928  || Decoder Loss:  0.03936928 Validation Decoder Loss:  0.33964345
Encoder Loss:  0.035945456  || Decoder Loss:  0.035945456 Validation Decoder Loss:  0.34060478
Encoder Loss:  0.034028124  || Decoder Loss:  0.034028124 Validation Decoder Loss:  0.342091
Encoder Loss:  0.033615883  || Decoder Loss:  0.033615883 Validation Decoder Loss:  0.34374866
Encoder Loss:  0.03347606  || Decoder Loss:  0.03347606 Validation Decoder Loss:  0.34491473
Encoder Loss:  0.03340088  || Decoder Loss:  0.03340088 Validation Decoder Loss:  0.3458301
Encoder Loss:  0.033348408  || Decoder Loss:  0.033348408 Validation Decoder Loss:  0.34653693
Encoder Loss:  0.033303842  || Decoder Loss:  0.033303842 Validation Decoder Loss:  0.34688264
Encoder Loss:  0.033262968  || Decoder Loss:  0.033262968 Validation Decoder Loss:  0.3471086
Encoder Loss:  0.033222813  || Decoder Loss:  0.033222813 Validation Decoder Loss:  0.34724614
Encoder Loss:  0.033175252  || Decoder Loss:  0.033175252 Validation Decoder Loss:  0.3468842
Encoder Loss:  0.033117965  || Decoder Loss:  0.033117965 Validation Decoder Loss:  0.34601367
Encoder Loss:  0.033061862  || Decoder Loss:  0.033061862 Validation Decoder Loss:  0.34539896
Encoder Loss:  0.033015754  || Decoder Loss:  0.033015754 Validation Decoder Loss:  0.3450372
Encoder Loss:  0.032979798  || Decoder Loss:  0.032979798 Validation Decoder Loss:  0.34482867
Encoder Loss:  0.03295164  || Decoder Loss:  0.03295164 Validation Decoder Loss:  0.34470677
Encoder Loss:  0.03292913  || Decoder Loss:  0.03292913 Validation Decoder Loss:  0.3446356
Encoder Loss:  0.03291071  || Decoder Loss:  0.03291071 Validation Decoder Loss:  0.34459573
Encoder Loss:  0.032895196  || Decoder Loss:  0.032895196 Validation Decoder Loss:  0.34457606
Encoder Loss:  0.032881763  || Decoder Loss:  0.032881763 Validation Decoder Loss:  0.34456974
Encoder Loss:  0.03286984  || Decoder Loss:  0.03286984 Validation Decoder Loss:  0.34457237
Encoder Loss:  0.0328591  || Decoder Loss:  0.0328591 Validation Decoder Loss:  0.3445812
Encoder Loss:  0.032849208  || Decoder Loss:  0.032849208 Validation Decoder Loss:  0.34459448
Encoder Loss:  0.032840002  || Decoder Loss:  0.032840002 Validation Decoder Loss:  0.34461105
Encoder Loss:  0.032831363  || Decoder Loss:  0.032831363 Validation Decoder Loss:  0.34463012
Encoder Loss:  0.032823205  || Decoder Loss:  0.032823205 Validation Decoder Loss:  0.34465107
Encoder Loss:  0.032815445  || Decoder Loss:  0.032815445 Validation Decoder Loss:  0.3446734
Encoder Loss:  0.032808077  || Decoder Loss:  0.032808077 Validation Decoder Loss:  0.34469664
Encoder Loss:  0.032801002  || Decoder Loss:  0.032801002 Validation Decoder Loss:  0.34472045
Encoder Loss:  0.03279427  || Decoder Loss:  0.03279427 Validation Decoder Loss:  0.34474432
Encoder Loss:  0.032787837  || Decoder Loss:  0.032787837 Validation Decoder Loss:  0.344768
Encoder Loss:  0.032781653  || Decoder Loss:  0.032781653 Validation Decoder Loss:  0.34479105
Encoder Loss:  0.032775756  || Decoder Loss:  0.032775756 Validation Decoder Loss:  0.34481323
Encoder Loss:  0.032770086  || Decoder Loss:  0.032770086 Validation Decoder Loss:  0.34483412
Encoder Loss:  0.032764602  || Decoder Loss:  0.032764602 Validation Decoder Loss:  0.34485352
Encoder Loss:  0.032759383  || Decoder Loss:  0.032759383 Validation Decoder Loss:  0.34487098
Encoder Loss:  0.03275433  || Decoder Loss:  0.03275433 Validation Decoder Loss:  0.3448863
Encoder Loss:  0.032749463  || Decoder Loss:  0.032749463 Validation Decoder Loss:  0.34489912
Encoder Loss:  0.032744735  || Decoder Loss:  0.032744735 Validation Decoder Loss:  0.3449093
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3449093
Model: "sequential_885"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_629 (Conv3D (None, 177, 10, 20, 1)    307       
_________________________________________________________________
dropout_1289 (Dropout)       (None, 177, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_630 (Conv3D (None, 220, 11, 20, 1)    89        
_________________________________________________________________
reshape_226 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_887"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_431 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_1291 (Dropout)       (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_432 (Conv2D)          (None, 2420, 20, 1)       172       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_888"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_431 (Conv2D (None, 2480, 20, 1)       62        
_________________________________________________________________
dropout_1293 (Dropout)       (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_432 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14406145  || Decoder Loss:  0.08727077 Validation Decoder Loss:  0.32708386
Encoder Loss:  0.042886343  || Decoder Loss:  0.034428515 Validation Decoder Loss:  0.3288219
Encoder Loss:  0.04254909  || Decoder Loss:  0.033943452 Validation Decoder Loss:  0.32932663
Encoder Loss:  0.04229713  || Decoder Loss:  0.033780195 Validation Decoder Loss:  0.32949227
Encoder Loss:  0.0422554  || Decoder Loss:  0.033720486 Validation Decoder Loss:  0.32977647
Encoder Loss:  0.04223757  || Decoder Loss:  0.033679284 Validation Decoder Loss:  0.32978642
Encoder Loss:  0.042157564  || Decoder Loss:  0.03366856 Validation Decoder Loss:  0.32969972
Encoder Loss:  0.04208499  || Decoder Loss:  0.033921704 Validation Decoder Loss:  0.32772195
Encoder Loss:  0.04178718  || Decoder Loss:  0.03370532 Validation Decoder Loss:  0.325136
Encoder Loss:  0.04152502  || Decoder Loss:  0.03319519 Validation Decoder Loss:  0.32744533
Encoder Loss:  0.041379094  || Decoder Loss:  0.03289586 Validation Decoder Loss:  0.325495
Encoder Loss:  0.04133572  || Decoder Loss:  0.032819442 Validation Decoder Loss:  0.32635325
Encoder Loss:  0.041352425  || Decoder Loss:  0.032807536 Validation Decoder Loss:  0.3272848
Encoder Loss:  0.04129012  || Decoder Loss:  0.03273953 Validation Decoder Loss:  0.32507655
Encoder Loss:  0.04128706  || Decoder Loss:  0.03271036 Validation Decoder Loss:  0.32492888
Encoder Loss:  0.041244775  || Decoder Loss:  0.03263383 Validation Decoder Loss:  0.32757032
Encoder Loss:  0.04126489  || Decoder Loss:  0.03267886 Validation Decoder Loss:  0.32497966
Encoder Loss:  0.04123146  || Decoder Loss:  0.03262693 Validation Decoder Loss:  0.32553315
Encoder Loss:  0.041224126  || Decoder Loss:  0.03261574 Validation Decoder Loss:  0.3265614
Encoder Loss:  0.041216787  || Decoder Loss:  0.032610834 Validation Decoder Loss:  0.32623565
Encoder Loss:  0.041299008  || Decoder Loss:  0.032683395 Validation Decoder Loss:  0.32478845
Encoder Loss:  0.041222982  || Decoder Loss:  0.032630127 Validation Decoder Loss:  0.32578546
Encoder Loss:  0.041228905  || Decoder Loss:  0.032645956 Validation Decoder Loss:  0.32588905
Encoder Loss:  0.04121585  || Decoder Loss:  0.0326211 Validation Decoder Loss:  0.32616982
Encoder Loss:  0.04123129  || Decoder Loss:  0.032655865 Validation Decoder Loss:  0.32592222
Encoder Loss:  0.041218214  || Decoder Loss:  0.03263636 Validation Decoder Loss:  0.3260452
Encoder Loss:  0.04120237  || Decoder Loss:  0.03262078 Validation Decoder Loss:  0.32617486
Encoder Loss:  0.04123354  || Decoder Loss:  0.03267428 Validation Decoder Loss:  0.3260403
Encoder Loss:  0.0412435  || Decoder Loss:  0.03268964 Validation Decoder Loss:  0.3263482
Encoder Loss:  0.041217875  || Decoder Loss:  0.032651532 Validation Decoder Loss:  0.32603133
Encoder Loss:  0.041248642  || Decoder Loss:  0.0327167 Validation Decoder Loss:  0.32537052
Encoder Loss:  0.041242618  || Decoder Loss:  0.03272033 Validation Decoder Loss:  0.32572612
Encoder Loss:  0.041219115  || Decoder Loss:  0.032668956 Validation Decoder Loss:  0.32637906
Encoder Loss:  0.04127654  || Decoder Loss:  0.032689217 Validation Decoder Loss:  0.32586223
Encoder Loss:  0.041223053  || Decoder Loss:  0.032685388 Validation Decoder Loss:  0.32634744
Encoder Loss:  0.041238617  || Decoder Loss:  0.032707132 Validation Decoder Loss:  0.3257987
Encoder Loss:  0.041227255  || Decoder Loss:  0.032697037 Validation Decoder Loss:  0.32601506
Encoder Loss:  0.041234255  || Decoder Loss:  0.032708164 Validation Decoder Loss:  0.32588476
Encoder Loss:  0.041220203  || Decoder Loss:  0.03266937 Validation Decoder Loss:  0.3261487
Encoder Loss:  0.041289467  || Decoder Loss:  0.032713246 Validation Decoder Loss:  0.3259858
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3259858
Model: "sequential_889"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_632 (Conv3D (None, 172, 10, 20, 1)    219       
_________________________________________________________________
dropout_1295 (Dropout)       (None, 172, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_633 (Conv3D (None, 220, 11, 20, 1)    99        
_________________________________________________________________
reshape_227 (Reshape)        (None, 2420, 20, 1)       0         
=================================================================
Total params: 318
Trainable params: 318
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_891"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_433 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_1297 (Dropout)       (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_434 (Conv2D)          (None, 2420, 20, 1)       182       
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_892"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_433 (Conv2D (None, 2540, 20, 1)       122       
_________________________________________________________________
dropout_1299 (Dropout)       (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_434 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12614879  || Decoder Loss:  0.11690547 Validation Decoder Loss:  0.34380317
Encoder Loss:  0.037095472  || Decoder Loss:  0.035029426 Validation Decoder Loss:  0.33162338
Encoder Loss:  0.035916597  || Decoder Loss:  0.034140233 Validation Decoder Loss:  0.3322752
Encoder Loss:  0.03570925  || Decoder Loss:  0.033929802 Validation Decoder Loss:  0.33313936
Encoder Loss:  0.035656556  || Decoder Loss:  0.033874128 Validation Decoder Loss:  0.3331797
Encoder Loss:  0.035635374  || Decoder Loss:  0.03385515 Validation Decoder Loss:  0.33333096
Encoder Loss:  0.03565857  || Decoder Loss:  0.0338832 Validation Decoder Loss:  0.33182913
Encoder Loss:  0.035677705  || Decoder Loss:  0.033906594 Validation Decoder Loss:  0.33303925
Encoder Loss:  0.035686165  || Decoder Loss:  0.033920847 Validation Decoder Loss:  0.33353832
Encoder Loss:  0.035710998  || Decoder Loss:  0.033948958 Validation Decoder Loss:  0.33366305
Encoder Loss:  0.03571796  || Decoder Loss:  0.033957694 Validation Decoder Loss:  0.33364335
Encoder Loss:  0.03571759  || Decoder Loss:  0.033953995 Validation Decoder Loss:  0.33375883
Encoder Loss:  0.03564951  || Decoder Loss:  0.033882614 Validation Decoder Loss:  0.3336854
Encoder Loss:  0.035636064  || Decoder Loss:  0.03387712 Validation Decoder Loss:  0.33403414
Encoder Loss:  0.035603322  || Decoder Loss:  0.033833466 Validation Decoder Loss:  0.33379966
Encoder Loss:  0.035514727  || Decoder Loss:  0.03373978 Validation Decoder Loss:  0.33394793
Encoder Loss:  0.035505075  || Decoder Loss:  0.03372978 Validation Decoder Loss:  0.33374697
Encoder Loss:  0.035450652  || Decoder Loss:  0.03367197 Validation Decoder Loss:  0.33374578
Encoder Loss:  0.03540593  || Decoder Loss:  0.033622805 Validation Decoder Loss:  0.33371413
Encoder Loss:  0.035410535  || Decoder Loss:  0.033628985 Validation Decoder Loss:  0.3340379
Encoder Loss:  0.035356626  || Decoder Loss:  0.033568453 Validation Decoder Loss:  0.33419514
Encoder Loss:  0.035346583  || Decoder Loss:  0.033560324 Validation Decoder Loss:  0.3340643
Encoder Loss:  0.035339233  || Decoder Loss:  0.033550546 Validation Decoder Loss:  0.3341229
Encoder Loss:  0.035281535  || Decoder Loss:  0.03348659 Validation Decoder Loss:  0.33466333
Encoder Loss:  0.035287775  || Decoder Loss:  0.03349337 Validation Decoder Loss:  0.33507484
Encoder Loss:  0.035266683  || Decoder Loss:  0.033470035 Validation Decoder Loss:  0.3349319
Encoder Loss:  0.03522961  || Decoder Loss:  0.03342947 Validation Decoder Loss:  0.33537516
Encoder Loss:  0.035182115  || Decoder Loss:  0.033378106 Validation Decoder Loss:  0.33564013
Encoder Loss:  0.035184503  || Decoder Loss:  0.033378724 Validation Decoder Loss:  0.33551094
Encoder Loss:  0.035184905  || Decoder Loss:  0.033379596 Validation Decoder Loss:  0.3351287
Encoder Loss:  0.035167  || Decoder Loss:  0.033359464 Validation Decoder Loss:  0.3369799
Encoder Loss:  0.035137337  || Decoder Loss:  0.03332647 Validation Decoder Loss:  0.3371868
Encoder Loss:  0.035108365  || Decoder Loss:  0.033293203 Validation Decoder Loss:  0.33750278
Encoder Loss:  0.03507879  || Decoder Loss:  0.033261508 Validation Decoder Loss:  0.3370901
Encoder Loss:  0.035048377  || Decoder Loss:  0.033226747 Validation Decoder Loss:  0.336715
Encoder Loss:  0.035028648  || Decoder Loss:  0.033205945 Validation Decoder Loss:  0.33799836
Encoder Loss:  0.03501261  || Decoder Loss:  0.03318896 Validation Decoder Loss:  0.33760244
Encoder Loss:  0.03498989  || Decoder Loss:  0.033163562 Validation Decoder Loss:  0.33801186
Encoder Loss:  0.034967788  || Decoder Loss:  0.03313996 Validation Decoder Loss:  0.33858883
Encoder Loss:  0.03496046  || Decoder Loss:  0.033129815 Validation Decoder Loss:  0.33959106
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3395911
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.328744113445282 2
[(220, 11, 20, 1)] [(2420, 20, 1)]
[(2420, 20, 1)] [(2420, 20, 1)]
[(2607, 20, 1)] [(2420, 20, 1)]
