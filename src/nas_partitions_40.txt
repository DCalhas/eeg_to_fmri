Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(40, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(80, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(120, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(160, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(200, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(240, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(280, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(320, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(360, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(400, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(40, 2607, 8)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-12-10 09:25:01.555837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-12-10 09:25:01.559157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-12-10 09:25:01.559306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-10 09:25:01.560418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-12-10 09:25:01.561568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-12-10 09:25:01.561765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-12-10 09:25:01.562768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-12-10 09:25:01.563288: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-12-10 09:25:01.565774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-10 09:25:01.566962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-12-10 09:25:01.567158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-12-10 09:25:01.591826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-12-10 09:25:01.592484: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca07321570 executing computations on platform Host. Devices:
2019-12-10 09:25:01.592516: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-10 09:25:01.593361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-12-10 09:25:01.593394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-10 09:25:01.593404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-12-10 09:25:01.593413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-12-10 09:25:01.593422: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-12-10 09:25:01.593431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-12-10 09:25:01.593440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-12-10 09:25:01.593449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-10 09:25:01.594807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-12-10 09:25:01.594832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-12-10 09:25:01.662294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-10 09:25:01.662324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-12-10 09:25:01.662329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-12-10 09:25:01.664133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-12-10 09:25:01.665270: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca07b5df30 executing computations on platform CUDA. Devices:
2019-12-10 09:25:01.665288: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-12-10 09:25:02.121934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(80, 2607, 8)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 86, 20, 8, 1)      369       
_________________________________________________________________
reshape (Reshape)            (None, 1720, 8, 1)        0         
=================================================================
Total params: 369
Trainable params: 369
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1720, 8, 1)        889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 8, 1)        889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11306283  || Decoder Loss:  0.008657505 Validation Decoder Loss:  0.7583134
Encoder Loss:  0.090031244  || Decoder Loss:  0.007421025 Validation Decoder Loss:  0.76574653
Encoder Loss:  0.066808954  || Decoder Loss:  0.0035468005 Validation Decoder Loss:  0.76748693
Encoder Loss:  0.05493556  || Decoder Loss:  0.0035092202 Validation Decoder Loss:  0.76879996
Encoder Loss:  0.049193967  || Decoder Loss:  0.00350117 Validation Decoder Loss:  0.76998335
Encoder Loss:  0.045920443  || Decoder Loss:  0.0034941484 Validation Decoder Loss:  0.7710655
Encoder Loss:  0.04331588  || Decoder Loss:  0.003484651 Validation Decoder Loss:  0.77206665
Encoder Loss:  0.040977836  || Decoder Loss:  0.0034736348 Validation Decoder Loss:  0.77291524
Encoder Loss:  0.038914207  || Decoder Loss:  0.0034629132 Validation Decoder Loss:  0.7736156
Encoder Loss:  0.036648605  || Decoder Loss:  0.003448989 Validation Decoder Loss:  0.7741873
Encoder Loss:  0.033711586  || Decoder Loss:  0.003432855 Validation Decoder Loss:  0.7746523
Encoder Loss:  0.03171918  || Decoder Loss:  0.0034182186 Validation Decoder Loss:  0.7750576
Encoder Loss:  0.030135782  || Decoder Loss:  0.0034027009 Validation Decoder Loss:  0.77538854
Encoder Loss:  0.028999995  || Decoder Loss:  0.0033870186 Validation Decoder Loss:  0.77568245
Encoder Loss:  0.027890585  || Decoder Loss:  0.0033716797 Validation Decoder Loss:  0.7759065
Encoder Loss:  0.026894018  || Decoder Loss:  0.0033598389 Validation Decoder Loss:  0.77611053
Encoder Loss:  0.026141733  || Decoder Loss:  0.0033494919 Validation Decoder Loss:  0.7763364
Encoder Loss:  0.025413916  || Decoder Loss:  0.0033404785 Validation Decoder Loss:  0.7766149
Encoder Loss:  0.024730576  || Decoder Loss:  0.0033313325 Validation Decoder Loss:  0.7770108
Encoder Loss:  0.023944635  || Decoder Loss:  0.0033202625 Validation Decoder Loss:  0.77776587
Encoder Loss:  0.023020843  || Decoder Loss:  0.0033162516 Validation Decoder Loss:  0.77872956
Encoder Loss:  0.022219168  || Decoder Loss:  0.0033177796 Validation Decoder Loss:  0.7793005
Encoder Loss:  0.021316826  || Decoder Loss:  0.0033196283 Validation Decoder Loss:  0.7804501
Encoder Loss:  0.02038358  || Decoder Loss:  0.0033169738 Validation Decoder Loss:  0.7814338
Encoder Loss:  0.019633744  || Decoder Loss:  0.00331167 Validation Decoder Loss:  0.78199905
Encoder Loss:  0.019001752  || Decoder Loss:  0.0033008896 Validation Decoder Loss:  0.78215045
Encoder Loss:  0.018388301  || Decoder Loss:  0.0032871554 Validation Decoder Loss:  0.78204775
Encoder Loss:  0.017780835  || Decoder Loss:  0.0032732452 Validation Decoder Loss:  0.7818601
Encoder Loss:  0.017257636  || Decoder Loss:  0.0032594863 Validation Decoder Loss:  0.7816223
Encoder Loss:  0.01680184  || Decoder Loss:  0.003245144 Validation Decoder Loss:  0.7813681
Encoder Loss:  0.016401017  || Decoder Loss:  0.0032311308 Validation Decoder Loss:  0.7811197
Encoder Loss:  0.016052367  || Decoder Loss:  0.0032181651 Validation Decoder Loss:  0.7807638
Encoder Loss:  0.015733957  || Decoder Loss:  0.0032050365 Validation Decoder Loss:  0.7803116
Encoder Loss:  0.015333147  || Decoder Loss:  0.003193956 Validation Decoder Loss:  0.77990687
Encoder Loss:  0.014927128  || Decoder Loss:  0.0031857442 Validation Decoder Loss:  0.7795118
Encoder Loss:  0.014710182  || Decoder Loss:  0.00317908 Validation Decoder Loss:  0.7791171
Encoder Loss:  0.014540194  || Decoder Loss:  0.0031742386 Validation Decoder Loss:  0.7786866
Encoder Loss:  0.014389929  || Decoder Loss:  0.0031700563 Validation Decoder Loss:  0.77822024
Encoder Loss:  0.014253396  || Decoder Loss:  0.0031664209 Validation Decoder Loss:  0.7777024
Encoder Loss:  0.014129389  || Decoder Loss:  0.0031628455 Validation Decoder Loss:  0.7771378
Model: bold_synthesis_net_lr_0.0006740650133742933 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7771378
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 95, 6, 8, 1)       65        
_________________________________________________________________
reshape_1 (Reshape)          (None, 570, 8, 1)         0         
=================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 570, 8, 1)         901       
=================================================================
Total params: 901
Trainable params: 901
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 8, 1)        901       
=================================================================
Total params: 901
Trainable params: 901
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06740128  || Decoder Loss:  0.00866961 Validation Decoder Loss:  0.7595356
Encoder Loss:  0.065347314  || Decoder Loss:  0.008646404 Validation Decoder Loss:  0.7594024
Encoder Loss:  0.063440315  || Decoder Loss:  0.008622398 Validation Decoder Loss:  0.759307
Encoder Loss:  0.061717108  || Decoder Loss:  0.008595843 Validation Decoder Loss:  0.75922984
Encoder Loss:  0.06020888  || Decoder Loss:  0.008564315 Validation Decoder Loss:  0.7591461
Encoder Loss:  0.058976665  || Decoder Loss:  0.008523651 Validation Decoder Loss:  0.7590449
Encoder Loss:  0.0577233  || Decoder Loss:  0.008466822 Validation Decoder Loss:  0.7589631
Encoder Loss:  0.056344822  || Decoder Loss:  0.008382322 Validation Decoder Loss:  0.7589856
Encoder Loss:  0.054698233  || Decoder Loss:  0.008249178 Validation Decoder Loss:  0.75921774
Encoder Loss:  0.052892957  || Decoder Loss:  0.008021228 Validation Decoder Loss:  0.7597989
Encoder Loss:  0.050769188  || Decoder Loss:  0.0075743515 Validation Decoder Loss:  0.76101106
Encoder Loss:  0.048308533  || Decoder Loss:  0.0064460547 Validation Decoder Loss:  0.76409495
Encoder Loss:  0.045162935  || Decoder Loss:  0.004261214 Validation Decoder Loss:  0.76807404
Encoder Loss:  0.043217506  || Decoder Loss:  0.0034353163 Validation Decoder Loss:  0.7689828
Encoder Loss:  0.04197905  || Decoder Loss:  0.003431788 Validation Decoder Loss:  0.76913905
Encoder Loss:  0.040902477  || Decoder Loss:  0.003431437 Validation Decoder Loss:  0.7693121
Encoder Loss:  0.039812397  || Decoder Loss:  0.0034312508 Validation Decoder Loss:  0.76948947
Encoder Loss:  0.038967174  || Decoder Loss:  0.003430969 Validation Decoder Loss:  0.7696786
Encoder Loss:  0.0379131  || Decoder Loss:  0.0034307647 Validation Decoder Loss:  0.7698761
Encoder Loss:  0.03677106  || Decoder Loss:  0.003430901 Validation Decoder Loss:  0.77008164
Encoder Loss:  0.03590871  || Decoder Loss:  0.0034311751 Validation Decoder Loss:  0.7702847
Encoder Loss:  0.034893136  || Decoder Loss:  0.0034314399 Validation Decoder Loss:  0.77048963
Encoder Loss:  0.034006856  || Decoder Loss:  0.0034316273 Validation Decoder Loss:  0.77069855
Encoder Loss:  0.033191625  || Decoder Loss:  0.003431925 Validation Decoder Loss:  0.7709027
Encoder Loss:  0.032707073  || Decoder Loss:  0.003432106 Validation Decoder Loss:  0.77110964
Encoder Loss:  0.032271035  || Decoder Loss:  0.0034322685 Validation Decoder Loss:  0.7713155
Encoder Loss:  0.0318311  || Decoder Loss:  0.0034322967 Validation Decoder Loss:  0.77152145
Encoder Loss:  0.03143071  || Decoder Loss:  0.0034321793 Validation Decoder Loss:  0.7717277
Encoder Loss:  0.031070763  || Decoder Loss:  0.003432038 Validation Decoder Loss:  0.77193093
Encoder Loss:  0.030734973  || Decoder Loss:  0.0034318797 Validation Decoder Loss:  0.77213264
Encoder Loss:  0.030403368  || Decoder Loss:  0.0034316361 Validation Decoder Loss:  0.772331
Encoder Loss:  0.029809715  || Decoder Loss:  0.0034314394 Validation Decoder Loss:  0.7725236
Encoder Loss:  0.029302925  || Decoder Loss:  0.0034312063 Validation Decoder Loss:  0.7727181
Encoder Loss:  0.028950619  || Decoder Loss:  0.003430965 Validation Decoder Loss:  0.7729091
Encoder Loss:  0.028376333  || Decoder Loss:  0.0034307279 Validation Decoder Loss:  0.77309006
Encoder Loss:  0.027548207  || Decoder Loss:  0.0034304564 Validation Decoder Loss:  0.7732617
Encoder Loss:  0.026953578  || Decoder Loss:  0.0034301605 Validation Decoder Loss:  0.7734339
Encoder Loss:  0.026608087  || Decoder Loss:  0.003429818 Validation Decoder Loss:  0.77359873
Encoder Loss:  0.026288373  || Decoder Loss:  0.0034294236 Validation Decoder Loss:  0.77375674
Encoder Loss:  0.02602493  || Decoder Loss:  0.0034289907 Validation Decoder Loss:  0.77390754
Model: bold_synthesis_net_lr_0.00019258603149001523 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.77390754
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 81, 20, 8, 1)      145       
_________________________________________________________________
reshape_2 (Reshape)          (None, 1620, 8, 1)        0         
=================================================================
Total params: 145
Trainable params: 145
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 1620, 8, 1)        989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 8, 1)        989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17733164  || Decoder Loss:  0.008643542 Validation Decoder Loss:  0.76356196
Encoder Loss:  0.17094946  || Decoder Loss:  0.008637417 Validation Decoder Loss:  0.76321673
Encoder Loss:  0.16393599  || Decoder Loss:  0.008631114 Validation Decoder Loss:  0.7628915
Encoder Loss:  0.1561012  || Decoder Loss:  0.008624022 Validation Decoder Loss:  0.7625996
Encoder Loss:  0.14896782  || Decoder Loss:  0.008615019 Validation Decoder Loss:  0.762343
Encoder Loss:  0.14287212  || Decoder Loss:  0.008601817 Validation Decoder Loss:  0.76211685
Encoder Loss:  0.13803348  || Decoder Loss:  0.008579254 Validation Decoder Loss:  0.7619004
Encoder Loss:  0.13381836  || Decoder Loss:  0.00853421 Validation Decoder Loss:  0.7616724
Encoder Loss:  0.12976478  || Decoder Loss:  0.008437803 Validation Decoder Loss:  0.7615173
Encoder Loss:  0.12514934  || Decoder Loss:  0.008250067 Validation Decoder Loss:  0.7615292
Encoder Loss:  0.11940974  || Decoder Loss:  0.007955747 Validation Decoder Loss:  0.76160514
Encoder Loss:  0.113848545  || Decoder Loss:  0.0076111984 Validation Decoder Loss:  0.7614218
Encoder Loss:  0.1092066  || Decoder Loss:  0.0073302872 Validation Decoder Loss:  0.7609812
Encoder Loss:  0.10505061  || Decoder Loss:  0.007155049 Validation Decoder Loss:  0.7605294
Encoder Loss:  0.10108884  || Decoder Loss:  0.0070465715 Validation Decoder Loss:  0.76013595
Encoder Loss:  0.09680627  || Decoder Loss:  0.0069726054 Validation Decoder Loss:  0.75980985
Encoder Loss:  0.09093226  || Decoder Loss:  0.0069159847 Validation Decoder Loss:  0.7595691
Encoder Loss:  0.08327315  || Decoder Loss:  0.0068644024 Validation Decoder Loss:  0.7594561
Encoder Loss:  0.07870285  || Decoder Loss:  0.006804639 Validation Decoder Loss:  0.7595205
Encoder Loss:  0.07609734  || Decoder Loss:  0.006720408 Validation Decoder Loss:  0.75978446
Encoder Loss:  0.074299246  || Decoder Loss:  0.006585992 Validation Decoder Loss:  0.76025033
Encoder Loss:  0.07263232  || Decoder Loss:  0.0063685165 Validation Decoder Loss:  0.76091474
Encoder Loss:  0.070816524  || Decoder Loss:  0.0060305377 Validation Decoder Loss:  0.7617427
Encoder Loss:  0.0682988  || Decoder Loss:  0.0055249794 Validation Decoder Loss:  0.7629247
Encoder Loss:  0.0655853  || Decoder Loss:  0.004261306 Validation Decoder Loss:  0.7662664
Encoder Loss:  0.06343995  || Decoder Loss:  0.0035310613 Validation Decoder Loss:  0.766747
Encoder Loss:  0.06178834  || Decoder Loss:  0.0035209153 Validation Decoder Loss:  0.767038
Encoder Loss:  0.060397036  || Decoder Loss:  0.003509819 Validation Decoder Loss:  0.7673508
Encoder Loss:  0.05916122  || Decoder Loss:  0.0034996588 Validation Decoder Loss:  0.76767266
Encoder Loss:  0.058011692  || Decoder Loss:  0.0034908871 Validation Decoder Loss:  0.76798576
Encoder Loss:  0.056815192  || Decoder Loss:  0.00348291 Validation Decoder Loss:  0.768291
Encoder Loss:  0.054848146  || Decoder Loss:  0.0034753648 Validation Decoder Loss:  0.7686128
Encoder Loss:  0.05294725  || Decoder Loss:  0.0034685151 Validation Decoder Loss:  0.7689373
Encoder Loss:  0.05171584  || Decoder Loss:  0.0034623444 Validation Decoder Loss:  0.769243
Encoder Loss:  0.050789  || Decoder Loss:  0.003456823 Validation Decoder Loss:  0.7695304
Encoder Loss:  0.049939904  || Decoder Loss:  0.0034519762 Validation Decoder Loss:  0.76980394
Encoder Loss:  0.049134992  || Decoder Loss:  0.003447733 Validation Decoder Loss:  0.7700609
Encoder Loss:  0.04836378  || Decoder Loss:  0.0034438192 Validation Decoder Loss:  0.77030474
Encoder Loss:  0.047582794  || Decoder Loss:  0.003440516 Validation Decoder Loss:  0.7705305
Encoder Loss:  0.04649926  || Decoder Loss:  0.0034377743 Validation Decoder Loss:  0.77073777
Model: bold_synthesis_net_lr_0.00010351905222384826 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.77073777
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 65, 8, 8, 1)       9         
_________________________________________________________________
reshape_3 (Reshape)          (None, 520, 8, 1)         0         
=================================================================
Total params: 9
Trainable params: 9
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 520, 8, 1)         1570      
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 8, 1)        2089      
=================================================================
Total params: 2,089
Trainable params: 2,089
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.008607709 Validation Decoder Loss:  0.7648307
Encoder Loss:  0.17063923  || Decoder Loss:  0.006786105 Validation Decoder Loss:  0.76679593
Encoder Loss:  0.17029305  || Decoder Loss:  0.0062563876 Validation Decoder Loss:  0.76725465
Encoder Loss:  0.17002259  || Decoder Loss:  0.00584281 Validation Decoder Loss:  0.7646346
Encoder Loss:  0.16962686  || Decoder Loss:  0.005237622 Validation Decoder Loss:  0.7645138
Encoder Loss:  0.16943099  || Decoder Loss:  0.004938175 Validation Decoder Loss:  0.7645278
Encoder Loss:  0.16929705  || Decoder Loss:  0.004733168 Validation Decoder Loss:  0.7642328
Encoder Loss:  0.16915943  || Decoder Loss:  0.0045224098 Validation Decoder Loss:  0.7639081
Encoder Loss:  0.16905813  || Decoder Loss:  0.004367483 Validation Decoder Loss:  0.7636405
Encoder Loss:  0.16897672  || Decoder Loss:  0.0042430125 Validation Decoder Loss:  0.76341707
Encoder Loss:  0.16890183  || Decoder Loss:  0.0041285055 Validation Decoder Loss:  0.7632305
Encoder Loss:  0.16883306  || Decoder Loss:  0.004023387 Validation Decoder Loss:  0.76307493
Encoder Loss:  0.16877021  || Decoder Loss:  0.003927331 Validation Decoder Loss:  0.76294243
Encoder Loss:  0.16871464  || Decoder Loss:  0.0038421794 Validation Decoder Loss:  0.7628519
Encoder Loss:  0.16867204  || Decoder Loss:  0.0037769813 Validation Decoder Loss:  0.7628068
Encoder Loss:  0.16864392  || Decoder Loss:  0.0037340675 Validation Decoder Loss:  0.76276237
Encoder Loss:  0.1686209  || Decoder Loss:  0.0036987746 Validation Decoder Loss:  0.76268584
Encoder Loss:  0.16859844  || Decoder Loss:  0.0036645348 Validation Decoder Loss:  0.76259875
Encoder Loss:  0.16857752  || Decoder Loss:  0.003632392 Validation Decoder Loss:  0.76250875
Encoder Loss:  0.16855977  || Decoder Loss:  0.0036054698 Validation Decoder Loss:  0.7624048
Encoder Loss:  0.16854814  || Decoder Loss:  0.0035873721 Validation Decoder Loss:  0.7623323
Encoder Loss:  0.16853654  || Decoder Loss:  0.003569977 Validation Decoder Loss:  0.76226187
Encoder Loss:  0.16852567  || Decoder Loss:  0.003553353 Validation Decoder Loss:  0.7621949
Encoder Loss:  0.16851562  || Decoder Loss:  0.0035378162 Validation Decoder Loss:  0.76213187
Encoder Loss:  0.16850631  || Decoder Loss:  0.003523343 Validation Decoder Loss:  0.7620744
Encoder Loss:  0.16849685  || Decoder Loss:  0.003509191 Validation Decoder Loss:  0.76202613
Encoder Loss:  0.16848594  || Decoder Loss:  0.0034923244 Validation Decoder Loss:  0.7619928
Encoder Loss:  0.16847767  || Decoder Loss:  0.003479522 Validation Decoder Loss:  0.7619604
Encoder Loss:  0.16847153  || Decoder Loss:  0.0034703366 Validation Decoder Loss:  0.76192266
Encoder Loss:  0.1684673  || Decoder Loss:  0.0034636166 Validation Decoder Loss:  0.76193017
Encoder Loss:  0.16846472  || Decoder Loss:  0.0034596357 Validation Decoder Loss:  0.7618756
Encoder Loss:  0.16846265  || Decoder Loss:  0.0034567718 Validation Decoder Loss:  0.76189536
Encoder Loss:  0.16846171  || Decoder Loss:  0.0034544833 Validation Decoder Loss:  0.76185167
Encoder Loss:  0.16845955  || Decoder Loss:  0.0034518612 Validation Decoder Loss:  0.76186746
Encoder Loss:  0.16845804  || Decoder Loss:  0.003449758 Validation Decoder Loss:  0.76182824
Encoder Loss:  0.16845678  || Decoder Loss:  0.0034476055 Validation Decoder Loss:  0.7618362
Encoder Loss:  0.16845539  || Decoder Loss:  0.0034454449 Validation Decoder Loss:  0.7618065
Encoder Loss:  0.16845433  || Decoder Loss:  0.0034437603 Validation Decoder Loss:  0.7618077
Encoder Loss:  0.16845307  || Decoder Loss:  0.0034416863 Validation Decoder Loss:  0.76179475
Encoder Loss:  0.16845205  || Decoder Loss:  0.0034399407 Validation Decoder Loss:  0.7617869
Model: bold_synthesis_net_lr_0.0008754070440259004 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7617869
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 121, 20, 8, 1)     697       
_________________________________________________________________
reshape_4 (Reshape)          (None, 2420, 8, 1)        0         
=================================================================
Total params: 697
Trainable params: 697
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18846701  || Decoder Loss:  0.008948981 Validation Decoder Loss:  0.7511989
Encoder Loss:  0.1845645  || Decoder Loss:  0.008952308 Validation Decoder Loss:  0.75161654
Encoder Loss:  0.18129814  || Decoder Loss:  0.008953259 Validation Decoder Loss:  0.7520478
Encoder Loss:  0.17851628  || Decoder Loss:  0.008951665 Validation Decoder Loss:  0.75248903
Encoder Loss:  0.17597623  || Decoder Loss:  0.008947287 Validation Decoder Loss:  0.752939
Encoder Loss:  0.17364417  || Decoder Loss:  0.008939523 Validation Decoder Loss:  0.7533994
Encoder Loss:  0.17151764  || Decoder Loss:  0.008926879 Validation Decoder Loss:  0.7538773
Encoder Loss:  0.16953707  || Decoder Loss:  0.008905534 Validation Decoder Loss:  0.7543874
Encoder Loss:  0.16767204  || Decoder Loss:  0.008865603 Validation Decoder Loss:  0.7549605
Encoder Loss:  0.16587757  || Decoder Loss:  0.008781715 Validation Decoder Loss:  0.755648
Encoder Loss:  0.16410552  || Decoder Loss:  0.008599257 Validation Decoder Loss:  0.75649333
Encoder Loss:  0.16233586  || Decoder Loss:  0.008248271 Validation Decoder Loss:  0.7573615
Encoder Loss:  0.1605999  || Decoder Loss:  0.007711747 Validation Decoder Loss:  0.7575548
Encoder Loss:  0.15886348  || Decoder Loss:  0.0067850873 Validation Decoder Loss:  0.75354904
Encoder Loss:  0.15707903  || Decoder Loss:  0.0054656477 Validation Decoder Loss:  0.74549186
Encoder Loss:  0.15536578  || Decoder Loss:  0.004738962 Validation Decoder Loss:  0.7409782
Encoder Loss:  0.1536391  || Decoder Loss:  0.004437987 Validation Decoder Loss:  0.7386531
Encoder Loss:  0.15209424  || Decoder Loss:  0.004352199 Validation Decoder Loss:  0.7378636
Encoder Loss:  0.15064886  || Decoder Loss:  0.0043149902 Validation Decoder Loss:  0.7375641
Encoder Loss:  0.14918749  || Decoder Loss:  0.0042942376 Validation Decoder Loss:  0.73763484
Encoder Loss:  0.14774421  || Decoder Loss:  0.0042773434 Validation Decoder Loss:  0.7378246
Encoder Loss:  0.14636691  || Decoder Loss:  0.0042600636 Validation Decoder Loss:  0.7380437
Encoder Loss:  0.14499995  || Decoder Loss:  0.0042428104 Validation Decoder Loss:  0.7382505
Encoder Loss:  0.14371015  || Decoder Loss:  0.0042261807 Validation Decoder Loss:  0.7384621
Encoder Loss:  0.14258584  || Decoder Loss:  0.00420931 Validation Decoder Loss:  0.7386454
Encoder Loss:  0.14156176  || Decoder Loss:  0.004192091 Validation Decoder Loss:  0.73880315
Encoder Loss:  0.14059883  || Decoder Loss:  0.0041756076 Validation Decoder Loss:  0.7389557
Encoder Loss:  0.1396801  || Decoder Loss:  0.004158349 Validation Decoder Loss:  0.7390654
Encoder Loss:  0.13879678  || Decoder Loss:  0.004140847 Validation Decoder Loss:  0.7391202
Encoder Loss:  0.13794337  || Decoder Loss:  0.004124073 Validation Decoder Loss:  0.7391785
Encoder Loss:  0.13711405  || Decoder Loss:  0.004106777 Validation Decoder Loss:  0.7392176
Encoder Loss:  0.13630088  || Decoder Loss:  0.004089439 Validation Decoder Loss:  0.7392415
Encoder Loss:  0.1354869  || Decoder Loss:  0.004070809 Validation Decoder Loss:  0.739216
Encoder Loss:  0.13462852  || Decoder Loss:  0.0040512946 Validation Decoder Loss:  0.7391053
Encoder Loss:  0.1336777  || Decoder Loss:  0.004031013 Validation Decoder Loss:  0.7389052
Encoder Loss:  0.13266723  || Decoder Loss:  0.00401009 Validation Decoder Loss:  0.738612
Encoder Loss:  0.13160492  || Decoder Loss:  0.0039899596 Validation Decoder Loss:  0.7383287
Encoder Loss:  0.1305935  || Decoder Loss:  0.0039709457 Validation Decoder Loss:  0.7380551
Encoder Loss:  0.12968276  || Decoder Loss:  0.0039537833 Validation Decoder Loss:  0.7378075
Encoder Loss:  0.12887971  || Decoder Loss:  0.0039379476 Validation Decoder Loss:  0.7375497
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: bold_synthesis_net_lr_0.0004006277546164723 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7375497
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 220, 11, 8, 1)     218       
_________________________________________________________________
reshape_5 (Reshape)          (None, 2420, 8, 1)        0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20698166  || Decoder Loss:  0.008638841 Validation Decoder Loss:  0.76225543
Encoder Loss:  0.20187607  || Decoder Loss:  0.008632721 Validation Decoder Loss:  0.76180196
Encoder Loss:  0.19719477  || Decoder Loss:  0.0086260075 Validation Decoder Loss:  0.7613763
Encoder Loss:  0.192886  || Decoder Loss:  0.008617936 Validation Decoder Loss:  0.7609801
Encoder Loss:  0.18888064  || Decoder Loss:  0.00860702 Validation Decoder Loss:  0.76060784
Encoder Loss:  0.18524529  || Decoder Loss:  0.008590077 Validation Decoder Loss:  0.76024157
Encoder Loss:  0.18187347  || Decoder Loss:  0.008559045 Validation Decoder Loss:  0.7598337
Encoder Loss:  0.17860456  || Decoder Loss:  0.008489392 Validation Decoder Loss:  0.75930357
Encoder Loss:  0.1751069  || Decoder Loss:  0.008300833 Validation Decoder Loss:  0.7587909
Encoder Loss:  0.17115362  || Decoder Loss:  0.0077895937 Validation Decoder Loss:  0.75839263
Encoder Loss:  0.1675822  || Decoder Loss:  0.0066876775 Validation Decoder Loss:  0.7548215
Encoder Loss:  0.16448957  || Decoder Loss:  0.005303428 Validation Decoder Loss:  0.7463586
Encoder Loss:  0.16184157  || Decoder Loss:  0.0043999045 Validation Decoder Loss:  0.73848414
Encoder Loss:  0.15955916  || Decoder Loss:  0.004027553 Validation Decoder Loss:  0.72995126
Encoder Loss:  0.15748726  || Decoder Loss:  0.0038468933 Validation Decoder Loss:  0.72040904
Encoder Loss:  0.15555261  || Decoder Loss:  0.0037044766 Validation Decoder Loss:  0.7088451
Encoder Loss:  0.15372358  || Decoder Loss:  0.0035894068 Validation Decoder Loss:  0.6994154
Encoder Loss:  0.15198246  || Decoder Loss:  0.0035281011 Validation Decoder Loss:  0.6934739
Encoder Loss:  0.15031849  || Decoder Loss:  0.003466551 Validation Decoder Loss:  0.688348
Encoder Loss:  0.14868483  || Decoder Loss:  0.0034157222 Validation Decoder Loss:  0.6849799
Encoder Loss:  0.14705667  || Decoder Loss:  0.003374168 Validation Decoder Loss:  0.681731
Encoder Loss:  0.14544739  || Decoder Loss:  0.0033426248 Validation Decoder Loss:  0.67882484
Encoder Loss:  0.14384782  || Decoder Loss:  0.0033170301 Validation Decoder Loss:  0.6762079
Encoder Loss:  0.14228998  || Decoder Loss:  0.0032918656 Validation Decoder Loss:  0.67280394
Encoder Loss:  0.14077596  || Decoder Loss:  0.0032652651 Validation Decoder Loss:  0.6685194
Encoder Loss:  0.13921456  || Decoder Loss:  0.0032374645 Validation Decoder Loss:  0.66384697
Encoder Loss:  0.13750787  || Decoder Loss:  0.0032058803 Validation Decoder Loss:  0.65874267
Encoder Loss:  0.13568313  || Decoder Loss:  0.0031673457 Validation Decoder Loss:  0.65124494
Encoder Loss:  0.13389659  || Decoder Loss:  0.003106627 Validation Decoder Loss:  0.63741493
Encoder Loss:  0.13234955  || Decoder Loss:  0.0030430537 Validation Decoder Loss:  0.62739044
Encoder Loss:  0.13095477  || Decoder Loss:  0.0030087542 Validation Decoder Loss:  0.6258153
Encoder Loss:  0.1296525  || Decoder Loss:  0.0029813435 Validation Decoder Loss:  0.6258879
Encoder Loss:  0.12837875  || Decoder Loss:  0.0029585925 Validation Decoder Loss:  0.6265036
Encoder Loss:  0.12710857  || Decoder Loss:  0.0029402557 Validation Decoder Loss:  0.6267493
Encoder Loss:  0.12589717  || Decoder Loss:  0.0029268856 Validation Decoder Loss:  0.6273854
Encoder Loss:  0.12474146  || Decoder Loss:  0.002915766 Validation Decoder Loss:  0.62757945
Encoder Loss:  0.123659216  || Decoder Loss:  0.0029086256 Validation Decoder Loss:  0.6280036
Encoder Loss:  0.122648805  || Decoder Loss:  0.0029016235 Validation Decoder Loss:  0.6276607
Encoder Loss:  0.12169513  || Decoder Loss:  0.0028969403 Validation Decoder Loss:  0.6275578
Encoder Loss:  0.120802045  || Decoder Loss:  0.0028934344 Validation Decoder Loss:  0.6279223
Model: bold_synthesis_net_lr_0.0004006296000428298 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.6279223
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 220, 11, 8, 1)     283       
_________________________________________________________________
reshape_6 (Reshape)          (None, 2420, 8, 1)        0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21541803  || Decoder Loss:  0.0087068705 Validation Decoder Loss:  0.7555297
Encoder Loss:  0.21160313  || Decoder Loss:  0.008712743 Validation Decoder Loss:  0.7557202
Encoder Loss:  0.20817783  || Decoder Loss:  0.008718033 Validation Decoder Loss:  0.75593954
Encoder Loss:  0.20513768  || Decoder Loss:  0.008722241 Validation Decoder Loss:  0.7561809
Encoder Loss:  0.20238513  || Decoder Loss:  0.008725081 Validation Decoder Loss:  0.7564381
Encoder Loss:  0.199828  || Decoder Loss:  0.008726106 Validation Decoder Loss:  0.7567076
Encoder Loss:  0.19737297  || Decoder Loss:  0.008724375 Validation Decoder Loss:  0.7569891
Encoder Loss:  0.19490728  || Decoder Loss:  0.008717701 Validation Decoder Loss:  0.757288
Encoder Loss:  0.19240153  || Decoder Loss:  0.008700325 Validation Decoder Loss:  0.7576194
Encoder Loss:  0.18982595  || Decoder Loss:  0.008656738 Validation Decoder Loss:  0.7580057
Encoder Loss:  0.18734522  || Decoder Loss:  0.008550677 Validation Decoder Loss:  0.7584542
Encoder Loss:  0.18512425  || Decoder Loss:  0.008332081 Validation Decoder Loss:  0.75886536
Encoder Loss:  0.18307371  || Decoder Loss:  0.008025137 Validation Decoder Loss:  0.7590937
Encoder Loss:  0.18109639  || Decoder Loss:  0.0077532018 Validation Decoder Loss:  0.75920653
Encoder Loss:  0.17918502  || Decoder Loss:  0.0075705973 Validation Decoder Loss:  0.7592965
Encoder Loss:  0.17729393  || Decoder Loss:  0.007456079 Validation Decoder Loss:  0.7594016
Encoder Loss:  0.1754229  || Decoder Loss:  0.0073788543 Validation Decoder Loss:  0.75954
Encoder Loss:  0.17372759  || Decoder Loss:  0.0073137064 Validation Decoder Loss:  0.7597082
Encoder Loss:  0.1721436  || Decoder Loss:  0.007235769 Validation Decoder Loss:  0.7598556
Encoder Loss:  0.17055194  || Decoder Loss:  0.0071270745 Validation Decoder Loss:  0.75989634
Encoder Loss:  0.16895297  || Decoder Loss:  0.0070217364 Validation Decoder Loss:  0.75991386
Encoder Loss:  0.16741247  || Decoder Loss:  0.006959544 Validation Decoder Loss:  0.7600077
Encoder Loss:  0.165907  || Decoder Loss:  0.006926247 Validation Decoder Loss:  0.76015544
Encoder Loss:  0.16455163  || Decoder Loss:  0.0069047916 Validation Decoder Loss:  0.76032996
Encoder Loss:  0.16330062  || Decoder Loss:  0.0068887337 Validation Decoder Loss:  0.7605157
Encoder Loss:  0.16206785  || Decoder Loss:  0.006875303 Validation Decoder Loss:  0.76070356
Encoder Loss:  0.16085055  || Decoder Loss:  0.006863144 Validation Decoder Loss:  0.760888
Encoder Loss:  0.15964839  || Decoder Loss:  0.006851348 Validation Decoder Loss:  0.76106405
Encoder Loss:  0.1583782  || Decoder Loss:  0.0068389773 Validation Decoder Loss:  0.7612212
Encoder Loss:  0.15686987  || Decoder Loss:  0.0068240957 Validation Decoder Loss:  0.7613205
Encoder Loss:  0.15538213  || Decoder Loss:  0.006800515 Validation Decoder Loss:  0.7611819
Encoder Loss:  0.15405823  || Decoder Loss:  0.0067348103 Validation Decoder Loss:  0.76018435
Encoder Loss:  0.15263611  || Decoder Loss:  0.006463327 Validation Decoder Loss:  0.75768733
Encoder Loss:  0.15114725  || Decoder Loss:  0.0061679943 Validation Decoder Loss:  0.752945
Encoder Loss:  0.14976707  || Decoder Loss:  0.0058685695 Validation Decoder Loss:  0.74683535
Encoder Loss:  0.14844072  || Decoder Loss:  0.0055103307 Validation Decoder Loss:  0.7442367
Encoder Loss:  0.14717558  || Decoder Loss:  0.0052784956 Validation Decoder Loss:  0.7410334
Encoder Loss:  0.1458742  || Decoder Loss:  0.004975307 Validation Decoder Loss:  0.7338791
Encoder Loss:  0.14458413  || Decoder Loss:  0.00455627 Validation Decoder Loss:  0.7247947
Encoder Loss:  0.14342482  || Decoder Loss:  0.0041979295 Validation Decoder Loss:  0.7177363
Model: bold_synthesis_net_lr_0.0004006616606474115 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7177363
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 95, 26, 8, 1)      577       
_________________________________________________________________
reshape_7 (Reshape)          (None, 2470, 8, 1)        0         
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 2470, 8, 1)        139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 8, 1)        139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1451358  || Decoder Loss:  0.008708912 Validation Decoder Loss:  0.75255114
Encoder Loss:  0.1403853  || Decoder Loss:  0.008675868 Validation Decoder Loss:  0.7529643
Encoder Loss:  0.13638856  || Decoder Loss:  0.008638261 Validation Decoder Loss:  0.75330424
Encoder Loss:  0.13328652  || Decoder Loss:  0.008590283 Validation Decoder Loss:  0.75350296
Encoder Loss:  0.13071188  || Decoder Loss:  0.00851912 Validation Decoder Loss:  0.75342834
Encoder Loss:  0.12843493  || Decoder Loss:  0.008387825 Validation Decoder Loss:  0.7529968
Encoder Loss:  0.12632011  || Decoder Loss:  0.008072858 Validation Decoder Loss:  0.75239325
Encoder Loss:  0.12412786  || Decoder Loss:  0.007092398 Validation Decoder Loss:  0.74876547
Encoder Loss:  0.12154379  || Decoder Loss:  0.0047601657 Validation Decoder Loss:  0.73432404
Encoder Loss:  0.11965423  || Decoder Loss:  0.0039316067 Validation Decoder Loss:  0.72818494
Encoder Loss:  0.118156515  || Decoder Loss:  0.0038641088 Validation Decoder Loss:  0.7256876
Encoder Loss:  0.1167867  || Decoder Loss:  0.0038172102 Validation Decoder Loss:  0.7240973
Encoder Loss:  0.11552482  || Decoder Loss:  0.0037813066 Validation Decoder Loss:  0.7229671
Encoder Loss:  0.11434717  || Decoder Loss:  0.0037520248 Validation Decoder Loss:  0.7220714
Encoder Loss:  0.11323647  || Decoder Loss:  0.0037265876 Validation Decoder Loss:  0.72136897
Encoder Loss:  0.11217676  || Decoder Loss:  0.0037042194 Validation Decoder Loss:  0.72078454
Encoder Loss:  0.11116092  || Decoder Loss:  0.003683988 Validation Decoder Loss:  0.7202767
Encoder Loss:  0.11018887  || Decoder Loss:  0.0036664212 Validation Decoder Loss:  0.71985954
Encoder Loss:  0.10925104  || Decoder Loss:  0.003650947 Validation Decoder Loss:  0.7195472
Encoder Loss:  0.10834217  || Decoder Loss:  0.0036368603 Validation Decoder Loss:  0.7193089
Encoder Loss:  0.107471  || Decoder Loss:  0.0036232672 Validation Decoder Loss:  0.7191422
Encoder Loss:  0.106637664  || Decoder Loss:  0.003609701 Validation Decoder Loss:  0.7190026
Encoder Loss:  0.105835974  || Decoder Loss:  0.0035965925 Validation Decoder Loss:  0.71890366
Encoder Loss:  0.1050614  || Decoder Loss:  0.003584475 Validation Decoder Loss:  0.7188331
Encoder Loss:  0.10430776  || Decoder Loss:  0.0035733317 Validation Decoder Loss:  0.71883863
Encoder Loss:  0.103566244  || Decoder Loss:  0.0035624956 Validation Decoder Loss:  0.7187993
Encoder Loss:  0.10281716  || Decoder Loss:  0.003553641 Validation Decoder Loss:  0.71881425
Encoder Loss:  0.10203089  || Decoder Loss:  0.0035457464 Validation Decoder Loss:  0.7188361
Encoder Loss:  0.10119295  || Decoder Loss:  0.0035383147 Validation Decoder Loss:  0.7188398
Encoder Loss:  0.10027726  || Decoder Loss:  0.0035314546 Validation Decoder Loss:  0.71883345
Encoder Loss:  0.0994143  || Decoder Loss:  0.0035254841 Validation Decoder Loss:  0.7188042
Encoder Loss:  0.0986474  || Decoder Loss:  0.0035203234 Validation Decoder Loss:  0.7187494
Encoder Loss:  0.09788066  || Decoder Loss:  0.0035159655 Validation Decoder Loss:  0.7187096
Encoder Loss:  0.097096786  || Decoder Loss:  0.0035119208 Validation Decoder Loss:  0.71866775
Encoder Loss:  0.0963558  || Decoder Loss:  0.0035080216 Validation Decoder Loss:  0.7186291
Encoder Loss:  0.09555565  || Decoder Loss:  0.0035043592 Validation Decoder Loss:  0.71861404
Encoder Loss:  0.09465788  || Decoder Loss:  0.0035011135 Validation Decoder Loss:  0.7186225
Encoder Loss:  0.09382046  || Decoder Loss:  0.003497743 Validation Decoder Loss:  0.71861887
Encoder Loss:  0.0929612  || Decoder Loss:  0.0034949407 Validation Decoder Loss:  0.71862143
Encoder Loss:  0.09212346  || Decoder Loss:  0.0034917253 Validation Decoder Loss:  0.718572
Model: bold_synthesis_net_lr_0.0005197012180387746 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.718572
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 242, 10, 8, 1)     1075      
_________________________________________________________________
reshape_8 (Reshape)          (None, 2420, 8, 1)        0         
=================================================================
Total params: 1,075
Trainable params: 1,075
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18223041  || Decoder Loss:  0.009055696 Validation Decoder Loss:  0.7512213
Encoder Loss:  0.17893013  || Decoder Loss:  0.009031189 Validation Decoder Loss:  0.75166816
Encoder Loss:  0.17607796  || Decoder Loss:  0.009001285 Validation Decoder Loss:  0.7521029
Encoder Loss:  0.17358568  || Decoder Loss:  0.008966858 Validation Decoder Loss:  0.7525465
Encoder Loss:  0.17123145  || Decoder Loss:  0.008928802 Validation Decoder Loss:  0.75301003
Encoder Loss:  0.16883588  || Decoder Loss:  0.008887365 Validation Decoder Loss:  0.7534927
Encoder Loss:  0.16638002  || Decoder Loss:  0.008837027 Validation Decoder Loss:  0.75399977
Encoder Loss:  0.16398636  || Decoder Loss:  0.00876494 Validation Decoder Loss:  0.7545574
Encoder Loss:  0.16168448  || Decoder Loss:  0.008649367 Validation Decoder Loss:  0.75519866
Encoder Loss:  0.1594049  || Decoder Loss:  0.008428265 Validation Decoder Loss:  0.7559047
Encoder Loss:  0.15701589  || Decoder Loss:  0.007957413 Validation Decoder Loss:  0.75628453
Encoder Loss:  0.15454651  || Decoder Loss:  0.0070671975 Validation Decoder Loss:  0.75569475
Encoder Loss:  0.15215103  || Decoder Loss:  0.006080759 Validation Decoder Loss:  0.7541987
Encoder Loss:  0.14992972  || Decoder Loss:  0.0053172437 Validation Decoder Loss:  0.7516095
Encoder Loss:  0.14788945  || Decoder Loss:  0.0047776964 Validation Decoder Loss:  0.7492496
Encoder Loss:  0.1460512  || Decoder Loss:  0.0046144496 Validation Decoder Loss:  0.7485671
Encoder Loss:  0.14430442  || Decoder Loss:  0.004577341 Validation Decoder Loss:  0.74845904
Encoder Loss:  0.14260203  || Decoder Loss:  0.004540363 Validation Decoder Loss:  0.74855065
Encoder Loss:  0.1409248  || Decoder Loss:  0.004453468 Validation Decoder Loss:  0.7485357
Encoder Loss:  0.13921762  || Decoder Loss:  0.0043680975 Validation Decoder Loss:  0.74876136
Encoder Loss:  0.13747823  || Decoder Loss:  0.004313897 Validation Decoder Loss:  0.7493381
Encoder Loss:  0.13560392  || Decoder Loss:  0.0042750454 Validation Decoder Loss:  0.75006545
Encoder Loss:  0.1335658  || Decoder Loss:  0.004251622 Validation Decoder Loss:  0.75078636
Encoder Loss:  0.13151777  || Decoder Loss:  0.0042255726 Validation Decoder Loss:  0.7512589
Encoder Loss:  0.12947303  || Decoder Loss:  0.004195559 Validation Decoder Loss:  0.7513831
Encoder Loss:  0.12753713  || Decoder Loss:  0.0041680206 Validation Decoder Loss:  0.75168365
Encoder Loss:  0.1257469  || Decoder Loss:  0.0041449224 Validation Decoder Loss:  0.7520077
Encoder Loss:  0.12387114  || Decoder Loss:  0.0041238824 Validation Decoder Loss:  0.7522397
Encoder Loss:  0.121944055  || Decoder Loss:  0.0041039395 Validation Decoder Loss:  0.7523826
Encoder Loss:  0.12014259  || Decoder Loss:  0.0040859524 Validation Decoder Loss:  0.7524506
Encoder Loss:  0.11843674  || Decoder Loss:  0.004065251 Validation Decoder Loss:  0.752401
Encoder Loss:  0.11695112  || Decoder Loss:  0.004044264 Validation Decoder Loss:  0.7522893
Encoder Loss:  0.11560691  || Decoder Loss:  0.0040215054 Validation Decoder Loss:  0.752122
Encoder Loss:  0.11434706  || Decoder Loss:  0.003999622 Validation Decoder Loss:  0.75193506
Encoder Loss:  0.11314566  || Decoder Loss:  0.003979941 Validation Decoder Loss:  0.7517403
Encoder Loss:  0.11199791  || Decoder Loss:  0.003961276 Validation Decoder Loss:  0.7515207
Encoder Loss:  0.1108619  || Decoder Loss:  0.0039443104 Validation Decoder Loss:  0.7512871
Encoder Loss:  0.10966544  || Decoder Loss:  0.003926567 Validation Decoder Loss:  0.75097626
Encoder Loss:  0.108327575  || Decoder Loss:  0.003908224 Validation Decoder Loss:  0.75058097
Encoder Loss:  0.10696989  || Decoder Loss:  0.0038888794 Validation Decoder Loss:  0.7501283
Model: bold_synthesis_net_lr_0.0003997974606181408 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7501283
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 220, 11, 8, 1)     283       
_________________________________________________________________
reshape_9 (Reshape)          (None, 2420, 8, 1)        0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2167089  || Decoder Loss:  0.008706889 Validation Decoder Loss:  0.7555303
Encoder Loss:  0.21286096  || Decoder Loss:  0.008712771 Validation Decoder Loss:  0.75572145
Encoder Loss:  0.20940746  || Decoder Loss:  0.008718072 Validation Decoder Loss:  0.75594145
Encoder Loss:  0.20634286  || Decoder Loss:  0.008722278 Validation Decoder Loss:  0.75618356
Encoder Loss:  0.2035684  || Decoder Loss:  0.008725108 Validation Decoder Loss:  0.7564416
Encoder Loss:  0.20099056  || Decoder Loss:  0.008726108 Validation Decoder Loss:  0.756712
Encoder Loss:  0.1985145  || Decoder Loss:  0.008724318 Validation Decoder Loss:  0.75699455
Encoder Loss:  0.1960263  || Decoder Loss:  0.0087175 Validation Decoder Loss:  0.7572947
Encoder Loss:  0.19349761  || Decoder Loss:  0.008699745 Validation Decoder Loss:  0.7576278
Encoder Loss:  0.19089851  || Decoder Loss:  0.008655102 Validation Decoder Loss:  0.75801677
Encoder Loss:  0.18840303  || Decoder Loss:  0.008546429 Validation Decoder Loss:  0.75846756
Encoder Loss:  0.18617004  || Decoder Loss:  0.008323719 Validation Decoder Loss:  0.758876
Encoder Loss:  0.18410678  || Decoder Loss:  0.008015066 Validation Decoder Loss:  0.7590994
Encoder Loss:  0.1821156  || Decoder Loss:  0.007745146 Validation Decoder Loss:  0.7592108
Encoder Loss:  0.18019082  || Decoder Loss:  0.0075650606 Validation Decoder Loss:  0.7593008
Encoder Loss:  0.17828284  || Decoder Loss:  0.0074522677 Validation Decoder Loss:  0.75940704
Encoder Loss:  0.17640083  || Decoder Loss:  0.007375813 Validation Decoder Loss:  0.7595476
Encoder Loss:  0.1746986  || Decoder Loss:  0.007310454 Validation Decoder Loss:  0.75971705
Encoder Loss:  0.17310295  || Decoder Loss:  0.00723098 Validation Decoder Loss:  0.7598612
Encoder Loss:  0.17149623  || Decoder Loss:  0.0071207504 Validation Decoder Loss:  0.75989604
Encoder Loss:  0.16988641  || Decoder Loss:  0.0070170118 Validation Decoder Loss:  0.75991595
Encoder Loss:  0.16833487  || Decoder Loss:  0.0069569666 Validation Decoder Loss:  0.7600144
Encoder Loss:  0.16682135  || Decoder Loss:  0.006924649 Validation Decoder Loss:  0.760165
Encoder Loss:  0.16546372  || Decoder Loss:  0.0069036274 Validation Decoder Loss:  0.7603413
Encoder Loss:  0.16420457  || Decoder Loss:  0.006887758 Validation Decoder Loss:  0.7605278
Encoder Loss:  0.16296151  || Decoder Loss:  0.0068744156 Validation Decoder Loss:  0.7607161
Encoder Loss:  0.16173537  || Decoder Loss:  0.006862284 Validation Decoder Loss:  0.76090056
Encoder Loss:  0.16052212  || Decoder Loss:  0.006850459 Validation Decoder Loss:  0.7610762
Encoder Loss:  0.15922837  || Decoder Loss:  0.0068379687 Validation Decoder Loss:  0.76123136
Encoder Loss:  0.1576921  || Decoder Loss:  0.0068227323 Validation Decoder Loss:  0.7613228
Encoder Loss:  0.15620928  || Decoder Loss:  0.006797805 Validation Decoder Loss:  0.76114815
Encoder Loss:  0.15487528  || Decoder Loss:  0.006724322 Validation Decoder Loss:  0.76001775
Encoder Loss:  0.153429  || Decoder Loss:  0.006431639 Validation Decoder Loss:  0.7574525
Encoder Loss:  0.15193608  || Decoder Loss:  0.006149177 Validation Decoder Loss:  0.752388
Encoder Loss:  0.15055272  || Decoder Loss:  0.0058368705 Validation Decoder Loss:  0.7465463
Encoder Loss:  0.14922304  || Decoder Loss:  0.005489597 Validation Decoder Loss:  0.74409103
Encoder Loss:  0.1479494  || Decoder Loss:  0.005257551 Validation Decoder Loss:  0.74056983
Encoder Loss:  0.14663415  || Decoder Loss:  0.004944825 Validation Decoder Loss:  0.7332464
Encoder Loss:  0.14534564  || Decoder Loss:  0.004519355 Validation Decoder Loss:  0.7241693
Encoder Loss:  0.14419067  || Decoder Loss:  0.0041737035 Validation Decoder Loss:  0.717152
Model: bold_synthesis_net_lr_0.0004016966242166538 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.717152
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 242, 10, 8, 1)     359       
_________________________________________________________________
reshape_10 (Reshape)         (None, 2420, 8, 1)        0         
=================================================================
Total params: 359
Trainable params: 359
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21092956  || Decoder Loss:  0.008831234 Validation Decoder Loss:  0.75570863
Encoder Loss:  0.20817788  || Decoder Loss:  0.008833868 Validation Decoder Loss:  0.7560083
Encoder Loss:  0.20577988  || Decoder Loss:  0.008833615 Validation Decoder Loss:  0.75631034
Encoder Loss:  0.20364532  || Decoder Loss:  0.00883057 Validation Decoder Loss:  0.75661707
Encoder Loss:  0.20160888  || Decoder Loss:  0.008824406 Validation Decoder Loss:  0.7569307
Encoder Loss:  0.1995105  || Decoder Loss:  0.008813796 Validation Decoder Loss:  0.7572575
Encoder Loss:  0.19725555  || Decoder Loss:  0.008795001 Validation Decoder Loss:  0.75761193
Encoder Loss:  0.19481511  || Decoder Loss:  0.008757919 Validation Decoder Loss:  0.7580221
Encoder Loss:  0.19234824  || Decoder Loss:  0.008677658 Validation Decoder Loss:  0.75853056
Encoder Loss:  0.19008061  || Decoder Loss:  0.008507254 Validation Decoder Loss:  0.7591469
Encoder Loss:  0.18801971  || Decoder Loss:  0.008217636 Validation Decoder Loss:  0.7597436
Encoder Loss:  0.18602204  || Decoder Loss:  0.007893596 Validation Decoder Loss:  0.7601678
Encoder Loss:  0.18410113  || Decoder Loss:  0.0076462715 Validation Decoder Loss:  0.7604694
Encoder Loss:  0.18234473  || Decoder Loss:  0.0074668285 Validation Decoder Loss:  0.76073015
Encoder Loss:  0.18072478  || Decoder Loss:  0.0072919833 Validation Decoder Loss:  0.760883
Encoder Loss:  0.17915843  || Decoder Loss:  0.0071234056 Validation Decoder Loss:  0.7609024
Encoder Loss:  0.177604  || Decoder Loss:  0.0070118695 Validation Decoder Loss:  0.7609191
Encoder Loss:  0.17605545  || Decoder Loss:  0.0069404035 Validation Decoder Loss:  0.76096463
Encoder Loss:  0.17452611  || Decoder Loss:  0.006865061 Validation Decoder Loss:  0.7608087
Encoder Loss:  0.17292966  || Decoder Loss:  0.0063282615 Validation Decoder Loss:  0.7505663
Encoder Loss:  0.17104156  || Decoder Loss:  0.0047267885 Validation Decoder Loss:  0.7386894
Encoder Loss:  0.16927429  || Decoder Loss:  0.0044588754 Validation Decoder Loss:  0.7353331
Encoder Loss:  0.16716595  || Decoder Loss:  0.0043960023 Validation Decoder Loss:  0.73398536
Encoder Loss:  0.16455299  || Decoder Loss:  0.004359042 Validation Decoder Loss:  0.73337996
Encoder Loss:  0.16194065  || Decoder Loss:  0.0043244893 Validation Decoder Loss:  0.73299384
Encoder Loss:  0.15921444  || Decoder Loss:  0.0042791576 Validation Decoder Loss:  0.7321903
Encoder Loss:  0.15625532  || Decoder Loss:  0.004221961 Validation Decoder Loss:  0.7309012
Encoder Loss:  0.15343766  || Decoder Loss:  0.0041778446 Validation Decoder Loss:  0.7297398
Encoder Loss:  0.15113348  || Decoder Loss:  0.0041444045 Validation Decoder Loss:  0.7283927
Encoder Loss:  0.14922652  || Decoder Loss:  0.0041171922 Validation Decoder Loss:  0.72682947
Encoder Loss:  0.1474925  || Decoder Loss:  0.004087265 Validation Decoder Loss:  0.72452545
Encoder Loss:  0.14584906  || Decoder Loss:  0.0040532574 Validation Decoder Loss:  0.720784
Encoder Loss:  0.14427432  || Decoder Loss:  0.004018701 Validation Decoder Loss:  0.71615297
Encoder Loss:  0.14267609  || Decoder Loss:  0.003982529 Validation Decoder Loss:  0.71127623
Encoder Loss:  0.14104457  || Decoder Loss:  0.0039456724 Validation Decoder Loss:  0.7078648
Encoder Loss:  0.13949081  || Decoder Loss:  0.003914685 Validation Decoder Loss:  0.7056309
Encoder Loss:  0.13803568  || Decoder Loss:  0.0038931442 Validation Decoder Loss:  0.7049324
Encoder Loss:  0.1366731  || Decoder Loss:  0.0038727517 Validation Decoder Loss:  0.70548826
Encoder Loss:  0.13542204  || Decoder Loss:  0.0038530314 Validation Decoder Loss:  0.70655143
Encoder Loss:  0.13425721  || Decoder Loss:  0.0038352376 Validation Decoder Loss:  0.706956
Model: bold_synthesis_net_lr_0.0004037860350243782 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.706956
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 484, 5, 8, 1)      296       
_________________________________________________________________
reshape_11 (Reshape)         (None, 2420, 8, 1)        0         
=================================================================
Total params: 296
Trainable params: 296
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22425807  || Decoder Loss:  0.008883446 Validation Decoder Loss:  0.7554325
Encoder Loss:  0.22043115  || Decoder Loss:  0.008899704 Validation Decoder Loss:  0.7557675
Encoder Loss:  0.2171493  || Decoder Loss:  0.008911464 Validation Decoder Loss:  0.7561146
Encoder Loss:  0.2142974  || Decoder Loss:  0.008918756 Validation Decoder Loss:  0.75646764
Encoder Loss:  0.21162854  || Decoder Loss:  0.008921311 Validation Decoder Loss:  0.75682694
Encoder Loss:  0.20895222  || Decoder Loss:  0.008917762 Validation Decoder Loss:  0.75720024
Encoder Loss:  0.20610502  || Decoder Loss:  0.0089035425 Validation Decoder Loss:  0.7576104
Encoder Loss:  0.20332874  || Decoder Loss:  0.008864118 Validation Decoder Loss:  0.75810426
Encoder Loss:  0.20067033  || Decoder Loss:  0.008759954 Validation Decoder Loss:  0.7587464
Encoder Loss:  0.19813193  || Decoder Loss:  0.008525192 Validation Decoder Loss:  0.75950193
Encoder Loss:  0.19563963  || Decoder Loss:  0.008174755 Validation Decoder Loss:  0.7601251
Encoder Loss:  0.19319378  || Decoder Loss:  0.007867216 Validation Decoder Loss:  0.7605602
Encoder Loss:  0.19093415  || Decoder Loss:  0.0076661063 Validation Decoder Loss:  0.76093733
Encoder Loss:  0.18887968  || Decoder Loss:  0.0075130574 Validation Decoder Loss:  0.7613078
Encoder Loss:  0.18697505  || Decoder Loss:  0.007339796 Validation Decoder Loss:  0.76154274
Encoder Loss:  0.18514696  || Decoder Loss:  0.007174896 Validation Decoder Loss:  0.7616458
Encoder Loss:  0.18340454  || Decoder Loss:  0.0070748283 Validation Decoder Loss:  0.76172644
Encoder Loss:  0.18175837  || Decoder Loss:  0.006998871 Validation Decoder Loss:  0.7609828
Encoder Loss:  0.18004562  || Decoder Loss:  0.006731492 Validation Decoder Loss:  0.74055296
Encoder Loss:  0.17797226  || Decoder Loss:  0.0058775097 Validation Decoder Loss:  0.73265505
Encoder Loss:  0.17557244  || Decoder Loss:  0.005486746 Validation Decoder Loss:  0.72976416
Encoder Loss:  0.17300154  || Decoder Loss:  0.0050813328 Validation Decoder Loss:  0.7267459
Encoder Loss:  0.17056513  || Decoder Loss:  0.0048285574 Validation Decoder Loss:  0.7232581
Encoder Loss:  0.16798244  || Decoder Loss:  0.004636991 Validation Decoder Loss:  0.7175371
Encoder Loss:  0.16562071  || Decoder Loss:  0.0045812577 Validation Decoder Loss:  0.7158997
Encoder Loss:  0.163543  || Decoder Loss:  0.0045359693 Validation Decoder Loss:  0.7148187
Encoder Loss:  0.16141145  || Decoder Loss:  0.0044850507 Validation Decoder Loss:  0.71379507
Encoder Loss:  0.15917505  || Decoder Loss:  0.004428232 Validation Decoder Loss:  0.7123595
Encoder Loss:  0.15675026  || Decoder Loss:  0.00438401 Validation Decoder Loss:  0.71126676
Encoder Loss:  0.15431032  || Decoder Loss:  0.00435695 Validation Decoder Loss:  0.7106563
Encoder Loss:  0.15198646  || Decoder Loss:  0.0043371785 Validation Decoder Loss:  0.70996934
Encoder Loss:  0.14949733  || Decoder Loss:  0.004320308 Validation Decoder Loss:  0.70916504
Encoder Loss:  0.14723273  || Decoder Loss:  0.0043054046 Validation Decoder Loss:  0.7082908
Encoder Loss:  0.14517938  || Decoder Loss:  0.00429063 Validation Decoder Loss:  0.70709145
Encoder Loss:  0.14300933  || Decoder Loss:  0.0042751455 Validation Decoder Loss:  0.7053952
Encoder Loss:  0.14075463  || Decoder Loss:  0.004258878 Validation Decoder Loss:  0.70335764
Encoder Loss:  0.13823964  || Decoder Loss:  0.004242566 Validation Decoder Loss:  0.7010757
Encoder Loss:  0.13550346  || Decoder Loss:  0.004224535 Validation Decoder Loss:  0.6978482
Encoder Loss:  0.13293254  || Decoder Loss:  0.004202528 Validation Decoder Loss:  0.69310486
Encoder Loss:  0.13047709  || Decoder Loss:  0.0041746097 Validation Decoder Loss:  0.68791795
Model: bold_synthesis_net_lr_0.0004687878181369875 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.68791795
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 110, 22, 8, 1)     283       
_________________________________________________________________
reshape_12 (Reshape)         (None, 2420, 8, 1)        0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22748119  || Decoder Loss:  0.008709126 Validation Decoder Loss:  0.75558776
Encoder Loss:  0.22275956  || Decoder Loss:  0.008715954 Validation Decoder Loss:  0.75582767
Encoder Loss:  0.2185822  || Decoder Loss:  0.008721789 Validation Decoder Loss:  0.75610423
Encoder Loss:  0.21488342  || Decoder Loss:  0.008725864 Validation Decoder Loss:  0.75640696
Encoder Loss:  0.21141863  || Decoder Loss:  0.008727445 Validation Decoder Loss:  0.7567288
Encoder Loss:  0.20800582  || Decoder Loss:  0.008724823 Validation Decoder Loss:  0.7570698
Encoder Loss:  0.20464723  || Decoder Loss:  0.008712962 Validation Decoder Loss:  0.7574435
Encoder Loss:  0.20137121  || Decoder Loss:  0.008675635 Validation Decoder Loss:  0.75788355
Encoder Loss:  0.19813877  || Decoder Loss:  0.008565901 Validation Decoder Loss:  0.75842416
Encoder Loss:  0.19493014  || Decoder Loss:  0.0083038565 Validation Decoder Loss:  0.75892067
Encoder Loss:  0.19149275  || Decoder Loss:  0.007933007 Validation Decoder Loss:  0.7591413
Encoder Loss:  0.1881571  || Decoder Loss:  0.0076468782 Validation Decoder Loss:  0.7592461
Encoder Loss:  0.18573733  || Decoder Loss:  0.007485806 Validation Decoder Loss:  0.759372
Encoder Loss:  0.18365923  || Decoder Loss:  0.0073925997 Validation Decoder Loss:  0.7595503
Encoder Loss:  0.18171756  || Decoder Loss:  0.00732118 Validation Decoder Loss:  0.7597768
Encoder Loss:  0.17977597  || Decoder Loss:  0.007234166 Validation Decoder Loss:  0.75998765
Encoder Loss:  0.17760022  || Decoder Loss:  0.0071046185 Validation Decoder Loss:  0.7600379
Encoder Loss:  0.1753731  || Decoder Loss:  0.006991646 Validation Decoder Loss:  0.76008517
Encoder Loss:  0.17323364  || Decoder Loss:  0.0069380077 Validation Decoder Loss:  0.76023287
Encoder Loss:  0.17132391  || Decoder Loss:  0.006911201 Validation Decoder Loss:  0.76043177
Encoder Loss:  0.16958895  || Decoder Loss:  0.006894085 Validation Decoder Loss:  0.76065123
Encoder Loss:  0.16790809  || Decoder Loss:  0.0068812408 Validation Decoder Loss:  0.76087683
Encoder Loss:  0.16623576  || Decoder Loss:  0.0068706763 Validation Decoder Loss:  0.76110107
Encoder Loss:  0.16454792  || Decoder Loss:  0.00686139 Validation Decoder Loss:  0.7613193
Encoder Loss:  0.16284609  || Decoder Loss:  0.0068528093 Validation Decoder Loss:  0.76152986
Encoder Loss:  0.16116998  || Decoder Loss:  0.0068446286 Validation Decoder Loss:  0.76173246
Encoder Loss:  0.15951957  || Decoder Loss:  0.006836608 Validation Decoder Loss:  0.76192605
Encoder Loss:  0.15790084  || Decoder Loss:  0.006828561 Validation Decoder Loss:  0.76211095
Encoder Loss:  0.15629281  || Decoder Loss:  0.0068203383 Validation Decoder Loss:  0.7622876
Encoder Loss:  0.15462667  || Decoder Loss:  0.006811723 Validation Decoder Loss:  0.76245725
Encoder Loss:  0.15326305  || Decoder Loss:  0.0068024048 Validation Decoder Loss:  0.76262206
Encoder Loss:  0.15212406  || Decoder Loss:  0.0067917635 Validation Decoder Loss:  0.7627849
Encoder Loss:  0.15106727  || Decoder Loss:  0.0067787976 Validation Decoder Loss:  0.76294905
Encoder Loss:  0.15005755  || Decoder Loss:  0.0067614596 Validation Decoder Loss:  0.7631204
Encoder Loss:  0.14907654  || Decoder Loss:  0.006734298 Validation Decoder Loss:  0.7632981
Encoder Loss:  0.14810267  || Decoder Loss:  0.0066747363 Validation Decoder Loss:  0.76333016
Encoder Loss:  0.14707963  || Decoder Loss:  0.0064541628 Validation Decoder Loss:  0.7613472
Encoder Loss:  0.14589001  || Decoder Loss:  0.00571074 Validation Decoder Loss:  0.74819
Encoder Loss:  0.14445828  || Decoder Loss:  0.0039862604 Validation Decoder Loss:  0.7212315
Encoder Loss:  0.14335647  || Decoder Loss:  0.0035340888 Validation Decoder Loss:  0.67522156
Model: bold_synthesis_net_lr_0.0004777913557234788 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.67522156
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 220, 11, 8, 1)     218       
_________________________________________________________________
reshape_13 (Reshape)         (None, 2420, 8, 1)        0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 2420, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 8, 1)        189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25974175  || Decoder Loss:  0.0086362315 Validation Decoder Loss:  0.7618285
Encoder Loss:  0.24812733  || Decoder Loss:  0.008623725 Validation Decoder Loss:  0.76104623
Encoder Loss:  0.23821644  || Decoder Loss:  0.008604711 Validation Decoder Loss:  0.76037234
Encoder Loss:  0.22976618  || Decoder Loss:  0.0085580135 Validation Decoder Loss:  0.7596651
Encoder Loss:  0.22159122  || Decoder Loss:  0.008338757 Validation Decoder Loss:  0.7588522
Encoder Loss:  0.21297182  || Decoder Loss:  0.0072216634 Validation Decoder Loss:  0.7554782
Encoder Loss:  0.20641428  || Decoder Loss:  0.0049269143 Validation Decoder Loss:  0.73883
Encoder Loss:  0.20116809  || Decoder Loss:  0.003938539 Validation Decoder Loss:  0.7217469
Encoder Loss:  0.19661874  || Decoder Loss:  0.0036723316 Validation Decoder Loss:  0.70063037
Encoder Loss:  0.1924992  || Decoder Loss:  0.0035288048 Validation Decoder Loss:  0.68759936
Encoder Loss:  0.18862975  || Decoder Loss:  0.003424426 Validation Decoder Loss:  0.67949903
Encoder Loss:  0.18481526  || Decoder Loss:  0.003354662 Validation Decoder Loss:  0.67666733
Encoder Loss:  0.18112952  || Decoder Loss:  0.003298602 Validation Decoder Loss:  0.6731589
Encoder Loss:  0.17740296  || Decoder Loss:  0.003246631 Validation Decoder Loss:  0.66664815
Encoder Loss:  0.17329992  || Decoder Loss:  0.0031892755 Validation Decoder Loss:  0.6555683
Encoder Loss:  0.16929664  || Decoder Loss:  0.003090164 Validation Decoder Loss:  0.62784785
Encoder Loss:  0.16601285  || Decoder Loss:  0.0030046827 Validation Decoder Loss:  0.6209612
Encoder Loss:  0.16299255  || Decoder Loss:  0.0029490984 Validation Decoder Loss:  0.6206087
Encoder Loss:  0.16010836  || Decoder Loss:  0.0029166932 Validation Decoder Loss:  0.621002
Encoder Loss:  0.15752266  || Decoder Loss:  0.0028974554 Validation Decoder Loss:  0.62134266
Encoder Loss:  0.15523106  || Decoder Loss:  0.0028889054 Validation Decoder Loss:  0.62152404
Encoder Loss:  0.1531377  || Decoder Loss:  0.0028822883 Validation Decoder Loss:  0.6213514
Encoder Loss:  0.15116715  || Decoder Loss:  0.0028786962 Validation Decoder Loss:  0.62126625
Encoder Loss:  0.14933586  || Decoder Loss:  0.0028749222 Validation Decoder Loss:  0.6206968
Encoder Loss:  0.14760831  || Decoder Loss:  0.0028725318 Validation Decoder Loss:  0.6203103
Encoder Loss:  0.1459424  || Decoder Loss:  0.0028693376 Validation Decoder Loss:  0.61979014
Encoder Loss:  0.14424935  || Decoder Loss:  0.0028653229 Validation Decoder Loss:  0.61879075
Encoder Loss:  0.142678  || Decoder Loss:  0.0028622556 Validation Decoder Loss:  0.6182101
Encoder Loss:  0.14103341  || Decoder Loss:  0.0028584944 Validation Decoder Loss:  0.6174617
Encoder Loss:  0.13851337  || Decoder Loss:  0.002854101 Validation Decoder Loss:  0.6164163
Encoder Loss:  0.13648108  || Decoder Loss:  0.002850632 Validation Decoder Loss:  0.61577016
Encoder Loss:  0.13480248  || Decoder Loss:  0.0028470678 Validation Decoder Loss:  0.6150943
Encoder Loss:  0.13326088  || Decoder Loss:  0.0028425292 Validation Decoder Loss:  0.61405945
Encoder Loss:  0.13170467  || Decoder Loss:  0.0028378698 Validation Decoder Loss:  0.61320364
Encoder Loss:  0.13025647  || Decoder Loss:  0.0028323445 Validation Decoder Loss:  0.61247325
Encoder Loss:  0.12882032  || Decoder Loss:  0.0028254667 Validation Decoder Loss:  0.611357
Encoder Loss:  0.12742688  || Decoder Loss:  0.0028185989 Validation Decoder Loss:  0.61083716
Encoder Loss:  0.12612998  || Decoder Loss:  0.0028109783 Validation Decoder Loss:  0.6097287
Encoder Loss:  0.124770984  || Decoder Loss:  0.0028027706 Validation Decoder Loss:  0.6085893
Encoder Loss:  0.12330538  || Decoder Loss:  0.0027963098 Validation Decoder Loss:  0.6078971
2019-12-10 11:40:26.234771: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: bold_synthesis_net_lr_0.0007690955963238933 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.6078971
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_14 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.0062900516 Validation Decoder Loss:  0.7651068
Encoder Loss:  0.07855657  || Decoder Loss:  0.003344947 Validation Decoder Loss:  0.76355314
Encoder Loss:  0.078519836  || Decoder Loss:  0.0033014365 Validation Decoder Loss:  0.7616218
Encoder Loss:  0.078488864  || Decoder Loss:  0.003264579 Validation Decoder Loss:  0.76021063
Encoder Loss:  0.078472525  || Decoder Loss:  0.0032451726 Validation Decoder Loss:  0.7560964
Encoder Loss:  0.07832315  || Decoder Loss:  0.0030678674 Validation Decoder Loss:  0.6462174
Encoder Loss:  0.07801001  || Decoder Loss:  0.0026960126 Validation Decoder Loss:  0.6429185
Encoder Loss:  0.0779919  || Decoder Loss:  0.0026744916 Validation Decoder Loss:  0.64278704
Encoder Loss:  0.07797085  || Decoder Loss:  0.002649572 Validation Decoder Loss:  0.6419206
Encoder Loss:  0.07794853  || Decoder Loss:  0.002623072 Validation Decoder Loss:  0.64095634
Encoder Loss:  0.077935755  || Decoder Loss:  0.0026079188 Validation Decoder Loss:  0.64068085
Encoder Loss:  0.07792777  || Decoder Loss:  0.0025983779 Validation Decoder Loss:  0.64059097
Encoder Loss:  0.07792067  || Decoder Loss:  0.0025899885 Validation Decoder Loss:  0.64054954
Encoder Loss:  0.077913046  || Decoder Loss:  0.0025809333 Validation Decoder Loss:  0.6412201
Encoder Loss:  0.07789469  || Decoder Loss:  0.0025591413 Validation Decoder Loss:  0.64232713
Encoder Loss:  0.077882  || Decoder Loss:  0.002544076 Validation Decoder Loss:  0.6427885
Encoder Loss:  0.07787448  || Decoder Loss:  0.002535057 Validation Decoder Loss:  0.64295906
Encoder Loss:  0.077867985  || Decoder Loss:  0.0025273685 Validation Decoder Loss:  0.6430425
Encoder Loss:  0.07786174  || Decoder Loss:  0.0025199985 Validation Decoder Loss:  0.6428791
Encoder Loss:  0.077855244  || Decoder Loss:  0.002512275 Validation Decoder Loss:  0.64250076
Encoder Loss:  0.07784803  || Decoder Loss:  0.0025037345 Validation Decoder Loss:  0.64143324
Encoder Loss:  0.07782608  || Decoder Loss:  0.0024776664 Validation Decoder Loss:  0.5786442
Encoder Loss:  0.07754316  || Decoder Loss:  0.0021417711 Validation Decoder Loss:  0.5187655
Encoder Loss:  0.077419326  || Decoder Loss:  0.0019946874 Validation Decoder Loss:  0.50844306
Encoder Loss:  0.07728903  || Decoder Loss:  0.0018400226 Validation Decoder Loss:  0.43248174
Encoder Loss:  0.07714994  || Decoder Loss:  0.001674835 Validation Decoder Loss:  0.42764267
Encoder Loss:  0.07713752  || Decoder Loss:  0.0016600721 Validation Decoder Loss:  0.42553532
Encoder Loss:  0.07712074  || Decoder Loss:  0.0016401468 Validation Decoder Loss:  0.42336816
Encoder Loss:  0.07709469  || Decoder Loss:  0.001609248 Validation Decoder Loss:  0.4221666
Encoder Loss:  0.07707851  || Decoder Loss:  0.0015900345 Validation Decoder Loss:  0.4216576
Encoder Loss:  0.077069625  || Decoder Loss:  0.0015794622 Validation Decoder Loss:  0.42148033
Encoder Loss:  0.0770627  || Decoder Loss:  0.0015712279 Validation Decoder Loss:  0.42140535
Encoder Loss:  0.07705744  || Decoder Loss:  0.0015650095 Validation Decoder Loss:  0.4213195
Encoder Loss:  0.07705339  || Decoder Loss:  0.0015602512 Validation Decoder Loss:  0.4212375
Encoder Loss:  0.077050164  || Decoder Loss:  0.001556312 Validation Decoder Loss:  0.42118266
Encoder Loss:  0.077047214  || Decoder Loss:  0.0015528358 Validation Decoder Loss:  0.42112106
Encoder Loss:  0.0770445  || Decoder Loss:  0.001549674 Validation Decoder Loss:  0.42109016
Encoder Loss:  0.077042036  || Decoder Loss:  0.0015467595 Validation Decoder Loss:  0.42106327
Encoder Loss:  0.07703969  || Decoder Loss:  0.0015438917 Validation Decoder Loss:  0.4210463
Encoder Loss:  0.0770374  || Decoder Loss:  0.0015412469 Validation Decoder Loss:  0.42104056
Model: bold_synthesis_net_lr_0.0008351033545960005 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.42104056
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_15 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 320, 8, 1)         694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058637775  || Decoder Loss:  0.008043897 Validation Decoder Loss:  0.76801
Encoder Loss:  0.04429323  || Decoder Loss:  0.0045687607 Validation Decoder Loss:  0.77744013
Encoder Loss:  0.034174215  || Decoder Loss:  0.0033758637 Validation Decoder Loss:  0.77939194
Encoder Loss:  0.02884447  || Decoder Loss:  0.0033191575 Validation Decoder Loss:  0.77758837
Encoder Loss:  0.025351431  || Decoder Loss:  0.0032874737 Validation Decoder Loss:  0.7762649
Encoder Loss:  0.020550437  || Decoder Loss:  0.0032818916 Validation Decoder Loss:  0.77507806
Encoder Loss:  0.018427994  || Decoder Loss:  0.0032492606 Validation Decoder Loss:  0.7725579
Encoder Loss:  0.016885545  || Decoder Loss:  0.0032095485 Validation Decoder Loss:  0.76961756
Encoder Loss:  0.015365015  || Decoder Loss:  0.0031736926 Validation Decoder Loss:  0.76621515
Encoder Loss:  0.01437915  || Decoder Loss:  0.003123738 Validation Decoder Loss:  0.7619062
Encoder Loss:  0.0133993635  || Decoder Loss:  0.0030489143 Validation Decoder Loss:  0.7553886
Encoder Loss:  0.012544902  || Decoder Loss:  0.0029393444 Validation Decoder Loss:  0.7451951
Encoder Loss:  0.011797506  || Decoder Loss:  0.002799738 Validation Decoder Loss:  0.73133016
Encoder Loss:  0.011063184  || Decoder Loss:  0.0026548987 Validation Decoder Loss:  0.7154988
Encoder Loss:  0.010504062  || Decoder Loss:  0.0025342533 Validation Decoder Loss:  0.7003711
Encoder Loss:  0.010025414  || Decoder Loss:  0.002441874 Validation Decoder Loss:  0.68544996
Encoder Loss:  0.009598699  || Decoder Loss:  0.002377997 Validation Decoder Loss:  0.6711064
Encoder Loss:  0.009254868  || Decoder Loss:  0.0023412842 Validation Decoder Loss:  0.6580976
Encoder Loss:  0.008969205  || Decoder Loss:  0.0023252028 Validation Decoder Loss:  0.64641744
Encoder Loss:  0.008725871  || Decoder Loss:  0.0023225893 Validation Decoder Loss:  0.6355106
Encoder Loss:  0.008515507  || Decoder Loss:  0.0023272387 Validation Decoder Loss:  0.6259837
Encoder Loss:  0.008335213  || Decoder Loss:  0.0023398467 Validation Decoder Loss:  0.61822414
Encoder Loss:  0.008179144  || Decoder Loss:  0.0023570627 Validation Decoder Loss:  0.6121477
Encoder Loss:  0.008020847  || Decoder Loss:  0.0023715924 Validation Decoder Loss:  0.60666144
Encoder Loss:  0.007596181  || Decoder Loss:  0.002354629 Validation Decoder Loss:  0.5996059
Encoder Loss:  0.0073553193  || Decoder Loss:  0.0023333633 Validation Decoder Loss:  0.59421957
Encoder Loss:  0.007261244  || Decoder Loss:  0.0023413764 Validation Decoder Loss:  0.59041315
Encoder Loss:  0.0071825827  || Decoder Loss:  0.0023545178 Validation Decoder Loss:  0.5869535
Encoder Loss:  0.007102575  || Decoder Loss:  0.0023675985 Validation Decoder Loss:  0.5826926
Encoder Loss:  0.0069849663  || Decoder Loss:  0.0023456954 Validation Decoder Loss:  0.5770737
Encoder Loss:  0.0069228667  || Decoder Loss:  0.0023495315 Validation Decoder Loss:  0.57432836
Encoder Loss:  0.0068800356  || Decoder Loss:  0.0023695831 Validation Decoder Loss:  0.57237387
Encoder Loss:  0.0067778993  || Decoder Loss:  0.0023989219 Validation Decoder Loss:  0.5728043
Encoder Loss:  0.0066026505  || Decoder Loss:  0.0024590276 Validation Decoder Loss:  0.57266504
Encoder Loss:  0.0065252176  || Decoder Loss:  0.0024722407 Validation Decoder Loss:  0.5713239
Encoder Loss:  0.006470202  || Decoder Loss:  0.0024727022 Validation Decoder Loss:  0.56922966
Encoder Loss:  0.006432408  || Decoder Loss:  0.0024792773 Validation Decoder Loss:  0.5682699
Encoder Loss:  0.006415171  || Decoder Loss:  0.0024975198 Validation Decoder Loss:  0.5679386
Encoder Loss:  0.0064024413  || Decoder Loss:  0.0025189272 Validation Decoder Loss:  0.5677984
Encoder Loss:  0.0063929236  || Decoder Loss:  0.0025442627 Validation Decoder Loss:  0.56787276
Model: bold_synthesis_net_lr_0.0008351033513098258 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.5678727
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_16 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 320, 8, 1)         694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 8, 1)        1013      
=================================================================
Total params: 1,013
Trainable params: 1,013
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05777207  || Decoder Loss:  0.0070159705 Validation Decoder Loss:  0.77855486
Encoder Loss:  0.04328759  || Decoder Loss:  0.003374683 Validation Decoder Loss:  0.781542
Encoder Loss:  0.034154117  || Decoder Loss:  0.0033520055 Validation Decoder Loss:  0.7839543
Encoder Loss:  0.02886046  || Decoder Loss:  0.003338136 Validation Decoder Loss:  0.7842884
Encoder Loss:  0.025376827  || Decoder Loss:  0.0033176204 Validation Decoder Loss:  0.7819004
Encoder Loss:  0.020537695  || Decoder Loss:  0.0032667625 Validation Decoder Loss:  0.77551657
Encoder Loss:  0.018372295  || Decoder Loss:  0.0031831218 Validation Decoder Loss:  0.76254493
Encoder Loss:  0.016802296  || Decoder Loss:  0.003110861 Validation Decoder Loss:  0.75205344
Encoder Loss:  0.015266774  || Decoder Loss:  0.0030570468 Validation Decoder Loss:  0.74417603
Encoder Loss:  0.014288591  || Decoder Loss:  0.0030162027 Validation Decoder Loss:  0.7383842
Encoder Loss:  0.013354042  || Decoder Loss:  0.0029950787 Validation Decoder Loss:  0.7334342
Encoder Loss:  0.012582047  || Decoder Loss:  0.002984001 Validation Decoder Loss:  0.7292484
Encoder Loss:  0.01194741  || Decoder Loss:  0.0029786876 Validation Decoder Loss:  0.7251589
Encoder Loss:  0.01132953  || Decoder Loss:  0.0029711204 Validation Decoder Loss:  0.72061723
Encoder Loss:  0.010862658  || Decoder Loss:  0.0029599848 Validation Decoder Loss:  0.7159277
Encoder Loss:  0.010455488  || Decoder Loss:  0.002952473 Validation Decoder Loss:  0.7117576
Encoder Loss:  0.010100315  || Decoder Loss:  0.0029485847 Validation Decoder Loss:  0.7081932
Encoder Loss:  0.009767595  || Decoder Loss:  0.0029477272 Validation Decoder Loss:  0.70505244
Encoder Loss:  0.009495271  || Decoder Loss:  0.0029529927 Validation Decoder Loss:  0.70250297
Encoder Loss:  0.009239294  || Decoder Loss:  0.002960705 Validation Decoder Loss:  0.7000169
Encoder Loss:  0.0090264  || Decoder Loss:  0.0029718955 Validation Decoder Loss:  0.69758624
Encoder Loss:  0.008606123  || Decoder Loss:  0.0029696173 Validation Decoder Loss:  0.6944095
Encoder Loss:  0.008287153  || Decoder Loss:  0.0029637413 Validation Decoder Loss:  0.6917668
Encoder Loss:  0.008139528  || Decoder Loss:  0.0029742753 Validation Decoder Loss:  0.6895624
Encoder Loss:  0.00803318  || Decoder Loss:  0.002991375 Validation Decoder Loss:  0.68751717
Encoder Loss:  0.007919258  || Decoder Loss:  0.0030084685 Validation Decoder Loss:  0.68504477
Encoder Loss:  0.007780301  || Decoder Loss:  0.0030027167 Validation Decoder Loss:  0.68242896
Encoder Loss:  0.007692157  || Decoder Loss:  0.0030098804 Validation Decoder Loss:  0.6801573
Encoder Loss:  0.007623712  || Decoder Loss:  0.0030208162 Validation Decoder Loss:  0.67783576
Encoder Loss:  0.0075582312  || Decoder Loss:  0.0030299176 Validation Decoder Loss:  0.67537963
Encoder Loss:  0.0074814507  || Decoder Loss:  0.0030365202 Validation Decoder Loss:  0.6726271
Encoder Loss:  0.0071933535  || Decoder Loss:  0.0030480055 Validation Decoder Loss:  0.67035353
Encoder Loss:  0.007077304  || Decoder Loss:  0.0030658345 Validation Decoder Loss:  0.66758937
Encoder Loss:  0.007035908  || Decoder Loss:  0.003068132 Validation Decoder Loss:  0.6647226
Encoder Loss:  0.0069978437  || Decoder Loss:  0.0030706716 Validation Decoder Loss:  0.66184634
Encoder Loss:  0.0069636293  || Decoder Loss:  0.0030744167 Validation Decoder Loss:  0.65904516
Encoder Loss:  0.00693349  || Decoder Loss:  0.0030798193 Validation Decoder Loss:  0.6562808
Encoder Loss:  0.0068940376  || Decoder Loss:  0.003078224 Validation Decoder Loss:  0.6532004
Encoder Loss:  0.006852205  || Decoder Loss:  0.0030765976 Validation Decoder Loss:  0.65032315
Encoder Loss:  0.0068312613  || Decoder Loss:  0.0030849385 Validation Decoder Loss:  0.6476915
Model: bold_synthesis_net_lr_0.0008351033468048805 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.6476915
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_17 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 320, 8, 1)         1013      
=================================================================
Total params: 1,013
Trainable params: 1,013
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 8, 1)        2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.041756596  || Decoder Loss:  0.008016673 Validation Decoder Loss:  0.7673914
Encoder Loss:  0.03004273  || Decoder Loss:  0.006733911 Validation Decoder Loss:  0.7675579
Encoder Loss:  0.01785719  || Decoder Loss:  0.0062871748 Validation Decoder Loss:  0.7577292
Encoder Loss:  0.012497384  || Decoder Loss:  0.0042926283 Validation Decoder Loss:  0.7439682
Encoder Loss:  0.009432419  || Decoder Loss:  0.00352019 Validation Decoder Loss:  0.72607565
Encoder Loss:  0.0073082414  || Decoder Loss:  0.0033869487 Validation Decoder Loss:  0.7178848
Encoder Loss:  0.007015835  || Decoder Loss:  0.0032987602 Validation Decoder Loss:  0.7141464
Encoder Loss:  0.0067834756  || Decoder Loss:  0.0032452424 Validation Decoder Loss:  0.71125257
Encoder Loss:  0.0065946123  || Decoder Loss:  0.0032071483 Validation Decoder Loss:  0.70952827
Encoder Loss:  0.0064435415  || Decoder Loss:  0.0031797562 Validation Decoder Loss:  0.70863324
Encoder Loss:  0.006144259  || Decoder Loss:  0.003154369 Validation Decoder Loss:  0.70739836
Encoder Loss:  0.0058881384  || Decoder Loss:  0.0031285295 Validation Decoder Loss:  0.7059845
Encoder Loss:  0.005852474  || Decoder Loss:  0.003100685 Validation Decoder Loss:  0.7044575
Encoder Loss:  0.005806383  || Decoder Loss:  0.0030608766 Validation Decoder Loss:  0.70243126
Encoder Loss:  0.005728246  || Decoder Loss:  0.0029825016 Validation Decoder Loss:  0.6975717
Encoder Loss:  0.005604757  || Decoder Loss:  0.0028491472 Validation Decoder Loss:  0.6886817
Encoder Loss:  0.005430105  || Decoder Loss:  0.0026551015 Validation Decoder Loss:  0.67380697
Encoder Loss:  0.0052280542  || Decoder Loss:  0.0024275815 Validation Decoder Loss:  0.6552698
Encoder Loss:  0.0050385515  || Decoder Loss:  0.0022117158 Validation Decoder Loss:  0.6367157
Encoder Loss:  0.004873125  || Decoder Loss:  0.0020225828 Validation Decoder Loss:  0.61820215
Encoder Loss:  0.004728789  || Decoder Loss:  0.0018571995 Validation Decoder Loss:  0.60048
Encoder Loss:  0.004607994  || Decoder Loss:  0.0017185684 Validation Decoder Loss:  0.58401644
Encoder Loss:  0.004511776  || Decoder Loss:  0.0016081342 Validation Decoder Loss:  0.56974006
Encoder Loss:  0.004434915  || Decoder Loss:  0.0015199415 Validation Decoder Loss:  0.55706435
Encoder Loss:  0.0043699164  || Decoder Loss:  0.0014451952 Validation Decoder Loss:  0.54443663
Encoder Loss:  0.00431207  || Decoder Loss:  0.0013784558 Validation Decoder Loss:  0.5319174
Encoder Loss:  0.004262519  || Decoder Loss:  0.0013211531 Validation Decoder Loss:  0.5198206
Encoder Loss:  0.004222614  || Decoder Loss:  0.0012749734 Validation Decoder Loss:  0.508911
Encoder Loss:  0.0041918554  || Decoder Loss:  0.0012395269 Validation Decoder Loss:  0.49903286
Encoder Loss:  0.004162064  || Decoder Loss:  0.0012049541 Validation Decoder Loss:  0.49035046
Encoder Loss:  0.004143322  || Decoder Loss:  0.0011833202 Validation Decoder Loss:  0.48252472
Encoder Loss:  0.004130499  || Decoder Loss:  0.0011687176 Validation Decoder Loss:  0.47582778
Encoder Loss:  0.0041187666  || Decoder Loss:  0.0011552691 Validation Decoder Loss:  0.46976623
Encoder Loss:  0.0041071977  || Decoder Loss:  0.0011418457 Validation Decoder Loss:  0.46460804
Encoder Loss:  0.004095079  || Decoder Loss:  0.0011277534 Validation Decoder Loss:  0.4594039
Encoder Loss:  0.0040821177  || Decoder Loss:  0.0011125309 Validation Decoder Loss:  0.45444462
Encoder Loss:  0.0040652268  || Decoder Loss:  0.0010927005 Validation Decoder Loss:  0.44895414
Encoder Loss:  0.00405044  || Decoder Loss:  0.0010752712 Validation Decoder Loss:  0.44407752
Encoder Loss:  0.0040337876  || Decoder Loss:  0.0010556201 Validation Decoder Loss:  0.43921652
Encoder Loss:  0.004017792  || Decoder Loss:  0.0010367156 Validation Decoder Loss:  0.43439323
Model: bold_synthesis_net_lr_0.0008351033575969854 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.43439323
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_18 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 320, 8, 1)         375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.059778713  || Decoder Loss:  0.0060598627 Validation Decoder Loss:  0.74706507
Encoder Loss:  0.050033048  || Decoder Loss:  0.0031998889 Validation Decoder Loss:  0.6865237
Encoder Loss:  0.042435568  || Decoder Loss:  0.002977501 Validation Decoder Loss:  0.66024745
Encoder Loss:  0.03523165  || Decoder Loss:  0.0028460966 Validation Decoder Loss:  0.64668065
Encoder Loss:  0.02959836  || Decoder Loss:  0.0027774787 Validation Decoder Loss:  0.63811076
Encoder Loss:  0.025377724  || Decoder Loss:  0.0027239001 Validation Decoder Loss:  0.63027906
Encoder Loss:  0.022717245  || Decoder Loss:  0.0026791883 Validation Decoder Loss:  0.62313485
Encoder Loss:  0.02079279  || Decoder Loss:  0.00264457 Validation Decoder Loss:  0.6166393
Encoder Loss:  0.018883059  || Decoder Loss:  0.0026202495 Validation Decoder Loss:  0.6099721
Encoder Loss:  0.017124835  || Decoder Loss:  0.0026050375 Validation Decoder Loss:  0.6029737
Encoder Loss:  0.015213522  || Decoder Loss:  0.002591262 Validation Decoder Loss:  0.5953041
Encoder Loss:  0.014282511  || Decoder Loss:  0.002581264 Validation Decoder Loss:  0.5878878
Encoder Loss:  0.013443194  || Decoder Loss:  0.0025836406 Validation Decoder Loss:  0.58070797
Encoder Loss:  0.012353532  || Decoder Loss:  0.0025917932 Validation Decoder Loss:  0.5728349
Encoder Loss:  0.010977388  || Decoder Loss:  0.0025740108 Validation Decoder Loss:  0.5639952
Encoder Loss:  0.0104473485  || Decoder Loss:  0.0025681858 Validation Decoder Loss:  0.5551217
Encoder Loss:  0.0096020335  || Decoder Loss:  0.00256 Validation Decoder Loss:  0.5454703
Encoder Loss:  0.009159838  || Decoder Loss:  0.0025603059 Validation Decoder Loss:  0.53593814
Encoder Loss:  0.008880713  || Decoder Loss:  0.002566603 Validation Decoder Loss:  0.5260581
Encoder Loss:  0.008639418  || Decoder Loss:  0.0025809377 Validation Decoder Loss:  0.51637554
Encoder Loss:  0.008418592  || Decoder Loss:  0.0026000247 Validation Decoder Loss:  0.50660545
Encoder Loss:  0.008220967  || Decoder Loss:  0.0026229615 Validation Decoder Loss:  0.49748144
Encoder Loss:  0.0080632  || Decoder Loss:  0.0026555995 Validation Decoder Loss:  0.48931304
Encoder Loss:  0.007922241  || Decoder Loss:  0.0026868924 Validation Decoder Loss:  0.4815036
Encoder Loss:  0.0077895294  || Decoder Loss:  0.0027148202 Validation Decoder Loss:  0.47432876
Encoder Loss:  0.0076643126  || Decoder Loss:  0.002739916 Validation Decoder Loss:  0.46749228
Encoder Loss:  0.007347908  || Decoder Loss:  0.0027301696 Validation Decoder Loss:  0.45974362
Encoder Loss:  0.007120829  || Decoder Loss:  0.002720256 Validation Decoder Loss:  0.45466638
Encoder Loss:  0.0067271646  || Decoder Loss:  0.002690618 Validation Decoder Loss:  0.44804314
Encoder Loss:  0.0066617583  || Decoder Loss:  0.0026865022 Validation Decoder Loss:  0.44540647
Encoder Loss:  0.006606476  || Decoder Loss:  0.0026900235 Validation Decoder Loss:  0.44436675
Encoder Loss:  0.0065528383  || Decoder Loss:  0.0026906382 Validation Decoder Loss:  0.44418105
Encoder Loss:  0.00650664  || Decoder Loss:  0.0026950142 Validation Decoder Loss:  0.44509193
Encoder Loss:  0.0064668725  || Decoder Loss:  0.0027020928 Validation Decoder Loss:  0.44645637
Encoder Loss:  0.006429911  || Decoder Loss:  0.002711206 Validation Decoder Loss:  0.4481858
Encoder Loss:  0.0064016334  || Decoder Loss:  0.0027235646 Validation Decoder Loss:  0.45002288
Encoder Loss:  0.0063769533  || Decoder Loss:  0.0027366744 Validation Decoder Loss:  0.4519949
Encoder Loss:  0.006352902  || Decoder Loss:  0.0027486673 Validation Decoder Loss:  0.45375964
Encoder Loss:  0.006327858  || Decoder Loss:  0.0027577148 Validation Decoder Loss:  0.45492622
Encoder Loss:  0.0063120713  || Decoder Loss:  0.0027713191 Validation Decoder Loss:  0.45648956
Model: bold_synthesis_net_lr_0.000835103395833327 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.45648947
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_19 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 320, 8, 1)         1970      
=================================================================
Total params: 1,970
Trainable params: 1,970
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.008012836 Validation Decoder Loss:  0.76689696
Encoder Loss:  0.0835558  || Decoder Loss:  0.0059393374 Validation Decoder Loss:  0.7672747
Encoder Loss:  0.08266268  || Decoder Loss:  0.0048713237 Validation Decoder Loss:  0.77234626
Encoder Loss:  0.08142168  || Decoder Loss:  0.0033873757 Validation Decoder Loss:  0.77241015
Encoder Loss:  0.08138963  || Decoder Loss:  0.0033490031 Validation Decoder Loss:  0.7722818
Encoder Loss:  0.08138567  || Decoder Loss:  0.0033443088 Validation Decoder Loss:  0.7722445
Encoder Loss:  0.08138278  || Decoder Loss:  0.0033408054 Validation Decoder Loss:  0.77248085
Encoder Loss:  0.08137629  || Decoder Loss:  0.003333103 Validation Decoder Loss:  0.7725394
Encoder Loss:  0.08136612  || Decoder Loss:  0.003320951 Validation Decoder Loss:  0.77228683
Encoder Loss:  0.0813562  || Decoder Loss:  0.0033091076 Validation Decoder Loss:  0.772091
Encoder Loss:  0.08135205  || Decoder Loss:  0.0033041714 Validation Decoder Loss:  0.77197367
Encoder Loss:  0.081349425  || Decoder Loss:  0.0033010324 Validation Decoder Loss:  0.77188355
Encoder Loss:  0.081347264  || Decoder Loss:  0.003298331 Validation Decoder Loss:  0.77180076
Encoder Loss:  0.08134507  || Decoder Loss:  0.0032957096 Validation Decoder Loss:  0.77172804
Encoder Loss:  0.081343174  || Decoder Loss:  0.0032934875 Validation Decoder Loss:  0.7716729
Encoder Loss:  0.08134175  || Decoder Loss:  0.0032918267 Validation Decoder Loss:  0.77164406
Encoder Loss:  0.081340514  || Decoder Loss:  0.003290279 Validation Decoder Loss:  0.77168953
Encoder Loss:  0.081336685  || Decoder Loss:  0.003285651 Validation Decoder Loss:  0.7723587
Encoder Loss:  0.0813317  || Decoder Loss:  0.0032797584 Validation Decoder Loss:  0.7723639
Encoder Loss:  0.08132834  || Decoder Loss:  0.0032756883 Validation Decoder Loss:  0.7723201
Encoder Loss:  0.08132597  || Decoder Loss:  0.0032728955 Validation Decoder Loss:  0.7722888
Encoder Loss:  0.08132422  || Decoder Loss:  0.0032707702 Validation Decoder Loss:  0.7722653
Encoder Loss:  0.08132254  || Decoder Loss:  0.0032689488 Validation Decoder Loss:  0.7722367
Encoder Loss:  0.08132121  || Decoder Loss:  0.0032672272 Validation Decoder Loss:  0.7722138
Encoder Loss:  0.08131977  || Decoder Loss:  0.0032655406 Validation Decoder Loss:  0.7721899
Encoder Loss:  0.08131831  || Decoder Loss:  0.0032638211 Validation Decoder Loss:  0.7721719
Encoder Loss:  0.08131689  || Decoder Loss:  0.0032620514 Validation Decoder Loss:  0.7721544
Encoder Loss:  0.08131533  || Decoder Loss:  0.0032601806 Validation Decoder Loss:  0.7721414
Encoder Loss:  0.08131364  || Decoder Loss:  0.0032581543 Validation Decoder Loss:  0.7721336
Encoder Loss:  0.0813119  || Decoder Loss:  0.0032559414 Validation Decoder Loss:  0.7721298
Encoder Loss:  0.0813098  || Decoder Loss:  0.0032536385 Validation Decoder Loss:  0.7721524
Encoder Loss:  0.081307754  || Decoder Loss:  0.0032512299 Validation Decoder Loss:  0.7721024
Encoder Loss:  0.08130565  || Decoder Loss:  0.0032485644 Validation Decoder Loss:  0.77215284
Encoder Loss:  0.08130341  || Decoder Loss:  0.0032459502 Validation Decoder Loss:  0.7721517
Encoder Loss:  0.08130111  || Decoder Loss:  0.003243134 Validation Decoder Loss:  0.772134
Encoder Loss:  0.08129737  || Decoder Loss:  0.0032387078 Validation Decoder Loss:  0.7714792
Encoder Loss:  0.081293136  || Decoder Loss:  0.003233664 Validation Decoder Loss:  0.77093005
Encoder Loss:  0.081290714  || Decoder Loss:  0.0032307885 Validation Decoder Loss:  0.77071536
Encoder Loss:  0.081288725  || Decoder Loss:  0.0032284665 Validation Decoder Loss:  0.77062124
Encoder Loss:  0.08128717  || Decoder Loss:  0.003226445 Validation Decoder Loss:  0.77054304
Model: bold_synthesis_net_lr_0.0008303540261802837 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.77054304
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_20 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 320, 8, 1)         1013      
=================================================================
Total params: 1,013
Trainable params: 1,013
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036223218  || Decoder Loss:  0.0065781716 Validation Decoder Loss:  0.7789038
Encoder Loss:  0.023844056  || Decoder Loss:  0.003351153 Validation Decoder Loss:  0.7815779
Encoder Loss:  0.013653918  || Decoder Loss:  0.0033214963 Validation Decoder Loss:  0.7816253
Encoder Loss:  0.010408494  || Decoder Loss:  0.0032410466 Validation Decoder Loss:  0.77131045
Encoder Loss:  0.008225731  || Decoder Loss:  0.003089821 Validation Decoder Loss:  0.75524324
Encoder Loss:  0.006422318  || Decoder Loss:  0.0029636275 Validation Decoder Loss:  0.7434407
Encoder Loss:  0.006158277  || Decoder Loss:  0.0028745485 Validation Decoder Loss:  0.7334319
Encoder Loss:  0.005919762  || Decoder Loss:  0.0027836866 Validation Decoder Loss:  0.719655
Encoder Loss:  0.0057105836  || Decoder Loss:  0.002696009 Validation Decoder Loss:  0.7071947
Encoder Loss:  0.0055393563  || Decoder Loss:  0.0026236244 Validation Decoder Loss:  0.6961201
Encoder Loss:  0.005272444  || Decoder Loss:  0.0025542025 Validation Decoder Loss:  0.68443793
Encoder Loss:  0.004960926  || Decoder Loss:  0.0024599493 Validation Decoder Loss:  0.6700557
Encoder Loss:  0.004857661  || Decoder Loss:  0.002352096 Validation Decoder Loss:  0.65350366
Encoder Loss:  0.004752346  || Decoder Loss:  0.0022418366 Validation Decoder Loss:  0.6365258
Encoder Loss:  0.004655649  || Decoder Loss:  0.0021409933 Validation Decoder Loss:  0.6207735
Encoder Loss:  0.004571549  || Decoder Loss:  0.0020540757 Validation Decoder Loss:  0.6072701
Encoder Loss:  0.004498606  || Decoder Loss:  0.0019811115 Validation Decoder Loss:  0.59488887
Encoder Loss:  0.004434921  || Decoder Loss:  0.0019164769 Validation Decoder Loss:  0.58278626
Encoder Loss:  0.0043787183  || Decoder Loss:  0.0018585523 Validation Decoder Loss:  0.57102734
Encoder Loss:  0.0043302304  || Decoder Loss:  0.0018082269 Validation Decoder Loss:  0.5596634
Encoder Loss:  0.0042872545  || Decoder Loss:  0.0017632858 Validation Decoder Loss:  0.54876846
Encoder Loss:  0.0042500924  || Decoder Loss:  0.0017242378 Validation Decoder Loss:  0.53862834
Encoder Loss:  0.0042177145  || Decoder Loss:  0.0016898718 Validation Decoder Loss:  0.52955085
Encoder Loss:  0.0041913777  || Decoder Loss:  0.0016618206 Validation Decoder Loss:  0.5215679
Encoder Loss:  0.004170506  || Decoder Loss:  0.0016395658 Validation Decoder Loss:  0.51498157
Encoder Loss:  0.004154789  || Decoder Loss:  0.00162292 Validation Decoder Loss:  0.5093808
Encoder Loss:  0.004142207  || Decoder Loss:  0.0016095629 Validation Decoder Loss:  0.5046904
Encoder Loss:  0.0041335374  || Decoder Loss:  0.0016005009 Validation Decoder Loss:  0.5004623
Encoder Loss:  0.0041285884  || Decoder Loss:  0.0015956071 Validation Decoder Loss:  0.49673718
Encoder Loss:  0.004127615  || Decoder Loss:  0.0015951308 Validation Decoder Loss:  0.4934393
Encoder Loss:  0.004129277  || Decoder Loss:  0.0015976677 Validation Decoder Loss:  0.4903229
Encoder Loss:  0.004127708  || Decoder Loss:  0.0015961993 Validation Decoder Loss:  0.48684472
Encoder Loss:  0.0041283662  || Decoder Loss:  0.0015974023 Validation Decoder Loss:  0.4836576
Encoder Loss:  0.0041273995  || Decoder Loss:  0.0015965544 Validation Decoder Loss:  0.48060912
Encoder Loss:  0.00412087  || Decoder Loss:  0.0015892087 Validation Decoder Loss:  0.477198
Encoder Loss:  0.004108644  || Decoder Loss:  0.00157517 Validation Decoder Loss:  0.47357208
Encoder Loss:  0.004092363  || Decoder Loss:  0.0015564384 Validation Decoder Loss:  0.46976388
Encoder Loss:  0.0040742634  || Decoder Loss:  0.0015355403 Validation Decoder Loss:  0.46572715
Encoder Loss:  0.004054032  || Decoder Loss:  0.0015121659 Validation Decoder Loss:  0.46148095
Encoder Loss:  0.0040309276  || Decoder Loss:  0.0014854436 Validation Decoder Loss:  0.45704383
Model: bold_synthesis_net_lr_0.0008509171340802109 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.45704383
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_21 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 320, 8, 1)         2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.007990607 Validation Decoder Loss:  0.766932
Encoder Loss:  0.077009976  || Decoder Loss:  0.0059244 Validation Decoder Loss:  0.7672696
Encoder Loss:  0.0760524  || Decoder Loss:  0.004797878 Validation Decoder Loss:  0.7723186
Encoder Loss:  0.074848406  || Decoder Loss:  0.003381527 Validation Decoder Loss:  0.7723931
Encoder Loss:  0.07482032  || Decoder Loss:  0.0033484749 Validation Decoder Loss:  0.77228755
Encoder Loss:  0.07481678  || Decoder Loss:  0.0033442914 Validation Decoder Loss:  0.77225447
Encoder Loss:  0.07481326  || Decoder Loss:  0.0033401875 Validation Decoder Loss:  0.77253795
Encoder Loss:  0.074806534  || Decoder Loss:  0.0033322598 Validation Decoder Loss:  0.77252585
Encoder Loss:  0.07479549  || Decoder Loss:  0.0033192593 Validation Decoder Loss:  0.7722576
Encoder Loss:  0.07478618  || Decoder Loss:  0.0033083989 Validation Decoder Loss:  0.77207696
Encoder Loss:  0.07478237  || Decoder Loss:  0.0033038398 Validation Decoder Loss:  0.77196395
Encoder Loss:  0.07477975  || Decoder Loss:  0.0033007858 Validation Decoder Loss:  0.7718743
Encoder Loss:  0.074777484  || Decoder Loss:  0.0032980938 Validation Decoder Loss:  0.77179116
Encoder Loss:  0.0747753  || Decoder Loss:  0.003295452 Validation Decoder Loss:  0.77171904
Encoder Loss:  0.07477335  || Decoder Loss:  0.0032932425 Validation Decoder Loss:  0.77166677
Encoder Loss:  0.074771896  || Decoder Loss:  0.0032916127 Validation Decoder Loss:  0.7716394
Encoder Loss:  0.07477068  || Decoder Loss:  0.003290058 Validation Decoder Loss:  0.7716883
Encoder Loss:  0.07476659  || Decoder Loss:  0.0032852653 Validation Decoder Loss:  0.7723625
Encoder Loss:  0.07476153  || Decoder Loss:  0.0032792771 Validation Decoder Loss:  0.77234983
Encoder Loss:  0.07475802  || Decoder Loss:  0.0032751698 Validation Decoder Loss:  0.772313
Encoder Loss:  0.0747557  || Decoder Loss:  0.0032724098 Validation Decoder Loss:  0.7722821
Encoder Loss:  0.07475376  || Decoder Loss:  0.0032702938 Validation Decoder Loss:  0.7722554
Encoder Loss:  0.074752286  || Decoder Loss:  0.003268442 Validation Decoder Loss:  0.77223086
Encoder Loss:  0.07475083  || Decoder Loss:  0.0032666977 Validation Decoder Loss:  0.7722073
Encoder Loss:  0.07474927  || Decoder Loss:  0.0032649585 Validation Decoder Loss:  0.7721854
Encoder Loss:  0.07474776  || Decoder Loss:  0.0032631913 Validation Decoder Loss:  0.7721653
Encoder Loss:  0.07474613  || Decoder Loss:  0.003261353 Validation Decoder Loss:  0.7721466
Encoder Loss:  0.07474448  || Decoder Loss:  0.0032593757 Validation Decoder Loss:  0.7721376
Encoder Loss:  0.07474271  || Decoder Loss:  0.0032572406 Validation Decoder Loss:  0.7721276
Encoder Loss:  0.07474081  || Decoder Loss:  0.0032549847 Validation Decoder Loss:  0.77214384
Encoder Loss:  0.07473875  || Decoder Loss:  0.003252533 Validation Decoder Loss:  0.7721298
Encoder Loss:  0.07473659  || Decoder Loss:  0.0032499703 Validation Decoder Loss:  0.7721009
Encoder Loss:  0.074734375  || Decoder Loss:  0.003247392 Validation Decoder Loss:  0.7721536
Encoder Loss:  0.07473198  || Decoder Loss:  0.0032446156 Validation Decoder Loss:  0.77211213
Encoder Loss:  0.07472953  || Decoder Loss:  0.003241665 Validation Decoder Loss:  0.7720111
Encoder Loss:  0.07472514  || Decoder Loss:  0.0032365196 Validation Decoder Loss:  0.7712297
Encoder Loss:  0.07472157  || Decoder Loss:  0.0032322037 Validation Decoder Loss:  0.7708473
Encoder Loss:  0.0747192  || Decoder Loss:  0.0032295554 Validation Decoder Loss:  0.77068543
Encoder Loss:  0.07471745  || Decoder Loss:  0.003227393 Validation Decoder Loss:  0.7705832
Encoder Loss:  0.0747157  || Decoder Loss:  0.00322537 Validation Decoder Loss:  0.7705008
Model: bold_synthesis_net_lr_0.0008413774060059128 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7705008
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_22 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.0069871047 Validation Decoder Loss:  0.7632504
Encoder Loss:  0.06041075  || Decoder Loss:  0.0033808781 Validation Decoder Loss:  0.758854
Encoder Loss:  0.06033868  || Decoder Loss:  0.0032989506 Validation Decoder Loss:  0.754071
Encoder Loss:  0.06031328  || Decoder Loss:  0.003270135 Validation Decoder Loss:  0.7424332
Encoder Loss:  0.05995515  || Decoder Loss:  0.002863313 Validation Decoder Loss:  0.6428182
Encoder Loss:  0.05983451  || Decoder Loss:  0.0027262513 Validation Decoder Loss:  0.6403079
Encoder Loss:  0.05980733  || Decoder Loss:  0.0026954154 Validation Decoder Loss:  0.63969624
Encoder Loss:  0.05979365  || Decoder Loss:  0.0026798975 Validation Decoder Loss:  0.63987404
Encoder Loss:  0.059773695  || Decoder Loss:  0.0026572396 Validation Decoder Loss:  0.6405391
Encoder Loss:  0.059759215  || Decoder Loss:  0.0026407791 Validation Decoder Loss:  0.64088106
Encoder Loss:  0.059749585  || Decoder Loss:  0.0026297788 Validation Decoder Loss:  0.6411221
Encoder Loss:  0.059741307  || Decoder Loss:  0.002620375 Validation Decoder Loss:  0.6413264
Encoder Loss:  0.059734028  || Decoder Loss:  0.0026121433 Validation Decoder Loss:  0.6415426
Encoder Loss:  0.059727363  || Decoder Loss:  0.002604543 Validation Decoder Loss:  0.64176726
Encoder Loss:  0.059720106  || Decoder Loss:  0.0025963662 Validation Decoder Loss:  0.6419498
Encoder Loss:  0.0597118  || Decoder Loss:  0.0025868863 Validation Decoder Loss:  0.6419921
Encoder Loss:  0.05970156  || Decoder Loss:  0.002575269 Validation Decoder Loss:  0.64181435
Encoder Loss:  0.059692707  || Decoder Loss:  0.0025652382 Validation Decoder Loss:  0.64147264
Encoder Loss:  0.05968637  || Decoder Loss:  0.0025580171 Validation Decoder Loss:  0.64097613
Encoder Loss:  0.059681352  || Decoder Loss:  0.00255233 Validation Decoder Loss:  0.6403553
Encoder Loss:  0.05966724  || Decoder Loss:  0.002536299 Validation Decoder Loss:  0.6400376
Encoder Loss:  0.059638202  || Decoder Loss:  0.0025033099 Validation Decoder Loss:  0.6249235
Encoder Loss:  0.059298933  || Decoder Loss:  0.0021179253 Validation Decoder Loss:  0.5112304
Encoder Loss:  0.059162922  || Decoder Loss:  0.0019634292 Validation Decoder Loss:  0.45209253
Encoder Loss:  0.058892738  || Decoder Loss:  0.0016565323 Validation Decoder Loss:  0.42165878
Encoder Loss:  0.05885827  || Decoder Loss:  0.0016174128 Validation Decoder Loss:  0.42076096
Encoder Loss:  0.05884663  || Decoder Loss:  0.0016041438 Validation Decoder Loss:  0.42034492
Encoder Loss:  0.058839113  || Decoder Loss:  0.0015955897 Validation Decoder Loss:  0.41984975
Encoder Loss:  0.05883467  || Decoder Loss:  0.0015905339 Validation Decoder Loss:  0.41914317
Encoder Loss:  0.058830135  || Decoder Loss:  0.001585403 Validation Decoder Loss:  0.4185371
Encoder Loss:  0.058825385  || Decoder Loss:  0.0015800167 Validation Decoder Loss:  0.41797706
Encoder Loss:  0.05881989  || Decoder Loss:  0.0015738286 Validation Decoder Loss:  0.41688138
Encoder Loss:  0.058811028  || Decoder Loss:  0.0015637152 Validation Decoder Loss:  0.413452
Encoder Loss:  0.05879785  || Decoder Loss:  0.0015487515 Validation Decoder Loss:  0.4110289
Encoder Loss:  0.05878956  || Decoder Loss:  0.001539334 Validation Decoder Loss:  0.4107234
Encoder Loss:  0.058784056  || Decoder Loss:  0.001533086 Validation Decoder Loss:  0.4108552
Encoder Loss:  0.058779456  || Decoder Loss:  0.0015278055 Validation Decoder Loss:  0.41098666
Encoder Loss:  0.058775596  || Decoder Loss:  0.001523445 Validation Decoder Loss:  0.41102222
Encoder Loss:  0.058772247  || Decoder Loss:  0.0015196775 Validation Decoder Loss:  0.4110253
Encoder Loss:  0.05876953  || Decoder Loss:  0.0015165366 Validation Decoder Loss:  0.411003
Model: bold_synthesis_net_lr_0.0008658224465657658 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.411003
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_23 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 320, 8, 1)         694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03459339  || Decoder Loss:  0.0059099295 Validation Decoder Loss:  0.74514365
Encoder Loss:  0.025147727  || Decoder Loss:  0.003170149 Validation Decoder Loss:  0.6819493
Encoder Loss:  0.019873343  || Decoder Loss:  0.00294421 Validation Decoder Loss:  0.65169036
Encoder Loss:  0.016786529  || Decoder Loss:  0.002810898 Validation Decoder Loss:  0.6401364
Encoder Loss:  0.01462777  || Decoder Loss:  0.0027487227 Validation Decoder Loss:  0.6326357
Encoder Loss:  0.012000361  || Decoder Loss:  0.0027016574 Validation Decoder Loss:  0.62568086
Encoder Loss:  0.010912771  || Decoder Loss:  0.002663087 Validation Decoder Loss:  0.61943895
Encoder Loss:  0.009955643  || Decoder Loss:  0.0026338464 Validation Decoder Loss:  0.6131759
Encoder Loss:  0.00924774  || Decoder Loss:  0.0026100215 Validation Decoder Loss:  0.6060478
Encoder Loss:  0.0086561  || Decoder Loss:  0.0025941664 Validation Decoder Loss:  0.5985384
Encoder Loss:  0.008164352  || Decoder Loss:  0.0025846036 Validation Decoder Loss:  0.5907298
Encoder Loss:  0.0077896407  || Decoder Loss:  0.0025855144 Validation Decoder Loss:  0.5829541
Encoder Loss:  0.0074316496  || Decoder Loss:  0.0025969516 Validation Decoder Loss:  0.57509124
Encoder Loss:  0.007155422  || Decoder Loss:  0.0026099284 Validation Decoder Loss:  0.5672837
Encoder Loss:  0.0069291284  || Decoder Loss:  0.00262762 Validation Decoder Loss:  0.559446
Encoder Loss:  0.006727638  || Decoder Loss:  0.0026427363 Validation Decoder Loss:  0.5509262
Encoder Loss:  0.0065405457  || Decoder Loss:  0.002651196 Validation Decoder Loss:  0.54181236
Encoder Loss:  0.0063822246  || Decoder Loss:  0.0026621644 Validation Decoder Loss:  0.53248155
Encoder Loss:  0.0062454287  || Decoder Loss:  0.0026750264 Validation Decoder Loss:  0.5227535
Encoder Loss:  0.0061328276  || Decoder Loss:  0.0026886058 Validation Decoder Loss:  0.51354647
Encoder Loss:  0.0060329973  || Decoder Loss:  0.0027105298 Validation Decoder Loss:  0.50401723
Encoder Loss:  0.0057564145  || Decoder Loss:  0.002670184 Validation Decoder Loss:  0.48956138
Encoder Loss:  0.0054958626  || Decoder Loss:  0.002630094 Validation Decoder Loss:  0.47893718
Encoder Loss:  0.0052301353  || Decoder Loss:  0.0026186465 Validation Decoder Loss:  0.46500972
Encoder Loss:  0.0049092467  || Decoder Loss:  0.002551395 Validation Decoder Loss:  0.44953635
Encoder Loss:  0.0046757734  || Decoder Loss:  0.0024341682 Validation Decoder Loss:  0.43707517
Encoder Loss:  0.004623393  || Decoder Loss:  0.0024100535 Validation Decoder Loss:  0.43031216
Encoder Loss:  0.0046014963  || Decoder Loss:  0.002415451 Validation Decoder Loss:  0.42618707
Encoder Loss:  0.004582968  || Decoder Loss:  0.002426316 Validation Decoder Loss:  0.42334095
Encoder Loss:  0.0045743166  || Decoder Loss:  0.0024444503 Validation Decoder Loss:  0.4223171
Encoder Loss:  0.0045772623  || Decoder Loss:  0.0024701753 Validation Decoder Loss:  0.4229807
Encoder Loss:  0.0045815054  || Decoder Loss:  0.0024954982 Validation Decoder Loss:  0.42422214
Encoder Loss:  0.0045920936  || Decoder Loss:  0.002525165 Validation Decoder Loss:  0.4265592
Encoder Loss:  0.0045997603  || Decoder Loss:  0.0025506716 Validation Decoder Loss:  0.42958426
Encoder Loss:  0.004605419  || Decoder Loss:  0.0025737518 Validation Decoder Loss:  0.4331168
Encoder Loss:  0.004615727  || Decoder Loss:  0.002600837 Validation Decoder Loss:  0.43690273
Encoder Loss:  0.0046351966  || Decoder Loss:  0.0026348154 Validation Decoder Loss:  0.4417636
Encoder Loss:  0.004663508  || Decoder Loss:  0.0026775503 Validation Decoder Loss:  0.4467483
Encoder Loss:  0.004697421  || Decoder Loss:  0.0027256103 Validation Decoder Loss:  0.45171535
Encoder Loss:  0.004737018  || Decoder Loss:  0.0027792037 Validation Decoder Loss:  0.4567793
Model: bold_synthesis_net_lr_0.0008901687784892776 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.4567793
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_24 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 320, 8, 1)         56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037703194  || Decoder Loss:  0.007988325 Validation Decoder Loss:  0.768214
Encoder Loss:  0.029484745  || Decoder Loss:  0.0042060213 Validation Decoder Loss:  0.7784189
Encoder Loss:  0.02361678  || Decoder Loss:  0.0033526313 Validation Decoder Loss:  0.77893376
Encoder Loss:  0.01944562  || Decoder Loss:  0.003302117 Validation Decoder Loss:  0.77712625
Encoder Loss:  0.01567419  || Decoder Loss:  0.003289451 Validation Decoder Loss:  0.77580607
Encoder Loss:  0.012708742  || Decoder Loss:  0.0032587384 Validation Decoder Loss:  0.7733378
Encoder Loss:  0.010066047  || Decoder Loss:  0.003216 Validation Decoder Loss:  0.7702406
Encoder Loss:  0.00857645  || Decoder Loss:  0.003174417 Validation Decoder Loss:  0.76645684
Encoder Loss:  0.007362976  || Decoder Loss:  0.0031167949 Validation Decoder Loss:  0.76124644
Encoder Loss:  0.00668084  || Decoder Loss:  0.0030259825 Validation Decoder Loss:  0.75277156
Encoder Loss:  0.00613604  || Decoder Loss:  0.002879738 Validation Decoder Loss:  0.73759127
Encoder Loss:  0.005600209  || Decoder Loss:  0.0026766586 Validation Decoder Loss:  0.7159293
Encoder Loss:  0.0050021075  || Decoder Loss:  0.0024618781 Validation Decoder Loss:  0.692367
Encoder Loss:  0.0044095144  || Decoder Loss:  0.002276332 Validation Decoder Loss:  0.66928256
Encoder Loss:  0.0040729796  || Decoder Loss:  0.0021043469 Validation Decoder Loss:  0.6461618
Encoder Loss:  0.003834811  || Decoder Loss:  0.0019475978 Validation Decoder Loss:  0.6243893
Encoder Loss:  0.0036473037  || Decoder Loss:  0.0018175455 Validation Decoder Loss:  0.6047014
Encoder Loss:  0.003453183  || Decoder Loss:  0.0017039978 Validation Decoder Loss:  0.58653253
Encoder Loss:  0.0032739746  || Decoder Loss:  0.0015935375 Validation Decoder Loss:  0.5691136
Encoder Loss:  0.0031486987  || Decoder Loss:  0.0014958254 Validation Decoder Loss:  0.5529708
Encoder Loss:  0.003038564  || Decoder Loss:  0.0014082802 Validation Decoder Loss:  0.53823817
Encoder Loss:  0.0029503382  || Decoder Loss:  0.0013326993 Validation Decoder Loss:  0.52546054
Encoder Loss:  0.002878486  || Decoder Loss:  0.0012687626 Validation Decoder Loss:  0.514348
Encoder Loss:  0.002819083  || Decoder Loss:  0.0012154293 Validation Decoder Loss:  0.50504607
Encoder Loss:  0.0027684688  || Decoder Loss:  0.0011691069 Validation Decoder Loss:  0.49707982
Encoder Loss:  0.002724855  || Decoder Loss:  0.0011281386 Validation Decoder Loss:  0.48984775
Encoder Loss:  0.002686288  || Decoder Loss:  0.0010911815 Validation Decoder Loss:  0.48365784
Encoder Loss:  0.0026516388  || Decoder Loss:  0.0010574105 Validation Decoder Loss:  0.47807038
Encoder Loss:  0.0026217436  || Decoder Loss:  0.0010279801 Validation Decoder Loss:  0.47305042
Encoder Loss:  0.0025951022  || Decoder Loss:  0.0010014429 Validation Decoder Loss:  0.46851146
Encoder Loss:  0.0025703881  || Decoder Loss:  0.0009764875 Validation Decoder Loss:  0.4642664
Encoder Loss:  0.0025488047  || Decoder Loss:  0.000954529 Validation Decoder Loss:  0.46043175
Encoder Loss:  0.0025314246  || Decoder Loss:  0.00093683356 Validation Decoder Loss:  0.4570367
Encoder Loss:  0.0025142336  || Decoder Loss:  0.00091908034 Validation Decoder Loss:  0.45391476
Encoder Loss:  0.002500586  || Decoder Loss:  0.00090498955 Validation Decoder Loss:  0.4508931
Encoder Loss:  0.0024926285  || Decoder Loss:  0.0008969897 Validation Decoder Loss:  0.44865006
Encoder Loss:  0.0024960623  || Decoder Loss:  0.0009013587 Validation Decoder Loss:  0.44739586
Encoder Loss:  0.0024948504  || Decoder Loss:  0.000900424 Validation Decoder Loss:  0.44582167
Encoder Loss:  0.0024880446  || Decoder Loss:  0.0008932812 Validation Decoder Loss:  0.4441421
Encoder Loss:  0.0024788075  || Decoder Loss:  0.0008834258 Validation Decoder Loss:  0.44228104
Model: bold_synthesis_net_lr_0.0008946385638671043 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.44228104
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_25 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 320, 8, 1)         2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.005816696  || Decoder Loss:  0.005816696 Validation Decoder Loss:  0.7537618
Encoder Loss:  0.0033262433  || Decoder Loss:  0.0033262433 Validation Decoder Loss:  0.71670604
Encoder Loss:  0.002987005  || Decoder Loss:  0.002987005 Validation Decoder Loss:  0.65411264
Encoder Loss:  0.0028737504  || Decoder Loss:  0.0028737504 Validation Decoder Loss:  0.6525428
Encoder Loss:  0.0028310367  || Decoder Loss:  0.0028310367 Validation Decoder Loss:  0.65291387
Encoder Loss:  0.0027905144  || Decoder Loss:  0.0027905144 Validation Decoder Loss:  0.6528622
Encoder Loss:  0.002757231  || Decoder Loss:  0.002757231 Validation Decoder Loss:  0.6514446
Encoder Loss:  0.0027322501  || Decoder Loss:  0.0027322501 Validation Decoder Loss:  0.6463207
Encoder Loss:  0.0024446074  || Decoder Loss:  0.0024446074 Validation Decoder Loss:  0.52064985
Encoder Loss:  0.0020711035  || Decoder Loss:  0.0020711035 Validation Decoder Loss:  0.5127135
Encoder Loss:  0.0020449087  || Decoder Loss:  0.0020449087 Validation Decoder Loss:  0.5049577
Encoder Loss:  0.0017972835  || Decoder Loss:  0.0017972835 Validation Decoder Loss:  0.42193082
Encoder Loss:  0.0016852249  || Decoder Loss:  0.0016852249 Validation Decoder Loss:  0.41875476
Encoder Loss:  0.0016718828  || Decoder Loss:  0.0016718828 Validation Decoder Loss:  0.41767403
Encoder Loss:  0.0016600025  || Decoder Loss:  0.0016600025 Validation Decoder Loss:  0.4178359
Encoder Loss:  0.0016476376  || Decoder Loss:  0.0016476376 Validation Decoder Loss:  0.4180677
Encoder Loss:  0.0016363588  || Decoder Loss:  0.0016363588 Validation Decoder Loss:  0.41804013
Encoder Loss:  0.0016269941  || Decoder Loss:  0.0016269941 Validation Decoder Loss:  0.41803235
Encoder Loss:  0.0016190133  || Decoder Loss:  0.0016190133 Validation Decoder Loss:  0.41814435
Encoder Loss:  0.0016118924  || Decoder Loss:  0.0016118924 Validation Decoder Loss:  0.41829616
Encoder Loss:  0.0016055343  || Decoder Loss:  0.0016055343 Validation Decoder Loss:  0.41847348
Encoder Loss:  0.0015998243  || Decoder Loss:  0.0015998243 Validation Decoder Loss:  0.41858342
Encoder Loss:  0.001594483  || Decoder Loss:  0.001594483 Validation Decoder Loss:  0.41863796
Encoder Loss:  0.0015895802  || Decoder Loss:  0.0015895802 Validation Decoder Loss:  0.4185452
Encoder Loss:  0.0015848029  || Decoder Loss:  0.0015848029 Validation Decoder Loss:  0.4184148
Encoder Loss:  0.0015801196  || Decoder Loss:  0.0015801196 Validation Decoder Loss:  0.4180189
Encoder Loss:  0.0015750937  || Decoder Loss:  0.0015750937 Validation Decoder Loss:  0.41710716
Encoder Loss:  0.0015682966  || Decoder Loss:  0.0015682966 Validation Decoder Loss:  0.41451946
Encoder Loss:  0.0015591836  || Decoder Loss:  0.0015591836 Validation Decoder Loss:  0.41246566
Encoder Loss:  0.0015531944  || Decoder Loss:  0.0015531944 Validation Decoder Loss:  0.41165528
Encoder Loss:  0.0015489773  || Decoder Loss:  0.0015489773 Validation Decoder Loss:  0.411229
Encoder Loss:  0.0015453274  || Decoder Loss:  0.0015453274 Validation Decoder Loss:  0.41093373
Encoder Loss:  0.0015419812  || Decoder Loss:  0.0015419812 Validation Decoder Loss:  0.4107038
Encoder Loss:  0.0015387961  || Decoder Loss:  0.0015387961 Validation Decoder Loss:  0.41051987
Encoder Loss:  0.0015356105  || Decoder Loss:  0.0015356105 Validation Decoder Loss:  0.41038096
Encoder Loss:  0.0015324989  || Decoder Loss:  0.0015324989 Validation Decoder Loss:  0.41027427
Encoder Loss:  0.0015293964  || Decoder Loss:  0.0015293964 Validation Decoder Loss:  0.41018638
Encoder Loss:  0.0015263387  || Decoder Loss:  0.0015263387 Validation Decoder Loss:  0.4100944
Encoder Loss:  0.0015232951  || Decoder Loss:  0.0015232951 Validation Decoder Loss:  0.41000766
Encoder Loss:  0.0015203096  || Decoder Loss:  0.0015203096 Validation Decoder Loss:  0.40994895
Model: bold_synthesis_net_lr_0.0009631041553792925 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.40994895
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_26 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 320, 8, 1)         56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 2607, 8, 1)        1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.007018965  || Decoder Loss:  0.007018965 Validation Decoder Loss:  0.7766119
Encoder Loss:  0.0033804527  || Decoder Loss:  0.0033804527 Validation Decoder Loss:  0.77698356
Encoder Loss:  0.0033023166  || Decoder Loss:  0.0033023166 Validation Decoder Loss:  0.7750247
Encoder Loss:  0.0032254043  || Decoder Loss:  0.0032254043 Validation Decoder Loss:  0.7741699
Encoder Loss:  0.003209349  || Decoder Loss:  0.003209349 Validation Decoder Loss:  0.7740564
Encoder Loss:  0.0031996046  || Decoder Loss:  0.0031996046 Validation Decoder Loss:  0.7740852
Encoder Loss:  0.003190583  || Decoder Loss:  0.003190583 Validation Decoder Loss:  0.77421343
Encoder Loss:  0.003182046  || Decoder Loss:  0.003182046 Validation Decoder Loss:  0.77424157
Encoder Loss:  0.0031742128  || Decoder Loss:  0.0031742128 Validation Decoder Loss:  0.77427864
Encoder Loss:  0.003165581  || Decoder Loss:  0.003165581 Validation Decoder Loss:  0.77429587
Encoder Loss:  0.0031522883  || Decoder Loss:  0.0031522883 Validation Decoder Loss:  0.7731557
Encoder Loss:  0.0031214296  || Decoder Loss:  0.0031214296 Validation Decoder Loss:  0.77109915
Encoder Loss:  0.0030942005  || Decoder Loss:  0.0030942005 Validation Decoder Loss:  0.77021056
Encoder Loss:  0.003079285  || Decoder Loss:  0.003079285 Validation Decoder Loss:  0.77062833
Encoder Loss:  0.0030329723  || Decoder Loss:  0.0030329723 Validation Decoder Loss:  0.76901317
Encoder Loss:  0.0029993115  || Decoder Loss:  0.0029993115 Validation Decoder Loss:  0.7693288
Encoder Loss:  0.0029834898  || Decoder Loss:  0.0029834898 Validation Decoder Loss:  0.7697944
Encoder Loss:  0.0029647935  || Decoder Loss:  0.0029647935 Validation Decoder Loss:  0.77116036
Encoder Loss:  0.0029212548  || Decoder Loss:  0.0029212548 Validation Decoder Loss:  0.7724609
Encoder Loss:  0.002901804  || Decoder Loss:  0.002901804 Validation Decoder Loss:  0.7725302
Encoder Loss:  0.0028891058  || Decoder Loss:  0.0028891058 Validation Decoder Loss:  0.7723084
Encoder Loss:  0.0028736652  || Decoder Loss:  0.0028736652 Validation Decoder Loss:  0.773703
Encoder Loss:  0.0028599382  || Decoder Loss:  0.0028599382 Validation Decoder Loss:  0.7735402
Encoder Loss:  0.0028430326  || Decoder Loss:  0.0028430326 Validation Decoder Loss:  0.77028435
Encoder Loss:  0.002823758  || Decoder Loss:  0.002823758 Validation Decoder Loss:  0.7701304
Encoder Loss:  0.0028082263  || Decoder Loss:  0.0028082263 Validation Decoder Loss:  0.76869226
Encoder Loss:  0.0027982716  || Decoder Loss:  0.0027982716 Validation Decoder Loss:  0.7693149
Encoder Loss:  0.002789712  || Decoder Loss:  0.002789712 Validation Decoder Loss:  0.76809317
Encoder Loss:  0.0027842445  || Decoder Loss:  0.0027842445 Validation Decoder Loss:  0.76879394
Encoder Loss:  0.0027781825  || Decoder Loss:  0.0027781825 Validation Decoder Loss:  0.7675944
Encoder Loss:  0.0027740886  || Decoder Loss:  0.0027740886 Validation Decoder Loss:  0.7683638
Encoder Loss:  0.0027681692  || Decoder Loss:  0.0027681692 Validation Decoder Loss:  0.7662567
Encoder Loss:  0.0027633207  || Decoder Loss:  0.0027633207 Validation Decoder Loss:  0.7667358
Encoder Loss:  0.0027586175  || Decoder Loss:  0.0027586175 Validation Decoder Loss:  0.7650729
Encoder Loss:  0.002754909  || Decoder Loss:  0.002754909 Validation Decoder Loss:  0.7662475
Encoder Loss:  0.0027509436  || Decoder Loss:  0.0027509436 Validation Decoder Loss:  0.7646378
Encoder Loss:  0.0027479453  || Decoder Loss:  0.0027479453 Validation Decoder Loss:  0.7658883
Encoder Loss:  0.0027446172  || Decoder Loss:  0.0027446172 Validation Decoder Loss:  0.76436687
Encoder Loss:  0.0027420486  || Decoder Loss:  0.0027420486 Validation Decoder Loss:  0.76557976
Encoder Loss:  0.0027388055  || Decoder Loss:  0.0027388055 Validation Decoder Loss:  0.7642462
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7642462
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_27 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 320, 8, 1)         1970      
=================================================================
Total params: 1,970
Trainable params: 1,970
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2607, 8, 1)        1970      
=================================================================
Total params: 1,970
Trainable params: 1,970
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.007847208 Validation Decoder Loss:  0.767603
Encoder Loss:  0.014153273  || Decoder Loss:  0.0063137654 Validation Decoder Loss:  0.76646614
Encoder Loss:  0.0133489305  || Decoder Loss:  0.0054958966 Validation Decoder Loss:  0.76617974
Encoder Loss:  0.012992662  || Decoder Loss:  0.005133631 Validation Decoder Loss:  0.7660531
Encoder Loss:  0.012768617  || Decoder Loss:  0.0049058115 Validation Decoder Loss:  0.7659158
Encoder Loss:  0.01258773  || Decoder Loss:  0.004721879 Validation Decoder Loss:  0.7657431
Encoder Loss:  0.012431704  || Decoder Loss:  0.004563236 Validation Decoder Loss:  0.7655424
Encoder Loss:  0.0122908885  || Decoder Loss:  0.0044200416 Validation Decoder Loss:  0.7653048
Encoder Loss:  0.012149627  || Decoder Loss:  0.0042764056 Validation Decoder Loss:  0.7650007
Encoder Loss:  0.012034029  || Decoder Loss:  0.0041588536 Validation Decoder Loss:  0.76467866
Encoder Loss:  0.011923739  || Decoder Loss:  0.004046715 Validation Decoder Loss:  0.7642746
Encoder Loss:  0.011808727  || Decoder Loss:  0.0039297664 Validation Decoder Loss:  0.76383054
Encoder Loss:  0.011705516  || Decoder Loss:  0.003824816 Validation Decoder Loss:  0.76351035
Encoder Loss:  0.011628106  || Decoder Loss:  0.003746102 Validation Decoder Loss:  0.76315236
Encoder Loss:  0.011535018  || Decoder Loss:  0.0036514516 Validation Decoder Loss:  0.7624585
Encoder Loss:  0.011327904  || Decoder Loss:  0.0034408558 Validation Decoder Loss:  0.7591131
Encoder Loss:  0.011257558  || Decoder Loss:  0.003369331 Validation Decoder Loss:  0.75893486
Encoder Loss:  0.011253761  || Decoder Loss:  0.0033654731 Validation Decoder Loss:  0.7588264
Encoder Loss:  0.011250811  || Decoder Loss:  0.0033624698 Validation Decoder Loss:  0.75872666
Encoder Loss:  0.0112480465  || Decoder Loss:  0.0033596535 Validation Decoder Loss:  0.7586531
Encoder Loss:  0.011245354  || Decoder Loss:  0.0033569161 Validation Decoder Loss:  0.7585867
Encoder Loss:  0.011242946  || Decoder Loss:  0.0033544665 Validation Decoder Loss:  0.758525
Encoder Loss:  0.011240883  || Decoder Loss:  0.0033523696 Validation Decoder Loss:  0.7584714
Encoder Loss:  0.011234437  || Decoder Loss:  0.0033458145 Validation Decoder Loss:  0.75641435
Encoder Loss:  0.011215825  || Decoder Loss:  0.0033268882 Validation Decoder Loss:  0.7560479
Encoder Loss:  0.011211208  || Decoder Loss:  0.0033221946 Validation Decoder Loss:  0.75589824
Encoder Loss:  0.011208573  || Decoder Loss:  0.0033195156 Validation Decoder Loss:  0.7558013
Encoder Loss:  0.011206625  || Decoder Loss:  0.0033175433 Validation Decoder Loss:  0.755724
Encoder Loss:  0.011204979  || Decoder Loss:  0.0033158646 Validation Decoder Loss:  0.75565094
Encoder Loss:  0.01120346  || Decoder Loss:  0.00331432 Validation Decoder Loss:  0.75555664
Encoder Loss:  0.011201951  || Decoder Loss:  0.0033127812 Validation Decoder Loss:  0.75540334
Encoder Loss:  0.011200322  || Decoder Loss:  0.0033111225 Validation Decoder Loss:  0.7550899
Encoder Loss:  0.011198473  || Decoder Loss:  0.0033092503 Validation Decoder Loss:  0.75458604
Encoder Loss:  0.011195739  || Decoder Loss:  0.0033064587 Validation Decoder Loss:  0.75432396
Encoder Loss:  0.011192828  || Decoder Loss:  0.003303505 Validation Decoder Loss:  0.7543387
Encoder Loss:  0.011190537  || Decoder Loss:  0.0033011783 Validation Decoder Loss:  0.754379
Encoder Loss:  0.011189459  || Decoder Loss:  0.003300077 Validation Decoder Loss:  0.75432897
Encoder Loss:  0.01118767  || Decoder Loss:  0.0032982598 Validation Decoder Loss:  0.7545605
Encoder Loss:  0.011186495  || Decoder Loss:  0.00329706 Validation Decoder Loss:  0.75433135
Encoder Loss:  0.01118529  || Decoder Loss:  0.0032958405 Validation Decoder Loss:  0.754608
Model: bold_synthesis_net_lr_0.000918487303235254 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.754608
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_28 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 2607, 8, 1)        1013      
=================================================================
Total params: 1,013
Trainable params: 1,013
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.0085244775 Validation Decoder Loss:  0.7661608
Encoder Loss:  0.13125587  || Decoder Loss:  0.007983227 Validation Decoder Loss:  0.7668972
Encoder Loss:  0.13034736  || Decoder Loss:  0.0067533622 Validation Decoder Loss:  0.76895875
Encoder Loss:  0.12837215  || Decoder Loss:  0.004080254 Validation Decoder Loss:  0.76875883
Encoder Loss:  0.12788776  || Decoder Loss:  0.0034246116 Validation Decoder Loss:  0.76890993
Encoder Loss:  0.12782653  || Decoder Loss:  0.0033416427 Validation Decoder Loss:  0.7687439
Encoder Loss:  0.12779723  || Decoder Loss:  0.0033020882 Validation Decoder Loss:  0.76799446
Encoder Loss:  0.12777916  || Decoder Loss:  0.0032773998 Validation Decoder Loss:  0.7679443
Encoder Loss:  0.12776999  || Decoder Loss:  0.0032652733 Validation Decoder Loss:  0.7680714
Encoder Loss:  0.12776247  || Decoder Loss:  0.003255056 Validation Decoder Loss:  0.7684944
Encoder Loss:  0.12774861  || Decoder Loss:  0.0032361564 Validation Decoder Loss:  0.7690902
Encoder Loss:  0.12773551  || Decoder Loss:  0.0032184052 Validation Decoder Loss:  0.76919335
Encoder Loss:  0.12772852  || Decoder Loss:  0.0032091858 Validation Decoder Loss:  0.7692733
Encoder Loss:  0.12772296  || Decoder Loss:  0.003201554 Validation Decoder Loss:  0.7694002
Encoder Loss:  0.12771603  || Decoder Loss:  0.0031922343 Validation Decoder Loss:  0.76973647
Encoder Loss:  0.12769866  || Decoder Loss:  0.003168619 Validation Decoder Loss:  0.7702528
Encoder Loss:  0.12767676  || Decoder Loss:  0.0031391466 Validation Decoder Loss:  0.77013135
Encoder Loss:  0.12766851  || Decoder Loss:  0.0031277442 Validation Decoder Loss:  0.7699697
Encoder Loss:  0.12766191  || Decoder Loss:  0.0031190768 Validation Decoder Loss:  0.76974183
Encoder Loss:  0.12765642  || Decoder Loss:  0.003111367 Validation Decoder Loss:  0.769346
Encoder Loss:  0.12765108  || Decoder Loss:  0.0031043591 Validation Decoder Loss:  0.76875246
Encoder Loss:  0.12764627  || Decoder Loss:  0.0030975493 Validation Decoder Loss:  0.7680201
Encoder Loss:  0.1276416  || Decoder Loss:  0.0030914864 Validation Decoder Loss:  0.7673619
Encoder Loss:  0.1276377  || Decoder Loss:  0.0030861262 Validation Decoder Loss:  0.76672685
Encoder Loss:  0.12763423  || Decoder Loss:  0.0030814847 Validation Decoder Loss:  0.76610947
Encoder Loss:  0.12763178  || Decoder Loss:  0.0030783282 Validation Decoder Loss:  0.7657064
Encoder Loss:  0.12763026  || Decoder Loss:  0.0030761247 Validation Decoder Loss:  0.7654575
Encoder Loss:  0.1276291  || Decoder Loss:  0.0030743333 Validation Decoder Loss:  0.7652914
Encoder Loss:  0.12762788  || Decoder Loss:  0.003072786 Validation Decoder Loss:  0.7651648
Encoder Loss:  0.12762684  || Decoder Loss:  0.0030713966 Validation Decoder Loss:  0.7650597
Encoder Loss:  0.12762584  || Decoder Loss:  0.0030701172 Validation Decoder Loss:  0.76497245
Encoder Loss:  0.12762494  || Decoder Loss:  0.0030689123 Validation Decoder Loss:  0.7648917
Encoder Loss:  0.12762403  || Decoder Loss:  0.0030677672 Validation Decoder Loss:  0.76482224
Encoder Loss:  0.12762336  || Decoder Loss:  0.0030666664 Validation Decoder Loss:  0.76476645
Encoder Loss:  0.12762266  || Decoder Loss:  0.0030656056 Validation Decoder Loss:  0.7647127
Encoder Loss:  0.12762183  || Decoder Loss:  0.0030645907 Validation Decoder Loss:  0.76465774
Encoder Loss:  0.12762117  || Decoder Loss:  0.0030635914 Validation Decoder Loss:  0.764613
Encoder Loss:  0.12762035  || Decoder Loss:  0.0030626296 Validation Decoder Loss:  0.7645723
Encoder Loss:  0.12761964  || Decoder Loss:  0.0030616939 Validation Decoder Loss:  0.7645373
Encoder Loss:  0.12761913  || Decoder Loss:  0.0030607893 Validation Decoder Loss:  0.7645127
Model: bold_synthesis_net_lr_0.0003160196189458321 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7645127
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_29 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 320, 8, 1)         2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.006725684 Validation Decoder Loss:  0.76990026
Encoder Loss:  0.05774963  || Decoder Loss:  0.0032833286 Validation Decoder Loss:  0.7665525
Encoder Loss:  0.057717036  || Decoder Loss:  0.0032465465 Validation Decoder Loss:  0.7659262
Encoder Loss:  0.057690088  || Decoder Loss:  0.0032160557 Validation Decoder Loss:  0.76450026
Encoder Loss:  0.057674736  || Decoder Loss:  0.003198765 Validation Decoder Loss:  0.7639348
Encoder Loss:  0.05766479  || Decoder Loss:  0.0031875058 Validation Decoder Loss:  0.76400876
Encoder Loss:  0.057651557  || Decoder Loss:  0.0031725923 Validation Decoder Loss:  0.76517236
Encoder Loss:  0.05763145  || Decoder Loss:  0.0031498808 Validation Decoder Loss:  0.76622444
Encoder Loss:  0.057615846  || Decoder Loss:  0.0031322879 Validation Decoder Loss:  0.7662688
Encoder Loss:  0.05760697  || Decoder Loss:  0.003122255 Validation Decoder Loss:  0.76608694
Encoder Loss:  0.05758929  || Decoder Loss:  0.0031022702 Validation Decoder Loss:  0.7639006
Encoder Loss:  0.05757277  || Decoder Loss:  0.0030836621 Validation Decoder Loss:  0.7636393
Encoder Loss:  0.057562158  || Decoder Loss:  0.0030716811 Validation Decoder Loss:  0.7634956
Encoder Loss:  0.05755431  || Decoder Loss:  0.003062833 Validation Decoder Loss:  0.76353407
Encoder Loss:  0.057547852  || Decoder Loss:  0.0030555034 Validation Decoder Loss:  0.76354796
Encoder Loss:  0.05754276  || Decoder Loss:  0.003049773 Validation Decoder Loss:  0.7634664
Encoder Loss:  0.057538733  || Decoder Loss:  0.0030451955 Validation Decoder Loss:  0.76331544
Encoder Loss:  0.057535272  || Decoder Loss:  0.003041247 Validation Decoder Loss:  0.7631127
Encoder Loss:  0.057529572  || Decoder Loss:  0.0030348368 Validation Decoder Loss:  0.7634869
Encoder Loss:  0.057513013  || Decoder Loss:  0.0030161631 Validation Decoder Loss:  0.76384544
Encoder Loss:  0.057503313  || Decoder Loss:  0.0030052466 Validation Decoder Loss:  0.76403457
Encoder Loss:  0.057493825  || Decoder Loss:  0.0029944836 Validation Decoder Loss:  0.76426053
Encoder Loss:  0.057487153  || Decoder Loss:  0.0029869615 Validation Decoder Loss:  0.7641939
Encoder Loss:  0.057481866  || Decoder Loss:  0.0029810301 Validation Decoder Loss:  0.7640699
Encoder Loss:  0.05747742  || Decoder Loss:  0.0029760236 Validation Decoder Loss:  0.7639125
Encoder Loss:  0.0574733  || Decoder Loss:  0.0029713556 Validation Decoder Loss:  0.76374847
Encoder Loss:  0.057469305  || Decoder Loss:  0.002966805 Validation Decoder Loss:  0.76355535
Encoder Loss:  0.05746527  || Decoder Loss:  0.0029622435 Validation Decoder Loss:  0.7633658
Encoder Loss:  0.05746103  || Decoder Loss:  0.0029574665 Validation Decoder Loss:  0.7631222
Encoder Loss:  0.05745699  || Decoder Loss:  0.0029529359 Validation Decoder Loss:  0.7628973
Encoder Loss:  0.057453807  || Decoder Loss:  0.00294933 Validation Decoder Loss:  0.7627671
Encoder Loss:  0.057451434  || Decoder Loss:  0.0029466865 Validation Decoder Loss:  0.76265585
Encoder Loss:  0.057449523  || Decoder Loss:  0.0029445062 Validation Decoder Loss:  0.76256174
Encoder Loss:  0.05744786  || Decoder Loss:  0.0029426091 Validation Decoder Loss:  0.7624774
Encoder Loss:  0.05744636  || Decoder Loss:  0.0029409353 Validation Decoder Loss:  0.76239365
Encoder Loss:  0.05744501  || Decoder Loss:  0.0029394072 Validation Decoder Loss:  0.7623155
Encoder Loss:  0.057443745  || Decoder Loss:  0.0029379705 Validation Decoder Loss:  0.7622389
Encoder Loss:  0.05744243  || Decoder Loss:  0.002936542 Validation Decoder Loss:  0.76216376
Encoder Loss:  0.057441164  || Decoder Loss:  0.0029350629 Validation Decoder Loss:  0.76207685
Encoder Loss:  0.057439912  || Decoder Loss:  0.0029336622 Validation Decoder Loss:  0.7619883
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7619883
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_30 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.006913887 Validation Decoder Loss:  0.7632359
Encoder Loss:  0.05598167  || Decoder Loss:  0.0033736222 Validation Decoder Loss:  0.75908446
Encoder Loss:  0.055913597  || Decoder Loss:  0.0032971348 Validation Decoder Loss:  0.75437415
Encoder Loss:  0.055888966  || Decoder Loss:  0.003269483 Validation Decoder Loss:  0.74954396
Encoder Loss:  0.0556347  || Decoder Loss:  0.0029836458 Validation Decoder Loss:  0.6436887
Encoder Loss:  0.05540586  || Decoder Loss:  0.002726374 Validation Decoder Loss:  0.64041054
Encoder Loss:  0.055377387  || Decoder Loss:  0.0026943795 Validation Decoder Loss:  0.63960344
Encoder Loss:  0.055363305  || Decoder Loss:  0.002678589 Validation Decoder Loss:  0.6397245
Encoder Loss:  0.05534298  || Decoder Loss:  0.0026557443 Validation Decoder Loss:  0.6403545
Encoder Loss:  0.055328734  || Decoder Loss:  0.0026396965 Validation Decoder Loss:  0.6406645
Encoder Loss:  0.055319335  || Decoder Loss:  0.0026291441 Validation Decoder Loss:  0.6408847
Encoder Loss:  0.05531138  || Decoder Loss:  0.0026201808 Validation Decoder Loss:  0.64107627
Encoder Loss:  0.055304516  || Decoder Loss:  0.0026124988 Validation Decoder Loss:  0.6412996
Encoder Loss:  0.055298243  || Decoder Loss:  0.0026054012 Validation Decoder Loss:  0.6415302
Encoder Loss:  0.055291664  || Decoder Loss:  0.0025980326 Validation Decoder Loss:  0.6417384
Encoder Loss:  0.05528498  || Decoder Loss:  0.002590499 Validation Decoder Loss:  0.6419062
Encoder Loss:  0.055277735  || Decoder Loss:  0.0025823829 Validation Decoder Loss:  0.64201057
Encoder Loss:  0.055268575  || Decoder Loss:  0.0025721164 Validation Decoder Loss:  0.6419071
Encoder Loss:  0.055259157  || Decoder Loss:  0.0025614726 Validation Decoder Loss:  0.64160067
Encoder Loss:  0.055252112  || Decoder Loss:  0.0025535885 Validation Decoder Loss:  0.6411778
Encoder Loss:  0.05524253  || Decoder Loss:  0.0025428128 Validation Decoder Loss:  0.64185035
Encoder Loss:  0.05522017  || Decoder Loss:  0.0025176762 Validation Decoder Loss:  0.64097214
Encoder Loss:  0.05520317  || Decoder Loss:  0.0024986 Validation Decoder Loss:  0.62867445
Encoder Loss:  0.054880522  || Decoder Loss:  0.002135884 Validation Decoder Loss:  0.5104527
Encoder Loss:  0.05468841  || Decoder Loss:  0.0019199185 Validation Decoder Loss:  0.4319642
Encoder Loss:  0.054450262  || Decoder Loss:  0.0016522522 Validation Decoder Loss:  0.42220187
Encoder Loss:  0.05442024  || Decoder Loss:  0.0016184761 Validation Decoder Loss:  0.42118916
Encoder Loss:  0.054406133  || Decoder Loss:  0.0016026129 Validation Decoder Loss:  0.4207127
Encoder Loss:  0.05439916  || Decoder Loss:  0.0015948458 Validation Decoder Loss:  0.42024708
Encoder Loss:  0.054395128  || Decoder Loss:  0.0015902631 Validation Decoder Loss:  0.4196484
Encoder Loss:  0.054390404  || Decoder Loss:  0.0015849529 Validation Decoder Loss:  0.41905272
Encoder Loss:  0.054385357  || Decoder Loss:  0.0015793059 Validation Decoder Loss:  0.41850623
Encoder Loss:  0.05437961  || Decoder Loss:  0.0015728031 Validation Decoder Loss:  0.41775012
Encoder Loss:  0.054370873  || Decoder Loss:  0.0015630225 Validation Decoder Loss:  0.41525298
Encoder Loss:  0.054356452  || Decoder Loss:  0.0015467905 Validation Decoder Loss:  0.4120519
Encoder Loss:  0.054346684  || Decoder Loss:  0.0015357852 Validation Decoder Loss:  0.41157678
Encoder Loss:  0.054341137  || Decoder Loss:  0.0015295537 Validation Decoder Loss:  0.41142964
Encoder Loss:  0.05433676  || Decoder Loss:  0.0015246432 Validation Decoder Loss:  0.4113434
Encoder Loss:  0.054333117  || Decoder Loss:  0.0015206152 Validation Decoder Loss:  0.41128427
Encoder Loss:  0.054330047  || Decoder Loss:  0.0015170731 Validation Decoder Loss:  0.41123286
Model: bold_synthesis_net_lr_0.000884797856295376 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.41123286
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_31 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.006921577 Validation Decoder Loss:  0.7632365
Encoder Loss:  0.053025562  || Decoder Loss:  0.003374358 Validation Decoder Loss:  0.75905627
Encoder Loss:  0.05295648  || Decoder Loss:  0.0032972184 Validation Decoder Loss:  0.75433457
Encoder Loss:  0.052931715  || Decoder Loss:  0.0032695832 Validation Decoder Loss:  0.74912405
Encoder Loss:  0.052662212  || Decoder Loss:  0.002968689 Validation Decoder Loss:  0.64356375
Encoder Loss:  0.052444555  || Decoder Loss:  0.0027257514 Validation Decoder Loss:  0.6404004
Encoder Loss:  0.05241632  || Decoder Loss:  0.0026942645 Validation Decoder Loss:  0.63961077
Encoder Loss:  0.05240224  || Decoder Loss:  0.0026785415 Validation Decoder Loss:  0.63974726
Encoder Loss:  0.052381713  || Decoder Loss:  0.0026556547 Validation Decoder Loss:  0.640388
Encoder Loss:  0.052367467  || Decoder Loss:  0.0026396844 Validation Decoder Loss:  0.6406945
Encoder Loss:  0.05235797  || Decoder Loss:  0.0026290887 Validation Decoder Loss:  0.6409242
Encoder Loss:  0.052349858  || Decoder Loss:  0.00262008 Validation Decoder Loss:  0.64111894
Encoder Loss:  0.052343007  || Decoder Loss:  0.002612362 Validation Decoder Loss:  0.64133584
Encoder Loss:  0.052336585  || Decoder Loss:  0.002605212 Validation Decoder Loss:  0.64156896
Encoder Loss:  0.05232993  || Decoder Loss:  0.00259778 Validation Decoder Loss:  0.64176995
Encoder Loss:  0.052323017  || Decoder Loss:  0.0025901021 Validation Decoder Loss:  0.64194316
Encoder Loss:  0.052315388  || Decoder Loss:  0.0025815621 Validation Decoder Loss:  0.64200187
Encoder Loss:  0.0523056  || Decoder Loss:  0.0025706484 Validation Decoder Loss:  0.6418568
Encoder Loss:  0.05229649  || Decoder Loss:  0.0025604588 Validation Decoder Loss:  0.64153105
Encoder Loss:  0.05228992  || Decoder Loss:  0.0025531233 Validation Decoder Loss:  0.6410748
Encoder Loss:  0.05227966  || Decoder Loss:  0.0025416887 Validation Decoder Loss:  0.6417276
Encoder Loss:  0.052257378  || Decoder Loss:  0.002516864 Validation Decoder Loss:  0.6403076
Encoder Loss:  0.052230768  || Decoder Loss:  0.0024871072 Validation Decoder Loss:  0.6037985
Encoder Loss:  0.051839728  || Decoder Loss:  0.0020506384 Validation Decoder Loss:  0.50870675
Encoder Loss:  0.051664934  || Decoder Loss:  0.0018554813 Validation Decoder Loss:  0.42624062
Encoder Loss:  0.05147392  || Decoder Loss:  0.0016422317 Validation Decoder Loss:  0.42180184
Encoder Loss:  0.05144885  || Decoder Loss:  0.0016142841 Validation Decoder Loss:  0.42103314
Encoder Loss:  0.051436964  || Decoder Loss:  0.0016009592 Validation Decoder Loss:  0.42058918
Encoder Loss:  0.051430713  || Decoder Loss:  0.0015940131 Validation Decoder Loss:  0.42010945
Encoder Loss:  0.05142686  || Decoder Loss:  0.0015897413 Validation Decoder Loss:  0.41950032
Encoder Loss:  0.05142191  || Decoder Loss:  0.0015841958 Validation Decoder Loss:  0.41890454
Encoder Loss:  0.051417023  || Decoder Loss:  0.0015787162 Validation Decoder Loss:  0.41837218
Encoder Loss:  0.05141103  || Decoder Loss:  0.0015720528 Validation Decoder Loss:  0.4174452
Encoder Loss:  0.051401556  || Decoder Loss:  0.001561492 Validation Decoder Loss:  0.41431576
Encoder Loss:  0.051386822  || Decoder Loss:  0.0015450511 Validation Decoder Loss:  0.4117937
Encoder Loss:  0.051377997  || Decoder Loss:  0.0015352002 Validation Decoder Loss:  0.41148284
Encoder Loss:  0.051372588  || Decoder Loss:  0.0015291305 Validation Decoder Loss:  0.4113739
Encoder Loss:  0.05136833  || Decoder Loss:  0.0015243882 Validation Decoder Loss:  0.41130775
Encoder Loss:  0.051364746  || Decoder Loss:  0.0015203975 Validation Decoder Loss:  0.4112565
Encoder Loss:  0.051361665  || Decoder Loss:  0.0015169258 Validation Decoder Loss:  0.4112084
Model: bold_synthesis_net_lr_0.000882865138534861 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.4112084
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_32 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 320, 8, 1)         375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.014573149  || Decoder Loss:  0.007873896 Validation Decoder Loss:  0.76835394
Encoder Loss:  0.009531597  || Decoder Loss:  0.003871109 Validation Decoder Loss:  0.77880204
Encoder Loss:  0.007869237  || Decoder Loss:  0.0033464073 Validation Decoder Loss:  0.7788922
Encoder Loss:  0.0068700598  || Decoder Loss:  0.0032992614 Validation Decoder Loss:  0.7770422
Encoder Loss:  0.0061344625  || Decoder Loss:  0.003284373 Validation Decoder Loss:  0.774971
Encoder Loss:  0.005686379  || Decoder Loss:  0.003235751 Validation Decoder Loss:  0.77185005
Encoder Loss:  0.0053641363  || Decoder Loss:  0.0031938418 Validation Decoder Loss:  0.7680963
Encoder Loss:  0.005084213  || Decoder Loss:  0.0031365866 Validation Decoder Loss:  0.7630215
Encoder Loss:  0.0048072324  || Decoder Loss:  0.0030431813 Validation Decoder Loss:  0.7546756
Encoder Loss:  0.004481632  || Decoder Loss:  0.0028977985 Validation Decoder Loss:  0.74050516
Encoder Loss:  0.004143373  || Decoder Loss:  0.002716161 Validation Decoder Loss:  0.72163445
Encoder Loss:  0.00387519  || Decoder Loss:  0.0025511894 Validation Decoder Loss:  0.70222384
Encoder Loss:  0.0036498802  || Decoder Loss:  0.0024214108 Validation Decoder Loss:  0.68322855
Encoder Loss:  0.0034351887  || Decoder Loss:  0.0023188216 Validation Decoder Loss:  0.66473687
Encoder Loss:  0.0032628407  || Decoder Loss:  0.0022513724 Validation Decoder Loss:  0.64751834
Encoder Loss:  0.0031534708  || Decoder Loss:  0.002212978 Validation Decoder Loss:  0.63244224
Encoder Loss:  0.0030926573  || Decoder Loss:  0.0022006473 Validation Decoder Loss:  0.6189176
Encoder Loss:  0.002969676  || Decoder Loss:  0.0021739446 Validation Decoder Loss:  0.6064512
Encoder Loss:  0.0029458588  || Decoder Loss:  0.0021811316 Validation Decoder Loss:  0.597122
Encoder Loss:  0.0029470029  || Decoder Loss:  0.0022093607 Validation Decoder Loss:  0.5903647
Encoder Loss:  0.002952779  || Decoder Loss:  0.0022394916 Validation Decoder Loss:  0.5852614
Encoder Loss:  0.0029573045  || Decoder Loss:  0.0022659055 Validation Decoder Loss:  0.58121854
Encoder Loss:  0.002955352  || Decoder Loss:  0.002283446 Validation Decoder Loss:  0.5774133
Encoder Loss:  0.002948394  || Decoder Loss:  0.0022938137 Validation Decoder Loss:  0.5736879
Encoder Loss:  0.0029437367  || Decoder Loss:  0.0023046953 Validation Decoder Loss:  0.5697821
Encoder Loss:  0.0029429914  || Decoder Loss:  0.0023179348 Validation Decoder Loss:  0.56650877
Encoder Loss:  0.0029452017  || Decoder Loss:  0.002332751 Validation Decoder Loss:  0.56370133
Encoder Loss:  0.0029502395  || Decoder Loss:  0.0023491932 Validation Decoder Loss:  0.5612566
Encoder Loss:  0.0029572253  || Decoder Loss:  0.002366674 Validation Decoder Loss:  0.55891746
Encoder Loss:  0.0029606996  || Decoder Loss:  0.002379867 Validation Decoder Loss:  0.55704284
Encoder Loss:  0.0029643066  || Decoder Loss:  0.0023926408 Validation Decoder Loss:  0.5553924
Encoder Loss:  0.0029673777  || Decoder Loss:  0.002405027 Validation Decoder Loss:  0.5535677
Encoder Loss:  0.0029734836  || Decoder Loss:  0.002419099 Validation Decoder Loss:  0.55240226
Encoder Loss:  0.0029861773  || Decoder Loss:  0.0024413196 Validation Decoder Loss:  0.5525023
Encoder Loss:  0.0030174875  || Decoder Loss:  0.0024913123 Validation Decoder Loss:  0.5549282
Encoder Loss:  0.003063332  || Decoder Loss:  0.0025438224 Validation Decoder Loss:  0.55623627
Encoder Loss:  0.0030995219  || Decoder Loss:  0.0025915843 Validation Decoder Loss:  0.5578473
Encoder Loss:  0.0030770237  || Decoder Loss:  0.0025961853 Validation Decoder Loss:  0.5574607
Encoder Loss:  0.0031234627  || Decoder Loss:  0.0026474304 Validation Decoder Loss:  0.56060266
Encoder Loss:  0.003203408  || Decoder Loss:  0.0027328455 Validation Decoder Loss:  0.5666329
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.5666329
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_33 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 320, 8, 1)         1013      
=================================================================
Total params: 1,013
Trainable params: 1,013
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2607, 8, 1)        1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0070189643  || Decoder Loss:  0.0070189643 Validation Decoder Loss:  0.77661204
Encoder Loss:  0.0033804532  || Decoder Loss:  0.0033804532 Validation Decoder Loss:  0.77698356
Encoder Loss:  0.003302316  || Decoder Loss:  0.003302316 Validation Decoder Loss:  0.7750247
Encoder Loss:  0.0032254043  || Decoder Loss:  0.0032254043 Validation Decoder Loss:  0.7741701
Encoder Loss:  0.003209349  || Decoder Loss:  0.003209349 Validation Decoder Loss:  0.7740564
Encoder Loss:  0.003199605  || Decoder Loss:  0.003199605 Validation Decoder Loss:  0.7740852
Encoder Loss:  0.0031905838  || Decoder Loss:  0.0031905838 Validation Decoder Loss:  0.77421343
Encoder Loss:  0.0031820468  || Decoder Loss:  0.0031820468 Validation Decoder Loss:  0.77424157
Encoder Loss:  0.0031742128  || Decoder Loss:  0.0031742128 Validation Decoder Loss:  0.7742786
Encoder Loss:  0.0031655813  || Decoder Loss:  0.0031655813 Validation Decoder Loss:  0.77429587
Encoder Loss:  0.0031522878  || Decoder Loss:  0.0031522878 Validation Decoder Loss:  0.7731557
Encoder Loss:  0.0031214294  || Decoder Loss:  0.0031214294 Validation Decoder Loss:  0.77109915
Encoder Loss:  0.0030942005  || Decoder Loss:  0.0030942005 Validation Decoder Loss:  0.77021056
Encoder Loss:  0.0030792837  || Decoder Loss:  0.0030792837 Validation Decoder Loss:  0.7706282
Encoder Loss:  0.0030329698  || Decoder Loss:  0.0030329698 Validation Decoder Loss:  0.7690111
Encoder Loss:  0.0029993153  || Decoder Loss:  0.0029993153 Validation Decoder Loss:  0.7693268
Encoder Loss:  0.002983516  || Decoder Loss:  0.002983516 Validation Decoder Loss:  0.7697985
Encoder Loss:  0.0029648955  || Decoder Loss:  0.0029648955 Validation Decoder Loss:  0.77115107
Encoder Loss:  0.002921357  || Decoder Loss:  0.002921357 Validation Decoder Loss:  0.77245605
Encoder Loss:  0.0029017814  || Decoder Loss:  0.0029017814 Validation Decoder Loss:  0.772516
Encoder Loss:  0.0028891314  || Decoder Loss:  0.0028891314 Validation Decoder Loss:  0.77231246
Encoder Loss:  0.0028736463  || Decoder Loss:  0.0028736463 Validation Decoder Loss:  0.77371293
Encoder Loss:  0.0028598483  || Decoder Loss:  0.0028598483 Validation Decoder Loss:  0.7735305
Encoder Loss:  0.0028428996  || Decoder Loss:  0.0028428996 Validation Decoder Loss:  0.77022
Encoder Loss:  0.002823558  || Decoder Loss:  0.002823558 Validation Decoder Loss:  0.77012825
Encoder Loss:  0.0028081252  || Decoder Loss:  0.0028081252 Validation Decoder Loss:  0.76862216
Encoder Loss:  0.002798246  || Decoder Loss:  0.002798246 Validation Decoder Loss:  0.76932144
Encoder Loss:  0.0027897898  || Decoder Loss:  0.0027897898 Validation Decoder Loss:  0.7680942
Encoder Loss:  0.0027842708  || Decoder Loss:  0.0027842708 Validation Decoder Loss:  0.7687978
Encoder Loss:  0.0027782596  || Decoder Loss:  0.0027782596 Validation Decoder Loss:  0.76760924
Encoder Loss:  0.0027740616  || Decoder Loss:  0.0027740616 Validation Decoder Loss:  0.76837206
Encoder Loss:  0.0027681938  || Decoder Loss:  0.0027681938 Validation Decoder Loss:  0.7662786
Encoder Loss:  0.002763365  || Decoder Loss:  0.002763365 Validation Decoder Loss:  0.766732
Encoder Loss:  0.0027586294  || Decoder Loss:  0.0027586294 Validation Decoder Loss:  0.7651451
Encoder Loss:  0.0027548769  || Decoder Loss:  0.0027548769 Validation Decoder Loss:  0.7662321
Encoder Loss:  0.0027509427  || Decoder Loss:  0.0027509427 Validation Decoder Loss:  0.7646364
Encoder Loss:  0.0027479571  || Decoder Loss:  0.0027479571 Validation Decoder Loss:  0.7658887
Encoder Loss:  0.0027446146  || Decoder Loss:  0.0027446146 Validation Decoder Loss:  0.764367
Encoder Loss:  0.0027420402  || Decoder Loss:  0.0027420402 Validation Decoder Loss:  0.76558113
Encoder Loss:  0.0027388185  || Decoder Loss:  0.0027388185 Validation Decoder Loss:  0.7642493
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7642493
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_34 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 320, 8, 1)         694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 2607, 8, 1)        2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.039465923  || Decoder Loss:  0.007955437 Validation Decoder Loss:  0.76745343
Encoder Loss:  0.030677624  || Decoder Loss:  0.006716107 Validation Decoder Loss:  0.76717585
Encoder Loss:  0.024433568  || Decoder Loss:  0.006005373 Validation Decoder Loss:  0.7560756
Encoder Loss:  0.019482253  || Decoder Loss:  0.0041486174 Validation Decoder Loss:  0.7413769
Encoder Loss:  0.016556472  || Decoder Loss:  0.0034808563 Validation Decoder Loss:  0.72684586
Encoder Loss:  0.013561418  || Decoder Loss:  0.0033302975 Validation Decoder Loss:  0.7223323
Encoder Loss:  0.012340677  || Decoder Loss:  0.0032688244 Validation Decoder Loss:  0.72049606
Encoder Loss:  0.01130805  || Decoder Loss:  0.003232386 Validation Decoder Loss:  0.71971214
Encoder Loss:  0.010489699  || Decoder Loss:  0.0032018162 Validation Decoder Loss:  0.7191508
Encoder Loss:  0.009851198  || Decoder Loss:  0.0031693205 Validation Decoder Loss:  0.7187549
Encoder Loss:  0.009288351  || Decoder Loss:  0.0031180508 Validation Decoder Loss:  0.7182314
Encoder Loss:  0.008789037  || Decoder Loss:  0.0030295607 Validation Decoder Loss:  0.71674764
Encoder Loss:  0.008315477  || Decoder Loss:  0.0029118173 Validation Decoder Loss:  0.71321875
Encoder Loss:  0.007859905  || Decoder Loss:  0.0027816626 Validation Decoder Loss:  0.70722
Encoder Loss:  0.0074506933  || Decoder Loss:  0.0026547925 Validation Decoder Loss:  0.69884896
Encoder Loss:  0.0071158903  || Decoder Loss:  0.0025535475 Validation Decoder Loss:  0.6893559
Encoder Loss:  0.0068212654  || Decoder Loss:  0.0024792054 Validation Decoder Loss:  0.67913
Encoder Loss:  0.006590163  || Decoder Loss:  0.0024284804 Validation Decoder Loss:  0.6686008
Encoder Loss:  0.006400129  || Decoder Loss:  0.0023979058 Validation Decoder Loss:  0.65809804
Encoder Loss:  0.0062349406  || Decoder Loss:  0.0023739634 Validation Decoder Loss:  0.6473745
Encoder Loss:  0.006092757  || Decoder Loss:  0.0023585514 Validation Decoder Loss:  0.63686025
Encoder Loss:  0.005804528  || Decoder Loss:  0.0023226636 Validation Decoder Loss:  0.6251508
Encoder Loss:  0.005623178  || Decoder Loss:  0.0022922833 Validation Decoder Loss:  0.61470556
Encoder Loss:  0.0054327683  || Decoder Loss:  0.002266332 Validation Decoder Loss:  0.6044835
Encoder Loss:  0.005328416  || Decoder Loss:  0.0022603509 Validation Decoder Loss:  0.5965179
Encoder Loss:  0.005276075  || Decoder Loss:  0.0022740252 Validation Decoder Loss:  0.5897354
Encoder Loss:  0.0052329823  || Decoder Loss:  0.0022913103 Validation Decoder Loss:  0.5843726
Encoder Loss:  0.0051965294  || Decoder Loss:  0.0023113852 Validation Decoder Loss:  0.5800704
Encoder Loss:  0.0051521235  || Decoder Loss:  0.0023224729 Validation Decoder Loss:  0.57605875
Encoder Loss:  0.005121798  || Decoder Loss:  0.0023376998 Validation Decoder Loss:  0.5731717
Encoder Loss:  0.005106618  || Decoder Loss:  0.002362394 Validation Decoder Loss:  0.5710245
Encoder Loss:  0.0050757863  || Decoder Loss:  0.0023811755 Validation Decoder Loss:  0.5690125
Encoder Loss:  0.0050546965  || Decoder Loss:  0.0024014541 Validation Decoder Loss:  0.567822
Encoder Loss:  0.0050445176  || Decoder Loss:  0.002426089 Validation Decoder Loss:  0.56741405
Encoder Loss:  0.0050458447  || Decoder Loss:  0.0024566888 Validation Decoder Loss:  0.5673285
Encoder Loss:  0.005039667  || Decoder Loss:  0.0024849796 Validation Decoder Loss:  0.5674816
Encoder Loss:  0.004936223  || Decoder Loss:  0.0025093243 Validation Decoder Loss:  0.5676843
Encoder Loss:  0.0048679607  || Decoder Loss:  0.0025431535 Validation Decoder Loss:  0.5694334
Encoder Loss:  0.004834832  || Decoder Loss:  0.0025742564 Validation Decoder Loss:  0.56861275
Encoder Loss:  0.004799247  || Decoder Loss:  0.00258945 Validation Decoder Loss:  0.5636554
Model: bold_synthesis_net_lr_0.0008885805615863858 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.5636554
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_35 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 320, 8, 1)         375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03989872  || Decoder Loss:  0.006448768 Validation Decoder Loss:  0.7795889
Encoder Loss:  0.03225413  || Decoder Loss:  0.0033500611 Validation Decoder Loss:  0.7822907
Encoder Loss:  0.027243802  || Decoder Loss:  0.003316051 Validation Decoder Loss:  0.7808058
Encoder Loss:  0.022609519  || Decoder Loss:  0.0032200862 Validation Decoder Loss:  0.7693226
Encoder Loss:  0.018975368  || Decoder Loss:  0.0030845946 Validation Decoder Loss:  0.7548711
Encoder Loss:  0.016386012  || Decoder Loss:  0.0030017826 Validation Decoder Loss:  0.7454012
Encoder Loss:  0.014596477  || Decoder Loss:  0.0029429765 Validation Decoder Loss:  0.73675406
Encoder Loss:  0.013363128  || Decoder Loss:  0.0028865747 Validation Decoder Loss:  0.7275241
Encoder Loss:  0.012409334  || Decoder Loss:  0.002844908 Validation Decoder Loss:  0.71930796
Encoder Loss:  0.011567757  || Decoder Loss:  0.0028204985 Validation Decoder Loss:  0.7120274
Encoder Loss:  0.010161135  || Decoder Loss:  0.0028039718 Validation Decoder Loss:  0.7047964
Encoder Loss:  0.009486071  || Decoder Loss:  0.0027907165 Validation Decoder Loss:  0.697974
Encoder Loss:  0.008995904  || Decoder Loss:  0.0027869511 Validation Decoder Loss:  0.69169396
Encoder Loss:  0.008190737  || Decoder Loss:  0.0027798016 Validation Decoder Loss:  0.68538225
Encoder Loss:  0.0077706017  || Decoder Loss:  0.002770178 Validation Decoder Loss:  0.67948335
Encoder Loss:  0.0074972245  || Decoder Loss:  0.0027676339 Validation Decoder Loss:  0.67405075
Encoder Loss:  0.0072425185  || Decoder Loss:  0.0027739566 Validation Decoder Loss:  0.6685406
Encoder Loss:  0.00687193  || Decoder Loss:  0.0027832314 Validation Decoder Loss:  0.6628038
Encoder Loss:  0.0066235573  || Decoder Loss:  0.002794703 Validation Decoder Loss:  0.6576994
Encoder Loss:  0.006495245  || Decoder Loss:  0.0028201018 Validation Decoder Loss:  0.65282214
Encoder Loss:  0.0063718543  || Decoder Loss:  0.002851849 Validation Decoder Loss:  0.64797425
Encoder Loss:  0.0061657247  || Decoder Loss:  0.0028775537 Validation Decoder Loss:  0.6431326
Encoder Loss:  0.006084675  || Decoder Loss:  0.002904814 Validation Decoder Loss:  0.63816005
Encoder Loss:  0.006009829  || Decoder Loss:  0.0029274907 Validation Decoder Loss:  0.63300616
Encoder Loss:  0.005945904  || Decoder Loss:  0.0029483296 Validation Decoder Loss:  0.6277949
Encoder Loss:  0.0058570993  || Decoder Loss:  0.0029652647 Validation Decoder Loss:  0.62238234
Encoder Loss:  0.0057942667  || Decoder Loss:  0.0029786502 Validation Decoder Loss:  0.61688715
Encoder Loss:  0.0057452666  || Decoder Loss:  0.0029903934 Validation Decoder Loss:  0.6115935
Encoder Loss:  0.005700125  || Decoder Loss:  0.0029999607 Validation Decoder Loss:  0.60657907
Encoder Loss:  0.005655337  || Decoder Loss:  0.0030064685 Validation Decoder Loss:  0.60166717
Encoder Loss:  0.0056166514  || Decoder Loss:  0.0030123598 Validation Decoder Loss:  0.5971216
Encoder Loss:  0.0055777137  || Decoder Loss:  0.003014332 Validation Decoder Loss:  0.5928471
Encoder Loss:  0.0055398415  || Decoder Loss:  0.0030144125 Validation Decoder Loss:  0.588474
Encoder Loss:  0.0055037607  || Decoder Loss:  0.0030128555 Validation Decoder Loss:  0.5843888
Encoder Loss:  0.005474776  || Decoder Loss:  0.00301432 Validation Decoder Loss:  0.5804092
Encoder Loss:  0.005449545  || Decoder Loss:  0.0030170677 Validation Decoder Loss:  0.5764428
Encoder Loss:  0.0054289084  || Decoder Loss:  0.0030225185 Validation Decoder Loss:  0.5727184
Encoder Loss:  0.005412101  || Decoder Loss:  0.003031841 Validation Decoder Loss:  0.5692805
Encoder Loss:  0.005402029  || Decoder Loss:  0.0030467645 Validation Decoder Loss:  0.5660438
Encoder Loss:  0.0054036146  || Decoder Loss:  0.0030709102 Validation Decoder Loss:  0.56345844
Model: bold_synthesis_net_lr_0.0008848067693841735 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.56345844
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_36 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 2607, 8, 1)        2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.008598644 Validation Decoder Loss:  0.765346
Encoder Loss:  0.052635234  || Decoder Loss:  0.006627065 Validation Decoder Loss:  0.7668061
Encoder Loss:  0.052278444  || Decoder Loss:  0.0062318216 Validation Decoder Loss:  0.767334
Encoder Loss:  0.05184924  || Decoder Loss:  0.00575645 Validation Decoder Loss:  0.76512617
Encoder Loss:  0.05127602  || Decoder Loss:  0.005121513 Validation Decoder Loss:  0.76487565
Encoder Loss:  0.05103131  || Decoder Loss:  0.0048504723 Validation Decoder Loss:  0.7644694
Encoder Loss:  0.0508744  || Decoder Loss:  0.004676653 Validation Decoder Loss:  0.76415366
Encoder Loss:  0.05071034  || Decoder Loss:  0.004494919 Validation Decoder Loss:  0.76387495
Encoder Loss:  0.05056628  || Decoder Loss:  0.004335379 Validation Decoder Loss:  0.76359373
Encoder Loss:  0.050453976  || Decoder Loss:  0.0042109834 Validation Decoder Loss:  0.7633722
Encoder Loss:  0.05035213  || Decoder Loss:  0.004098148 Validation Decoder Loss:  0.7631903
Encoder Loss:  0.050259188  || Decoder Loss:  0.0039952016 Validation Decoder Loss:  0.76303947
Encoder Loss:  0.050174553  || Decoder Loss:  0.0039014649 Validation Decoder Loss:  0.7629094
Encoder Loss:  0.050102368  || Decoder Loss:  0.003821514 Validation Decoder Loss:  0.7628288
Encoder Loss:  0.050048422  || Decoder Loss:  0.0037617187 Validation Decoder Loss:  0.7627992
Encoder Loss:  0.050013788  || Decoder Loss:  0.0037234025 Validation Decoder Loss:  0.7627384
Encoder Loss:  0.049981944  || Decoder Loss:  0.0036881573 Validation Decoder Loss:  0.76265574
Encoder Loss:  0.049951427  || Decoder Loss:  0.0036543312 Validation Decoder Loss:  0.7625643
Encoder Loss:  0.049922965  || Decoder Loss:  0.0036228134 Validation Decoder Loss:  0.76244664
Encoder Loss:  0.049901824  || Decoder Loss:  0.0035994195 Validation Decoder Loss:  0.76237077
Encoder Loss:  0.04988587  || Decoder Loss:  0.003581729 Validation Decoder Loss:  0.7622983
Encoder Loss:  0.04987028  || Decoder Loss:  0.0035644474 Validation Decoder Loss:  0.76222783
Encoder Loss:  0.04985552  || Decoder Loss:  0.0035481201 Validation Decoder Loss:  0.76216143
Encoder Loss:  0.049841892  || Decoder Loss:  0.0035330078 Validation Decoder Loss:  0.7620993
Encoder Loss:  0.049829338  || Decoder Loss:  0.0035191341 Validation Decoder Loss:  0.7620428
Encoder Loss:  0.04981784  || Decoder Loss:  0.0035063622 Validation Decoder Loss:  0.7619904
Encoder Loss:  0.049807046  || Decoder Loss:  0.0034943847 Validation Decoder Loss:  0.761948
Encoder Loss:  0.049798056  || Decoder Loss:  0.0034844487 Validation Decoder Loss:  0.7619262
Encoder Loss:  0.04978728  || Decoder Loss:  0.0034725182 Validation Decoder Loss:  0.76189923
Encoder Loss:  0.04978001  || Decoder Loss:  0.003464439 Validation Decoder Loss:  0.7618473
Encoder Loss:  0.0497759  || Decoder Loss:  0.0034598922 Validation Decoder Loss:  0.761855
Encoder Loss:  0.049773093  || Decoder Loss:  0.0034567707 Validation Decoder Loss:  0.76182663
Encoder Loss:  0.049771015  || Decoder Loss:  0.0034544873 Validation Decoder Loss:  0.7618304
Encoder Loss:  0.0497683  || Decoder Loss:  0.0034515057 Validation Decoder Loss:  0.7618065
Encoder Loss:  0.049766567  || Decoder Loss:  0.003449603 Validation Decoder Loss:  0.7618073
Encoder Loss:  0.04976427  || Decoder Loss:  0.0034469687 Validation Decoder Loss:  0.7618002
Encoder Loss:  0.049762305  || Decoder Loss:  0.003444824 Validation Decoder Loss:  0.7617999
Encoder Loss:  0.049761232  || Decoder Loss:  0.003443617 Validation Decoder Loss:  0.76179117
Encoder Loss:  0.04975913  || Decoder Loss:  0.003441327 Validation Decoder Loss:  0.7617865
Encoder Loss:  0.049757686  || Decoder Loss:  0.0034397235 Validation Decoder Loss:  0.76177436
Model: bold_synthesis_net_lr_0.0008843913995314382 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.76177436
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_37 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2607, 8, 1)        1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.007995208 Validation Decoder Loss:  0.76688784
Encoder Loss:  0.057071645  || Decoder Loss:  0.005883473 Validation Decoder Loss:  0.76735765
Encoder Loss:  0.055729084  || Decoder Loss:  0.0043784087 Validation Decoder Loss:  0.77246183
Encoder Loss:  0.0548233  || Decoder Loss:  0.0033629665 Validation Decoder Loss:  0.7724144
Encoder Loss:  0.05481018  || Decoder Loss:  0.0033482783 Validation Decoder Loss:  0.77233046
Encoder Loss:  0.054806847  || Decoder Loss:  0.0033445281 Validation Decoder Loss:  0.772396
Encoder Loss:  0.054800633  || Decoder Loss:  0.0033375327 Validation Decoder Loss:  0.7726091
Encoder Loss:  0.05479197  || Decoder Loss:  0.0033278903 Validation Decoder Loss:  0.7723958
Encoder Loss:  0.054778814  || Decoder Loss:  0.003313103 Validation Decoder Loss:  0.77215075
Encoder Loss:  0.054773156  || Decoder Loss:  0.003306786 Validation Decoder Loss:  0.7720182
Encoder Loss:  0.054770112  || Decoder Loss:  0.0033033497 Validation Decoder Loss:  0.7719255
Encoder Loss:  0.054767616  || Decoder Loss:  0.0033005513 Validation Decoder Loss:  0.77184355
Encoder Loss:  0.05476512  || Decoder Loss:  0.0032977578 Validation Decoder Loss:  0.7717685
Encoder Loss:  0.05476277  || Decoder Loss:  0.0032951306 Validation Decoder Loss:  0.7717062
Encoder Loss:  0.054760944  || Decoder Loss:  0.0032930812 Validation Decoder Loss:  0.7716632
Encoder Loss:  0.054759435  || Decoder Loss:  0.0032914116 Validation Decoder Loss:  0.7716607
Encoder Loss:  0.054756366  || Decoder Loss:  0.0032879303 Validation Decoder Loss:  0.77234155
Encoder Loss:  0.054750226  || Decoder Loss:  0.0032810662 Validation Decoder Loss:  0.7723642
Encoder Loss:  0.054745894  || Decoder Loss:  0.0032761933 Validation Decoder Loss:  0.77233225
Encoder Loss:  0.05474316  || Decoder Loss:  0.0032731136 Validation Decoder Loss:  0.77229905
Encoder Loss:  0.0547411  || Decoder Loss:  0.003270831 Validation Decoder Loss:  0.77227014
Encoder Loss:  0.0547393  || Decoder Loss:  0.0032688442 Validation Decoder Loss:  0.7722409
Encoder Loss:  0.054737616  || Decoder Loss:  0.0032669322 Validation Decoder Loss:  0.77221626
Encoder Loss:  0.054735906  || Decoder Loss:  0.0032649941 Validation Decoder Loss:  0.7721948
Encoder Loss:  0.054734077  || Decoder Loss:  0.0032629687 Validation Decoder Loss:  0.7721764
Encoder Loss:  0.05473217  || Decoder Loss:  0.0032608116 Validation Decoder Loss:  0.77216154
Encoder Loss:  0.054730047  || Decoder Loss:  0.0032584649 Validation Decoder Loss:  0.7721498
Encoder Loss:  0.054727815  || Decoder Loss:  0.003255993 Validation Decoder Loss:  0.7721414
Encoder Loss:  0.05472563  || Decoder Loss:  0.0032535004 Validation Decoder Loss:  0.7721605
Encoder Loss:  0.054723278  || Decoder Loss:  0.003250879 Validation Decoder Loss:  0.772107
Encoder Loss:  0.054720923  || Decoder Loss:  0.0032482182 Validation Decoder Loss:  0.7720902
Encoder Loss:  0.05471858  || Decoder Loss:  0.0032455567 Validation Decoder Loss:  0.7720944
Encoder Loss:  0.05471623  || Decoder Loss:  0.0032429988 Validation Decoder Loss:  0.77211
Encoder Loss:  0.054713316  || Decoder Loss:  0.0032397152 Validation Decoder Loss:  0.77197576
Encoder Loss:  0.054708637  || Decoder Loss:  0.003234457 Validation Decoder Loss:  0.7710906
Encoder Loss:  0.05470517  || Decoder Loss:  0.0032305405 Validation Decoder Loss:  0.77077186
Encoder Loss:  0.054702874  || Decoder Loss:  0.0032279575 Validation Decoder Loss:  0.7706718
Encoder Loss:  0.054700997  || Decoder Loss:  0.0032258728 Validation Decoder Loss:  0.7705625
Encoder Loss:  0.054699317  || Decoder Loss:  0.003223957 Validation Decoder Loss:  0.77047545
Encoder Loss:  0.054697584  || Decoder Loss:  0.0032220897 Validation Decoder Loss:  0.7703985
Model: bold_synthesis_net_lr_0.0008819668118832304 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.7703985
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_38 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.006265935  || Decoder Loss:  0.006265935 Validation Decoder Loss:  0.7746791
Encoder Loss:  0.0033291443  || Decoder Loss:  0.0033291443 Validation Decoder Loss:  0.7718336
Encoder Loss:  0.0032843768  || Decoder Loss:  0.0032843768 Validation Decoder Loss:  0.7701921
Encoder Loss:  0.0032465877  || Decoder Loss:  0.0032465877 Validation Decoder Loss:  0.7684458
Encoder Loss:  0.0032263477  || Decoder Loss:  0.0032263477 Validation Decoder Loss:  0.76738197
Encoder Loss:  0.003211512  || Decoder Loss:  0.003211512 Validation Decoder Loss:  0.7666631
Encoder Loss:  0.0031965263  || Decoder Loss:  0.0031965263 Validation Decoder Loss:  0.7650179
Encoder Loss:  0.003174103  || Decoder Loss:  0.003174103 Validation Decoder Loss:  0.76365983
Encoder Loss:  0.0031626795  || Decoder Loss:  0.0031626795 Validation Decoder Loss:  0.763386
Encoder Loss:  0.0031533858  || Decoder Loss:  0.0031533858 Validation Decoder Loss:  0.76343936
Encoder Loss:  0.0031431683  || Decoder Loss:  0.0031431683 Validation Decoder Loss:  0.7637414
Encoder Loss:  0.003125753  || Decoder Loss:  0.003125753 Validation Decoder Loss:  0.7653019
Encoder Loss:  0.003103126  || Decoder Loss:  0.003103126 Validation Decoder Loss:  0.7659594
Encoder Loss:  0.0030874629  || Decoder Loss:  0.0030874629 Validation Decoder Loss:  0.7662574
Encoder Loss:  0.003074779  || Decoder Loss:  0.003074779 Validation Decoder Loss:  0.76608175
Encoder Loss:  0.0030565362  || Decoder Loss:  0.0030565362 Validation Decoder Loss:  0.76148695
Encoder Loss:  0.0029887357  || Decoder Loss:  0.0029887357 Validation Decoder Loss:  0.7535123
Encoder Loss:  0.0029521247  || Decoder Loss:  0.0029521247 Validation Decoder Loss:  0.7518806
Encoder Loss:  0.0029345357  || Decoder Loss:  0.0029345357 Validation Decoder Loss:  0.7506474
Encoder Loss:  0.002922165  || Decoder Loss:  0.002922165 Validation Decoder Loss:  0.7495907
Encoder Loss:  0.0029079043  || Decoder Loss:  0.0029079043 Validation Decoder Loss:  0.74689794
Encoder Loss:  0.0028804536  || Decoder Loss:  0.0028804536 Validation Decoder Loss:  0.7396327
Encoder Loss:  0.0028074174  || Decoder Loss:  0.0028074174 Validation Decoder Loss:  0.73011184
Encoder Loss:  0.0026334326  || Decoder Loss:  0.0026334326 Validation Decoder Loss:  0.706386
Encoder Loss:  0.002505135  || Decoder Loss:  0.002505135 Validation Decoder Loss:  0.70379686
Encoder Loss:  0.0024881158  || Decoder Loss:  0.0024881158 Validation Decoder Loss:  0.70369726
Encoder Loss:  0.002468903  || Decoder Loss:  0.002468903 Validation Decoder Loss:  0.70394945
Encoder Loss:  0.0024537207  || Decoder Loss:  0.0024537207 Validation Decoder Loss:  0.70355296
Encoder Loss:  0.0024433704  || Decoder Loss:  0.0024433704 Validation Decoder Loss:  0.70319617
Encoder Loss:  0.0024328595  || Decoder Loss:  0.0024328595 Validation Decoder Loss:  0.70291024
Encoder Loss:  0.0024231735  || Decoder Loss:  0.0024231735 Validation Decoder Loss:  0.7026312
Encoder Loss:  0.0024144792  || Decoder Loss:  0.0024144792 Validation Decoder Loss:  0.702401
Encoder Loss:  0.0024072581  || Decoder Loss:  0.0024072581 Validation Decoder Loss:  0.7021912
Encoder Loss:  0.0024012227  || Decoder Loss:  0.0024012227 Validation Decoder Loss:  0.70197344
Encoder Loss:  0.002395995  || Decoder Loss:  0.002395995 Validation Decoder Loss:  0.7017779
Encoder Loss:  0.0023915062  || Decoder Loss:  0.0023915062 Validation Decoder Loss:  0.7016177
Encoder Loss:  0.0023874557  || Decoder Loss:  0.0023874557 Validation Decoder Loss:  0.70146513
Encoder Loss:  0.0023814843  || Decoder Loss:  0.0023814843 Validation Decoder Loss:  0.7007597
Encoder Loss:  0.0022583748  || Decoder Loss:  0.0022583748 Validation Decoder Loss:  0.64659005
Encoder Loss:  0.0021450373  || Decoder Loss:  0.0021450373 Validation Decoder Loss:  0.6457945
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.6457945
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_39 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2607, 8, 1)        2289      
=================================================================
Total params: 2,289
Trainable params: 2,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.00845726 Validation Decoder Loss:  0.76721
Encoder Loss:  0.062285442  || Decoder Loss:  0.0064663794 Validation Decoder Loss:  0.76698375
Encoder Loss:  0.061985694  || Decoder Loss:  0.006126561 Validation Decoder Loss:  0.76729417
Encoder Loss:  0.061363854  || Decoder Loss:  0.005421626 Validation Decoder Loss:  0.7650686
Encoder Loss:  0.06093844  || Decoder Loss:  0.0049393694 Validation Decoder Loss:  0.764591
Encoder Loss:  0.060754716  || Decoder Loss:  0.0047311056 Validation Decoder Loss:  0.7642022
Encoder Loss:  0.060611695  || Decoder Loss:  0.0045689614 Validation Decoder Loss:  0.76387787
Encoder Loss:  0.060471326  || Decoder Loss:  0.0044098883 Validation Decoder Loss:  0.76364374
Encoder Loss:  0.06032483  || Decoder Loss:  0.004243794 Validation Decoder Loss:  0.7633727
Encoder Loss:  0.06021333  || Decoder Loss:  0.004117345 Validation Decoder Loss:  0.763176
Encoder Loss:  0.060113966  || Decoder Loss:  0.004004754 Validation Decoder Loss:  0.7630194
Encoder Loss:  0.06002459  || Decoder Loss:  0.0039034558 Validation Decoder Loss:  0.76288533
Encoder Loss:  0.059949182  || Decoder Loss:  0.0038179627 Validation Decoder Loss:  0.7628013
Encoder Loss:  0.059894506  || Decoder Loss:  0.0037559574 Validation Decoder Loss:  0.76277244
Encoder Loss:  0.059859443  || Decoder Loss:  0.0037161892 Validation Decoder Loss:  0.7627021
Encoder Loss:  0.059826292  || Decoder Loss:  0.0036786166 Validation Decoder Loss:  0.76261157
Encoder Loss:  0.05979478  || Decoder Loss:  0.0036429057 Validation Decoder Loss:  0.76251364
Encoder Loss:  0.059766896  || Decoder Loss:  0.0036112496 Validation Decoder Loss:  0.7623985
Encoder Loss:  0.059748463  || Decoder Loss:  0.0035903566 Validation Decoder Loss:  0.7623184
Encoder Loss:  0.05973182  || Decoder Loss:  0.0035714745 Validation Decoder Loss:  0.76224226
Encoder Loss:  0.059715886  || Decoder Loss:  0.0035534343 Validation Decoder Loss:  0.7621702
Encoder Loss:  0.059701122  || Decoder Loss:  0.0035367208 Validation Decoder Loss:  0.76210266
Encoder Loss:  0.05968768  || Decoder Loss:  0.0035214776 Validation Decoder Loss:  0.7620397
Encoder Loss:  0.05967544  || Decoder Loss:  0.0035076432 Validation Decoder Loss:  0.7619836
Encoder Loss:  0.05966457  || Decoder Loss:  0.0034952236 Validation Decoder Loss:  0.7619332
Encoder Loss:  0.059657227  || Decoder Loss:  0.0034869767 Validation Decoder Loss:  0.76190126
Encoder Loss:  0.05964849  || Decoder Loss:  0.00347702 Validation Decoder Loss:  0.7618817
Encoder Loss:  0.059638232  || Decoder Loss:  0.0034654594 Validation Decoder Loss:  0.76182395
Encoder Loss:  0.059633434  || Decoder Loss:  0.003460014 Validation Decoder Loss:  0.761838
Encoder Loss:  0.059630133  || Decoder Loss:  0.0034562312 Validation Decoder Loss:  0.76182204
Encoder Loss:  0.05962805  || Decoder Loss:  0.003453887 Validation Decoder Loss:  0.7618122
Encoder Loss:  0.059625115  || Decoder Loss:  0.003450509 Validation Decoder Loss:  0.76179934
Encoder Loss:  0.05962351  || Decoder Loss:  0.0034487392 Validation Decoder Loss:  0.7617926
Encoder Loss:  0.05962105  || Decoder Loss:  0.0034459336 Validation Decoder Loss:  0.76179206
Encoder Loss:  0.059619214  || Decoder Loss:  0.003443936 Validation Decoder Loss:  0.76179004
Encoder Loss:  0.059618358  || Decoder Loss:  0.0034428323 Validation Decoder Loss:  0.7617825
Encoder Loss:  0.05961603  || Decoder Loss:  0.0034403717 Validation Decoder Loss:  0.76177794
Encoder Loss:  0.059614666  || Decoder Loss:  0.0034387517 Validation Decoder Loss:  0.76176625
Encoder Loss:  0.059613977  || Decoder Loss:  0.0034378741 Validation Decoder Loss:  0.76176625
Encoder Loss:  0.059612114  || Decoder Loss:  0.0034358052 Validation Decoder Loss:  0.76175874
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.76175874
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_40 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 2607, 8, 1)        375       
=================================================================
Total params: 375
Trainable params: 375
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.0062074047 Validation Decoder Loss:  0.7649418
Encoder Loss:  0.056495246  || Decoder Loss:  0.0033442772 Validation Decoder Loss:  0.76349455
Encoder Loss:  0.056455866  || Decoder Loss:  0.0032999527 Validation Decoder Loss:  0.76153475
Encoder Loss:  0.05642348  || Decoder Loss:  0.003263513 Validation Decoder Loss:  0.7601048
Encoder Loss:  0.056403175  || Decoder Loss:  0.0032406487 Validation Decoder Loss:  0.75232387
Encoder Loss:  0.056120366  || Decoder Loss:  0.0029223377 Validation Decoder Loss:  0.6441422
Encoder Loss:  0.055914246  || Decoder Loss:  0.0026903115 Validation Decoder Loss:  0.642964
Encoder Loss:  0.05589726  || Decoder Loss:  0.0026712262 Validation Decoder Loss:  0.6428854
Encoder Loss:  0.055873558  || Decoder Loss:  0.0026445503 Validation Decoder Loss:  0.64195776
Encoder Loss:  0.055850867  || Decoder Loss:  0.0026189697 Validation Decoder Loss:  0.6409879
Encoder Loss:  0.055838294  || Decoder Loss:  0.0026048997 Validation Decoder Loss:  0.6407386
Encoder Loss:  0.055829927  || Decoder Loss:  0.002595444 Validation Decoder Loss:  0.6406595
Encoder Loss:  0.055822376  || Decoder Loss:  0.002586928 Validation Decoder Loss:  0.6406595
Encoder Loss:  0.055809114  || Decoder Loss:  0.0025719898 Validation Decoder Loss:  0.64205146
Encoder Loss:  0.055790193  || Decoder Loss:  0.0025507542 Validation Decoder Loss:  0.64273584
Encoder Loss:  0.05578006  || Decoder Loss:  0.0025393136 Validation Decoder Loss:  0.6430208
Encoder Loss:  0.05577262  || Decoder Loss:  0.0025309813 Validation Decoder Loss:  0.64320374
Encoder Loss:  0.05576623  || Decoder Loss:  0.002523738 Validation Decoder Loss:  0.6431887
Encoder Loss:  0.055759765  || Decoder Loss:  0.0025164855 Validation Decoder Loss:  0.6429241
Encoder Loss:  0.055753026  || Decoder Loss:  0.0025089288 Validation Decoder Loss:  0.642462
Encoder Loss:  0.05574541  || Decoder Loss:  0.002500364 Validation Decoder Loss:  0.6409334
Encoder Loss:  0.055678386  || Decoder Loss:  0.0024248983 Validation Decoder Loss:  0.5610171
Encoder Loss:  0.055377454  || Decoder Loss:  0.002086163 Validation Decoder Loss:  0.5153961
Encoder Loss:  0.055287793  || Decoder Loss:  0.0019853215 Validation Decoder Loss:  0.50443935
Encoder Loss:  0.05510487  || Decoder Loss:  0.0017794031 Validation Decoder Loss:  0.43060216
Encoder Loss:  0.05500818  || Decoder Loss:  0.0016705554 Validation Decoder Loss:  0.427165
Encoder Loss:  0.05499437  || Decoder Loss:  0.0016550788 Validation Decoder Loss:  0.42501336
Encoder Loss:  0.054971922  || Decoder Loss:  0.0016297661 Validation Decoder Loss:  0.42294884
Encoder Loss:  0.054945372  || Decoder Loss:  0.0015999266 Validation Decoder Loss:  0.4220025
Encoder Loss:  0.05493143  || Decoder Loss:  0.0015841901 Validation Decoder Loss:  0.4216508
Encoder Loss:  0.054923266  || Decoder Loss:  0.0015749879 Validation Decoder Loss:  0.4215491
Encoder Loss:  0.054916963  || Decoder Loss:  0.0015679047 Validation Decoder Loss:  0.4214708
Encoder Loss:  0.054912135  || Decoder Loss:  0.001562506 Validation Decoder Loss:  0.42138463
Encoder Loss:  0.05490836  || Decoder Loss:  0.0015581957 Validation Decoder Loss:  0.42132378
Encoder Loss:  0.05490508  || Decoder Loss:  0.0015545307 Validation Decoder Loss:  0.42126355
Encoder Loss:  0.054902148  || Decoder Loss:  0.0015512373 Validation Decoder Loss:  0.42120302
Encoder Loss:  0.05489944  || Decoder Loss:  0.0015482116 Validation Decoder Loss:  0.42116624
Encoder Loss:  0.05489693  || Decoder Loss:  0.0015453574 Validation Decoder Loss:  0.42113152
Encoder Loss:  0.05489447  || Decoder Loss:  0.001542592 Validation Decoder Loss:  0.42112026
Encoder Loss:  0.054892134  || Decoder Loss:  0.0015399562 Validation Decoder Loss:  0.42111477
Model: bold_synthesis_net_lr_0.0008545800913520845 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.42111477
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_41 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 320, 8, 1)         56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.049931355  || Decoder Loss:  0.0066465517 Validation Decoder Loss:  0.779829
Encoder Loss:  0.040940426  || Decoder Loss:  0.003351861 Validation Decoder Loss:  0.7824839
Encoder Loss:  0.03395355  || Decoder Loss:  0.0033211259 Validation Decoder Loss:  0.78176725
Encoder Loss:  0.028276734  || Decoder Loss:  0.0032386791 Validation Decoder Loss:  0.7721164
Encoder Loss:  0.022680292  || Decoder Loss:  0.0031093617 Validation Decoder Loss:  0.7580879
Encoder Loss:  0.018532343  || Decoder Loss:  0.003019019 Validation Decoder Loss:  0.74787384
Encoder Loss:  0.014464047  || Decoder Loss:  0.0029527808 Validation Decoder Loss:  0.7392169
Encoder Loss:  0.011683338  || Decoder Loss:  0.002883647 Validation Decoder Loss:  0.7291469
Encoder Loss:  0.009796642  || Decoder Loss:  0.0028144927 Validation Decoder Loss:  0.71935976
Encoder Loss:  0.008615263  || Decoder Loss:  0.0027533388 Validation Decoder Loss:  0.7103272
Encoder Loss:  0.007852742  || Decoder Loss:  0.0026969342 Validation Decoder Loss:  0.7013084
Encoder Loss:  0.0072852606  || Decoder Loss:  0.0026428243 Validation Decoder Loss:  0.6919954
Encoder Loss:  0.0067283083  || Decoder Loss:  0.0025917331 Validation Decoder Loss:  0.6824437
Encoder Loss:  0.006133868  || Decoder Loss:  0.0025439376 Validation Decoder Loss:  0.6736142
Encoder Loss:  0.0055317627  || Decoder Loss:  0.0024990102 Validation Decoder Loss:  0.6648258
Encoder Loss:  0.0052605323  || Decoder Loss:  0.0024527297 Validation Decoder Loss:  0.65657175
Encoder Loss:  0.0050938935  || Decoder Loss:  0.0024133625 Validation Decoder Loss:  0.6489116
Encoder Loss:  0.0049666893  || Decoder Loss:  0.0023800642 Validation Decoder Loss:  0.64159834
Encoder Loss:  0.0048140483  || Decoder Loss:  0.0023457636 Validation Decoder Loss:  0.63362885
Encoder Loss:  0.0046522324  || Decoder Loss:  0.002292097 Validation Decoder Loss:  0.6250639
Encoder Loss:  0.004545812  || Decoder Loss:  0.0022362473 Validation Decoder Loss:  0.6160158
Encoder Loss:  0.0044576055  || Decoder Loss:  0.0021793302 Validation Decoder Loss:  0.60648733
Encoder Loss:  0.00436687  || Decoder Loss:  0.0021157893 Validation Decoder Loss:  0.59618056
Encoder Loss:  0.00428814  || Decoder Loss:  0.0020500757 Validation Decoder Loss:  0.58554935
Encoder Loss:  0.004215387  || Decoder Loss:  0.001985449 Validation Decoder Loss:  0.5748898
Encoder Loss:  0.004149938  || Decoder Loss:  0.0019256765 Validation Decoder Loss:  0.5647023
Encoder Loss:  0.0040926742  || Decoder Loss:  0.0018719599 Validation Decoder Loss:  0.55499387
Encoder Loss:  0.0040414836  || Decoder Loss:  0.0018223581 Validation Decoder Loss:  0.54576373
Encoder Loss:  0.0039945  || Decoder Loss:  0.0017756649 Validation Decoder Loss:  0.5370838
Encoder Loss:  0.0039509134  || Decoder Loss:  0.0017314402 Validation Decoder Loss:  0.52873415
Encoder Loss:  0.00391034  || Decoder Loss:  0.001689553 Validation Decoder Loss:  0.5207096
Encoder Loss:  0.003871957  || Decoder Loss:  0.0016493014 Validation Decoder Loss:  0.5127983
Encoder Loss:  0.0038359058  || Decoder Loss:  0.0016110167 Validation Decoder Loss:  0.50502867
Encoder Loss:  0.0038015682  || Decoder Loss:  0.0015741363 Validation Decoder Loss:  0.49741974
Encoder Loss:  0.0037692918  || Decoder Loss:  0.0015391669 Validation Decoder Loss:  0.49002686
Encoder Loss:  0.0037383132  || Decoder Loss:  0.0015053203 Validation Decoder Loss:  0.4829444
Encoder Loss:  0.003709435  || Decoder Loss:  0.0014735925 Validation Decoder Loss:  0.47619212
Encoder Loss:  0.003682733  || Decoder Loss:  0.0014441116 Validation Decoder Loss:  0.46983624
Encoder Loss:  0.0036579762  || Decoder Loss:  0.0014166695 Validation Decoder Loss:  0.4637645
Encoder Loss:  0.003634808  || Decoder Loss:  0.001390894 Validation Decoder Loss:  0.45801914
Model: bold_synthesis_net_lr_0.0008240783961862558 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.45801914
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_42 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 320, 8, 1)         1651      
=================================================================
Total params: 1,651
Trainable params: 1,651
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 2607, 8, 1)        56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.0046515386 Validation Decoder Loss:  0.6654889
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029153484 Validation Decoder Loss:  0.59920895
Encoder Loss:  0.48000005  || Decoder Loss:  0.002731909 Validation Decoder Loss:  0.5887072
Encoder Loss:  0.48000005  || Decoder Loss:  0.002427866 Validation Decoder Loss:  0.50809157
Encoder Loss:  0.48000005  || Decoder Loss:  0.0021176564 Validation Decoder Loss:  0.49114022
Encoder Loss:  0.48000005  || Decoder Loss:  0.0020667813 Validation Decoder Loss:  0.48595592
Encoder Loss:  0.48000005  || Decoder Loss:  0.0020328881 Validation Decoder Loss:  0.48103455
Encoder Loss:  0.48000005  || Decoder Loss:  0.0019777722 Validation Decoder Loss:  0.4561566
Encoder Loss:  0.48000005  || Decoder Loss:  0.0018279469 Validation Decoder Loss:  0.4073449
Encoder Loss:  0.48000005  || Decoder Loss:  0.0017067444 Validation Decoder Loss:  0.39010194
Encoder Loss:  0.48000005  || Decoder Loss:  0.0016487645 Validation Decoder Loss:  0.38522273
Encoder Loss:  0.48000005  || Decoder Loss:  0.0016116507 Validation Decoder Loss:  0.3835031
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015915631 Validation Decoder Loss:  0.3821216
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015817288 Validation Decoder Loss:  0.3813686
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015743246 Validation Decoder Loss:  0.3808361
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015683827 Validation Decoder Loss:  0.38040578
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015633916 Validation Decoder Loss:  0.38002923
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015589624 Validation Decoder Loss:  0.37967706
Encoder Loss:  0.48000005  || Decoder Loss:  0.001554711 Validation Decoder Loss:  0.3792845
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015502986 Validation Decoder Loss:  0.3786853
Encoder Loss:  0.48000005  || Decoder Loss:  0.0015452515 Validation Decoder Loss:  0.37672913
Encoder Loss:  0.48000005  || Decoder Loss:  0.0014672024 Validation Decoder Loss:  0.279782
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012772308 Validation Decoder Loss:  0.26241577
Encoder Loss:  0.48000005  || Decoder Loss:  0.001258898 Validation Decoder Loss:  0.26054406
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012546295 Validation Decoder Loss:  0.25995386
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012522546 Validation Decoder Loss:  0.25970107
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012505335 Validation Decoder Loss:  0.2595713
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012491418 Validation Decoder Loss:  0.25949317
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012479739 Validation Decoder Loss:  0.25943983
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012469406 Validation Decoder Loss:  0.25940052
Encoder Loss:  0.48000005  || Decoder Loss:  0.001246038 Validation Decoder Loss:  0.25936997
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012452267 Validation Decoder Loss:  0.25934488
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012444891 Validation Decoder Loss:  0.25932342
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012437984 Validation Decoder Loss:  0.25930396
Encoder Loss:  0.48000005  || Decoder Loss:  0.001243171 Validation Decoder Loss:  0.2592861
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012425832 Validation Decoder Loss:  0.25926796
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012420247 Validation Decoder Loss:  0.25924826
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012415231 Validation Decoder Loss:  0.25922957
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012410299 Validation Decoder Loss:  0.25921166
Encoder Loss:  0.48000005  || Decoder Loss:  0.0012405707 Validation Decoder Loss:  0.2591934
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.2591934
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_43 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2607, 8, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  nan  || Decoder Loss:  0.004983374 Validation Decoder Loss:  0.7676629
Encoder Loss:  0.48000005  || Decoder Loss:  0.00325638 Validation Decoder Loss:  0.7660928
Encoder Loss:  0.48000005  || Decoder Loss:  0.0032233966 Validation Decoder Loss:  0.7652023
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031955226 Validation Decoder Loss:  0.7648352
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031689054 Validation Decoder Loss:  0.7656792
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031422866 Validation Decoder Loss:  0.76586646
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031295463 Validation Decoder Loss:  0.76586443
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031204743 Validation Decoder Loss:  0.7658376
Encoder Loss:  0.48000005  || Decoder Loss:  0.0031066705 Validation Decoder Loss:  0.7638362
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030804118 Validation Decoder Loss:  0.76357466
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030668303 Validation Decoder Loss:  0.7636138
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030577783 Validation Decoder Loss:  0.7635714
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030513883 Validation Decoder Loss:  0.7634552
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030462905 Validation Decoder Loss:  0.7633126
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030421754 Validation Decoder Loss:  0.76315665
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030383477 Validation Decoder Loss:  0.7630043
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030344804 Validation Decoder Loss:  0.7628419
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030211015 Validation Decoder Loss:  0.76369554
Encoder Loss:  0.48000005  || Decoder Loss:  0.0030080487 Validation Decoder Loss:  0.7636519
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029971106 Validation Decoder Loss:  0.7642223
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029904013 Validation Decoder Loss:  0.76390684
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029851468 Validation Decoder Loss:  0.76409566
Encoder Loss:  0.48000005  || Decoder Loss:  0.002979686 Validation Decoder Loss:  0.7641103
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029738059 Validation Decoder Loss:  0.7640127
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029684233 Validation Decoder Loss:  0.76387715
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029629893 Validation Decoder Loss:  0.76377726
Encoder Loss:  0.48000005  || Decoder Loss:  0.002958323 Validation Decoder Loss:  0.7636541
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029538646 Validation Decoder Loss:  0.76353925
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029501298 Validation Decoder Loss:  0.7634182
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029463489 Validation Decoder Loss:  0.76329195
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029428778 Validation Decoder Loss:  0.76314324
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029392997 Validation Decoder Loss:  0.7630247
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029357797 Validation Decoder Loss:  0.7628768
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029323138 Validation Decoder Loss:  0.76276207
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029294067 Validation Decoder Loss:  0.7626352
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029267415 Validation Decoder Loss:  0.7625382
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029244197 Validation Decoder Loss:  0.76238936
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029220842 Validation Decoder Loss:  0.76216775
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029195615 Validation Decoder Loss:  0.76126504
Encoder Loss:  0.48000005  || Decoder Loss:  0.0029155118 Validation Decoder Loss:  0.76037675
Model: bold_synthesis_net_lr_0.001 Train Intances: 10000 | Validation Instances: 400 | Validation Loss: 0.76037675
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 64, 5, 8, 1)       2         
_________________________________________________________________
reshape_44 (Reshape)         (None, 320, 8, 1)         0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 320, 8, 1)         1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 2607, 8, 1)        1332      
=================================================================
Total params: 1,332
Trainable params: 1,332
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [1.0e-03 1.0e+00 1.0e+00 1.0e+00 1.0e+00 8.0e+00 3.2e+02]
Optimized Validation Decoder Loss: 0.25919339060783386











Optimizing at level  2
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.25919339060783386 2
[(64, 5, 8, 1)] [(320, 8, 1)]
[(320, 8, 1)] [(320, 8, 1)]
[(2607, 8, 1)] [(320, 8, 1)]
