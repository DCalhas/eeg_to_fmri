{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Cross Correlation between EEG and BOLD signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GOAL: perform convolution among bands and channels for each timestep, with non linear activations, in order to have a signal of the same length as the BOLD signal and correlate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The loss will be the inverse cross correlation between the activation signal and BOLD signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import eeg_utils\n",
    "import fmri_utils\n",
    "import deep_cross_corr as deep_corr\n",
    "\n",
    "import numpy as np\n",
    "from numpy import correlate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from nilearn.masking import apply_mask, compute_epi_mask\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from scipy.signal import resample\n",
    "from nilearn.image import smooth_img, index_img, iter_img, clean_img, math_img, mean_img\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    }
   ],
   "source": [
    "mask = fmri_utils.get_population_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162022  =      0.000 ...   648.088 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 197234  =      0.000 ...   788.936 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 181949  =      0.000 ...   727.796 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 195159  =      0.000 ...   780.636 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 179384  =      0.000 ...   717.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182129  =      0.000 ...   728.516 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 173914  =      0.000 ...   695.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 184909  =      0.000 ...   739.636 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170594  =      0.000 ...   682.376 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169854  =      0.000 ...   679.416 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168099  =      0.000 ...   672.396 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 172264  =      0.000 ...   689.056 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/47/export/20130710470002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182594  =      0.000 ...   730.376 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/48/export/20130717480002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 171739  =      0.000 ...   686.956 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/49/export/20130918490002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 167579  =      0.000 ...   670.316 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 14164, 20)\n",
      "Extracting parameters from /home/david/eeg_informed_fmri/datasets/01/EEG/50/export/20131003_500002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168019  =      0.000 ...   672.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eeg_utils.py:35: RuntimeWarning: No coordinate information found for channels ['ECG', 'O9', 'O10']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  return mne.io.read_raw_brainvision(complete_path, preload=True)\n",
      "/home/david/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/nilearn/image/resampling.py:510: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 14164, 20)\n",
      "(224, 64, 5, 20) (224, 14164, 20)\n"
     ]
    }
   ],
   "source": [
    "n_partitions = 16\n",
    "\n",
    "X_train, y_train = deep_corr.get_data(list(range(14)), masker=mask, n_partitions=n_partitions)\n",
    "\n",
    "X_test, y_test = deep_corr.get_data(list(range(14, 16)), masker=mask, n_partitions=n_partitions)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lack of data, due to only having space for 100 instances:\n",
    "\n",
    "Our dataset has multiple X instances being equal with different target y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 5, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_198 (Conv3D)          (None, 32, 2, 20, 1)      5         \n",
      "_________________________________________________________________\n",
      "batch_normalization_309 (Bat (None, 32, 2, 20, 1)      4         \n",
      "_________________________________________________________________\n",
      "conv3d_199 (Conv3D)          (None, 16, 1, 20, 1)      5         \n",
      "_________________________________________________________________\n",
      "batch_normalization_310 (Bat (None, 16, 1, 20, 1)      4         \n",
      "_________________________________________________________________\n",
      "conv3d_200 (Conv3D)          (None, 1, 1, 20, 1)       17        \n",
      "_________________________________________________________________\n",
      "batch_normalization_311 (Bat (None, 1, 1, 20, 1)       4         \n",
      "_________________________________________________________________\n",
      "time_distributed_137 (TimeDi (None, 1, 20)             0         \n",
      "_________________________________________________________________\n",
      "lstm_137 (LSTM)              (None, 20)                3280      \n",
      "=================================================================\n",
      "Total params: 3,319\n",
      "Trainable params: 3,313\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n",
      "(14164, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_197 (Conv2D)          (None, 282, 20, 1)        101       \n",
      "_________________________________________________________________\n",
      "batch_normalization_312 (Bat (None, 282, 20, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 16, 20, 1)         101       \n",
      "_________________________________________________________________\n",
      "batch_normalization_313 (Bat (None, 16, 20, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 1, 20, 1)          17        \n",
      "_________________________________________________________________\n",
      "batch_normalization_314 (Bat (None, 1, 20, 1)          4         \n",
      "_________________________________________________________________\n",
      "time_distributed_138 (TimeDi (None, 1, 20)             0         \n",
      "_________________________________________________________________\n",
      "lstm_138 (LSTM)              (None, 20)                3280      \n",
      "=================================================================\n",
      "Total params: 3,511\n",
      "Trainable params: 3,505\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.initializers import Zeros\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, BatchNormalization, LSTM, TimeDistributed, Dense, Lambda, Input, MaxPooling2D, MaxPooling3D \n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mae\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#hyperparameters to be optimized:\n",
    "#n_partitions, output_dim, activation_function, reg_l, n_layers, dropout, maxpooling\n",
    "\n",
    "output_dim = 20\n",
    "activation_function = 'selu'\n",
    "reg_l=0\n",
    "regularizer = regularizers.l1(reg_l)\n",
    "\n",
    "def eeg_network(input_shape, kernel_size, output_dim=20, activation_function='selu', regularizer=regularizers.l1(0.001)):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    model.add(Conv3D(1, kernel_size=(2, 2, kernel_size[2]),\n",
    "                     activation=activation_function, strides=(2,2,1),\n",
    "                     input_shape=input_shape, kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(1, kernel_size=(2, 2, kernel_size[2]),\n",
    "                     activation=activation_function, strides=(2,2,1),\n",
    "                     input_shape=input_shape, kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(1, kernel_size=(16, 1, kernel_size[2]),\n",
    "                     activation=activation_function, strides=(2,1,1),\n",
    "                     input_shape=input_shape, kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(output_dim))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def bold_network(input_shape, kernel_size, output_dim=20, activation_function='selu', regularizer=regularizers.l1(0.001)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(1, kernel_size=(100, kernel_size[1]),\n",
    "                     activation=activation_function, strides=(50,1),\n",
    "                     input_shape=input_shape, kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1, kernel_size=(100, kernel_size[1]),\n",
    "                     activation=activation_function, strides=(12,1),\n",
    "                     kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(1, kernel_size=(16, kernel_size[1]),\n",
    "                     activation=activation_function, strides=(1,1),\n",
    "                     kernel_regularizer=regularizer, \n",
    "                    bias_regularizer=regularizer, activity_regularizer=regularizer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(output_dim, input_shape=input_shape))\n",
    "    \n",
    "    return model\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3], 1)\n",
    "\n",
    "eeg_input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "\n",
    "kernel_size = (X_train.shape[1], X_train.shape[2], 1)\n",
    "print(kernel_size)\n",
    "#eeg network\n",
    "eeg_network = eeg_network(eeg_input_shape, kernel_size, output_dim=output_dim, \n",
    "                          activation_function=activation_function, regularizer=regularizer)\n",
    "print(eeg_network.summary())\n",
    "\n",
    "#BOLD network (224, 64, 5, 20) (224, 14164, 20)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], y_train.shape[2], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], y_test.shape[2], 1)\n",
    "\n",
    "bold_input_shape = (y_train.shape[1], y_train.shape[2], 1)\n",
    "\n",
    "kernel_size = (y_train.shape[1], 1)\n",
    "print(kernel_size)\n",
    "\n",
    "bold_network = bold_network(bold_input_shape, kernel_size, output_dim=output_dim, \n",
    "                            activation_function=activation_function, regularizer=regularizer)\n",
    "print(bold_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_eeg = Input(shape=eeg_input_shape)\n",
    "input_bold = Input(shape=bold_input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_eeg = eeg_network(input_eeg)\n",
    "processed_bold = bold_network(input_bold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a cross correlation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlation(x, y):\n",
    "    #how should the normalization be done??\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    y = K.l2_normalize(y, axis=1)\n",
    "\n",
    "    a = K.batch_dot(x, y, axes=1)\n",
    "\n",
    "    b = K.batch_dot(x, x, axes=1)\n",
    "    c = K.batch_dot(y, y, axes=1)\n",
    "\n",
    "    return 1 - (a / (K.sqrt(b) * K.sqrt(c)))\n",
    "\n",
    "def correlation(vects):\n",
    "    #how should the normalization be done??\n",
    "    x, y = vects\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    y = K.l2_normalize(y, axis=1)\n",
    "\n",
    "    a = K.batch_dot(x, y, axes=1)\n",
    "\n",
    "    b = K.batch_dot(x, x, axes=1)\n",
    "    c = K.batch_dot(y, y, axes=1)\n",
    "\n",
    "    return 1 - (a / (K.sqrt(b) * K.sqrt(c)))\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(1.0 - y_pred, 0))\n",
    "        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "correlation = Lambda(correlation,#compare this results with euclidean\n",
    "              output_shape=cos_dist_output_shape)([processed_eeg, \n",
    "              processed_bold])\n",
    "\n",
    "multi_modal_model = Model([input_eeg, input_bold], correlation)\n",
    "\n",
    "multi_modal_model.compile(loss=contrastive_loss, optimizer=Adam(lr=0.0001))\n",
    "eeg_network.compile(loss=cross_correlation, optimizer=Adam(lr=0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create positive and negative pairs of EEG and BOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_bold_pairs(eeg, bold):\n",
    "    x_eeg = []\n",
    "    x_bold = []\n",
    "    y = []\n",
    "    \n",
    "    #how are we going to pair these? only different individuals??\n",
    "    #different timesteps of the same individual\n",
    "    \n",
    "    #redefine this variable\n",
    "    instances_per_individual = 10\n",
    "\n",
    "    #building pairs\n",
    "    for individual in range(int(len(eeg)/instances_per_individual)):\n",
    "        for other_individual in range(int(len(eeg)/instances_per_individual)):\n",
    "            for time_partitions in range(instances_per_individual):\n",
    "                if(individual == other_individual):\n",
    "                    x_eeg += [eeg[individual + time_partitions]]\n",
    "                    x_bold += [bold[other_individual + time_partitions]]\n",
    "                    y += [[1]]\n",
    "                else:\n",
    "                    x_eeg += [eeg[individual + time_partitions]]\n",
    "                    x_bold += [bold[other_individual + time_partitions]]\n",
    "                    y += [[0]]\n",
    "                    print\n",
    "    \n",
    "    x_eeg = np.array(x_eeg)\n",
    "    x_bold = np.array(x_bold)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x_eeg, x_bold, y\n",
    "\n",
    "X_train_eeg, X_train_bold, tr_y = create_eeg_bold_pairs(X_train, y_train)\n",
    "X_test_eeg, X_test_bold, te_y = create_eeg_bold_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4840, 64, 5, 20, 1)\n",
      "(4840, 14164, 20, 1)\n",
      "(90, 64, 5, 20, 1)\n",
      "(90, 14164, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_eeg.shape)\n",
    "print(X_train_bold.shape)\n",
    "\n",
    "print(X_test_eeg.shape)\n",
    "print(X_test_bold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally train and see if it converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4840 samples, validate on 90 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "history = multi_modal_model.fit([X_train_eeg, X_train_bold], tr_y, \n",
    "                    epochs=100, \n",
    "                    batch_size=n_partitions*16, validation_data=([X_test_eeg, X_test_bold], te_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.plot(history.history['val_loss'], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the activations and plot the cross-correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_embeddings = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_corr = correlate(eeg_embeddings[0], y[0])\n",
    "linear_corr = correlate(X[0][0][0].reshape(1,-1)[0], y[0])\n",
    "print(deep_corr, linear_corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
