{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo to optimize kernel and stride in convolution operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      " /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162022  =      0.000 ...   648.088 secs...\n",
      "(30, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 197234  =      0.000 ...   788.936 secs...\n",
      "(60, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 181949  =      0.000 ...   727.796 secs...\n",
      "(90, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 195159  =      0.000 ...   780.636 secs...\n",
      "(120, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 179384  =      0.000 ...   717.536 secs...\n",
      "(150, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182129  =      0.000 ...   728.516 secs...\n",
      "(180, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 173914  =      0.000 ...   695.656 secs...\n",
      "(210, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 184909  =      0.000 ...   739.636 secs...\n",
      "(240, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170594  =      0.000 ...   682.376 secs...\n",
      "(270, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169854  =      0.000 ...   679.416 secs...\n",
      "(300, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168099  =      0.000 ...   672.396 secs...\n",
      "(30, 2607, 10)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 172264  =      0.000 ...   689.056 secs...\n",
      "(60, 2607, 10)\n",
      "Finished Loading Data\n",
      "Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "import iterative_naive_nas\n",
    "\n",
    "import utils.gen_dims_utils as gen_dim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import custom_training\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import utils.losses_utils as losses\n",
    "\n",
    "import utils.data_utils as data_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_models_and_shapes(eeg_file='../../optimized_nets/eeg/eeg_bold_shift_0.json', \n",
    "                          bold_file='../../optimized_nets/bold/bold_bold_shift_0.json',\n",
    "                          decoder_file='../../optimized_nets/decoder/decoder_bold_shift_0.json'):\n",
    "    json_file = open(eeg_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    eeg_network = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    \n",
    "    json_file = open(bold_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    bold_network = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    \n",
    "    json_file = open(decoder_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    decoder_network = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    \n",
    "    return eeg_network, bold_network, decoder_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162022  =      0.000 ...   648.088 secs...\n",
      "(16, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 197234  =      0.000 ...   788.936 secs...\n",
      "(32, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 181949  =      0.000 ...   727.796 secs...\n",
      "(48, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 195159  =      0.000 ...   780.636 secs...\n",
      "(64, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 179384  =      0.000 ...   717.536 secs...\n",
      "(80, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182129  =      0.000 ...   728.516 secs...\n",
      "(96, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 173914  =      0.000 ...   695.656 secs...\n",
      "(112, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 184909  =      0.000 ...   739.636 secs...\n",
      "(128, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170594  =      0.000 ...   682.376 secs...\n",
      "(144, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169854  =      0.000 ...   679.416 secs...\n",
      "(160, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168099  =      0.000 ...   672.396 secs...\n",
      "(16, 2607, 19)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 172264  =      0.000 ...   689.056 secs...\n",
      "(32, 2607, 19)\n",
      "Finished Loading Data\n",
      "Pairs Created\n"
     ]
    }
   ],
   "source": [
    "bold_shift=3\n",
    "n_partitions=16\n",
    "eeg_train, bold_train, eeg_val, bold_val = data_utils.load_data(list(range(10)), \n",
    "                                                                list(range(10, 12)), \n",
    "                                                                bold_shift=bold_shift, \n",
    "                                                                n_partitions=n_partitions, \n",
    "                                                                roi=1, roi_ica_components=20)\n",
    "n_voxels = bold_train.shape[1]\n",
    "\n",
    "print(\"Finished Loading Data\")\n",
    "\n",
    "X_train_eeg, X_train_bold, tr_y = data_utils.create_eeg_bold_pairs(eeg_train, bold_train)\n",
    "X_val_eeg, X_val_bold, tv_y = data_utils.create_eeg_bold_pairs(eeg_val, bold_val)\n",
    "\n",
    "\n",
    "X_train_eeg = X_train_eeg.astype(np.float32)\n",
    "X_train_bold = X_train_bold.astype(np.float32)\n",
    "X_val_eeg = X_val_eeg.astype(np.float32)\n",
    "X_val_bold = X_val_bold.astype(np.float32)\n",
    "\n",
    "\n",
    "tr_y = np.array(tr_y, dtype=np.float32)\n",
    "tv_y = np.array(tv_y, dtype=np.float32)\n",
    "\n",
    "eeg_train = eeg_train.astype('float32')\n",
    "bold_train = bold_train.astype('float32')\n",
    "eeg_val = eeg_val.astype('float32')\n",
    "bold_val = bold_val.astype('float32')\n",
    "\n",
    "print(\"Pairs Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_network, bold_network, decoder_network = get_models_and_shapes()\n",
    "\n",
    "eeg_input_shape = (64, 5, 19, 1)\n",
    "bold_input_shape=(2570, 19, 1)\n",
    "\n",
    "multi_modal_model = custom_training.multi_modal_network(eeg_input_shape, bold_input_shape, eeg_network, bold_network, dcca=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the kernel and stride of the current shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3d_transpose_105\n",
      "0 (64, 5, 19, 1)\n",
      "((451, 1), (10, 8), (73, 7), (136, 6), (199, 5), (262, 4), (325, 3), (388, 2))\n",
      "((1, 1),)\n",
      "((1, 1),)\n",
      "((1, 1),)\n",
      "reshape_105\n",
      "conv2d_105\n",
      "0 (2570, 19, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer \"conv2d_105\" has multiple inbound nodes, with different output shapes. Hence the notion of \"output shape\" is ill-defined for the layer. Use `get_output_shape_at(node_index)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e40a6a39fbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madd_kernel_stride_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eeg_net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madd_kernel_stride_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bold_net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e40a6a39fbf0>\u001b[0m in \u001b[0;36madd_kernel_stride_hyperparameters\u001b[0;34m(network, net_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_possible_kernel_size_deconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_input_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 hyperparameters += [{'name': net_name + '_' + str(layer) + '_' + str(dim), 'type': 'discrete',\n\u001b[1;32m     37\u001b[0m                                     'domain': tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].output_shape)[dim]))}]\n",
      "\u001b[0;32m~/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m                            \u001b[0;34m'ill-defined for the layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                            \u001b[0;34m'Use `get_output_shape_at(node_index)` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m                            'instead.' % self.name)\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer \"conv2d_105\" has multiple inbound nodes, with different output shapes. Hence the notion of \"output shape\" is ill-defined for the layer. Use `get_output_shape_at(node_index)` instead."
     ]
    }
   ],
   "source": [
    "def batch_to_dim(shape):\n",
    "    return shape[1:]\n",
    "\n",
    "\n",
    "hyperparameters = []\n",
    "\n",
    "def add_kernel_stride_hyperparameters(network, net_name):\n",
    "    \n",
    "    hyperparameters = []\n",
    "    \n",
    "    previous_layer = -1\n",
    "    \n",
    "    for layer in range(len(network.layers)):\n",
    "        print(network.layers[layer].name)\n",
    "        if('transpose' in network.layers[layer].name):\n",
    "            if(previous_layer < 0):\n",
    "                eeg_input_shape = (64, 5, 19, 1)\n",
    "            else:\n",
    "                eeg_input_shape = batch_to_dim(network.layers[previous_layer].output_shape)\n",
    "            print(layer, eeg_input_shape)\n",
    "            for dim in range(len(eeg_input_shape)):\n",
    "                print(tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].output_shape)[dim])))\n",
    "                hyperparameters += [{'name': net_name + '_' + str(layer) + '_' + str(dim), 'type': 'discrete',\n",
    "                                    'domain': tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].output_shape)[dim]))}]\n",
    "\n",
    "            previous_layer = layer\n",
    "        \n",
    "        elif('transpose' not in network.layers[layer].name and 'reshape' not in network.layers[layer].name):\n",
    "            if(previous_layer < 0):\n",
    "                eeg_input_shape = (2570, 19, 1)\n",
    "            else:\n",
    "                eeg_input_shape = batch_to_dim(network.layers[previous_layer].output_shape)\n",
    "            print(layer, eeg_input_shape)\n",
    "            for dim in range(len(eeg_input_shape)):\n",
    "                print(tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].output_shape)[dim])))\n",
    "                hyperparameters += [{'name': net_name + '_' + str(layer) + '_' + str(dim), 'type': 'discrete',\n",
    "                                    'domain': tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].output_shape)[dim]))}]\n",
    "\n",
    "            previous_layer = layer\n",
    "            \n",
    "    return hyperparameters\n",
    "            \n",
    "hyperparameters += [add_kernel_stride_hyperparameters(eeg_network, 'eeg_net')]\n",
    "hyperparameters += [add_kernel_stride_hyperparameters(bold_network, 'bold_net')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
