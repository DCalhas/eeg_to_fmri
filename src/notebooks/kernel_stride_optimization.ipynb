{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo to optimize kernel and stride in convolution operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      " /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162022  =      0.000 ...   648.088 secs...\n",
      "(50, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 197234  =      0.000 ...   788.936 secs...\n",
      "(100, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 181949  =      0.000 ...   727.796 secs...\n",
      "(150, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 195159  =      0.000 ...   780.636 secs...\n",
      "(200, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 179384  =      0.000 ...   717.536 secs...\n",
      "(250, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182129  =      0.000 ...   728.516 secs...\n",
      "(300, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 173914  =      0.000 ...   695.656 secs...\n",
      "(350, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 184909  =      0.000 ...   739.636 secs...\n",
      "(400, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170594  =      0.000 ...   682.376 secs...\n",
      "(450, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169854  =      0.000 ...   679.416 secs...\n",
      "(500, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168099  =      0.000 ...   672.396 secs...\n",
      "(50, 2607, 7)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 172264  =      0.000 ...   689.056 secs...\n",
      "(100, 2607, 7)\n",
      "Finished Loading Data\n",
      "Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "import iterative_naive_nas\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import custom_training\n",
    "\n",
    "import utils.losses_utils as losses\n",
    "\n",
    "import utils.data_utils as data_utils\n",
    "\n",
    "import viz_results as viz\n",
    "\n",
    "import GPyOpt, GPy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from utils import gen_dims_utils as gen_dim\n",
    "\n",
    "#30_paritions\n",
    "#optimized_parameters = [3.46661820e-04, 4.01120020e-01, 9.09580986e-01, 4.13090818e-01,\n",
    "# 3.93104672e-01, 8.00000000e+00, 8.20000000e+02]\n",
    "#25_partitions\n",
    "optimized_parameters = [6.80863834e-04, 4.68269339e-01, 4.51964628e-01, 1.80029101e-01,\n",
    " 3.94141219e-01, 2.00000000e+00, 7.20000000e+02]\n",
    "#21_partitions\n",
    "#optimized_parameters = [1.0e-14, 1.0e-04, 1.0e+00, 1.0e-04, 0.0e+00, 1.6e+01, 8.2e+02]\n",
    "\n",
    "learning_rate = float(optimized_parameters[0])\n",
    "l1_penalization_eeg = float(optimized_parameters[1])\n",
    "l1_penalization_bold = float(optimized_parameters[2])\n",
    "l1_penalization_decoder = float(optimized_parameters[3])\n",
    "loss_coefficient = float(optimized_parameters[4])\n",
    "batch_size = int(optimized_parameters[5])\n",
    "current_shape = int(optimized_parameters[6])\n",
    "#eeg_hidden_shape = int(optimized_parameters[6])\n",
    "#bold_hidden_shape = int(optimized_parameters[7])\n",
    "#decoder_hidden_shape = int(optimized_parameters[8])\n",
    "\n",
    "bold_shift=3\n",
    "f_resample=1.8\n",
    "n_partitions=25\n",
    "\n",
    "eeg_file='../../optimized_nets/eeg/eeg_' + str(n_partitions) + '_partitions.json'\n",
    "bold_file='../../optimized_nets/bold/bold_' + str(n_partitions) + '_partitions.json'\n",
    "decoder_file='../../optimized_nets/decoder/decoder_' + str(n_partitions) + '_partitions.json'\n",
    "\n",
    "\n",
    "def batch_to_dim(shape):\n",
    "    return shape[1:]\n",
    "\n",
    "def add_kernel_stride_hyperparameters(network, net_name):\n",
    "    \n",
    "    hyperparameters = []\n",
    "    \n",
    "    previous_layer = -1\n",
    "    \n",
    "    for layer in range(len(network.layers)):\n",
    "        if('transpose' in network.layers[layer].name):\n",
    "            if(previous_layer < 0):\n",
    "                eeg_input_shape = network.input_shape[1:-1]\n",
    "            else:\n",
    "                eeg_input_shape = batch_to_dim(network.layers[previous_layer].get_output_shape_at(0)[:-1])\n",
    "            for dim in range(len(eeg_input_shape)):\n",
    "                hyperparameters += [{'name': net_name + '_l' + str(layer) + '_d' + str(dim), 'type': 'discrete',\n",
    "                                    'domain': tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].get_output_shape_at(0))[dim]))}]\n",
    "\n",
    "            previous_layer = layer\n",
    "        \n",
    "        elif('transpose' not in network.layers[layer].name and 'reshape' not in network.layers[layer].name):\n",
    "            if(previous_layer < 0):\n",
    "                eeg_input_shape = network.input_shape[1:-1]\n",
    "            else:\n",
    "                eeg_input_shape = batch_to_dim(network.layers[previous_layer].get_output_shape_at(0)[:-1])\n",
    "            for dim in range(len(eeg_input_shape)):\n",
    "                hyperparameters += [{'name': net_name + '_l' + str(layer) + '_d' + str(dim), 'type': 'discrete',\n",
    "                                    'domain': tuple(gen_dim.get_possible_kernel_size_deconv(eeg_input_shape[dim], batch_to_dim(network.layers[layer].get_output_shape_at(0))[dim]))}]\n",
    "\n",
    "            previous_layer = layer\n",
    "            \n",
    "    return hyperparameters\n",
    "\n",
    "\n",
    "def get_unmutable_parameters(parameters, index_opt=0, name=None, layers_index=None):\n",
    "    if(layers_index==None):\n",
    "        layers_index = {}\n",
    "    \n",
    "    \n",
    "    for i in range(len(parameters)):\n",
    "        if(name in parameters[i]['name']):\n",
    "            layer_index = int(parameters[i]['name'][-4])\n",
    "            dim_index = int(parameters[i]['name'][-1])\n",
    "            \n",
    "            if(layer_index in layers_index.keys()):\n",
    "                layers_index[layer_index][dim_index] = {'kernel': parameters[i]['domain'][index_opt][0], \n",
    "                                                        'stride': parameters[i]['domain'][index_opt][1]}\n",
    "            else:\n",
    "                layers_index[layer_index] = {dim_index: {'kernel': parameters[i]['domain'][index_opt][0], \n",
    "                                                         'stride': parameters[i]['domain'][index_opt][1]}}\n",
    "    \n",
    "    return layers_index\n",
    "\n",
    "def get_models_unmutable_parameters(parameters, index_opt=np.array([[0,0,0]]), new_parameters=None):\n",
    "    \n",
    "    if(new_parameters == None):\n",
    "        new_parameters = {'eeg': None, 'bold': None, 'decoder': None}\n",
    "    \n",
    "    new_parameters['eeg'] = get_unmutable_parameters(parameters, \n",
    "                                                     index_opt=int(index_opt[:,0]), \n",
    "                                                     name='eeg', \n",
    "                                                     layers_index=new_parameters['eeg'])\n",
    "    new_parameters['bold'] = get_unmutable_parameters(parameters, \n",
    "                                                      index_opt=int(index_opt[:,1]), \n",
    "                                                      name='bold', \n",
    "                                                      layers_index=new_parameters['bold'])\n",
    "    new_parameters['decoder'] = get_unmutable_parameters(parameters, \n",
    "                                                         index_opt=int(index_opt[:,2]), \n",
    "                                                         name='decoder', \n",
    "                                                         layers_index=new_parameters['decoder'])\n",
    "    \n",
    "    return new_parameters\n",
    "\n",
    "def get_model_by_kernel_stride(network, kernel_stride, name='eeg'):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    for layer in range(len(network.layers)):\n",
    "        if('conv' in network.layers[layer].name):\n",
    "            kernel_size = ()\n",
    "            strides = ()\n",
    "            \n",
    "            #build kernel\n",
    "            for dim in range(len(kernel_stride[name][layer].keys())):\n",
    "                kernel_size += (kernel_stride[name][layer][dim]['kernel'], )\n",
    "                strides += (kernel_stride[name][layer][dim]['stride'], )\n",
    "                \n",
    "            model.add(network.layers[layer].__class__(1, \n",
    "                                                      kernel_size=kernel_size, \n",
    "                                                      strides=strides, \n",
    "                                                      activation=network.layers[layer].activation))\n",
    "        else:\n",
    "            model.add(network.layers[layer])\n",
    "            \n",
    "    model.build(input_shape=network.input_shape)\n",
    "            \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162022  =      0.000 ...   648.088 secs...\n",
      "(25, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 197234  =      0.000 ...   788.936 secs...\n",
      "(50, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 181949  =      0.000 ...   727.796 secs...\n",
      "(75, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 195159  =      0.000 ...   780.636 secs...\n",
      "(100, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 179384  =      0.000 ...   717.536 secs...\n",
      "(125, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182129  =      0.000 ...   728.516 secs...\n",
      "(150, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 173914  =      0.000 ...   695.656 secs...\n",
      "(175, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 184909  =      0.000 ...   739.636 secs...\n",
      "(200, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170594  =      0.000 ...   682.376 secs...\n",
      "(225, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169854  =      0.000 ...   679.416 secs...\n",
      "(250, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168099  =      0.000 ...   672.396 secs...\n",
      "(25, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 172264  =      0.000 ...   689.056 secs...\n",
      "(50, 2607, 14)\n",
      "Finished Loading Data\n",
      "Pairs Created\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/47/export/20130710470002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 182594  =      0.000 ...   730.376 secs...\n",
      "(25, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/48/export/20130717480002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 171739  =      0.000 ...   686.956 secs...\n",
      "(50, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/49/export/20130918490002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 167579  =      0.000 ...   670.316 secs...\n",
      "(75, 2607, 14)\n",
      "Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/50/export/20131003_500002_Pulse_Artifact_Correction_bin.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 168019  =      0.000 ...   672.076 secs...\n",
      "(100, 2607, 14)\n"
     ]
    }
   ],
   "source": [
    "eeg_train, bold_train, eeg_val, bold_val = data_utils.load_data(list(range(10)), \n",
    "                                                                list(range(10, 12)), \n",
    "                                                                bold_shift=bold_shift, \n",
    "                                                                n_partitions=n_partitions, f_resample=f_resample,\n",
    "                                                                roi=1, roi_ica_components=20)\n",
    "\n",
    "#standardize data\n",
    "eeg_train, bold_train, eeg_scaler, bold_scaler = data_utils.standardize(eeg_train, bold_train)\n",
    "eeg_val, bold_val, _, _ = data_utils.standardize(eeg_val, bold_val, eeg_scaler=eeg_scaler, bold_scaler=bold_scaler)\n",
    "\n",
    "n_voxels = bold_train.shape[1]\n",
    "\n",
    "print(\"Finished Loading Data\")\n",
    "\n",
    "X_train_eeg, X_train_bold, tr_y = data_utils.create_eeg_bold_pairs(eeg_train, bold_train)\n",
    "X_val_eeg, X_val_bold, tv_y = data_utils.create_eeg_bold_pairs(eeg_val, bold_val)\n",
    "\n",
    "\n",
    "X_train_eeg = X_train_eeg.astype(np.float32)\n",
    "X_train_bold = X_train_bold.astype(np.float32)\n",
    "X_val_eeg = X_val_eeg.astype(np.float32)\n",
    "X_val_bold = X_val_bold.astype(np.float32)\n",
    "\n",
    "\n",
    "tr_y = np.array(tr_y, dtype=np.float32)\n",
    "tv_y = np.array(tv_y, dtype=np.float32)\n",
    "\n",
    "eeg_train = eeg_train.astype('float32')\n",
    "bold_train = bold_train.astype('float32')\n",
    "eeg_val = eeg_val.astype('float32')\n",
    "bold_val = bold_val.astype('float32')\n",
    "\n",
    "print(\"Pairs Created\")\n",
    "\n",
    "_, _, eeg_test, bold_test = data_utils.load_data(list(range(0)), list(range(12, 16)), \n",
    "                                                 bold_shift=bold_shift, \n",
    "                                                 n_partitions=n_partitions, \n",
    "                                                 f_resample=f_resample, \n",
    "                                                 roi=1, roi_ica_components=20)\n",
    "\n",
    "eeg_test, bold_test, _, _ = data_utils.standardize(eeg_test, bold_test, eeg_scaler=eeg_scaler, bold_scaler=bold_scaler)\n",
    "\n",
    "eeg_test = eeg_test.astype('float32')\n",
    "bold_test = bold_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Loss:  0.17020757  || Decoder Loss:  -0.010124166 Validation Decoder Loss:  -1.0552443\n",
      "Encoder Loss:  0.14676447  || Decoder Loss:  -0.044733025 Validation Decoder Loss:  -0.87587005\n",
      "Encoder Loss:  0.16261142  || Decoder Loss:  -0.093693346 Validation Decoder Loss:  -0.6989015\n",
      "Encoder Loss:  0.18167289  || Decoder Loss:  -0.1315524 Validation Decoder Loss:  -0.48065498\n",
      "Encoder Loss:  0.19646579  || Decoder Loss:  -0.16001979 Validation Decoder Loss:  -0.37717324\n",
      "Encoder Loss:  0.20483561  || Decoder Loss:  -0.17668647 Validation Decoder Loss:  -0.31909654\n",
      "Encoder Loss:  0.21047658  || Decoder Loss:  -0.18785256 Validation Decoder Loss:  -0.28698\n",
      "Encoder Loss:  0.21375448  || Decoder Loss:  -0.19439176 Validation Decoder Loss:  -0.27822572\n",
      "Encoder Loss:  0.21608122  || Decoder Loss:  -0.19980654 Validation Decoder Loss:  -0.26055348\n",
      "Encoder Loss:  0.21853417  || Decoder Loss:  -0.20480274 Validation Decoder Loss:  -0.23926584\n",
      "Encoder Loss:  0.22064428  || Decoder Loss:  -0.20997141 Validation Decoder Loss:  -0.22420001\n",
      "Encoder Loss:  0.22251521  || Decoder Loss:  -0.21419546 Validation Decoder Loss:  -0.21720791\n",
      "Encoder Loss:  0.22448488  || Decoder Loss:  -0.21781027 Validation Decoder Loss:  -0.20978308\n",
      "Encoder Loss:  0.22610214  || Decoder Loss:  -0.22111623 Validation Decoder Loss:  -0.20137253\n",
      "Encoder Loss:  0.22746284  || Decoder Loss:  -0.22455983 Validation Decoder Loss:  -0.1858402\n",
      "Encoder Loss:  0.22893418  || Decoder Loss:  -0.22897251 Validation Decoder Loss:  -0.15225299\n",
      "Encoder Loss:  0.23080589  || Decoder Loss:  -0.23415297 Validation Decoder Loss:  -0.13643433\n",
      "Encoder Loss:  0.23141026  || Decoder Loss:  -0.23680997 Validation Decoder Loss:  -0.13007171\n",
      "Encoder Loss:  0.23193116  || Decoder Loss:  -0.23853077 Validation Decoder Loss:  -0.12732351\n",
      "Encoder Loss:  0.23240085  || Decoder Loss:  -0.2397246 Validation Decoder Loss:  -0.13081713\n",
      "Encoder Loss:  0.23221251  || Decoder Loss:  -0.24091299 Validation Decoder Loss:  -0.13441701\n",
      "Encoder Loss:  0.23221469  || Decoder Loss:  -0.24234392 Validation Decoder Loss:  -0.13543549\n",
      "Encoder Loss:  0.23222755  || Decoder Loss:  -0.24344315 Validation Decoder Loss:  -0.1405538\n",
      "Encoder Loss:  0.23204193  || Decoder Loss:  -0.24479315 Validation Decoder Loss:  -0.13539901\n",
      "Encoder Loss:  0.23268504  || Decoder Loss:  -0.2461613 Validation Decoder Loss:  -0.13057168\n",
      "Encoder Loss:  0.2328287  || Decoder Loss:  -0.24704586 Validation Decoder Loss:  -0.13023311\n",
      "Encoder Loss:  0.23301157  || Decoder Loss:  -0.24792753 Validation Decoder Loss:  -0.124990426\n",
      "Encoder Loss:  0.23372883  || Decoder Loss:  -0.24965377 Validation Decoder Loss:  -0.12147096\n",
      "Encoder Loss:  0.23446234  || Decoder Loss:  -0.25118497 Validation Decoder Loss:  -0.12661195\n",
      "Encoder Loss:  0.23493257  || Decoder Loss:  -0.25235593 Validation Decoder Loss:  -0.12585545\n",
      "Encoder Loss:  0.23535438  || Decoder Loss:  -0.25318965 Validation Decoder Loss:  -0.12182065\n",
      "Encoder Loss:  0.23569338  || Decoder Loss:  -0.25392103 Validation Decoder Loss:  -0.11835313\n",
      "Encoder Loss:  0.23562199  || Decoder Loss:  -0.25466534 Validation Decoder Loss:  -0.12085337\n",
      "Encoder Loss:  0.23532163  || Decoder Loss:  -0.25552365 Validation Decoder Loss:  -0.12530096\n",
      "Encoder Loss:  0.23568065  || Decoder Loss:  -0.2564937 Validation Decoder Loss:  -0.12284328\n",
      "Encoder Loss:  0.23586924  || Decoder Loss:  -0.25738102 Validation Decoder Loss:  -0.12341297\n",
      "Encoder Loss:  0.23607562  || Decoder Loss:  -0.25812888 Validation Decoder Loss:  -0.122043\n",
      "Encoder Loss:  0.23637018  || Decoder Loss:  -0.25898528 Validation Decoder Loss:  -0.120328695\n",
      "Encoder Loss:  0.2363994  || Decoder Loss:  -0.25941575 Validation Decoder Loss:  -0.11993036\n",
      "Encoder Loss:  0.23606724  || Decoder Loss:  -0.259254 Validation Decoder Loss:  -0.119947046\n"
     ]
    }
   ],
   "source": [
    "\"\"\"LCOMB\"\"\"\n",
    "\n",
    "\n",
    "eeg_network, bold_network, decoder_network = viz.get_models_and_shapes(eeg_file=eeg_file, \n",
    "                                                                      bold_file=bold_file, \n",
    "                                                                      decoder_file=decoder_file)\n",
    "\n",
    "#linear - -0.26785496 - converges\n",
    "#relu - -0.29416773 - converges\n",
    "#sigmoid - -1.4700432 - doesn't converge\n",
    "#tanh - -0.119947046 - converges\n",
    "\n",
    "eeg_network.layers[0].activation = tf.keras.activations.relu\n",
    "bold_network.layers[0].activation = tf.keras.activations.relu\n",
    "decoder_network.layers[0].activation = tf.keras.activations.relu\n",
    "\n",
    "\n",
    "eeg_input_shape = (eeg_train.shape[1], eeg_train.shape[2], eeg_train.shape[3], eeg_train.shape[4])\n",
    "bold_input_shape=(bold_train.shape[1], bold_train.shape[2], bold_train.shape[3])\n",
    "\n",
    "multi_modal_model = custom_training.multi_modal_network(eeg_input_shape, bold_input_shape, eeg_network, bold_network, dcca=False)\n",
    "\n",
    "\n",
    "validation_loss = custom_training.linear_combination_training(X_train_eeg, \n",
    "                                                            X_train_bold, \n",
    "                                                            tr_y, \n",
    "                                                            eeg_network, \n",
    "                                                            decoder_network, \n",
    "                                                            multi_modal_model, \n",
    "                                                            epochs=40, \n",
    "                                                            encoder_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                                            decoder_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                                            loss_function=losses.get_reconstruction_log_cosine_loss,\n",
    "                                                            batch_size=batch_size, \n",
    "                                                            linear_combination=loss_coefficient,\n",
    "                                                            X_val_eeg=X_val_eeg,\n",
    "                                                            X_val_bold=X_val_bold,\n",
    "                                                            tv_y=tv_y)\n",
    "\n",
    "model_name = \"LComb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get possible kernel and stride combinations according to input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = []\n",
    "            \n",
    "hyperparameters += add_kernel_stride_hyperparameters(eeg_network, 'eeg_net')\n",
    "hyperparameters += add_kernel_stride_hyperparameters(bold_network, 'bold_net')\n",
    "hyperparameters += add_kernel_stride_hyperparameters(decoder_network, 'decoder_net')\n",
    "\n",
    "hyperparameters = list(hyperparameters)\n",
    "\n",
    "set_parameters = []\n",
    "\n",
    "all_checked=False\n",
    "while(not all_checked):\n",
    "    for i in range(len(hyperparameters)):\n",
    "\n",
    "        if(len(hyperparameters[i]['domain']) == 1):\n",
    "            print(hyperparameters[i].copy())\n",
    "            set_parameters += [hyperparameters[i].copy()]\n",
    "            hyperparameters.pop(i)\n",
    "            break\n",
    "        elif(i < len(hyperparameters)-1):\n",
    "            continue\n",
    "            \n",
    "        all_checked = True\n",
    "\n",
    "hyperparameters_index = []\n",
    "\n",
    "for param in hyperparameters:\n",
    "    index_param = param.copy()\n",
    "    index_param['domain'] = tuple(range(len(index_param['domain'])))\n",
    "    hyperparameters_index += [index_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_stride_BO(hyperparameters_index, \n",
    "                 hyperparameters, \n",
    "                 optimized_parameters,\n",
    "                 get_models_unmutable_parameters(set_parameters), \n",
    "                 eeg_network, \n",
    "                 bold_network, \n",
    "                 decoder_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_stride_BO(indexes, hyperparameters, optimized_parameters, unmutable, eeg_network, bold_network, decoder_network):\n",
    "\n",
    "    def bayesian_optimization_function(x):\n",
    "        \n",
    "        test_parameters = get_models_unmutable_parameters(hyperparameters, \n",
    "                                                          index_opt=x, \n",
    "                                                          new_parameters=copy.deepcopy(unmutable))\n",
    "        \n",
    "        model_name = 'bold_synthesis_net_lr'\n",
    "        \n",
    "        dcca=False\n",
    "\n",
    "\n",
    "        ######################################################################################################\n",
    "        #\n",
    "        #\t\t\t\t\t\t\t\t\t\tDEFINING ARCHITECTURES\n",
    "        #\n",
    "        ######################################################################################################\n",
    "\n",
    "        global X_train_eeg, X_train_bold, X_val_bold, X_val_eeg, tv_y, tr_y, eeg_train, bold_train, eeg_val, bold_val, eeg_network, bold_network, decoder_network, optimized_parameters\n",
    "\n",
    "        current_learning_rate = float(optimized_parameters[0])\n",
    "        current_loss_coefficient = float(optimized_parameters[4])\n",
    "        current_batch_size = int(optimized_parameters[5])\n",
    "        \n",
    "        new_eeg_net = get_model_by_kernel_stride(eeg_network, test_parameters, name='eeg')\n",
    "        new_bold_net = get_model_by_kernel_stride(bold_network, test_parameters, name='bold')\n",
    "        new_decoder_net = get_model_by_kernel_stride(decoder_network, test_parameters, name='decoder')\n",
    "        \n",
    "        eeg_input_shape = (X_train_eeg.shape[1], X_train_eeg.shape[2], X_train_eeg.shape[3], 1)\n",
    "        bold_input_shape = (X_train_bold.shape[1], X_train_bold.shape[2], 1)\n",
    "        \n",
    "        #Joining EEG and BOLD branches\n",
    "        multi_modal_model = custom_training.multi_modal_network(eeg_input_shape, \n",
    "                                                                bold_input_shape, \n",
    "                                                                new_eeg_net, \n",
    "                                                                new_bold_net, \n",
    "                                                                dcca=dcca, \n",
    "                                                                corr_distance=True)\n",
    "\n",
    "        ######################################################################################################\n",
    "        #\n",
    "        #\t\t\t\t\t\t\t\t\t\tRUN TRAINING SESSION\n",
    "        #\n",
    "        ######################################################################################################\n",
    "        print(\"Starting training\")\t\t\n",
    "\n",
    "        #exception can appear\n",
    "        validation_loss = custom_training.linear_combination_training(X_train_eeg, \n",
    "                                                                      X_train_bold, \n",
    "                                                                      tr_y, \n",
    "                                                                      new_eeg_net, \n",
    "                                                                      new_decoder_net, \n",
    "                                                                      multi_modal_model,\n",
    "                                                                      epochs=40, \n",
    "                                                                      encoder_optimizer=tf.keras.optimizers.Adam(learning_rate=current_learning_rate),\n",
    "                                                                      decoder_optimizer=tf.keras.optimizers.Adam(learning_rate=current_learning_rate),\n",
    "                                                                      loss_function=losses.get_reconstruction_cosine_loss,\n",
    "                                                                      batch_size=current_batch_size, linear_combination=current_loss_coefficient,\n",
    "                                                                      X_val_eeg=X_val_eeg,\n",
    "                                                                      X_val_bold=X_val_bold,\n",
    "                                                                      tv_y=tv_y)\n",
    "\n",
    "        print(\"Model: \" + model_name +\n",
    "        ' Train Intances: ' + str(len(X_train_bold)) + ' | Validation Instances: ' + str(len(X_val_bold)) +  ' | Validation Loss: ' + str(validation_loss))\n",
    "        \n",
    "        return validation_loss\n",
    "\n",
    "    optimizer = GPyOpt.methods.BayesianOptimization(f=bayesian_optimization_function, \n",
    "                                                    domain=indexes, \n",
    "                                                    model_type=\"GP_MCMC\", \n",
    "                                                    acquisition_type=\"EI_MCMC\")\n",
    "\n",
    "    print(\"Started Optimization Process\")\n",
    "    optimizer.run_optimization(max_iter=100)\n",
    "    \n",
    "    test_parameters = get_models_unmutable_parameters(hyperparameters, \n",
    "                                                      index_opt=optimizer.fx_opt, \n",
    "                                                      new_parameters=copy.deepcopy(unmutable))\n",
    "    \n",
    "    new_eeg_net = get_model_by_kernel_stride(eeg_network, test_parameters, name='eeg')\n",
    "    new_bold_net = get_model_by_kernel_stride(bold_network, test_parameters, name='bold')\n",
    "    new_decoder_net = get_model_by_kernel_stride(decoder_network, test_parameters, name='decoder')\n",
    "\n",
    "    if(not (new_eeg_net and new_bold_net and new_decoder_net)):\n",
    "        return None, None, None, None\n",
    "\n",
    "    print(\"Optimized Parameters: {0}\".format(optimizer.x_opt))\n",
    "    print(\"Optimized Validation Decoder Loss: {0}\".format(optimizer.fx_opt))\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    return new_eeg_net, new_bold_net, new_decoder_net, optimizer.fx_opt\n",
    "\n",
    "\n",
    "\n",
    "kernel_stride_BO(hyperparameters_index, \n",
    "                 hyperparameters, \n",
    "                 optimized_parameters,\n",
    "                 get_models_unmutable_parameters(set_parameters), \n",
    "                 eeg_network, \n",
    "                 bold_network, \n",
    "                 decoder_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
