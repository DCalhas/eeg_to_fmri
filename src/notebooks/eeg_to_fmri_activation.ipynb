{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endless-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n",
      "I: Starting to Load Data\n",
      "I: Finished Loading Data\n",
      "I: Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import tf_config, preprocess_data, search_algorithms, train, losses_utils, metrics\n",
    "\n",
    "from models import fmri_ae, eeg_to_fmri, uniconv_fmri\n",
    "\n",
    "from layers import locally_connected\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import time\n",
    "\n",
    "dataset=\"01\"\n",
    "memory_limit=1500\n",
    "n_individuals=10\n",
    "interval_eeg=10\n",
    "\n",
    "tf_config.set_seed(seed=42)\n",
    "tf_config.setup_tensorflow(device=\"GPU\", memory_limit=memory_limit)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_data, _ = preprocess_data.dataset(dataset, n_individuals=n_individuals,\n",
    "                                            interval_eeg=interval_eeg, \n",
    "                                            ind_volume_fit=False,\n",
    "                                            standardize_fmri=True,\n",
    "                                            iqr=False,\n",
    "                                            verbose=True)\n",
    "    eeg_train, fmri_train =train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instructional-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_train = eeg_train[:100]\n",
    "fmri_train = fmri_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 134, 10, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-asset",
   "metadata": {},
   "source": [
    "## Build fMRI AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "engaged-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (0.002980911194116198, 0.0004396489214334123, (9, 9, 4), (1, 1, 1), 4, (7, 7, 7), 4, True, True, True, True, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "leading-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unroll hyperparameters\n",
    "learning_rate=float(theta[0])\n",
    "weight_decay = float(theta[1])\n",
    "kernel_size = theta[2]\n",
    "stride_size = theta[3]\n",
    "batch_size=int(theta[4])\n",
    "latent_dimension=theta[5]\n",
    "n_channels=int(theta[6])\n",
    "max_pool=bool(theta[7])\n",
    "batch_norm=bool(theta[8])\n",
    "skip_connections=bool(theta[9])\n",
    "dropout=bool(theta[10])\n",
    "n_stacks=int(theta[11])\n",
    "outfilter=int(theta[12])\n",
    "local=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "above-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_to_fMRI(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, latent_shape, input_shape, kernel_size, stride_size, n_channels,\n",
    "                maxpool=True, weight_decay=0.000, \n",
    "                skip_connections=False, batch_norm=True,\n",
    "                n_stacks=2, local=True, \n",
    "                seed=None, fmri_args=None):\n",
    "        super(EEG_to_fMRI, self).__init__()\n",
    "        \n",
    "        self.fmri_ae = fmri_ae.fMRI_AE(*fmri_args)\n",
    "        \n",
    "        self.build_encoder(latent_shape, input_shape, kernel_size, \n",
    "                            stride_size, n_channels, maxpool=maxpool,\n",
    "                            weight_decay=weight_decay, skip_connections=skip_connections,\n",
    "                            n_stacks=n_stacks, local=local, seed=seed)\n",
    "        self.build_decoder()\n",
    "        \n",
    "    def build_encoder(self, latent_shape, input_shape, kernel_size, \n",
    "                            stride_size, n_channels, maxpool=True,\n",
    "                            weight_decay=0.000, skip_connections=False,\n",
    "                            n_stacks=2, local=True, seed=None):\n",
    "        \n",
    "        input_shape = tf.keras.layers.Input(shape=input_shape)\n",
    "        \n",
    "        x = input_shape\n",
    "        previous_block_x = input_shape\n",
    "\n",
    "        for i in range(n_stacks):\n",
    "            x = fmri_ae.stack(x, previous_block_x, tf.keras.layers.Conv3D, \n",
    "                        kernel_size, stride_size, n_channels,\n",
    "                        maxpool=maxpool, batch_norm=batch_norm, weight_decay=weight_decay, \n",
    "                        skip_connections=skip_connections, seed=seed)\n",
    "            previous_block_x=x\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.experimental.RandomFourierFeatures(latent_shape[0]*latent_shape[1]*latent_shape[2],\n",
    "                                                              trainable=True)(x)\n",
    "        \n",
    "        if(dropout):\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        x = tf.keras.layers.Reshape(latent_shape)(x)\n",
    "        \n",
    "        self.eeg_encoder = tf.keras.Model(input_shape, x)\n",
    "        self.fmri_encoder = self.fmri_ae.encoder\n",
    "        \n",
    "    def build_decoder(self):\n",
    "        self.decoder = self.fmri_ae.decoder\n",
    "        \n",
    "    def build(self, input_shape1, input_shape2):\n",
    "        self.eeg_encoder.build(input_shape=input_shape1)\n",
    "        \n",
    "        self.fmri_ae.build(input_shape=input_shape2)\n",
    "        self.fmri_encoder.build(input_shape=input_shape2)\n",
    "        \n",
    "        model.built=True\n",
    "    \n",
    "    def call(self, X, training=True):\n",
    "        x1, x2 = X\n",
    "        \n",
    "        z1 = self.eeg_encoder(x1)\n",
    "        z2 = self.fmri_encoder(x2)\n",
    "        \n",
    "        if(training):\n",
    "            return [self.decoder(z1), z1, z2]\n",
    "        return self.decoder(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exclusive-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.convolutional.Conv3D'>\n",
      "<class 'tensorflow.python.keras.layers.convolutional.Conv3D'>\n",
      "<class 'tensorflow.python.keras.layers.convolutional.Conv3D'>\n",
      "<class 'tensorflow.python.keras.layers.convolutional.Conv3D'>\n",
      "<class 'tensorflow.python.keras.layers.convolutional.Conv3D'>\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(fmri_ae)\n",
    "importlib.reload(eeg_to_fmri)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = eeg_to_fmri.EEG_to_fMRI(latent_dimension, eeg_train.shape[1:], (10,20,2), (1,1,1), 4,\n",
    "                        maxpool=True, weight_decay=0.000, skip_connections=True,\n",
    "                        batch_norm=True, dropout=False,\n",
    "                        n_stacks=2, local=True, seed=None, \n",
    "                        fmri_args = (latent_dimension, fmri_train.shape[1:], \n",
    "                        kernel_size, stride_size, n_channels, \n",
    "                        max_pool, batch_norm, weight_decay, skip_connections,\n",
    "                        n_stacks, True, False, outfilter, dropout))\n",
    "    \n",
    "    model.build(eeg_train.shape, fmri_train.shape)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    loss_fn = losses_utils.mse_cosine\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((eeg_train, fmri_train)).batch(batch_size)\n",
    "    dev_set= tf.data.Dataset.from_tensor_slices((eeg_train, fmri_train)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impressed-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ... with loss: 1.501963\n",
      "Batch ... with loss: 1.4254586\n",
      "Batch ... with loss: 1.3694496\n",
      "Batch ... with loss: 1.2983569\n",
      "Batch ... with loss: 1.187983\n",
      "Batch ... with loss: 1.0915617\n",
      "Batch ... with loss: 1.0210397\n",
      "Batch ... with loss: 0.97537935\n",
      "Batch ... with loss: 0.9373429\n",
      "Batch ... with loss: 0.9195987\n",
      "Batch ... with loss: 0.8990369\n",
      "Batch ... with loss: 0.885739\n",
      "Batch ... with loss: 0.8679184\n",
      "Batch ... with loss: 0.8594571\n",
      "Batch ... with loss: 0.8520824\n",
      "Batch ... with loss: 0.8466145\n",
      "Batch ... with loss: 0.8533242\n",
      "Batch ... with loss: 0.84611297\n",
      "Batch ... with loss: 0.84913194\n",
      "Batch ... with loss: 0.8487206\n",
      "Batch ... with loss: 0.8530009\n",
      "Batch ... with loss: 0.8499419\n",
      "Batch ... with loss: 0.8462373\n",
      "Batch ... with loss: 0.8489804\n",
      "Batch ... with loss: 0.834661\n",
      "Epoch 1 with loss: 0.9827637147903442\n",
      "Epoch 1 with l2loss: 0.02161714982241392\n",
      "Batch ... with loss: 0.8436123\n",
      "Batch ... with loss: 0.83708155\n",
      "Batch ... with loss: 0.8418976\n",
      "Batch ... with loss: 0.8373609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-74877753d200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loss_history = train.train(train_set, model, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mu_architecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             val_set=dev_set, verbose=True, verbose_batch=True)[0]\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, model, opt, loss_fn, epochs, val_set, u_architecture, additional_losses, file_output, verbose, verbose_batch)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_architecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_architecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mn_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, x, optimizer, loss_fn, u_architecture)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_architecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(model, optimizer, loss_fn, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    267\u001b[0m     factor = _safe_shape_div(\n\u001b[1;32m    268\u001b[0m         math_ops.reduce_prod(input_shape), math_ops.reduce_prod(output_shape))\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m   \"\"\"\n\u001b[0;32m-> 1336\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1273\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7323\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7324\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7325\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   7326\u001b[0m         _ctx, \"RealDiv\", name, x, y)\n\u001b[1;32m   7327\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history = train.train(train_set, model, optimizer, \n",
    "                            loss_fn, epochs=10, \n",
    "                            u_architecture=True,\n",
    "                            val_set=dev_set, verbose=True, verbose_batch=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-penetration",
   "metadata": {},
   "source": [
    "## Prediction vs ground truth plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-comment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import viz_utils\n",
    "\n",
    "save_path = \"/home/david/eeg_to_fmri/plots/100_instances/\"\n",
    "\n",
    "instance = 1\n",
    "for instance_x, instance_y in dev_set.repeat(1):\n",
    "    fig = viz_utils.plot_3D_representation_projected_slices(instance_y.numpy()[0])\n",
    "    plt.savefig(save_path + str(instance) + \"_ground_truth.pdf\", format=\"pdf\")\n",
    "    \n",
    "    fig = viz_utils.plot_3D_representation_projected_slices(model([instance_x, instance_y])[0].numpy()[0])\n",
    "    plt.savefig(save_path + str(instance) + \"_predicted.pdf\", format=\"pdf\")\n",
    "    \n",
    "    instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-competition",
   "metadata": {},
   "source": [
    "## Structural Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ssim(dev_set, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
