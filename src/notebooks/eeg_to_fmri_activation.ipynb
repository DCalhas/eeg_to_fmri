{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "growing-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n",
      "I: Starting to Load Data\n",
      "I: Finished Loading Data\n",
      "I: Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import tf_config, preprocess_data, search_algorithms, train\n",
    "\n",
    "from models import fmri_ae, eeg_to_fmri, uniconv_fmri\n",
    "\n",
    "from layers import locally_connected\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import time\n",
    "\n",
    "dataset=\"01\"\n",
    "memory_limit=1500\n",
    "n_individuals=10\n",
    "interval_eeg=10\n",
    "\n",
    "tf_config.set_seed(seed=42)\n",
    "tf_config.setup_tensorflow(device=\"GPU\", memory_limit=memory_limit)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_data, _ = preprocess_data.dataset(dataset, n_individuals=n_individuals,\n",
    "                                            interval_eeg=interval_eeg, \n",
    "                                            ind_volume_fit=False,\n",
    "                                            standardize_fmri=True,\n",
    "                                            iqr=False,\n",
    "                                            verbose=True)\n",
    "    eeg_train, fmri_train =train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_train = eeg_train[:100]\n",
    "fmri_train = fmri_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-flesh",
   "metadata": {},
   "source": [
    "## Build fMRI AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attended-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (0.002980911194116198, 0.0004396489214334123, (9, 9, 4), (1, 1, 1), 16, (7, 7, 7), 4, True, True, True, True, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inner-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unroll hyperparameters\n",
    "learning_rate=float(theta[0])\n",
    "weight_decay = float(theta[1])\n",
    "kernel_size = theta[2]\n",
    "stride_size = theta[3]\n",
    "batch_size=int(theta[4])\n",
    "latent_dimension=theta[5]\n",
    "n_channels=int(theta[6])\n",
    "max_pool=bool(theta[7])\n",
    "batch_norm=bool(theta[8])\n",
    "skip_connections=bool(theta[9])\n",
    "dropout=bool(theta[10])\n",
    "n_stacks=int(theta[11])\n",
    "outfilter=int(theta[12])\n",
    "local=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noble-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_to_fMRI(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, latent_shape, input_shape, kernel_size, stride_size, n_channels,\n",
    "                maxpool=True, weight_decay=0.000, skip_connections=False,\n",
    "                n_stacks=2, local=True, seed=None, fmri_args=None):\n",
    "        super(EEG_to_fMRI, self).__init__()\n",
    "        \n",
    "        self.training=False\n",
    "        \n",
    "        self.fmri_ae = fmri_ae.fMRI_AE(*fmri_args)\n",
    "        \n",
    "        self.build_encoder(latent_shape, input_shape, kernel_size, \n",
    "                            stride_size, n_channels, maxpool=maxpool,\n",
    "                            weight_decay=weight_decay, skip_connections=skip_connections,\n",
    "                            n_stacks=n_stacks, local=local, seed=seed)\n",
    "        self.build_decoder()\n",
    "        \n",
    "    def build_encoder(self, latent_shape, input_shape, kernel_size, \n",
    "                            stride_size, n_channels, maxpool=True,\n",
    "                            weight_decay=0.000, skip_connections=False,\n",
    "                            n_stacks=2, local=True, seed=None):\n",
    "        \n",
    "        input_shape = tf.keras.layers.Input(shape=input_shape)\n",
    "        \n",
    "        x = input_shape\n",
    "        previous_block_x = input_shape\n",
    "\n",
    "        for i in range(n_stacks):\n",
    "            x = fmri_ae.stack(x, previous_block_x, tf.keras.layers.Conv3D, \n",
    "                        kernel_size, stride_size, n_channels,\n",
    "                        maxpool=maxpool, batch_norm=batch_norm, weight_decay=weight_decay, \n",
    "                        skip_connections=skip_connections, seed=seed)\n",
    "            previous_block_x=x\n",
    "\n",
    "        if(local):\n",
    "            operation=tf.keras.layers.Conv3D\n",
    "        else:\n",
    "            operation=LocallyConnected3D\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(latent_shape[0]*latent_shape[1]*latent_shape[2], \n",
    "                                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x)\n",
    "        if(dropout):\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        x = tf.keras.layers.Reshape(latent_shape)(x)\n",
    "        \n",
    "        self.eeg_encoder = tf.keras.Model(input_shape, x)\n",
    "        self.fmri_encoder = self.fmri_ae.encoder\n",
    "        \n",
    "    def build_decoder(self):\n",
    "        self.decoder = self.fmri_ae.decoder\n",
    "        \n",
    "    def build(self, input_shape1, input_shape2):\n",
    "        self.eeg_encoder.build(input_shape=input_shape1)\n",
    "        \n",
    "        self.fmri_ae.build(input_shape=input_shape2)        \n",
    "        self.fmri_encoder.build(input_shape=input_shape2)\n",
    "        \n",
    "        model.built=True\n",
    "    \n",
    "    def call(self, X):\n",
    "        x1, x2 = X\n",
    "        \n",
    "        z1 = self.eeg_encoder(x1)\n",
    "        z2 = self.fmri_encoder(x2)\n",
    "        \n",
    "        if(self.training):\n",
    "            return [self.decoder(z1), z1, z2]\n",
    "        return self.decoder(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "similar-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_cosine(y_true, y_pred):\n",
    "    return tf.reduce_mean(((y_pred[0] - y_true)**2)/2, axis=(1,2,3)) + cosine(y_pred[1], y_pred[2])\n",
    "\n",
    "def cosine(x1, x2):\n",
    "    return 1.0 - tf.tensordot(x1,x2, [[1,2,3],[3,2,1]])/(tf.norm(x1, ord=2)*tf.norm(x2, ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proprietary-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = EEG_to_fMRI(latent_dimension, eeg_train.shape[1:], (10,20,2), (1,1,1), 4,\n",
    "                        maxpool=True, weight_decay=0.000, skip_connections=False,\n",
    "                        n_stacks=2, local=True, seed=None, \n",
    "                        fmri_args = (latent_dimension, fmri_train.shape[1:], \n",
    "                        kernel_size, stride_size, n_channels, \n",
    "                        max_pool, batch_norm, weight_decay, skip_connections,\n",
    "                        n_stacks, True, False, outfilter, dropout))\n",
    "    \n",
    "    model.build(eeg_train.shape, fmri_train.shape)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    loss_fn = mse_cosine\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((eeg_train, fmri_train)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-brief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ... with loss: 1.5032337\n",
      "Batch ... with loss: 539.1995\n",
      "Batch ... with loss: 11.167909\n",
      "Batch ... with loss: 1.4469583\n",
      "Batch ... with loss: 1.4374226\n",
      "Batch ... with loss: 1.4373065\n",
      "Batch ... with loss: 1.2625042\n",
      "Epoch 1 with loss: 79.63640827792031\n",
      "Batch ... with loss: 1.4384742\n",
      "Batch ... with loss: 1.4364989\n",
      "Batch ... with loss: 1.4347734\n",
      "Batch ... with loss: 1.4323633\n",
      "Batch ... with loss: 1.4300501\n",
      "Batch ... with loss: 1.4288636\n",
      "Batch ... with loss: 1.2443109\n",
      "Epoch 2 with loss: 1.40647634438106\n",
      "Batch ... with loss: 1.4272562\n",
      "Batch ... with loss: 1.4259734\n",
      "Batch ... with loss: 1.4254628\n",
      "Batch ... with loss: 1.4239901\n",
      "Batch ... with loss: 1.422209\n",
      "Batch ... with loss: 1.4212545\n",
      "Batch ... with loss: 1.236349\n",
      "Epoch 3 with loss: 1.3974993058613367\n",
      "Batch ... with loss: 1.4196662\n",
      "Batch ... with loss: 1.4183391\n"
     ]
    }
   ],
   "source": [
    "model.training=True\n",
    "loss_history = train.train(train_set, model, optimizer, \n",
    "                            loss_fn, epochs=10, \n",
    "                            u_architecture=True,\n",
    "                            val_set=None, verbose=True, verbose_batch=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-assumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
