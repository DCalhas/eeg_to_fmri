{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n",
      "I: Starting to Load Data\n",
      "I: Finished Loading Data\n",
      "I: Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import tf_config, preprocess_data, search_algorithms, train\n",
    "\n",
    "from models import fmri_ae, eeg_to_fmri, uniconv_fmri\n",
    "\n",
    "from layers import locally_connected\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "dataset=\"01\"\n",
    "memory_limit=1500\n",
    "n_individuals=8\n",
    "interval_eeg=6\n",
    "\n",
    "tf_config.setup_tensorflow(device=\"GPU\", memory_limit=memory_limit, seed=42)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_data, _ = preprocess_data.dataset(dataset, n_individuals=n_individuals, interval_eeg=interval_eeg, verbose=True)\n",
    "    _, fmri_train =train_data\n",
    "    #eeg_val, fmri_val =val_data\n",
    "    \n",
    "    fmri_train = fmri_train[:296]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and hyperparameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "learning_rate=0.001\n",
    "skip_connections=True\n",
    "maxpool=False\n",
    "batch_norm=True\n",
    "weight_decay=1e-5\n",
    "n_channels=16\n",
    "latent_dimension=(5,5,5)\n",
    "kernel_size=(9,9,5)\n",
    "stride_size=(1,1,1)\n",
    "n_stacks=3\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss_fn = tf.keras.losses.MSE\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((fmri_train, fmri_train)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fmri_ae.fMRI_AE(latent_dimension, fmri_train.shape[1:], \n",
    "                kernel_size, stride_size, n_channels,\n",
    "                maxpool=maxpool, batch_norm=batch_norm, weight_decay=weight_decay, \n",
    "                skip_connections=skip_connections, n_stacks=n_stacks, \n",
    "                local=True, local_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a7b2a174d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_loss, val_loss = train.train(train_set, model, optimizer, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                    \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    val_set=None, verbose=True)\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, model, opt, loss_fn, epochs, val_set, file_output, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(X, model, loss_fn)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mn_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_loss, val_loss = train.train(train_set, model, optimizer, \n",
    "                                   loss_fn, epochs=10, \n",
    "                                   val_set=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize brain slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n",
    "\n",
    "volume=0\n",
    "xslice=30\n",
    "yslice=30\n",
    "zslice=15\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,30))\n",
    "axes[0].imshow(rotate(fmri_train[volume,xslice,:,:,:], 90))\n",
    "axes[1].imshow(rotate(model(fmri_train[volume:volume+1]).numpy()[volume,xslice,:,:,:], 90, axes=(0,1)))\n",
    "difference = np.abs(rotate(fmri_train[volume,xslice,:,:,:], 90)-rotate(model(fmri_train[volume:volume+1]).numpy()[0,xslice,:,:,:], 90, axes=(0,1)))\n",
    "axes[2].imshow(difference)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,30))\n",
    "axes[0].imshow(rotate(fmri_train[volume,:,yslice,:,:], 90))\n",
    "axes[1].imshow(rotate(model(fmri_train[volume:volume+1]).numpy()[volume,:,yslice,:,:], 90, axes=(0,1)))\n",
    "difference = np.abs(rotate(fmri_train[volume,:,yslice,:,:], 90)-rotate(model(fmri_train[volume:volume+1]).numpy()[0,:,yslice,:,:], 90, axes=(0,1)))\n",
    "axes[2].imshow(difference)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,30))\n",
    "axes[0].imshow(fmri_train[volume,:,:,zslice,:])\n",
    "axes[1].imshow(model(fmri_train[volume:volume+1]).numpy()[volume,:,:,zslice,:])\n",
    "difference = np.abs(fmri_train[volume,:,:,zslice,:]-model(fmri_train[volume:volume+1]).numpy()[0,:,:,zslice,:])\n",
    "axes[2].imshow(difference)\n",
    "plt.show()\n",
    "\n",
    "#plt.imshow(rotate(fmri_train[4,:,:,15,:], 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCAONS\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
