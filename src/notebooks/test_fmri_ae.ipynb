{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stretch-doctor",
   "metadata": {},
   "source": [
    "# Bayesian Optimization for fMRI autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-ivory",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n",
      "I: Starting to Load Data\n",
      "I: Finished Loading Data\n",
      "I: Pairs Created\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import tf_config, preprocess_data, search_algorithms, train, bnn_utils, outlier_utils, eeg_utils, viz_utils\n",
    "\n",
    "from models import fmri_ae\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import time\n",
    "\n",
    "raw_eeg=False#time or frequency features? raw-time nonraw-frequency\n",
    "resampling=False\n",
    "dataset=\"01\"\n",
    "if(dataset==\"01\"):\n",
    "    n_volumes=300-3\n",
    "if(dataset==\"02\"):\n",
    "    n_volumes=170-3\n",
    "memory_limit=1500\n",
    "n_individuals=10\n",
    "n_individuals_train=8\n",
    "n_individuals_test=2\n",
    "#parametrize the interval eeg?\n",
    "interval_eeg=6\n",
    "\n",
    "tf_config.set_seed(seed=42)\n",
    "tf_config.setup_tensorflow(device=\"GPU\", memory_limit=memory_limit)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_data, test_data = preprocess_data.dataset(dataset, n_individuals=n_individuals, \n",
    "                                                    interval_eeg=interval_eeg, \n",
    "                                                    ind_volume_fit=False,\n",
    "                                                    standardize_fmri=True,\n",
    "                                                    iqr=False,\n",
    "                                                    verbose=True)\n",
    "    _, fmri_train = train_data\n",
    "    _, fmri_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-gossip",
   "metadata": {},
   "source": [
    "## Hyperparameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pursuant-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (0.002980911194116198, 0.0004396489214334123, (9, 9, 4), (1, 1, 1), 1, (7, 7, 7), 4, True, True, True, True, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-detection",
   "metadata": {},
   "source": [
    "## Unpack hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unroll hyperparameters\n",
    "learning_rate=float(theta[0])\n",
    "weight_decay = float(theta[1])\n",
    "kernel_size = theta[2]\n",
    "stride_size = theta[3]\n",
    "batch_size=int(theta[4])\n",
    "latent_dimension=theta[5]\n",
    "n_channels=int(theta[6])\n",
    "max_pool=bool(theta[7])\n",
    "batch_norm=bool(theta[8])\n",
    "skip_connections=bool(theta[9])\n",
    "dropout=bool(theta[10])\n",
    "n_stacks=int(theta[11])\n",
    "outfilter=int(theta[12])\n",
    "local=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-identity",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "postal-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_specification = ([(9,9,4),(9,9,4),(9,9,4),(9,9,4),(9,9,4),(9,9,4)], \n",
    "                    [(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,1)],\n",
    "                   True,\n",
    "                   (2,2,1),\n",
    "                   (1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "municipal-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block18(x, operation, kernel_size, stride_size, n_channels,\n",
    "            maxpool=True, batch_norm=True, weight_decay=0.000,  padding=\"valid\",\n",
    "            maxpool_k=None, maxpool_s=None,\n",
    "            seed=None):\n",
    "\n",
    "    x = operation(filters=n_channels, kernel_size=kernel_size, strides=stride_size,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L2(weight_decay),\n",
    "                    bias_regularizer=tf.keras.regularizers.L2(weight_decay),\n",
    "                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed),\n",
    "                    padding=padding)(x)\n",
    "    if(maxpool):\n",
    "        x = tf.keras.layers.MaxPool3D(pool_size=maxpool_k, strides=maxpool_s)(x)\n",
    "    if(batch_norm):\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "\n",
    "def skip_block18(x, skip_x, operation, kernel_size, stride_size, n_channels,\n",
    "                maxpool=True, batch_norm=True, weight_decay=0.000, padding=\"valid\",\n",
    "                maxpool_k=None, maxpool_s=None,\n",
    "                seed=None):\n",
    "\n",
    "    skip_x = operation(filters=n_channels, kernel_size=kernel_size, strides=stride_size,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L2(weight_decay),\n",
    "                    bias_regularizer=tf.keras.regularizers.L2(weight_decay),\n",
    "                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed),\n",
    "                    padding=padding)(skip_x)\n",
    "\n",
    "    if(maxpool):\n",
    "        skip_x = tf.keras.layers.MaxPool3D(pool_size=maxpool_k, strides=maxpool_s)(skip_x)\n",
    "    if(batch_norm):\n",
    "        skip_x = tf.keras.layers.BatchNormalization()(skip_x)\n",
    "\n",
    "    x = tf.keras.layers.Add()([x, skip_x])\n",
    "\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "def stack18(x, previous_block_x, operation, kernel_size, stride_size, n_channels,\n",
    "                        maxpool=True, batch_norm=True, \n",
    "                        weight_decay=0.000, skip_connections=False,\n",
    "                        maxpool_k=None, maxpool_s=None,\n",
    "                        seed=None):\n",
    "    #downsampling block    \n",
    "    x = block18(x, operation, kernel_size, stride_size, n_channels,\n",
    "            maxpool=maxpool, batch_norm=batch_norm, \n",
    "            maxpool_k=maxpool_k, maxpool_s=maxpool_s,\n",
    "            weight_decay=weight_decay, padding=\"valid\",\n",
    "            seed=seed)\n",
    "\n",
    "    #non downsampling block\n",
    "    x = block18(x, operation, 3, 1, n_channels,\n",
    "            maxpool=False, batch_norm=batch_norm, \n",
    "            weight_decay=weight_decay, padding=\"same\",\n",
    "            seed=seed)\n",
    "\n",
    "    #skip connection\n",
    "    if(skip_connections):\n",
    "        x = skip_block18(x, previous_block_x, operation, \n",
    "                        kernel_size, stride_size, n_channels,\n",
    "                        maxpool=maxpool, batch_norm=batch_norm,\n",
    "                        maxpool_k=maxpool_k, maxpool_s=maxpool_s,\n",
    "                        weight_decay=weight_decay, padding=\"valid\",\n",
    "                        seed=seed)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class fMRI_AE(tf.keras.Model):\n",
    "    \"\"\"\n",
    "        NA_specification - tuple - (list1, list2, bool, tuple1, tuple2)\n",
    "                                    * list1 - kernel sizes\n",
    "                                    * list2 - stride sizes\n",
    "                                    * bool - maxpool\n",
    "                                    * tuple1 - kernel size of maxpool\n",
    "                                    * tuple2 - stride size of maxpool\n",
    "                                    Example:\n",
    "                                    na = ([(2,2,2), (2,2,2)], [(1,1,1), (1,1,1)], True, (2,2,2), (1,1,1))\n",
    "                                    na is a neural architecture with 2 layers, kernel of size 2 for all 3 dimensions\n",
    "                                    stride of size 1 for all dimensions, between each layer a max pooling operation \n",
    "                                    is applied with kernel size 2 for all dimensions and stride size 1 for all dimensions\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_shape, input_shape, na_spec, n_channels,\n",
    "                        batch_norm=True, weight_decay=0.000, skip_connections=False,\n",
    "                        local=True, local_attention=False, outfilter=0, dropout=False, seed=None):\n",
    "\n",
    "\n",
    "        super(fMRI_AE, self).__init__()\n",
    "\n",
    "        self.build_encoder(latent_shape, input_shape, na_spec, n_channels,\n",
    "                        batch_norm=batch_norm, weight_decay=weight_decay, skip_connections=skip_connections,\n",
    "                        local=local, local_attention=local_attention, dropout=dropout, seed=seed)\n",
    "\n",
    "        self.build_decoder(outfilter=outfilter, seed=seed)\n",
    "\n",
    "    def build_encoder(self, latent_shape, input_shape, na_spec, n_channels,\n",
    "                        batch_norm=True, weight_decay=0.000, skip_connections=False,\n",
    "                        local=True, local_attention=False, dropout=False, seed=None):\n",
    "\n",
    "        self.latent_shape = latent_shape\n",
    "        self.in_shape = input_shape\n",
    "\n",
    "\n",
    "        input_shape = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "        x = input_shape\n",
    "        previous_block_x = input_shape\n",
    "\n",
    "        for i in range(len(na_spec[0])):\n",
    "            x = stack18(x, previous_block_x, tf.keras.layers.Conv3D, \n",
    "                        na_spec[0][i], na_spec[1][i], n_channels,\n",
    "                        maxpool=na_spec[2], batch_norm=batch_norm, weight_decay=weight_decay, \n",
    "                        maxpool_k=na_spec[3], maxpool_s=na_spec[4],\n",
    "                        skip_connections=skip_connections, seed=seed)\n",
    "            previous_block_x=x\n",
    "            print(x.shape)\n",
    "\n",
    "        if(local):\n",
    "            operation=tf.keras.layers.Conv3D\n",
    "        else:\n",
    "            operation=LocallyConnected3D\n",
    "\n",
    "        #x = block(x, operation, (7,7,7), stride_size, n_channels,\n",
    "        #x = block18(x, operation, (7,7,7), stride_size, n_channels,\n",
    "        #        maxpool=maxpool, batch_norm=batch_norm, weight_decay=weight_decay, seed=seed)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(self.latent_shape[0]*self.latent_shape[1]*self.latent_shape[2], \n",
    "                                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x)\n",
    "        if(dropout):\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        x = tf.keras.layers.Reshape(self.latent_shape)(x)\n",
    "\n",
    "        if(local_attention):\n",
    "            #x = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=2, attention_axes=(1, 2, 3))(x,x)\n",
    "            x = tf.keras.layers.MultiHeadAttention(num_heads=n_channels, key_dim=x.shape[1]*x.shape[2]*x.shape[3], attention_axes=(1, 2, 3),\n",
    "                                                kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x,x)\n",
    "\n",
    "        self.encoder = tf.keras.Model(input_shape, x)\n",
    "\n",
    "    def build_decoder(self, outfilter=0, seed=None):\n",
    "        input_shape = tf.keras.layers.Input(shape=self.latent_shape)\n",
    "\n",
    "        x = tf.keras.layers.Flatten()(input_shape)\n",
    "\n",
    "        #upsampling\n",
    "        x = tf.keras.layers.Dense(self.in_shape[0]*self.in_shape[1]*self.in_shape[2],\n",
    "                                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x)\n",
    "        x = tf.keras.layers.Reshape(self.in_shape)(x)\n",
    "\n",
    "        #filter\n",
    "        if(outfilter == 1):\n",
    "            x = tf.keras.layers.Conv3D(filters=1, kernel_size=1, strides=1,\n",
    "                                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x)\n",
    "        elif(outfilter == 2):\n",
    "            x = LocallyConnected3D(filters=1, kernel_size=1, strides=1, implementation=3,\n",
    "                                    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed))(x)\n",
    "\n",
    "        self.decoder = tf.keras.Model(input_shape, x)    \n",
    "\n",
    "    def encode(self, X):\n",
    "        return self.encoder(X)\n",
    "\n",
    "    def decode(self, Z):\n",
    "        return self.decoder(Z)\n",
    "\n",
    "    def call(self, X):\n",
    "        if(not self.encoder.built):\n",
    "            self.encoder.build(X.shape)\n",
    "\n",
    "        return self.decode(self.encode(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "british-antarctica",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 46, 46, 24, 4)\n",
      "(None, 28, 28, 18, 4)\n",
      "(None, 21, 21, 12, 4)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(fmri_ae)\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    #build model\n",
    "    model = fmri_ae.fMRI_AE(latent_dimension, fmri_train.shape[1:], kernel_size, stride_size, n_channels,\n",
    "                            maxpool=True,\n",
    "                        batch_norm=batch_norm, weight_decay=weight_decay, skip_connections=skip_connections,\n",
    "                        local=True, local_attention=False, outfilter=outfilter, dropout=dropout)\n",
    "    \n",
    "    model.build(input_shape=fmri_train.shape)\n",
    "\n",
    "    #train model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    loss_fn = tf.keras.losses.MSE#replace\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((fmri_train, fmri_train)).batch(batch_size)\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((fmri_test, fmri_test)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-humor",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caring-dominant",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv3D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-314f7b8559cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loss_history = train.train(train_set, model, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             val_set=None, verbose=True, verbose_batch=True)[0]\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, model, opt, loss_fn, epochs, val_set, u_architecture, additional_losses, file_output, verbose, verbose_batch)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_architecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_architecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mn_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, x, optimizer, loss_fn, u_architecture)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_architecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eeg_to_fmri/src/utils/train.py\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(model, optimizer, loss_fn, x, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-04520b837ede>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-04520b837ede>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     name=None):\n\u001b[0;32m-> 1013\u001b[0;31m   return convolution_internal(\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       return op(\n\u001b[0m\u001b[1;32m   1144\u001b[0m           \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv3d_expanded_batch\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m     \u001b[0;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m     return gen_nn_ops.conv3d(\n\u001b[0m\u001b[1;32m   3012\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1398\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eeg_fmri/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv3D]"
     ]
    }
   ],
   "source": [
    "loss_history = train.train(train_set, model, optimizer, \n",
    "            loss_fn, epochs=10, \n",
    "            val_set=None, verbose=True, verbose_batch=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-desperate",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.evaluate(test_set, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-branch",
   "metadata": {},
   "source": [
    "## Train loss convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(np.arange(1,11,1), loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.title(\"Train loss convergence\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-madness",
   "metadata": {},
   "source": [
    "## Visualize predicted slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import viz_utils\n",
    "\n",
    "save_path = \"/home/ist_davidcalhas/eeg_to_fmri/plots/fmri_ae/\"\n",
    "\n",
    "instance = 1\n",
    "for instance_x, _ in test_set.repeat(1):\n",
    "    fig = viz_utils.plot_3D_representation_projected_slices(instance_x.numpy()[0])\n",
    "    #plt.savefig(save_path + str(instance) + \"_ground_truth.pdf\", format=\"pdf\")\n",
    "    \n",
    "    fig = viz_utils.plot_3D_representation_projected_slices(model(instance_x).numpy()[0])\n",
    "    #plt.savefig(save_path + str(instance) + \"_predicted.pdf\", format=\"pdf\")\n",
    "    fig\n",
    "    break\n",
    "    instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-senate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
