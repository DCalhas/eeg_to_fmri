Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 2607, 19)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-22 12:24:19.107539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-22 12:24:19.110889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-22 12:24:19.111034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-22 12:24:19.112126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-22 12:24:19.113201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-22 12:24:19.113405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-22 12:24:19.114385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-22 12:24:19.114897: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-22 12:24:19.117049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-22 12:24:19.118186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-22 12:24:19.118373: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-22 12:24:19.143991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-22 12:24:19.144901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55be703c5560 executing computations on platform Host. Devices:
2019-11-22 12:24:19.144932: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-22 12:24:19.146165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-22 12:24:19.146212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-22 12:24:19.146228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-22 12:24:19.146242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-22 12:24:19.146256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-22 12:24:19.146270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-22 12:24:19.146285: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-22 12:24:19.146299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-22 12:24:19.148519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-22 12:24:19.148631: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-22 12:24:19.214061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-22 12:24:19.214088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-22 12:24:19.214092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-22 12:24:19.215803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-22 12:24:19.216989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55be6c410d80 executing computations on platform CUDA. Devices:
2019-11-22 12:24:19.217010: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-22 12:24:19.676116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 2607, 19)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 121, 20, 19, 1)    697       
_________________________________________________________________
reshape (Reshape)            (None, 2420, 19, 1)       0         
=================================================================
Total params: 697
Trainable params: 697
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09845077  || Decoder Loss:  0.05039641 Validation Decoder Loss:  0.33883104
Encoder Loss:  0.10093979  || Decoder Loss:  0.05404132 Validation Decoder Loss:  0.33984646
Encoder Loss:  0.1043635  || Decoder Loss:  0.059114955 Validation Decoder Loss:  0.3427805
Encoder Loss:  0.108896896  || Decoder Loss:  0.06606524 Validation Decoder Loss:  0.34770194
Encoder Loss:  0.09781139  || Decoder Loss:  0.056328807 Validation Decoder Loss:  0.3416804
Encoder Loss:  0.07615405  || Decoder Loss:  0.03732404 Validation Decoder Loss:  0.33471298
Encoder Loss:  0.06184206  || Decoder Loss:  0.03772208 Validation Decoder Loss:  0.33463418
Encoder Loss:  0.043376926  || Decoder Loss:  0.037295625 Validation Decoder Loss:  0.33190626
Encoder Loss:  0.042247996  || Decoder Loss:  0.03591679 Validation Decoder Loss:  0.33091527
Encoder Loss:  0.041793127  || Decoder Loss:  0.035450846 Validation Decoder Loss:  0.33036655
Encoder Loss:  0.04154437  || Decoder Loss:  0.03522594 Validation Decoder Loss:  0.3299777
Encoder Loss:  0.041350044  || Decoder Loss:  0.035084296 Validation Decoder Loss:  0.32968473
Encoder Loss:  0.041068755  || Decoder Loss:  0.03498111 Validation Decoder Loss:  0.32947022
Encoder Loss:  0.038706534  || Decoder Loss:  0.034898035 Validation Decoder Loss:  0.329373
Encoder Loss:  0.037406575  || Decoder Loss:  0.034873065 Validation Decoder Loss:  0.32931232
Encoder Loss:  0.03730597  || Decoder Loss:  0.034853872 Validation Decoder Loss:  0.32924312
Encoder Loss:  0.037263658  || Decoder Loss:  0.034827515 Validation Decoder Loss:  0.32922482
Encoder Loss:  0.037229832  || Decoder Loss:  0.034808043 Validation Decoder Loss:  0.32925534
Encoder Loss:  0.037206676  || Decoder Loss:  0.03479593 Validation Decoder Loss:  0.32931447
Encoder Loss:  0.03718889  || Decoder Loss:  0.03478841 Validation Decoder Loss:  0.3293966
Encoder Loss:  0.03716935  || Decoder Loss:  0.034782942 Validation Decoder Loss:  0.32950354
Encoder Loss:  0.037150875  || Decoder Loss:  0.034778174 Validation Decoder Loss:  0.3296274
Encoder Loss:  0.037130717  || Decoder Loss:  0.034772053 Validation Decoder Loss:  0.32976928
Encoder Loss:  0.037107546  || Decoder Loss:  0.03476329 Validation Decoder Loss:  0.32992393
Encoder Loss:  0.037080932  || Decoder Loss:  0.034751184 Validation Decoder Loss:  0.33008552
Encoder Loss:  0.037050873  || Decoder Loss:  0.034735437 Validation Decoder Loss:  0.33024833
Encoder Loss:  0.03701633  || Decoder Loss:  0.034715593 Validation Decoder Loss:  0.33040798
Encoder Loss:  0.036978196  || Decoder Loss:  0.034691416 Validation Decoder Loss:  0.33055955
Encoder Loss:  0.03693783  || Decoder Loss:  0.034663096 Validation Decoder Loss:  0.33069694
Encoder Loss:  0.036890972  || Decoder Loss:  0.03462978 Validation Decoder Loss:  0.33081704
Encoder Loss:  0.036839385  || Decoder Loss:  0.034592375 Validation Decoder Loss:  0.33092183
Encoder Loss:  0.03679074  || Decoder Loss:  0.034553126 Validation Decoder Loss:  0.33100563
Encoder Loss:  0.03674069  || Decoder Loss:  0.03451266 Validation Decoder Loss:  0.33106697
Encoder Loss:  0.036687534  || Decoder Loss:  0.034472078 Validation Decoder Loss:  0.33111304
Encoder Loss:  0.03663627  || Decoder Loss:  0.034430526 Validation Decoder Loss:  0.33114138
Encoder Loss:  0.036588587  || Decoder Loss:  0.034390405 Validation Decoder Loss:  0.3311574
Encoder Loss:  0.036545105  || Decoder Loss:  0.034354117 Validation Decoder Loss:  0.33117002
Encoder Loss:  0.036503296  || Decoder Loss:  0.03432379 Validation Decoder Loss:  0.33118117
Encoder Loss:  0.036468517  || Decoder Loss:  0.03430078 Validation Decoder Loss:  0.3312025
Encoder Loss:  0.036445178  || Decoder Loss:  0.034282383 Validation Decoder Loss:  0.33121574
Model: siamese_net_lr_0.00029574456513503314 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33121574
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 128, 15, 19, 1)    15        
_________________________________________________________________
reshape_1 (Reshape)          (None, 1920, 19, 1)       0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 1920, 19, 1)       689       
=================================================================
Total params: 689
Trainable params: 689
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 19, 1)       689       
=================================================================
Total params: 689
Trainable params: 689
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11991493  || Decoder Loss:  0.06614332 Validation Decoder Loss:  0.36127323
Encoder Loss:  0.1197252  || Decoder Loss:  0.065924734 Validation Decoder Loss:  0.36140078
Encoder Loss:  0.11950207  || Decoder Loss:  0.06566807 Validation Decoder Loss:  0.36150342
Encoder Loss:  0.119268686  || Decoder Loss:  0.065400094 Validation Decoder Loss:  0.3615628
Encoder Loss:  0.11903339  || Decoder Loss:  0.06513061 Validation Decoder Loss:  0.36157987
Encoder Loss:  0.11879801  || Decoder Loss:  0.064861745 Validation Decoder Loss:  0.36156058
Encoder Loss:  0.118562266  || Decoder Loss:  0.06459342 Validation Decoder Loss:  0.361511
Encoder Loss:  0.11832538  || Decoder Loss:  0.064324915 Validation Decoder Loss:  0.36143565
Encoder Loss:  0.11808641  || Decoder Loss:  0.06405534 Validation Decoder Loss:  0.3613378
Encoder Loss:  0.117844224  || Decoder Loss:  0.06378369 Validation Decoder Loss:  0.36121893
Encoder Loss:  0.11759745  || Decoder Loss:  0.0635088 Validation Decoder Loss:  0.3610791
Encoder Loss:  0.117344424  || Decoder Loss:  0.06322923 Validation Decoder Loss:  0.3609171
Encoder Loss:  0.11708307  || Decoder Loss:  0.06294321 Validation Decoder Loss:  0.36073038
Encoder Loss:  0.11681043  || Decoder Loss:  0.06264831 Validation Decoder Loss:  0.36051512
Encoder Loss:  0.11652239  || Decoder Loss:  0.062341176 Validation Decoder Loss:  0.36026555
Encoder Loss:  0.11621273  || Decoder Loss:  0.062016748 Validation Decoder Loss:  0.359973
Encoder Loss:  0.115871534  || Decoder Loss:  0.06166712 Validation Decoder Loss:  0.3596236
Encoder Loss:  0.11548131  || Decoder Loss:  0.061278757 Validation Decoder Loss:  0.35919252
Encoder Loss:  0.11500787  || Decoder Loss:  0.06082606 Validation Decoder Loss:  0.35862887
Encoder Loss:  0.11437121  || Decoder Loss:  0.060252883 Validation Decoder Loss:  0.35780537
Encoder Loss:  0.113324724  || Decoder Loss:  0.059406046 Validation Decoder Loss:  0.35629576
Encoder Loss:  0.11056599  || Decoder Loss:  0.057694428 Validation Decoder Loss:  0.3518631
Encoder Loss:  0.12776273  || Decoder Loss:  0.10230884 Validation Decoder Loss:  1.2511888
Encoder Loss:  0.23305598  || Decoder Loss:  0.24557489 Validation Decoder Loss:  0.49908715
Encoder Loss:  0.09024565  || Decoder Loss:  0.08672639 Validation Decoder Loss:  0.50023836
Encoder Loss:  0.087405965  || Decoder Loss:  0.08328617 Validation Decoder Loss:  0.44136554
Encoder Loss:  0.07741885  || Decoder Loss:  0.072874956 Validation Decoder Loss:  0.42383167
Encoder Loss:  0.073040485  || Decoder Loss:  0.06833785 Validation Decoder Loss:  0.41279742
Encoder Loss:  0.07023386  || Decoder Loss:  0.065408975 Validation Decoder Loss:  0.4058949
Encoder Loss:  0.06837821  || Decoder Loss:  0.06343836 Validation Decoder Loss:  0.400535
Encoder Loss:  0.06677291  || Decoder Loss:  0.061727002 Validation Decoder Loss:  0.39348823
Encoder Loss:  0.06482237  || Decoder Loss:  0.05956932 Validation Decoder Loss:  0.39036715
Encoder Loss:  0.06414283  || Decoder Loss:  0.058826704 Validation Decoder Loss:  0.3844191
Encoder Loss:  0.06216594  || Decoder Loss:  0.05671019 Validation Decoder Loss:  0.38375813
Encoder Loss:  0.06185538  || Decoder Loss:  0.056279823 Validation Decoder Loss:  0.37726817
Encoder Loss:  0.05982156  || Decoder Loss:  0.05434374 Validation Decoder Loss:  0.3791467
Encoder Loss:  0.059797175  || Decoder Loss:  0.05395868 Validation Decoder Loss:  0.37397045
Encoder Loss:  0.05854769  || Decoder Loss:  0.052718587 Validation Decoder Loss:  0.37114453
Encoder Loss:  0.057434645  || Decoder Loss:  0.05163664 Validation Decoder Loss:  0.3706578
Encoder Loss:  0.056928225  || Decoder Loss:  0.050936274 Validation Decoder Loss:  0.3689486
Model: siamese_net_lr_0.0007350403977035338 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3689486
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 514, 5, 19, 1)     326       
_________________________________________________________________
reshape_2 (Reshape)          (None, 2570, 19, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2986861  || Decoder Loss:  0.038369045 Validation Decoder Loss:  0.31727904
Encoder Loss:  0.2301888  || Decoder Loss:  0.038528685 Validation Decoder Loss:  0.3303542
Encoder Loss:  0.07077071  || Decoder Loss:  0.035337362 Validation Decoder Loss:  0.3303547
Encoder Loss:  0.06944636  || Decoder Loss:  0.035332207 Validation Decoder Loss:  0.3304292
Encoder Loss:  0.06894136  || Decoder Loss:  0.035329103 Validation Decoder Loss:  0.33049864
Encoder Loss:  0.06814446  || Decoder Loss:  0.035327356 Validation Decoder Loss:  0.33056632
Encoder Loss:  0.04957443  || Decoder Loss:  0.035317875 Validation Decoder Loss:  0.33061492
Encoder Loss:  0.046739455  || Decoder Loss:  0.03528143 Validation Decoder Loss:  0.3306647
Encoder Loss:  0.046282362  || Decoder Loss:  0.035246912 Validation Decoder Loss:  0.3307255
Encoder Loss:  0.04624515  || Decoder Loss:  0.03523494 Validation Decoder Loss:  0.3307981
Encoder Loss:  0.046039004  || Decoder Loss:  0.035236657 Validation Decoder Loss:  0.330858
Encoder Loss:  0.04588929  || Decoder Loss:  0.035246506 Validation Decoder Loss:  0.33089757
Encoder Loss:  0.045830473  || Decoder Loss:  0.03526143 Validation Decoder Loss:  0.33090448
Encoder Loss:  0.045607038  || Decoder Loss:  0.035276946 Validation Decoder Loss:  0.3309037
Encoder Loss:  0.045522112  || Decoder Loss:  0.035290588 Validation Decoder Loss:  0.3308889
Encoder Loss:  0.04530878  || Decoder Loss:  0.035304848 Validation Decoder Loss:  0.3308727
Encoder Loss:  0.045309395  || Decoder Loss:  0.035308745 Validation Decoder Loss:  0.33084834
Encoder Loss:  0.04514909  || Decoder Loss:  0.035307754 Validation Decoder Loss:  0.33083418
Encoder Loss:  0.045154847  || Decoder Loss:  0.035302166 Validation Decoder Loss:  0.33082205
Encoder Loss:  0.045155197  || Decoder Loss:  0.035299033 Validation Decoder Loss:  0.33080825
Encoder Loss:  0.045151163  || Decoder Loss:  0.03529674 Validation Decoder Loss:  0.33078873
Encoder Loss:  0.04511193  || Decoder Loss:  0.035295304 Validation Decoder Loss:  0.33076775
Encoder Loss:  0.045126893  || Decoder Loss:  0.03529374 Validation Decoder Loss:  0.33074713
Encoder Loss:  0.045179702  || Decoder Loss:  0.035292868 Validation Decoder Loss:  0.3307309
Encoder Loss:  0.04510815  || Decoder Loss:  0.035292443 Validation Decoder Loss:  0.33071113
Encoder Loss:  0.04514469  || Decoder Loss:  0.03529109 Validation Decoder Loss:  0.3306926
Encoder Loss:  0.045120507  || Decoder Loss:  0.035291124 Validation Decoder Loss:  0.33068225
Encoder Loss:  0.04509075  || Decoder Loss:  0.035291225 Validation Decoder Loss:  0.3306681
Encoder Loss:  0.045105726  || Decoder Loss:  0.03528999 Validation Decoder Loss:  0.33065993
Encoder Loss:  0.045088816  || Decoder Loss:  0.035289083 Validation Decoder Loss:  0.33065218
Encoder Loss:  0.045149088  || Decoder Loss:  0.035289183 Validation Decoder Loss:  0.33064845
Encoder Loss:  0.045113627  || Decoder Loss:  0.035289332 Validation Decoder Loss:  0.3306427
Encoder Loss:  0.04507338  || Decoder Loss:  0.03528912 Validation Decoder Loss:  0.33063984
Encoder Loss:  0.045132738  || Decoder Loss:  0.03528753 Validation Decoder Loss:  0.33064452
Encoder Loss:  0.04513138  || Decoder Loss:  0.035284318 Validation Decoder Loss:  0.33064762
Encoder Loss:  0.045132656  || Decoder Loss:  0.03528236 Validation Decoder Loss:  0.33065844
Encoder Loss:  0.045122806  || Decoder Loss:  0.03528162 Validation Decoder Loss:  0.33066756
Encoder Loss:  0.04508621  || Decoder Loss:  0.03527892 Validation Decoder Loss:  0.3306778
Encoder Loss:  0.0450912  || Decoder Loss:  0.035276376 Validation Decoder Loss:  0.33069688
Encoder Loss:  0.04507748  || Decoder Loss:  0.035273183 Validation Decoder Loss:  0.33071777
Model: siamese_net_lr_0.0007908459907954653 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33071777
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 474, 5, 19, 1)     97        
_________________________________________________________________
reshape_3 (Reshape)          (None, 2370, 19, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42196196  || Decoder Loss:  0.04234052 Validation Decoder Loss:  0.35065195
Encoder Loss:  0.42180097  || Decoder Loss:  0.042364635 Validation Decoder Loss:  0.35072935
Encoder Loss:  0.4215762  || Decoder Loss:  0.0424188 Validation Decoder Loss:  0.3507886
Encoder Loss:  0.4212715  || Decoder Loss:  0.042520203 Validation Decoder Loss:  0.35086542
Encoder Loss:  0.42084244  || Decoder Loss:  0.04269489 Validation Decoder Loss:  0.35098517
Encoder Loss:  0.42019427  || Decoder Loss:  0.042993885 Validation Decoder Loss:  0.3511915
Encoder Loss:  0.41909015  || Decoder Loss:  0.043534156 Validation Decoder Loss:  0.35159987
Encoder Loss:  0.4167456  || Decoder Loss:  0.044651147 Validation Decoder Loss:  0.35260257
Encoder Loss:  0.40882927  || Decoder Loss:  0.04778332 Validation Decoder Loss:  0.3565619
Encoder Loss:  0.3141236  || Decoder Loss:  0.07173803 Validation Decoder Loss:  0.5610367
Encoder Loss:  0.14189285  || Decoder Loss:  0.118391864 Validation Decoder Loss:  0.36492983
Encoder Loss:  0.11857444  || Decoder Loss:  0.05745207 Validation Decoder Loss:  0.33380312
Encoder Loss:  0.1129751  || Decoder Loss:  0.043142892 Validation Decoder Loss:  0.32950586
Encoder Loss:  0.11048894  || Decoder Loss:  0.03916321 Validation Decoder Loss:  0.32961002
Encoder Loss:  0.10945964  || Decoder Loss:  0.03812444 Validation Decoder Loss:  0.32997292
Encoder Loss:  0.110013984  || Decoder Loss:  0.03780799 Validation Decoder Loss:  0.33009985
Encoder Loss:  0.10932493  || Decoder Loss:  0.037610065 Validation Decoder Loss:  0.33007795
Encoder Loss:  0.108313896  || Decoder Loss:  0.03743615 Validation Decoder Loss:  0.33003837
Encoder Loss:  0.1069828  || Decoder Loss:  0.03727567 Validation Decoder Loss:  0.32998317
Encoder Loss:  0.10687466  || Decoder Loss:  0.037136957 Validation Decoder Loss:  0.32994
Encoder Loss:  0.106203824  || Decoder Loss:  0.037010156 Validation Decoder Loss:  0.32988828
Encoder Loss:  0.105829455  || Decoder Loss:  0.03689553 Validation Decoder Loss:  0.32983452
Encoder Loss:  0.10604146  || Decoder Loss:  0.03678334 Validation Decoder Loss:  0.32979208
Encoder Loss:  0.10520348  || Decoder Loss:  0.03667669 Validation Decoder Loss:  0.3297388
Encoder Loss:  0.10472196  || Decoder Loss:  0.03658117 Validation Decoder Loss:  0.32968384
Encoder Loss:  0.10469027  || Decoder Loss:  0.03648709 Validation Decoder Loss:  0.32964012
Encoder Loss:  0.10331354  || Decoder Loss:  0.03639716 Validation Decoder Loss:  0.32958865
Encoder Loss:  0.10147686  || Decoder Loss:  0.03631016 Validation Decoder Loss:  0.329547
Encoder Loss:  0.07158817  || Decoder Loss:  0.036219135 Validation Decoder Loss:  0.32973796
Encoder Loss:  0.05914105  || Decoder Loss:  0.03610924 Validation Decoder Loss:  0.32957685
Encoder Loss:  0.056921266  || Decoder Loss:  0.036090128 Validation Decoder Loss:  0.32949102
Encoder Loss:  0.055519532  || Decoder Loss:  0.0360392 Validation Decoder Loss:  0.3294341
Encoder Loss:  0.05498133  || Decoder Loss:  0.03598213 Validation Decoder Loss:  0.3293889
Encoder Loss:  0.05460176  || Decoder Loss:  0.035925206 Validation Decoder Loss:  0.32934433
Encoder Loss:  0.054196823  || Decoder Loss:  0.03587125 Validation Decoder Loss:  0.3292978
Encoder Loss:  0.053816013  || Decoder Loss:  0.035820886 Validation Decoder Loss:  0.3292519
Encoder Loss:  0.053518888  || Decoder Loss:  0.035771035 Validation Decoder Loss:  0.32921803
Encoder Loss:  0.05343112  || Decoder Loss:  0.03571937 Validation Decoder Loss:  0.32919744
Encoder Loss:  0.053384334  || Decoder Loss:  0.03566812 Validation Decoder Loss:  0.32918477
Encoder Loss:  0.05332604  || Decoder Loss:  0.0356195 Validation Decoder Loss:  0.329178
Model: siamese_net_lr_0.0009167177458938878 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32917798
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 414, 5, 19, 1)     226       
_________________________________________________________________
reshape_4 (Reshape)          (None, 2070, 19, 1)       0         
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37216064  || Decoder Loss:  0.0635942 Validation Decoder Loss:  0.3602938
Encoder Loss:  0.37119862  || Decoder Loss:  0.06442347 Validation Decoder Loss:  0.36035737
Encoder Loss:  0.36969525  || Decoder Loss:  0.06593995 Validation Decoder Loss:  0.3600625
Encoder Loss:  0.36706924  || Decoder Loss:  0.06867201 Validation Decoder Loss:  0.35977143
Encoder Loss:  0.36165532  || Decoder Loss:  0.07403907 Validation Decoder Loss:  0.36062062
Encoder Loss:  0.3462278  || Decoder Loss:  0.08771808 Validation Decoder Loss:  0.37149987
Encoder Loss:  0.25378716  || Decoder Loss:  0.17963228 Validation Decoder Loss:  0.8515177
Encoder Loss:  0.12409642  || Decoder Loss:  0.2346973 Validation Decoder Loss:  0.58050215
Encoder Loss:  0.10241452  || Decoder Loss:  0.14019771 Validation Decoder Loss:  0.48991895
Encoder Loss:  0.0940843  || Decoder Loss:  0.09726338 Validation Decoder Loss:  0.42159534
Encoder Loss:  0.08848493  || Decoder Loss:  0.06922313 Validation Decoder Loss:  0.38297573
Encoder Loss:  0.08532145  || Decoder Loss:  0.053972647 Validation Decoder Loss:  0.3636235
Encoder Loss:  0.08367445  || Decoder Loss:  0.046150956 Validation Decoder Loss:  0.35300857
Encoder Loss:  0.082636826  || Decoder Loss:  0.041820988 Validation Decoder Loss:  0.34658933
Encoder Loss:  0.08162024  || Decoder Loss:  0.039117068 Validation Decoder Loss:  0.34239137
Encoder Loss:  0.078865394  || Decoder Loss:  0.03731806 Validation Decoder Loss:  0.33940557
Encoder Loss:  0.051592883  || Decoder Loss:  0.035832144 Validation Decoder Loss:  0.3363157
Encoder Loss:  0.04941085  || Decoder Loss:  0.035055276 Validation Decoder Loss:  0.3352726
Encoder Loss:  0.04927523  || Decoder Loss:  0.0346462 Validation Decoder Loss:  0.33453134
Encoder Loss:  0.04915077  || Decoder Loss:  0.03437854 Validation Decoder Loss:  0.33397844
Encoder Loss:  0.048991375  || Decoder Loss:  0.034206495 Validation Decoder Loss:  0.333556
Encoder Loss:  0.04889715  || Decoder Loss:  0.034098748 Validation Decoder Loss:  0.33323425
Encoder Loss:  0.04880953  || Decoder Loss:  0.03403235 Validation Decoder Loss:  0.33299315
Encoder Loss:  0.04873616  || Decoder Loss:  0.033992503 Validation Decoder Loss:  0.3328055
Encoder Loss:  0.048667487  || Decoder Loss:  0.03396848 Validation Decoder Loss:  0.33266258
Encoder Loss:  0.04858807  || Decoder Loss:  0.033952538 Validation Decoder Loss:  0.33255172
Encoder Loss:  0.04852698  || Decoder Loss:  0.033939604 Validation Decoder Loss:  0.33247378
Encoder Loss:  0.048449803  || Decoder Loss:  0.033926204 Validation Decoder Loss:  0.33241785
Encoder Loss:  0.048398625  || Decoder Loss:  0.033911437 Validation Decoder Loss:  0.33238325
Encoder Loss:  0.048329387  || Decoder Loss:  0.03389216 Validation Decoder Loss:  0.33236524
Encoder Loss:  0.04822978  || Decoder Loss:  0.033866838 Validation Decoder Loss:  0.33236003
Encoder Loss:  0.048157115  || Decoder Loss:  0.03383544 Validation Decoder Loss:  0.33236587
Encoder Loss:  0.048094198  || Decoder Loss:  0.03379742 Validation Decoder Loss:  0.3323815
Encoder Loss:  0.047982473  || Decoder Loss:  0.033752862 Validation Decoder Loss:  0.3323981
Encoder Loss:  0.047891498  || Decoder Loss:  0.033703286 Validation Decoder Loss:  0.33242124
Encoder Loss:  0.047836717  || Decoder Loss:  0.033649508 Validation Decoder Loss:  0.3324498
Encoder Loss:  0.04775505  || Decoder Loss:  0.03359408 Validation Decoder Loss:  0.33248377
Encoder Loss:  0.04769712  || Decoder Loss:  0.033536915 Validation Decoder Loss:  0.33251846
Encoder Loss:  0.047631726  || Decoder Loss:  0.033481304 Validation Decoder Loss:  0.33255357
Encoder Loss:  0.047604304  || Decoder Loss:  0.03342881 Validation Decoder Loss:  0.33258575
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.00042427125451068015 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33258575
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 474, 5, 19, 1)     223       
_________________________________________________________________
reshape_5 (Reshape)          (None, 2370, 19, 1)       0         
=================================================================
Total params: 223
Trainable params: 223
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44648388  || Decoder Loss:  0.044640347 Validation Decoder Loss:  0.34582108
Encoder Loss:  0.4458698  || Decoder Loss:  0.04506887 Validation Decoder Loss:  0.3455734
Encoder Loss:  0.4449885  || Decoder Loss:  0.04568584 Validation Decoder Loss:  0.34524286
Encoder Loss:  0.44374764  || Decoder Loss:  0.046555024 Validation Decoder Loss:  0.34488386
Encoder Loss:  0.44192243  || Decoder Loss:  0.047823474 Validation Decoder Loss:  0.3445723
Encoder Loss:  0.4390508  || Decoder Loss:  0.04978148 Validation Decoder Loss:  0.34448552
Encoder Loss:  0.4340595  || Decoder Loss:  0.053065438 Validation Decoder Loss:  0.34512544
Encoder Loss:  0.4239391  || Decoder Loss:  0.05929558 Validation Decoder Loss:  0.34818423
Encoder Loss:  0.39742616  || Decoder Loss:  0.073372625 Validation Decoder Loss:  0.36099607
Encoder Loss:  0.2879394  || Decoder Loss:  0.10652037 Validation Decoder Loss:  0.37651917
Encoder Loss:  0.10267868  || Decoder Loss:  0.06787309 Validation Decoder Loss:  0.34963983
Encoder Loss:  0.10156217  || Decoder Loss:  0.042153984 Validation Decoder Loss:  0.33501315
Encoder Loss:  0.10352045  || Decoder Loss:  0.03983761 Validation Decoder Loss:  0.33527124
Encoder Loss:  0.10227377  || Decoder Loss:  0.03867576 Validation Decoder Loss:  0.3358326
Encoder Loss:  0.100967996  || Decoder Loss:  0.03801148 Validation Decoder Loss:  0.33518502
Encoder Loss:  0.10078301  || Decoder Loss:  0.03754475 Validation Decoder Loss:  0.3348844
Encoder Loss:  0.10026714  || Decoder Loss:  0.037168473 Validation Decoder Loss:  0.33443737
Encoder Loss:  0.09988143  || Decoder Loss:  0.036861833 Validation Decoder Loss:  0.33398774
Encoder Loss:  0.099534415  || Decoder Loss:  0.036600567 Validation Decoder Loss:  0.33356708
Encoder Loss:  0.09932158  || Decoder Loss:  0.036379173 Validation Decoder Loss:  0.33316535
Encoder Loss:  0.09893534  || Decoder Loss:  0.036182936 Validation Decoder Loss:  0.3328027
Encoder Loss:  0.09830885  || Decoder Loss:  0.036019187 Validation Decoder Loss:  0.33247298
Encoder Loss:  0.09763672  || Decoder Loss:  0.03586774 Validation Decoder Loss:  0.3321813
Encoder Loss:  0.09407893  || Decoder Loss:  0.03574486 Validation Decoder Loss:  0.33192244
Encoder Loss:  0.062868394  || Decoder Loss:  0.035644893 Validation Decoder Loss:  0.33158863
Encoder Loss:  0.05735627  || Decoder Loss:  0.035473205 Validation Decoder Loss:  0.33135653
Encoder Loss:  0.056931023  || Decoder Loss:  0.035364375 Validation Decoder Loss:  0.33115608
Encoder Loss:  0.05598225  || Decoder Loss:  0.03527276 Validation Decoder Loss:  0.33096063
Encoder Loss:  0.05527409  || Decoder Loss:  0.035181645 Validation Decoder Loss:  0.3307724
Encoder Loss:  0.054698735  || Decoder Loss:  0.035093546 Validation Decoder Loss:  0.33059
Encoder Loss:  0.05418874  || Decoder Loss:  0.03501344 Validation Decoder Loss:  0.33042157
Encoder Loss:  0.054052815  || Decoder Loss:  0.03494464 Validation Decoder Loss:  0.33027297
Encoder Loss:  0.053887162  || Decoder Loss:  0.034889057 Validation Decoder Loss:  0.33015364
Encoder Loss:  0.053790044  || Decoder Loss:  0.03484872 Validation Decoder Loss:  0.33005512
Encoder Loss:  0.05366438  || Decoder Loss:  0.034821976 Validation Decoder Loss:  0.32998556
Encoder Loss:  0.053637132  || Decoder Loss:  0.034794915 Validation Decoder Loss:  0.3299082
Encoder Loss:  0.053475603  || Decoder Loss:  0.03477101 Validation Decoder Loss:  0.32985318
Encoder Loss:  0.053569123  || Decoder Loss:  0.034752 Validation Decoder Loss:  0.32980096
Encoder Loss:  0.05332739  || Decoder Loss:  0.03474075 Validation Decoder Loss:  0.329769
Encoder Loss:  0.05354829  || Decoder Loss:  0.034725662 Validation Decoder Loss:  0.32973206
Model: siamese_net_lr_0.0009986560433385455 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32973206
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 514, 5, 19, 1)     74        
_________________________________________________________________
reshape_6 (Reshape)          (None, 2570, 19, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06490031  || Decoder Loss:  0.035870336 Validation Decoder Loss:  0.33307368
Encoder Loss:  0.041001007  || Decoder Loss:  0.03547986 Validation Decoder Loss:  0.33193094
Encoder Loss:  0.036581222  || Decoder Loss:  0.035333987 Validation Decoder Loss:  0.33192354
Encoder Loss:  0.036528267  || Decoder Loss:  0.03531288 Validation Decoder Loss:  0.33192047
Encoder Loss:  0.03649137  || Decoder Loss:  0.035304096 Validation Decoder Loss:  0.3319254
Encoder Loss:  0.03647938  || Decoder Loss:  0.035298318 Validation Decoder Loss:  0.3319307
Encoder Loss:  0.036488548  || Decoder Loss:  0.03529384 Validation Decoder Loss:  0.33193463
Encoder Loss:  0.03648169  || Decoder Loss:  0.03528908 Validation Decoder Loss:  0.33194017
Encoder Loss:  0.036473207  || Decoder Loss:  0.035285324 Validation Decoder Loss:  0.33194995
Encoder Loss:  0.036475696  || Decoder Loss:  0.03528099 Validation Decoder Loss:  0.33195257
Encoder Loss:  0.036471013  || Decoder Loss:  0.035278205 Validation Decoder Loss:  0.33196297
Encoder Loss:  0.036458768  || Decoder Loss:  0.035276044 Validation Decoder Loss:  0.33196914
Encoder Loss:  0.036467046  || Decoder Loss:  0.035272986 Validation Decoder Loss:  0.33197743
Encoder Loss:  0.03644316  || Decoder Loss:  0.035271015 Validation Decoder Loss:  0.33197963
Encoder Loss:  0.036452837  || Decoder Loss:  0.035268653 Validation Decoder Loss:  0.33198398
Encoder Loss:  0.036451384  || Decoder Loss:  0.035266697 Validation Decoder Loss:  0.33199644
Encoder Loss:  0.036450993  || Decoder Loss:  0.03526451 Validation Decoder Loss:  0.33199447
Encoder Loss:  0.036454745  || Decoder Loss:  0.03526309 Validation Decoder Loss:  0.33199978
Encoder Loss:  0.036439143  || Decoder Loss:  0.035262357 Validation Decoder Loss:  0.3320155
Encoder Loss:  0.036435753  || Decoder Loss:  0.03525899 Validation Decoder Loss:  0.33202082
Encoder Loss:  0.03643205  || Decoder Loss:  0.035259075 Validation Decoder Loss:  0.33202538
Encoder Loss:  0.036434006  || Decoder Loss:  0.03525637 Validation Decoder Loss:  0.33203515
Encoder Loss:  0.036459323  || Decoder Loss:  0.03525766 Validation Decoder Loss:  0.33203334
Encoder Loss:  0.036445275  || Decoder Loss:  0.035255104 Validation Decoder Loss:  0.3320475
Encoder Loss:  0.036421813  || Decoder Loss:  0.035254944 Validation Decoder Loss:  0.332054
Encoder Loss:  0.036426444  || Decoder Loss:  0.03525447 Validation Decoder Loss:  0.33205402
Encoder Loss:  0.03643578  || Decoder Loss:  0.03525327 Validation Decoder Loss:  0.3320665
Encoder Loss:  0.036446024  || Decoder Loss:  0.03525439 Validation Decoder Loss:  0.33206564
Encoder Loss:  0.036439024  || Decoder Loss:  0.035252623 Validation Decoder Loss:  0.3320728
Encoder Loss:  0.03642998  || Decoder Loss:  0.03525157 Validation Decoder Loss:  0.3320731
Encoder Loss:  0.0364274  || Decoder Loss:  0.035251666 Validation Decoder Loss:  0.33207557
Encoder Loss:  0.036421582  || Decoder Loss:  0.035252493 Validation Decoder Loss:  0.33207035
Encoder Loss:  0.036436424  || Decoder Loss:  0.035253156 Validation Decoder Loss:  0.3320725
Encoder Loss:  0.036446605  || Decoder Loss:  0.035254188 Validation Decoder Loss:  0.3320748
Encoder Loss:  0.036435336  || Decoder Loss:  0.03525421 Validation Decoder Loss:  0.33207187
Encoder Loss:  0.036437657  || Decoder Loss:  0.035255276 Validation Decoder Loss:  0.33207726
Encoder Loss:  0.03643419  || Decoder Loss:  0.035255183 Validation Decoder Loss:  0.33207503
Encoder Loss:  0.03643706  || Decoder Loss:  0.035255086 Validation Decoder Loss:  0.33208066
Encoder Loss:  0.036420494  || Decoder Loss:  0.035256207 Validation Decoder Loss:  0.3320782
Encoder Loss:  0.03641639  || Decoder Loss:  0.03525667 Validation Decoder Loss:  0.33208314
Model: siamese_net_lr_0.0009360959198384187 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33208314
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 121, 20, 19, 1)    233       
_________________________________________________________________
reshape_7 (Reshape)          (None, 2420, 19, 1)       0         
=================================================================
Total params: 233
Trainable params: 233
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4096828  || Decoder Loss:  0.042369843 Validation Decoder Loss:  0.33856195
Encoder Loss:  0.4064665  || Decoder Loss:  0.04478004 Validation Decoder Loss:  0.3368798
Encoder Loss:  0.3937574  || Decoder Loss:  0.05365951 Validation Decoder Loss:  0.34053686
Encoder Loss:  0.21249901  || Decoder Loss:  0.052402887 Validation Decoder Loss:  0.3327048
Encoder Loss:  0.09142841  || Decoder Loss:  0.03781045 Validation Decoder Loss:  0.33176172
Encoder Loss:  0.09050059  || Decoder Loss:  0.03665382 Validation Decoder Loss:  0.33090144
Encoder Loss:  0.089677304  || Decoder Loss:  0.03601444 Validation Decoder Loss:  0.33042905
Encoder Loss:  0.089175336  || Decoder Loss:  0.035641346 Validation Decoder Loss:  0.33016548
Encoder Loss:  0.08647509  || Decoder Loss:  0.035418645 Validation Decoder Loss:  0.32999164
Encoder Loss:  0.057005744  || Decoder Loss:  0.035268575 Validation Decoder Loss:  0.3301102
Encoder Loss:  0.054432865  || Decoder Loss:  0.035199754 Validation Decoder Loss:  0.33005401
Encoder Loss:  0.05411826  || Decoder Loss:  0.035128046 Validation Decoder Loss:  0.33007407
Encoder Loss:  0.05391829  || Decoder Loss:  0.035084963 Validation Decoder Loss:  0.3300735
Encoder Loss:  0.05369932  || Decoder Loss:  0.03505938 Validation Decoder Loss:  0.33009613
Encoder Loss:  0.05354244  || Decoder Loss:  0.035041537 Validation Decoder Loss:  0.33014077
Encoder Loss:  0.05334824  || Decoder Loss:  0.035026103 Validation Decoder Loss:  0.33020395
Encoder Loss:  0.053148627  || Decoder Loss:  0.035006728 Validation Decoder Loss:  0.33028913
Encoder Loss:  0.052999593  || Decoder Loss:  0.034983817 Validation Decoder Loss:  0.3303942
Encoder Loss:  0.052804183  || Decoder Loss:  0.03495614 Validation Decoder Loss:  0.33051786
Encoder Loss:  0.05249025  || Decoder Loss:  0.03492256 Validation Decoder Loss:  0.3306651
Encoder Loss:  0.052303843  || Decoder Loss:  0.034882072 Validation Decoder Loss:  0.3308074
Encoder Loss:  0.052095946  || Decoder Loss:  0.03483957 Validation Decoder Loss:  0.33096305
Encoder Loss:  0.051984664  || Decoder Loss:  0.034793463 Validation Decoder Loss:  0.33109733
Encoder Loss:  0.051748514  || Decoder Loss:  0.034739867 Validation Decoder Loss:  0.33123937
Encoder Loss:  0.05164896  || Decoder Loss:  0.03468535 Validation Decoder Loss:  0.33137053
Encoder Loss:  0.051327568  || Decoder Loss:  0.03462596 Validation Decoder Loss:  0.33151704
Encoder Loss:  0.051241416  || Decoder Loss:  0.03456895 Validation Decoder Loss:  0.33165318
Encoder Loss:  0.051107753  || Decoder Loss:  0.034511413 Validation Decoder Loss:  0.33178818
Encoder Loss:  0.050829314  || Decoder Loss:  0.03445836 Validation Decoder Loss:  0.33192345
Encoder Loss:  0.050912835  || Decoder Loss:  0.03441174 Validation Decoder Loss:  0.3320381
Encoder Loss:  0.050634455  || Decoder Loss:  0.03436752 Validation Decoder Loss:  0.3321507
Encoder Loss:  0.050443545  || Decoder Loss:  0.03432623 Validation Decoder Loss:  0.33227038
Encoder Loss:  0.050392102  || Decoder Loss:  0.034284215 Validation Decoder Loss:  0.33238187
Encoder Loss:  0.050451446  || Decoder Loss:  0.0342444 Validation Decoder Loss:  0.33248985
Encoder Loss:  0.050339695  || Decoder Loss:  0.034202263 Validation Decoder Loss:  0.33259398
Encoder Loss:  0.050115064  || Decoder Loss:  0.03416375 Validation Decoder Loss:  0.33269355
Encoder Loss:  0.050227698  || Decoder Loss:  0.03414583 Validation Decoder Loss:  0.33277828
Encoder Loss:  0.05008705  || Decoder Loss:  0.034120914 Validation Decoder Loss:  0.33285868
Encoder Loss:  0.050059773  || Decoder Loss:  0.034102824 Validation Decoder Loss:  0.33291924
Encoder Loss:  0.05010067  || Decoder Loss:  0.03409078 Validation Decoder Loss:  0.33295956
Model: siamese_net_lr_0.0008077428089452408 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33295956
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 220, 11, 19, 1)    283       
_________________________________________________________________
reshape_8 (Reshape)          (None, 2420, 19, 1)       0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06971941  || Decoder Loss:  0.043820783 Validation Decoder Loss:  0.3374728
Encoder Loss:  0.07696016  || Decoder Loss:  0.05454571 Validation Decoder Loss:  0.33779714
Encoder Loss:  0.042628817  || Decoder Loss:  0.03901121 Validation Decoder Loss:  0.3305217
Encoder Loss:  0.038845893  || Decoder Loss:  0.036092438 Validation Decoder Loss:  0.32973427
Encoder Loss:  0.03825361  || Decoder Loss:  0.03551429 Validation Decoder Loss:  0.32947627
Encoder Loss:  0.038004316  || Decoder Loss:  0.03528815 Validation Decoder Loss:  0.32934391
Encoder Loss:  0.037862614  || Decoder Loss:  0.03518134 Validation Decoder Loss:  0.32923183
Encoder Loss:  0.03775689  || Decoder Loss:  0.035115764 Validation Decoder Loss:  0.32912785
Encoder Loss:  0.037640944  || Decoder Loss:  0.03506628 Validation Decoder Loss:  0.32903945
Encoder Loss:  0.03671879  || Decoder Loss:  0.035025943 Validation Decoder Loss:  0.32899714
Encoder Loss:  0.036232807  || Decoder Loss:  0.035011243 Validation Decoder Loss:  0.32895884
Encoder Loss:  0.036216754  || Decoder Loss:  0.03501074 Validation Decoder Loss:  0.3289976
Encoder Loss:  0.03620837  || Decoder Loss:  0.035016645 Validation Decoder Loss:  0.32909358
Encoder Loss:  0.036208212  || Decoder Loss:  0.03502803 Validation Decoder Loss:  0.3292174
Encoder Loss:  0.036209725  || Decoder Loss:  0.035041697 Validation Decoder Loss:  0.32936433
Encoder Loss:  0.03621048  || Decoder Loss:  0.035052493 Validation Decoder Loss:  0.3295267
Encoder Loss:  0.0362041  || Decoder Loss:  0.035056375 Validation Decoder Loss:  0.32969388
Encoder Loss:  0.03619186  || Decoder Loss:  0.035051707 Validation Decoder Loss:  0.3298466
Encoder Loss:  0.036164403  || Decoder Loss:  0.03503604 Validation Decoder Loss:  0.33000562
Encoder Loss:  0.036132313  || Decoder Loss:  0.035006188 Validation Decoder Loss:  0.3300684
Encoder Loss:  0.03608273  || Decoder Loss:  0.03496582 Validation Decoder Loss:  0.3300839
Encoder Loss:  0.036025908  || Decoder Loss:  0.03491638 Validation Decoder Loss:  0.3300413
Encoder Loss:  0.03595762  || Decoder Loss:  0.034860402 Validation Decoder Loss:  0.3299797
Encoder Loss:  0.03589548  || Decoder Loss:  0.03480439 Validation Decoder Loss:  0.3298043
Encoder Loss:  0.03583423  || Decoder Loss:  0.03475375 Validation Decoder Loss:  0.32962805
Encoder Loss:  0.035775997  || Decoder Loss:  0.034708384 Validation Decoder Loss:  0.3294985
Encoder Loss:  0.03573079  || Decoder Loss:  0.034671787 Validation Decoder Loss:  0.3292826
Encoder Loss:  0.035695292  || Decoder Loss:  0.03464675 Validation Decoder Loss:  0.32905924
Encoder Loss:  0.035672735  || Decoder Loss:  0.034634057 Validation Decoder Loss:  0.32892895
Encoder Loss:  0.03566699  || Decoder Loss:  0.03463514 Validation Decoder Loss:  0.32885188
Encoder Loss:  0.035675835  || Decoder Loss:  0.034646843 Validation Decoder Loss:  0.3287893
Encoder Loss:  0.035688218  || Decoder Loss:  0.034662396 Validation Decoder Loss:  0.3287817
Encoder Loss:  0.03570313  || Decoder Loss:  0.03468089 Validation Decoder Loss:  0.32878253
Encoder Loss:  0.03572056  || Decoder Loss:  0.034699827 Validation Decoder Loss:  0.32877624
Encoder Loss:  0.035738338  || Decoder Loss:  0.034718424 Validation Decoder Loss:  0.32871938
Encoder Loss:  0.035752922  || Decoder Loss:  0.034736373 Validation Decoder Loss:  0.3287676
Encoder Loss:  0.03576649  || Decoder Loss:  0.034752842 Validation Decoder Loss:  0.32886574
Encoder Loss:  0.03578123  || Decoder Loss:  0.034770098 Validation Decoder Loss:  0.32888418
Encoder Loss:  0.035794545  || Decoder Loss:  0.034785178 Validation Decoder Loss:  0.32891494
Encoder Loss:  0.035807874  || Decoder Loss:  0.034800578 Validation Decoder Loss:  0.3289121
Model: siamese_net_lr_0.00033560767274479393 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32891214
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 242, 10, 19, 1)    359       
_________________________________________________________________
reshape_9 (Reshape)          (None, 2420, 19, 1)       0         
=================================================================
Total params: 359
Trainable params: 359
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33930787  || Decoder Loss:  0.05003946 Validation Decoder Loss:  0.33374327
Encoder Loss:  0.08475835  || Decoder Loss:  0.03660535 Validation Decoder Loss:  0.33102438
Encoder Loss:  0.055993035  || Decoder Loss:  0.035465658 Validation Decoder Loss:  0.33067632
Encoder Loss:  0.05461199  || Decoder Loss:  0.03516554 Validation Decoder Loss:  0.33068594
Encoder Loss:  0.053801488  || Decoder Loss:  0.035113126 Validation Decoder Loss:  0.33095372
Encoder Loss:  0.053144798  || Decoder Loss:  0.035078358 Validation Decoder Loss:  0.33137506
Encoder Loss:  0.052350655  || Decoder Loss:  0.034969337 Validation Decoder Loss:  0.3315316
Encoder Loss:  0.051740292  || Decoder Loss:  0.03480732 Validation Decoder Loss:  0.33140877
Encoder Loss:  0.051363412  || Decoder Loss:  0.034663267 Validation Decoder Loss:  0.33128464
Encoder Loss:  0.05109201  || Decoder Loss:  0.034552407 Validation Decoder Loss:  0.33123857
Encoder Loss:  0.050910197  || Decoder Loss:  0.034504194 Validation Decoder Loss:  0.3312617
Encoder Loss:  0.0508157  || Decoder Loss:  0.034497514 Validation Decoder Loss:  0.33129314
Encoder Loss:  0.050789498  || Decoder Loss:  0.03451814 Validation Decoder Loss:  0.33131677
Encoder Loss:  0.050745897  || Decoder Loss:  0.034552015 Validation Decoder Loss:  0.3313615
Encoder Loss:  0.05067638  || Decoder Loss:  0.034597985 Validation Decoder Loss:  0.3313977
Encoder Loss:  0.050698385  || Decoder Loss:  0.03464297 Validation Decoder Loss:  0.33142257
Encoder Loss:  0.050664224  || Decoder Loss:  0.034690112 Validation Decoder Loss:  0.33147636
Encoder Loss:  0.050671145  || Decoder Loss:  0.03472425 Validation Decoder Loss:  0.33154374
Encoder Loss:  0.050589036  || Decoder Loss:  0.034749288 Validation Decoder Loss:  0.33157918
Encoder Loss:  0.05052906  || Decoder Loss:  0.034783572 Validation Decoder Loss:  0.33164784
Encoder Loss:  0.050481033  || Decoder Loss:  0.034810577 Validation Decoder Loss:  0.33171016
Encoder Loss:  0.050584197  || Decoder Loss:  0.03483706 Validation Decoder Loss:  0.3317184
Encoder Loss:  0.050500166  || Decoder Loss:  0.034864485 Validation Decoder Loss:  0.33177558
Encoder Loss:  0.050581086  || Decoder Loss:  0.034878135 Validation Decoder Loss:  0.33178955
Encoder Loss:  0.050468773  || Decoder Loss:  0.034890197 Validation Decoder Loss:  0.33188948
Encoder Loss:  0.050501585  || Decoder Loss:  0.034894094 Validation Decoder Loss:  0.3319466
Encoder Loss:  0.05055083  || Decoder Loss:  0.034910005 Validation Decoder Loss:  0.33192977
Encoder Loss:  0.050412927  || Decoder Loss:  0.034920726 Validation Decoder Loss:  0.33198178
Encoder Loss:  0.050508786  || Decoder Loss:  0.034926273 Validation Decoder Loss:  0.3319932
Encoder Loss:  0.050432965  || Decoder Loss:  0.03493247 Validation Decoder Loss:  0.3320215
Encoder Loss:  0.05048178  || Decoder Loss:  0.03493571 Validation Decoder Loss:  0.3320289
Encoder Loss:  0.050529033  || Decoder Loss:  0.03494311 Validation Decoder Loss:  0.33206022
Encoder Loss:  0.05055376  || Decoder Loss:  0.034944057 Validation Decoder Loss:  0.3321049
Encoder Loss:  0.050443765  || Decoder Loss:  0.034946855 Validation Decoder Loss:  0.33212173
Encoder Loss:  0.05044506  || Decoder Loss:  0.034954034 Validation Decoder Loss:  0.33211076
Encoder Loss:  0.050526686  || Decoder Loss:  0.03495775 Validation Decoder Loss:  0.33211598
Encoder Loss:  0.050498463  || Decoder Loss:  0.034958955 Validation Decoder Loss:  0.33214608
Encoder Loss:  0.050507437  || Decoder Loss:  0.034957934 Validation Decoder Loss:  0.33213362
Encoder Loss:  0.05046098  || Decoder Loss:  0.034961566 Validation Decoder Loss:  0.3321815
Encoder Loss:  0.050512515  || Decoder Loss:  0.034963902 Validation Decoder Loss:  0.332204
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.332204
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 90, 23, 19, 1)     190       
_________________________________________________________________
reshape_10 (Reshape)         (None, 2070, 19, 1)       0         
=================================================================
Total params: 190
Trainable params: 190
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30174702  || Decoder Loss:  0.10615492 Validation Decoder Loss:  0.4761594
Encoder Loss:  0.08307  || Decoder Loss:  0.048004106 Validation Decoder Loss:  0.33425176
Encoder Loss:  0.057468437  || Decoder Loss:  0.03435144 Validation Decoder Loss:  0.33135036
Encoder Loss:  0.050897688  || Decoder Loss:  0.03387904 Validation Decoder Loss:  0.33128116
Encoder Loss:  0.050517697  || Decoder Loss:  0.03379028 Validation Decoder Loss:  0.33134812
Encoder Loss:  0.05018132  || Decoder Loss:  0.03373371 Validation Decoder Loss:  0.33140558
Encoder Loss:  0.04983503  || Decoder Loss:  0.03365982 Validation Decoder Loss:  0.33137935
Encoder Loss:  0.049420983  || Decoder Loss:  0.03353694 Validation Decoder Loss:  0.33133018
Encoder Loss:  0.04895709  || Decoder Loss:  0.033387702 Validation Decoder Loss:  0.33133936
Encoder Loss:  0.048549104  || Decoder Loss:  0.033255886 Validation Decoder Loss:  0.33140385
Encoder Loss:  0.04848011  || Decoder Loss:  0.033163425 Validation Decoder Loss:  0.33147395
Encoder Loss:  0.04840589  || Decoder Loss:  0.033114623 Validation Decoder Loss:  0.33150867
Encoder Loss:  0.048426986  || Decoder Loss:  0.033101257 Validation Decoder Loss:  0.33155075
Encoder Loss:  0.048329543  || Decoder Loss:  0.033097006 Validation Decoder Loss:  0.33159187
Encoder Loss:  0.048336815  || Decoder Loss:  0.033109117 Validation Decoder Loss:  0.33162743
Encoder Loss:  0.048322573  || Decoder Loss:  0.03311935 Validation Decoder Loss:  0.33164376
Encoder Loss:  0.048269276  || Decoder Loss:  0.03313163 Validation Decoder Loss:  0.33168274
Encoder Loss:  0.048325136  || Decoder Loss:  0.03315846 Validation Decoder Loss:  0.3316963
Encoder Loss:  0.04825422  || Decoder Loss:  0.033183083 Validation Decoder Loss:  0.33173662
Encoder Loss:  0.048305985  || Decoder Loss:  0.03320989 Validation Decoder Loss:  0.33176154
Encoder Loss:  0.048346635  || Decoder Loss:  0.033234462 Validation Decoder Loss:  0.33178896
Encoder Loss:  0.048318706  || Decoder Loss:  0.033248913 Validation Decoder Loss:  0.3317992
Encoder Loss:  0.04830174  || Decoder Loss:  0.033263214 Validation Decoder Loss:  0.33184576
Encoder Loss:  0.048286784  || Decoder Loss:  0.03328135 Validation Decoder Loss:  0.33185437
Encoder Loss:  0.04829633  || Decoder Loss:  0.03330394 Validation Decoder Loss:  0.3318977
Encoder Loss:  0.048339058  || Decoder Loss:  0.033323355 Validation Decoder Loss:  0.33194348
Encoder Loss:  0.04826605  || Decoder Loss:  0.033339433 Validation Decoder Loss:  0.33197138
Encoder Loss:  0.048224453  || Decoder Loss:  0.03335311 Validation Decoder Loss:  0.33198667
Encoder Loss:  0.048208546  || Decoder Loss:  0.033367444 Validation Decoder Loss:  0.33202904
Encoder Loss:  0.04823712  || Decoder Loss:  0.033386447 Validation Decoder Loss:  0.3320618
Encoder Loss:  0.04819899  || Decoder Loss:  0.03339765 Validation Decoder Loss:  0.3321042
Encoder Loss:  0.048252713  || Decoder Loss:  0.033414114 Validation Decoder Loss:  0.3321425
Encoder Loss:  0.048194874  || Decoder Loss:  0.033420917 Validation Decoder Loss:  0.33216918
Encoder Loss:  0.048177604  || Decoder Loss:  0.033437353 Validation Decoder Loss:  0.33221227
Encoder Loss:  0.048259582  || Decoder Loss:  0.03345908 Validation Decoder Loss:  0.33223617
Encoder Loss:  0.048148666  || Decoder Loss:  0.03346133 Validation Decoder Loss:  0.3322837
Encoder Loss:  0.04818704  || Decoder Loss:  0.033473562 Validation Decoder Loss:  0.33231992
Encoder Loss:  0.048180558  || Decoder Loss:  0.033486277 Validation Decoder Loss:  0.33236966
Encoder Loss:  0.04821913  || Decoder Loss:  0.033494513 Validation Decoder Loss:  0.33239856
Encoder Loss:  0.04821159  || Decoder Loss:  0.03350163 Validation Decoder Loss:  0.33244407
Model: siamese_net_lr_0.000475465135648201 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33244407
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 79, 30, 19, 1)     225       
_________________________________________________________________
reshape_11 (Reshape)         (None, 2370, 19, 1)       0         
=================================================================
Total params: 225
Trainable params: 225
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.35114413
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.35114413
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631673  || Decoder Loss:  0.043631673 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Encoder Loss:  0.043631677  || Decoder Loss:  0.043631677 Validation Decoder Loss:  0.3511441
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3511441
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 220, 11, 19, 1)    283       
_________________________________________________________________
reshape_12 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05622469  || Decoder Loss:  0.0434955 Validation Decoder Loss:  0.33778876
Encoder Loss:  0.060704425  || Decoder Loss:  0.048656102 Validation Decoder Loss:  0.3393252
Encoder Loss:  0.054713707  || Decoder Loss:  0.049509235 Validation Decoder Loss:  0.3316695
Encoder Loss:  0.038180076  || Decoder Loss:  0.036836065 Validation Decoder Loss:  0.3302196
Encoder Loss:  0.037259683  || Decoder Loss:  0.035911538 Validation Decoder Loss:  0.32974315
Encoder Loss:  0.03684815  || Decoder Loss:  0.035503995 Validation Decoder Loss:  0.3295473
Encoder Loss:  0.036645602  || Decoder Loss:  0.035310883 Validation Decoder Loss:  0.32942355
Encoder Loss:  0.03653032  || Decoder Loss:  0.035208 Validation Decoder Loss:  0.32932118
Encoder Loss:  0.036450554  || Decoder Loss:  0.03514292 Validation Decoder Loss:  0.32922196
Encoder Loss:  0.03638521  || Decoder Loss:  0.03509449 Validation Decoder Loss:  0.3291281
Encoder Loss:  0.036322672  || Decoder Loss:  0.035054438 Validation Decoder Loss:  0.32904708
Encoder Loss:  0.036173314  || Decoder Loss:  0.03501902 Validation Decoder Loss:  0.32898003
Encoder Loss:  0.035601784  || Decoder Loss:  0.03499298 Validation Decoder Loss:  0.32892147
Encoder Loss:  0.035589334  || Decoder Loss:  0.034991056 Validation Decoder Loss:  0.32891575
Encoder Loss:  0.035587896  || Decoder Loss:  0.034995355 Validation Decoder Loss:  0.32895684
Encoder Loss:  0.03559219  || Decoder Loss:  0.03500463 Validation Decoder Loss:  0.32903677
Encoder Loss:  0.03559791  || Decoder Loss:  0.03501705 Validation Decoder Loss:  0.3291516
Encoder Loss:  0.03560776  || Decoder Loss:  0.035032395 Validation Decoder Loss:  0.32929423
Encoder Loss:  0.035615385  || Decoder Loss:  0.035045907 Validation Decoder Loss:  0.32946056
Encoder Loss:  0.035617184  || Decoder Loss:  0.035053104 Validation Decoder Loss:  0.32964435
Encoder Loss:  0.03560884  || Decoder Loss:  0.035050355 Validation Decoder Loss:  0.32983318
Encoder Loss:  0.03558925  || Decoder Loss:  0.03503516 Validation Decoder Loss:  0.3299989
Encoder Loss:  0.03555775  || Decoder Loss:  0.035008017 Validation Decoder Loss:  0.3301378
Encoder Loss:  0.03551921  || Decoder Loss:  0.034969226 Validation Decoder Loss:  0.3301734
Encoder Loss:  0.0354709  || Decoder Loss:  0.034925543 Validation Decoder Loss:  0.33020055
Encoder Loss:  0.03541931  || Decoder Loss:  0.03487792 Validation Decoder Loss:  0.33017758
Encoder Loss:  0.03536369  || Decoder Loss:  0.034827955 Validation Decoder Loss:  0.33015543
Encoder Loss:  0.035311796  || Decoder Loss:  0.034779683 Validation Decoder Loss:  0.33008093
Encoder Loss:  0.035253752  || Decoder Loss:  0.034732334 Validation Decoder Loss:  0.33017665
Encoder Loss:  0.035199184  || Decoder Loss:  0.03468397 Validation Decoder Loss:  0.33034453
Encoder Loss:  0.03516781  || Decoder Loss:  0.03465252 Validation Decoder Loss:  0.33019835
Encoder Loss:  0.035148174  || Decoder Loss:  0.034637567 Validation Decoder Loss:  0.33017245
Encoder Loss:  0.035134874  || Decoder Loss:  0.034627523 Validation Decoder Loss:  0.33024228
Encoder Loss:  0.03513919  || Decoder Loss:  0.0346285 Validation Decoder Loss:  0.3299468
Encoder Loss:  0.035138186  || Decoder Loss:  0.034632504 Validation Decoder Loss:  0.3299237
Encoder Loss:  0.035149563  || Decoder Loss:  0.03464292 Validation Decoder Loss:  0.32969442
Encoder Loss:  0.035153642  || Decoder Loss:  0.034649283 Validation Decoder Loss:  0.329673
Encoder Loss:  0.035161287  || Decoder Loss:  0.03465745 Validation Decoder Loss:  0.32945335
Encoder Loss:  0.035169803  || Decoder Loss:  0.034667693 Validation Decoder Loss:  0.32943183
Encoder Loss:  0.035176408  || Decoder Loss:  0.034676455 Validation Decoder Loss:  0.32945728
Model: siamese_net_lr_0.0002838817935414137 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32945728
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 242, 10, 19, 1)    233       
_________________________________________________________________
reshape_13 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 233
Trainable params: 233
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809846  || Decoder Loss:  0.041809846 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809864  || Decoder Loss:  0.041809864 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809846  || Decoder Loss:  0.041809846 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809853  || Decoder Loss:  0.041809853 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809864  || Decoder Loss:  0.041809864 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180986  || Decoder Loss:  0.04180986 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.041809864  || Decoder Loss:  0.041809864 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Encoder Loss:  0.04180985  || Decoder Loss:  0.04180985 Validation Decoder Loss:  0.34147733
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34147733
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 220, 11, 19, 1)    472       
_________________________________________________________________
reshape_14 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 472
Trainable params: 472
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0997684  || Decoder Loss:  0.04783808 Validation Decoder Loss:  0.3344419
Encoder Loss:  0.070604876  || Decoder Loss:  0.04727987 Validation Decoder Loss:  0.33108723
Encoder Loss:  0.041313883  || Decoder Loss:  0.036069047 Validation Decoder Loss:  0.32988435
Encoder Loss:  0.040508617  || Decoder Loss:  0.03530254 Validation Decoder Loss:  0.32965392
Encoder Loss:  0.040177125  || Decoder Loss:  0.03508227 Validation Decoder Loss:  0.32952076
Encoder Loss:  0.03960708  || Decoder Loss:  0.034973633 Validation Decoder Loss:  0.32946074
Encoder Loss:  0.03744187  || Decoder Loss:  0.034929752 Validation Decoder Loss:  0.32946637
Encoder Loss:  0.037412222  || Decoder Loss:  0.03494291 Validation Decoder Loss:  0.32961896
Encoder Loss:  0.037395854  || Decoder Loss:  0.03497343 Validation Decoder Loss:  0.32983115
Encoder Loss:  0.03739431  || Decoder Loss:  0.03500697 Validation Decoder Loss:  0.33011672
Encoder Loss:  0.037381686  || Decoder Loss:  0.035022866 Validation Decoder Loss:  0.33046672
Encoder Loss:  0.037339028  || Decoder Loss:  0.03500608 Validation Decoder Loss:  0.33084118
Encoder Loss:  0.037248623  || Decoder Loss:  0.034945916 Validation Decoder Loss:  0.3311541
Encoder Loss:  0.037120067  || Decoder Loss:  0.034847282 Validation Decoder Loss:  0.3313012
Encoder Loss:  0.036971405  || Decoder Loss:  0.034725107 Validation Decoder Loss:  0.3312767
Encoder Loss:  0.036808368  || Decoder Loss:  0.034589518 Validation Decoder Loss:  0.33116734
Encoder Loss:  0.036661908  || Decoder Loss:  0.034454927 Validation Decoder Loss:  0.33105373
Encoder Loss:  0.036543176  || Decoder Loss:  0.034355666 Validation Decoder Loss:  0.33100384
Encoder Loss:  0.036484424  || Decoder Loss:  0.03430863 Validation Decoder Loss:  0.33096334
Encoder Loss:  0.036477163  || Decoder Loss:  0.03429763 Validation Decoder Loss:  0.33096144
Encoder Loss:  0.03648609  || Decoder Loss:  0.034320615 Validation Decoder Loss:  0.33096486
Encoder Loss:  0.036528755  || Decoder Loss:  0.03436081 Validation Decoder Loss:  0.3309431
Encoder Loss:  0.03654402  || Decoder Loss:  0.03439271 Validation Decoder Loss:  0.33097705
Encoder Loss:  0.03658003  || Decoder Loss:  0.03443772 Validation Decoder Loss:  0.33099213
Encoder Loss:  0.0366186  || Decoder Loss:  0.03448698 Validation Decoder Loss:  0.33103573
Encoder Loss:  0.036665093  || Decoder Loss:  0.034541804 Validation Decoder Loss:  0.33106607
Encoder Loss:  0.036707826  || Decoder Loss:  0.034589685 Validation Decoder Loss:  0.33107027
Encoder Loss:  0.03674717  || Decoder Loss:  0.03464207 Validation Decoder Loss:  0.33108968
Encoder Loss:  0.036787014  || Decoder Loss:  0.03468733 Validation Decoder Loss:  0.33108664
Encoder Loss:  0.03681707  || Decoder Loss:  0.034724228 Validation Decoder Loss:  0.33109093
Encoder Loss:  0.03684127  || Decoder Loss:  0.034756 Validation Decoder Loss:  0.33108532
Encoder Loss:  0.036865994  || Decoder Loss:  0.03478261 Validation Decoder Loss:  0.3310896
Encoder Loss:  0.03687684  || Decoder Loss:  0.03480096 Validation Decoder Loss:  0.3311123
Encoder Loss:  0.036901835  || Decoder Loss:  0.034829214 Validation Decoder Loss:  0.3310926
Encoder Loss:  0.036915198  || Decoder Loss:  0.034847993 Validation Decoder Loss:  0.3310958
Encoder Loss:  0.036927328  || Decoder Loss:  0.034864742 Validation Decoder Loss:  0.33110577
Encoder Loss:  0.036930446  || Decoder Loss:  0.03486779 Validation Decoder Loss:  0.3311033
Encoder Loss:  0.036931396  || Decoder Loss:  0.034872167 Validation Decoder Loss:  0.3311011
Encoder Loss:  0.036943283  || Decoder Loss:  0.034881637 Validation Decoder Loss:  0.33113134
Encoder Loss:  0.03694595  || Decoder Loss:  0.034887943 Validation Decoder Loss:  0.33114222
Model: siamese_net_lr_0.00048526663430788626 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33114225
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 514, 5, 19, 1)     452       
_________________________________________________________________
reshape_15 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 452
Trainable params: 452
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10993613  || Decoder Loss:  0.03550339 Validation Decoder Loss:  0.3330843
Encoder Loss:  0.109945  || Decoder Loss:  0.03553294 Validation Decoder Loss:  0.3327105
Encoder Loss:  0.1099545  || Decoder Loss:  0.03556361 Validation Decoder Loss:  0.33232385
Encoder Loss:  0.10996475  || Decoder Loss:  0.0355956 Validation Decoder Loss:  0.33192405
Encoder Loss:  0.109975845  || Decoder Loss:  0.035629008 Validation Decoder Loss:  0.33151132
Encoder Loss:  0.10998778  || Decoder Loss:  0.0356639 Validation Decoder Loss:  0.33108616
Encoder Loss:  0.11000065  || Decoder Loss:  0.03570041 Validation Decoder Loss:  0.33064958
Encoder Loss:  0.11001446  || Decoder Loss:  0.035738543 Validation Decoder Loss:  0.33020288
Encoder Loss:  0.11002919  || Decoder Loss:  0.03577832 Validation Decoder Loss:  0.32974756
Encoder Loss:  0.11004482  || Decoder Loss:  0.03581978 Validation Decoder Loss:  0.3292852
Encoder Loss:  0.11006143  || Decoder Loss:  0.03586291 Validation Decoder Loss:  0.32881737
Encoder Loss:  0.110078886  || Decoder Loss:  0.035907708 Validation Decoder Loss:  0.3283452
Encoder Loss:  0.11009724  || Decoder Loss:  0.035954192 Validation Decoder Loss:  0.3278697
Encoder Loss:  0.110116504  || Decoder Loss:  0.036002368 Validation Decoder Loss:  0.32739162
Encoder Loss:  0.11013664  || Decoder Loss:  0.036052223 Validation Decoder Loss:  0.32691148
Encoder Loss:  0.11015762  || Decoder Loss:  0.036103785 Validation Decoder Loss:  0.32642967
Encoder Loss:  0.11017945  || Decoder Loss:  0.036157086 Validation Decoder Loss:  0.32594648
Encoder Loss:  0.11020221  || Decoder Loss:  0.036212124 Validation Decoder Loss:  0.3254621
Encoder Loss:  0.110225804  || Decoder Loss:  0.03626894 Validation Decoder Loss:  0.32497665
Encoder Loss:  0.110250264  || Decoder Loss:  0.036327552 Validation Decoder Loss:  0.32449013
Encoder Loss:  0.11027567  || Decoder Loss:  0.036387973 Validation Decoder Loss:  0.32400262
Encoder Loss:  0.11030191  || Decoder Loss:  0.03645027 Validation Decoder Loss:  0.32351395
Encoder Loss:  0.11032909  || Decoder Loss:  0.03651443 Validation Decoder Loss:  0.32302427
Encoder Loss:  0.11035712  || Decoder Loss:  0.03658051 Validation Decoder Loss:  0.3225334
Encoder Loss:  0.110386126  || Decoder Loss:  0.03664853 Validation Decoder Loss:  0.32204136
Encoder Loss:  0.110416025  || Decoder Loss:  0.03671853 Validation Decoder Loss:  0.32154813
Encoder Loss:  0.110446855  || Decoder Loss:  0.036790527 Validation Decoder Loss:  0.32105368
Encoder Loss:  0.1104786  || Decoder Loss:  0.036864538 Validation Decoder Loss:  0.32055795
Encoder Loss:  0.1105113  || Decoder Loss:  0.03694062 Validation Decoder Loss:  0.32006103
Encoder Loss:  0.1105449  || Decoder Loss:  0.037018795 Validation Decoder Loss:  0.31956276
Encoder Loss:  0.11057948  || Decoder Loss:  0.037099075 Validation Decoder Loss:  0.31906325
Encoder Loss:  0.11061495  || Decoder Loss:  0.037181478 Validation Decoder Loss:  0.3185624
Encoder Loss:  0.11065136  || Decoder Loss:  0.037266064 Validation Decoder Loss:  0.31806028
Encoder Loss:  0.11068864  || Decoder Loss:  0.037352845 Validation Decoder Loss:  0.31755686
Encoder Loss:  0.11072692  || Decoder Loss:  0.037441824 Validation Decoder Loss:  0.31705216
Encoder Loss:  0.1107661  || Decoder Loss:  0.03753303 Validation Decoder Loss:  0.3165462
Encoder Loss:  0.11080618  || Decoder Loss:  0.037626494 Validation Decoder Loss:  0.31603906
Encoder Loss:  0.1108471  || Decoder Loss:  0.037722215 Validation Decoder Loss:  0.31553078
Encoder Loss:  0.11088891  || Decoder Loss:  0.03782021 Validation Decoder Loss:  0.31502146
Encoder Loss:  0.110931545  || Decoder Loss:  0.03792049 Validation Decoder Loss:  0.31451118
Model: siamese_net_lr_3.795505193491637e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31451118
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 514, 5, 19, 1)     137       
_________________________________________________________________
reshape_16 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10376099  || Decoder Loss:  0.03569676 Validation Decoder Loss:  0.3307346
Encoder Loss:  0.103758916  || Decoder Loss:  0.03569747 Validation Decoder Loss:  0.33071664
Encoder Loss:  0.10375694  || Decoder Loss:  0.03569823 Validation Decoder Loss:  0.33069903
Encoder Loss:  0.10375499  || Decoder Loss:  0.03569904 Validation Decoder Loss:  0.33068168
Encoder Loss:  0.10375308  || Decoder Loss:  0.03569988 Validation Decoder Loss:  0.33066458
Encoder Loss:  0.10375118  || Decoder Loss:  0.03570075 Validation Decoder Loss:  0.33064765
Encoder Loss:  0.10374934  || Decoder Loss:  0.035701647 Validation Decoder Loss:  0.3306309
Encoder Loss:  0.10374753  || Decoder Loss:  0.03570257 Validation Decoder Loss:  0.33061433
Encoder Loss:  0.10374577  || Decoder Loss:  0.035703517 Validation Decoder Loss:  0.33059797
Encoder Loss:  0.10374402  || Decoder Loss:  0.035704512 Validation Decoder Loss:  0.33058172
Encoder Loss:  0.103742234  || Decoder Loss:  0.035705518 Validation Decoder Loss:  0.33056557
Encoder Loss:  0.10374051  || Decoder Loss:  0.035706557 Validation Decoder Loss:  0.33054957
Encoder Loss:  0.10373881  || Decoder Loss:  0.035707615 Validation Decoder Loss:  0.33053362
Encoder Loss:  0.103737116  || Decoder Loss:  0.035708703 Validation Decoder Loss:  0.33051783
Encoder Loss:  0.103735425  || Decoder Loss:  0.03570982 Validation Decoder Loss:  0.33050203
Encoder Loss:  0.10373372  || Decoder Loss:  0.035710964 Validation Decoder Loss:  0.3304864
Encoder Loss:  0.103732064  || Decoder Loss:  0.035712123 Validation Decoder Loss:  0.33047074
Encoder Loss:  0.10373041  || Decoder Loss:  0.035713326 Validation Decoder Loss:  0.33045518
Encoder Loss:  0.10372877  || Decoder Loss:  0.03571455 Validation Decoder Loss:  0.33043966
Encoder Loss:  0.103727125  || Decoder Loss:  0.03571579 Validation Decoder Loss:  0.3304242
Encoder Loss:  0.1037255  || Decoder Loss:  0.035717074 Validation Decoder Loss:  0.3304087
Encoder Loss:  0.10372386  || Decoder Loss:  0.035718385 Validation Decoder Loss:  0.33039325
Encoder Loss:  0.10372224  || Decoder Loss:  0.035719723 Validation Decoder Loss:  0.33037782
Encoder Loss:  0.103720605  || Decoder Loss:  0.035721086 Validation Decoder Loss:  0.33036244
Encoder Loss:  0.10371896  || Decoder Loss:  0.03572247 Validation Decoder Loss:  0.33034703
Encoder Loss:  0.103717335  || Decoder Loss:  0.035723895 Validation Decoder Loss:  0.33033162
Encoder Loss:  0.103715725  || Decoder Loss:  0.035725333 Validation Decoder Loss:  0.33031625
Encoder Loss:  0.103714116  || Decoder Loss:  0.035726815 Validation Decoder Loss:  0.3303008
Encoder Loss:  0.10371246  || Decoder Loss:  0.03572832 Validation Decoder Loss:  0.33028543
Encoder Loss:  0.103710845  || Decoder Loss:  0.035729855 Validation Decoder Loss:  0.33027002
Encoder Loss:  0.10370922  || Decoder Loss:  0.03573143 Validation Decoder Loss:  0.3302546
Encoder Loss:  0.10370758  || Decoder Loss:  0.035733026 Validation Decoder Loss:  0.33023918
Encoder Loss:  0.10370592  || Decoder Loss:  0.035734665 Validation Decoder Loss:  0.3302238
Encoder Loss:  0.10370429  || Decoder Loss:  0.03573632 Validation Decoder Loss:  0.33020836
Encoder Loss:  0.103702635  || Decoder Loss:  0.035738006 Validation Decoder Loss:  0.33019286
Encoder Loss:  0.103701  || Decoder Loss:  0.03573974 Validation Decoder Loss:  0.33017743
Encoder Loss:  0.103699334  || Decoder Loss:  0.0357415 Validation Decoder Loss:  0.33016196
Encoder Loss:  0.10369765  || Decoder Loss:  0.035743285 Validation Decoder Loss:  0.3301465
Encoder Loss:  0.10369597  || Decoder Loss:  0.035745114 Validation Decoder Loss:  0.330131
Encoder Loss:  0.103694275  || Decoder Loss:  0.03574697 Validation Decoder Loss:  0.3301155
Model: siamese_net_lr_2.2277404158132797e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3301155
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 257, 10, 19, 1)    11        
_________________________________________________________________
reshape_17 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11844336  || Decoder Loss:  0.035771202 Validation Decoder Loss:  0.3318252
Encoder Loss:  0.11843265  || Decoder Loss:  0.035763394 Validation Decoder Loss:  0.3318156
Encoder Loss:  0.1184219  || Decoder Loss:  0.035755664 Validation Decoder Loss:  0.3318063
Encoder Loss:  0.118411236  || Decoder Loss:  0.035748027 Validation Decoder Loss:  0.33179718
Encoder Loss:  0.118400514  || Decoder Loss:  0.035740454 Validation Decoder Loss:  0.33178818
Encoder Loss:  0.1183898  || Decoder Loss:  0.035732914 Validation Decoder Loss:  0.3317793
Encoder Loss:  0.11837908  || Decoder Loss:  0.035725415 Validation Decoder Loss:  0.33177057
Encoder Loss:  0.11836835  || Decoder Loss:  0.035717938 Validation Decoder Loss:  0.3317619
Encoder Loss:  0.11835749  || Decoder Loss:  0.035710476 Validation Decoder Loss:  0.3317533
Encoder Loss:  0.118346624  || Decoder Loss:  0.035703007 Validation Decoder Loss:  0.3317448
Encoder Loss:  0.11833573  || Decoder Loss:  0.035695553 Validation Decoder Loss:  0.33173633
Encoder Loss:  0.11832468  || Decoder Loss:  0.035688087 Validation Decoder Loss:  0.33172792
Encoder Loss:  0.11831362  || Decoder Loss:  0.0356806 Validation Decoder Loss:  0.33171955
Encoder Loss:  0.11830248  || Decoder Loss:  0.035673097 Validation Decoder Loss:  0.3317112
Encoder Loss:  0.1182912  || Decoder Loss:  0.035665568 Validation Decoder Loss:  0.3317029
Encoder Loss:  0.11827982  || Decoder Loss:  0.03565799 Validation Decoder Loss:  0.3316946
Encoder Loss:  0.11826832  || Decoder Loss:  0.035650376 Validation Decoder Loss:  0.33168632
Encoder Loss:  0.118256696  || Decoder Loss:  0.035642717 Validation Decoder Loss:  0.3316781
Encoder Loss:  0.11824492  || Decoder Loss:  0.035635 Validation Decoder Loss:  0.3316698
Encoder Loss:  0.11823299  || Decoder Loss:  0.035627216 Validation Decoder Loss:  0.33166155
Encoder Loss:  0.1182209  || Decoder Loss:  0.035619393 Validation Decoder Loss:  0.33165333
Encoder Loss:  0.11820868  || Decoder Loss:  0.03561148 Validation Decoder Loss:  0.33164507
Encoder Loss:  0.11819629  || Decoder Loss:  0.03560351 Validation Decoder Loss:  0.3316368
Encoder Loss:  0.11818375  || Decoder Loss:  0.035595465 Validation Decoder Loss:  0.33162856
Encoder Loss:  0.11817098  || Decoder Loss:  0.035587344 Validation Decoder Loss:  0.33162028
Encoder Loss:  0.118158035  || Decoder Loss:  0.03557915 Validation Decoder Loss:  0.331612
Encoder Loss:  0.11814493  || Decoder Loss:  0.035570856 Validation Decoder Loss:  0.33160377
Encoder Loss:  0.11813159  || Decoder Loss:  0.035562485 Validation Decoder Loss:  0.33159548
Encoder Loss:  0.11811807  || Decoder Loss:  0.035554036 Validation Decoder Loss:  0.3315872
Encoder Loss:  0.11810426  || Decoder Loss:  0.03554549 Validation Decoder Loss:  0.33157897
Encoder Loss:  0.11809028  || Decoder Loss:  0.035536855 Validation Decoder Loss:  0.33157074
Encoder Loss:  0.11807606  || Decoder Loss:  0.035528146 Validation Decoder Loss:  0.33156255
Encoder Loss:  0.11806154  || Decoder Loss:  0.03551933 Validation Decoder Loss:  0.33155435
Encoder Loss:  0.11804678  || Decoder Loss:  0.035510432 Validation Decoder Loss:  0.3315462
Encoder Loss:  0.1180318  || Decoder Loss:  0.035501447 Validation Decoder Loss:  0.3315381
Encoder Loss:  0.11801646  || Decoder Loss:  0.035492383 Validation Decoder Loss:  0.3315301
Encoder Loss:  0.11800087  || Decoder Loss:  0.035483226 Validation Decoder Loss:  0.3315222
Encoder Loss:  0.117984936  || Decoder Loss:  0.035474014 Validation Decoder Loss:  0.33151436
Encoder Loss:  0.117968656  || Decoder Loss:  0.035464708 Validation Decoder Loss:  0.33150667
Encoder Loss:  0.11795204  || Decoder Loss:  0.035455357 Validation Decoder Loss:  0.3314991
Model: siamese_net_lr_5.7004213566157575e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3314991
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 514, 5, 19, 1)     11        
_________________________________________________________________
reshape_18 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10098917  || Decoder Loss:  0.035771944 Validation Decoder Loss:  0.33182743
Encoder Loss:  0.10098651  || Decoder Loss:  0.035769876 Validation Decoder Loss:  0.33182487
Encoder Loss:  0.10098388  || Decoder Loss:  0.035767853 Validation Decoder Loss:  0.33182237
Encoder Loss:  0.10098133  || Decoder Loss:  0.035765875 Validation Decoder Loss:  0.33181992
Encoder Loss:  0.10097879  || Decoder Loss:  0.03576393 Validation Decoder Loss:  0.33181754
Encoder Loss:  0.100976326  || Decoder Loss:  0.035762016 Validation Decoder Loss:  0.33181518
Encoder Loss:  0.10097385  || Decoder Loss:  0.03576013 Validation Decoder Loss:  0.33181286
Encoder Loss:  0.100971416  || Decoder Loss:  0.03575828 Validation Decoder Loss:  0.3318106
Encoder Loss:  0.10096902  || Decoder Loss:  0.035756443 Validation Decoder Loss:  0.3318084
Encoder Loss:  0.100966685  || Decoder Loss:  0.035754632 Validation Decoder Loss:  0.33180612
Encoder Loss:  0.10096431  || Decoder Loss:  0.035752848 Validation Decoder Loss:  0.33180398
Encoder Loss:  0.10096196  || Decoder Loss:  0.03575106 Validation Decoder Loss:  0.33180183
Encoder Loss:  0.1009597  || Decoder Loss:  0.03574932 Validation Decoder Loss:  0.3317997
Encoder Loss:  0.10095736  || Decoder Loss:  0.035747577 Validation Decoder Loss:  0.33179754
Encoder Loss:  0.10095511  || Decoder Loss:  0.035745855 Validation Decoder Loss:  0.33179545
Encoder Loss:  0.10095282  || Decoder Loss:  0.035744146 Validation Decoder Loss:  0.33179337
Encoder Loss:  0.100950584  || Decoder Loss:  0.035742447 Validation Decoder Loss:  0.33179134
Encoder Loss:  0.10094833  || Decoder Loss:  0.035740755 Validation Decoder Loss:  0.33178926
Encoder Loss:  0.10094608  || Decoder Loss:  0.035739057 Validation Decoder Loss:  0.33178726
Encoder Loss:  0.10094388  || Decoder Loss:  0.035737384 Validation Decoder Loss:  0.3317852
Encoder Loss:  0.10094165  || Decoder Loss:  0.035735726 Validation Decoder Loss:  0.33178318
Encoder Loss:  0.100939415  || Decoder Loss:  0.035734057 Validation Decoder Loss:  0.33178115
Encoder Loss:  0.10093723  || Decoder Loss:  0.0357324 Validation Decoder Loss:  0.33177918
Encoder Loss:  0.10093501  || Decoder Loss:  0.03573075 Validation Decoder Loss:  0.33177716
Encoder Loss:  0.100932814  || Decoder Loss:  0.035729088 Validation Decoder Loss:  0.33177516
Encoder Loss:  0.100930616  || Decoder Loss:  0.03572744 Validation Decoder Loss:  0.3317732
Encoder Loss:  0.10092841  || Decoder Loss:  0.0357258 Validation Decoder Loss:  0.3317712
Encoder Loss:  0.10092618  || Decoder Loss:  0.035724152 Validation Decoder Loss:  0.33176923
Encoder Loss:  0.100924015  || Decoder Loss:  0.03572251 Validation Decoder Loss:  0.33176726
Encoder Loss:  0.1009218  || Decoder Loss:  0.035720874 Validation Decoder Loss:  0.33176523
Encoder Loss:  0.10091956  || Decoder Loss:  0.03571923 Validation Decoder Loss:  0.33176327
Encoder Loss:  0.1009174  || Decoder Loss:  0.035717584 Validation Decoder Loss:  0.3317613
Encoder Loss:  0.10091515  || Decoder Loss:  0.035715953 Validation Decoder Loss:  0.33175933
Encoder Loss:  0.10091297  || Decoder Loss:  0.035714302 Validation Decoder Loss:  0.33175737
Encoder Loss:  0.10091075  || Decoder Loss:  0.03571267 Validation Decoder Loss:  0.3317554
Encoder Loss:  0.10090855  || Decoder Loss:  0.035711024 Validation Decoder Loss:  0.33175343
Encoder Loss:  0.100906335  || Decoder Loss:  0.035709377 Validation Decoder Loss:  0.33175147
Encoder Loss:  0.100904115  || Decoder Loss:  0.035707723 Validation Decoder Loss:  0.33174953
Encoder Loss:  0.10090187  || Decoder Loss:  0.03570609 Validation Decoder Loss:  0.33174756
Encoder Loss:  0.10089966  || Decoder Loss:  0.035704445 Validation Decoder Loss:  0.33174556
Model: siamese_net_lr_1.5268905347788136e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33174556
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 257, 10, 19, 1)    787       
_________________________________________________________________
reshape_19 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1235135  || Decoder Loss:  0.042162746 Validation Decoder Loss:  0.3249882
Encoder Loss:  0.123609856  || Decoder Loss:  0.04239965 Validation Decoder Loss:  0.3249055
Encoder Loss:  0.12370674  || Decoder Loss:  0.042638782 Validation Decoder Loss:  0.324826
Encoder Loss:  0.12380398  || Decoder Loss:  0.04288014 Validation Decoder Loss:  0.32474875
Encoder Loss:  0.123901576  || Decoder Loss:  0.04312379 Validation Decoder Loss:  0.32467318
Encoder Loss:  0.123999536  || Decoder Loss:  0.0433698 Validation Decoder Loss:  0.3245989
Encoder Loss:  0.124097526  || Decoder Loss:  0.043618117 Validation Decoder Loss:  0.3245257
Encoder Loss:  0.124195725  || Decoder Loss:  0.043868657 Validation Decoder Loss:  0.3244537
Encoder Loss:  0.12429361  || Decoder Loss:  0.044121247 Validation Decoder Loss:  0.32438293
Encoder Loss:  0.12439122  || Decoder Loss:  0.04437574 Validation Decoder Loss:  0.3243137
Encoder Loss:  0.124488145  || Decoder Loss:  0.04463189 Validation Decoder Loss:  0.32424623
Encoder Loss:  0.12458416  || Decoder Loss:  0.044889446 Validation Decoder Loss:  0.32418063
Encoder Loss:  0.12467908  || Decoder Loss:  0.04514818 Validation Decoder Loss:  0.32411695
Encoder Loss:  0.124772504  || Decoder Loss:  0.045407772 Validation Decoder Loss:  0.32405522
Encoder Loss:  0.12486411  || Decoder Loss:  0.04566791 Validation Decoder Loss:  0.32399544
Encoder Loss:  0.124953516  || Decoder Loss:  0.04592826 Validation Decoder Loss:  0.32393754
Encoder Loss:  0.12504031  || Decoder Loss:  0.046188317 Validation Decoder Loss:  0.3238814
Encoder Loss:  0.125124  || Decoder Loss:  0.046447653 Validation Decoder Loss:  0.32382667
Encoder Loss:  0.12520403  || Decoder Loss:  0.046705637 Validation Decoder Loss:  0.3237731
Encoder Loss:  0.12527983  || Decoder Loss:  0.046961583 Validation Decoder Loss:  0.32372016
Encoder Loss:  0.12535062  || Decoder Loss:  0.04721471 Validation Decoder Loss:  0.32366735
Encoder Loss:  0.12541561  || Decoder Loss:  0.047464084 Validation Decoder Loss:  0.323614
Encoder Loss:  0.12547386  || Decoder Loss:  0.047708612 Validation Decoder Loss:  0.32355943
Encoder Loss:  0.12552416  || Decoder Loss:  0.04794705 Validation Decoder Loss:  0.3235028
Encoder Loss:  0.12556541  || Decoder Loss:  0.04817787 Validation Decoder Loss:  0.3234433
Encoder Loss:  0.125596  || Decoder Loss:  0.048399378 Validation Decoder Loss:  0.32337987
Encoder Loss:  0.12561432  || Decoder Loss:  0.048609514 Validation Decoder Loss:  0.32331145
Encoder Loss:  0.12561825  || Decoder Loss:  0.04880588 Validation Decoder Loss:  0.32323676
Encoder Loss:  0.12560557  || Decoder Loss:  0.048985682 Validation Decoder Loss:  0.32315445
Encoder Loss:  0.12557346  || Decoder Loss:  0.049145542 Validation Decoder Loss:  0.32306278
Encoder Loss:  0.12551862  || Decoder Loss:  0.049281426 Validation Decoder Loss:  0.32295978
Encoder Loss:  0.12543708  || Decoder Loss:  0.049388573 Validation Decoder Loss:  0.32284313
Encoder Loss:  0.1253242  || Decoder Loss:  0.049461145 Validation Decoder Loss:  0.32271016
Encoder Loss:  0.12517431  || Decoder Loss:  0.049492143 Validation Decoder Loss:  0.3225578
Encoder Loss:  0.12498039  || Decoder Loss:  0.04947298 Validation Decoder Loss:  0.3223827
Encoder Loss:  0.12473406  || Decoder Loss:  0.04939307 Validation Decoder Loss:  0.3221811
Encoder Loss:  0.124424726  || Decoder Loss:  0.04923933 Validation Decoder Loss:  0.321949
Encoder Loss:  0.12403928  || Decoder Loss:  0.048995346 Validation Decoder Loss:  0.32168275
Encoder Loss:  0.12356127  || Decoder Loss:  0.048640493 Validation Decoder Loss:  0.3213793
Encoder Loss:  0.12296966  || Decoder Loss:  0.048148558 Validation Decoder Loss:  0.32103807
Model: siamese_net_lr_6.218144814357209e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32103807
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 514, 5, 19, 1)     137       
_________________________________________________________________
reshape_20 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.314378  || Decoder Loss:  0.035721075 Validation Decoder Loss:  0.33025467
Encoder Loss:  0.31395337  || Decoder Loss:  0.03579458 Validation Decoder Loss:  0.32966334
Encoder Loss:  0.31307876  || Decoder Loss:  0.036002122 Validation Decoder Loss:  0.32896715
Encoder Loss:  0.30953816  || Decoder Loss:  0.036690697 Validation Decoder Loss:  0.3283813
Encoder Loss:  0.18994349  || Decoder Loss:  0.036876522 Validation Decoder Loss:  0.3309952
Encoder Loss:  0.07963728  || Decoder Loss:  0.035443567 Validation Decoder Loss:  0.33092967
Encoder Loss:  0.077226155  || Decoder Loss:  0.035273097 Validation Decoder Loss:  0.33079442
Encoder Loss:  0.07688887  || Decoder Loss:  0.035216786 Validation Decoder Loss:  0.33075225
Encoder Loss:  0.076216124  || Decoder Loss:  0.035187587 Validation Decoder Loss:  0.33074814
Encoder Loss:  0.07599188  || Decoder Loss:  0.035165954 Validation Decoder Loss:  0.33075917
Encoder Loss:  0.07548262  || Decoder Loss:  0.03514852 Validation Decoder Loss:  0.33077544
Encoder Loss:  0.07500116  || Decoder Loss:  0.03513426 Validation Decoder Loss:  0.3307922
Encoder Loss:  0.07465467  || Decoder Loss:  0.035122596 Validation Decoder Loss:  0.33080786
Encoder Loss:  0.0742534  || Decoder Loss:  0.03511307 Validation Decoder Loss:  0.33082247
Encoder Loss:  0.07369415  || Decoder Loss:  0.0351053 Validation Decoder Loss:  0.33083546
Encoder Loss:  0.073049136  || Decoder Loss:  0.03509906 Validation Decoder Loss:  0.3308472
Encoder Loss:  0.069607474  || Decoder Loss:  0.035093952 Validation Decoder Loss:  0.33086142
Encoder Loss:  0.052784882  || Decoder Loss:  0.0350956 Validation Decoder Loss:  0.33087516
Encoder Loss:  0.050250746  || Decoder Loss:  0.035089422 Validation Decoder Loss:  0.3309048
Encoder Loss:  0.0475604  || Decoder Loss:  0.03508223 Validation Decoder Loss:  0.33092412
Encoder Loss:  0.047183976  || Decoder Loss:  0.03507854 Validation Decoder Loss:  0.3309394
Encoder Loss:  0.047234844  || Decoder Loss:  0.035076536 Validation Decoder Loss:  0.33095294
Encoder Loss:  0.046995174  || Decoder Loss:  0.035074573 Validation Decoder Loss:  0.33096582
Encoder Loss:  0.04673339  || Decoder Loss:  0.035071608 Validation Decoder Loss:  0.33098006
Encoder Loss:  0.046648752  || Decoder Loss:  0.03506839 Validation Decoder Loss:  0.3309937
Encoder Loss:  0.046572972  || Decoder Loss:  0.03506523 Validation Decoder Loss:  0.33100754
Encoder Loss:  0.04669401  || Decoder Loss:  0.03506311 Validation Decoder Loss:  0.33101827
Encoder Loss:  0.046496615  || Decoder Loss:  0.035060577 Validation Decoder Loss:  0.3310318
Encoder Loss:  0.046630412  || Decoder Loss:  0.035059165 Validation Decoder Loss:  0.3310415
Encoder Loss:  0.046470128  || Decoder Loss:  0.03505733 Validation Decoder Loss:  0.3310534
Encoder Loss:  0.046424232  || Decoder Loss:  0.03505507 Validation Decoder Loss:  0.33106583
Encoder Loss:  0.046359926  || Decoder Loss:  0.03505315 Validation Decoder Loss:  0.33107847
Encoder Loss:  0.04646003  || Decoder Loss:  0.035052355 Validation Decoder Loss:  0.33108738
Encoder Loss:  0.04640686  || Decoder Loss:  0.035051946 Validation Decoder Loss:  0.33109593
Encoder Loss:  0.046395756  || Decoder Loss:  0.03505136 Validation Decoder Loss:  0.3311035
Encoder Loss:  0.046355363  || Decoder Loss:  0.035050917 Validation Decoder Loss:  0.3311106
Encoder Loss:  0.04633044  || Decoder Loss:  0.035050575 Validation Decoder Loss:  0.3311177
Encoder Loss:  0.046256084  || Decoder Loss:  0.035049733 Validation Decoder Loss:  0.33112574
Encoder Loss:  0.046189547  || Decoder Loss:  0.03504856 Validation Decoder Loss:  0.33113506
Encoder Loss:  0.046103466  || Decoder Loss:  0.035046987 Validation Decoder Loss:  0.33114517
Model: siamese_net_lr_0.0005436830190390601 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33114517
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 514, 5, 19, 1)     389       
_________________________________________________________________
reshape_21 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.14150122  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.1415012  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33043253
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 514, 5, 19, 1)     137       
_________________________________________________________________
reshape_22 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696145  || Decoder Loss:  0.035696145 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696145  || Decoder Loss:  0.035696145 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.03569614  || Decoder Loss:  0.03569614 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696134  || Decoder Loss:  0.035696134 Validation Decoder Loss:  0.33075237
Encoder Loss:  0.035696138  || Decoder Loss:  0.035696138 Validation Decoder Loss:  0.33075237
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33075237
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 257, 10, 19, 1)    1165      
_________________________________________________________________
reshape_23 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 1,165
Trainable params: 1,165
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.093030825  || Decoder Loss:  0.040464934 Validation Decoder Loss:  0.33247033
Encoder Loss:  0.093496434  || Decoder Loss:  0.041209936 Validation Decoder Loss:  0.33163407
Encoder Loss:  0.094046995  || Decoder Loss:  0.042082433 Validation Decoder Loss:  0.33079964
Encoder Loss:  0.09467812  || Decoder Loss:  0.043076254 Validation Decoder Loss:  0.32998532
Encoder Loss:  0.095397025  || Decoder Loss:  0.04420401 Validation Decoder Loss:  0.32920444
Encoder Loss:  0.09620936  || Decoder Loss:  0.04547742 Validation Decoder Loss:  0.32846016
Encoder Loss:  0.09711606  || Decoder Loss:  0.046903826 Validation Decoder Loss:  0.3277433
Encoder Loss:  0.09810669  || Decoder Loss:  0.048479084 Validation Decoder Loss:  0.32703814
Encoder Loss:  0.099145815  || Decoder Loss:  0.050171748 Validation Decoder Loss:  0.32632023
Encoder Loss:  0.10014225  || Decoder Loss:  0.051887847 Validation Decoder Loss:  0.32552895
Encoder Loss:  0.10087184  || Decoder Loss:  0.05338189 Validation Decoder Loss:  0.32448858
Encoder Loss:  0.10074765  || Decoder Loss:  0.05399162 Validation Decoder Loss:  0.32270658
Encoder Loss:  0.09793887  || Decoder Loss:  0.051620547 Validation Decoder Loss:  0.31930637
Encoder Loss:  0.0872064  || Decoder Loss:  0.04023721 Validation Decoder Loss:  0.33383894
Encoder Loss:  0.08189911  || Decoder Loss:  0.03529943 Validation Decoder Loss:  0.32998198
Encoder Loss:  0.08065731  || Decoder Loss:  0.035273694 Validation Decoder Loss:  0.33006427
Encoder Loss:  0.079220474  || Decoder Loss:  0.035285294 Validation Decoder Loss:  0.33020777
Encoder Loss:  0.07749998  || Decoder Loss:  0.03529579 Validation Decoder Loss:  0.3303519
Encoder Loss:  0.07542363  || Decoder Loss:  0.035304796 Validation Decoder Loss:  0.3305058
Encoder Loss:  0.07289647  || Decoder Loss:  0.03531229 Validation Decoder Loss:  0.33065596
Encoder Loss:  0.069787614  || Decoder Loss:  0.035318397 Validation Decoder Loss:  0.33079332
Encoder Loss:  0.06591133  || Decoder Loss:  0.035323456 Validation Decoder Loss:  0.33091375
Encoder Loss:  0.06101349  || Decoder Loss:  0.035327863 Validation Decoder Loss:  0.33101916
Encoder Loss:  0.05479106  || Decoder Loss:  0.035331827 Validation Decoder Loss:  0.3311178
Encoder Loss:  0.047046326  || Decoder Loss:  0.035335455 Validation Decoder Loss:  0.33121985
Encoder Loss:  0.040722214  || Decoder Loss:  0.035337683 Validation Decoder Loss:  0.3312671
Encoder Loss:  0.040654194  || Decoder Loss:  0.035336193 Validation Decoder Loss:  0.33127892
Encoder Loss:  0.040671557  || Decoder Loss:  0.035334375 Validation Decoder Loss:  0.33128995
Encoder Loss:  0.04064211  || Decoder Loss:  0.03533248 Validation Decoder Loss:  0.33130002
Encoder Loss:  0.040621195  || Decoder Loss:  0.035330556 Validation Decoder Loss:  0.33130997
Encoder Loss:  0.04059725  || Decoder Loss:  0.035328608 Validation Decoder Loss:  0.33132
Encoder Loss:  0.040580675  || Decoder Loss:  0.035326626 Validation Decoder Loss:  0.33132932
Encoder Loss:  0.040558256  || Decoder Loss:  0.03532463 Validation Decoder Loss:  0.3313387
Encoder Loss:  0.040537342  || Decoder Loss:  0.03532261 Validation Decoder Loss:  0.33134782
Encoder Loss:  0.040518895  || Decoder Loss:  0.03532057 Validation Decoder Loss:  0.33135664
Encoder Loss:  0.04049645  || Decoder Loss:  0.035318516 Validation Decoder Loss:  0.33136564
Encoder Loss:  0.04047859  || Decoder Loss:  0.03531644 Validation Decoder Loss:  0.33137462
Encoder Loss:  0.040460758  || Decoder Loss:  0.035314362 Validation Decoder Loss:  0.331384
Encoder Loss:  0.040452562  || Decoder Loss:  0.035312265 Validation Decoder Loss:  0.33139253
Encoder Loss:  0.040427495  || Decoder Loss:  0.035310153 Validation Decoder Loss:  0.33140153
Model: siamese_net_lr_0.00029558188800653154 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33140153
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 257, 10, 19, 1)    11        
_________________________________________________________________
reshape_24 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774294  || Decoder Loss:  0.035774294 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.03577431  || Decoder Loss:  0.03577431 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774294  || Decoder Loss:  0.035774294 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774305  || Decoder Loss:  0.035774305 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774294  || Decoder Loss:  0.035774294 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.0357743  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33183324
Encoder Loss:  0.035774298  || Decoder Loss:  0.035774298 Validation Decoder Loss:  0.33183324
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33183324
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 514, 5, 19, 1)     200       
_________________________________________________________________
reshape_25 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123667 Validation Decoder Loss:  0.32778794
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123667 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.1019014  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778794
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.10190142  || Decoder Loss:  0.03612368 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.32778794
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778794
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.32778788
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123674 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.03612367 Validation Decoder Loss:  0.3277879
Encoder Loss:  0.101901405  || Decoder Loss:  0.036123678 Validation Decoder Loss:  0.3277879
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3277879
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 514, 5, 19, 1)     389       
_________________________________________________________________
reshape_26 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217783  || Decoder Loss:  0.036217783 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621777  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.03621778  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217775  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33043253
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 514, 5, 19, 1)     11        
_________________________________________________________________
reshape_27 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940342  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940344  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940344  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940342  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.14940344  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33182964
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 514, 5, 19, 1)     11        
_________________________________________________________________
reshape_28 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.035772767  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772767  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772774  || Decoder Loss:  0.035772774 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772767  || Decoder Loss:  0.035772767 Validation Decoder Loss:  0.3318296
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.035772763  || Decoder Loss:  0.035772763 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Encoder Loss:  0.03577277  || Decoder Loss:  0.03577277 Validation Decoder Loss:  0.33182964
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33182964
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 514, 5, 19, 1)     389       
_________________________________________________________________
reshape_29 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217798  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.036217794  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33043253
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 122, 10, 19, 1)    355       
_________________________________________________________________
reshape_30 (Reshape)         (None, 1220, 19, 1)       0         
=================================================================
Total params: 355
Trainable params: 355
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 1220, 19, 1)       170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 2607, 19, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1733336  || Decoder Loss:  0.08949635 Validation Decoder Loss:  0.36395973
Encoder Loss:  0.15949732  || Decoder Loss:  0.076447375 Validation Decoder Loss:  0.36709994
Encoder Loss:  0.14907996  || Decoder Loss:  0.077796705 Validation Decoder Loss:  0.420677
Encoder Loss:  0.24173269  || Decoder Loss:  0.27118093 Validation Decoder Loss:  1.128377
Encoder Loss:  0.26707822  || Decoder Loss:  0.33059847 Validation Decoder Loss:  0.86680776
Encoder Loss:  0.113509856  || Decoder Loss:  0.13225661 Validation Decoder Loss:  0.3706783
Encoder Loss:  0.03711871  || Decoder Loss:  0.031594224 Validation Decoder Loss:  0.3429607
Encoder Loss:  0.035103545  || Decoder Loss:  0.029094474 Validation Decoder Loss:  0.34232822
Encoder Loss:  0.03473549  || Decoder Loss:  0.028681431 Validation Decoder Loss:  0.34256065
Encoder Loss:  0.03447127  || Decoder Loss:  0.02842905 Validation Decoder Loss:  0.3429168
Encoder Loss:  0.034301985  || Decoder Loss:  0.028246544 Validation Decoder Loss:  0.34328276
Encoder Loss:  0.03414391  || Decoder Loss:  0.02811014 Validation Decoder Loss:  0.34364495
Encoder Loss:  0.034018017  || Decoder Loss:  0.028008165 Validation Decoder Loss:  0.34401482
Encoder Loss:  0.03393004  || Decoder Loss:  0.027928848 Validation Decoder Loss:  0.34437793
Encoder Loss:  0.033830702  || Decoder Loss:  0.027863527 Validation Decoder Loss:  0.34469748
Encoder Loss:  0.033736996  || Decoder Loss:  0.027813053 Validation Decoder Loss:  0.34496808
Encoder Loss:  0.033679258  || Decoder Loss:  0.027764987 Validation Decoder Loss:  0.3451836
Encoder Loss:  0.033580016  || Decoder Loss:  0.027721608 Validation Decoder Loss:  0.3453204
Encoder Loss:  0.033497397  || Decoder Loss:  0.027690507 Validation Decoder Loss:  0.34548134
Encoder Loss:  0.0334417  || Decoder Loss:  0.027650027 Validation Decoder Loss:  0.34560344
Encoder Loss:  0.033407077  || Decoder Loss:  0.027598515 Validation Decoder Loss:  0.34562385
Encoder Loss:  0.033337586  || Decoder Loss:  0.027559007 Validation Decoder Loss:  0.34555116
Encoder Loss:  0.033289768  || Decoder Loss:  0.027537134 Validation Decoder Loss:  0.34560502
Encoder Loss:  0.033246208  || Decoder Loss:  0.0274977 Validation Decoder Loss:  0.34553996
Encoder Loss:  0.033215534  || Decoder Loss:  0.027469335 Validation Decoder Loss:  0.3455404
Encoder Loss:  0.03318397  || Decoder Loss:  0.027435651 Validation Decoder Loss:  0.34548843
Encoder Loss:  0.03313211  || Decoder Loss:  0.02741035 Validation Decoder Loss:  0.3453897
Encoder Loss:  0.033113316  || Decoder Loss:  0.027388088 Validation Decoder Loss:  0.34547278
Encoder Loss:  0.033098888  || Decoder Loss:  0.02736426 Validation Decoder Loss:  0.34532937
Encoder Loss:  0.03308626  || Decoder Loss:  0.027350573 Validation Decoder Loss:  0.34528565
Encoder Loss:  0.03306717  || Decoder Loss:  0.027336642 Validation Decoder Loss:  0.3451805
Encoder Loss:  0.03304163  || Decoder Loss:  0.027325863 Validation Decoder Loss:  0.34508944
Encoder Loss:  0.033047188  || Decoder Loss:  0.027320473 Validation Decoder Loss:  0.34505486
Encoder Loss:  0.033033766  || Decoder Loss:  0.027315319 Validation Decoder Loss:  0.34498328
Encoder Loss:  0.033020798  || Decoder Loss:  0.027310057 Validation Decoder Loss:  0.3449037
Encoder Loss:  0.033018123  || Decoder Loss:  0.027314417 Validation Decoder Loss:  0.34491912
Encoder Loss:  0.03301103  || Decoder Loss:  0.027316289 Validation Decoder Loss:  0.34485245
Encoder Loss:  0.033013158  || Decoder Loss:  0.027309986 Validation Decoder Loss:  0.34485167
Encoder Loss:  0.03300954  || Decoder Loss:  0.027315333 Validation Decoder Loss:  0.3448956
Encoder Loss:  0.03301793  || Decoder Loss:  0.027316721 Validation Decoder Loss:  0.34490877
Model: siamese_net_lr_0.0005561562304456599 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34490877
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 69, 30, 19, 1)     133       
_________________________________________________________________
reshape_31 (Reshape)         (None, 2070, 19, 1)       0         
=================================================================
Total params: 133
Trainable params: 133
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2753666  || Decoder Loss:  0.058396406 Validation Decoder Loss:  0.36339033
Encoder Loss:  0.27470222  || Decoder Loss:  0.057857323 Validation Decoder Loss:  0.36355206
Encoder Loss:  0.27373287  || Decoder Loss:  0.057478428 Validation Decoder Loss:  0.3631848
Encoder Loss:  0.27177218  || Decoder Loss:  0.05749061 Validation Decoder Loss:  0.36284935
Encoder Loss:  0.26259494  || Decoder Loss:  0.059594728 Validation Decoder Loss:  0.36810982
Encoder Loss:  0.21547417  || Decoder Loss:  0.25344697 Validation Decoder Loss:  0.8719801
Encoder Loss:  0.1367373  || Decoder Loss:  0.19240704 Validation Decoder Loss:  0.59114003
Encoder Loss:  0.09834691  || Decoder Loss:  0.107607394 Validation Decoder Loss:  0.42533326
Encoder Loss:  0.08156837  || Decoder Loss:  0.069787875 Validation Decoder Loss:  0.36309725
Encoder Loss:  0.072875105  || Decoder Loss:  0.052129593 Validation Decoder Loss:  0.345276
Encoder Loss:  0.0691353  || Decoder Loss:  0.0437118 Validation Decoder Loss:  0.33806652
Encoder Loss:  0.06706816  || Decoder Loss:  0.03955892 Validation Decoder Loss:  0.33513966
Encoder Loss:  0.06584025  || Decoder Loss:  0.037559044 Validation Decoder Loss:  0.33391705
Encoder Loss:  0.06490315  || Decoder Loss:  0.036584202 Validation Decoder Loss:  0.33330333
Encoder Loss:  0.053065047  || Decoder Loss:  0.036028497 Validation Decoder Loss:  0.3329236
Encoder Loss:  0.04557771  || Decoder Loss:  0.03569536 Validation Decoder Loss:  0.33270025
Encoder Loss:  0.045386963  || Decoder Loss:  0.035420414 Validation Decoder Loss:  0.33253494
Encoder Loss:  0.045191266  || Decoder Loss:  0.035244007 Validation Decoder Loss:  0.33239162
Encoder Loss:  0.045075342  || Decoder Loss:  0.03509136 Validation Decoder Loss:  0.33226633
Encoder Loss:  0.044968847  || Decoder Loss:  0.034966037 Validation Decoder Loss:  0.332161
Encoder Loss:  0.044871412  || Decoder Loss:  0.034868073 Validation Decoder Loss:  0.33207175
Encoder Loss:  0.04479331  || Decoder Loss:  0.034793653 Validation Decoder Loss:  0.33199644
Encoder Loss:  0.04470849  || Decoder Loss:  0.034733243 Validation Decoder Loss:  0.33192796
Encoder Loss:  0.04465597  || Decoder Loss:  0.034688663 Validation Decoder Loss:  0.33188316
Encoder Loss:  0.044584762  || Decoder Loss:  0.03465298 Validation Decoder Loss:  0.3318485
Encoder Loss:  0.044536795  || Decoder Loss:  0.034627095 Validation Decoder Loss:  0.33181268
Encoder Loss:  0.04446105  || Decoder Loss:  0.03460263 Validation Decoder Loss:  0.3317762
Encoder Loss:  0.04442414  || Decoder Loss:  0.03458227 Validation Decoder Loss:  0.3317611
Encoder Loss:  0.044394802  || Decoder Loss:  0.034566328 Validation Decoder Loss:  0.33174968
Encoder Loss:  0.044321336  || Decoder Loss:  0.034548853 Validation Decoder Loss:  0.33173266
Encoder Loss:  0.04429465  || Decoder Loss:  0.034538295 Validation Decoder Loss:  0.33172113
Encoder Loss:  0.04425101  || Decoder Loss:  0.03452236 Validation Decoder Loss:  0.3317184
Encoder Loss:  0.04427278  || Decoder Loss:  0.034513988 Validation Decoder Loss:  0.33169925
Encoder Loss:  0.044205476  || Decoder Loss:  0.03449835 Validation Decoder Loss:  0.33169168
Encoder Loss:  0.044254065  || Decoder Loss:  0.034496482 Validation Decoder Loss:  0.331675
Encoder Loss:  0.044229083  || Decoder Loss:  0.034483537 Validation Decoder Loss:  0.33166352
Encoder Loss:  0.04411677  || Decoder Loss:  0.034467112 Validation Decoder Loss:  0.3316812
Encoder Loss:  0.044167213  || Decoder Loss:  0.034463003 Validation Decoder Loss:  0.3316644
Encoder Loss:  0.044069186  || Decoder Loss:  0.034449294 Validation Decoder Loss:  0.3316599
Encoder Loss:  0.04413741  || Decoder Loss:  0.034447923 Validation Decoder Loss:  0.3316679
Model: siamese_net_lr_0.0009200591263240054 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3316679
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 414, 5, 19, 1)     289       
_________________________________________________________________
reshape_32 (Reshape)         (None, 2070, 19, 1)       0         
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32683808  || Decoder Loss:  0.064111054 Validation Decoder Loss:  0.36077484
Encoder Loss:  0.32644883  || Decoder Loss:  0.06465281 Validation Decoder Loss:  0.360748
Encoder Loss:  0.32591462  || Decoder Loss:  0.06549011 Validation Decoder Loss:  0.36047196
Encoder Loss:  0.32518765  || Decoder Loss:  0.0667122 Validation Decoder Loss:  0.35999754
Encoder Loss:  0.32414332  || Decoder Loss:  0.068496 Validation Decoder Loss:  0.3594269
Encoder Loss:  0.32254392  || Decoder Loss:  0.07116701 Validation Decoder Loss:  0.35893893
Encoder Loss:  0.31989157  || Decoder Loss:  0.0753779 Validation Decoder Loss:  0.35896856
Encoder Loss:  0.31499112  || Decoder Loss:  0.08262573 Validation Decoder Loss:  0.36093527
Encoder Loss:  0.30440056  || Decoder Loss:  0.09714945 Validation Decoder Loss:  0.37129757
Encoder Loss:  0.27603105  || Decoder Loss:  0.13592483 Validation Decoder Loss:  0.4413523
Encoder Loss:  0.20981367  || Decoder Loss:  0.31314075 Validation Decoder Loss:  0.9783106
Encoder Loss:  0.20862854  || Decoder Loss:  0.42578447 Validation Decoder Loss:  0.7312722
Encoder Loss:  0.1488038  || Decoder Loss:  0.28412953 Validation Decoder Loss:  0.67458135
Encoder Loss:  0.1258761  || Decoder Loss:  0.20537397 Validation Decoder Loss:  0.61693895
Encoder Loss:  0.116507165  || Decoder Loss:  0.17258263 Validation Decoder Loss:  0.54938996
Encoder Loss:  0.104430325  || Decoder Loss:  0.13684309 Validation Decoder Loss:  0.48549408
Encoder Loss:  0.094198465  || Decoder Loss:  0.10517183 Validation Decoder Loss:  0.4324131
Encoder Loss:  0.08597942  || Decoder Loss:  0.07957717 Validation Decoder Loss:  0.39568305
Encoder Loss:  0.08047407  || Decoder Loss:  0.062128697 Validation Decoder Loss:  0.37233192
Encoder Loss:  0.076693304  || Decoder Loss:  0.05160417 Validation Decoder Loss:  0.35819134
Encoder Loss:  0.074711256  || Decoder Loss:  0.045830574 Validation Decoder Loss:  0.34963095
Encoder Loss:  0.07330271  || Decoder Loss:  0.042591345 Validation Decoder Loss:  0.34489575
Encoder Loss:  0.07214159  || Decoder Loss:  0.040580865 Validation Decoder Loss:  0.34199274
Encoder Loss:  0.06859613  || Decoder Loss:  0.039151166 Validation Decoder Loss:  0.33967337
Encoder Loss:  0.05207661  || Decoder Loss:  0.0381771 Validation Decoder Loss:  0.3383313
Encoder Loss:  0.049524378  || Decoder Loss:  0.03727147 Validation Decoder Loss:  0.3373751
Encoder Loss:  0.047769893  || Decoder Loss:  0.036565058 Validation Decoder Loss:  0.33649936
Encoder Loss:  0.046925183  || Decoder Loss:  0.036017466 Validation Decoder Loss:  0.33576524
Encoder Loss:  0.046640452  || Decoder Loss:  0.035635084 Validation Decoder Loss:  0.33518597
Encoder Loss:  0.04651453  || Decoder Loss:  0.035344034 Validation Decoder Loss:  0.33471906
Encoder Loss:  0.046397705  || Decoder Loss:  0.035118207 Validation Decoder Loss:  0.33433935
Encoder Loss:  0.046293434  || Decoder Loss:  0.03494476 Validation Decoder Loss:  0.33404124
Encoder Loss:  0.04619879  || Decoder Loss:  0.03481326 Validation Decoder Loss:  0.3337947
Encoder Loss:  0.046137113  || Decoder Loss:  0.03471178 Validation Decoder Loss:  0.33359742
Encoder Loss:  0.046055604  || Decoder Loss:  0.034632836 Validation Decoder Loss:  0.33342892
Encoder Loss:  0.0460152  || Decoder Loss:  0.034571983 Validation Decoder Loss:  0.33329374
Encoder Loss:  0.045949034  || Decoder Loss:  0.034520607 Validation Decoder Loss:  0.3331728
Encoder Loss:  0.04589144  || Decoder Loss:  0.034479745 Validation Decoder Loss:  0.33307672
Encoder Loss:  0.045828797  || Decoder Loss:  0.034444124 Validation Decoder Loss:  0.33299536
Encoder Loss:  0.045796834  || Decoder Loss:  0.03441314 Validation Decoder Loss:  0.33292395
Model: siamese_net_lr_0.000959354705360572 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33292395
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 514, 5, 19, 1)     137       
_________________________________________________________________
reshape_33 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20657757  || Decoder Loss:  0.03570126 Validation Decoder Loss:  0.3306381
Encoder Loss:  0.20652846  || Decoder Loss:  0.035712652 Validation Decoder Loss:  0.33048308
Encoder Loss:  0.20646809  || Decoder Loss:  0.035728976 Validation Decoder Loss:  0.33031473
Encoder Loss:  0.20639774  || Decoder Loss:  0.035751674 Validation Decoder Loss:  0.33013463
Encoder Loss:  0.20631452  || Decoder Loss:  0.035782967 Validation Decoder Loss:  0.3299424
Encoder Loss:  0.20621312  || Decoder Loss:  0.035826422 Validation Decoder Loss:  0.32973847
Encoder Loss:  0.20608473  || Decoder Loss:  0.035887953 Validation Decoder Loss:  0.32952368
Encoder Loss:  0.20591411  || Decoder Loss:  0.035977732 Validation Decoder Loss:  0.32929558
Encoder Loss:  0.20567127  || Decoder Loss:  0.036113705 Validation Decoder Loss:  0.32904863
Encoder Loss:  0.20528962  || Decoder Loss:  0.036327466 Validation Decoder Loss:  0.32878298
Encoder Loss:  0.20459257  || Decoder Loss:  0.03667483 Validation Decoder Loss:  0.3285261
Encoder Loss:  0.20298074  || Decoder Loss:  0.0372514 Validation Decoder Loss:  0.32840624
Encoder Loss:  0.19742142  || Decoder Loss:  0.03818585 Validation Decoder Loss:  0.3288484
Encoder Loss:  0.15831952  || Decoder Loss:  0.039329298 Validation Decoder Loss:  0.32996726
Encoder Loss:  0.06653131  || Decoder Loss:  0.03805316 Validation Decoder Loss:  0.3296785
Encoder Loss:  0.065373205  || Decoder Loss:  0.036196128 Validation Decoder Loss:  0.3302766
Encoder Loss:  0.06549015  || Decoder Loss:  0.035681475 Validation Decoder Loss:  0.33073032
Encoder Loss:  0.06426521  || Decoder Loss:  0.035518903 Validation Decoder Loss:  0.33091107
Encoder Loss:  0.063593455  || Decoder Loss:  0.035440255 Validation Decoder Loss:  0.33092788
Encoder Loss:  0.06324379  || Decoder Loss:  0.035384964 Validation Decoder Loss:  0.3308854
Encoder Loss:  0.063229986  || Decoder Loss:  0.035342526 Validation Decoder Loss:  0.33083224
Encoder Loss:  0.06278199  || Decoder Loss:  0.035309557 Validation Decoder Loss:  0.3307857
Encoder Loss:  0.06263993  || Decoder Loss:  0.0352839 Validation Decoder Loss:  0.33074746
Encoder Loss:  0.06245913  || Decoder Loss:  0.035263784 Validation Decoder Loss:  0.33071655
Encoder Loss:  0.062288307  || Decoder Loss:  0.035247605 Validation Decoder Loss:  0.33069217
Encoder Loss:  0.06216368  || Decoder Loss:  0.035234727 Validation Decoder Loss:  0.33067304
Encoder Loss:  0.062029853  || Decoder Loss:  0.035223722 Validation Decoder Loss:  0.3306582
Encoder Loss:  0.061863955  || Decoder Loss:  0.035214406 Validation Decoder Loss:  0.33064717
Encoder Loss:  0.061814476  || Decoder Loss:  0.035206195 Validation Decoder Loss:  0.3306392
Encoder Loss:  0.061707806  || Decoder Loss:  0.0351988 Validation Decoder Loss:  0.33063376
Encoder Loss:  0.061496563  || Decoder Loss:  0.035192 Validation Decoder Loss:  0.33063057
Encoder Loss:  0.06155295  || Decoder Loss:  0.03518569 Validation Decoder Loss:  0.33062893
Encoder Loss:  0.061287228  || Decoder Loss:  0.035179704 Validation Decoder Loss:  0.3306288
Encoder Loss:  0.06135699  || Decoder Loss:  0.035174124 Validation Decoder Loss:  0.3306298
Encoder Loss:  0.06117437  || Decoder Loss:  0.035168678 Validation Decoder Loss:  0.3306315
Encoder Loss:  0.061072245  || Decoder Loss:  0.035163607 Validation Decoder Loss:  0.33063403
Encoder Loss:  0.060982957  || Decoder Loss:  0.035158783 Validation Decoder Loss:  0.33063716
Encoder Loss:  0.06092174  || Decoder Loss:  0.03515398 Validation Decoder Loss:  0.33064044
Encoder Loss:  0.06080024  || Decoder Loss:  0.03514962 Validation Decoder Loss:  0.33064413
Encoder Loss:  0.060785327  || Decoder Loss:  0.03514539 Validation Decoder Loss:  0.3306482
Model: siamese_net_lr_0.0006137247526172699 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306482
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 257, 10, 19, 1)    787       
_________________________________________________________________
reshape_34 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058982 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.14749642  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32507354
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 220, 11, 19, 1)    472       
_________________________________________________________________
reshape_35 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 472
Trainable params: 472
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36050063  || Decoder Loss:  0.043857 Validation Decoder Loss:  0.34230283
Encoder Loss:  0.35990104  || Decoder Loss:  0.044314977 Validation Decoder Loss:  0.34125218
Encoder Loss:  0.35916543  || Decoder Loss:  0.04484661 Validation Decoder Loss:  0.34028447
Encoder Loss:  0.3582618  || Decoder Loss:  0.045449134 Validation Decoder Loss:  0.33939028
Encoder Loss:  0.35712874  || Decoder Loss:  0.046120547 Validation Decoder Loss:  0.3385626
Encoder Loss:  0.3556719  || Decoder Loss:  0.046861053 Validation Decoder Loss:  0.33778858
Encoder Loss:  0.35375828  || Decoder Loss:  0.047703113 Validation Decoder Loss:  0.3370318
Encoder Loss:  0.35121307  || Decoder Loss:  0.048728384 Validation Decoder Loss:  0.33624738
Encoder Loss:  0.34779906  || Decoder Loss:  0.050050955 Validation Decoder Loss:  0.3354067
Encoder Loss:  0.34316102  || Decoder Loss:  0.051812463 Validation Decoder Loss:  0.3345032
Encoder Loss:  0.33674312  || Decoder Loss:  0.054214567 Validation Decoder Loss:  0.33356917
Encoder Loss:  0.3276573  || Decoder Loss:  0.05756778 Validation Decoder Loss:  0.33269775
Encoder Loss:  0.31444034  || Decoder Loss:  0.062321957 Validation Decoder Loss:  0.3320527
Encoder Loss:  0.29457548  || Decoder Loss:  0.06877248 Validation Decoder Loss:  0.3314691
Encoder Loss:  0.26318702  || Decoder Loss:  0.07365239 Validation Decoder Loss:  0.32533816
Encoder Loss:  0.20858258  || Decoder Loss:  0.050409492 Validation Decoder Loss:  0.33755726
Encoder Loss:  0.13250954  || Decoder Loss:  0.03793296 Validation Decoder Loss:  0.32996666
Encoder Loss:  0.06854104  || Decoder Loss:  0.038604528 Validation Decoder Loss:  0.32978177
Encoder Loss:  0.06758987  || Decoder Loss:  0.0379252 Validation Decoder Loss:  0.3299592
Encoder Loss:  0.06768701  || Decoder Loss:  0.037447914 Validation Decoder Loss:  0.3299748
Encoder Loss:  0.06743291  || Decoder Loss:  0.03709075 Validation Decoder Loss:  0.3299171
Encoder Loss:  0.0673056  || Decoder Loss:  0.036801226 Validation Decoder Loss:  0.3298354
Encoder Loss:  0.06713124  || Decoder Loss:  0.036564093 Validation Decoder Loss:  0.32975268
Encoder Loss:  0.06703653  || Decoder Loss:  0.036364973 Validation Decoder Loss:  0.32967773
Encoder Loss:  0.06699793  || Decoder Loss:  0.036196906 Validation Decoder Loss:  0.3296152
Encoder Loss:  0.06691916  || Decoder Loss:  0.036053788 Validation Decoder Loss:  0.3295669
Encoder Loss:  0.066714704  || Decoder Loss:  0.035931442 Validation Decoder Loss:  0.3295285
Encoder Loss:  0.06657092  || Decoder Loss:  0.035826694 Validation Decoder Loss:  0.3295003
Encoder Loss:  0.06641472  || Decoder Loss:  0.03573626 Validation Decoder Loss:  0.3294791
Encoder Loss:  0.066265725  || Decoder Loss:  0.035658464 Validation Decoder Loss:  0.32946482
Encoder Loss:  0.066126734  || Decoder Loss:  0.035590477 Validation Decoder Loss:  0.3294556
Encoder Loss:  0.06598994  || Decoder Loss:  0.03553116 Validation Decoder Loss:  0.32945028
Encoder Loss:  0.06586232  || Decoder Loss:  0.035479046 Validation Decoder Loss:  0.32945013
Encoder Loss:  0.065714575  || Decoder Loss:  0.03543289 Validation Decoder Loss:  0.32944658
Encoder Loss:  0.065660365  || Decoder Loss:  0.035392903 Validation Decoder Loss:  0.32945275
Encoder Loss:  0.065500475  || Decoder Loss:  0.0353562 Validation Decoder Loss:  0.3294541
Encoder Loss:  0.06539004  || Decoder Loss:  0.035324264 Validation Decoder Loss:  0.3294602
Encoder Loss:  0.065259054  || Decoder Loss:  0.035294987 Validation Decoder Loss:  0.32946295
Encoder Loss:  0.065178476  || Decoder Loss:  0.03526893 Validation Decoder Loss:  0.32946825
Encoder Loss:  0.06506279  || Decoder Loss:  0.03524499 Validation Decoder Loss:  0.32947278
Model: siamese_net_lr_0.0003266231921641198 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32947278
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 82, 10, 19, 1)     39        
_________________________________________________________________
reshape_36 (Reshape)         (None, 820, 19, 1)        0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 820, 19, 1)        151       
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 2607, 19, 1)       1789      
=================================================================
Total params: 1,789
Trainable params: 1,789
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20469813  || Decoder Loss:  0.0732119 Validation Decoder Loss:  0.3588658
Encoder Loss:  0.20315476  || Decoder Loss:  0.070877306 Validation Decoder Loss:  0.35878143
Encoder Loss:  0.20157331  || Decoder Loss:  0.06849889 Validation Decoder Loss:  0.35910374
Encoder Loss:  0.200094  || Decoder Loss:  0.06629667 Validation Decoder Loss:  0.35970795
Encoder Loss:  0.19871561  || Decoder Loss:  0.06427686 Validation Decoder Loss:  0.36048868
Encoder Loss:  0.19742586  || Decoder Loss:  0.062430196 Validation Decoder Loss:  0.3613943
Encoder Loss:  0.19621024  || Decoder Loss:  0.060747758 Validation Decoder Loss:  0.36240938
Encoder Loss:  0.19504997  || Decoder Loss:  0.059221607 Validation Decoder Loss:  0.36354172
Encoder Loss:  0.19391662  || Decoder Loss:  0.05784595 Validation Decoder Loss:  0.3648213
Encoder Loss:  0.19276088  || Decoder Loss:  0.056620173 Validation Decoder Loss:  0.3663187
Encoder Loss:  0.19147995  || Decoder Loss:  0.055558305 Validation Decoder Loss:  0.36821657
Encoder Loss:  0.18980257  || Decoder Loss:  0.054721963 Validation Decoder Loss:  0.37108052
Encoder Loss:  0.18670925  || Decoder Loss:  0.054380678 Validation Decoder Loss:  0.3773418
Encoder Loss:  0.1752674  || Decoder Loss:  0.056755956 Validation Decoder Loss:  0.41800913
Encoder Loss:  0.2645717  || Decoder Loss:  0.314467 Validation Decoder Loss:  1.3564928
Encoder Loss:  0.26537192  || Decoder Loss:  0.34535846 Validation Decoder Loss:  1.2532026
Encoder Loss:  0.24614254  || Decoder Loss:  0.31614628 Validation Decoder Loss:  1.1708151
Encoder Loss:  0.229536  || Decoder Loss:  0.2921936 Validation Decoder Loss:  1.1049414
Encoder Loss:  0.2072046  || Decoder Loss:  0.25908145 Validation Decoder Loss:  1.0375336
Encoder Loss:  0.18326366  || Decoder Loss:  0.22288425 Validation Decoder Loss:  0.9674536
Encoder Loss:  0.1602375  || Decoder Loss:  0.1876607 Validation Decoder Loss:  0.88000643
Encoder Loss:  0.13723898  || Decoder Loss:  0.15254335 Validation Decoder Loss:  0.77985334
Encoder Loss:  0.11559543  || Decoder Loss:  0.11950298 Validation Decoder Loss:  0.6961361
Encoder Loss:  0.10028395  || Decoder Loss:  0.09602049 Validation Decoder Loss:  0.62124753
Encoder Loss:  0.08817462  || Decoder Loss:  0.07762769 Validation Decoder Loss:  0.5681859
Encoder Loss:  0.08021883  || Decoder Loss:  0.065525934 Validation Decoder Loss:  0.5296942
Encoder Loss:  0.07479764  || Decoder Loss:  0.057302836 Validation Decoder Loss:  0.4993355
Encoder Loss:  0.071008675  || Decoder Loss:  0.051528927 Validation Decoder Loss:  0.47510558
Encoder Loss:  0.06833684  || Decoder Loss:  0.047571592 Validation Decoder Loss:  0.45638347
Encoder Loss:  0.06643141  || Decoder Loss:  0.04475445 Validation Decoder Loss:  0.44056526
Encoder Loss:  0.06496662  || Decoder Loss:  0.0426575 Validation Decoder Loss:  0.42752838
Encoder Loss:  0.063853264  || Decoder Loss:  0.04103972 Validation Decoder Loss:  0.41569042
Encoder Loss:  0.062903106  || Decoder Loss:  0.039713033 Validation Decoder Loss:  0.40537766
Encoder Loss:  0.062077064  || Decoder Loss:  0.038606513 Validation Decoder Loss:  0.3965191
Encoder Loss:  0.061327796  || Decoder Loss:  0.037661303 Validation Decoder Loss:  0.3889513
Encoder Loss:  0.06067051  || Decoder Loss:  0.036831584 Validation Decoder Loss:  0.38203663
Encoder Loss:  0.059830967  || Decoder Loss:  0.03610018 Validation Decoder Loss:  0.3768114
Encoder Loss:  0.05885818  || Decoder Loss:  0.035453435 Validation Decoder Loss:  0.37171185
Encoder Loss:  0.056109246  || Decoder Loss:  0.034854006 Validation Decoder Loss:  0.3673538
Encoder Loss:  0.044307765  || Decoder Loss:  0.03433382 Validation Decoder Loss:  0.35964084
Model: siamese_net_lr_0.0006032529222686687 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35964084
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 110, 22, 19, 1)    847       
_________________________________________________________________
reshape_37 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 847
Trainable params: 847
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29229054  || Decoder Loss:  0.05104622 Validation Decoder Loss:  0.33948845
Encoder Loss:  0.29204398  || Decoder Loss:  0.05147197 Validation Decoder Loss:  0.33944482
Encoder Loss:  0.29175305  || Decoder Loss:  0.05195517 Validation Decoder Loss:  0.3394461
Encoder Loss:  0.29143295  || Decoder Loss:  0.05246274 Validation Decoder Loss:  0.33949366
Encoder Loss:  0.29108268  || Decoder Loss:  0.052993406 Validation Decoder Loss:  0.33958563
Encoder Loss:  0.29069895  || Decoder Loss:  0.05354875 Validation Decoder Loss:  0.3397219
Encoder Loss:  0.29027796  || Decoder Loss:  0.0541302 Validation Decoder Loss:  0.33990413
Encoder Loss:  0.28981495  || Decoder Loss:  0.05473889 Validation Decoder Loss:  0.3401348
Encoder Loss:  0.28930423  || Decoder Loss:  0.055376004 Validation Decoder Loss:  0.34041673
Encoder Loss:  0.28873956  || Decoder Loss:  0.056043494 Validation Decoder Loss:  0.34075296
Encoder Loss:  0.28811392  || Decoder Loss:  0.056744564 Validation Decoder Loss:  0.34114683
Encoder Loss:  0.28742003  || Decoder Loss:  0.057483736 Validation Decoder Loss:  0.34160137
Encoder Loss:  0.2866501  || Decoder Loss:  0.058266398 Validation Decoder Loss:  0.34211928
Encoder Loss:  0.28579548  || Decoder Loss:  0.05909853 Validation Decoder Loss:  0.34270275
Encoder Loss:  0.28484607  || Decoder Loss:  0.05998627 Validation Decoder Loss:  0.34335357
Encoder Loss:  0.28379008  || Decoder Loss:  0.060935766 Validation Decoder Loss:  0.3440737
Encoder Loss:  0.2826134  || Decoder Loss:  0.06195293 Validation Decoder Loss:  0.34486523
Encoder Loss:  0.281299  || Decoder Loss:  0.06304341 Validation Decoder Loss:  0.34573132
Encoder Loss:  0.27982578  || Decoder Loss:  0.06421213 Validation Decoder Loss:  0.34667674
Encoder Loss:  0.27816814  || Decoder Loss:  0.0654626 Validation Decoder Loss:  0.34770787
Encoder Loss:  0.27629432  || Decoder Loss:  0.066795275 Validation Decoder Loss:  0.34883308
Encoder Loss:  0.2741641  || Decoder Loss:  0.06820431 Validation Decoder Loss:  0.35006198
Encoder Loss:  0.27172565  || Decoder Loss:  0.06966972 Validation Decoder Loss:  0.351404
Encoder Loss:  0.26890746  || Decoder Loss:  0.071139544 Validation Decoder Loss:  0.35286036
Encoder Loss:  0.26559895  || Decoder Loss:  0.07248486 Validation Decoder Loss:  0.35439962
Encoder Loss:  0.26159945  || Decoder Loss:  0.07336953 Validation Decoder Loss:  0.3558939
Encoder Loss:  0.25643373  || Decoder Loss:  0.07277142 Validation Decoder Loss:  0.35700983
Encoder Loss:  0.24837065  || Decoder Loss:  0.066384904 Validation Decoder Loss:  0.36096472
Encoder Loss:  0.23496264  || Decoder Loss:  0.048067883 Validation Decoder Loss:  0.3659267
Encoder Loss:  0.22503732  || Decoder Loss:  0.04173061 Validation Decoder Loss:  0.35433668
Encoder Loss:  0.21535146  || Decoder Loss:  0.039307103 Validation Decoder Loss:  0.34486178
Encoder Loss:  0.20472163  || Decoder Loss:  0.038347963 Validation Decoder Loss:  0.33968633
Encoder Loss:  0.19247904  || Decoder Loss:  0.037962295 Validation Decoder Loss:  0.337157
Encoder Loss:  0.17807207  || Decoder Loss:  0.03782631 Validation Decoder Loss:  0.3358488
Encoder Loss:  0.16091326  || Decoder Loss:  0.03783118 Validation Decoder Loss:  0.33504218
Encoder Loss:  0.14034091  || Decoder Loss:  0.03791903 Validation Decoder Loss:  0.33439505
Encoder Loss:  0.11577984  || Decoder Loss:  0.038038153 Validation Decoder Loss:  0.3337555
Encoder Loss:  0.08721763  || Decoder Loss:  0.03814357 Validation Decoder Loss:  0.3330975
Encoder Loss:  0.0633852  || Decoder Loss:  0.038136095 Validation Decoder Loss:  0.33250335
Encoder Loss:  0.06394093  || Decoder Loss:  0.037758246 Validation Decoder Loss:  0.33210248
Model: siamese_net_lr_0.0003407461921597056 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3321025
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 210, 12, 19, 1)    337       
_________________________________________________________________
reshape_38 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 337
Trainable params: 337
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4417988  || Decoder Loss:  0.03916323 Validation Decoder Loss:  0.32905072
Encoder Loss:  0.44090503  || Decoder Loss:  0.03968758 Validation Decoder Loss:  0.32853818
Encoder Loss:  0.43974096  || Decoder Loss:  0.040377732 Validation Decoder Loss:  0.3280581
Encoder Loss:  0.4381755  || Decoder Loss:  0.041310053 Validation Decoder Loss:  0.32762912
Encoder Loss:  0.43599486  || Decoder Loss:  0.04259701 Validation Decoder Loss:  0.32728893
Encoder Loss:  0.43281356  || Decoder Loss:  0.044407032 Validation Decoder Loss:  0.3271097
Encoder Loss:  0.4278659  || Decoder Loss:  0.046928506 Validation Decoder Loss:  0.32712752
Encoder Loss:  0.41941082  || Decoder Loss:  0.04981403 Validation Decoder Loss:  0.3263187
Encoder Loss:  0.40257645  || Decoder Loss:  0.046081953 Validation Decoder Loss:  0.32502347
Encoder Loss:  0.35763255  || Decoder Loss:  0.035448283 Validation Decoder Loss:  0.32783538
Encoder Loss:  0.17602609  || Decoder Loss:  0.035486385 Validation Decoder Loss:  0.32788283
Encoder Loss:  0.09930931  || Decoder Loss:  0.0355203 Validation Decoder Loss:  0.32795447
Encoder Loss:  0.0985577  || Decoder Loss:  0.03544017 Validation Decoder Loss:  0.32803816
Encoder Loss:  0.09838643  || Decoder Loss:  0.035380796 Validation Decoder Loss:  0.32813013
Encoder Loss:  0.09827826  || Decoder Loss:  0.035332724 Validation Decoder Loss:  0.328229
Encoder Loss:  0.09797821  || Decoder Loss:  0.03529297 Validation Decoder Loss:  0.32831758
Encoder Loss:  0.0978879  || Decoder Loss:  0.035260152 Validation Decoder Loss:  0.32840157
Encoder Loss:  0.0978492  || Decoder Loss:  0.03523203 Validation Decoder Loss:  0.3284866
Encoder Loss:  0.09760333  || Decoder Loss:  0.035207998 Validation Decoder Loss:  0.32856315
Encoder Loss:  0.097479075  || Decoder Loss:  0.03518742 Validation Decoder Loss:  0.32863438
Encoder Loss:  0.097340114  || Decoder Loss:  0.03516977 Validation Decoder Loss:  0.32870018
Encoder Loss:  0.09717679  || Decoder Loss:  0.03515463 Validation Decoder Loss:  0.3287627
Encoder Loss:  0.09688256  || Decoder Loss:  0.035141684 Validation Decoder Loss:  0.32881725
Encoder Loss:  0.096658394  || Decoder Loss:  0.03513044 Validation Decoder Loss:  0.32886922
Encoder Loss:  0.0961475  || Decoder Loss:  0.035120778 Validation Decoder Loss:  0.32891315
Encoder Loss:  0.095420286  || Decoder Loss:  0.035112355 Validation Decoder Loss:  0.32895392
Encoder Loss:  0.09288344  || Decoder Loss:  0.035104785 Validation Decoder Loss:  0.32899252
Encoder Loss:  0.06711962  || Decoder Loss:  0.035096265 Validation Decoder Loss:  0.32904583
Encoder Loss:  0.055518948  || Decoder Loss:  0.0350839 Validation Decoder Loss:  0.32904685
Encoder Loss:  0.055269383  || Decoder Loss:  0.0350708 Validation Decoder Loss:  0.32905278
Encoder Loss:  0.055128932  || Decoder Loss:  0.035060875 Validation Decoder Loss:  0.32906684
Encoder Loss:  0.054996442  || Decoder Loss:  0.035054527 Validation Decoder Loss:  0.32908523
Encoder Loss:  0.054880075  || Decoder Loss:  0.035049096 Validation Decoder Loss:  0.3291036
Encoder Loss:  0.054755025  || Decoder Loss:  0.035043634 Validation Decoder Loss:  0.3291211
Encoder Loss:  0.054618668  || Decoder Loss:  0.03503847 Validation Decoder Loss:  0.32914162
Encoder Loss:  0.054513726  || Decoder Loss:  0.03503271 Validation Decoder Loss:  0.32915816
Encoder Loss:  0.05438942  || Decoder Loss:  0.03502625 Validation Decoder Loss:  0.3291788
Encoder Loss:  0.05427039  || Decoder Loss:  0.035020337 Validation Decoder Loss:  0.3292
Encoder Loss:  0.05416335  || Decoder Loss:  0.035013847 Validation Decoder Loss:  0.3292204
Encoder Loss:  0.054064497  || Decoder Loss:  0.0350072 Validation Decoder Loss:  0.32924265
Model: siamese_net_lr_0.00029897661120785197 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32924262
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 514, 5, 19, 1)     74        
_________________________________________________________________
reshape_39 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642546 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642534 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642546 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642546 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219346
Encoder Loss:  0.29112253  || Decoder Loss:  0.035642542 Validation Decoder Loss:  0.33219343
Encoder Loss:  0.29112253  || Decoder Loss:  0.03564254 Validation Decoder Loss:  0.33219343
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33219343
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 345, 6, 19, 1)     313       
_________________________________________________________________
reshape_40 (Reshape)         (None, 2070, 19, 1)       0         
=================================================================
Total params: 313
Trainable params: 313
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06404206  || Decoder Loss:  0.06404206 Validation Decoder Loss:  0.36020598
Encoder Loss:  0.06088897  || Decoder Loss:  0.06088897 Validation Decoder Loss:  0.35241038
Encoder Loss:  0.058656253  || Decoder Loss:  0.058656253 Validation Decoder Loss:  0.34646434
Encoder Loss:  0.05554247  || Decoder Loss:  0.05554247 Validation Decoder Loss:  0.34130824
Encoder Loss:  0.035762627  || Decoder Loss:  0.035762627 Validation Decoder Loss:  0.3476112
Encoder Loss:  0.03221903  || Decoder Loss:  0.03221903 Validation Decoder Loss:  0.3443603
Encoder Loss:  0.031996988  || Decoder Loss:  0.031996988 Validation Decoder Loss:  0.34421945
Encoder Loss:  0.0318738  || Decoder Loss:  0.0318738 Validation Decoder Loss:  0.34429604
Encoder Loss:  0.03177495  || Decoder Loss:  0.03177495 Validation Decoder Loss:  0.34442678
Encoder Loss:  0.031687297  || Decoder Loss:  0.031687297 Validation Decoder Loss:  0.34458798
Encoder Loss:  0.031606335  || Decoder Loss:  0.031606335 Validation Decoder Loss:  0.34477443
Encoder Loss:  0.031530038  || Decoder Loss:  0.031530038 Validation Decoder Loss:  0.34498286
Encoder Loss:  0.03145754  || Decoder Loss:  0.03145754 Validation Decoder Loss:  0.34520787
Encoder Loss:  0.03138865  || Decoder Loss:  0.03138865 Validation Decoder Loss:  0.34544098
Encoder Loss:  0.03132347  || Decoder Loss:  0.03132347 Validation Decoder Loss:  0.3456728
Encoder Loss:  0.03126222  || Decoder Loss:  0.03126222 Validation Decoder Loss:  0.34589523
Encoder Loss:  0.03120505  || Decoder Loss:  0.03120505 Validation Decoder Loss:  0.34610322
Encoder Loss:  0.031151999  || Decoder Loss:  0.031151999 Validation Decoder Loss:  0.3462938
Encoder Loss:  0.031102955  || Decoder Loss:  0.031102955 Validation Decoder Loss:  0.34646648
Encoder Loss:  0.031057708  || Decoder Loss:  0.031057708 Validation Decoder Loss:  0.3466221
Encoder Loss:  0.031015947  || Decoder Loss:  0.031015947 Validation Decoder Loss:  0.3467626
Encoder Loss:  0.030977316  || Decoder Loss:  0.030977316 Validation Decoder Loss:  0.3468902
Encoder Loss:  0.030941524  || Decoder Loss:  0.030941524 Validation Decoder Loss:  0.34700716
Encoder Loss:  0.030908236  || Decoder Loss:  0.030908236 Validation Decoder Loss:  0.34711546
Encoder Loss:  0.030877158  || Decoder Loss:  0.030877158 Validation Decoder Loss:  0.34721678
Encoder Loss:  0.030848052  || Decoder Loss:  0.030848052 Validation Decoder Loss:  0.3473125
Encoder Loss:  0.030820716  || Decoder Loss:  0.030820716 Validation Decoder Loss:  0.34740362
Encoder Loss:  0.030794928  || Decoder Loss:  0.030794928 Validation Decoder Loss:  0.347491
Encoder Loss:  0.030770525  || Decoder Loss:  0.030770525 Validation Decoder Loss:  0.3475753
Encoder Loss:  0.030747376  || Decoder Loss:  0.030747376 Validation Decoder Loss:  0.34765702
Encoder Loss:  0.03072536  || Decoder Loss:  0.03072536 Validation Decoder Loss:  0.34773642
Encoder Loss:  0.03070433  || Decoder Loss:  0.03070433 Validation Decoder Loss:  0.34781384
Encoder Loss:  0.030684233  || Decoder Loss:  0.030684233 Validation Decoder Loss:  0.34788954
Encoder Loss:  0.030664979  || Decoder Loss:  0.030664979 Validation Decoder Loss:  0.34796357
Encoder Loss:  0.030646496  || Decoder Loss:  0.030646496 Validation Decoder Loss:  0.3480361
Encoder Loss:  0.030628726  || Decoder Loss:  0.030628726 Validation Decoder Loss:  0.34810734
Encoder Loss:  0.030611599  || Decoder Loss:  0.030611599 Validation Decoder Loss:  0.34817716
Encoder Loss:  0.030595096  || Decoder Loss:  0.030595096 Validation Decoder Loss:  0.3482457
Encoder Loss:  0.030579142  || Decoder Loss:  0.030579142 Validation Decoder Loss:  0.348313
Encoder Loss:  0.030563736  || Decoder Loss:  0.030563736 Validation Decoder Loss:  0.34837914
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34837914
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 120, 21, 19, 1)    742       
_________________________________________________________________
reshape_41 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 742
Trainable params: 742
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33868358  || Decoder Loss:  0.04498892 Validation Decoder Loss:  0.32837474
Encoder Loss:  0.33695933  || Decoder Loss:  0.04662183 Validation Decoder Loss:  0.32861924
Encoder Loss:  0.33489716  || Decoder Loss:  0.048519917 Validation Decoder Loss:  0.3291645
Encoder Loss:  0.3323868  || Decoder Loss:  0.050733484 Validation Decoder Loss:  0.33004326
Encoder Loss:  0.32928875  || Decoder Loss:  0.053289223 Validation Decoder Loss:  0.33125284
Encoder Loss:  0.32538942  || Decoder Loss:  0.05613051 Validation Decoder Loss:  0.3326604
Encoder Loss:  0.32028684  || Decoder Loss:  0.058841422 Validation Decoder Loss:  0.33356315
Encoder Loss:  0.31277153  || Decoder Loss:  0.058465175 Validation Decoder Loss:  0.32861823
Encoder Loss:  0.29798657  || Decoder Loss:  0.03860897 Validation Decoder Loss:  0.3324107
Encoder Loss:  0.2833786  || Decoder Loss:  0.03517573 Validation Decoder Loss:  0.33183706
Encoder Loss:  0.2629949  || Decoder Loss:  0.035012215 Validation Decoder Loss:  0.33118677
Encoder Loss:  0.23019153  || Decoder Loss:  0.03494567 Validation Decoder Loss:  0.33024713
Encoder Loss:  0.17211227  || Decoder Loss:  0.035029948 Validation Decoder Loss:  0.3290422
Encoder Loss:  0.08583522  || Decoder Loss:  0.035244077 Validation Decoder Loss:  0.32842213
Encoder Loss:  0.07219297  || Decoder Loss:  0.035235405 Validation Decoder Loss:  0.32852793
Encoder Loss:  0.071932696  || Decoder Loss:  0.03517571 Validation Decoder Loss:  0.32862067
Encoder Loss:  0.0717913  || Decoder Loss:  0.035127312 Validation Decoder Loss:  0.3287059
Encoder Loss:  0.07166764  || Decoder Loss:  0.035087552 Validation Decoder Loss:  0.32878566
Encoder Loss:  0.071521446  || Decoder Loss:  0.03505451 Validation Decoder Loss:  0.32885706
Encoder Loss:  0.071384914  || Decoder Loss:  0.0350268 Validation Decoder Loss:  0.32891974
Encoder Loss:  0.071221784  || Decoder Loss:  0.035003804 Validation Decoder Loss:  0.32897282
Encoder Loss:  0.07106296  || Decoder Loss:  0.034984373 Validation Decoder Loss:  0.3290205
Encoder Loss:  0.07083951  || Decoder Loss:  0.0349677 Validation Decoder Loss:  0.32905808
Encoder Loss:  0.07059703  || Decoder Loss:  0.034953367 Validation Decoder Loss:  0.3290903
Encoder Loss:  0.07021222  || Decoder Loss:  0.034940835 Validation Decoder Loss:  0.32911456
Encoder Loss:  0.069592096  || Decoder Loss:  0.034929868 Validation Decoder Loss:  0.3291329
Encoder Loss:  0.067971446  || Decoder Loss:  0.034919962 Validation Decoder Loss:  0.32914978
Encoder Loss:  0.05679614  || Decoder Loss:  0.03491052 Validation Decoder Loss:  0.3291918
Encoder Loss:  0.04891915  || Decoder Loss:  0.034919683 Validation Decoder Loss:  0.32922566
Encoder Loss:  0.048763245  || Decoder Loss:  0.03493022 Validation Decoder Loss:  0.3292513
Encoder Loss:  0.04867457  || Decoder Loss:  0.034932967 Validation Decoder Loss:  0.32927215
Encoder Loss:  0.048618056  || Decoder Loss:  0.034933552 Validation Decoder Loss:  0.32929057
Encoder Loss:  0.048567433  || Decoder Loss:  0.034933683 Validation Decoder Loss:  0.32930654
Encoder Loss:  0.04851864  || Decoder Loss:  0.03493477 Validation Decoder Loss:  0.32932115
Encoder Loss:  0.04846166  || Decoder Loss:  0.034937073 Validation Decoder Loss:  0.32933557
Encoder Loss:  0.048405718  || Decoder Loss:  0.034940116 Validation Decoder Loss:  0.3293503
Encoder Loss:  0.048345517  || Decoder Loss:  0.034943577 Validation Decoder Loss:  0.3293653
Encoder Loss:  0.048287217  || Decoder Loss:  0.03494781 Validation Decoder Loss:  0.32938206
Encoder Loss:  0.048222896  || Decoder Loss:  0.034952365 Validation Decoder Loss:  0.32940114
Encoder Loss:  0.04816382  || Decoder Loss:  0.034957483 Validation Decoder Loss:  0.32942325
Model: siamese_net_lr_0.00017384973520033866 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32942325
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 126, 20, 19, 1)    757       
_________________________________________________________________
reshape_42 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 757
Trainable params: 757
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3317001  || Decoder Loss:  0.049206596 Validation Decoder Loss:  0.33114928
Encoder Loss:  0.3014346  || Decoder Loss:  0.048072394 Validation Decoder Loss:  0.3336021
Encoder Loss:  0.12394448  || Decoder Loss:  0.035018064 Validation Decoder Loss:  0.32819277
Encoder Loss:  0.07244109  || Decoder Loss:  0.0350409 Validation Decoder Loss:  0.32844216
Encoder Loss:  0.07072706  || Decoder Loss:  0.034947407 Validation Decoder Loss:  0.3285688
Encoder Loss:  0.05184257  || Decoder Loss:  0.03490625 Validation Decoder Loss:  0.3288194
Encoder Loss:  0.05039649  || Decoder Loss:  0.034915704 Validation Decoder Loss:  0.32886928
Encoder Loss:  0.050146762  || Decoder Loss:  0.03491797 Validation Decoder Loss:  0.3289137
Encoder Loss:  0.049964175  || Decoder Loss:  0.03492677 Validation Decoder Loss:  0.32900387
Encoder Loss:  0.04977887  || Decoder Loss:  0.034941696 Validation Decoder Loss:  0.32910967
Encoder Loss:  0.04957008  || Decoder Loss:  0.034955535 Validation Decoder Loss:  0.32923487
Encoder Loss:  0.04940367  || Decoder Loss:  0.034967877 Validation Decoder Loss:  0.32936162
Encoder Loss:  0.049191814  || Decoder Loss:  0.034978986 Validation Decoder Loss:  0.32946616
Encoder Loss:  0.04900544  || Decoder Loss:  0.03499426 Validation Decoder Loss:  0.32952756
Encoder Loss:  0.048718568  || Decoder Loss:  0.035005815 Validation Decoder Loss:  0.32956317
Encoder Loss:  0.048474666  || Decoder Loss:  0.03501134 Validation Decoder Loss:  0.32960403
Encoder Loss:  0.048157528  || Decoder Loss:  0.03500901 Validation Decoder Loss:  0.32966122
Encoder Loss:  0.047969937  || Decoder Loss:  0.034993857 Validation Decoder Loss:  0.32970205
Encoder Loss:  0.047765117  || Decoder Loss:  0.034978144 Validation Decoder Loss:  0.32975098
Encoder Loss:  0.047412146  || Decoder Loss:  0.034959793 Validation Decoder Loss:  0.3297996
Encoder Loss:  0.047186922  || Decoder Loss:  0.034942593 Validation Decoder Loss:  0.32983458
Encoder Loss:  0.047030278  || Decoder Loss:  0.03493706 Validation Decoder Loss:  0.32987162
Encoder Loss:  0.046989754  || Decoder Loss:  0.034937542 Validation Decoder Loss:  0.32988858
Encoder Loss:  0.046909112  || Decoder Loss:  0.034940477 Validation Decoder Loss:  0.3299138
Encoder Loss:  0.046874955  || Decoder Loss:  0.034945145 Validation Decoder Loss:  0.32992274
Encoder Loss:  0.046971902  || Decoder Loss:  0.03495356 Validation Decoder Loss:  0.3299243
Encoder Loss:  0.046848163  || Decoder Loss:  0.034958348 Validation Decoder Loss:  0.32994407
Encoder Loss:  0.046948332  || Decoder Loss:  0.034965735 Validation Decoder Loss:  0.32994652
Encoder Loss:  0.046850134  || Decoder Loss:  0.034969494 Validation Decoder Loss:  0.3299494
Encoder Loss:  0.046995822  || Decoder Loss:  0.034976393 Validation Decoder Loss:  0.329947
Encoder Loss:  0.046797518  || Decoder Loss:  0.034979355 Validation Decoder Loss:  0.3299598
Encoder Loss:  0.04678856  || Decoder Loss:  0.03498577 Validation Decoder Loss:  0.32997188
Encoder Loss:  0.046931677  || Decoder Loss:  0.034994975 Validation Decoder Loss:  0.32997566
Encoder Loss:  0.046908807  || Decoder Loss:  0.034997962 Validation Decoder Loss:  0.3299648
Encoder Loss:  0.046763316  || Decoder Loss:  0.034999713 Validation Decoder Loss:  0.32997572
Encoder Loss:  0.04675964  || Decoder Loss:  0.03500492 Validation Decoder Loss:  0.3299865
Encoder Loss:  0.046787225  || Decoder Loss:  0.03501164 Validation Decoder Loss:  0.32998824
Encoder Loss:  0.04693593  || Decoder Loss:  0.035015956 Validation Decoder Loss:  0.32997447
Encoder Loss:  0.046776827  || Decoder Loss:  0.035018057 Validation Decoder Loss:  0.32998973
Encoder Loss:  0.046762384  || Decoder Loss:  0.035022415 Validation Decoder Loss:  0.32999396
Model: siamese_net_lr_0.000409271536878615 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.329994
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 504, 5, 19, 1)     127       
_________________________________________________________________
reshape_43 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17684978  || Decoder Loss:  0.03698349 Validation Decoder Loss:  0.33440647
Encoder Loss:  0.17681356  || Decoder Loss:  0.036987275 Validation Decoder Loss:  0.3343247
Encoder Loss:  0.17677179  || Decoder Loss:  0.036995992 Validation Decoder Loss:  0.33424345
Encoder Loss:  0.17672725  || Decoder Loss:  0.037012093 Validation Decoder Loss:  0.3341645
Encoder Loss:  0.17667979  || Decoder Loss:  0.037037794 Validation Decoder Loss:  0.3340884
Encoder Loss:  0.17662868  || Decoder Loss:  0.03707604 Validation Decoder Loss:  0.33401623
Encoder Loss:  0.17657278  || Decoder Loss:  0.037131112 Validation Decoder Loss:  0.33395004
Encoder Loss:  0.17651056  || Decoder Loss:  0.03720939 Validation Decoder Loss:  0.33389285
Encoder Loss:  0.1764394  || Decoder Loss:  0.037320808 Validation Decoder Loss:  0.33384928
Encoder Loss:  0.17635489  || Decoder Loss:  0.03748143 Validation Decoder Loss:  0.33382735
Encoder Loss:  0.1762484  || Decoder Loss:  0.037718795 Validation Decoder Loss:  0.3338438
Encoder Loss:  0.17610136  || Decoder Loss:  0.038083598 Validation Decoder Loss:  0.33393767
Encoder Loss:  0.17586748  || Decoder Loss:  0.038678754 Validation Decoder Loss:  0.33420908
Encoder Loss:  0.1754057  || Decoder Loss:  0.039741922 Validation Decoder Loss:  0.33495364
Encoder Loss:  0.17413789  || Decoder Loss:  0.041926265 Validation Decoder Loss:  0.33726066
Encoder Loss:  0.16821282  || Decoder Loss:  0.047495462 Validation Decoder Loss:  0.34643435
Encoder Loss:  0.120100744  || Decoder Loss:  0.0666403 Validation Decoder Loss:  0.38861585
Encoder Loss:  0.091593444  || Decoder Loss:  0.06462536 Validation Decoder Loss:  0.34280133
Encoder Loss:  0.06694687  || Decoder Loss:  0.048258916 Validation Decoder Loss:  0.3358107
Encoder Loss:  0.064771295  || Decoder Loss:  0.042963214 Validation Decoder Loss:  0.33219907
Encoder Loss:  0.06388197  || Decoder Loss:  0.039945778 Validation Decoder Loss:  0.3303896
Encoder Loss:  0.06203212  || Decoder Loss:  0.038087074 Validation Decoder Loss:  0.3296103
Encoder Loss:  0.06114602  || Decoder Loss:  0.036958307 Validation Decoder Loss:  0.32934806
Encoder Loss:  0.06059411  || Decoder Loss:  0.036280073 Validation Decoder Loss:  0.32934842
Encoder Loss:  0.060165945  || Decoder Loss:  0.035888158 Validation Decoder Loss:  0.32946375
Encoder Loss:  0.059866417  || Decoder Loss:  0.035672907 Validation Decoder Loss:  0.32960963
Encoder Loss:  0.05970448  || Decoder Loss:  0.035560112 Validation Decoder Loss:  0.3297414
Encoder Loss:  0.05960166  || Decoder Loss:  0.03550521 Validation Decoder Loss:  0.3298418
Encoder Loss:  0.059580237  || Decoder Loss:  0.03547679 Validation Decoder Loss:  0.3299101
Encoder Loss:  0.059441075  || Decoder Loss:  0.035460435 Validation Decoder Loss:  0.32995203
Encoder Loss:  0.059365034  || Decoder Loss:  0.035450082 Validation Decoder Loss:  0.3299762
Encoder Loss:  0.059393514  || Decoder Loss:  0.035441503 Validation Decoder Loss:  0.3299904
Encoder Loss:  0.05927732  || Decoder Loss:  0.035433404 Validation Decoder Loss:  0.32999766
Encoder Loss:  0.059296366  || Decoder Loss:  0.035426144 Validation Decoder Loss:  0.33000264
Encoder Loss:  0.05911824  || Decoder Loss:  0.03541917 Validation Decoder Loss:  0.33000413
Encoder Loss:  0.059193395  || Decoder Loss:  0.03541297 Validation Decoder Loss:  0.33000672
Encoder Loss:  0.059168003  || Decoder Loss:  0.035405815 Validation Decoder Loss:  0.33000863
Encoder Loss:  0.059049774  || Decoder Loss:  0.035399914 Validation Decoder Loss:  0.33000982
Encoder Loss:  0.05907728  || Decoder Loss:  0.035393275 Validation Decoder Loss:  0.3300125
Encoder Loss:  0.058986235  || Decoder Loss:  0.035386987 Validation Decoder Loss:  0.3300141
Model: siamese_net_lr_0.0005149202568486276 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3300141
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 217, 10, 19, 1)    547       
_________________________________________________________________
reshape_44 (Reshape)         (None, 2170, 19, 1)       0         
=================================================================
Total params: 547
Trainable params: 547
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 2170, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 2607, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2753253  || Decoder Loss:  0.073752806 Validation Decoder Loss:  0.3762153
Encoder Loss:  0.13758828  || Decoder Loss:  0.092769936 Validation Decoder Loss:  0.3501302
Encoder Loss:  0.06771111  || Decoder Loss:  0.038696427 Validation Decoder Loss:  0.33405158
Encoder Loss:  0.048605967  || Decoder Loss:  0.03497856 Validation Decoder Loss:  0.33298635
Encoder Loss:  0.04610346  || Decoder Loss:  0.03416729 Validation Decoder Loss:  0.3334309
Encoder Loss:  0.0454102  || Decoder Loss:  0.033752028 Validation Decoder Loss:  0.3338514
Encoder Loss:  0.045130488  || Decoder Loss:  0.03351014 Validation Decoder Loss:  0.33413947
Encoder Loss:  0.04509582  || Decoder Loss:  0.03330939 Validation Decoder Loss:  0.33422178
Encoder Loss:  0.044798777  || Decoder Loss:  0.033102598 Validation Decoder Loss:  0.33425122
Encoder Loss:  0.044600524  || Decoder Loss:  0.032917675 Validation Decoder Loss:  0.3341413
Encoder Loss:  0.0444599  || Decoder Loss:  0.032755833 Validation Decoder Loss:  0.3339514
Encoder Loss:  0.04441881  || Decoder Loss:  0.032616857 Validation Decoder Loss:  0.33379346
Encoder Loss:  0.04401732  || Decoder Loss:  0.03248553 Validation Decoder Loss:  0.33352137
Encoder Loss:  0.043768488  || Decoder Loss:  0.03238458 Validation Decoder Loss:  0.3333556
Encoder Loss:  0.04362576  || Decoder Loss:  0.03230247 Validation Decoder Loss:  0.33322886
Encoder Loss:  0.043652512  || Decoder Loss:  0.03223523 Validation Decoder Loss:  0.33331603
Encoder Loss:  0.043564133  || Decoder Loss:  0.032185372 Validation Decoder Loss:  0.333351
Encoder Loss:  0.0434915  || Decoder Loss:  0.032146387 Validation Decoder Loss:  0.33334064
Encoder Loss:  0.043403767  || Decoder Loss:  0.032120947 Validation Decoder Loss:  0.33333626
Encoder Loss:  0.043468844  || Decoder Loss:  0.032099336 Validation Decoder Loss:  0.3335452
Encoder Loss:  0.043369588  || Decoder Loss:  0.032080725 Validation Decoder Loss:  0.33354193
Encoder Loss:  0.04332887  || Decoder Loss:  0.032070443 Validation Decoder Loss:  0.33349973
Encoder Loss:  0.043340143  || Decoder Loss:  0.03207478 Validation Decoder Loss:  0.33368462
Encoder Loss:  0.043279625  || Decoder Loss:  0.0320667 Validation Decoder Loss:  0.33359662
Encoder Loss:  0.043274295  || Decoder Loss:  0.03208647 Validation Decoder Loss:  0.3336839
Encoder Loss:  0.0433179  || Decoder Loss:  0.03210756 Validation Decoder Loss:  0.33377922
Encoder Loss:  0.043266114  || Decoder Loss:  0.03210763 Validation Decoder Loss:  0.3337801
Encoder Loss:  0.043243323  || Decoder Loss:  0.032124873 Validation Decoder Loss:  0.3338039
Encoder Loss:  0.043218404  || Decoder Loss:  0.032157674 Validation Decoder Loss:  0.3338297
Encoder Loss:  0.04322064  || Decoder Loss:  0.03218618 Validation Decoder Loss:  0.33373648
Encoder Loss:  0.043237157  || Decoder Loss:  0.03221048 Validation Decoder Loss:  0.3337265
Encoder Loss:  0.04323171  || Decoder Loss:  0.0322372 Validation Decoder Loss:  0.33378077
Encoder Loss:  0.043203026  || Decoder Loss:  0.032267638 Validation Decoder Loss:  0.3337078
Encoder Loss:  0.04320324  || Decoder Loss:  0.032316834 Validation Decoder Loss:  0.33370197
Encoder Loss:  0.043215618  || Decoder Loss:  0.032347802 Validation Decoder Loss:  0.33379194
Encoder Loss:  0.043221097  || Decoder Loss:  0.03236897 Validation Decoder Loss:  0.33377546
Encoder Loss:  0.04317515  || Decoder Loss:  0.03239083 Validation Decoder Loss:  0.3337056
Encoder Loss:  0.04323041  || Decoder Loss:  0.03244386 Validation Decoder Loss:  0.33370897
Encoder Loss:  0.043278717  || Decoder Loss:  0.03247886 Validation Decoder Loss:  0.33375582
Encoder Loss:  0.043167762  || Decoder Loss:  0.032513503 Validation Decoder Loss:  0.33363894
Model: siamese_net_lr_0.0006752533036840017 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33363894
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 257, 10, 19, 1)    787       
_________________________________________________________________
reshape_45 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12207417  || Decoder Loss:  0.042128693 Validation Decoder Loss:  0.325016
Encoder Loss:  0.12214011  || Decoder Loss:  0.0422867 Validation Decoder Loss:  0.32496005
Encoder Loss:  0.12220595  || Decoder Loss:  0.042444486 Validation Decoder Loss:  0.3249061
Encoder Loss:  0.12227147  || Decoder Loss:  0.04260208 Validation Decoder Loss:  0.32485384
Encoder Loss:  0.1223367  || Decoder Loss:  0.042759642 Validation Decoder Loss:  0.32480288
Encoder Loss:  0.12240182  || Decoder Loss:  0.04291727 Validation Decoder Loss:  0.32475305
Encoder Loss:  0.122466676  || Decoder Loss:  0.043075036 Validation Decoder Loss:  0.32470414
Encoder Loss:  0.12253137  || Decoder Loss:  0.043233007 Validation Decoder Loss:  0.32465607
Encoder Loss:  0.12259599  || Decoder Loss:  0.043391246 Validation Decoder Loss:  0.32460874
Encoder Loss:  0.12266034  || Decoder Loss:  0.04354976 Validation Decoder Loss:  0.324562
Encoder Loss:  0.122724555  || Decoder Loss:  0.043708626 Validation Decoder Loss:  0.3245159
Encoder Loss:  0.12278858  || Decoder Loss:  0.04386787 Validation Decoder Loss:  0.32447052
Encoder Loss:  0.12285237  || Decoder Loss:  0.044027496 Validation Decoder Loss:  0.3244258
Encoder Loss:  0.12291592  || Decoder Loss:  0.044187516 Validation Decoder Loss:  0.32438177
Encoder Loss:  0.12297929  || Decoder Loss:  0.04434795 Validation Decoder Loss:  0.32433864
Encoder Loss:  0.12304234  || Decoder Loss:  0.04450878 Validation Decoder Loss:  0.32429636
Encoder Loss:  0.12310503  || Decoder Loss:  0.044670023 Validation Decoder Loss:  0.32425493
Encoder Loss:  0.123167336  || Decoder Loss:  0.044831645 Validation Decoder Loss:  0.32421446
Encoder Loss:  0.12322926  || Decoder Loss:  0.044993643 Validation Decoder Loss:  0.32417488
Encoder Loss:  0.12329073  || Decoder Loss:  0.04515602 Validation Decoder Loss:  0.32413623
Encoder Loss:  0.12335162  || Decoder Loss:  0.04531872 Validation Decoder Loss:  0.32409847
Encoder Loss:  0.12341204  || Decoder Loss:  0.045481753 Validation Decoder Loss:  0.3240617
Encoder Loss:  0.12347181  || Decoder Loss:  0.045645043 Validation Decoder Loss:  0.32402584
Encoder Loss:  0.123530924  || Decoder Loss:  0.045808572 Validation Decoder Loss:  0.32399094
Encoder Loss:  0.1235893  || Decoder Loss:  0.045972273 Validation Decoder Loss:  0.32395694
Encoder Loss:  0.123646826  || Decoder Loss:  0.04613606 Validation Decoder Loss:  0.32392383
Encoder Loss:  0.12370345  || Decoder Loss:  0.046299905 Validation Decoder Loss:  0.32389152
Encoder Loss:  0.12375905  || Decoder Loss:  0.046463672 Validation Decoder Loss:  0.32385996
Encoder Loss:  0.1238135  || Decoder Loss:  0.04662727 Validation Decoder Loss:  0.32382905
Encoder Loss:  0.12386676  || Decoder Loss:  0.04679058 Validation Decoder Loss:  0.32379875
Encoder Loss:  0.12391858  || Decoder Loss:  0.046953477 Validation Decoder Loss:  0.3237689
Encoder Loss:  0.12396895  || Decoder Loss:  0.047115836 Validation Decoder Loss:  0.3237394
Encoder Loss:  0.124017686  || Decoder Loss:  0.047277473 Validation Decoder Loss:  0.32371008
Encoder Loss:  0.12406458  || Decoder Loss:  0.047438182 Validation Decoder Loss:  0.32368088
Encoder Loss:  0.1241095  || Decoder Loss:  0.047597848 Validation Decoder Loss:  0.3236516
Encoder Loss:  0.124152124  || Decoder Loss:  0.04775612 Validation Decoder Loss:  0.32362214
Encoder Loss:  0.124192454  || Decoder Loss:  0.0479129 Validation Decoder Loss:  0.32359228
Encoder Loss:  0.12423006  || Decoder Loss:  0.04806782 Validation Decoder Loss:  0.32356188
Encoder Loss:  0.12426479  || Decoder Loss:  0.04822063 Validation Decoder Loss:  0.3235308
Encoder Loss:  0.12429634  || Decoder Loss:  0.04837102 Validation Decoder Loss:  0.32349885
Model: siamese_net_lr_4.1906160642500016e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32349885
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 257, 10, 19, 1)    409       
_________________________________________________________________
reshape_46 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776446  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.03677644  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776446  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.036776442  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025712
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33025706
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 72, 35, 19, 1)     64        
_________________________________________________________________
reshape_47 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25492668  || Decoder Loss:  0.036774646 Validation Decoder Loss:  0.33560407
Encoder Loss:  0.2548234  || Decoder Loss:  0.036735997 Validation Decoder Loss:  0.33557433
Encoder Loss:  0.25470123  || Decoder Loss:  0.036702286 Validation Decoder Loss:  0.33556128
Encoder Loss:  0.25455606  || Decoder Loss:  0.03667887 Validation Decoder Loss:  0.33557183
Encoder Loss:  0.25437653  || Decoder Loss:  0.036673173 Validation Decoder Loss:  0.33562082
Encoder Loss:  0.25413805  || Decoder Loss:  0.036702108 Validation Decoder Loss:  0.3357443
Encoder Loss:  0.25377396  || Decoder Loss:  0.036811363 Validation Decoder Loss:  0.3360544
Encoder Loss:  0.252992  || Decoder Loss:  0.03717626 Validation Decoder Loss:  0.33712098
Encoder Loss:  0.24659482  || Decoder Loss:  0.039414268 Validation Decoder Loss:  0.34870315
Encoder Loss:  0.104332656  || Decoder Loss:  0.04951489 Validation Decoder Loss:  0.34953585
Encoder Loss:  0.07371442  || Decoder Loss:  0.04222179 Validation Decoder Loss:  0.34132645
Encoder Loss:  0.07288036  || Decoder Loss:  0.03910237 Validation Decoder Loss:  0.33754158
Encoder Loss:  0.07281619  || Decoder Loss:  0.037531666 Validation Decoder Loss:  0.33532873
Encoder Loss:  0.0716936  || Decoder Loss:  0.03662515 Validation Decoder Loss:  0.3340093
Encoder Loss:  0.07155094  || Decoder Loss:  0.036088966 Validation Decoder Loss:  0.33316964
Encoder Loss:  0.0712756  || Decoder Loss:  0.03577654 Validation Decoder Loss:  0.33264998
Encoder Loss:  0.07091145  || Decoder Loss:  0.03560564 Validation Decoder Loss:  0.33235165
Encoder Loss:  0.07090661  || Decoder Loss:  0.03551291 Validation Decoder Loss:  0.33218533
Encoder Loss:  0.070923455  || Decoder Loss:  0.0354615 Validation Decoder Loss:  0.3320968
Encoder Loss:  0.07045582  || Decoder Loss:  0.035429146 Validation Decoder Loss:  0.33205223
Encoder Loss:  0.07049808  || Decoder Loss:  0.035407554 Validation Decoder Loss:  0.33202735
Encoder Loss:  0.07030747  || Decoder Loss:  0.03539209 Validation Decoder Loss:  0.33201283
Encoder Loss:  0.07014098  || Decoder Loss:  0.03537894 Validation Decoder Loss:  0.3320027
Encoder Loss:  0.069957875  || Decoder Loss:  0.035368465 Validation Decoder Loss:  0.33199546
Encoder Loss:  0.069488555  || Decoder Loss:  0.035358794 Validation Decoder Loss:  0.33199003
Encoder Loss:  0.068932794  || Decoder Loss:  0.035350434 Validation Decoder Loss:  0.33198446
Encoder Loss:  0.06509317  || Decoder Loss:  0.035343036 Validation Decoder Loss:  0.33197975
Encoder Loss:  0.052393705  || Decoder Loss:  0.03533715 Validation Decoder Loss:  0.33197564
Encoder Loss:  0.05093914  || Decoder Loss:  0.0353411 Validation Decoder Loss:  0.33196592
Encoder Loss:  0.049513005  || Decoder Loss:  0.035346106 Validation Decoder Loss:  0.331949
Encoder Loss:  0.04914766  || Decoder Loss:  0.03534621 Validation Decoder Loss:  0.33193454
Encoder Loss:  0.049133968  || Decoder Loss:  0.03534187 Validation Decoder Loss:  0.3319261
Encoder Loss:  0.049083102  || Decoder Loss:  0.03533496 Validation Decoder Loss:  0.3319223
Encoder Loss:  0.048738133  || Decoder Loss:  0.03532824 Validation Decoder Loss:  0.3319188
Encoder Loss:  0.048806883  || Decoder Loss:  0.0353216 Validation Decoder Loss:  0.3319168
Encoder Loss:  0.048606053  || Decoder Loss:  0.035315085 Validation Decoder Loss:  0.331915
Encoder Loss:  0.048575208  || Decoder Loss:  0.035308674 Validation Decoder Loss:  0.33191413
Encoder Loss:  0.048515845  || Decoder Loss:  0.035302278 Validation Decoder Loss:  0.3319137
Encoder Loss:  0.048500847  || Decoder Loss:  0.03529624 Validation Decoder Loss:  0.33191374
Encoder Loss:  0.048412133  || Decoder Loss:  0.035290305 Validation Decoder Loss:  0.33191395
Model: siamese_net_lr_0.00048718781127153935 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33191392
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 252, 10, 19, 1)    379       
_________________________________________________________________
reshape_48 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 379
Trainable params: 379
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03844014  || Decoder Loss:  0.03844014 Validation Decoder Loss:  0.33457938
Encoder Loss:  0.038422585  || Decoder Loss:  0.038422585 Validation Decoder Loss:  0.33457148
Encoder Loss:  0.0384052  || Decoder Loss:  0.0384052 Validation Decoder Loss:  0.33456364
Encoder Loss:  0.03838809  || Decoder Loss:  0.03838809 Validation Decoder Loss:  0.33455566
Encoder Loss:  0.038371217  || Decoder Loss:  0.038371217 Validation Decoder Loss:  0.33454746
Encoder Loss:  0.038354557  || Decoder Loss:  0.038354557 Validation Decoder Loss:  0.334539
Encoder Loss:  0.038338065  || Decoder Loss:  0.038338065 Validation Decoder Loss:  0.3345303
Encoder Loss:  0.038321722  || Decoder Loss:  0.038321722 Validation Decoder Loss:  0.33452132
Encoder Loss:  0.038305487  || Decoder Loss:  0.038305487 Validation Decoder Loss:  0.334512
Encoder Loss:  0.038289323  || Decoder Loss:  0.038289323 Validation Decoder Loss:  0.33450237
Encoder Loss:  0.038273223  || Decoder Loss:  0.038273223 Validation Decoder Loss:  0.33449244
Encoder Loss:  0.038257137  || Decoder Loss:  0.038257137 Validation Decoder Loss:  0.33448213
Encoder Loss:  0.038241077  || Decoder Loss:  0.038241077 Validation Decoder Loss:  0.33447146
Encoder Loss:  0.038225  || Decoder Loss:  0.038225 Validation Decoder Loss:  0.33446044
Encoder Loss:  0.038208876  || Decoder Loss:  0.038208876 Validation Decoder Loss:  0.33444893
Encoder Loss:  0.038192682  || Decoder Loss:  0.038192682 Validation Decoder Loss:  0.33443707
Encoder Loss:  0.03817642  || Decoder Loss:  0.03817642 Validation Decoder Loss:  0.3344247
Encoder Loss:  0.03816005  || Decoder Loss:  0.03816005 Validation Decoder Loss:  0.33441192
Encoder Loss:  0.03814355  || Decoder Loss:  0.03814355 Validation Decoder Loss:  0.33439863
Encoder Loss:  0.038126897  || Decoder Loss:  0.038126897 Validation Decoder Loss:  0.33438486
Encoder Loss:  0.038110096  || Decoder Loss:  0.038110096 Validation Decoder Loss:  0.3343705
Encoder Loss:  0.038093083  || Decoder Loss:  0.038093083 Validation Decoder Loss:  0.33435565
Encoder Loss:  0.038075868  || Decoder Loss:  0.038075868 Validation Decoder Loss:  0.33434024
Encoder Loss:  0.03805844  || Decoder Loss:  0.03805844 Validation Decoder Loss:  0.3343242
Encoder Loss:  0.038040753  || Decoder Loss:  0.038040753 Validation Decoder Loss:  0.3343076
Encoder Loss:  0.03802279  || Decoder Loss:  0.03802279 Validation Decoder Loss:  0.33429036
Encoder Loss:  0.03800453  || Decoder Loss:  0.03800453 Validation Decoder Loss:  0.3342725
Encoder Loss:  0.037985936  || Decoder Loss:  0.037985936 Validation Decoder Loss:  0.33425394
Encoder Loss:  0.037967015  || Decoder Loss:  0.037967015 Validation Decoder Loss:  0.3342347
Encoder Loss:  0.03794772  || Decoder Loss:  0.03794772 Validation Decoder Loss:  0.3342148
Encoder Loss:  0.03792803  || Decoder Loss:  0.03792803 Validation Decoder Loss:  0.33419418
Encoder Loss:  0.037907913  || Decoder Loss:  0.037907913 Validation Decoder Loss:  0.33417287
Encoder Loss:  0.03788734  || Decoder Loss:  0.03788734 Validation Decoder Loss:  0.33415085
Encoder Loss:  0.03786628  || Decoder Loss:  0.03786628 Validation Decoder Loss:  0.33412808
Encoder Loss:  0.037844703  || Decoder Loss:  0.037844703 Validation Decoder Loss:  0.3341046
Encoder Loss:  0.037822556  || Decoder Loss:  0.037822556 Validation Decoder Loss:  0.33408043
Encoder Loss:  0.037799798  || Decoder Loss:  0.037799798 Validation Decoder Loss:  0.33405548
Encoder Loss:  0.037776414  || Decoder Loss:  0.037776414 Validation Decoder Loss:  0.33402985
Encoder Loss:  0.03775234  || Decoder Loss:  0.03775234 Validation Decoder Loss:  0.3340036
Encoder Loss:  0.03772754  || Decoder Loss:  0.03772754 Validation Decoder Loss:  0.3339767
Model: siamese_net_lr_8.254484855258642e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33397666
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 110, 22, 19, 1)    659       
_________________________________________________________________
reshape_49 (Reshape)         (None, 2420, 19, 1)       0         
=================================================================
Total params: 659
Trainable params: 659
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 2420, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 2607, 19, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04808881  || Decoder Loss:  0.04808881 Validation Decoder Loss:  0.33875388
Encoder Loss:  0.04794528  || Decoder Loss:  0.04794528 Validation Decoder Loss:  0.33839962
Encoder Loss:  0.04778174  || Decoder Loss:  0.04778174 Validation Decoder Loss:  0.33840993
Encoder Loss:  0.047579218  || Decoder Loss:  0.047579218 Validation Decoder Loss:  0.33861572
Encoder Loss:  0.047291897  || Decoder Loss:  0.047291897 Validation Decoder Loss:  0.3389398
Encoder Loss:  0.046766747  || Decoder Loss:  0.046766747 Validation Decoder Loss:  0.33919513
Encoder Loss:  0.045225907  || Decoder Loss:  0.045225907 Validation Decoder Loss:  0.33660468
Encoder Loss:  0.041140415  || Decoder Loss:  0.041140415 Validation Decoder Loss:  0.3367679
Encoder Loss:  0.036796793  || Decoder Loss:  0.036796793 Validation Decoder Loss:  0.33372515
Encoder Loss:  0.034725398  || Decoder Loss:  0.034725398 Validation Decoder Loss:  0.33152896
Encoder Loss:  0.034121603  || Decoder Loss:  0.034121603 Validation Decoder Loss:  0.3308225
Encoder Loss:  0.0339597  || Decoder Loss:  0.0339597 Validation Decoder Loss:  0.33066094
Encoder Loss:  0.033897582  || Decoder Loss:  0.033897582 Validation Decoder Loss:  0.3306643
Encoder Loss:  0.033862766  || Decoder Loss:  0.033862766 Validation Decoder Loss:  0.3307053
Encoder Loss:  0.033837833  || Decoder Loss:  0.033837833 Validation Decoder Loss:  0.330748
Encoder Loss:  0.033817433  || Decoder Loss:  0.033817433 Validation Decoder Loss:  0.33078313
Encoder Loss:  0.0337996  || Decoder Loss:  0.0337996 Validation Decoder Loss:  0.33080977
Encoder Loss:  0.033783447  || Decoder Loss:  0.033783447 Validation Decoder Loss:  0.33082902
Encoder Loss:  0.033768523  || Decoder Loss:  0.033768523 Validation Decoder Loss:  0.33084258
Encoder Loss:  0.033754565  || Decoder Loss:  0.033754565 Validation Decoder Loss:  0.33085206
Encoder Loss:  0.0337414  || Decoder Loss:  0.0337414 Validation Decoder Loss:  0.33085847
Encoder Loss:  0.0337289  || Decoder Loss:  0.0337289 Validation Decoder Loss:  0.33086255
Encoder Loss:  0.033716995  || Decoder Loss:  0.033716995 Validation Decoder Loss:  0.33086494
Encoder Loss:  0.03370557  || Decoder Loss:  0.03370557 Validation Decoder Loss:  0.33086598
Encoder Loss:  0.03369458  || Decoder Loss:  0.03369458 Validation Decoder Loss:  0.3308658
Encoder Loss:  0.033683985  || Decoder Loss:  0.033683985 Validation Decoder Loss:  0.33086458
Encoder Loss:  0.033673722  || Decoder Loss:  0.033673722 Validation Decoder Loss:  0.3308624
Encoder Loss:  0.033663776  || Decoder Loss:  0.033663776 Validation Decoder Loss:  0.33085933
Encoder Loss:  0.033654094  || Decoder Loss:  0.033654094 Validation Decoder Loss:  0.33085537
Encoder Loss:  0.03364465  || Decoder Loss:  0.03364465 Validation Decoder Loss:  0.33085054
Encoder Loss:  0.03363542  || Decoder Loss:  0.03363542 Validation Decoder Loss:  0.33084482
Encoder Loss:  0.033626404  || Decoder Loss:  0.033626404 Validation Decoder Loss:  0.3308383
Encoder Loss:  0.033617552  || Decoder Loss:  0.033617552 Validation Decoder Loss:  0.33083087
Encoder Loss:  0.03360886  || Decoder Loss:  0.03360886 Validation Decoder Loss:  0.3308226
Encoder Loss:  0.03360032  || Decoder Loss:  0.03360032 Validation Decoder Loss:  0.33081347
Encoder Loss:  0.03359189  || Decoder Loss:  0.03359189 Validation Decoder Loss:  0.33080357
Encoder Loss:  0.033583596  || Decoder Loss:  0.033583596 Validation Decoder Loss:  0.3307929
Encoder Loss:  0.033575412  || Decoder Loss:  0.033575412 Validation Decoder Loss:  0.33078158
Encoder Loss:  0.033567317  || Decoder Loss:  0.033567317 Validation Decoder Loss:  0.3307696
Encoder Loss:  0.033559337  || Decoder Loss:  0.033559337 Validation Decoder Loss:  0.3307571
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3307571
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 257, 10, 19, 1)    137       
_________________________________________________________________
reshape_50 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05762719  || Decoder Loss:  0.035723735 Validation Decoder Loss:  0.33013356
Encoder Loss:  0.05770334  || Decoder Loss:  0.03587104 Validation Decoder Loss:  0.329221
Encoder Loss:  0.058088135  || Decoder Loss:  0.036653653 Validation Decoder Loss:  0.32840437
Encoder Loss:  0.044280786  || Decoder Loss:  0.03601446 Validation Decoder Loss:  0.33112812
Encoder Loss:  0.03867758  || Decoder Loss:  0.03528729 Validation Decoder Loss:  0.33093593
Encoder Loss:  0.0386999  || Decoder Loss:  0.035208434 Validation Decoder Loss:  0.33085725
Encoder Loss:  0.038679704  || Decoder Loss:  0.03516738 Validation Decoder Loss:  0.33083206
Encoder Loss:  0.03854006  || Decoder Loss:  0.035139933 Validation Decoder Loss:  0.3308355
Encoder Loss:  0.03845372  || Decoder Loss:  0.035119474 Validation Decoder Loss:  0.33084893
Encoder Loss:  0.038376603  || Decoder Loss:  0.035104193 Validation Decoder Loss:  0.33086365
Encoder Loss:  0.0382666  || Decoder Loss:  0.035092946 Validation Decoder Loss:  0.33087716
Encoder Loss:  0.03647514  || Decoder Loss:  0.03508359 Validation Decoder Loss:  0.33092174
Encoder Loss:  0.036053855  || Decoder Loss:  0.035074838 Validation Decoder Loss:  0.33094975
Encoder Loss:  0.03603259  || Decoder Loss:  0.03506978 Validation Decoder Loss:  0.33097148
Encoder Loss:  0.03600344  || Decoder Loss:  0.03506453 Validation Decoder Loss:  0.3309934
Encoder Loss:  0.036012996  || Decoder Loss:  0.035060987 Validation Decoder Loss:  0.33101106
Encoder Loss:  0.03601369  || Decoder Loss:  0.035059202 Validation Decoder Loss:  0.3310266
Encoder Loss:  0.0360022  || Decoder Loss:  0.03505755 Validation Decoder Loss:  0.33104163
Encoder Loss:  0.035986144  || Decoder Loss:  0.035054848 Validation Decoder Loss:  0.33105645
Encoder Loss:  0.03599004  || Decoder Loss:  0.0350536 Validation Decoder Loss:  0.33106843
Encoder Loss:  0.03596097  || Decoder Loss:  0.035049748 Validation Decoder Loss:  0.33108586
Encoder Loss:  0.035974417  || Decoder Loss:  0.035047237 Validation Decoder Loss:  0.33109763
Encoder Loss:  0.035967715  || Decoder Loss:  0.0350467 Validation Decoder Loss:  0.33111015
Encoder Loss:  0.035972368  || Decoder Loss:  0.035046328 Validation Decoder Loss:  0.33111638
Encoder Loss:  0.035965182  || Decoder Loss:  0.035046212 Validation Decoder Loss:  0.33112344
Encoder Loss:  0.035956062  || Decoder Loss:  0.035045765 Validation Decoder Loss:  0.33113047
Encoder Loss:  0.035957005  || Decoder Loss:  0.035045512 Validation Decoder Loss:  0.33113673
Encoder Loss:  0.035962474  || Decoder Loss:  0.0350459 Validation Decoder Loss:  0.33113316
Encoder Loss:  0.035938982  || Decoder Loss:  0.03504297 Validation Decoder Loss:  0.33114737
Encoder Loss:  0.035931088  || Decoder Loss:  0.035041507 Validation Decoder Loss:  0.33115485
Encoder Loss:  0.03595241  || Decoder Loss:  0.035043195 Validation Decoder Loss:  0.3311515
Encoder Loss:  0.03594875  || Decoder Loss:  0.035045516 Validation Decoder Loss:  0.3311479
Encoder Loss:  0.03594825  || Decoder Loss:  0.03504768 Validation Decoder Loss:  0.33114126
Encoder Loss:  0.035954103  || Decoder Loss:  0.03504999 Validation Decoder Loss:  0.3311302
Encoder Loss:  0.035945695  || Decoder Loss:  0.035051726 Validation Decoder Loss:  0.33112437
Encoder Loss:  0.035946064  || Decoder Loss:  0.035053097 Validation Decoder Loss:  0.33111542
Encoder Loss:  0.035947055  || Decoder Loss:  0.035054814 Validation Decoder Loss:  0.33110452
Encoder Loss:  0.035942286  || Decoder Loss:  0.035055734 Validation Decoder Loss:  0.33109838
Encoder Loss:  0.035940908  || Decoder Loss:  0.035056725 Validation Decoder Loss:  0.3310876
Encoder Loss:  0.035925314  || Decoder Loss:  0.035055272 Validation Decoder Loss:  0.3310836
Model: siamese_net_lr_0.0007680446519345587 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3310836
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 104, 5, 19, 1)     42        
_________________________________________________________________
reshape_51 (Reshape)         (None, 520, 19, 1)        0         
=================================================================
Total params: 42
Trainable params: 42
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 520, 19, 1)        2089      
=================================================================
Total params: 2,089
Trainable params: 2,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 2607, 19, 1)       13        
=================================================================
Total params: 13
Trainable params: 13
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40125456  || Decoder Loss:  0.036812786 Validation Decoder Loss:  0.32939014
Encoder Loss:  0.40049487  || Decoder Loss:  0.035582677 Validation Decoder Loss:  0.3284525
Encoder Loss:  0.39965492  || Decoder Loss:  0.035324648 Validation Decoder Loss:  0.3281004
Encoder Loss:  0.39854503  || Decoder Loss:  0.035326872 Validation Decoder Loss:  0.32789326
Encoder Loss:  0.39698088  || Decoder Loss:  0.035389863 Validation Decoder Loss:  0.32773
Encoder Loss:  0.3946783  || Decoder Loss:  0.035463747 Validation Decoder Loss:  0.32759678
Encoder Loss:  0.3911065  || Decoder Loss:  0.035536267 Validation Decoder Loss:  0.32750046
Encoder Loss:  0.38514382  || Decoder Loss:  0.035598114 Validation Decoder Loss:  0.3274538
Encoder Loss:  0.37403014  || Decoder Loss:  0.035638656 Validation Decoder Loss:  0.32746714
Encoder Loss:  0.34920037  || Decoder Loss:  0.035645653 Validation Decoder Loss:  0.32758433
Encoder Loss:  0.26768565  || Decoder Loss:  0.035569187 Validation Decoder Loss:  0.32804286
Encoder Loss:  0.0978994  || Decoder Loss:  0.035456978 Validation Decoder Loss:  0.3283783
Encoder Loss:  0.08979949  || Decoder Loss:  0.03537232 Validation Decoder Loss:  0.3286218
Encoder Loss:  0.08969924  || Decoder Loss:  0.035311468 Validation Decoder Loss:  0.32884204
Encoder Loss:  0.089620665  || Decoder Loss:  0.035268355 Validation Decoder Loss:  0.3290401
Encoder Loss:  0.08956806  || Decoder Loss:  0.03523836 Validation Decoder Loss:  0.32921553
Encoder Loss:  0.08950059  || Decoder Loss:  0.03521811 Validation Decoder Loss:  0.32936743
Encoder Loss:  0.089413576  || Decoder Loss:  0.03520501 Validation Decoder Loss:  0.3294958
Encoder Loss:  0.08933945  || Decoder Loss:  0.03519697 Validation Decoder Loss:  0.3296005
Encoder Loss:  0.08931491  || Decoder Loss:  0.035192337 Validation Decoder Loss:  0.32968253
Encoder Loss:  0.08921013  || Decoder Loss:  0.035189807 Validation Decoder Loss:  0.32974398
Encoder Loss:  0.08914872  || Decoder Loss:  0.035188537 Validation Decoder Loss:  0.3297877
Encoder Loss:  0.08908251  || Decoder Loss:  0.035187878 Validation Decoder Loss:  0.32981706
Encoder Loss:  0.08904396  || Decoder Loss:  0.03518753 Validation Decoder Loss:  0.32983553
Encoder Loss:  0.08893566  || Decoder Loss:  0.03518734 Validation Decoder Loss:  0.32984674
Encoder Loss:  0.08885721  || Decoder Loss:  0.035187233 Validation Decoder Loss:  0.32985315
Encoder Loss:  0.08877662  || Decoder Loss:  0.03518714 Validation Decoder Loss:  0.32985654
Encoder Loss:  0.0887119  || Decoder Loss:  0.03518707 Validation Decoder Loss:  0.32985812
Encoder Loss:  0.08856819  || Decoder Loss:  0.035187036 Validation Decoder Loss:  0.32985884
Encoder Loss:  0.088504314  || Decoder Loss:  0.035187017 Validation Decoder Loss:  0.3298588
Encoder Loss:  0.08835779  || Decoder Loss:  0.03518699 Validation Decoder Loss:  0.3298586
Encoder Loss:  0.08826235  || Decoder Loss:  0.035186995 Validation Decoder Loss:  0.3298583
Encoder Loss:  0.08814072  || Decoder Loss:  0.03518697 Validation Decoder Loss:  0.3298577
Encoder Loss:  0.087971896  || Decoder Loss:  0.035186946 Validation Decoder Loss:  0.32985735
Encoder Loss:  0.08781014  || Decoder Loss:  0.035186935 Validation Decoder Loss:  0.3298568
Encoder Loss:  0.087608755  || Decoder Loss:  0.035186935 Validation Decoder Loss:  0.3298565
Encoder Loss:  0.08740462  || Decoder Loss:  0.03518692 Validation Decoder Loss:  0.32985604
Encoder Loss:  0.08714357  || Decoder Loss:  0.035186883 Validation Decoder Loss:  0.3298557
Encoder Loss:  0.08684468  || Decoder Loss:  0.035186905 Validation Decoder Loss:  0.3298552
Encoder Loss:  0.08643922  || Decoder Loss:  0.035186857 Validation Decoder Loss:  0.329855
Model: siamese_net_lr_5.3572137817620897e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.329855
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 65, 8, 19, 1)      9         
_________________________________________________________________
reshape_52 (Reshape)         (None, 520, 19, 1)        0         
=================================================================
Total params: 9
Trainable params: 9
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 520, 19, 1)        2089      
=================================================================
Total params: 2,089
Trainable params: 2,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 2607, 19, 1)       1570      
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36066124  || Decoder Loss:  0.07918027 Validation Decoder Loss:  0.35552323
Encoder Loss:  0.35828745  || Decoder Loss:  0.070259854 Validation Decoder Loss:  0.35265422
Encoder Loss:  0.35597885  || Decoder Loss:  0.06257025 Validation Decoder Loss:  0.35185406
Encoder Loss:  0.3534416  || Decoder Loss:  0.056279026 Validation Decoder Loss:  0.35302997
Encoder Loss:  0.34665367  || Decoder Loss:  0.051115617 Validation Decoder Loss:  0.3529877
Encoder Loss:  0.109115236  || Decoder Loss:  0.04582122 Validation Decoder Loss:  0.4082172
Encoder Loss:  0.07681515  || Decoder Loss:  0.04098875 Validation Decoder Loss:  0.3867666
Encoder Loss:  0.07593037  || Decoder Loss:  0.0382413 Validation Decoder Loss:  0.37835303
Encoder Loss:  0.07534854  || Decoder Loss:  0.036408573 Validation Decoder Loss:  0.37080437
Encoder Loss:  0.07480367  || Decoder Loss:  0.03507084 Validation Decoder Loss:  0.36507195
Encoder Loss:  0.07446494  || Decoder Loss:  0.03405252 Validation Decoder Loss:  0.36174077
Encoder Loss:  0.074163616  || Decoder Loss:  0.0332419 Validation Decoder Loss:  0.3583113
Encoder Loss:  0.07401504  || Decoder Loss:  0.032580666 Validation Decoder Loss:  0.35607886
Encoder Loss:  0.07368022  || Decoder Loss:  0.032014333 Validation Decoder Loss:  0.35363343
Encoder Loss:  0.07334031  || Decoder Loss:  0.031532742 Validation Decoder Loss:  0.3521707
Encoder Loss:  0.07319353  || Decoder Loss:  0.03112697 Validation Decoder Loss:  0.35069627
Encoder Loss:  0.07298958  || Decoder Loss:  0.030783337 Validation Decoder Loss:  0.34908664
Encoder Loss:  0.072622  || Decoder Loss:  0.030472849 Validation Decoder Loss:  0.34824777
Encoder Loss:  0.07267208  || Decoder Loss:  0.03021606 Validation Decoder Loss:  0.34695226
Encoder Loss:  0.07199426  || Decoder Loss:  0.029986728 Validation Decoder Loss:  0.34639376
Encoder Loss:  0.071965195  || Decoder Loss:  0.02980039 Validation Decoder Loss:  0.34580445
Encoder Loss:  0.07164148  || Decoder Loss:  0.029630575 Validation Decoder Loss:  0.34529683
Encoder Loss:  0.071349576  || Decoder Loss:  0.029486872 Validation Decoder Loss:  0.3448224
Encoder Loss:  0.07075897  || Decoder Loss:  0.029358277 Validation Decoder Loss:  0.34446588
Encoder Loss:  0.07002648  || Decoder Loss:  0.029241197 Validation Decoder Loss:  0.3440898
Encoder Loss:  0.068141736  || Decoder Loss:  0.029126897 Validation Decoder Loss:  0.343876
Encoder Loss:  0.06506419  || Decoder Loss:  0.0289972 Validation Decoder Loss:  0.34243536
Encoder Loss:  0.06025609  || Decoder Loss:  0.028855145 Validation Decoder Loss:  0.3426143
Encoder Loss:  0.05872044  || Decoder Loss:  0.028772548 Validation Decoder Loss:  0.34322673
Encoder Loss:  0.057577893  || Decoder Loss:  0.028710278 Validation Decoder Loss:  0.34403366
Encoder Loss:  0.056913994  || Decoder Loss:  0.028656092 Validation Decoder Loss:  0.34465146
Encoder Loss:  0.056429636  || Decoder Loss:  0.028611744 Validation Decoder Loss:  0.34511465
Encoder Loss:  0.056022964  || Decoder Loss:  0.028572908 Validation Decoder Loss:  0.3455124
Encoder Loss:  0.05568498  || Decoder Loss:  0.02854387 Validation Decoder Loss:  0.34597737
Encoder Loss:  0.055392247  || Decoder Loss:  0.028521854 Validation Decoder Loss:  0.3463456
Encoder Loss:  0.055078425  || Decoder Loss:  0.02849975 Validation Decoder Loss:  0.34665364
Encoder Loss:  0.054806307  || Decoder Loss:  0.028483853 Validation Decoder Loss:  0.34704784
Encoder Loss:  0.054532975  || Decoder Loss:  0.028476374 Validation Decoder Loss:  0.3475322
Encoder Loss:  0.05417638  || Decoder Loss:  0.028484564 Validation Decoder Loss:  0.34813905
Encoder Loss:  0.053735778  || Decoder Loss:  0.0285078 Validation Decoder Loss:  0.348793
Model: siamese_net_lr_0.00028880814772617243 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.348793
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 77, 10, 19, 1)     29        
_________________________________________________________________
reshape_53 (Reshape)         (None, 770, 19, 1)        0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 770, 19, 1)        301       
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 2607, 19, 1)       301       
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23322003  || Decoder Loss:  0.04464314 Validation Decoder Loss:  0.35432488
Encoder Loss:  0.23265389  || Decoder Loss:  0.044297606 Validation Decoder Loss:  0.3538227
Encoder Loss:  0.23093122  || Decoder Loss:  0.043851033 Validation Decoder Loss:  0.3500588
Encoder Loss:  0.13348486  || Decoder Loss:  0.03912073 Validation Decoder Loss:  0.330594
Encoder Loss:  0.066795  || Decoder Loss:  0.035602044 Validation Decoder Loss:  0.3310164
Encoder Loss:  0.066551626  || Decoder Loss:  0.035373017 Validation Decoder Loss:  0.33102214
Encoder Loss:  0.06630297  || Decoder Loss:  0.035220645 Validation Decoder Loss:  0.3310145
Encoder Loss:  0.06604055  || Decoder Loss:  0.035112273 Validation Decoder Loss:  0.3310255
Encoder Loss:  0.06572447  || Decoder Loss:  0.03503369 Validation Decoder Loss:  0.3310556
Encoder Loss:  0.06488316  || Decoder Loss:  0.03497422 Validation Decoder Loss:  0.3310926
Encoder Loss:  0.052158423  || Decoder Loss:  0.034929607 Validation Decoder Loss:  0.33110562
Encoder Loss:  0.045547865  || Decoder Loss:  0.034901146 Validation Decoder Loss:  0.33112037
Encoder Loss:  0.0454607  || Decoder Loss:  0.03486873 Validation Decoder Loss:  0.3311624
Encoder Loss:  0.04537337  || Decoder Loss:  0.034837473 Validation Decoder Loss:  0.3312011
Encoder Loss:  0.045257907  || Decoder Loss:  0.034809858 Validation Decoder Loss:  0.33123773
Encoder Loss:  0.04517435  || Decoder Loss:  0.034785222 Validation Decoder Loss:  0.3312732
Encoder Loss:  0.04510008  || Decoder Loss:  0.034763824 Validation Decoder Loss:  0.3313049
Encoder Loss:  0.045010615  || Decoder Loss:  0.03474599 Validation Decoder Loss:  0.33133572
Encoder Loss:  0.044934988  || Decoder Loss:  0.034731578 Validation Decoder Loss:  0.33136648
Encoder Loss:  0.044852886  || Decoder Loss:  0.034720797 Validation Decoder Loss:  0.33139956
Encoder Loss:  0.044758696  || Decoder Loss:  0.034713596 Validation Decoder Loss:  0.33143163
Encoder Loss:  0.044658575  || Decoder Loss:  0.03470945 Validation Decoder Loss:  0.33146316
Encoder Loss:  0.044561636  || Decoder Loss:  0.034707375 Validation Decoder Loss:  0.3315066
Encoder Loss:  0.044450823  || Decoder Loss:  0.034706652 Validation Decoder Loss:  0.3315747
Encoder Loss:  0.044331636  || Decoder Loss:  0.034705788 Validation Decoder Loss:  0.33165497
Encoder Loss:  0.044216424  || Decoder Loss:  0.034701984 Validation Decoder Loss:  0.33176795
Encoder Loss:  0.044090115  || Decoder Loss:  0.03469412 Validation Decoder Loss:  0.3318849
Encoder Loss:  0.04400267  || Decoder Loss:  0.034682695 Validation Decoder Loss:  0.33197612
Encoder Loss:  0.04390493  || Decoder Loss:  0.03466784 Validation Decoder Loss:  0.3320819
Encoder Loss:  0.043830246  || Decoder Loss:  0.034649935 Validation Decoder Loss:  0.33216912
Encoder Loss:  0.043741502  || Decoder Loss:  0.034630615 Validation Decoder Loss:  0.33225042
Encoder Loss:  0.043650895  || Decoder Loss:  0.034609824 Validation Decoder Loss:  0.3323146
Encoder Loss:  0.043566875  || Decoder Loss:  0.03458864 Validation Decoder Loss:  0.33237076
Encoder Loss:  0.043487567  || Decoder Loss:  0.03456691 Validation Decoder Loss:  0.33240715
Encoder Loss:  0.043408893  || Decoder Loss:  0.034545127 Validation Decoder Loss:  0.33243662
Encoder Loss:  0.043296248  || Decoder Loss:  0.034522597 Validation Decoder Loss:  0.3325004
Encoder Loss:  0.043226194  || Decoder Loss:  0.034501925 Validation Decoder Loss:  0.3324758
Encoder Loss:  0.043159347  || Decoder Loss:  0.034482583 Validation Decoder Loss:  0.33249393
Encoder Loss:  0.043080974  || Decoder Loss:  0.034461796 Validation Decoder Loss:  0.33251798
Encoder Loss:  0.043016043  || Decoder Loss:  0.034442 Validation Decoder Loss:  0.33256397
Model: siamese_net_lr_0.00021284348683918317 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33256397
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 110, 7, 19, 1)     142       
_________________________________________________________________
reshape_54 (Reshape)         (None, 770, 19, 1)        0         
=================================================================
Total params: 142
Trainable params: 142
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 770, 19, 1)        1070      
=================================================================
Total params: 1,070
Trainable params: 1,070
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 2607, 19, 1)       301       
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15741535  || Decoder Loss:  0.052033413 Validation Decoder Loss:  0.34899926
Encoder Loss:  0.15847939  || Decoder Loss:  0.055138644 Validation Decoder Loss:  0.35011935
Encoder Loss:  0.1597936  || Decoder Loss:  0.060343474 Validation Decoder Loss:  0.35276765
Encoder Loss:  0.14727266  || Decoder Loss:  0.05267833 Validation Decoder Loss:  0.34410226
Encoder Loss:  0.09206387  || Decoder Loss:  0.03643674 Validation Decoder Loss:  0.33678985
Encoder Loss:  0.053328384  || Decoder Loss:  0.036088765 Validation Decoder Loss:  0.33383042
Encoder Loss:  0.052089423  || Decoder Loss:  0.035457008 Validation Decoder Loss:  0.3328532
Encoder Loss:  0.051824752  || Decoder Loss:  0.035183266 Validation Decoder Loss:  0.33244163
Encoder Loss:  0.051647544  || Decoder Loss:  0.035017975 Validation Decoder Loss:  0.3322713
Encoder Loss:  0.051471017  || Decoder Loss:  0.034898322 Validation Decoder Loss:  0.3322228
Encoder Loss:  0.051305838  || Decoder Loss:  0.03480335 Validation Decoder Loss:  0.33222717
Encoder Loss:  0.051068295  || Decoder Loss:  0.034724563 Validation Decoder Loss:  0.33225876
Encoder Loss:  0.049442854  || Decoder Loss:  0.034658726 Validation Decoder Loss:  0.33224663
Encoder Loss:  0.045898933  || Decoder Loss:  0.03461379 Validation Decoder Loss:  0.3322147
Encoder Loss:  0.043425325  || Decoder Loss:  0.034585107 Validation Decoder Loss:  0.332295
Encoder Loss:  0.041786496  || Decoder Loss:  0.03456169 Validation Decoder Loss:  0.33237958
Encoder Loss:  0.041434363  || Decoder Loss:  0.034539156 Validation Decoder Loss:  0.33246532
Encoder Loss:  0.040937435  || Decoder Loss:  0.034516502 Validation Decoder Loss:  0.33254123
Encoder Loss:  0.040612515  || Decoder Loss:  0.03449638 Validation Decoder Loss:  0.3326067
Encoder Loss:  0.040441323  || Decoder Loss:  0.034478616 Validation Decoder Loss:  0.3326652
Encoder Loss:  0.040367223  || Decoder Loss:  0.034459338 Validation Decoder Loss:  0.3327165
Encoder Loss:  0.04015061  || Decoder Loss:  0.03444206 Validation Decoder Loss:  0.33275956
Encoder Loss:  0.04011084  || Decoder Loss:  0.034427453 Validation Decoder Loss:  0.33279702
Encoder Loss:  0.039942082  || Decoder Loss:  0.034415334 Validation Decoder Loss:  0.33283475
Encoder Loss:  0.03985213  || Decoder Loss:  0.034404833 Validation Decoder Loss:  0.33287376
Encoder Loss:  0.039770022  || Decoder Loss:  0.034394864 Validation Decoder Loss:  0.33291063
Encoder Loss:  0.039837603  || Decoder Loss:  0.03438229 Validation Decoder Loss:  0.3329469
Encoder Loss:  0.03968325  || Decoder Loss:  0.034373812 Validation Decoder Loss:  0.3329869
Encoder Loss:  0.039617527  || Decoder Loss:  0.034361783 Validation Decoder Loss:  0.33302128
Encoder Loss:  0.039545566  || Decoder Loss:  0.034351315 Validation Decoder Loss:  0.33305144
Encoder Loss:  0.039555162  || Decoder Loss:  0.034342397 Validation Decoder Loss:  0.33308005
Encoder Loss:  0.039557364  || Decoder Loss:  0.034333855 Validation Decoder Loss:  0.33310443
Encoder Loss:  0.039588436  || Decoder Loss:  0.034323025 Validation Decoder Loss:  0.3331249
Encoder Loss:  0.039557736  || Decoder Loss:  0.034310527 Validation Decoder Loss:  0.33314443
Encoder Loss:  0.03959435  || Decoder Loss:  0.034297124 Validation Decoder Loss:  0.33316088
Encoder Loss:  0.03938259  || Decoder Loss:  0.034286927 Validation Decoder Loss:  0.33316898
Encoder Loss:  0.039341915  || Decoder Loss:  0.034279104 Validation Decoder Loss:  0.3331791
Encoder Loss:  0.039262656  || Decoder Loss:  0.034270953 Validation Decoder Loss:  0.3331896
Encoder Loss:  0.039451435  || Decoder Loss:  0.034256957 Validation Decoder Loss:  0.3331951
Encoder Loss:  0.039197396  || Decoder Loss:  0.03424735 Validation Decoder Loss:  0.333202
Model: siamese_net_lr_0.0007074516056320261 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.333202
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 514, 5, 19, 1)     326       
_________________________________________________________________
reshape_55 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.03668787 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.3270992
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687862 Validation Decoder Loss:  0.32709917
Encoder Loss:  0.1330918  || Decoder Loss:  0.036687866 Validation Decoder Loss:  0.32709917
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3270992
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 514, 5, 19, 1)     263       
_________________________________________________________________
reshape_56 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.036667194 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667198 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.3268358
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.3268358
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667198 Validation Decoder Loss:  0.3268358
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667194 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667198 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667198 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667194 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.3268358
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667194 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683587
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.12687142  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.036667194 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Encoder Loss:  0.1268714  || Decoder Loss:  0.03666719 Validation Decoder Loss:  0.32683584
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32683584
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 212, 10, 19, 1)    139       
_________________________________________________________________
reshape_57 (Reshape)         (None, 2120, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 2120, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 2607, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27734336  || Decoder Loss:  0.0558416 Validation Decoder Loss:  0.36384666
Encoder Loss:  0.27641973  || Decoder Loss:  0.055401735 Validation Decoder Loss:  0.36421347
Encoder Loss:  0.2747128  || Decoder Loss:  0.055501804 Validation Decoder Loss:  0.3637119
Encoder Loss:  0.26489487  || Decoder Loss:  0.058821864 Validation Decoder Loss:  0.37558526
Encoder Loss:  0.15269516  || Decoder Loss:  0.18152651 Validation Decoder Loss:  0.5894178
Encoder Loss:  0.099223755  || Decoder Loss:  0.10383033 Validation Decoder Loss:  0.39863685
Encoder Loss:  0.08184188  || Decoder Loss:  0.064177394 Validation Decoder Loss:  0.35581827
Encoder Loss:  0.076148525  || Decoder Loss:  0.051450454 Validation Decoder Loss:  0.34449884
Encoder Loss:  0.0734599  || Decoder Loss:  0.04559274 Validation Decoder Loss:  0.33899838
Encoder Loss:  0.07172625  || Decoder Loss:  0.042026754 Validation Decoder Loss:  0.33577758
Encoder Loss:  0.070530295  || Decoder Loss:  0.039656647 Validation Decoder Loss:  0.3337947
Encoder Loss:  0.06959132  || Decoder Loss:  0.038033154 Validation Decoder Loss:  0.3325975
Encoder Loss:  0.06875189  || Decoder Loss:  0.036919482 Validation Decoder Loss:  0.3318805
Encoder Loss:  0.06681926  || Decoder Loss:  0.036153354 Validation Decoder Loss:  0.3314811
Encoder Loss:  0.047736254  || Decoder Loss:  0.03561467 Validation Decoder Loss:  0.33128768
Encoder Loss:  0.046049338  || Decoder Loss:  0.035305962 Validation Decoder Loss:  0.33126262
Encoder Loss:  0.04580111  || Decoder Loss:  0.035082463 Validation Decoder Loss:  0.33126342
Encoder Loss:  0.04569693  || Decoder Loss:  0.034921277 Validation Decoder Loss:  0.3312918
Encoder Loss:  0.045596924  || Decoder Loss:  0.03481333 Validation Decoder Loss:  0.33132955
Encoder Loss:  0.04552199  || Decoder Loss:  0.034742072 Validation Decoder Loss:  0.3313628
Encoder Loss:  0.045461908  || Decoder Loss:  0.034693714 Validation Decoder Loss:  0.33138725
Encoder Loss:  0.045398947  || Decoder Loss:  0.03465886 Validation Decoder Loss:  0.33140165
Encoder Loss:  0.04534415  || Decoder Loss:  0.034633014 Validation Decoder Loss:  0.33140868
Encoder Loss:  0.04529149  || Decoder Loss:  0.03461165 Validation Decoder Loss:  0.3314107
Encoder Loss:  0.04523624  || Decoder Loss:  0.0345936 Validation Decoder Loss:  0.3314081
Encoder Loss:  0.045184985  || Decoder Loss:  0.034577988 Validation Decoder Loss:  0.3314032
Encoder Loss:  0.04513215  || Decoder Loss:  0.034561593 Validation Decoder Loss:  0.33139843
Encoder Loss:  0.045065474  || Decoder Loss:  0.034545414 Validation Decoder Loss:  0.33139372
Encoder Loss:  0.0450124  || Decoder Loss:  0.03453022 Validation Decoder Loss:  0.3313898
Encoder Loss:  0.044958886  || Decoder Loss:  0.03451444 Validation Decoder Loss:  0.33138812
Encoder Loss:  0.044901792  || Decoder Loss:  0.034499086 Validation Decoder Loss:  0.33138883
Encoder Loss:  0.04484938  || Decoder Loss:  0.03448327 Validation Decoder Loss:  0.33139107
Encoder Loss:  0.044800814  || Decoder Loss:  0.034468662 Validation Decoder Loss:  0.33139256
Encoder Loss:  0.04474586  || Decoder Loss:  0.03445281 Validation Decoder Loss:  0.33139932
Encoder Loss:  0.0446981  || Decoder Loss:  0.0344384 Validation Decoder Loss:  0.331403
Encoder Loss:  0.04465789  || Decoder Loss:  0.034424916 Validation Decoder Loss:  0.33140528
Encoder Loss:  0.044615388  || Decoder Loss:  0.034412313 Validation Decoder Loss:  0.3314075
Encoder Loss:  0.044579197  || Decoder Loss:  0.034400593 Validation Decoder Loss:  0.33140922
Encoder Loss:  0.04454727  || Decoder Loss:  0.03438952 Validation Decoder Loss:  0.3314092
Encoder Loss:  0.044525407  || Decoder Loss:  0.034378566 Validation Decoder Loss:  0.33141172
Model: siamese_net_lr_0.0003367153766898582 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33141172
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 257, 10, 19, 1)    409       
_________________________________________________________________
reshape_58 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092422  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092422  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092422  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.15092424  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3302571
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 514, 5, 19, 1)     389       
_________________________________________________________________
reshape_59 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.036217775 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621777 Validation Decoder Loss:  0.33043253
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043256
Encoder Loss:  0.12838066  || Decoder Loss:  0.03621778 Validation Decoder Loss:  0.33043253
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33043253
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 106, 20, 19, 1)    689       
_________________________________________________________________
reshape_60 (Reshape)         (None, 2120, 19, 1)       0         
=================================================================
Total params: 689
Trainable params: 689
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 2120, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 2607, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22615856  || Decoder Loss:  0.07065088 Validation Decoder Loss:  0.36151606
Encoder Loss:  0.22532676  || Decoder Loss:  0.07366839 Validation Decoder Loss:  0.36368978
Encoder Loss:  0.223451  || Decoder Loss:  0.07802736 Validation Decoder Loss:  0.36619458
Encoder Loss:  0.21899538  || Decoder Loss:  0.085003175 Validation Decoder Loss:  0.37135443
Encoder Loss:  0.20725691  || Decoder Loss:  0.0979552 Validation Decoder Loss:  0.3891705
Encoder Loss:  0.16824049  || Decoder Loss:  0.12625961 Validation Decoder Loss:  0.6574882
Encoder Loss:  0.12243754  || Decoder Loss:  0.15502131 Validation Decoder Loss:  0.4463412
Encoder Loss:  0.074986584  || Decoder Loss:  0.07231633 Validation Decoder Loss:  0.37411433
Encoder Loss:  0.06284881  || Decoder Loss:  0.051881418 Validation Decoder Loss:  0.35227686
Encoder Loss:  0.05764067  || Decoder Loss:  0.04369203 Validation Decoder Loss:  0.3429668
Encoder Loss:  0.050072387  || Decoder Loss:  0.039519537 Validation Decoder Loss:  0.3373801
Encoder Loss:  0.04557221  || Decoder Loss:  0.03730041 Validation Decoder Loss:  0.3357854
Encoder Loss:  0.04439889  || Decoder Loss:  0.036266074 Validation Decoder Loss:  0.3351004
Encoder Loss:  0.04383618  || Decoder Loss:  0.035630517 Validation Decoder Loss:  0.3347246
Encoder Loss:  0.043458015  || Decoder Loss:  0.035173103 Validation Decoder Loss:  0.33453605
Encoder Loss:  0.043187868  || Decoder Loss:  0.034829717 Validation Decoder Loss:  0.3344636
Encoder Loss:  0.042984933  || Decoder Loss:  0.03456552 Validation Decoder Loss:  0.33445528
Encoder Loss:  0.042815972  || Decoder Loss:  0.03435124 Validation Decoder Loss:  0.33448404
Encoder Loss:  0.042667426  || Decoder Loss:  0.034174915 Validation Decoder Loss:  0.33453733
Encoder Loss:  0.042583566  || Decoder Loss:  0.03402943 Validation Decoder Loss:  0.3346098
Encoder Loss:  0.042422265  || Decoder Loss:  0.03391032 Validation Decoder Loss:  0.3346763
Encoder Loss:  0.04232388  || Decoder Loss:  0.03380517 Validation Decoder Loss:  0.33475125
Encoder Loss:  0.042267215  || Decoder Loss:  0.033711635 Validation Decoder Loss:  0.3348111
Encoder Loss:  0.042133294  || Decoder Loss:  0.033627905 Validation Decoder Loss:  0.3348626
Encoder Loss:  0.042077485  || Decoder Loss:  0.033551466 Validation Decoder Loss:  0.33491963
Encoder Loss:  0.041973315  || Decoder Loss:  0.03348615 Validation Decoder Loss:  0.3349773
Encoder Loss:  0.041923814  || Decoder Loss:  0.033425745 Validation Decoder Loss:  0.33502963
Encoder Loss:  0.04184529  || Decoder Loss:  0.033372752 Validation Decoder Loss:  0.3350683
Encoder Loss:  0.04178235  || Decoder Loss:  0.033322647 Validation Decoder Loss:  0.33508724
Encoder Loss:  0.041702013  || Decoder Loss:  0.033277106 Validation Decoder Loss:  0.3351132
Encoder Loss:  0.041636076  || Decoder Loss:  0.033235114 Validation Decoder Loss:  0.3351215
Encoder Loss:  0.04155378  || Decoder Loss:  0.03319921 Validation Decoder Loss:  0.33513004
Encoder Loss:  0.041516054  || Decoder Loss:  0.0331661 Validation Decoder Loss:  0.3351435
Encoder Loss:  0.041519094  || Decoder Loss:  0.033132676 Validation Decoder Loss:  0.33514035
Encoder Loss:  0.041491665  || Decoder Loss:  0.033104926 Validation Decoder Loss:  0.33515397
Encoder Loss:  0.04151561  || Decoder Loss:  0.033078868 Validation Decoder Loss:  0.33516222
Encoder Loss:  0.04147913  || Decoder Loss:  0.033054356 Validation Decoder Loss:  0.33515465
Encoder Loss:  0.04138585  || Decoder Loss:  0.033034787 Validation Decoder Loss:  0.33516267
Encoder Loss:  0.041304518  || Decoder Loss:  0.033019938 Validation Decoder Loss:  0.33516145
Encoder Loss:  0.041235585  || Decoder Loss:  0.033009313 Validation Decoder Loss:  0.33518574
Model: siamese_net_lr_0.0006140110356438271 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33518574
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 257, 10, 19, 1)    787       
_________________________________________________________________
reshape_61 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058982 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058982 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058982 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Encoder Loss:  0.1104141  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.1104141  || Decoder Loss:  0.04205899 Validation Decoder Loss:  0.32507357
Encoder Loss:  0.110414095  || Decoder Loss:  0.042058993 Validation Decoder Loss:  0.32507354
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32507357
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 257, 10, 19, 1)    409       
_________________________________________________________________
reshape_62 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.113910526  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.113910526  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11391053  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11391053  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3302571
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 204, 5, 19, 1)     142       
_________________________________________________________________
reshape_63 (Reshape)         (None, 1020, 19, 1)       0         
=================================================================
Total params: 142
Trainable params: 142
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 1020, 19, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 2607, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19328976  || Decoder Loss:  0.07028156 Validation Decoder Loss:  0.33593053
Encoder Loss:  0.0659422  || Decoder Loss:  0.03393959 Validation Decoder Loss:  0.33204418
Encoder Loss:  0.057814673  || Decoder Loss:  0.033537477 Validation Decoder Loss:  0.33163613
Encoder Loss:  0.057004523  || Decoder Loss:  0.03339289 Validation Decoder Loss:  0.33164036
Encoder Loss:  0.055969764  || Decoder Loss:  0.033339437 Validation Decoder Loss:  0.33138213
Encoder Loss:  0.055655718  || Decoder Loss:  0.033320226 Validation Decoder Loss:  0.33110407
Encoder Loss:  0.054270636  || Decoder Loss:  0.033421777 Validation Decoder Loss:  0.33085465
Encoder Loss:  0.05325585  || Decoder Loss:  0.03346539 Validation Decoder Loss:  0.33069777
Encoder Loss:  0.053020258  || Decoder Loss:  0.03339342 Validation Decoder Loss:  0.33036765
Encoder Loss:  0.051102642  || Decoder Loss:  0.0332307 Validation Decoder Loss:  0.32976273
Encoder Loss:  0.05212636  || Decoder Loss:  0.03306607 Validation Decoder Loss:  0.32892272
Encoder Loss:  0.050692014  || Decoder Loss:  0.033030145 Validation Decoder Loss:  0.32837868
Encoder Loss:  0.05035928  || Decoder Loss:  0.033032645 Validation Decoder Loss:  0.32812992
Encoder Loss:  0.049721107  || Decoder Loss:  0.033060573 Validation Decoder Loss:  0.3281339
Encoder Loss:  0.049569264  || Decoder Loss:  0.033106204 Validation Decoder Loss:  0.32790345
Encoder Loss:  0.04937267  || Decoder Loss:  0.033121612 Validation Decoder Loss:  0.32810658
Encoder Loss:  0.04913819  || Decoder Loss:  0.03312797 Validation Decoder Loss:  0.32808122
Encoder Loss:  0.04887775  || Decoder Loss:  0.033145078 Validation Decoder Loss:  0.3282194
Encoder Loss:  0.04910518  || Decoder Loss:  0.03318773 Validation Decoder Loss:  0.32836053
Encoder Loss:  0.048852906  || Decoder Loss:  0.033208523 Validation Decoder Loss:  0.32842988
Encoder Loss:  0.048615955  || Decoder Loss:  0.03322133 Validation Decoder Loss:  0.32855105
Encoder Loss:  0.04862966  || Decoder Loss:  0.03323712 Validation Decoder Loss:  0.32852837
Encoder Loss:  0.04889093  || Decoder Loss:  0.033256367 Validation Decoder Loss:  0.32892874
Encoder Loss:  0.048400264  || Decoder Loss:  0.033269145 Validation Decoder Loss:  0.3290066
Encoder Loss:  0.048360683  || Decoder Loss:  0.033293508 Validation Decoder Loss:  0.32916605
Encoder Loss:  0.04833035  || Decoder Loss:  0.03330216 Validation Decoder Loss:  0.32919383
Encoder Loss:  0.048384357  || Decoder Loss:  0.033314675 Validation Decoder Loss:  0.32945627
Encoder Loss:  0.048083395  || Decoder Loss:  0.033337977 Validation Decoder Loss:  0.3297337
Encoder Loss:  0.04799935  || Decoder Loss:  0.03334509 Validation Decoder Loss:  0.3297695
Encoder Loss:  0.047864966  || Decoder Loss:  0.033378482 Validation Decoder Loss:  0.32992297
Encoder Loss:  0.04783126  || Decoder Loss:  0.03339571 Validation Decoder Loss:  0.3299768
Encoder Loss:  0.04782847  || Decoder Loss:  0.033413623 Validation Decoder Loss:  0.33014774
Encoder Loss:  0.047690973  || Decoder Loss:  0.033453174 Validation Decoder Loss:  0.33036563
Encoder Loss:  0.047667652  || Decoder Loss:  0.033480715 Validation Decoder Loss:  0.33053595
Encoder Loss:  0.047607694  || Decoder Loss:  0.033512793 Validation Decoder Loss:  0.3305323
Encoder Loss:  0.047586646  || Decoder Loss:  0.033543076 Validation Decoder Loss:  0.33066845
Encoder Loss:  0.047473785  || Decoder Loss:  0.033569917 Validation Decoder Loss:  0.33076704
Encoder Loss:  0.047515035  || Decoder Loss:  0.03360095 Validation Decoder Loss:  0.33098552
Encoder Loss:  0.047473527  || Decoder Loss:  0.033628102 Validation Decoder Loss:  0.3310742
Encoder Loss:  0.047438227  || Decoder Loss:  0.03363083 Validation Decoder Loss:  0.33116147
Model: siamese_net_lr_0.0009610203444459307 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3311615
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_64 (Conv3DT (None, 212, 10, 19, 1)    299       
_________________________________________________________________
reshape_64 (Reshape)         (None, 2120, 19, 1)       0         
=================================================================
Total params: 299
Trainable params: 299
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 2120, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 2607, 19, 1)       489       
=================================================================
Total params: 489
Trainable params: 489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44263673  || Decoder Loss:  0.063445285 Validation Decoder Loss:  0.35863996
Encoder Loss:  0.36110404  || Decoder Loss:  0.124371834 Validation Decoder Loss:  0.771121
Encoder Loss:  0.088746004  || Decoder Loss:  0.13431723 Validation Decoder Loss:  0.40182924
Encoder Loss:  0.08640003  || Decoder Loss:  0.05195912 Validation Decoder Loss:  0.34480774
Encoder Loss:  0.08510027  || Decoder Loss:  0.03919723 Validation Decoder Loss:  0.33649647
Encoder Loss:  0.062329497  || Decoder Loss:  0.03630589 Validation Decoder Loss:  0.33376688
Encoder Loss:  0.053301983  || Decoder Loss:  0.0351551 Validation Decoder Loss:  0.33315408
Encoder Loss:  0.053124122  || Decoder Loss:  0.03470206 Validation Decoder Loss:  0.3330468
Encoder Loss:  0.052900814  || Decoder Loss:  0.034437668 Validation Decoder Loss:  0.3331756
Encoder Loss:  0.052669324  || Decoder Loss:  0.034220595 Validation Decoder Loss:  0.3333627
Encoder Loss:  0.052389976  || Decoder Loss:  0.033994246 Validation Decoder Loss:  0.33355856
Encoder Loss:  0.052151173  || Decoder Loss:  0.033762842 Validation Decoder Loss:  0.33371654
Encoder Loss:  0.05174962  || Decoder Loss:  0.03354451 Validation Decoder Loss:  0.33377546
Encoder Loss:  0.0514468  || Decoder Loss:  0.033357393 Validation Decoder Loss:  0.33374253
Encoder Loss:  0.051264733  || Decoder Loss:  0.03321059 Validation Decoder Loss:  0.33370632
Encoder Loss:  0.051039  || Decoder Loss:  0.033103835 Validation Decoder Loss:  0.3335869
Encoder Loss:  0.05092117  || Decoder Loss:  0.033013172 Validation Decoder Loss:  0.33351976
Encoder Loss:  0.050911132  || Decoder Loss:  0.032958653 Validation Decoder Loss:  0.33356774
Encoder Loss:  0.05084615  || Decoder Loss:  0.03292422 Validation Decoder Loss:  0.33356574
Encoder Loss:  0.050843768  || Decoder Loss:  0.03290122 Validation Decoder Loss:  0.33355713
Encoder Loss:  0.050777014  || Decoder Loss:  0.032883868 Validation Decoder Loss:  0.33355004
Encoder Loss:  0.050732832  || Decoder Loss:  0.032876626 Validation Decoder Loss:  0.33356285
Encoder Loss:  0.05075249  || Decoder Loss:  0.032876812 Validation Decoder Loss:  0.3335686
Encoder Loss:  0.05072261  || Decoder Loss:  0.03288106 Validation Decoder Loss:  0.333615
Encoder Loss:  0.05071029  || Decoder Loss:  0.03288968 Validation Decoder Loss:  0.3336119
Encoder Loss:  0.050669864  || Decoder Loss:  0.03289183 Validation Decoder Loss:  0.33357182
Encoder Loss:  0.050681543  || Decoder Loss:  0.03290652 Validation Decoder Loss:  0.33363903
Encoder Loss:  0.0506517  || Decoder Loss:  0.032916002 Validation Decoder Loss:  0.33365446
Encoder Loss:  0.050633002  || Decoder Loss:  0.03292664 Validation Decoder Loss:  0.3335784
Encoder Loss:  0.050586544  || Decoder Loss:  0.032950927 Validation Decoder Loss:  0.33360952
Encoder Loss:  0.0506108  || Decoder Loss:  0.0329583 Validation Decoder Loss:  0.33360046
Encoder Loss:  0.050572824  || Decoder Loss:  0.032973565 Validation Decoder Loss:  0.33354902
Encoder Loss:  0.05056987  || Decoder Loss:  0.032984305 Validation Decoder Loss:  0.33350757
Encoder Loss:  0.05056017  || Decoder Loss:  0.03301342 Validation Decoder Loss:  0.33356467
Encoder Loss:  0.05054514  || Decoder Loss:  0.03302501 Validation Decoder Loss:  0.33350134
Encoder Loss:  0.05052486  || Decoder Loss:  0.03303793 Validation Decoder Loss:  0.3334139
Encoder Loss:  0.050501835  || Decoder Loss:  0.03305777 Validation Decoder Loss:  0.33343232
Encoder Loss:  0.05049856  || Decoder Loss:  0.03308351 Validation Decoder Loss:  0.33353075
Encoder Loss:  0.050508995  || Decoder Loss:  0.033102266 Validation Decoder Loss:  0.3333842
Encoder Loss:  0.05048708  || Decoder Loss:  0.033116944 Validation Decoder Loss:  0.33348733
Model: siamese_net_lr_0.0003869634775275389 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3334873
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 68, 15, 19, 1)     36        
_________________________________________________________________
reshape_65 (Reshape)         (None, 1020, 19, 1)       0         
=================================================================
Total params: 36
Trainable params: 36
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 1020, 19, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 2607, 19, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30353263  || Decoder Loss:  0.08041611 Validation Decoder Loss:  0.35715166
Encoder Loss:  0.3006172  || Decoder Loss:  0.0736038 Validation Decoder Loss:  0.3548482
Encoder Loss:  0.29770184  || Decoder Loss:  0.06727102 Validation Decoder Loss:  0.3539343
Encoder Loss:  0.29461777  || Decoder Loss:  0.06175898 Validation Decoder Loss:  0.35456386
Encoder Loss:  0.28957614  || Decoder Loss:  0.057366934 Validation Decoder Loss:  0.35824764
Encoder Loss:  0.25883868  || Decoder Loss:  0.21723694 Validation Decoder Loss:  1.0622551
Encoder Loss:  0.13396184  || Decoder Loss:  0.1873308 Validation Decoder Loss:  0.91183555
Encoder Loss:  0.10760579  || Decoder Loss:  0.120104216 Validation Decoder Loss:  0.6993074
Encoder Loss:  0.09235901  || Decoder Loss:  0.08232388 Validation Decoder Loss:  0.5823448
Encoder Loss:  0.08336946  || Decoder Loss:  0.0612131 Validation Decoder Loss:  0.52969587
Encoder Loss:  0.07912639  || Decoder Loss:  0.05002998 Validation Decoder Loss:  0.47030416
Encoder Loss:  0.07619404  || Decoder Loss:  0.04314411 Validation Decoder Loss:  0.4307372
Encoder Loss:  0.07438853  || Decoder Loss:  0.03910581 Validation Decoder Loss:  0.40099734
Encoder Loss:  0.07319621  || Decoder Loss:  0.036482815 Validation Decoder Loss:  0.3798904
Encoder Loss:  0.07206187  || Decoder Loss:  0.034709707 Validation Decoder Loss:  0.3701809
Encoder Loss:  0.07166001  || Decoder Loss:  0.033453327 Validation Decoder Loss:  0.36032313
Encoder Loss:  0.07086394  || Decoder Loss:  0.032494064 Validation Decoder Loss:  0.35506892
Encoder Loss:  0.07058623  || Decoder Loss:  0.03183086 Validation Decoder Loss:  0.3509975
Encoder Loss:  0.07026355  || Decoder Loss:  0.03135155 Validation Decoder Loss:  0.3481027
Encoder Loss:  0.06999224  || Decoder Loss:  0.031004053 Validation Decoder Loss:  0.34618127
Encoder Loss:  0.06965392  || Decoder Loss:  0.030764462 Validation Decoder Loss:  0.34477645
Encoder Loss:  0.06929914  || Decoder Loss:  0.030588523 Validation Decoder Loss:  0.34384573
Encoder Loss:  0.06920928  || Decoder Loss:  0.030464001 Validation Decoder Loss:  0.34314078
Encoder Loss:  0.06876451  || Decoder Loss:  0.030359935 Validation Decoder Loss:  0.34268302
Encoder Loss:  0.06804059  || Decoder Loss:  0.030270876 Validation Decoder Loss:  0.3423841
Encoder Loss:  0.06505269  || Decoder Loss:  0.030180812 Validation Decoder Loss:  0.34192812
Encoder Loss:  0.056492556  || Decoder Loss:  0.030070946 Validation Decoder Loss:  0.34189004
Encoder Loss:  0.05044464  || Decoder Loss:  0.03002093 Validation Decoder Loss:  0.34267157
Encoder Loss:  0.05031992  || Decoder Loss:  0.029979296 Validation Decoder Loss:  0.34287512
Encoder Loss:  0.049491648  || Decoder Loss:  0.029934764 Validation Decoder Loss:  0.3430986
Encoder Loss:  0.049429532  || Decoder Loss:  0.02989656 Validation Decoder Loss:  0.34323135
Encoder Loss:  0.04924037  || Decoder Loss:  0.029859979 Validation Decoder Loss:  0.34339893
Encoder Loss:  0.04892949  || Decoder Loss:  0.029826822 Validation Decoder Loss:  0.34359926
Encoder Loss:  0.04865508  || Decoder Loss:  0.029796828 Validation Decoder Loss:  0.34379882
Encoder Loss:  0.0487393  || Decoder Loss:  0.029768279 Validation Decoder Loss:  0.34394044
Encoder Loss:  0.048630312  || Decoder Loss:  0.029739143 Validation Decoder Loss:  0.34409365
Encoder Loss:  0.048454467  || Decoder Loss:  0.029712467 Validation Decoder Loss:  0.3442595
Encoder Loss:  0.04825726  || Decoder Loss:  0.029688392 Validation Decoder Loss:  0.34440225
Encoder Loss:  0.04819412  || Decoder Loss:  0.029664062 Validation Decoder Loss:  0.34452754
Encoder Loss:  0.04799504  || Decoder Loss:  0.029642316 Validation Decoder Loss:  0.34466928
Model: siamese_net_lr_0.0008571794062665185 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34466928
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 257, 10, 19, 1)    409       
_________________________________________________________________
reshape_66 (Reshape)         (None, 2570, 19, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.33025712
Encoder Loss:  0.110050805  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776446 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Encoder Loss:  0.110050805  || Decoder Loss:  0.03677644 Validation Decoder Loss:  0.33025706
Encoder Loss:  0.11005081  || Decoder Loss:  0.036776442 Validation Decoder Loss:  0.3302571
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33025706
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_67 (Conv3DT (None, 180, 9, 19, 1)     271       
_________________________________________________________________
reshape_67 (Reshape)         (None, 1620, 19, 1)       0         
=================================================================
Total params: 271
Trainable params: 271
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 1620, 19, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 2607, 19, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20801172  || Decoder Loss:  0.08727337 Validation Decoder Loss:  0.3634076
Encoder Loss:  0.19335002  || Decoder Loss:  0.08429179 Validation Decoder Loss:  0.45495707
Encoder Loss:  0.2228296  || Decoder Loss:  0.27923295 Validation Decoder Loss:  0.7279035
Encoder Loss:  0.08749318  || Decoder Loss:  0.082236394 Validation Decoder Loss:  0.34693104
Encoder Loss:  0.055081487  || Decoder Loss:  0.033242706 Validation Decoder Loss:  0.3365259
Encoder Loss:  0.053968765  || Decoder Loss:  0.032017346 Validation Decoder Loss:  0.3359334
Encoder Loss:  0.04734364  || Decoder Loss:  0.031724617 Validation Decoder Loss:  0.33579546
Encoder Loss:  0.041948725  || Decoder Loss:  0.031692266 Validation Decoder Loss:  0.3359363
Encoder Loss:  0.040480804  || Decoder Loss:  0.03168373 Validation Decoder Loss:  0.33607805
Encoder Loss:  0.040114645  || Decoder Loss:  0.031664267 Validation Decoder Loss:  0.33622915
Encoder Loss:  0.039848812  || Decoder Loss:  0.031646393 Validation Decoder Loss:  0.33639336
Encoder Loss:  0.03955513  || Decoder Loss:  0.031638756 Validation Decoder Loss:  0.33658743
Encoder Loss:  0.0393507  || Decoder Loss:  0.03164423 Validation Decoder Loss:  0.33680633
Encoder Loss:  0.039220124  || Decoder Loss:  0.03165369 Validation Decoder Loss:  0.33703783
Encoder Loss:  0.039021112  || Decoder Loss:  0.03167587 Validation Decoder Loss:  0.3373025
Encoder Loss:  0.038996425  || Decoder Loss:  0.031693786 Validation Decoder Loss:  0.33754975
Encoder Loss:  0.03900851  || Decoder Loss:  0.03170289 Validation Decoder Loss:  0.33779123
Encoder Loss:  0.03889109  || Decoder Loss:  0.031717874 Validation Decoder Loss:  0.33802867
Encoder Loss:  0.038864564  || Decoder Loss:  0.031734318 Validation Decoder Loss:  0.33829588
Encoder Loss:  0.03897072  || Decoder Loss:  0.03174411 Validation Decoder Loss:  0.33846572
Encoder Loss:  0.03894229  || Decoder Loss:  0.031731885 Validation Decoder Loss:  0.33866408
Encoder Loss:  0.038802106  || Decoder Loss:  0.031743776 Validation Decoder Loss:  0.33888465
Encoder Loss:  0.038870707  || Decoder Loss:  0.031753637 Validation Decoder Loss:  0.33906227
Encoder Loss:  0.038619205  || Decoder Loss:  0.0317859 Validation Decoder Loss:  0.33929306
Encoder Loss:  0.0387751  || Decoder Loss:  0.03180402 Validation Decoder Loss:  0.33949864
Encoder Loss:  0.039787985  || Decoder Loss:  0.031741127 Validation Decoder Loss:  0.33935034
Encoder Loss:  0.038635377  || Decoder Loss:  0.031734295 Validation Decoder Loss:  0.3394567
Encoder Loss:  0.038871195  || Decoder Loss:  0.031734772 Validation Decoder Loss:  0.3395675
Encoder Loss:  0.03857119  || Decoder Loss:  0.031760994 Validation Decoder Loss:  0.33976847
Encoder Loss:  0.038858544  || Decoder Loss:  0.03176482 Validation Decoder Loss:  0.33984327
Encoder Loss:  0.039141312  || Decoder Loss:  0.03174484 Validation Decoder Loss:  0.33986515
Encoder Loss:  0.038567062  || Decoder Loss:  0.031769834 Validation Decoder Loss:  0.3399764
Encoder Loss:  0.038625933  || Decoder Loss:  0.031817663 Validation Decoder Loss:  0.34019676
Encoder Loss:  0.038964428  || Decoder Loss:  0.03180477 Validation Decoder Loss:  0.34020057
Encoder Loss:  0.03869159  || Decoder Loss:  0.031779245 Validation Decoder Loss:  0.34027746
Encoder Loss:  0.038527977  || Decoder Loss:  0.031833436 Validation Decoder Loss:  0.3405267
Encoder Loss:  0.038693134  || Decoder Loss:  0.03185657 Validation Decoder Loss:  0.34067386
Encoder Loss:  0.038904805  || Decoder Loss:  0.03184447 Validation Decoder Loss:  0.3407046
Encoder Loss:  0.038893834  || Decoder Loss:  0.031780425 Validation Decoder Loss:  0.34052107
Encoder Loss:  0.038786154  || Decoder Loss:  0.03177378 Validation Decoder Loss:  0.34053662
Model: siamese_net_lr_0.0007734042592969101 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34053662
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 170, 6, 19, 1)     89        
_________________________________________________________________
reshape_68 (Reshape)         (None, 1020, 19, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 1020, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 2607, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11810164  || Decoder Loss:  0.06284892 Validation Decoder Loss:  0.3618283
Encoder Loss:  0.11802233  || Decoder Loss:  0.06285318 Validation Decoder Loss:  0.36190963
Encoder Loss:  0.11809498  || Decoder Loss:  0.063074216 Validation Decoder Loss:  0.36191708
Encoder Loss:  0.118371956  || Decoder Loss:  0.06360378 Validation Decoder Loss:  0.36195135
Encoder Loss:  0.11894253  || Decoder Loss:  0.06460746 Validation Decoder Loss:  0.3621313
Encoder Loss:  0.12000169  || Decoder Loss:  0.06646908 Validation Decoder Loss:  0.36281538
Encoder Loss:  0.122058965  || Decoder Loss:  0.07032463 Validation Decoder Loss:  0.36549938
Encoder Loss:  0.12711044  || Decoder Loss:  0.08219674 Validation Decoder Loss:  0.38774264
Encoder Loss:  0.1422041  || Decoder Loss:  0.14041373 Validation Decoder Loss:  0.45843074
Encoder Loss:  0.0997008  || Decoder Loss:  0.09894537 Validation Decoder Loss:  0.4135766
Encoder Loss:  0.08191347  || Decoder Loss:  0.078210786 Validation Decoder Loss:  0.3890515
Encoder Loss:  0.07122896  || Decoder Loss:  0.06575471 Validation Decoder Loss:  0.37164944
Encoder Loss:  0.063757636  || Decoder Loss:  0.057055727 Validation Decoder Loss:  0.3597255
Encoder Loss:  0.05847699  || Decoder Loss:  0.05091418 Validation Decoder Loss:  0.35161778
Encoder Loss:  0.054735128  || Decoder Loss:  0.04655075 Validation Decoder Loss:  0.3459586
Encoder Loss:  0.052062053  || Decoder Loss:  0.043444157 Validation Decoder Loss:  0.34205145
Encoder Loss:  0.0501501  || Decoder Loss:  0.04121544 Validation Decoder Loss:  0.33929676
Encoder Loss:  0.048749086  || Decoder Loss:  0.039585907 Validation Decoder Loss:  0.33730623
Encoder Loss:  0.04768803  || Decoder Loss:  0.03835894 Validation Decoder Loss:  0.33584547
Encoder Loss:  0.046862587  || Decoder Loss:  0.03740799 Validation Decoder Loss:  0.33475512
Encoder Loss:  0.046208166  || Decoder Loss:  0.03665294 Validation Decoder Loss:  0.33392173
Encoder Loss:  0.045676727  || Decoder Loss:  0.036042396 Validation Decoder Loss:  0.33326963
Encoder Loss:  0.045240432  || Decoder Loss:  0.03554838 Validation Decoder Loss:  0.3327732
Encoder Loss:  0.044894714  || Decoder Loss:  0.03515211 Validation Decoder Loss:  0.33237767
Encoder Loss:  0.044606924  || Decoder Loss:  0.034836575 Validation Decoder Loss:  0.33207202
Encoder Loss:  0.044380892  || Decoder Loss:  0.03458958 Validation Decoder Loss:  0.33183455
Encoder Loss:  0.044200357  || Decoder Loss:  0.03439845 Validation Decoder Loss:  0.33165085
Encoder Loss:  0.044059563  || Decoder Loss:  0.034251593 Validation Decoder Loss:  0.3315109
Encoder Loss:  0.043938667  || Decoder Loss:  0.034138463 Validation Decoder Loss:  0.3314016
Encoder Loss:  0.043829154  || Decoder Loss:  0.034050178 Validation Decoder Loss:  0.3313204
Encoder Loss:  0.043721195  || Decoder Loss:  0.033979308 Validation Decoder Loss:  0.33126158
Encoder Loss:  0.043592416  || Decoder Loss:  0.033920344 Validation Decoder Loss:  0.3312198
Encoder Loss:  0.043384105  || Decoder Loss:  0.033869438 Validation Decoder Loss:  0.3311919
Encoder Loss:  0.04208348  || Decoder Loss:  0.033823043 Validation Decoder Loss:  0.33118677
Encoder Loss:  0.03737401  || Decoder Loss:  0.033778757 Validation Decoder Loss:  0.33122772
Encoder Loss:  0.037229653  || Decoder Loss:  0.03375174 Validation Decoder Loss:  0.3312567
Encoder Loss:  0.03717113  || Decoder Loss:  0.033721723 Validation Decoder Loss:  0.33127448
Encoder Loss:  0.03712518  || Decoder Loss:  0.033690974 Validation Decoder Loss:  0.33129233
Encoder Loss:  0.037083667  || Decoder Loss:  0.033661284 Validation Decoder Loss:  0.33131027
Encoder Loss:  0.03704914  || Decoder Loss:  0.033632375 Validation Decoder Loss:  0.33132565
Model: siamese_net_lr_0.00018927696432619528 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33132565
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 102, 10, 19, 1)    235       
_________________________________________________________________
reshape_69 (Reshape)         (None, 1020, 19, 1)       0         
=================================================================
Total params: 235
Trainable params: 235
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 1020, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 2607, 19, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44119018  || Decoder Loss:  0.08658543 Validation Decoder Loss:  0.36460954
Encoder Loss:  0.44109222  || Decoder Loss:  0.0862748 Validation Decoder Loss:  0.3644721
Encoder Loss:  0.4409962  || Decoder Loss:  0.085969515 Validation Decoder Loss:  0.36434054
Encoder Loss:  0.4409014  || Decoder Loss:  0.08567205 Validation Decoder Loss:  0.36421478
Encoder Loss:  0.44080746  || Decoder Loss:  0.085381985 Validation Decoder Loss:  0.36409453
Encoder Loss:  0.4407143  || Decoder Loss:  0.08509875 Validation Decoder Loss:  0.36397946
Encoder Loss:  0.4406218  || Decoder Loss:  0.08482188 Validation Decoder Loss:  0.3638693
Encoder Loss:  0.4405301  || Decoder Loss:  0.08455092 Validation Decoder Loss:  0.36376375
Encoder Loss:  0.44043872  || Decoder Loss:  0.08428541 Validation Decoder Loss:  0.3636626
Encoder Loss:  0.44034782  || Decoder Loss:  0.084024906 Validation Decoder Loss:  0.36356568
Encoder Loss:  0.44025746  || Decoder Loss:  0.08376911 Validation Decoder Loss:  0.36347267
Encoder Loss:  0.44016728  || Decoder Loss:  0.083517626 Validation Decoder Loss:  0.36338347
Encoder Loss:  0.44007713  || Decoder Loss:  0.08327012 Validation Decoder Loss:  0.3632979
Encoder Loss:  0.43998736  || Decoder Loss:  0.08302635 Validation Decoder Loss:  0.36321583
Encoder Loss:  0.4398977  || Decoder Loss:  0.08278601 Validation Decoder Loss:  0.36313707
Encoder Loss:  0.43980792  || Decoder Loss:  0.08254886 Validation Decoder Loss:  0.3630615
Encoder Loss:  0.43971828  || Decoder Loss:  0.082314685 Validation Decoder Loss:  0.3629889
Encoder Loss:  0.4396285  || Decoder Loss:  0.08208323 Validation Decoder Loss:  0.36291924
Encoder Loss:  0.43953857  || Decoder Loss:  0.0818544 Validation Decoder Loss:  0.3628524
Encoder Loss:  0.43944862  || Decoder Loss:  0.08162797 Validation Decoder Loss:  0.3627882
Encoder Loss:  0.43935844  || Decoder Loss:  0.081403755 Validation Decoder Loss:  0.36272663
Encoder Loss:  0.43926814  || Decoder Loss:  0.08118169 Validation Decoder Loss:  0.36266756
Encoder Loss:  0.43917742  || Decoder Loss:  0.0809616 Validation Decoder Loss:  0.3626109
Encoder Loss:  0.4390865  || Decoder Loss:  0.08074335 Validation Decoder Loss:  0.36255664
Encoder Loss:  0.43899512  || Decoder Loss:  0.080526896 Validation Decoder Loss:  0.36250472
Encoder Loss:  0.43890354  || Decoder Loss:  0.08031212 Validation Decoder Loss:  0.36245498
Encoder Loss:  0.4388116  || Decoder Loss:  0.08009889 Validation Decoder Loss:  0.3624075
Encoder Loss:  0.43871915  || Decoder Loss:  0.079887204 Validation Decoder Loss:  0.3623622
Encoder Loss:  0.43862656  || Decoder Loss:  0.07967698 Validation Decoder Loss:  0.36231905
Encoder Loss:  0.43853313  || Decoder Loss:  0.07946812 Validation Decoder Loss:  0.36227798
Encoder Loss:  0.4384395  || Decoder Loss:  0.07926063 Validation Decoder Loss:  0.36223894
Encoder Loss:  0.43834522  || Decoder Loss:  0.07905441 Validation Decoder Loss:  0.362202
Encoder Loss:  0.43825057  || Decoder Loss:  0.07884941 Validation Decoder Loss:  0.36216706
Encoder Loss:  0.4381554  || Decoder Loss:  0.07864563 Validation Decoder Loss:  0.3621341
Encoder Loss:  0.43805972  || Decoder Loss:  0.078443006 Validation Decoder Loss:  0.36210313
Encoder Loss:  0.43796346  || Decoder Loss:  0.07824154 Validation Decoder Loss:  0.3620742
Encoder Loss:  0.43786666  || Decoder Loss:  0.07804119 Validation Decoder Loss:  0.36204717
Encoder Loss:  0.4377691  || Decoder Loss:  0.07784193 Validation Decoder Loss:  0.36202216
Encoder Loss:  0.43767112  || Decoder Loss:  0.077643745 Validation Decoder Loss:  0.36199915
Encoder Loss:  0.43757248  || Decoder Loss:  0.07744658 Validation Decoder Loss:  0.36197817
Model: siamese_net_lr_1.8816599657222526e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36197817
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_70 (Conv3DT (None, 70, 36, 19, 1)     197       
_________________________________________________________________
reshape_70 (Reshape)         (None, 2520, 19, 1)       0         
=================================================================
Total params: 197
Trainable params: 197
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 2520, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 2607, 19, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03653806  || Decoder Loss:  0.03653806 Validation Decoder Loss:  0.3326392
Encoder Loss:  0.034625098  || Decoder Loss:  0.034625098 Validation Decoder Loss:  0.32901904
Encoder Loss:  0.034460478  || Decoder Loss:  0.034460478 Validation Decoder Loss:  0.32918504
Encoder Loss:  0.034430765  || Decoder Loss:  0.034430765 Validation Decoder Loss:  0.32919106
Encoder Loss:  0.034410592  || Decoder Loss:  0.034410592 Validation Decoder Loss:  0.3291493
Encoder Loss:  0.034393396  || Decoder Loss:  0.034393396 Validation Decoder Loss:  0.32908374
Encoder Loss:  0.034377437  || Decoder Loss:  0.034377437 Validation Decoder Loss:  0.32900208
Encoder Loss:  0.034361955  || Decoder Loss:  0.034361955 Validation Decoder Loss:  0.32890683
Encoder Loss:  0.03434668  || Decoder Loss:  0.03434668 Validation Decoder Loss:  0.3287992
Encoder Loss:  0.03433154  || Decoder Loss:  0.03433154 Validation Decoder Loss:  0.3286814
Encoder Loss:  0.034316648  || Decoder Loss:  0.034316648 Validation Decoder Loss:  0.32855773
Encoder Loss:  0.034302212  || Decoder Loss:  0.034302212 Validation Decoder Loss:  0.32843477
Encoder Loss:  0.03428849  || Decoder Loss:  0.03428849 Validation Decoder Loss:  0.3283198
Encoder Loss:  0.03427565  || Decoder Loss:  0.03427565 Validation Decoder Loss:  0.32821852
Encoder Loss:  0.034263954  || Decoder Loss:  0.034263954 Validation Decoder Loss:  0.3281338
Encoder Loss:  0.03425338  || Decoder Loss:  0.03425338 Validation Decoder Loss:  0.3280652
Encoder Loss:  0.03424389  || Decoder Loss:  0.03424389 Validation Decoder Loss:  0.32801047
Encoder Loss:  0.034235418  || Decoder Loss:  0.034235418 Validation Decoder Loss:  0.32796693
Encoder Loss:  0.034227908  || Decoder Loss:  0.034227908 Validation Decoder Loss:  0.32793224
Encoder Loss:  0.03422121  || Decoder Loss:  0.03422121 Validation Decoder Loss:  0.32790446
Encoder Loss:  0.034215253  || Decoder Loss:  0.034215253 Validation Decoder Loss:  0.32788235
Encoder Loss:  0.03420994  || Decoder Loss:  0.03420994 Validation Decoder Loss:  0.32786494
Encoder Loss:  0.034205217  || Decoder Loss:  0.034205217 Validation Decoder Loss:  0.32785147
Encoder Loss:  0.03420104  || Decoder Loss:  0.03420104 Validation Decoder Loss:  0.3278414
Encoder Loss:  0.03419729  || Decoder Loss:  0.03419729 Validation Decoder Loss:  0.32783422
Encoder Loss:  0.034193948  || Decoder Loss:  0.034193948 Validation Decoder Loss:  0.32782954
Encoder Loss:  0.03419098  || Decoder Loss:  0.03419098 Validation Decoder Loss:  0.327827
Encoder Loss:  0.03418828  || Decoder Loss:  0.03418828 Validation Decoder Loss:  0.3278262
Encoder Loss:  0.03418588  || Decoder Loss:  0.03418588 Validation Decoder Loss:  0.32782698
Encoder Loss:  0.034183696  || Decoder Loss:  0.034183696 Validation Decoder Loss:  0.32782897
Encoder Loss:  0.034181762  || Decoder Loss:  0.034181762 Validation Decoder Loss:  0.32783204
Encoder Loss:  0.034179945  || Decoder Loss:  0.034179945 Validation Decoder Loss:  0.32783604
Encoder Loss:  0.034178335  || Decoder Loss:  0.034178335 Validation Decoder Loss:  0.32784075
Encoder Loss:  0.034176864  || Decoder Loss:  0.034176864 Validation Decoder Loss:  0.3278461
Encoder Loss:  0.03417547  || Decoder Loss:  0.03417547 Validation Decoder Loss:  0.327852
Encoder Loss:  0.034174256  || Decoder Loss:  0.034174256 Validation Decoder Loss:  0.32785833
Encoder Loss:  0.0341731  || Decoder Loss:  0.0341731 Validation Decoder Loss:  0.327865
Encoder Loss:  0.034172047  || Decoder Loss:  0.034172047 Validation Decoder Loss:  0.32787198
Encoder Loss:  0.034171037  || Decoder Loss:  0.034171037 Validation Decoder Loss:  0.32787922
Encoder Loss:  0.034170136  || Decoder Loss:  0.034170136 Validation Decoder Loss:  0.32788667
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3278867
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 74, 5, 19, 1)      12        
_________________________________________________________________
reshape_71 (Reshape)         (None, 370, 19, 1)        0         
=================================================================
Total params: 12
Trainable params: 12
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 370, 19, 1)        2239      
=================================================================
Total params: 2,239
Trainable params: 2,239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 2607, 19, 1)       2239      
=================================================================
Total params: 2,239
Trainable params: 2,239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.118008755  || Decoder Loss:  0.0475227 Validation Decoder Loss:  0.36162642
Encoder Loss:  0.11683502  || Decoder Loss:  0.046112638 Validation Decoder Loss:  0.3634771
Encoder Loss:  0.11585575  || Decoder Loss:  0.044941578 Validation Decoder Loss:  0.36403075
Encoder Loss:  0.11501224  || Decoder Loss:  0.043939643 Validation Decoder Loss:  0.36423916
Encoder Loss:  0.11426449  || Decoder Loss:  0.043060087 Validation Decoder Loss:  0.36427146
Encoder Loss:  0.113586396  || Decoder Loss:  0.0422739 Validation Decoder Loss:  0.36417645
Encoder Loss:  0.11295703  || Decoder Loss:  0.04156017 Validation Decoder Loss:  0.3639923
Encoder Loss:  0.11235782  || Decoder Loss:  0.040903915 Validation Decoder Loss:  0.36375117
Encoder Loss:  0.11176773  || Decoder Loss:  0.040294405 Validation Decoder Loss:  0.36347663
Encoder Loss:  0.11115363  || Decoder Loss:  0.039724097 Validation Decoder Loss:  0.3631861
Encoder Loss:  0.11043613  || Decoder Loss:  0.03918839 Validation Decoder Loss:  0.36289856
Encoder Loss:  0.109296836  || Decoder Loss:  0.038688596 Validation Decoder Loss:  0.36266184
Encoder Loss:  0.10369508  || Decoder Loss:  0.03833813 Validation Decoder Loss:  0.36371613
Encoder Loss:  0.109334596  || Decoder Loss:  0.103552245 Validation Decoder Loss:  0.72445804
Encoder Loss:  0.06976716  || Decoder Loss:  0.062250838 Validation Decoder Loss:  0.59541595
Encoder Loss:  0.061449286  || Decoder Loss:  0.052467514 Validation Decoder Loss:  0.5796969
Encoder Loss:  0.0577749  || Decoder Loss:  0.047858234 Validation Decoder Loss:  0.5413643
Encoder Loss:  0.05485891  || Decoder Loss:  0.044444583 Validation Decoder Loss:  0.52206767
Encoder Loss:  0.05313575  || Decoder Loss:  0.042405847 Validation Decoder Loss:  0.5077273
Encoder Loss:  0.05184192  || Decoder Loss:  0.04088397 Validation Decoder Loss:  0.49728805
Encoder Loss:  0.050762437  || Decoder Loss:  0.039602038 Validation Decoder Loss:  0.4833495
Encoder Loss:  0.04995384  || Decoder Loss:  0.038703267 Validation Decoder Loss:  0.4813214
Encoder Loss:  0.049393896  || Decoder Loss:  0.03798878 Validation Decoder Loss:  0.4735257
Encoder Loss:  0.048867006  || Decoder Loss:  0.03737663 Validation Decoder Loss:  0.46787477
Encoder Loss:  0.048363924  || Decoder Loss:  0.036788136 Validation Decoder Loss:  0.4616458
Encoder Loss:  0.047997933  || Decoder Loss:  0.0363141 Validation Decoder Loss:  0.4418976
Encoder Loss:  0.047234107  || Decoder Loss:  0.03559216 Validation Decoder Loss:  0.4478721
Encoder Loss:  0.047112335  || Decoder Loss:  0.03535371 Validation Decoder Loss:  0.44764522
Encoder Loss:  0.046947733  || Decoder Loss:  0.03507174 Validation Decoder Loss:  0.42965746
Encoder Loss:  0.046313535  || Decoder Loss:  0.034526248 Validation Decoder Loss:  0.43717688
Encoder Loss:  0.0463237  || Decoder Loss:  0.034358803 Validation Decoder Loss:  0.42300296
Encoder Loss:  0.045813564  || Decoder Loss:  0.033949282 Validation Decoder Loss:  0.43159187
Encoder Loss:  0.04583376  || Decoder Loss:  0.033758383 Validation Decoder Loss:  0.4128238
Encoder Loss:  0.04530992  || Decoder Loss:  0.033353362 Validation Decoder Loss:  0.42350078
Encoder Loss:  0.04547969  || Decoder Loss:  0.03328126 Validation Decoder Loss:  0.40952387
Encoder Loss:  0.04495509  || Decoder Loss:  0.03285761 Validation Decoder Loss:  0.40204877
Encoder Loss:  0.04466875  || Decoder Loss:  0.03262913 Validation Decoder Loss:  0.41017485
Encoder Loss:  0.044815596  || Decoder Loss:  0.032598935 Validation Decoder Loss:  0.40001783
Encoder Loss:  0.044422835  || Decoder Loss:  0.032253478 Validation Decoder Loss:  0.3931116
Encoder Loss:  0.044135623  || Decoder Loss:  0.03202304 Validation Decoder Loss:  0.39976203
Model: siamese_net_lr_0.00034114002190846964 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.39976203
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 434, 5, 19, 1)     120       
_________________________________________________________________
reshape_72 (Reshape)         (None, 2170, 19, 1)       0         
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 2170, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 2607, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18136431  || Decoder Loss:  0.054208945 Validation Decoder Loss:  0.36086762
Encoder Loss:  0.18127762  || Decoder Loss:  0.054480962 Validation Decoder Loss:  0.36164826
Encoder Loss:  0.18142137  || Decoder Loss:  0.055720072 Validation Decoder Loss:  0.36258548
Encoder Loss:  0.1819855  || Decoder Loss:  0.0618828 Validation Decoder Loss:  0.37100506
Encoder Loss:  0.16522852  || Decoder Loss:  0.15175664 Validation Decoder Loss:  0.4126631
Encoder Loss:  0.082571305  || Decoder Loss:  0.07275068 Validation Decoder Loss:  0.37412137
Encoder Loss:  0.06977189  || Decoder Loss:  0.05438294 Validation Decoder Loss:  0.35491616
Encoder Loss:  0.06403953  || Decoder Loss:  0.046072587 Validation Decoder Loss:  0.34427667
Encoder Loss:  0.061132647  || Decoder Loss:  0.041713223 Validation Decoder Loss:  0.33834058
Encoder Loss:  0.059198886  || Decoder Loss:  0.03928914 Validation Decoder Loss:  0.3351616
Encoder Loss:  0.057927597  || Decoder Loss:  0.037924267 Validation Decoder Loss:  0.33333978
Encoder Loss:  0.04686345  || Decoder Loss:  0.037076566 Validation Decoder Loss:  0.33217868
Encoder Loss:  0.042388186  || Decoder Loss:  0.036557525 Validation Decoder Loss:  0.33163714
Encoder Loss:  0.041923076  || Decoder Loss:  0.03611684 Validation Decoder Loss:  0.33121544
Encoder Loss:  0.04160237  || Decoder Loss:  0.035735525 Validation Decoder Loss:  0.33092597
Encoder Loss:  0.041356586  || Decoder Loss:  0.03543701 Validation Decoder Loss:  0.330751
Encoder Loss:  0.041144654  || Decoder Loss:  0.03521187 Validation Decoder Loss:  0.3306521
Encoder Loss:  0.040983178  || Decoder Loss:  0.0350438 Validation Decoder Loss:  0.33060038
Encoder Loss:  0.040850688  || Decoder Loss:  0.03491741 Validation Decoder Loss:  0.3305766
Encoder Loss:  0.040741015  || Decoder Loss:  0.03482329 Validation Decoder Loss:  0.33057457
Encoder Loss:  0.04065216  || Decoder Loss:  0.034753084 Validation Decoder Loss:  0.3305819
Encoder Loss:  0.040562753  || Decoder Loss:  0.034699026 Validation Decoder Loss:  0.33059978
Encoder Loss:  0.04051977  || Decoder Loss:  0.034657024 Validation Decoder Loss:  0.33062246
Encoder Loss:  0.04045647  || Decoder Loss:  0.034622885 Validation Decoder Loss:  0.33064312
Encoder Loss:  0.04039982  || Decoder Loss:  0.034595937 Validation Decoder Loss:  0.33066952
Encoder Loss:  0.040326048  || Decoder Loss:  0.034569636 Validation Decoder Loss:  0.33069342
Encoder Loss:  0.040256605  || Decoder Loss:  0.034545865 Validation Decoder Loss:  0.33071673
Encoder Loss:  0.040185973  || Decoder Loss:  0.03452395 Validation Decoder Loss:  0.3307432
Encoder Loss:  0.040135436  || Decoder Loss:  0.03450335 Validation Decoder Loss:  0.33077317
Encoder Loss:  0.040084597  || Decoder Loss:  0.03448278 Validation Decoder Loss:  0.33080125
Encoder Loss:  0.040031582  || Decoder Loss:  0.034458503 Validation Decoder Loss:  0.33082193
Encoder Loss:  0.03998059  || Decoder Loss:  0.034434665 Validation Decoder Loss:  0.33084083
Encoder Loss:  0.039931532  || Decoder Loss:  0.03441262 Validation Decoder Loss:  0.33086973
Encoder Loss:  0.039854098  || Decoder Loss:  0.034387175 Validation Decoder Loss:  0.33089414
Encoder Loss:  0.03980369  || Decoder Loss:  0.034362093 Validation Decoder Loss:  0.33091396
Encoder Loss:  0.039744638  || Decoder Loss:  0.034336727 Validation Decoder Loss:  0.33092645
Encoder Loss:  0.039700206  || Decoder Loss:  0.03431274 Validation Decoder Loss:  0.330934
Encoder Loss:  0.039677605  || Decoder Loss:  0.03428826 Validation Decoder Loss:  0.330923
Encoder Loss:  0.03963861  || Decoder Loss:  0.034265462 Validation Decoder Loss:  0.3309135
Encoder Loss:  0.039596748  || Decoder Loss:  0.03424413 Validation Decoder Loss:  0.33091283
Model: siamese_net_lr_0.0005988518595614346 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33091283
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_73 (Conv3DT (None, 434, 5, 19, 1)     246       
_________________________________________________________________
reshape_73 (Reshape)         (None, 2170, 19, 1)       0         
=================================================================
Total params: 246
Trainable params: 246
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 2170, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 2607, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2552063  || Decoder Loss:  0.057691023 Validation Decoder Loss:  0.35792783
Encoder Loss:  0.25500467  || Decoder Loss:  0.058797985 Validation Decoder Loss:  0.3581089
Encoder Loss:  0.2546873  || Decoder Loss:  0.06074978 Validation Decoder Loss:  0.35773253
Encoder Loss:  0.25403333  || Decoder Loss:  0.06440207 Validation Decoder Loss:  0.3570996
Encoder Loss:  0.25222352  || Decoder Loss:  0.07254442 Validation Decoder Loss:  0.3583405
Encoder Loss:  0.24412231  || Decoder Loss:  0.10048322 Validation Decoder Loss:  0.3994368
Encoder Loss:  0.21485242  || Decoder Loss:  0.2712545 Validation Decoder Loss:  0.5339009
Encoder Loss:  0.11647153  || Decoder Loss:  0.14149389 Validation Decoder Loss:  0.45485747
Encoder Loss:  0.092060745  || Decoder Loss:  0.09085677 Validation Decoder Loss:  0.4076959
Encoder Loss:  0.08026559  || Decoder Loss:  0.06815825 Validation Decoder Loss:  0.37652194
Encoder Loss:  0.073525175  || Decoder Loss:  0.054382302 Validation Decoder Loss:  0.3575871
Encoder Loss:  0.06908855  || Decoder Loss:  0.04645058 Validation Decoder Loss:  0.34818593
Encoder Loss:  0.067148425  || Decoder Loss:  0.042256918 Validation Decoder Loss:  0.34256563
Encoder Loss:  0.065479524  || Decoder Loss:  0.03990753 Validation Decoder Loss:  0.3393479
Encoder Loss:  0.05805755  || Decoder Loss:  0.038561136 Validation Decoder Loss:  0.33725402
Encoder Loss:  0.04583178  || Decoder Loss:  0.037757035 Validation Decoder Loss:  0.33581817
Encoder Loss:  0.04485299  || Decoder Loss:  0.037052575 Validation Decoder Loss:  0.3348921
Encoder Loss:  0.044530474  || Decoder Loss:  0.03652004 Validation Decoder Loss:  0.33417574
Encoder Loss:  0.04428126  || Decoder Loss:  0.036101934 Validation Decoder Loss:  0.3336502
Encoder Loss:  0.044063777  || Decoder Loss:  0.03575914 Validation Decoder Loss:  0.33319715
Encoder Loss:  0.043834206  || Decoder Loss:  0.035484627 Validation Decoder Loss:  0.33288556
Encoder Loss:  0.043756723  || Decoder Loss:  0.035263732 Validation Decoder Loss:  0.33264494
Encoder Loss:  0.04372801  || Decoder Loss:  0.03508906 Validation Decoder Loss:  0.33251297
Encoder Loss:  0.04342324  || Decoder Loss:  0.03494782 Validation Decoder Loss:  0.33240283
Encoder Loss:  0.043504965  || Decoder Loss:  0.034815777 Validation Decoder Loss:  0.33232856
Encoder Loss:  0.04322479  || Decoder Loss:  0.034706287 Validation Decoder Loss:  0.33227858
Encoder Loss:  0.043171555  || Decoder Loss:  0.03459994 Validation Decoder Loss:  0.33223438
Encoder Loss:  0.04317585  || Decoder Loss:  0.03450522 Validation Decoder Loss:  0.33222678
Encoder Loss:  0.043011047  || Decoder Loss:  0.034421913 Validation Decoder Loss:  0.33223134
Encoder Loss:  0.04296139  || Decoder Loss:  0.034343004 Validation Decoder Loss:  0.33224308
Encoder Loss:  0.04285352  || Decoder Loss:  0.03426793 Validation Decoder Loss:  0.33224145
Encoder Loss:  0.042772345  || Decoder Loss:  0.034195554 Validation Decoder Loss:  0.33224434
Encoder Loss:  0.042679783  || Decoder Loss:  0.034127045 Validation Decoder Loss:  0.33224374
Encoder Loss:  0.04266618  || Decoder Loss:  0.034065474 Validation Decoder Loss:  0.3322638
Encoder Loss:  0.04260852  || Decoder Loss:  0.03400969 Validation Decoder Loss:  0.3322928
Encoder Loss:  0.04259786  || Decoder Loss:  0.033957712 Validation Decoder Loss:  0.33232492
Encoder Loss:  0.04253079  || Decoder Loss:  0.033909224 Validation Decoder Loss:  0.3323601
Encoder Loss:  0.042470116  || Decoder Loss:  0.03386572 Validation Decoder Loss:  0.3323665
Encoder Loss:  0.04240923  || Decoder Loss:  0.033824395 Validation Decoder Loss:  0.33237782
Encoder Loss:  0.042371254  || Decoder Loss:  0.033787943 Validation Decoder Loss:  0.33238113
Model: siamese_net_lr_0.0008208686317962693 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33238113
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 110, 7, 19, 1)     142       
_________________________________________________________________
reshape_74 (Reshape)         (None, 770, 19, 1)        0         
=================================================================
Total params: 142
Trainable params: 142
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 770, 19, 1)        301       
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 2607, 19, 1)       301       
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20333685  || Decoder Loss:  0.05153537 Validation Decoder Loss:  0.34858292
Encoder Loss:  0.20348316  || Decoder Loss:  0.052928045 Validation Decoder Loss:  0.34897196
Encoder Loss:  0.20364456  || Decoder Loss:  0.054856107 Validation Decoder Loss:  0.3495119
Encoder Loss:  0.2037628  || Decoder Loss:  0.057553004 Validation Decoder Loss:  0.35052928
Encoder Loss:  0.20363006  || Decoder Loss:  0.061375868 Validation Decoder Loss:  0.35235924
Encoder Loss:  0.2022139  || Decoder Loss:  0.06624795 Validation Decoder Loss:  0.35385573
Encoder Loss:  0.18941025  || Decoder Loss:  0.06052754 Validation Decoder Loss:  0.36238334
Encoder Loss:  0.14615087  || Decoder Loss:  0.037591133 Validation Decoder Loss:  0.3364106
Encoder Loss:  0.067330524  || Decoder Loss:  0.03710799 Validation Decoder Loss:  0.33706805
Encoder Loss:  0.060561556  || Decoder Loss:  0.03636285 Validation Decoder Loss:  0.33535686
Encoder Loss:  0.05979737  || Decoder Loss:  0.035856005 Validation Decoder Loss:  0.33432817
Encoder Loss:  0.059505295  || Decoder Loss:  0.035547998 Validation Decoder Loss:  0.33364615
Encoder Loss:  0.05925367  || Decoder Loss:  0.035346385 Validation Decoder Loss:  0.3331855
Encoder Loss:  0.058965545  || Decoder Loss:  0.03520635 Validation Decoder Loss:  0.33286977
Encoder Loss:  0.058497895  || Decoder Loss:  0.035102736 Validation Decoder Loss:  0.3326541
Encoder Loss:  0.05137627  || Decoder Loss:  0.035021868 Validation Decoder Loss:  0.3325077
Encoder Loss:  0.042714354  || Decoder Loss:  0.03501521 Validation Decoder Loss:  0.33237317
Encoder Loss:  0.042197756  || Decoder Loss:  0.034994498 Validation Decoder Loss:  0.33228353
Encoder Loss:  0.042061914  || Decoder Loss:  0.03492689 Validation Decoder Loss:  0.33224085
Encoder Loss:  0.041974045  || Decoder Loss:  0.034871183 Validation Decoder Loss:  0.33221453
Encoder Loss:  0.041875266  || Decoder Loss:  0.03482291 Validation Decoder Loss:  0.33220333
Encoder Loss:  0.04176167  || Decoder Loss:  0.034781 Validation Decoder Loss:  0.33220518
Encoder Loss:  0.041677028  || Decoder Loss:  0.034745656 Validation Decoder Loss:  0.33221376
Encoder Loss:  0.04159899  || Decoder Loss:  0.034714855 Validation Decoder Loss:  0.33222455
Encoder Loss:  0.0415486  || Decoder Loss:  0.034688078 Validation Decoder Loss:  0.3322324
Encoder Loss:  0.041459594  || Decoder Loss:  0.03466238 Validation Decoder Loss:  0.33224964
Encoder Loss:  0.041439362  || Decoder Loss:  0.034639467 Validation Decoder Loss:  0.3322618
Encoder Loss:  0.041321624  || Decoder Loss:  0.034617633 Validation Decoder Loss:  0.33227712
Encoder Loss:  0.04135106  || Decoder Loss:  0.034596592 Validation Decoder Loss:  0.3322892
Encoder Loss:  0.04121865  || Decoder Loss:  0.034574963 Validation Decoder Loss:  0.33230022
Encoder Loss:  0.04124827  || Decoder Loss:  0.03455316 Validation Decoder Loss:  0.33230984
Encoder Loss:  0.041113626  || Decoder Loss:  0.034529816 Validation Decoder Loss:  0.33231294
Encoder Loss:  0.0411308  || Decoder Loss:  0.034506455 Validation Decoder Loss:  0.33231118
Encoder Loss:  0.04102281  || Decoder Loss:  0.034480892 Validation Decoder Loss:  0.33230597
Encoder Loss:  0.041017488  || Decoder Loss:  0.034455493 Validation Decoder Loss:  0.33229372
Encoder Loss:  0.04093723  || Decoder Loss:  0.034428235 Validation Decoder Loss:  0.3322791
Encoder Loss:  0.040937293  || Decoder Loss:  0.034401525 Validation Decoder Loss:  0.33225614
Encoder Loss:  0.04086092  || Decoder Loss:  0.034373097 Validation Decoder Loss:  0.33223367
Encoder Loss:  0.040844604  || Decoder Loss:  0.034347095 Validation Decoder Loss:  0.3322031
Encoder Loss:  0.040755447  || Decoder Loss:  0.034320556 Validation Decoder Loss:  0.33217168
Model: siamese_net_lr_0.0007312288415420447 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33217168
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 110, 7, 19, 1)     142       
_________________________________________________________________
reshape_75 (Reshape)         (None, 770, 19, 1)        0         
=================================================================
Total params: 142
Trainable params: 142
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 770, 19, 1)        1839      
=================================================================
Total params: 1,839
Trainable params: 1,839
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 2607, 19, 1)       1070      
=================================================================
Total params: 1,070
Trainable params: 1,070
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1803817  || Decoder Loss:  0.09355474 Validation Decoder Loss:  0.36720031
Encoder Loss:  0.1796961  || Decoder Loss:  0.092917465 Validation Decoder Loss:  0.36710954
Encoder Loss:  0.17891379  || Decoder Loss:  0.09223363 Validation Decoder Loss:  0.36700186
Encoder Loss:  0.17808038  || Decoder Loss:  0.09156507 Validation Decoder Loss:  0.36690208
Encoder Loss:  0.1771771  || Decoder Loss:  0.09091145 Validation Decoder Loss:  0.366815
Encoder Loss:  0.1761702  || Decoder Loss:  0.090265445 Validation Decoder Loss:  0.36674032
Encoder Loss:  0.17501074  || Decoder Loss:  0.0896183 Validation Decoder Loss:  0.36668685
Encoder Loss:  0.17362672  || Decoder Loss:  0.08896174 Validation Decoder Loss:  0.36668247
Encoder Loss:  0.17190948  || Decoder Loss:  0.08829379 Validation Decoder Loss:  0.36680102
Encoder Loss:  0.16969031  || Decoder Loss:  0.08763814 Validation Decoder Loss:  0.36725816
Encoder Loss:  0.16670778  || Decoder Loss:  0.08711637 Validation Decoder Loss:  0.36872512
Encoder Loss:  0.1626076  || Decoder Loss:  0.08726102 Validation Decoder Loss:  0.37364668
Encoder Loss:  0.1574434  || Decoder Loss:  0.09073438 Validation Decoder Loss:  0.39513722
Encoder Loss:  0.15910242  || Decoder Loss:  0.116927475 Validation Decoder Loss:  0.575947
Encoder Loss:  0.26990682  || Decoder Loss:  0.31672344 Validation Decoder Loss:  1.1257098
Encoder Loss:  0.31015497  || Decoder Loss:  0.37541977 Validation Decoder Loss:  0.9453212
Encoder Loss:  0.27527407  || Decoder Loss:  0.33355784 Validation Decoder Loss:  0.9444536
Encoder Loss:  0.25562802  || Decoder Loss:  0.3067698 Validation Decoder Loss:  0.8920098
Encoder Loss:  0.22901922  || Decoder Loss:  0.2713254 Validation Decoder Loss:  0.8040307
Encoder Loss:  0.1925762  || Decoder Loss:  0.22328436 Validation Decoder Loss:  0.6997435
Encoder Loss:  0.16031778  || Decoder Loss:  0.18039763 Validation Decoder Loss:  0.6006866
Encoder Loss:  0.13533446  || Decoder Loss:  0.1473299 Validation Decoder Loss:  0.5321398
Encoder Loss:  0.11505586  || Decoder Loss:  0.12044151 Validation Decoder Loss:  0.47704813
Encoder Loss:  0.097187586  || Decoder Loss:  0.09682241 Validation Decoder Loss:  0.43367633
Encoder Loss:  0.082768135  || Decoder Loss:  0.07763896 Validation Decoder Loss:  0.40160075
Encoder Loss:  0.07175571  || Decoder Loss:  0.063084796 Validation Decoder Loss:  0.38061756
Encoder Loss:  0.06401791  || Decoder Loss:  0.052861735 Validation Decoder Loss:  0.36696073
Encoder Loss:  0.05871036  || Decoder Loss:  0.045862228 Validation Decoder Loss:  0.358014
Encoder Loss:  0.05522929  || Decoder Loss:  0.041232716 Validation Decoder Loss:  0.35189852
Encoder Loss:  0.052922573  || Decoder Loss:  0.03820534 Validation Decoder Loss:  0.34756613
Encoder Loss:  0.051387515  || Decoder Loss:  0.036229603 Validation Decoder Loss:  0.3443951
Encoder Loss:  0.050384417  || Decoder Loss:  0.03492998 Validation Decoder Loss:  0.34201372
Encoder Loss:  0.049713116  || Decoder Loss:  0.034054488 Validation Decoder Loss:  0.3402313
Encoder Loss:  0.049214527  || Decoder Loss:  0.033449065 Validation Decoder Loss:  0.33894163
Encoder Loss:  0.04884798  || Decoder Loss:  0.033016063 Validation Decoder Loss:  0.33803436
Encoder Loss:  0.048602022  || Decoder Loss:  0.032696847 Validation Decoder Loss:  0.33740246
Encoder Loss:  0.048341304  || Decoder Loss:  0.032454774 Validation Decoder Loss:  0.33696836
Encoder Loss:  0.04823782  || Decoder Loss:  0.032266364 Validation Decoder Loss:  0.33665544
Encoder Loss:  0.04807573  || Decoder Loss:  0.032115754 Validation Decoder Loss:  0.33642608
Encoder Loss:  0.04792833  || Decoder Loss:  0.031993944 Validation Decoder Loss:  0.33626264
Model: siamese_net_lr_0.0007848794031504192 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33626264
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_76 (Conv3DT (None, 310, 7, 19, 1)     742       
_________________________________________________________________
reshape_76 (Reshape)         (None, 2170, 19, 1)       0         
=================================================================
Total params: 742
Trainable params: 742
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 2170, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 2607, 19, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34638625  || Decoder Loss:  0.061801314 Validation Decoder Loss:  0.3619741
Encoder Loss:  0.34623542  || Decoder Loss:  0.062028505 Validation Decoder Loss:  0.36205146
Encoder Loss:  0.34606406  || Decoder Loss:  0.062288035 Validation Decoder Loss:  0.36210805
Encoder Loss:  0.34588382  || Decoder Loss:  0.06256375 Validation Decoder Loss:  0.36214194
Encoder Loss:  0.34569535  || Decoder Loss:  0.062855035 Validation Decoder Loss:  0.36215544
Encoder Loss:  0.345498  || Decoder Loss:  0.06316261 Validation Decoder Loss:  0.36215147
Encoder Loss:  0.34529123  || Decoder Loss:  0.063487366 Validation Decoder Loss:  0.3621327
Encoder Loss:  0.34507436  || Decoder Loss:  0.063830115 Validation Decoder Loss:  0.36210155
Encoder Loss:  0.34484658  || Decoder Loss:  0.06419182 Validation Decoder Loss:  0.36206025
Encoder Loss:  0.34460717  || Decoder Loss:  0.06457343 Validation Decoder Loss:  0.36201066
Encoder Loss:  0.3443553  || Decoder Loss:  0.06497601 Validation Decoder Loss:  0.36195472
Encoder Loss:  0.34409  || Decoder Loss:  0.06540063 Validation Decoder Loss:  0.3618942
Encoder Loss:  0.3438105  || Decoder Loss:  0.06584847 Validation Decoder Loss:  0.3618307
Encoder Loss:  0.34351575  || Decoder Loss:  0.066320784 Validation Decoder Loss:  0.36176586
Encoder Loss:  0.3432045  || Decoder Loss:  0.06681892 Validation Decoder Loss:  0.36170128
Encoder Loss:  0.3428759  || Decoder Loss:  0.06734435 Validation Decoder Loss:  0.36163846
Encoder Loss:  0.34252852  || Decoder Loss:  0.06789861 Validation Decoder Loss:  0.36157882
Encoder Loss:  0.34216115  || Decoder Loss:  0.06848339 Validation Decoder Loss:  0.3615241
Encoder Loss:  0.34177235  || Decoder Loss:  0.06910051 Validation Decoder Loss:  0.36147574
Encoder Loss:  0.3413605  || Decoder Loss:  0.06975189 Validation Decoder Loss:  0.36143547
Encoder Loss:  0.3409241  || Decoder Loss:  0.07043964 Validation Decoder Loss:  0.36140507
Encoder Loss:  0.34046134  || Decoder Loss:  0.071166016 Validation Decoder Loss:  0.3613864
Encoder Loss:  0.33997023  || Decoder Loss:  0.0719335 Validation Decoder Loss:  0.3613815
Encoder Loss:  0.3394488  || Decoder Loss:  0.0727447 Validation Decoder Loss:  0.3613926
Encoder Loss:  0.33889475  || Decoder Loss:  0.0736025 Validation Decoder Loss:  0.36142212
Encoder Loss:  0.33830577  || Decoder Loss:  0.07451002 Validation Decoder Loss:  0.36147282
Encoder Loss:  0.337679  || Decoder Loss:  0.07547062 Validation Decoder Loss:  0.3615476
Encoder Loss:  0.33701172  || Decoder Loss:  0.076487996 Validation Decoder Loss:  0.36164975
Encoder Loss:  0.33630082  || Decoder Loss:  0.077566154 Validation Decoder Loss:  0.3617831
Encoder Loss:  0.33554286  || Decoder Loss:  0.07870944 Validation Decoder Loss:  0.3619517
Encoder Loss:  0.33473426  || Decoder Loss:  0.079922594 Validation Decoder Loss:  0.36216035
Encoder Loss:  0.33387077  || Decoder Loss:  0.081210844 Validation Decoder Loss:  0.36241436
Encoder Loss:  0.3329481  || Decoder Loss:  0.08257986 Validation Decoder Loss:  0.3627198
Encoder Loss:  0.33196136  || Decoder Loss:  0.08403587 Validation Decoder Loss:  0.36308372
Encoder Loss:  0.3309052  || Decoder Loss:  0.085585706 Validation Decoder Loss:  0.36351418
Encoder Loss:  0.3297738  || Decoder Loss:  0.08723686 Validation Decoder Loss:  0.36402035
Encoder Loss:  0.32856083  || Decoder Loss:  0.088997565 Validation Decoder Loss:  0.36461282
Encoder Loss:  0.3272591  || Decoder Loss:  0.09087689 Validation Decoder Loss:  0.3653038
Encoder Loss:  0.32586083  || Decoder Loss:  0.09288479 Validation Decoder Loss:  0.3661074
Encoder Loss:  0.32435745  || Decoder Loss:  0.09503228 Validation Decoder Loss:  0.36703956
Model: siamese_net_lr_0.00019883411383548772 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36703956
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 190, 13, 19, 1)    1144      
_________________________________________________________________
reshape_77 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 1,144
Trainable params: 1,144
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13524112  || Decoder Loss:  0.053390387 Validation Decoder Loss:  0.3366755
Encoder Loss:  0.141237  || Decoder Loss:  0.06965333 Validation Decoder Loss:  0.33532035
Encoder Loss:  0.08667589  || Decoder Loss:  0.036304247 Validation Decoder Loss:  0.32731947
Encoder Loss:  0.0450855  || Decoder Loss:  0.036861338 Validation Decoder Loss:  0.3275484
Encoder Loss:  0.04193153  || Decoder Loss:  0.035760574 Validation Decoder Loss:  0.32821572
Encoder Loss:  0.039467975  || Decoder Loss:  0.03545223 Validation Decoder Loss:  0.32870358
Encoder Loss:  0.039325453  || Decoder Loss:  0.035331782 Validation Decoder Loss:  0.3290217
Encoder Loss:  0.039225712  || Decoder Loss:  0.035272025 Validation Decoder Loss:  0.32927158
Encoder Loss:  0.039163835  || Decoder Loss:  0.03523384 Validation Decoder Loss:  0.32945597
Encoder Loss:  0.039109603  || Decoder Loss:  0.035202436 Validation Decoder Loss:  0.32958972
Encoder Loss:  0.03905555  || Decoder Loss:  0.035172176 Validation Decoder Loss:  0.32968825
Encoder Loss:  0.038996443  || Decoder Loss:  0.035140537 Validation Decoder Loss:  0.3297813
Encoder Loss:  0.038936142  || Decoder Loss:  0.03510876 Validation Decoder Loss:  0.329906
Encoder Loss:  0.03887665  || Decoder Loss:  0.035074223 Validation Decoder Loss:  0.33007175
Encoder Loss:  0.038812857  || Decoder Loss:  0.035042096 Validation Decoder Loss:  0.33024192
Encoder Loss:  0.038751137  || Decoder Loss:  0.03501025 Validation Decoder Loss:  0.3303475
Encoder Loss:  0.038694307  || Decoder Loss:  0.034982916 Validation Decoder Loss:  0.33038896
Encoder Loss:  0.038637195  || Decoder Loss:  0.03496081 Validation Decoder Loss:  0.33040488
Encoder Loss:  0.038589377  || Decoder Loss:  0.03494085 Validation Decoder Loss:  0.33040172
Encoder Loss:  0.038537934  || Decoder Loss:  0.034928773 Validation Decoder Loss:  0.3303969
Encoder Loss:  0.038497187  || Decoder Loss:  0.034921013 Validation Decoder Loss:  0.3303905
Encoder Loss:  0.038468514  || Decoder Loss:  0.03491884 Validation Decoder Loss:  0.33038735
Encoder Loss:  0.038442776  || Decoder Loss:  0.034919273 Validation Decoder Loss:  0.33038303
Encoder Loss:  0.03840199  || Decoder Loss:  0.034919683 Validation Decoder Loss:  0.33037028
Encoder Loss:  0.038388394  || Decoder Loss:  0.034921054 Validation Decoder Loss:  0.33035162
Encoder Loss:  0.038367175  || Decoder Loss:  0.034922384 Validation Decoder Loss:  0.33034983
Encoder Loss:  0.038357463  || Decoder Loss:  0.034924947 Validation Decoder Loss:  0.33036822
Encoder Loss:  0.038345855  || Decoder Loss:  0.03492713 Validation Decoder Loss:  0.3304021
Encoder Loss:  0.0383386  || Decoder Loss:  0.03493135 Validation Decoder Loss:  0.33044952
Encoder Loss:  0.038341187  || Decoder Loss:  0.03493674 Validation Decoder Loss:  0.3305052
Encoder Loss:  0.03834445  || Decoder Loss:  0.03494276 Validation Decoder Loss:  0.33055484
Encoder Loss:  0.03833627  || Decoder Loss:  0.03494837 Validation Decoder Loss:  0.3306041
Encoder Loss:  0.03835453  || Decoder Loss:  0.034957968 Validation Decoder Loss:  0.33065456
Encoder Loss:  0.038357392  || Decoder Loss:  0.03496332 Validation Decoder Loss:  0.33071277
Encoder Loss:  0.038352314  || Decoder Loss:  0.034970228 Validation Decoder Loss:  0.33075836
Encoder Loss:  0.03835543  || Decoder Loss:  0.034980178 Validation Decoder Loss:  0.3308048
Encoder Loss:  0.03836273  || Decoder Loss:  0.03498984 Validation Decoder Loss:  0.33084315
Encoder Loss:  0.038362175  || Decoder Loss:  0.035000727 Validation Decoder Loss:  0.33087915
Encoder Loss:  0.03838777  || Decoder Loss:  0.03501229 Validation Decoder Loss:  0.3309316
Encoder Loss:  0.03838852  || Decoder Loss:  0.035018828 Validation Decoder Loss:  0.33096495
Model: siamese_net_lr_0.0006519208104819818 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33096495
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 494, 5, 19, 1)     243       
_________________________________________________________________
reshape_78 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 243
Trainable params: 243
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1946273  || Decoder Loss:  0.040321264 Validation Decoder Loss:  0.33367467
Encoder Loss:  0.19453533  || Decoder Loss:  0.04360938 Validation Decoder Loss:  0.33219492
Encoder Loss:  0.18494546  || Decoder Loss:  0.05878629 Validation Decoder Loss:  0.31861472
Encoder Loss:  0.06221821  || Decoder Loss:  0.038041007 Validation Decoder Loss:  0.32693636
Encoder Loss:  0.059006594  || Decoder Loss:  0.03646084 Validation Decoder Loss:  0.32672495
Encoder Loss:  0.05833406  || Decoder Loss:  0.035991356 Validation Decoder Loss:  0.32685164
Encoder Loss:  0.045675386  || Decoder Loss:  0.035684437 Validation Decoder Loss:  0.32737184
Encoder Loss:  0.042603657  || Decoder Loss:  0.03553919 Validation Decoder Loss:  0.32768935
Encoder Loss:  0.04239418  || Decoder Loss:  0.035397753 Validation Decoder Loss:  0.3279149
Encoder Loss:  0.04224745  || Decoder Loss:  0.035300426 Validation Decoder Loss:  0.32811648
Encoder Loss:  0.042125836  || Decoder Loss:  0.03523599 Validation Decoder Loss:  0.32831424
Encoder Loss:  0.042024568  || Decoder Loss:  0.03517766 Validation Decoder Loss:  0.328512
Encoder Loss:  0.04191968  || Decoder Loss:  0.035126437 Validation Decoder Loss:  0.3286988
Encoder Loss:  0.041847914  || Decoder Loss:  0.035079587 Validation Decoder Loss:  0.32887208
Encoder Loss:  0.041761324  || Decoder Loss:  0.035033714 Validation Decoder Loss:  0.32904187
Encoder Loss:  0.04166726  || Decoder Loss:  0.034986306 Validation Decoder Loss:  0.3292034
Encoder Loss:  0.041581117  || Decoder Loss:  0.034938008 Validation Decoder Loss:  0.32936102
Encoder Loss:  0.041472524  || Decoder Loss:  0.034887053 Validation Decoder Loss:  0.32952842
Encoder Loss:  0.041364063  || Decoder Loss:  0.03483323 Validation Decoder Loss:  0.3296923
Encoder Loss:  0.041255817  || Decoder Loss:  0.03478023 Validation Decoder Loss:  0.3298409
Encoder Loss:  0.041164096  || Decoder Loss:  0.034731396 Validation Decoder Loss:  0.32993972
Encoder Loss:  0.04109328  || Decoder Loss:  0.034683887 Validation Decoder Loss:  0.33003595
Encoder Loss:  0.041038483  || Decoder Loss:  0.034641553 Validation Decoder Loss:  0.33008656
Encoder Loss:  0.040958427  || Decoder Loss:  0.034599707 Validation Decoder Loss:  0.3301586
Encoder Loss:  0.04087369  || Decoder Loss:  0.034560204 Validation Decoder Loss:  0.3301984
Encoder Loss:  0.04084715  || Decoder Loss:  0.034526266 Validation Decoder Loss:  0.3302393
Encoder Loss:  0.04078619  || Decoder Loss:  0.03450061 Validation Decoder Loss:  0.3302699
Encoder Loss:  0.040760044  || Decoder Loss:  0.03447614 Validation Decoder Loss:  0.3303206
Encoder Loss:  0.04073169  || Decoder Loss:  0.034461416 Validation Decoder Loss:  0.3303588
Encoder Loss:  0.04070296  || Decoder Loss:  0.034450606 Validation Decoder Loss:  0.33040327
Encoder Loss:  0.04069107  || Decoder Loss:  0.034442626 Validation Decoder Loss:  0.33043602
Encoder Loss:  0.04068561  || Decoder Loss:  0.034435984 Validation Decoder Loss:  0.33047932
Encoder Loss:  0.040645715  || Decoder Loss:  0.034432136 Validation Decoder Loss:  0.3305238
Encoder Loss:  0.04068555  || Decoder Loss:  0.03443784 Validation Decoder Loss:  0.33046156
Encoder Loss:  0.040666718  || Decoder Loss:  0.034441397 Validation Decoder Loss:  0.33048475
Encoder Loss:  0.040667705  || Decoder Loss:  0.03444245 Validation Decoder Loss:  0.33048517
Encoder Loss:  0.040668458  || Decoder Loss:  0.034444585 Validation Decoder Loss:  0.33050144
Encoder Loss:  0.04068432  || Decoder Loss:  0.034442328 Validation Decoder Loss:  0.33047703
Encoder Loss:  0.040642478  || Decoder Loss:  0.03443925 Validation Decoder Loss:  0.3304948
Encoder Loss:  0.040660337  || Decoder Loss:  0.034441687 Validation Decoder Loss:  0.3304971
Model: siamese_net_lr_0.000954840522439215 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33049706
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_79 (Conv3DT (None, 247, 10, 19, 1)    349       
_________________________________________________________________
reshape_79 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21226113  || Decoder Loss:  0.041021153 Validation Decoder Loss:  0.34107786
Encoder Loss:  0.20799133  || Decoder Loss:  0.047377463 Validation Decoder Loss:  0.35221228
Encoder Loss:  0.09913339  || Decoder Loss:  0.04325015 Validation Decoder Loss:  0.32716885
Encoder Loss:  0.059906963  || Decoder Loss:  0.036301438 Validation Decoder Loss:  0.32771853
Encoder Loss:  0.05894315  || Decoder Loss:  0.03534084 Validation Decoder Loss:  0.32860315
Encoder Loss:  0.057891466  || Decoder Loss:  0.034982946 Validation Decoder Loss:  0.3292461
Encoder Loss:  0.046126742  || Decoder Loss:  0.034858134 Validation Decoder Loss:  0.32982957
Encoder Loss:  0.0430557  || Decoder Loss:  0.034803856 Validation Decoder Loss:  0.33006933
Encoder Loss:  0.042925615  || Decoder Loss:  0.03476902 Validation Decoder Loss:  0.3302069
Encoder Loss:  0.042812824  || Decoder Loss:  0.034747545 Validation Decoder Loss:  0.33035332
Encoder Loss:  0.042706743  || Decoder Loss:  0.034735944 Validation Decoder Loss:  0.33050317
Encoder Loss:  0.04260104  || Decoder Loss:  0.034732427 Validation Decoder Loss:  0.33068496
Encoder Loss:  0.0424961  || Decoder Loss:  0.034733452 Validation Decoder Loss:  0.33093762
Encoder Loss:  0.04238215  || Decoder Loss:  0.034735836 Validation Decoder Loss:  0.33120742
Encoder Loss:  0.04225826  || Decoder Loss:  0.034736708 Validation Decoder Loss:  0.33153945
Encoder Loss:  0.042099003  || Decoder Loss:  0.034731522 Validation Decoder Loss:  0.33198634
Encoder Loss:  0.042019304  || Decoder Loss:  0.034720074 Validation Decoder Loss:  0.33233082
Encoder Loss:  0.041959275  || Decoder Loss:  0.034707688 Validation Decoder Loss:  0.33259106
Encoder Loss:  0.04184461  || Decoder Loss:  0.034694713 Validation Decoder Loss:  0.33292687
Encoder Loss:  0.0417938  || Decoder Loss:  0.034688152 Validation Decoder Loss:  0.3330859
Encoder Loss:  0.041804582  || Decoder Loss:  0.03468323 Validation Decoder Loss:  0.33317435
Encoder Loss:  0.041724868  || Decoder Loss:  0.0346744 Validation Decoder Loss:  0.3333333
Encoder Loss:  0.041714635  || Decoder Loss:  0.034668997 Validation Decoder Loss:  0.33325404
Encoder Loss:  0.04171619  || Decoder Loss:  0.034666054 Validation Decoder Loss:  0.3331876
Encoder Loss:  0.041648645  || Decoder Loss:  0.034661237 Validation Decoder Loss:  0.33319512
Encoder Loss:  0.04167295  || Decoder Loss:  0.034658324 Validation Decoder Loss:  0.33302304
Encoder Loss:  0.041653536  || Decoder Loss:  0.034659132 Validation Decoder Loss:  0.3329296
Encoder Loss:  0.04165308  || Decoder Loss:  0.03465944 Validation Decoder Loss:  0.3328423
Encoder Loss:  0.041636277  || Decoder Loss:  0.03465866 Validation Decoder Loss:  0.33270842
Encoder Loss:  0.04157271  || Decoder Loss:  0.034655582 Validation Decoder Loss:  0.33266532
Encoder Loss:  0.04158257  || Decoder Loss:  0.034658033 Validation Decoder Loss:  0.3325998
Encoder Loss:  0.041570734  || Decoder Loss:  0.03465771 Validation Decoder Loss:  0.3325404
Encoder Loss:  0.041543093  || Decoder Loss:  0.034657218 Validation Decoder Loss:  0.33256966
Encoder Loss:  0.041577388  || Decoder Loss:  0.03466111 Validation Decoder Loss:  0.3324089
Encoder Loss:  0.04156355  || Decoder Loss:  0.0346673 Validation Decoder Loss:  0.33229417
Encoder Loss:  0.04153662  || Decoder Loss:  0.034668077 Validation Decoder Loss:  0.33224148
Encoder Loss:  0.04156167  || Decoder Loss:  0.03467432 Validation Decoder Loss:  0.33214396
Encoder Loss:  0.04150932  || Decoder Loss:  0.03467224 Validation Decoder Loss:  0.33220127
Encoder Loss:  0.04153052  || Decoder Loss:  0.034677006 Validation Decoder Loss:  0.33206946
Encoder Loss:  0.041543666  || Decoder Loss:  0.034685705 Validation Decoder Loss:  0.33195925
Model: siamese_net_lr_0.0001843645774668196 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33195925
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 95, 26, 19, 1)     193       
_________________________________________________________________
reshape_80 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32562694  || Decoder Loss:  0.03892169 Validation Decoder Loss:  0.33739755
Encoder Loss:  0.3254583  || Decoder Loss:  0.0390259 Validation Decoder Loss:  0.33691475
Encoder Loss:  0.3252431  || Decoder Loss:  0.03916475 Validation Decoder Loss:  0.33641824
Encoder Loss:  0.32496864  || Decoder Loss:  0.039348938 Validation Decoder Loss:  0.33589768
Encoder Loss:  0.3246147  || Decoder Loss:  0.039593004 Validation Decoder Loss:  0.33534142
Encoder Loss:  0.32415164  || Decoder Loss:  0.039918408 Validation Decoder Loss:  0.33473277
Encoder Loss:  0.32353187  || Decoder Loss:  0.040358316 Validation Decoder Loss:  0.33404398
Encoder Loss:  0.3226712  || Decoder Loss:  0.04096639 Validation Decoder Loss:  0.3332278
Encoder Loss:  0.32140666  || Decoder Loss:  0.041834697 Validation Decoder Loss:  0.33220518
Encoder Loss:  0.3193767  || Decoder Loss:  0.04313767 Validation Decoder Loss:  0.33089375
Encoder Loss:  0.31561378  || Decoder Loss:  0.04525866 Validation Decoder Loss:  0.329382
Encoder Loss:  0.30656335  || Decoder Loss:  0.04928834 Validation Decoder Loss:  0.32861003
Encoder Loss:  0.27186507  || Decoder Loss:  0.060671497 Validation Decoder Loss:  0.33763158
Encoder Loss:  0.13383748  || Decoder Loss:  0.10254715 Validation Decoder Loss:  0.35251665
Encoder Loss:  0.08276964  || Decoder Loss:  0.06876662 Validation Decoder Loss:  0.31828833
Encoder Loss:  0.07320483  || Decoder Loss:  0.04658968 Validation Decoder Loss:  0.31845146
Encoder Loss:  0.07045029  || Decoder Loss:  0.039361943 Validation Decoder Loss:  0.3226759
Encoder Loss:  0.06958917  || Decoder Loss:  0.03714492 Validation Decoder Loss:  0.32585442
Encoder Loss:  0.069217026  || Decoder Loss:  0.036571093 Validation Decoder Loss:  0.32729697
Encoder Loss:  0.06894118  || Decoder Loss:  0.03639984 Validation Decoder Loss:  0.327721
Encoder Loss:  0.06866992  || Decoder Loss:  0.036302015 Validation Decoder Loss:  0.3277775
Encoder Loss:  0.0684054  || Decoder Loss:  0.036226775 Validation Decoder Loss:  0.32773918
Encoder Loss:  0.068203345  || Decoder Loss:  0.036163624 Validation Decoder Loss:  0.32768488
Encoder Loss:  0.067962795  || Decoder Loss:  0.036106266 Validation Decoder Loss:  0.3276378
Encoder Loss:  0.06777754  || Decoder Loss:  0.03605235 Validation Decoder Loss:  0.32760066
Encoder Loss:  0.06769552  || Decoder Loss:  0.036004156 Validation Decoder Loss:  0.3275717
Encoder Loss:  0.067614816  || Decoder Loss:  0.035959233 Validation Decoder Loss:  0.32754838
Encoder Loss:  0.06741782  || Decoder Loss:  0.035917316 Validation Decoder Loss:  0.32753098
Encoder Loss:  0.06727016  || Decoder Loss:  0.03587815 Validation Decoder Loss:  0.3275181
Encoder Loss:  0.06724558  || Decoder Loss:  0.035839945 Validation Decoder Loss:  0.32750672
Encoder Loss:  0.067184016  || Decoder Loss:  0.035805706 Validation Decoder Loss:  0.32750002
Encoder Loss:  0.06703047  || Decoder Loss:  0.035772286 Validation Decoder Loss:  0.32749778
Encoder Loss:  0.06683458  || Decoder Loss:  0.035739586 Validation Decoder Loss:  0.32749668
Encoder Loss:  0.066714995  || Decoder Loss:  0.03570863 Validation Decoder Loss:  0.327496
Encoder Loss:  0.066650786  || Decoder Loss:  0.035679795 Validation Decoder Loss:  0.32749218
Encoder Loss:  0.06662586  || Decoder Loss:  0.035652865 Validation Decoder Loss:  0.3275
Encoder Loss:  0.06639843  || Decoder Loss:  0.03562545 Validation Decoder Loss:  0.3275048
Encoder Loss:  0.066152  || Decoder Loss:  0.03560047 Validation Decoder Loss:  0.32751727
Encoder Loss:  0.065850705  || Decoder Loss:  0.03557525 Validation Decoder Loss:  0.32752636
Encoder Loss:  0.06555563  || Decoder Loss:  0.035550643 Validation Decoder Loss:  0.32753855
Model: siamese_net_lr_0.0003506876840901726 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32753855
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 130, 19, 19, 1)    29        
_________________________________________________________________
reshape_81 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26364434  || Decoder Loss:  0.03755764 Validation Decoder Loss:  0.3407809
Encoder Loss:  0.2635763  || Decoder Loss:  0.03747961 Validation Decoder Loss:  0.34062195
Encoder Loss:  0.26348794  || Decoder Loss:  0.03739617 Validation Decoder Loss:  0.34048313
Encoder Loss:  0.26337832  || Decoder Loss:  0.037314866 Validation Decoder Loss:  0.34036782
Encoder Loss:  0.26324174  || Decoder Loss:  0.037236623 Validation Decoder Loss:  0.34027514
Encoder Loss:  0.26307034  || Decoder Loss:  0.037162375 Validation Decoder Loss:  0.34020415
Encoder Loss:  0.2628525  || Decoder Loss:  0.037094258 Validation Decoder Loss:  0.3401541
Encoder Loss:  0.26256827  || Decoder Loss:  0.03703748 Validation Decoder Loss:  0.34012508
Encoder Loss:  0.2621769  || Decoder Loss:  0.037005223 Validation Decoder Loss:  0.34011996
Encoder Loss:  0.2615708  || Decoder Loss:  0.03703753 Validation Decoder Loss:  0.34015644
Encoder Loss:  0.26026046  || Decoder Loss:  0.037314467 Validation Decoder Loss:  0.340423
Encoder Loss:  0.24611704  || Decoder Loss:  0.04024911 Validation Decoder Loss:  0.35335112
Encoder Loss:  0.08545602  || Decoder Loss:  0.055194993 Validation Decoder Loss:  0.3519388
Encoder Loss:  0.06923173  || Decoder Loss:  0.047340408 Validation Decoder Loss:  0.34438008
Encoder Loss:  0.06954691  || Decoder Loss:  0.04378505 Validation Decoder Loss:  0.34001178
Encoder Loss:  0.067959696  || Decoder Loss:  0.04178355 Validation Decoder Loss:  0.33765733
Encoder Loss:  0.06705191  || Decoder Loss:  0.04055064 Validation Decoder Loss:  0.3361693
Encoder Loss:  0.06690815  || Decoder Loss:  0.03971359 Validation Decoder Loss:  0.33516818
Encoder Loss:  0.067589715  || Decoder Loss:  0.039068535 Validation Decoder Loss:  0.33445215
Encoder Loss:  0.06837362  || Decoder Loss:  0.038550824 Validation Decoder Loss:  0.33392996
Encoder Loss:  0.067348525  || Decoder Loss:  0.03811022 Validation Decoder Loss:  0.3335423
Encoder Loss:  0.066486746  || Decoder Loss:  0.037722405 Validation Decoder Loss:  0.3332267
Encoder Loss:  0.066253036  || Decoder Loss:  0.03738022 Validation Decoder Loss:  0.3329864
Encoder Loss:  0.06545543  || Decoder Loss:  0.03707298 Validation Decoder Loss:  0.33276278
Encoder Loss:  0.06589938  || Decoder Loss:  0.03680252 Validation Decoder Loss:  0.33260235
Encoder Loss:  0.0650502  || Decoder Loss:  0.036558457 Validation Decoder Loss:  0.33245146
Encoder Loss:  0.065093935  || Decoder Loss:  0.03634342 Validation Decoder Loss:  0.33232915
Encoder Loss:  0.06476848  || Decoder Loss:  0.036155447 Validation Decoder Loss:  0.33222935
Encoder Loss:  0.06420013  || Decoder Loss:  0.035992324 Validation Decoder Loss:  0.33212906
Encoder Loss:  0.06476202  || Decoder Loss:  0.03585569 Validation Decoder Loss:  0.33207268
Encoder Loss:  0.06418769  || Decoder Loss:  0.03574363 Validation Decoder Loss:  0.33201718
Encoder Loss:  0.064205095  || Decoder Loss:  0.0356529 Validation Decoder Loss:  0.3319736
Encoder Loss:  0.064403445  || Decoder Loss:  0.03558362 Validation Decoder Loss:  0.3319564
Encoder Loss:  0.06332018  || Decoder Loss:  0.035530046 Validation Decoder Loss:  0.33193073
Encoder Loss:  0.06359175  || Decoder Loss:  0.03549033 Validation Decoder Loss:  0.33192146
Encoder Loss:  0.06259878  || Decoder Loss:  0.035460405 Validation Decoder Loss:  0.33190793
Encoder Loss:  0.06176898  || Decoder Loss:  0.03543782 Validation Decoder Loss:  0.33189815
Encoder Loss:  0.055512175  || Decoder Loss:  0.035421085 Validation Decoder Loss:  0.33187073
Encoder Loss:  0.046103224  || Decoder Loss:  0.035418812 Validation Decoder Loss:  0.33179277
Encoder Loss:  0.045039937  || Decoder Loss:  0.035409197 Validation Decoder Loss:  0.33176938
Model: siamese_net_lr_0.0007414221535281731 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33176938
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_82 (Conv3DT (None, 90, 8, 19, 1)      109       
_________________________________________________________________
reshape_82 (Reshape)         (None, 720, 19, 1)        0         
=================================================================
Total params: 109
Trainable params: 109
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 720, 19, 1)        1889      
=================================================================
Total params: 1,889
Trainable params: 1,889
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 2607, 19, 1)       1889      
=================================================================
Total params: 1,889
Trainable params: 1,889
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37705597  || Decoder Loss:  0.06912679 Validation Decoder Loss:  0.36333734
Encoder Loss:  0.37700927  || Decoder Loss:  0.068984136 Validation Decoder Loss:  0.36337775
Encoder Loss:  0.37695408  || Decoder Loss:  0.06881608 Validation Decoder Loss:  0.3634228
Encoder Loss:  0.37689587  || Decoder Loss:  0.068640135 Validation Decoder Loss:  0.3634697
Encoder Loss:  0.37683693  || Decoder Loss:  0.068463184 Validation Decoder Loss:  0.36351782
Encoder Loss:  0.3767778  || Decoder Loss:  0.06828727 Validation Decoder Loss:  0.3635672
Encoder Loss:  0.3767187  || Decoder Loss:  0.06811289 Validation Decoder Loss:  0.36361784
Encoder Loss:  0.37665966  || Decoder Loss:  0.06794021 Validation Decoder Loss:  0.36366978
Encoder Loss:  0.3766006  || Decoder Loss:  0.067769244 Validation Decoder Loss:  0.36372307
Encoder Loss:  0.3765416  || Decoder Loss:  0.06760002 Validation Decoder Loss:  0.36377764
Encoder Loss:  0.37648267  || Decoder Loss:  0.06743248 Validation Decoder Loss:  0.36383355
Encoder Loss:  0.37642378  || Decoder Loss:  0.06726663 Validation Decoder Loss:  0.3638907
Encoder Loss:  0.37636483  || Decoder Loss:  0.06710243 Validation Decoder Loss:  0.3639491
Encoder Loss:  0.37630603  || Decoder Loss:  0.06693988 Validation Decoder Loss:  0.36400867
Encoder Loss:  0.3762471  || Decoder Loss:  0.06677894 Validation Decoder Loss:  0.36406946
Encoder Loss:  0.37618828  || Decoder Loss:  0.066619575 Validation Decoder Loss:  0.36413148
Encoder Loss:  0.37612945  || Decoder Loss:  0.06646178 Validation Decoder Loss:  0.3641947
Encoder Loss:  0.37607056  || Decoder Loss:  0.06630552 Validation Decoder Loss:  0.36425912
Encoder Loss:  0.37601173  || Decoder Loss:  0.066150784 Validation Decoder Loss:  0.36432475
Encoder Loss:  0.37595278  || Decoder Loss:  0.065997526 Validation Decoder Loss:  0.3643915
Encoder Loss:  0.37589395  || Decoder Loss:  0.06584576 Validation Decoder Loss:  0.36445946
Encoder Loss:  0.37583497  || Decoder Loss:  0.065695435 Validation Decoder Loss:  0.36452854
Encoder Loss:  0.375776  || Decoder Loss:  0.06554654 Validation Decoder Loss:  0.3645987
Encoder Loss:  0.37571695  || Decoder Loss:  0.06539906 Validation Decoder Loss:  0.3646699
Encoder Loss:  0.37565792  || Decoder Loss:  0.065252975 Validation Decoder Loss:  0.36474216
Encoder Loss:  0.37559876  || Decoder Loss:  0.065108255 Validation Decoder Loss:  0.36481538
Encoder Loss:  0.37553957  || Decoder Loss:  0.06496489 Validation Decoder Loss:  0.36488962
Encoder Loss:  0.37548023  || Decoder Loss:  0.06482287 Validation Decoder Loss:  0.36496484
Encoder Loss:  0.3754209  || Decoder Loss:  0.06468217 Validation Decoder Loss:  0.36504096
Encoder Loss:  0.3753615  || Decoder Loss:  0.06454278 Validation Decoder Loss:  0.36511803
Encoder Loss:  0.375302  || Decoder Loss:  0.06440466 Validation Decoder Loss:  0.365196
Encoder Loss:  0.37524238  || Decoder Loss:  0.06426783 Validation Decoder Loss:  0.3652749
Encoder Loss:  0.37518263  || Decoder Loss:  0.06413225 Validation Decoder Loss:  0.36535463
Encoder Loss:  0.37512276  || Decoder Loss:  0.063997895 Validation Decoder Loss:  0.3654353
Encoder Loss:  0.37506288  || Decoder Loss:  0.06386478 Validation Decoder Loss:  0.3655168
Encoder Loss:  0.3750028  || Decoder Loss:  0.06373287 Validation Decoder Loss:  0.36559913
Encoder Loss:  0.37494263  || Decoder Loss:  0.063602164 Validation Decoder Loss:  0.36568233
Encoder Loss:  0.37488228  || Decoder Loss:  0.06347264 Validation Decoder Loss:  0.36576635
Encoder Loss:  0.3748218  || Decoder Loss:  0.06334429 Validation Decoder Loss:  0.36585116
Encoder Loss:  0.37476122  || Decoder Loss:  0.06321709 Validation Decoder Loss:  0.36593682
Model: siamese_net_lr_8.213011637354211e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36593682
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 107, 10, 19, 1)    265       
_________________________________________________________________
reshape_83 (Reshape)         (None, 1070, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 1070, 19, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 2607, 19, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11518942  || Decoder Loss:  0.06703486 Validation Decoder Loss:  0.3607006
Encoder Loss:  0.119175136  || Decoder Loss:  0.073201545 Validation Decoder Loss:  0.3642059
Encoder Loss:  0.12558967  || Decoder Loss:  0.08393884 Validation Decoder Loss:  0.37213388
Encoder Loss:  0.10920762  || Decoder Loss:  0.07592435 Validation Decoder Loss:  0.39376795
Encoder Loss:  0.06811015  || Decoder Loss:  0.06232654 Validation Decoder Loss:  0.35429195
Encoder Loss:  0.047737956  || Decoder Loss:  0.04141499 Validation Decoder Loss:  0.33951628
Encoder Loss:  0.04451787  || Decoder Loss:  0.03775008 Validation Decoder Loss:  0.3356967
Encoder Loss:  0.04318751  || Decoder Loss:  0.0362477 Validation Decoder Loss:  0.33418748
Encoder Loss:  0.0424459  || Decoder Loss:  0.035423547 Validation Decoder Loss:  0.33353633
Encoder Loss:  0.041977547  || Decoder Loss:  0.034917336 Validation Decoder Loss:  0.33329695
Encoder Loss:  0.041653246  || Decoder Loss:  0.03457865 Validation Decoder Loss:  0.33326477
Encoder Loss:  0.041405864  || Decoder Loss:  0.034338146 Validation Decoder Loss:  0.33333802
Encoder Loss:  0.041198734  || Decoder Loss:  0.03416023 Validation Decoder Loss:  0.3334573
Encoder Loss:  0.040979505  || Decoder Loss:  0.034024633 Validation Decoder Loss:  0.33358008
Encoder Loss:  0.03999924  || Decoder Loss:  0.033923093 Validation Decoder Loss:  0.33362907
Encoder Loss:  0.038010135  || Decoder Loss:  0.033897795 Validation Decoder Loss:  0.33360168
Encoder Loss:  0.037288133  || Decoder Loss:  0.033891022 Validation Decoder Loss:  0.3336982
Encoder Loss:  0.03710661  || Decoder Loss:  0.033862345 Validation Decoder Loss:  0.3338092
Encoder Loss:  0.037011426  || Decoder Loss:  0.033823356 Validation Decoder Loss:  0.33392626
Encoder Loss:  0.036941398  || Decoder Loss:  0.033777718 Validation Decoder Loss:  0.3340537
Encoder Loss:  0.036897477  || Decoder Loss:  0.033722542 Validation Decoder Loss:  0.33420074
Encoder Loss:  0.036821608  || Decoder Loss:  0.03366035 Validation Decoder Loss:  0.33436236
Encoder Loss:  0.036739558  || Decoder Loss:  0.033592306 Validation Decoder Loss:  0.33454168
Encoder Loss:  0.036676932  || Decoder Loss:  0.033515256 Validation Decoder Loss:  0.33474302
Encoder Loss:  0.036544703  || Decoder Loss:  0.033434734 Validation Decoder Loss:  0.33493596
Encoder Loss:  0.036505774  || Decoder Loss:  0.033346318 Validation Decoder Loss:  0.33515137
Encoder Loss:  0.036386203  || Decoder Loss:  0.033256244 Validation Decoder Loss:  0.33531994
Encoder Loss:  0.036296196  || Decoder Loss:  0.033172127 Validation Decoder Loss:  0.33545884
Encoder Loss:  0.03622281  || Decoder Loss:  0.033095375 Validation Decoder Loss:  0.33556834
Encoder Loss:  0.03615497  || Decoder Loss:  0.03302788 Validation Decoder Loss:  0.33565336
Encoder Loss:  0.036092587  || Decoder Loss:  0.032975897 Validation Decoder Loss:  0.33570173
Encoder Loss:  0.035998132  || Decoder Loss:  0.032938052 Validation Decoder Loss:  0.33573243
Encoder Loss:  0.035952117  || Decoder Loss:  0.032914907 Validation Decoder Loss:  0.33576143
Encoder Loss:  0.035929002  || Decoder Loss:  0.03289727 Validation Decoder Loss:  0.33574647
Encoder Loss:  0.035879854  || Decoder Loss:  0.032888334 Validation Decoder Loss:  0.3357126
Encoder Loss:  0.03587537  || Decoder Loss:  0.03288223 Validation Decoder Loss:  0.3357147
Encoder Loss:  0.03581601  || Decoder Loss:  0.03288139 Validation Decoder Loss:  0.33566624
Encoder Loss:  0.03577729  || Decoder Loss:  0.032890614 Validation Decoder Loss:  0.33563635
Encoder Loss:  0.035748854  || Decoder Loss:  0.032909587 Validation Decoder Loss:  0.3355981
Encoder Loss:  0.035890117  || Decoder Loss:  0.03292555 Validation Decoder Loss:  0.33559546
Model: siamese_net_lr_0.0002450244029692738 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3355955
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 474, 5, 19, 1)     34        
_________________________________________________________________
reshape_84 (Reshape)         (None, 2370, 19, 1)       0         
=================================================================
Total params: 34
Trainable params: 34
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44007304  || Decoder Loss:  0.041369237 Validation Decoder Loss:  0.34994268
Encoder Loss:  0.33464828  || Decoder Loss:  0.040598635 Validation Decoder Loss:  0.3339768
Encoder Loss:  0.098647006  || Decoder Loss:  0.036284603 Validation Decoder Loss:  0.332137
Encoder Loss:  0.09481736  || Decoder Loss:  0.035423115 Validation Decoder Loss:  0.33201492
Encoder Loss:  0.09348414  || Decoder Loss:  0.03523166 Validation Decoder Loss:  0.33203572
Encoder Loss:  0.06606194  || Decoder Loss:  0.035174932 Validation Decoder Loss:  0.3320765
Encoder Loss:  0.054121576  || Decoder Loss:  0.0351411 Validation Decoder Loss:  0.3321223
Encoder Loss:  0.0536129  || Decoder Loss:  0.035117827 Validation Decoder Loss:  0.3321804
Encoder Loss:  0.053301893  || Decoder Loss:  0.035100233 Validation Decoder Loss:  0.33222008
Encoder Loss:  0.0529879  || Decoder Loss:  0.035085022 Validation Decoder Loss:  0.3322814
Encoder Loss:  0.052925244  || Decoder Loss:  0.035071623 Validation Decoder Loss:  0.3322938
Encoder Loss:  0.052752595  || Decoder Loss:  0.035059664 Validation Decoder Loss:  0.33232707
Encoder Loss:  0.05245392  || Decoder Loss:  0.035047304 Validation Decoder Loss:  0.33238465
Encoder Loss:  0.05223753  || Decoder Loss:  0.035035264 Validation Decoder Loss:  0.3324479
Encoder Loss:  0.05223736  || Decoder Loss:  0.03502321 Validation Decoder Loss:  0.33246005
Encoder Loss:  0.05218349  || Decoder Loss:  0.035012573 Validation Decoder Loss:  0.33245528
Encoder Loss:  0.051765203  || Decoder Loss:  0.034997918 Validation Decoder Loss:  0.3325965
Encoder Loss:  0.051976744  || Decoder Loss:  0.034983706 Validation Decoder Loss:  0.33255437
Encoder Loss:  0.05169241  || Decoder Loss:  0.034972176 Validation Decoder Loss:  0.33260882
Encoder Loss:  0.051419612  || Decoder Loss:  0.034949303 Validation Decoder Loss:  0.33273563
Encoder Loss:  0.051542047  || Decoder Loss:  0.034943655 Validation Decoder Loss:  0.33269757
Encoder Loss:  0.051690277  || Decoder Loss:  0.03492508 Validation Decoder Loss:  0.332664
Encoder Loss:  0.051212613  || Decoder Loss:  0.034905914 Validation Decoder Loss:  0.33277112
Encoder Loss:  0.051101256  || Decoder Loss:  0.034884676 Validation Decoder Loss:  0.33278757
Encoder Loss:  0.05122302  || Decoder Loss:  0.034878355 Validation Decoder Loss:  0.33265632
Encoder Loss:  0.05098205  || Decoder Loss:  0.034868736 Validation Decoder Loss:  0.33267534
Encoder Loss:  0.050909314  || Decoder Loss:  0.034850046 Validation Decoder Loss:  0.3327067
Encoder Loss:  0.050834928  || Decoder Loss:  0.034830593 Validation Decoder Loss:  0.3326856
Encoder Loss:  0.050916962  || Decoder Loss:  0.034824345 Validation Decoder Loss:  0.33257085
Encoder Loss:  0.050939463  || Decoder Loss:  0.034814175 Validation Decoder Loss:  0.33256602
Encoder Loss:  0.050931476  || Decoder Loss:  0.034803413 Validation Decoder Loss:  0.33258903
Encoder Loss:  0.050848447  || Decoder Loss:  0.034801356 Validation Decoder Loss:  0.33258593
Encoder Loss:  0.05084307  || Decoder Loss:  0.034794748 Validation Decoder Loss:  0.3325982
Encoder Loss:  0.050793637  || Decoder Loss:  0.03478576 Validation Decoder Loss:  0.3326152
Encoder Loss:  0.050851565  || Decoder Loss:  0.03478816 Validation Decoder Loss:  0.33263803
Encoder Loss:  0.050859503  || Decoder Loss:  0.034780167 Validation Decoder Loss:  0.33261353
Encoder Loss:  0.05086499  || Decoder Loss:  0.03478014 Validation Decoder Loss:  0.3326359
Encoder Loss:  0.050845712  || Decoder Loss:  0.03477244 Validation Decoder Loss:  0.33264238
Encoder Loss:  0.050819006  || Decoder Loss:  0.034773458 Validation Decoder Loss:  0.3326417
Encoder Loss:  0.050832186  || Decoder Loss:  0.03477372 Validation Decoder Loss:  0.3326584
Model: siamese_net_lr_0.0008493038295100506 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3326584
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_85 (Conv3DT (None, 474, 5, 19, 1)     349       
_________________________________________________________________
reshape_85 (Reshape)         (None, 2370, 19, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28673005  || Decoder Loss:  0.045359503 Validation Decoder Loss:  0.34781942
Encoder Loss:  0.28650895  || Decoder Loss:  0.04585498 Validation Decoder Loss:  0.34709206
Encoder Loss:  0.28623006  || Decoder Loss:  0.046487298 Validation Decoder Loss:  0.3462105
Encoder Loss:  0.2858772  || Decoder Loss:  0.047296003 Validation Decoder Loss:  0.34519386
Encoder Loss:  0.28541976  || Decoder Loss:  0.04834998 Validation Decoder Loss:  0.34404016
Encoder Loss:  0.28480938  || Decoder Loss:  0.049757853 Validation Decoder Loss:  0.34272963
Encoder Loss:  0.28396302  || Decoder Loss:  0.05170052 Validation Decoder Loss:  0.34125683
Encoder Loss:  0.28272754  || Decoder Loss:  0.054493066 Validation Decoder Loss:  0.3397569
Encoder Loss:  0.2807928  || Decoder Loss:  0.058708545 Validation Decoder Loss:  0.33866727
Encoder Loss:  0.2774415  || Decoder Loss:  0.06544784 Validation Decoder Loss:  0.33902955
Encoder Loss:  0.27058563  || Decoder Loss:  0.076689154 Validation Decoder Loss:  0.34295806
Encoder Loss:  0.25057647  || Decoder Loss:  0.089906834 Validation Decoder Loss:  0.33769453
Encoder Loss:  0.16697632  || Decoder Loss:  0.052197002 Validation Decoder Loss:  0.3353442
Encoder Loss:  0.06996981  || Decoder Loss:  0.040386066 Validation Decoder Loss:  0.33655912
Encoder Loss:  0.06795409  || Decoder Loss:  0.03792196 Validation Decoder Loss:  0.3370931
Encoder Loss:  0.067592956  || Decoder Loss:  0.037217546 Validation Decoder Loss:  0.33676508
Encoder Loss:  0.06748766  || Decoder Loss:  0.03676403 Validation Decoder Loss:  0.3360904
Encoder Loss:  0.06707552  || Decoder Loss:  0.036408506 Validation Decoder Loss:  0.33542928
Encoder Loss:  0.06670009  || Decoder Loss:  0.03611581 Validation Decoder Loss:  0.33486462
Encoder Loss:  0.06639268  || Decoder Loss:  0.03587921 Validation Decoder Loss:  0.33438414
Encoder Loss:  0.06619212  || Decoder Loss:  0.035680033 Validation Decoder Loss:  0.3339675
Encoder Loss:  0.06593589  || Decoder Loss:  0.035515856 Validation Decoder Loss:  0.3336137
Encoder Loss:  0.065728575  || Decoder Loss:  0.03537823 Validation Decoder Loss:  0.33330965
Encoder Loss:  0.06553519  || Decoder Loss:  0.035262585 Validation Decoder Loss:  0.33304477
Encoder Loss:  0.065353446  || Decoder Loss:  0.035164822 Validation Decoder Loss:  0.33282068
Encoder Loss:  0.06517707  || Decoder Loss:  0.03508361 Validation Decoder Loss:  0.33262435
Encoder Loss:  0.06503148  || Decoder Loss:  0.03501305 Validation Decoder Loss:  0.3324526
Encoder Loss:  0.06486483  || Decoder Loss:  0.034953255 Validation Decoder Loss:  0.3323037
Encoder Loss:  0.06472864  || Decoder Loss:  0.0349012 Validation Decoder Loss:  0.33217156
Encoder Loss:  0.06457127  || Decoder Loss:  0.034855787 Validation Decoder Loss:  0.33205754
Encoder Loss:  0.064437434  || Decoder Loss:  0.03481638 Validation Decoder Loss:  0.3319589
Encoder Loss:  0.06430428  || Decoder Loss:  0.034781784 Validation Decoder Loss:  0.3318743
Encoder Loss:  0.06415955  || Decoder Loss:  0.034751393 Validation Decoder Loss:  0.33179983
Encoder Loss:  0.06396699  || Decoder Loss:  0.034724053 Validation Decoder Loss:  0.3317363
Encoder Loss:  0.06381299  || Decoder Loss:  0.034699216 Validation Decoder Loss:  0.33168772
Encoder Loss:  0.06374118  || Decoder Loss:  0.03467691 Validation Decoder Loss:  0.33164474
Encoder Loss:  0.06320094  || Decoder Loss:  0.034657642 Validation Decoder Loss:  0.33161187
Encoder Loss:  0.060281213  || Decoder Loss:  0.034639943 Validation Decoder Loss:  0.33160108
Encoder Loss:  0.0485933  || Decoder Loss:  0.034633618 Validation Decoder Loss:  0.33156705
Encoder Loss:  0.04834376  || Decoder Loss:  0.034598336 Validation Decoder Loss:  0.3315109
Model: siamese_net_lr_0.0004015275881870654 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3315109
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 237, 10, 19, 1)    349       
_________________________________________________________________
reshape_86 (Reshape)         (None, 2370, 19, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 2370, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 2607, 19, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36885333  || Decoder Loss:  0.04588721 Validation Decoder Loss:  0.34609592
Encoder Loss:  0.36641574  || Decoder Loss:  0.048507217 Validation Decoder Loss:  0.34241074
Encoder Loss:  0.36003873  || Decoder Loss:  0.055241216 Validation Decoder Loss:  0.33829507
Encoder Loss:  0.3245825  || Decoder Loss:  0.06545128 Validation Decoder Loss:  0.3361128
Encoder Loss:  0.11125393  || Decoder Loss:  0.038893696 Validation Decoder Loss:  0.3376544
Encoder Loss:  0.07648092  || Decoder Loss:  0.036632005 Validation Decoder Loss:  0.33498675
Encoder Loss:  0.07595112  || Decoder Loss:  0.035705604 Validation Decoder Loss:  0.33349007
Encoder Loss:  0.075245045  || Decoder Loss:  0.035242304 Validation Decoder Loss:  0.33265454
Encoder Loss:  0.07465467  || Decoder Loss:  0.03498491 Validation Decoder Loss:  0.33214554
Encoder Loss:  0.073952064  || Decoder Loss:  0.034832433 Validation Decoder Loss:  0.33183032
Encoder Loss:  0.07294136  || Decoder Loss:  0.034734886 Validation Decoder Loss:  0.33164096
Encoder Loss:  0.05822315  || Decoder Loss:  0.034661293 Validation Decoder Loss:  0.3314308
Encoder Loss:  0.052771892  || Decoder Loss:  0.03455618 Validation Decoder Loss:  0.33121085
Encoder Loss:  0.05145543  || Decoder Loss:  0.034463435 Validation Decoder Loss:  0.33102122
Encoder Loss:  0.050857864  || Decoder Loss:  0.034390554 Validation Decoder Loss:  0.33086795
Encoder Loss:  0.05057066  || Decoder Loss:  0.034335352 Validation Decoder Loss:  0.33077538
Encoder Loss:  0.050599795  || Decoder Loss:  0.03428164 Validation Decoder Loss:  0.33070135
Encoder Loss:  0.05006438  || Decoder Loss:  0.03423238 Validation Decoder Loss:  0.33068097
Encoder Loss:  0.049909014  || Decoder Loss:  0.034186713 Validation Decoder Loss:  0.33065945
Encoder Loss:  0.049656015  || Decoder Loss:  0.034138136 Validation Decoder Loss:  0.3306524
Encoder Loss:  0.049422555  || Decoder Loss:  0.034093272 Validation Decoder Loss:  0.33065385
Encoder Loss:  0.04921038  || Decoder Loss:  0.03405039 Validation Decoder Loss:  0.33066216
Encoder Loss:  0.049020097  || Decoder Loss:  0.034005463 Validation Decoder Loss:  0.33066928
Encoder Loss:  0.048836797  || Decoder Loss:  0.033961233 Validation Decoder Loss:  0.33068442
Encoder Loss:  0.048620988  || Decoder Loss:  0.033919465 Validation Decoder Loss:  0.33068812
Encoder Loss:  0.04842957  || Decoder Loss:  0.033872053 Validation Decoder Loss:  0.3306759
Encoder Loss:  0.048286386  || Decoder Loss:  0.03381877 Validation Decoder Loss:  0.3306449
Encoder Loss:  0.048098803  || Decoder Loss:  0.033773053 Validation Decoder Loss:  0.33062434
Encoder Loss:  0.047987625  || Decoder Loss:  0.033729926 Validation Decoder Loss:  0.33061624
Encoder Loss:  0.04790033  || Decoder Loss:  0.033698622 Validation Decoder Loss:  0.33064926
Encoder Loss:  0.04779705  || Decoder Loss:  0.03366928 Validation Decoder Loss:  0.33066756
Encoder Loss:  0.04763694  || Decoder Loss:  0.033639148 Validation Decoder Loss:  0.33067593
Encoder Loss:  0.047561936  || Decoder Loss:  0.033615302 Validation Decoder Loss:  0.33068052
Encoder Loss:  0.047541477  || Decoder Loss:  0.033598 Validation Decoder Loss:  0.33070022
Encoder Loss:  0.04750999  || Decoder Loss:  0.033586636 Validation Decoder Loss:  0.33074957
Encoder Loss:  0.047457013  || Decoder Loss:  0.033581663 Validation Decoder Loss:  0.33079678
Encoder Loss:  0.047488403  || Decoder Loss:  0.03357791 Validation Decoder Loss:  0.33083928
Encoder Loss:  0.047428727  || Decoder Loss:  0.033576317 Validation Decoder Loss:  0.33087695
Encoder Loss:  0.047462706  || Decoder Loss:  0.033576444 Validation Decoder Loss:  0.33089447
Encoder Loss:  0.04742438  || Decoder Loss:  0.03358077 Validation Decoder Loss:  0.33088788
Model: siamese_net_lr_0.0006818736964059427 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33088788
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 97, 10, 19, 1)     69        
_________________________________________________________________
reshape_87 (Reshape)         (None, 970, 19, 1)        0         
=================================================================
Total params: 69
Trainable params: 69
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 970, 19, 1)        670       
=================================================================
Total params: 670
Trainable params: 670
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 2607, 19, 1)       1639      
=================================================================
Total params: 1,639
Trainable params: 1,639
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21456434  || Decoder Loss:  0.12573723 Validation Decoder Loss:  0.36237624
Encoder Loss:  0.061291847  || Decoder Loss:  0.03080437 Validation Decoder Loss:  0.33909413
Encoder Loss:  0.045377154  || Decoder Loss:  0.029209875 Validation Decoder Loss:  0.34003502
Encoder Loss:  0.044793047  || Decoder Loss:  0.028586399 Validation Decoder Loss:  0.34096044
Encoder Loss:  0.04435939  || Decoder Loss:  0.02816679 Validation Decoder Loss:  0.34190288
Encoder Loss:  0.043981176  || Decoder Loss:  0.027818512 Validation Decoder Loss:  0.34275764
Encoder Loss:  0.04369324  || Decoder Loss:  0.02750298 Validation Decoder Loss:  0.34361047
Encoder Loss:  0.043485705  || Decoder Loss:  0.027223704 Validation Decoder Loss:  0.34438777
Encoder Loss:  0.04335927  || Decoder Loss:  0.026918937 Validation Decoder Loss:  0.3455001
Encoder Loss:  0.04318076  || Decoder Loss:  0.026641998 Validation Decoder Loss:  0.34617501
Encoder Loss:  0.043093897  || Decoder Loss:  0.026397943 Validation Decoder Loss:  0.34715927
Encoder Loss:  0.042982794  || Decoder Loss:  0.026223557 Validation Decoder Loss:  0.34797907
Encoder Loss:  0.042815246  || Decoder Loss:  0.025992204 Validation Decoder Loss:  0.3483333
Encoder Loss:  0.042789597  || Decoder Loss:  0.025852432 Validation Decoder Loss:  0.34894103
Encoder Loss:  0.042622395  || Decoder Loss:  0.025698157 Validation Decoder Loss:  0.3495213
Encoder Loss:  0.042630352  || Decoder Loss:  0.025561549 Validation Decoder Loss:  0.35000098
Encoder Loss:  0.042520642  || Decoder Loss:  0.025484648 Validation Decoder Loss:  0.3505283
Encoder Loss:  0.042574674  || Decoder Loss:  0.02532341 Validation Decoder Loss:  0.3503036
Encoder Loss:  0.042493977  || Decoder Loss:  0.02526495 Validation Decoder Loss:  0.35106933
Encoder Loss:  0.042404365  || Decoder Loss:  0.02519742 Validation Decoder Loss:  0.35062104
Encoder Loss:  0.042340223  || Decoder Loss:  0.025090098 Validation Decoder Loss:  0.35069263
Encoder Loss:  0.042199686  || Decoder Loss:  0.025057888 Validation Decoder Loss:  0.3518219
Encoder Loss:  0.042227656  || Decoder Loss:  0.024913423 Validation Decoder Loss:  0.3517728
Encoder Loss:  0.04209534  || Decoder Loss:  0.024962073 Validation Decoder Loss:  0.3510299
Encoder Loss:  0.042179093  || Decoder Loss:  0.024890477 Validation Decoder Loss:  0.35131022
Encoder Loss:  0.04216012  || Decoder Loss:  0.024825137 Validation Decoder Loss:  0.35223323
Encoder Loss:  0.042064566  || Decoder Loss:  0.024768759 Validation Decoder Loss:  0.35288948
Encoder Loss:  0.042091023  || Decoder Loss:  0.024740119 Validation Decoder Loss:  0.35227188
Encoder Loss:  0.042032436  || Decoder Loss:  0.024667196 Validation Decoder Loss:  0.3528458
Encoder Loss:  0.042045303  || Decoder Loss:  0.024652526 Validation Decoder Loss:  0.35266376
Encoder Loss:  0.041888513  || Decoder Loss:  0.024594279 Validation Decoder Loss:  0.35227084
Encoder Loss:  0.041902468  || Decoder Loss:  0.024568986 Validation Decoder Loss:  0.35236952
Encoder Loss:  0.041970134  || Decoder Loss:  0.024554811 Validation Decoder Loss:  0.3524183
Encoder Loss:  0.04189438  || Decoder Loss:  0.024469549 Validation Decoder Loss:  0.3523791
Encoder Loss:  0.041927207  || Decoder Loss:  0.024483128 Validation Decoder Loss:  0.35257152
Encoder Loss:  0.041943263  || Decoder Loss:  0.024469862 Validation Decoder Loss:  0.3522604
Encoder Loss:  0.041867062  || Decoder Loss:  0.024405446 Validation Decoder Loss:  0.35197
Encoder Loss:  0.041904587  || Decoder Loss:  0.024390878 Validation Decoder Loss:  0.35183507
Encoder Loss:  0.041893005  || Decoder Loss:  0.024349619 Validation Decoder Loss:  0.35224617
Encoder Loss:  0.041722737  || Decoder Loss:  0.024319256 Validation Decoder Loss:  0.35206214
Model: siamese_net_lr_0.0007399595435826786 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35206214
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_88 (Conv3DT (None, 167, 10, 19, 1)    625       
_________________________________________________________________
reshape_88 (Reshape)         (None, 1670, 19, 1)       0         
=================================================================
Total params: 625
Trainable params: 625
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 1670, 19, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 2607, 19, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22266203  || Decoder Loss:  0.09606154 Validation Decoder Loss:  0.36886805
Encoder Loss:  0.21806736  || Decoder Loss:  0.09663491 Validation Decoder Loss:  0.3681044
Encoder Loss:  0.20872942  || Decoder Loss:  0.09603559 Validation Decoder Loss:  0.3666988
Encoder Loss:  0.19016846  || Decoder Loss:  0.09688096 Validation Decoder Loss:  0.4165907
Encoder Loss:  0.21090026  || Decoder Loss:  0.2242916 Validation Decoder Loss:  0.9866966
Encoder Loss:  0.26512063  || Decoder Loss:  0.3777695 Validation Decoder Loss:  0.87302464
Encoder Loss:  0.19686528  || Decoder Loss:  0.2684127 Validation Decoder Loss:  0.5738702
Encoder Loss:  0.100285076  || Decoder Loss:  0.113303296 Validation Decoder Loss:  0.3725146
Encoder Loss:  0.05762064  || Decoder Loss:  0.044880223 Validation Decoder Loss:  0.34160188
Encoder Loss:  0.051422223  || Decoder Loss:  0.03508667 Validation Decoder Loss:  0.33765262
Encoder Loss:  0.0501991  || Decoder Loss:  0.03329642 Validation Decoder Loss:  0.3364535
Encoder Loss:  0.049695026  || Decoder Loss:  0.03267969 Validation Decoder Loss:  0.33598334
Encoder Loss:  0.04939623  || Decoder Loss:  0.032378003 Validation Decoder Loss:  0.33580577
Encoder Loss:  0.049159426  || Decoder Loss:  0.0321844 Validation Decoder Loss:  0.3357708
Encoder Loss:  0.048942816  || Decoder Loss:  0.032042876 Validation Decoder Loss:  0.33580193
Encoder Loss:  0.048748124  || Decoder Loss:  0.031934 Validation Decoder Loss:  0.33584923
Encoder Loss:  0.048556905  || Decoder Loss:  0.03184744 Validation Decoder Loss:  0.33588845
Encoder Loss:  0.048357744  || Decoder Loss:  0.03177703 Validation Decoder Loss:  0.3359196
Encoder Loss:  0.048145294  || Decoder Loss:  0.031718552 Validation Decoder Loss:  0.33593458
Encoder Loss:  0.047904916  || Decoder Loss:  0.03167032 Validation Decoder Loss:  0.33594275
Encoder Loss:  0.047629163  || Decoder Loss:  0.031630825 Validation Decoder Loss:  0.33593312
Encoder Loss:  0.04723118  || Decoder Loss:  0.031599507 Validation Decoder Loss:  0.33591914
Encoder Loss:  0.04673615  || Decoder Loss:  0.031577125 Validation Decoder Loss:  0.3358719
Encoder Loss:  0.046075247  || Decoder Loss:  0.031565484 Validation Decoder Loss:  0.33579162
Encoder Loss:  0.045384787  || Decoder Loss:  0.031565852 Validation Decoder Loss:  0.33569208
Encoder Loss:  0.04441505  || Decoder Loss:  0.031576753 Validation Decoder Loss:  0.33564574
Encoder Loss:  0.043636523  || Decoder Loss:  0.031593986 Validation Decoder Loss:  0.33564696
Encoder Loss:  0.042933665  || Decoder Loss:  0.031617012 Validation Decoder Loss:  0.3356802
Encoder Loss:  0.042514514  || Decoder Loss:  0.031641796 Validation Decoder Loss:  0.3357558
Encoder Loss:  0.042207304  || Decoder Loss:  0.031665485 Validation Decoder Loss:  0.33585423
Encoder Loss:  0.041885357  || Decoder Loss:  0.03168925 Validation Decoder Loss:  0.3359716
Encoder Loss:  0.04160472  || Decoder Loss:  0.03171664 Validation Decoder Loss:  0.33610126
Encoder Loss:  0.0414492  || Decoder Loss:  0.031743154 Validation Decoder Loss:  0.33625558
Encoder Loss:  0.041109845  || Decoder Loss:  0.031773444 Validation Decoder Loss:  0.33641338
Encoder Loss:  0.040952872  || Decoder Loss:  0.03180854 Validation Decoder Loss:  0.3365736
Encoder Loss:  0.040806312  || Decoder Loss:  0.03185103 Validation Decoder Loss:  0.33674693
Encoder Loss:  0.040772695  || Decoder Loss:  0.03190008 Validation Decoder Loss:  0.33691347
Encoder Loss:  0.04057576  || Decoder Loss:  0.031961672 Validation Decoder Loss:  0.337061
Encoder Loss:  0.040552042  || Decoder Loss:  0.032027543 Validation Decoder Loss:  0.3372231
Encoder Loss:  0.040468484  || Decoder Loss:  0.03209599 Validation Decoder Loss:  0.33735272
Model: siamese_net_lr_0.0002311030605293094 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33735272
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 232, 10, 19, 1)    637       
_________________________________________________________________
reshape_89 (Reshape)         (None, 2320, 19, 1)       0         
=================================================================
Total params: 637
Trainable params: 637
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 2320, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 2607, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3065135  || Decoder Loss:  0.055548415 Validation Decoder Loss:  0.34857225
Encoder Loss:  0.30531093  || Decoder Loss:  0.057466876 Validation Decoder Loss:  0.3494844
Encoder Loss:  0.30376408  || Decoder Loss:  0.059810586 Validation Decoder Loss:  0.3507011
Encoder Loss:  0.3017372  || Decoder Loss:  0.06270443 Validation Decoder Loss:  0.35246915
Encoder Loss:  0.2990311  || Decoder Loss:  0.06631453 Validation Decoder Loss:  0.35509452
Encoder Loss:  0.29530317  || Decoder Loss:  0.07082503 Validation Decoder Loss:  0.3590905
Encoder Loss:  0.2898092  || Decoder Loss:  0.07611488 Validation Decoder Loss:  0.36589766
Encoder Loss:  0.27783817  || Decoder Loss:  0.0723702 Validation Decoder Loss:  0.37674803
Encoder Loss:  0.2503425  || Decoder Loss:  0.042173386 Validation Decoder Loss:  0.33838135
Encoder Loss:  0.21720058  || Decoder Loss:  0.03978075 Validation Decoder Loss:  0.34948143
Encoder Loss:  0.1420387  || Decoder Loss:  0.047445316 Validation Decoder Loss:  0.35537738
Encoder Loss:  0.07161313  || Decoder Loss:  0.044899564 Validation Decoder Loss:  0.3391967
Encoder Loss:  0.06798963  || Decoder Loss:  0.039515566 Validation Decoder Loss:  0.33482528
Encoder Loss:  0.04906396  || Decoder Loss:  0.03732448 Validation Decoder Loss:  0.33337337
Encoder Loss:  0.047022857  || Decoder Loss:  0.03648002 Validation Decoder Loss:  0.33274335
Encoder Loss:  0.046687104  || Decoder Loss:  0.035991486 Validation Decoder Loss:  0.33237302
Encoder Loss:  0.046451584  || Decoder Loss:  0.03561853 Validation Decoder Loss:  0.33216846
Encoder Loss:  0.046308212  || Decoder Loss:  0.035342306 Validation Decoder Loss:  0.33209634
Encoder Loss:  0.046169907  || Decoder Loss:  0.03512328 Validation Decoder Loss:  0.3320917
Encoder Loss:  0.04605574  || Decoder Loss:  0.034941662 Validation Decoder Loss:  0.33212525
Encoder Loss:  0.045929536  || Decoder Loss:  0.034780387 Validation Decoder Loss:  0.33217728
Encoder Loss:  0.04583698  || Decoder Loss:  0.034643117 Validation Decoder Loss:  0.33224028
Encoder Loss:  0.04574507  || Decoder Loss:  0.034521114 Validation Decoder Loss:  0.33230036
Encoder Loss:  0.04564442  || Decoder Loss:  0.03440754 Validation Decoder Loss:  0.33235365
Encoder Loss:  0.045559306  || Decoder Loss:  0.034305498 Validation Decoder Loss:  0.33239836
Encoder Loss:  0.04547827  || Decoder Loss:  0.03421013 Validation Decoder Loss:  0.33243203
Encoder Loss:  0.045389175  || Decoder Loss:  0.034122992 Validation Decoder Loss:  0.3324578
Encoder Loss:  0.045309357  || Decoder Loss:  0.03404152 Validation Decoder Loss:  0.33247513
Encoder Loss:  0.045231324  || Decoder Loss:  0.033964943 Validation Decoder Loss:  0.33248007
Encoder Loss:  0.04517157  || Decoder Loss:  0.033895962 Validation Decoder Loss:  0.33247823
Encoder Loss:  0.045100626  || Decoder Loss:  0.033831995 Validation Decoder Loss:  0.3324669
Encoder Loss:  0.04504505  || Decoder Loss:  0.033773385 Validation Decoder Loss:  0.33245632
Encoder Loss:  0.04499916  || Decoder Loss:  0.03372128 Validation Decoder Loss:  0.3324493
Encoder Loss:  0.044955473  || Decoder Loss:  0.033675957 Validation Decoder Loss:  0.33244202
Encoder Loss:  0.044909082  || Decoder Loss:  0.033638436 Validation Decoder Loss:  0.33243954
Encoder Loss:  0.044884693  || Decoder Loss:  0.033605088 Validation Decoder Loss:  0.33244842
Encoder Loss:  0.044872627  || Decoder Loss:  0.033577576 Validation Decoder Loss:  0.332457
Encoder Loss:  0.0448472  || Decoder Loss:  0.033552427 Validation Decoder Loss:  0.33246312
Encoder Loss:  0.044829544  || Decoder Loss:  0.033530887 Validation Decoder Loss:  0.33247903
Encoder Loss:  0.044819564  || Decoder Loss:  0.033514127 Validation Decoder Loss:  0.3324877
Model: siamese_net_lr_0.0003606047231185552 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3324877
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 68, 15, 19, 1)     16        
_________________________________________________________________
reshape_90 (Reshape)         (None, 1020, 19, 1)       0         
=================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 1020, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 2607, 19, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05909376  || Decoder Loss:  0.05909376 Validation Decoder Loss:  0.36181656
Encoder Loss:  0.058617927  || Decoder Loss:  0.058617927 Validation Decoder Loss:  0.36183602
Encoder Loss:  0.058117956  || Decoder Loss:  0.058117956 Validation Decoder Loss:  0.3617109
Encoder Loss:  0.057634555  || Decoder Loss:  0.057634555 Validation Decoder Loss:  0.36149055
Encoder Loss:  0.05716755  || Decoder Loss:  0.05716755 Validation Decoder Loss:  0.3612072
Encoder Loss:  0.05671421  || Decoder Loss:  0.05671421 Validation Decoder Loss:  0.36086142
Encoder Loss:  0.056272432  || Decoder Loss:  0.056272432 Validation Decoder Loss:  0.36043885
Encoder Loss:  0.055840645  || Decoder Loss:  0.055840645 Validation Decoder Loss:  0.35992074
Encoder Loss:  0.055417776  || Decoder Loss:  0.055417776 Validation Decoder Loss:  0.35928944
Encoder Loss:  0.05500354  || Decoder Loss:  0.05500354 Validation Decoder Loss:  0.35853073
Encoder Loss:  0.054599065  || Decoder Loss:  0.054599065 Validation Decoder Loss:  0.35763523
Encoder Loss:  0.054207712  || Decoder Loss:  0.054207712 Validation Decoder Loss:  0.35660148
Encoder Loss:  0.053836074  || Decoder Loss:  0.053836074 Validation Decoder Loss:  0.3554417
Encoder Loss:  0.05349422  || Decoder Loss:  0.05349422 Validation Decoder Loss:  0.3541925
Encoder Loss:  0.053192664  || Decoder Loss:  0.053192664 Validation Decoder Loss:  0.35292932
Encoder Loss:  0.05293364  || Decoder Loss:  0.05293364 Validation Decoder Loss:  0.3517756
Encoder Loss:  0.052701484  || Decoder Loss:  0.052701484 Validation Decoder Loss:  0.350865
Encoder Loss:  0.052468408  || Decoder Loss:  0.052468408 Validation Decoder Loss:  0.3502307
Encoder Loss:  0.05221195  || Decoder Loss:  0.05221195 Validation Decoder Loss:  0.3497588
Encoder Loss:  0.051917944  || Decoder Loss:  0.051917944 Validation Decoder Loss:  0.34930617
Encoder Loss:  0.05157142  || Decoder Loss:  0.05157142 Validation Decoder Loss:  0.34879678
Encoder Loss:  0.05114967  || Decoder Loss:  0.05114967 Validation Decoder Loss:  0.34819865
Encoder Loss:  0.050614867  || Decoder Loss:  0.050614867 Validation Decoder Loss:  0.34746867
Encoder Loss:  0.04989914  || Decoder Loss:  0.04989914 Validation Decoder Loss:  0.34652293
Encoder Loss:  0.04887056  || Decoder Loss:  0.04887056 Validation Decoder Loss:  0.34523705
Encoder Loss:  0.04725836  || Decoder Loss:  0.04725836 Validation Decoder Loss:  0.34357566
Encoder Loss:  0.044573404  || Decoder Loss:  0.044573404 Validation Decoder Loss:  0.34242773
Encoder Loss:  0.040754892  || Decoder Loss:  0.040754892 Validation Decoder Loss:  0.3448781
Encoder Loss:  0.037375245  || Decoder Loss:  0.037375245 Validation Decoder Loss:  0.3470999
Encoder Loss:  0.03513716  || Decoder Loss:  0.03513716 Validation Decoder Loss:  0.34763122
Encoder Loss:  0.03376223  || Decoder Loss:  0.03376223 Validation Decoder Loss:  0.34781975
Encoder Loss:  0.032946542  || Decoder Loss:  0.032946542 Validation Decoder Loss:  0.3478959
Encoder Loss:  0.032469224  || Decoder Loss:  0.032469224 Validation Decoder Loss:  0.3479073
Encoder Loss:  0.03217816  || Decoder Loss:  0.03217816 Validation Decoder Loss:  0.3479196
Encoder Loss:  0.031988602  || Decoder Loss:  0.031988602 Validation Decoder Loss:  0.34793195
Encoder Loss:  0.03185556  || Decoder Loss:  0.03185556 Validation Decoder Loss:  0.34794635
Encoder Loss:  0.031755403  || Decoder Loss:  0.031755403 Validation Decoder Loss:  0.3479644
Encoder Loss:  0.03167546  || Decoder Loss:  0.03167546 Validation Decoder Loss:  0.34798628
Encoder Loss:  0.031608704  || Decoder Loss:  0.031608704 Validation Decoder Loss:  0.3480114
Encoder Loss:  0.03155104  || Decoder Loss:  0.03155104 Validation Decoder Loss:  0.3480392
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3480392
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_91 (Conv3DT (None, 444, 5, 19, 1)     193       
_________________________________________________________________
reshape_91 (Reshape)         (None, 2220, 19, 1)       0         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 2220, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 2607, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10115559  || Decoder Loss:  0.053426605 Validation Decoder Loss:  0.3559817
Encoder Loss:  0.103276834  || Decoder Loss:  0.05639292 Validation Decoder Loss:  0.3563652
Encoder Loss:  0.11550753  || Decoder Loss:  0.074221514 Validation Decoder Loss:  0.40272537
Encoder Loss:  0.12229384  || Decoder Loss:  0.121041805 Validation Decoder Loss:  0.39527434
Encoder Loss:  0.06017785  || Decoder Loss:  0.054974537 Validation Decoder Loss:  0.36336425
Encoder Loss:  0.050289318  || Decoder Loss:  0.04366851 Validation Decoder Loss:  0.34781188
Encoder Loss:  0.04609317  || Decoder Loss:  0.039033297 Validation Decoder Loss:  0.34090373
Encoder Loss:  0.044394866  || Decoder Loss:  0.037145413 Validation Decoder Loss:  0.3374685
Encoder Loss:  0.0423965  || Decoder Loss:  0.036276594 Validation Decoder Loss:  0.33580914
Encoder Loss:  0.038542777  || Decoder Loss:  0.03586801 Validation Decoder Loss:  0.3347089
Encoder Loss:  0.03797017  || Decoder Loss:  0.03554144 Validation Decoder Loss:  0.3340333
Encoder Loss:  0.037575454  || Decoder Loss:  0.035222556 Validation Decoder Loss:  0.33335868
Encoder Loss:  0.03727364  || Decoder Loss:  0.034923073 Validation Decoder Loss:  0.33285934
Encoder Loss:  0.037022654  || Decoder Loss:  0.03471225 Validation Decoder Loss:  0.3325503
Encoder Loss:  0.036860045  || Decoder Loss:  0.03456621 Validation Decoder Loss:  0.33234692
Encoder Loss:  0.03673865  || Decoder Loss:  0.034458634 Validation Decoder Loss:  0.33221802
Encoder Loss:  0.036629938  || Decoder Loss:  0.03437072 Validation Decoder Loss:  0.33212712
Encoder Loss:  0.03653808  || Decoder Loss:  0.03429477 Validation Decoder Loss:  0.33208817
Encoder Loss:  0.03644764  || Decoder Loss:  0.03422157 Validation Decoder Loss:  0.33209127
Encoder Loss:  0.036364943  || Decoder Loss:  0.034151092 Validation Decoder Loss:  0.33211395
Encoder Loss:  0.036315393  || Decoder Loss:  0.034082144 Validation Decoder Loss:  0.33217496
Encoder Loss:  0.03622306  || Decoder Loss:  0.034016334 Validation Decoder Loss:  0.33221668
Encoder Loss:  0.03616102  || Decoder Loss:  0.03395296 Validation Decoder Loss:  0.3322651
Encoder Loss:  0.036082774  || Decoder Loss:  0.033893283 Validation Decoder Loss:  0.33231044
Encoder Loss:  0.03604033  || Decoder Loss:  0.033840176 Validation Decoder Loss:  0.33237165
Encoder Loss:  0.03596812  || Decoder Loss:  0.033789705 Validation Decoder Loss:  0.33238283
Encoder Loss:  0.03592171  || Decoder Loss:  0.03374253 Validation Decoder Loss:  0.33240736
Encoder Loss:  0.03587791  || Decoder Loss:  0.033701535 Validation Decoder Loss:  0.3324324
Encoder Loss:  0.035832316  || Decoder Loss:  0.033664145 Validation Decoder Loss:  0.33244413
Encoder Loss:  0.035801236  || Decoder Loss:  0.033631418 Validation Decoder Loss:  0.33249596
Encoder Loss:  0.035772298  || Decoder Loss:  0.033603825 Validation Decoder Loss:  0.3325089
Encoder Loss:  0.03574751  || Decoder Loss:  0.033575863 Validation Decoder Loss:  0.3325541
Encoder Loss:  0.0357219  || Decoder Loss:  0.03355046 Validation Decoder Loss:  0.3325833
Encoder Loss:  0.035695836  || Decoder Loss:  0.033527188 Validation Decoder Loss:  0.3325932
Encoder Loss:  0.035676833  || Decoder Loss:  0.033507388 Validation Decoder Loss:  0.33260977
Encoder Loss:  0.035659626  || Decoder Loss:  0.033489957 Validation Decoder Loss:  0.33261645
Encoder Loss:  0.03564051  || Decoder Loss:  0.03347421 Validation Decoder Loss:  0.3325931
Encoder Loss:  0.035631415  || Decoder Loss:  0.033463243 Validation Decoder Loss:  0.33259687
Encoder Loss:  0.035620857  || Decoder Loss:  0.033453494 Validation Decoder Loss:  0.3325979
Encoder Loss:  0.0356042  || Decoder Loss:  0.033447154 Validation Decoder Loss:  0.3325953
Model: siamese_net_lr_0.0008975183412470685 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33259532
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 145, 16, 19, 1)    985       
_________________________________________________________________
reshape_92 (Reshape)         (None, 2320, 19, 1)       0         
=================================================================
Total params: 985
Trainable params: 985
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 2320, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 2607, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11820312  || Decoder Loss:  0.05845116 Validation Decoder Loss:  0.33115757
Encoder Loss:  0.04448299  || Decoder Loss:  0.035972286 Validation Decoder Loss:  0.33214065
Encoder Loss:  0.041563686  || Decoder Loss:  0.03421284 Validation Decoder Loss:  0.33138916
Encoder Loss:  0.040183153  || Decoder Loss:  0.033527967 Validation Decoder Loss:  0.33144736
Encoder Loss:  0.039681446  || Decoder Loss:  0.03324852 Validation Decoder Loss:  0.3313065
Encoder Loss:  0.039487306  || Decoder Loss:  0.03309655 Validation Decoder Loss:  0.33126426
Encoder Loss:  0.03946558  || Decoder Loss:  0.03308131 Validation Decoder Loss:  0.33119792
Encoder Loss:  0.03947515  || Decoder Loss:  0.033102 Validation Decoder Loss:  0.33144596
Encoder Loss:  0.0395425  || Decoder Loss:  0.033156358 Validation Decoder Loss:  0.3313423
Encoder Loss:  0.039557613  || Decoder Loss:  0.03322033 Validation Decoder Loss:  0.33154422
Encoder Loss:  0.03957725  || Decoder Loss:  0.03328786 Validation Decoder Loss:  0.33123398
Encoder Loss:  0.039645903  || Decoder Loss:  0.033407975 Validation Decoder Loss:  0.3313315
Encoder Loss:  0.039701432  || Decoder Loss:  0.0335151 Validation Decoder Loss:  0.3315767
Encoder Loss:  0.039761994  || Decoder Loss:  0.033636644 Validation Decoder Loss:  0.33162925
Encoder Loss:  0.03988779  || Decoder Loss:  0.033788193 Validation Decoder Loss:  0.33148736
Encoder Loss:  0.03990762  || Decoder Loss:  0.03387753 Validation Decoder Loss:  0.3316358
Encoder Loss:  0.039980732  || Decoder Loss:  0.034010533 Validation Decoder Loss:  0.33130223
Encoder Loss:  0.040011972  || Decoder Loss:  0.03408017 Validation Decoder Loss:  0.33143115
Encoder Loss:  0.04005659  || Decoder Loss:  0.034181055 Validation Decoder Loss:  0.33143622
Encoder Loss:  0.04011785  || Decoder Loss:  0.034265764 Validation Decoder Loss:  0.33140373
Encoder Loss:  0.040143155  || Decoder Loss:  0.03434906 Validation Decoder Loss:  0.33129936
Encoder Loss:  0.04016182  || Decoder Loss:  0.03439379 Validation Decoder Loss:  0.33153787
Encoder Loss:  0.04020851  || Decoder Loss:  0.03443748 Validation Decoder Loss:  0.33164737
Encoder Loss:  0.040248536  || Decoder Loss:  0.034475993 Validation Decoder Loss:  0.3319501
Encoder Loss:  0.040227514  || Decoder Loss:  0.03451452 Validation Decoder Loss:  0.33195603
Encoder Loss:  0.040330652  || Decoder Loss:  0.034560814 Validation Decoder Loss:  0.33171296
Encoder Loss:  0.04024182  || Decoder Loss:  0.034579683 Validation Decoder Loss:  0.3317362
Encoder Loss:  0.040262856  || Decoder Loss:  0.03461876 Validation Decoder Loss:  0.3318684
Encoder Loss:  0.040281318  || Decoder Loss:  0.034641348 Validation Decoder Loss:  0.33197242
Encoder Loss:  0.040286887  || Decoder Loss:  0.034665823 Validation Decoder Loss:  0.3321489
Encoder Loss:  0.040294122  || Decoder Loss:  0.0346849 Validation Decoder Loss:  0.33208477
Encoder Loss:  0.040297575  || Decoder Loss:  0.034711663 Validation Decoder Loss:  0.33196414
Encoder Loss:  0.040298875  || Decoder Loss:  0.034730606 Validation Decoder Loss:  0.33223492
Encoder Loss:  0.040307  || Decoder Loss:  0.034757383 Validation Decoder Loss:  0.3322013
Encoder Loss:  0.04031042  || Decoder Loss:  0.034773044 Validation Decoder Loss:  0.33228934
Encoder Loss:  0.040331293  || Decoder Loss:  0.034802347 Validation Decoder Loss:  0.33227313
Encoder Loss:  0.040342502  || Decoder Loss:  0.03483247 Validation Decoder Loss:  0.33255357
Encoder Loss:  0.04038888  || Decoder Loss:  0.03483874 Validation Decoder Loss:  0.33231208
Encoder Loss:  0.04031943  || Decoder Loss:  0.034843635 Validation Decoder Loss:  0.3323691
Encoder Loss:  0.040342454  || Decoder Loss:  0.034861073 Validation Decoder Loss:  0.33251172
Model: siamese_net_lr_0.0009567645883740924 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33251172
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 65, 38, 19, 1)     37        
_________________________________________________________________
reshape_93 (Reshape)         (None, 2470, 19, 1)       0         
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 2470, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 2607, 19, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03752791  || Decoder Loss:  0.03752791 Validation Decoder Loss:  0.3406236
Encoder Loss:  0.037296925  || Decoder Loss:  0.037296925 Validation Decoder Loss:  0.34025684
Encoder Loss:  0.03706287  || Decoder Loss:  0.03706287 Validation Decoder Loss:  0.3399529
Encoder Loss:  0.036823772  || Decoder Loss:  0.036823772 Validation Decoder Loss:  0.33967376
Encoder Loss:  0.03657183  || Decoder Loss:  0.03657183 Validation Decoder Loss:  0.3393928
Encoder Loss:  0.036301505  || Decoder Loss:  0.036301505 Validation Decoder Loss:  0.33910352
Encoder Loss:  0.03601769  || Decoder Loss:  0.03601769 Validation Decoder Loss:  0.3388588
Encoder Loss:  0.035759624  || Decoder Loss:  0.035759624 Validation Decoder Loss:  0.33880708
Encoder Loss:  0.035585813  || Decoder Loss:  0.035585813 Validation Decoder Loss:  0.33882207
Encoder Loss:  0.0354539  || Decoder Loss:  0.0354539 Validation Decoder Loss:  0.33856803
Encoder Loss:  0.035314426  || Decoder Loss:  0.035314426 Validation Decoder Loss:  0.33821192
Encoder Loss:  0.03515935  || Decoder Loss:  0.03515935 Validation Decoder Loss:  0.3377909
Encoder Loss:  0.034984984  || Decoder Loss:  0.034984984 Validation Decoder Loss:  0.33725944
Encoder Loss:  0.034788705  || Decoder Loss:  0.034788705 Validation Decoder Loss:  0.3365674
Encoder Loss:  0.034570474  || Decoder Loss:  0.034570474 Validation Decoder Loss:  0.33566672
Encoder Loss:  0.03433659  || Decoder Loss:  0.03433659 Validation Decoder Loss:  0.33457363
Encoder Loss:  0.034105968  || Decoder Loss:  0.034105968 Validation Decoder Loss:  0.3334334
Encoder Loss:  0.03390951  || Decoder Loss:  0.03390951 Validation Decoder Loss:  0.33244717
Encoder Loss:  0.033769194  || Decoder Loss:  0.033769194 Validation Decoder Loss:  0.33175296
Encoder Loss:  0.03368052  || Decoder Loss:  0.03368052 Validation Decoder Loss:  0.33134696
Encoder Loss:  0.03362495  || Decoder Loss:  0.03362495 Validation Decoder Loss:  0.33113992
Encoder Loss:  0.033587363  || Decoder Loss:  0.033587363 Validation Decoder Loss:  0.33104295
Encoder Loss:  0.03355931  || Decoder Loss:  0.03355931 Validation Decoder Loss:  0.3310032
Encoder Loss:  0.033536583  || Decoder Loss:  0.033536583 Validation Decoder Loss:  0.3309937
Encoder Loss:  0.03351703  || Decoder Loss:  0.03351703 Validation Decoder Loss:  0.3310007
Encoder Loss:  0.033499517  || Decoder Loss:  0.033499517 Validation Decoder Loss:  0.3310169
Encoder Loss:  0.0334834  || Decoder Loss:  0.0334834 Validation Decoder Loss:  0.33103868
Encoder Loss:  0.033468295  || Decoder Loss:  0.033468295 Validation Decoder Loss:  0.33106396
Encoder Loss:  0.033453956  || Decoder Loss:  0.033453956 Validation Decoder Loss:  0.33109158
Encoder Loss:  0.03344023  || Decoder Loss:  0.03344023 Validation Decoder Loss:  0.3311211
Encoder Loss:  0.033427015  || Decoder Loss:  0.033427015 Validation Decoder Loss:  0.3311521
Encoder Loss:  0.033414215  || Decoder Loss:  0.033414215 Validation Decoder Loss:  0.33118442
Encoder Loss:  0.0334018  || Decoder Loss:  0.0334018 Validation Decoder Loss:  0.3312179
Encoder Loss:  0.033389725  || Decoder Loss:  0.033389725 Validation Decoder Loss:  0.33125252
Encoder Loss:  0.03337794  || Decoder Loss:  0.03337794 Validation Decoder Loss:  0.33128816
Encoder Loss:  0.033366457  || Decoder Loss:  0.033366457 Validation Decoder Loss:  0.3313248
Encoder Loss:  0.033355255  || Decoder Loss:  0.033355255 Validation Decoder Loss:  0.3313622
Encoder Loss:  0.033344325  || Decoder Loss:  0.033344325 Validation Decoder Loss:  0.33140028
Encoder Loss:  0.03333367  || Decoder Loss:  0.03333367 Validation Decoder Loss:  0.3314388
Encoder Loss:  0.033323288  || Decoder Loss:  0.033323288 Validation Decoder Loss:  0.33147758
Model: siamese_net_lr_0.0009999999999990392 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33147758
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_94 (Conv3DT (None, 444, 5, 19, 1)     130       
_________________________________________________________________
reshape_94 (Reshape)         (None, 2220, 19, 1)       0         
=================================================================
Total params: 130
Trainable params: 130
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 2220, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 2607, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32291386  || Decoder Loss:  0.051545564 Validation Decoder Loss:  0.3583114
Encoder Loss:  0.32106125  || Decoder Loss:  0.053858474 Validation Decoder Loss:  0.3598786
Encoder Loss:  0.22264916  || Decoder Loss:  0.112564676 Validation Decoder Loss:  0.38105434
Encoder Loss:  0.08690299  || Decoder Loss:  0.05518861 Validation Decoder Loss:  0.3527307
Encoder Loss:  0.08252638  || Decoder Loss:  0.04283376 Validation Decoder Loss:  0.34085354
Encoder Loss:  0.08090963  || Decoder Loss:  0.038456272 Validation Decoder Loss:  0.3353256
Encoder Loss:  0.07986453  || Decoder Loss:  0.0366285 Validation Decoder Loss:  0.33279586
Encoder Loss:  0.06721959  || Decoder Loss:  0.035842877 Validation Decoder Loss:  0.33170748
Encoder Loss:  0.050329633  || Decoder Loss:  0.03552996 Validation Decoder Loss:  0.33121753
Encoder Loss:  0.049324524  || Decoder Loss:  0.035263807 Validation Decoder Loss:  0.3309886
Encoder Loss:  0.04911937  || Decoder Loss:  0.03502968 Validation Decoder Loss:  0.33089817
Encoder Loss:  0.04884097  || Decoder Loss:  0.034863867 Validation Decoder Loss:  0.33087867
Encoder Loss:  0.048649743  || Decoder Loss:  0.034752138 Validation Decoder Loss:  0.33088452
Encoder Loss:  0.048392404  || Decoder Loss:  0.034675337 Validation Decoder Loss:  0.3308943
Encoder Loss:  0.048336912  || Decoder Loss:  0.034619574 Validation Decoder Loss:  0.3308953
Encoder Loss:  0.048169926  || Decoder Loss:  0.034575615 Validation Decoder Loss:  0.3308866
Encoder Loss:  0.047929265  || Decoder Loss:  0.03453716 Validation Decoder Loss:  0.33086956
Encoder Loss:  0.047862787  || Decoder Loss:  0.034502804 Validation Decoder Loss:  0.3308387
Encoder Loss:  0.047599178  || Decoder Loss:  0.034468666 Validation Decoder Loss:  0.33080027
Encoder Loss:  0.047454547  || Decoder Loss:  0.034435607 Validation Decoder Loss:  0.330747
Encoder Loss:  0.047300134  || Decoder Loss:  0.03440362 Validation Decoder Loss:  0.3306909
Encoder Loss:  0.04714591  || Decoder Loss:  0.034372125 Validation Decoder Loss:  0.3306344
Encoder Loss:  0.046982717  || Decoder Loss:  0.034341186 Validation Decoder Loss:  0.33057755
Encoder Loss:  0.046814628  || Decoder Loss:  0.034311548 Validation Decoder Loss:  0.3305241
Encoder Loss:  0.04664375  || Decoder Loss:  0.03428161 Validation Decoder Loss:  0.33047664
Encoder Loss:  0.04649016  || Decoder Loss:  0.034252964 Validation Decoder Loss:  0.33044824
Encoder Loss:  0.046354163  || Decoder Loss:  0.03422379 Validation Decoder Loss:  0.33043814
Encoder Loss:  0.046192255  || Decoder Loss:  0.034191083 Validation Decoder Loss:  0.33040828
Encoder Loss:  0.04606091  || Decoder Loss:  0.034162216 Validation Decoder Loss:  0.33039695
Encoder Loss:  0.046011362  || Decoder Loss:  0.034136154 Validation Decoder Loss:  0.33038574
Encoder Loss:  0.04585036  || Decoder Loss:  0.03411013 Validation Decoder Loss:  0.33040142
Encoder Loss:  0.045817662  || Decoder Loss:  0.03408812 Validation Decoder Loss:  0.33038682
Encoder Loss:  0.04576143  || Decoder Loss:  0.034069907 Validation Decoder Loss:  0.33038306
Encoder Loss:  0.045719255  || Decoder Loss:  0.034055073 Validation Decoder Loss:  0.33038715
Encoder Loss:  0.045683794  || Decoder Loss:  0.03404355 Validation Decoder Loss:  0.33040118
Encoder Loss:  0.045703072  || Decoder Loss:  0.034033086 Validation Decoder Loss:  0.33038557
Encoder Loss:  0.045647997  || Decoder Loss:  0.034022648 Validation Decoder Loss:  0.3304018
Encoder Loss:  0.04565483  || Decoder Loss:  0.03401595 Validation Decoder Loss:  0.33040625
Encoder Loss:  0.045650974  || Decoder Loss:  0.03400961 Validation Decoder Loss:  0.330406
Encoder Loss:  0.045628358  || Decoder Loss:  0.03400186 Validation Decoder Loss:  0.33040893
Model: siamese_net_lr_0.0005144735914866052 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33040893
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 185, 12, 19, 1)    473       
_________________________________________________________________
reshape_95 (Reshape)         (None, 2220, 19, 1)       0         
=================================================================
Total params: 473
Trainable params: 473
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 2220, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 2607, 19, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05002058  || Decoder Loss:  0.05002058 Validation Decoder Loss:  0.3406322
Encoder Loss:  0.032937437  || Decoder Loss:  0.032937437 Validation Decoder Loss:  0.3427902
Encoder Loss:  0.032593638  || Decoder Loss:  0.032593638 Validation Decoder Loss:  0.34293038
Encoder Loss:  0.03244392  || Decoder Loss:  0.03244392 Validation Decoder Loss:  0.34288532
Encoder Loss:  0.032324597  || Decoder Loss:  0.032324597 Validation Decoder Loss:  0.3428436
Encoder Loss:  0.032220222  || Decoder Loss:  0.032220222 Validation Decoder Loss:  0.3428325
Encoder Loss:  0.03212602  || Decoder Loss:  0.03212602 Validation Decoder Loss:  0.3428433
Encoder Loss:  0.032040037  || Decoder Loss:  0.032040037 Validation Decoder Loss:  0.34286374
Encoder Loss:  0.03196146  || Decoder Loss:  0.03196146 Validation Decoder Loss:  0.34288734
Encoder Loss:  0.03188982  || Decoder Loss:  0.03188982 Validation Decoder Loss:  0.34291178
Encoder Loss:  0.031825114  || Decoder Loss:  0.031825114 Validation Decoder Loss:  0.34293586
Encoder Loss:  0.031767115  || Decoder Loss:  0.031767115 Validation Decoder Loss:  0.34295893
Encoder Loss:  0.031715553  || Decoder Loss:  0.031715553 Validation Decoder Loss:  0.34298038
Encoder Loss:  0.03167008  || Decoder Loss:  0.03167008 Validation Decoder Loss:  0.34299994
Encoder Loss:  0.031630076  || Decoder Loss:  0.031630076 Validation Decoder Loss:  0.34301758
Encoder Loss:  0.031594962  || Decoder Loss:  0.031594962 Validation Decoder Loss:  0.3430335
Encoder Loss:  0.031564154  || Decoder Loss:  0.031564154 Validation Decoder Loss:  0.34304816
Encoder Loss:  0.031536974  || Decoder Loss:  0.031536974 Validation Decoder Loss:  0.34306192
Encoder Loss:  0.031512976  || Decoder Loss:  0.031512976 Validation Decoder Loss:  0.34307528
Encoder Loss:  0.03149156  || Decoder Loss:  0.03149156 Validation Decoder Loss:  0.34308848
Encoder Loss:  0.031472422  || Decoder Loss:  0.031472422 Validation Decoder Loss:  0.34310174
Encoder Loss:  0.03145519  || Decoder Loss:  0.03145519 Validation Decoder Loss:  0.34311518
Encoder Loss:  0.031439528  || Decoder Loss:  0.031439528 Validation Decoder Loss:  0.34312886
Encoder Loss:  0.031425267  || Decoder Loss:  0.031425267 Validation Decoder Loss:  0.34314275
Encoder Loss:  0.031412154  || Decoder Loss:  0.031412154 Validation Decoder Loss:  0.34315687
Encoder Loss:  0.03140008  || Decoder Loss:  0.03140008 Validation Decoder Loss:  0.34317118
Encoder Loss:  0.031388894  || Decoder Loss:  0.031388894 Validation Decoder Loss:  0.3431856
Encoder Loss:  0.031378478  || Decoder Loss:  0.031378478 Validation Decoder Loss:  0.3432001
Encoder Loss:  0.031368777  || Decoder Loss:  0.031368777 Validation Decoder Loss:  0.3432147
Encoder Loss:  0.03135964  || Decoder Loss:  0.03135964 Validation Decoder Loss:  0.34322935
Encoder Loss:  0.03135111  || Decoder Loss:  0.03135111 Validation Decoder Loss:  0.34324396
Encoder Loss:  0.03134304  || Decoder Loss:  0.03134304 Validation Decoder Loss:  0.34325853
Encoder Loss:  0.03133544  || Decoder Loss:  0.03133544 Validation Decoder Loss:  0.34327304
Encoder Loss:  0.031328224  || Decoder Loss:  0.031328224 Validation Decoder Loss:  0.34328747
Encoder Loss:  0.03132139  || Decoder Loss:  0.03132139 Validation Decoder Loss:  0.34330177
Encoder Loss:  0.031314924  || Decoder Loss:  0.031314924 Validation Decoder Loss:  0.34331602
Encoder Loss:  0.031308755  || Decoder Loss:  0.031308755 Validation Decoder Loss:  0.3433301
Encoder Loss:  0.031302888  || Decoder Loss:  0.031302888 Validation Decoder Loss:  0.34334406
Encoder Loss:  0.031297307  || Decoder Loss:  0.031297307 Validation Decoder Loss:  0.34335786
Encoder Loss:  0.03129195  || Decoder Loss:  0.03129195 Validation Decoder Loss:  0.3433715
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3433715
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 290, 8, 19, 1)     405       
_________________________________________________________________
reshape_96 (Reshape)         (None, 2320, 19, 1)       0         
=================================================================
Total params: 405
Trainable params: 405
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 2320, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 2607, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38531604  || Decoder Loss:  0.050119165 Validation Decoder Loss:  0.34948993
Encoder Loss:  0.3849305  || Decoder Loss:  0.050499476 Validation Decoder Loss:  0.34968752
Encoder Loss:  0.3844922  || Decoder Loss:  0.050928105 Validation Decoder Loss:  0.34988216
Encoder Loss:  0.38399693  || Decoder Loss:  0.0514066 Validation Decoder Loss:  0.3500876
Encoder Loss:  0.38343266  || Decoder Loss:  0.05194267 Validation Decoder Loss:  0.35031527
Encoder Loss:  0.38278678  || Decoder Loss:  0.052545074 Validation Decoder Loss:  0.35057557
Encoder Loss:  0.38204476  || Decoder Loss:  0.05322426 Validation Decoder Loss:  0.35087964
Encoder Loss:  0.3811896  || Decoder Loss:  0.053992864 Validation Decoder Loss:  0.35124028
Encoder Loss:  0.38020012  || Decoder Loss:  0.054866362 Validation Decoder Loss:  0.35167348
Encoder Loss:  0.37904966  || Decoder Loss:  0.055863906 Validation Decoder Loss:  0.35219938
Encoder Loss:  0.37770382  || Decoder Loss:  0.057009354 Validation Decoder Loss:  0.3528431
Encoder Loss:  0.37611815  || Decoder Loss:  0.05833267 Validation Decoder Loss:  0.35363787
Encoder Loss:  0.37423432  || Decoder Loss:  0.059871823 Validation Decoder Loss:  0.35462856
Encoder Loss:  0.37197343  || Decoder Loss:  0.061675005 Validation Decoder Loss:  0.3558752
Encoder Loss:  0.36922655  || Decoder Loss:  0.06380314 Validation Decoder Loss:  0.35745752
Encoder Loss:  0.3658387  || Decoder Loss:  0.066331506 Validation Decoder Loss:  0.35948303
Encoder Loss:  0.36158025  || Decoder Loss:  0.069344744 Validation Decoder Loss:  0.36209774
Encoder Loss:  0.3560922  || Decoder Loss:  0.0729051 Validation Decoder Loss:  0.3654827
Encoder Loss:  0.34875858  || Decoder Loss:  0.07690141 Validation Decoder Loss:  0.369787
Encoder Loss:  0.33835587  || Decoder Loss:  0.080292456 Validation Decoder Loss:  0.37462592
Encoder Loss:  0.32168868  || Decoder Loss:  0.07614538 Validation Decoder Loss:  0.3825522
Encoder Loss:  0.2926643  || Decoder Loss:  0.05744912 Validation Decoder Loss:  0.36483777
Encoder Loss:  0.24246746  || Decoder Loss:  0.053376686 Validation Decoder Loss:  0.3588924
Encoder Loss:  0.14519489  || Decoder Loss:  0.059097756 Validation Decoder Loss:  0.36808917
Encoder Loss:  0.09215934  || Decoder Loss:  0.05820308 Validation Decoder Loss:  0.3555049
Encoder Loss:  0.09111773  || Decoder Loss:  0.0517659 Validation Decoder Loss:  0.34730208
Encoder Loss:  0.09059787  || Decoder Loss:  0.047842577 Validation Decoder Loss:  0.34211636
Encoder Loss:  0.09003589  || Decoder Loss:  0.04523195 Validation Decoder Loss:  0.3386957
Encoder Loss:  0.08962479  || Decoder Loss:  0.043372482 Validation Decoder Loss:  0.3363526
Encoder Loss:  0.0893398  || Decoder Loss:  0.041980013 Validation Decoder Loss:  0.33468848
Encoder Loss:  0.08899303  || Decoder Loss:  0.04089689 Validation Decoder Loss:  0.3334971
Encoder Loss:  0.08872711  || Decoder Loss:  0.040019207 Validation Decoder Loss:  0.33262667
Encoder Loss:  0.088451296  || Decoder Loss:  0.03929447 Validation Decoder Loss:  0.33198416
Encoder Loss:  0.088160604  || Decoder Loss:  0.03868065 Validation Decoder Loss:  0.33150807
Encoder Loss:  0.08777663  || Decoder Loss:  0.03815732 Validation Decoder Loss:  0.33115888
Encoder Loss:  0.08734829  || Decoder Loss:  0.037703566 Validation Decoder Loss:  0.33090353
Encoder Loss:  0.08663706  || Decoder Loss:  0.03731097 Validation Decoder Loss:  0.33072042
Encoder Loss:  0.085214846  || Decoder Loss:  0.036967184 Validation Decoder Loss:  0.33059222
Encoder Loss:  0.08029578  || Decoder Loss:  0.036662202 Validation Decoder Loss:  0.33050254
Encoder Loss:  0.058882404  || Decoder Loss:  0.036383 Validation Decoder Loss:  0.33046186
Model: siamese_net_lr_0.00026591908727680285 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33046186
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_97 (Conv3DT (None, 116, 20, 19, 1)    849       
_________________________________________________________________
reshape_97 (Reshape)         (None, 2320, 19, 1)       0         
=================================================================
Total params: 849
Trainable params: 849
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 2320, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 2607, 19, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42826584  || Decoder Loss:  0.05863103 Validation Decoder Loss:  0.34867263
Encoder Loss:  0.42703965  || Decoder Loss:  0.05945618 Validation Decoder Loss:  0.34925923
Encoder Loss:  0.42554307  || Decoder Loss:  0.060423616 Validation Decoder Loss:  0.34987164
Encoder Loss:  0.4238282  || Decoder Loss:  0.061480608 Validation Decoder Loss:  0.3505221
Encoder Loss:  0.42186108  || Decoder Loss:  0.06263283 Validation Decoder Loss:  0.35124052
Encoder Loss:  0.4195911  || Decoder Loss:  0.06389341 Validation Decoder Loss:  0.35205314
Encoder Loss:  0.41695443  || Decoder Loss:  0.06527841 Validation Decoder Loss:  0.35298303
Encoder Loss:  0.4138699  || Decoder Loss:  0.06680831 Validation Decoder Loss:  0.35405523
Encoder Loss:  0.4102327  || Decoder Loss:  0.06851214 Validation Decoder Loss:  0.3553024
Encoder Loss:  0.40590858  || Decoder Loss:  0.07043195 Validation Decoder Loss:  0.35677248
Encoder Loss:  0.40072528  || Decoder Loss:  0.07262549 Validation Decoder Loss:  0.35854006
Encoder Loss:  0.39445806  || Decoder Loss:  0.075165845 Validation Decoder Loss:  0.36071932
Encoder Loss:  0.3868046  || Decoder Loss:  0.07813978 Validation Decoder Loss:  0.36347252
Encoder Loss:  0.37734798  || Decoder Loss:  0.081645034 Validation Decoder Loss:  0.36702138
Encoder Loss:  0.3655014  || Decoder Loss:  0.08576476 Validation Decoder Loss:  0.37168455
Encoder Loss:  0.3504294  || Decoder Loss:  0.09040239 Validation Decoder Loss:  0.3778963
Encoder Loss:  0.33090535  || Decoder Loss:  0.0942499 Validation Decoder Loss:  0.38612467
Encoder Loss:  0.30492985  || Decoder Loss:  0.08644362 Validation Decoder Loss:  0.43017477
Encoder Loss:  0.2696129  || Decoder Loss:  0.057945203 Validation Decoder Loss:  0.36614227
Encoder Loss:  0.22173364  || Decoder Loss:  0.05166486 Validation Decoder Loss:  0.36664984
Encoder Loss:  0.15582557  || Decoder Loss:  0.059501186 Validation Decoder Loss:  0.3803199
Encoder Loss:  0.083108224  || Decoder Loss:  0.06494677 Validation Decoder Loss:  0.37710547
Encoder Loss:  0.080957025  || Decoder Loss:  0.055981547 Validation Decoder Loss:  0.35712028
Encoder Loss:  0.07579567  || Decoder Loss:  0.048480816 Validation Decoder Loss:  0.34815073
Encoder Loss:  0.0763913  || Decoder Loss:  0.04475907 Validation Decoder Loss:  0.34262186
Encoder Loss:  0.07541254  || Decoder Loss:  0.042423397 Validation Decoder Loss:  0.33927628
Encoder Loss:  0.07409037  || Decoder Loss:  0.040858775 Validation Decoder Loss:  0.33706337
Encoder Loss:  0.06748925  || Decoder Loss:  0.039703958 Validation Decoder Loss:  0.33549348
Encoder Loss:  0.055151347  || Decoder Loss:  0.038893282 Validation Decoder Loss:  0.33479482
Encoder Loss:  0.053715467  || Decoder Loss:  0.038363706 Validation Decoder Loss:  0.3343169
Encoder Loss:  0.052775078  || Decoder Loss:  0.037982143 Validation Decoder Loss:  0.33395436
Encoder Loss:  0.05233918  || Decoder Loss:  0.037679918 Validation Decoder Loss:  0.3335993
Encoder Loss:  0.052166805  || Decoder Loss:  0.037380636 Validation Decoder Loss:  0.33324218
Encoder Loss:  0.052227236  || Decoder Loss:  0.03708346 Validation Decoder Loss:  0.33294994
Encoder Loss:  0.05203403  || Decoder Loss:  0.03682625 Validation Decoder Loss:  0.3327179
Encoder Loss:  0.052179556  || Decoder Loss:  0.036600973 Validation Decoder Loss:  0.33255285
Encoder Loss:  0.05227203  || Decoder Loss:  0.036412288 Validation Decoder Loss:  0.33244035
Encoder Loss:  0.052205324  || Decoder Loss:  0.036246542 Validation Decoder Loss:  0.33236018
Encoder Loss:  0.051989432  || Decoder Loss:  0.03609485 Validation Decoder Loss:  0.33229178
Encoder Loss:  0.05198877  || Decoder Loss:  0.035953313 Validation Decoder Loss:  0.33224547
Model: siamese_net_lr_0.0005961043077959772 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33224547
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 114, 5, 19, 1)     52        
_________________________________________________________________
reshape_98 (Reshape)         (None, 570, 19, 1)        0         
=================================================================
Total params: 52
Trainable params: 52
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 570, 19, 1)        1470      
=================================================================
Total params: 1,470
Trainable params: 1,470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 2607, 19, 1)       2039      
=================================================================
Total params: 2,039
Trainable params: 2,039
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.269525  || Decoder Loss:  0.05971043 Validation Decoder Loss:  0.36393863
Encoder Loss:  0.26910964  || Decoder Loss:  0.05892612 Validation Decoder Loss:  0.3646251
Encoder Loss:  0.26870123  || Decoder Loss:  0.058164533 Validation Decoder Loss:  0.3653221
Encoder Loss:  0.2683106  || Decoder Loss:  0.05744862 Validation Decoder Loss:  0.36602196
Encoder Loss:  0.2679361  || Decoder Loss:  0.056775216 Validation Decoder Loss:  0.36671764
Encoder Loss:  0.26757613  || Decoder Loss:  0.05614127 Validation Decoder Loss:  0.3674035
Encoder Loss:  0.2672291  || Decoder Loss:  0.055543922 Validation Decoder Loss:  0.3680744
Encoder Loss:  0.26689342  || Decoder Loss:  0.054980673 Validation Decoder Loss:  0.3687252
Encoder Loss:  0.26656783  || Decoder Loss:  0.054449048 Validation Decoder Loss:  0.36935103
Encoder Loss:  0.26625082  || Decoder Loss:  0.053946752 Validation Decoder Loss:  0.36994696
Encoder Loss:  0.26594105  || Decoder Loss:  0.05347164 Validation Decoder Loss:  0.37050882
Encoder Loss:  0.26563725  || Decoder Loss:  0.053021725 Validation Decoder Loss:  0.37103337
Encoder Loss:  0.26533806  || Decoder Loss:  0.052595187 Validation Decoder Loss:  0.3715187
Encoder Loss:  0.26504242  || Decoder Loss:  0.052190404 Validation Decoder Loss:  0.37196466
Encoder Loss:  0.26474902  || Decoder Loss:  0.051805962 Validation Decoder Loss:  0.3723727
Encoder Loss:  0.26445675  || Decoder Loss:  0.05144068 Validation Decoder Loss:  0.37274554
Encoder Loss:  0.2641646  || Decoder Loss:  0.051093478 Validation Decoder Loss:  0.3730868
Encoder Loss:  0.26387137  || Decoder Loss:  0.050763544 Validation Decoder Loss:  0.37340033
Encoder Loss:  0.26357612  || Decoder Loss:  0.050450105 Validation Decoder Loss:  0.37368983
Encoder Loss:  0.2632776  || Decoder Loss:  0.050152596 Validation Decoder Loss:  0.3739587
Encoder Loss:  0.26297456  || Decoder Loss:  0.04987041 Validation Decoder Loss:  0.37420976
Encoder Loss:  0.262666  || Decoder Loss:  0.049603127 Validation Decoder Loss:  0.37444532
Encoder Loss:  0.26235032  || Decoder Loss:  0.04935035 Validation Decoder Loss:  0.37466726
Encoder Loss:  0.26202607  || Decoder Loss:  0.049111746 Validation Decoder Loss:  0.37487677
Encoder Loss:  0.26169193  || Decoder Loss:  0.04888705 Validation Decoder Loss:  0.37507492
Encoder Loss:  0.2613459  || Decoder Loss:  0.048676033 Validation Decoder Loss:  0.37526238
Encoder Loss:  0.26098606  || Decoder Loss:  0.048478592 Validation Decoder Loss:  0.3754397
Encoder Loss:  0.26061034  || Decoder Loss:  0.04829465 Validation Decoder Loss:  0.3756072
Encoder Loss:  0.26021633  || Decoder Loss:  0.048124257 Validation Decoder Loss:  0.37576532
Encoder Loss:  0.25980118  || Decoder Loss:  0.04796754 Validation Decoder Loss:  0.3759143
Encoder Loss:  0.25936192  || Decoder Loss:  0.04782477 Validation Decoder Loss:  0.37605476
Encoder Loss:  0.25889492  || Decoder Loss:  0.04769632 Validation Decoder Loss:  0.37618726
Encoder Loss:  0.25839615  || Decoder Loss:  0.047582734 Validation Decoder Loss:  0.37631273
Encoder Loss:  0.25786075  || Decoder Loss:  0.047484737 Validation Decoder Loss:  0.37643233
Encoder Loss:  0.2572834  || Decoder Loss:  0.047403213 Validation Decoder Loss:  0.3765477
Encoder Loss:  0.25665742  || Decoder Loss:  0.047339324 Validation Decoder Loss:  0.37666082
Encoder Loss:  0.25597495  || Decoder Loss:  0.047294483 Validation Decoder Loss:  0.3767743
Encoder Loss:  0.25522694  || Decoder Loss:  0.04727045 Validation Decoder Loss:  0.37689137
Encoder Loss:  0.25440204  || Decoder Loss:  0.04726938 Validation Decoder Loss:  0.37701598
Encoder Loss:  0.25348666  || Decoder Loss:  0.047293924 Validation Decoder Loss:  0.37715298
Model: siamese_net_lr_0.00011159041288489677 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37715298
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 454, 5, 19, 1)     329       
_________________________________________________________________
reshape_99 (Reshape)         (None, 2270, 19, 1)       0         
=================================================================
Total params: 329
Trainable params: 329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 2270, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 2607, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37549835  || Decoder Loss:  0.05205293 Validation Decoder Loss:  0.3525483
Encoder Loss:  0.37235945  || Decoder Loss:  0.055541843 Validation Decoder Loss:  0.34940404
Encoder Loss:  0.36203396  || Decoder Loss:  0.06659355 Validation Decoder Loss:  0.34968415
Encoder Loss:  0.26131055  || Decoder Loss:  0.11692957 Validation Decoder Loss:  0.4285599
Encoder Loss:  0.087225474  || Decoder Loss:  0.06304337 Validation Decoder Loss:  0.36329156
Encoder Loss:  0.07872626  || Decoder Loss:  0.045585427 Validation Decoder Loss:  0.34625602
Encoder Loss:  0.07689545  || Decoder Loss:  0.039692387 Validation Decoder Loss:  0.33872533
Encoder Loss:  0.074692816  || Decoder Loss:  0.037204962 Validation Decoder Loss:  0.33522978
Encoder Loss:  0.052060775  || Decoder Loss:  0.03609149 Validation Decoder Loss:  0.3331796
Encoder Loss:  0.05007851  || Decoder Loss:  0.03573717 Validation Decoder Loss:  0.33263174
Encoder Loss:  0.049886033  || Decoder Loss:  0.035435602 Validation Decoder Loss:  0.33237925
Encoder Loss:  0.049652  || Decoder Loss:  0.035231818 Validation Decoder Loss:  0.33228955
Encoder Loss:  0.049473476  || Decoder Loss:  0.035075963 Validation Decoder Loss:  0.33230108
Encoder Loss:  0.04937836  || Decoder Loss:  0.034940884 Validation Decoder Loss:  0.3323936
Encoder Loss:  0.04917194  || Decoder Loss:  0.03481604 Validation Decoder Loss:  0.332499
Encoder Loss:  0.048975557  || Decoder Loss:  0.03469013 Validation Decoder Loss:  0.3325901
Encoder Loss:  0.048806656  || Decoder Loss:  0.034562975 Validation Decoder Loss:  0.33267927
Encoder Loss:  0.04862472  || Decoder Loss:  0.034431573 Validation Decoder Loss:  0.3327539
Encoder Loss:  0.04845994  || Decoder Loss:  0.03430133 Validation Decoder Loss:  0.33281177
Encoder Loss:  0.048306894  || Decoder Loss:  0.03418455 Validation Decoder Loss:  0.33285797
Encoder Loss:  0.04818244  || Decoder Loss:  0.03408956 Validation Decoder Loss:  0.33289626
Encoder Loss:  0.048032723  || Decoder Loss:  0.034004405 Validation Decoder Loss:  0.33290398
Encoder Loss:  0.047907796  || Decoder Loss:  0.03393404 Validation Decoder Loss:  0.33291513
Encoder Loss:  0.047857966  || Decoder Loss:  0.033884615 Validation Decoder Loss:  0.33294016
Encoder Loss:  0.047780305  || Decoder Loss:  0.03384473 Validation Decoder Loss:  0.33294216
Encoder Loss:  0.047737908  || Decoder Loss:  0.033814028 Validation Decoder Loss:  0.33294648
Encoder Loss:  0.04768917  || Decoder Loss:  0.03379463 Validation Decoder Loss:  0.33295077
Encoder Loss:  0.047599122  || Decoder Loss:  0.0337756 Validation Decoder Loss:  0.33291072
Encoder Loss:  0.04763544  || Decoder Loss:  0.033758175 Validation Decoder Loss:  0.33293164
Encoder Loss:  0.047611028  || Decoder Loss:  0.03374894 Validation Decoder Loss:  0.33294344
Encoder Loss:  0.047600053  || Decoder Loss:  0.03374268 Validation Decoder Loss:  0.3329528
Encoder Loss:  0.047563925  || Decoder Loss:  0.033735882 Validation Decoder Loss:  0.33295894
Encoder Loss:  0.04754571  || Decoder Loss:  0.033732574 Validation Decoder Loss:  0.3329631
Encoder Loss:  0.04751705  || Decoder Loss:  0.033730928 Validation Decoder Loss:  0.33299813
Encoder Loss:  0.04750916  || Decoder Loss:  0.033734623 Validation Decoder Loss:  0.3330335
Encoder Loss:  0.04748692  || Decoder Loss:  0.033739798 Validation Decoder Loss:  0.333046
Encoder Loss:  0.047497556  || Decoder Loss:  0.033744756 Validation Decoder Loss:  0.33302128
Encoder Loss:  0.047501467  || Decoder Loss:  0.03374869 Validation Decoder Loss:  0.33300716
Encoder Loss:  0.047467723  || Decoder Loss:  0.03375322 Validation Decoder Loss:  0.33299208
Encoder Loss:  0.04745929  || Decoder Loss:  0.033760212 Validation Decoder Loss:  0.3330034
Model: siamese_net_lr_0.00076490011803398 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3330034
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_100 (Conv3D (None, 227, 10, 19, 1)    77        
_________________________________________________________________
reshape_100 (Reshape)        (None, 2270, 19, 1)       0         
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 2270, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 2607, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25087693  || Decoder Loss:  0.047110833 Validation Decoder Loss:  0.35736457
Encoder Loss:  0.25023893  || Decoder Loss:  0.04699964 Validation Decoder Loss:  0.35735205
Encoder Loss:  0.24832231  || Decoder Loss:  0.048174717 Validation Decoder Loss:  0.35830635
Encoder Loss:  0.11086968  || Decoder Loss:  0.05550539 Validation Decoder Loss:  0.34080723
Encoder Loss:  0.07275541  || Decoder Loss:  0.04254487 Validation Decoder Loss:  0.3353247
Encoder Loss:  0.07078071  || Decoder Loss:  0.038868584 Validation Decoder Loss:  0.33215252
Encoder Loss:  0.069597915  || Decoder Loss:  0.03685434 Validation Decoder Loss:  0.3306797
Encoder Loss:  0.06889697  || Decoder Loss:  0.035810232 Validation Decoder Loss:  0.33018342
Encoder Loss:  0.06821494  || Decoder Loss:  0.03528965 Validation Decoder Loss:  0.3300896
Encoder Loss:  0.06684118  || Decoder Loss:  0.03500124 Validation Decoder Loss:  0.3301433
Encoder Loss:  0.0498684  || Decoder Loss:  0.0348339 Validation Decoder Loss:  0.3302546
Encoder Loss:  0.044430636  || Decoder Loss:  0.03475889 Validation Decoder Loss:  0.33024406
Encoder Loss:  0.04406438  || Decoder Loss:  0.034715943 Validation Decoder Loss:  0.3303309
Encoder Loss:  0.043987125  || Decoder Loss:  0.034673885 Validation Decoder Loss:  0.33042932
Encoder Loss:  0.043916054  || Decoder Loss:  0.03464135 Validation Decoder Loss:  0.33053267
Encoder Loss:  0.043826517  || Decoder Loss:  0.034616705 Validation Decoder Loss:  0.33067387
Encoder Loss:  0.043670956  || Decoder Loss:  0.034596905 Validation Decoder Loss:  0.33093956
Encoder Loss:  0.043491334  || Decoder Loss:  0.03457219 Validation Decoder Loss:  0.33107793
Encoder Loss:  0.04340269  || Decoder Loss:  0.03454645 Validation Decoder Loss:  0.3311109
Encoder Loss:  0.043324165  || Decoder Loss:  0.03452449 Validation Decoder Loss:  0.3311695
Encoder Loss:  0.043285295  || Decoder Loss:  0.03450635 Validation Decoder Loss:  0.3311334
Encoder Loss:  0.0432391  || Decoder Loss:  0.034490053 Validation Decoder Loss:  0.33121437
Encoder Loss:  0.04320961  || Decoder Loss:  0.03447624 Validation Decoder Loss:  0.33117923
Encoder Loss:  0.04319262  || Decoder Loss:  0.034464806 Validation Decoder Loss:  0.33113647
Encoder Loss:  0.043169025  || Decoder Loss:  0.03445294 Validation Decoder Loss:  0.3311565
Encoder Loss:  0.043138657  || Decoder Loss:  0.034440055 Validation Decoder Loss:  0.3311957
Encoder Loss:  0.04313714  || Decoder Loss:  0.034435414 Validation Decoder Loss:  0.33108762
Encoder Loss:  0.043116003  || Decoder Loss:  0.03442673 Validation Decoder Loss:  0.3310974
Encoder Loss:  0.04310626  || Decoder Loss:  0.034420222 Validation Decoder Loss:  0.33104715
Encoder Loss:  0.04310278  || Decoder Loss:  0.034414243 Validation Decoder Loss:  0.33106956
Encoder Loss:  0.043083005  || Decoder Loss:  0.03440548 Validation Decoder Loss:  0.33105963
Encoder Loss:  0.04307044  || Decoder Loss:  0.034397334 Validation Decoder Loss:  0.3310949
Encoder Loss:  0.043050766  || Decoder Loss:  0.03439071 Validation Decoder Loss:  0.33107373
Encoder Loss:  0.04304581  || Decoder Loss:  0.03438423 Validation Decoder Loss:  0.331078
Encoder Loss:  0.043044295  || Decoder Loss:  0.034376778 Validation Decoder Loss:  0.33112603
Encoder Loss:  0.043031886  || Decoder Loss:  0.034371216 Validation Decoder Loss:  0.33109385
Encoder Loss:  0.04301831  || Decoder Loss:  0.03436464 Validation Decoder Loss:  0.33110407
Encoder Loss:  0.043013453  || Decoder Loss:  0.034358975 Validation Decoder Loss:  0.33108205
Encoder Loss:  0.04298605  || Decoder Loss:  0.034353096 Validation Decoder Loss:  0.33108217
Encoder Loss:  0.04297772  || Decoder Loss:  0.034347545 Validation Decoder Loss:  0.33109164
Model: siamese_net_lr_0.00013644372188106473 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33109164
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 404, 5, 19, 1)     279       
_________________________________________________________________
reshape_101 (Reshape)        (None, 2020, 19, 1)       0         
=================================================================
Total params: 279
Trainable params: 279
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 2020, 19, 1)       589       
=================================================================
Total params: 589
Trainable params: 589
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 2607, 19, 1)       589       
=================================================================
Total params: 589
Trainable params: 589
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3077103  || Decoder Loss:  0.067446396 Validation Decoder Loss:  0.36150894
Encoder Loss:  0.30716333  || Decoder Loss:  0.06832761 Validation Decoder Loss:  0.36125162
Encoder Loss:  0.3063671  || Decoder Loss:  0.06986625 Validation Decoder Loss:  0.3608224
Encoder Loss:  0.30505636  || Decoder Loss:  0.072521865 Validation Decoder Loss:  0.3604198
Encoder Loss:  0.30250287  || Decoder Loss:  0.07739144 Validation Decoder Loss:  0.36072862
Encoder Loss:  0.29623082  || Decoder Loss:  0.087846175 Validation Decoder Loss:  0.36559573
Encoder Loss:  0.27380767  || Decoder Loss:  0.12085223 Validation Decoder Loss:  0.4254055
Encoder Loss:  0.21561433  || Decoder Loss:  0.33124816 Validation Decoder Loss:  0.8487165
Encoder Loss:  0.16449638  || Decoder Loss:  0.29391626 Validation Decoder Loss:  0.7039489
Encoder Loss:  0.13090281  || Decoder Loss:  0.20590593 Validation Decoder Loss:  0.59976614
Encoder Loss:  0.10978376  || Decoder Loss:  0.14851093 Validation Decoder Loss:  0.48796505
Encoder Loss:  0.09021957  || Decoder Loss:  0.09559138 Validation Decoder Loss:  0.40799657
Encoder Loss:  0.07812568  || Decoder Loss:  0.062990315 Validation Decoder Loss:  0.3725786
Encoder Loss:  0.07284464  || Decoder Loss:  0.04916276 Validation Decoder Loss:  0.35738593
Encoder Loss:  0.07052196  || Decoder Loss:  0.043290842 Validation Decoder Loss:  0.34924418
Encoder Loss:  0.06910011  || Decoder Loss:  0.040024437 Validation Decoder Loss:  0.34435847
Encoder Loss:  0.06812563  || Decoder Loss:  0.037928104 Validation Decoder Loss:  0.3411317
Encoder Loss:  0.067474015  || Decoder Loss:  0.03655397 Validation Decoder Loss:  0.33891886
Encoder Loss:  0.06707792  || Decoder Loss:  0.035651322 Validation Decoder Loss:  0.33734363
Encoder Loss:  0.066520594  || Decoder Loss:  0.035061423 Validation Decoder Loss:  0.33626962
Encoder Loss:  0.0662891  || Decoder Loss:  0.03466898 Validation Decoder Loss:  0.33544707
Encoder Loss:  0.06589603  || Decoder Loss:  0.03440195 Validation Decoder Loss:  0.33482957
Encoder Loss:  0.06560823  || Decoder Loss:  0.034214154 Validation Decoder Loss:  0.33435822
Encoder Loss:  0.06532356  || Decoder Loss:  0.034076244 Validation Decoder Loss:  0.33399308
Encoder Loss:  0.06501864  || Decoder Loss:  0.03397023 Validation Decoder Loss:  0.3337128
Encoder Loss:  0.06468213  || Decoder Loss:  0.033885077 Validation Decoder Loss:  0.33348882
Encoder Loss:  0.063902065  || Decoder Loss:  0.03381401 Validation Decoder Loss:  0.3332765
Encoder Loss:  0.057147097  || Decoder Loss:  0.03375477 Validation Decoder Loss:  0.3327421
Encoder Loss:  0.05196086  || Decoder Loss:  0.03373939 Validation Decoder Loss:  0.3324428
Encoder Loss:  0.04869872  || Decoder Loss:  0.0337468 Validation Decoder Loss:  0.3322773
Encoder Loss:  0.04821156  || Decoder Loss:  0.033757646 Validation Decoder Loss:  0.3321987
Encoder Loss:  0.046905972  || Decoder Loss:  0.033775315 Validation Decoder Loss:  0.33208248
Encoder Loss:  0.04793148  || Decoder Loss:  0.033792168 Validation Decoder Loss:  0.33208942
Encoder Loss:  0.04708573  || Decoder Loss:  0.03377925 Validation Decoder Loss:  0.33208692
Encoder Loss:  0.046374932  || Decoder Loss:  0.033798546 Validation Decoder Loss:  0.33200815
Encoder Loss:  0.046411496  || Decoder Loss:  0.03382971 Validation Decoder Loss:  0.3319552
Encoder Loss:  0.045980047  || Decoder Loss:  0.033858858 Validation Decoder Loss:  0.33190244
Encoder Loss:  0.045852717  || Decoder Loss:  0.0338922 Validation Decoder Loss:  0.33186394
Encoder Loss:  0.045762334  || Decoder Loss:  0.033924084 Validation Decoder Loss:  0.3318404
Encoder Loss:  0.045816075  || Decoder Loss:  0.033952896 Validation Decoder Loss:  0.3318326
Model: siamese_net_lr_0.0007066584517373273 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3318326
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 454, 5, 19, 1)     14        
_________________________________________________________________
reshape_102 (Reshape)        (None, 2270, 19, 1)       0         
=================================================================
Total params: 14
Trainable params: 14
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 2270, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 2607, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4489972  || Decoder Loss:  0.04558116 Validation Decoder Loss:  0.3544944
Encoder Loss:  0.28709653  || Decoder Loss:  0.042652797 Validation Decoder Loss:  0.33709118
Encoder Loss:  0.10156966  || Decoder Loss:  0.036445394 Validation Decoder Loss:  0.33339185
Encoder Loss:  0.095418476  || Decoder Loss:  0.035157684 Validation Decoder Loss:  0.33215636
Encoder Loss:  0.09032034  || Decoder Loss:  0.034870535 Validation Decoder Loss:  0.33190036
Encoder Loss:  0.090474226  || Decoder Loss:  0.034809362 Validation Decoder Loss:  0.3318745
Encoder Loss:  0.089978434  || Decoder Loss:  0.034773484 Validation Decoder Loss:  0.3319099
Encoder Loss:  0.08840691  || Decoder Loss:  0.034747563 Validation Decoder Loss:  0.33194017
Encoder Loss:  0.06624463  || Decoder Loss:  0.034772098 Validation Decoder Loss:  0.33182085
Encoder Loss:  0.059901267  || Decoder Loss:  0.03477881 Validation Decoder Loss:  0.33182132
Encoder Loss:  0.058275994  || Decoder Loss:  0.03478006 Validation Decoder Loss:  0.33181554
Encoder Loss:  0.058022324  || Decoder Loss:  0.03476846 Validation Decoder Loss:  0.33182216
Encoder Loss:  0.058207322  || Decoder Loss:  0.034754872 Validation Decoder Loss:  0.3318474
Encoder Loss:  0.058199164  || Decoder Loss:  0.034740355 Validation Decoder Loss:  0.33187562
Encoder Loss:  0.057520356  || Decoder Loss:  0.03472393 Validation Decoder Loss:  0.33190694
Encoder Loss:  0.057969607  || Decoder Loss:  0.03470756 Validation Decoder Loss:  0.33194268
Encoder Loss:  0.05669923  || Decoder Loss:  0.03468895 Validation Decoder Loss:  0.33199605
Encoder Loss:  0.056312375  || Decoder Loss:  0.034657005 Validation Decoder Loss:  0.33206788
Encoder Loss:  0.05644124  || Decoder Loss:  0.03462189 Validation Decoder Loss:  0.3321441
Encoder Loss:  0.056693487  || Decoder Loss:  0.034601122 Validation Decoder Loss:  0.33220118
Encoder Loss:  0.05520144  || Decoder Loss:  0.034571107 Validation Decoder Loss:  0.33231378
Encoder Loss:  0.05409949  || Decoder Loss:  0.034516666 Validation Decoder Loss:  0.33249038
Encoder Loss:  0.055639137  || Decoder Loss:  0.034466185 Validation Decoder Loss:  0.33263195
Encoder Loss:  0.0563383  || Decoder Loss:  0.034436423 Validation Decoder Loss:  0.33270702
Encoder Loss:  0.054701656  || Decoder Loss:  0.034407705 Validation Decoder Loss:  0.33283675
Encoder Loss:  0.055104524  || Decoder Loss:  0.034366727 Validation Decoder Loss:  0.3330476
Encoder Loss:  0.054038882  || Decoder Loss:  0.034305114 Validation Decoder Loss:  0.3332798
Encoder Loss:  0.054971997  || Decoder Loss:  0.034267228 Validation Decoder Loss:  0.33340812
Encoder Loss:  0.053299364  || Decoder Loss:  0.0342115 Validation Decoder Loss:  0.3337204
Encoder Loss:  0.054524366  || Decoder Loss:  0.034149326 Validation Decoder Loss:  0.33397105
Encoder Loss:  0.0541701  || Decoder Loss:  0.03410553 Validation Decoder Loss:  0.3342123
Encoder Loss:  0.054712683  || Decoder Loss:  0.034056224 Validation Decoder Loss:  0.33442318
Encoder Loss:  0.054146428  || Decoder Loss:  0.0340268 Validation Decoder Loss:  0.33463567
Encoder Loss:  0.05434643  || Decoder Loss:  0.033980116 Validation Decoder Loss:  0.33489788
Encoder Loss:  0.05432686  || Decoder Loss:  0.033932194 Validation Decoder Loss:  0.33514315
Encoder Loss:  0.053442847  || Decoder Loss:  0.033886585 Validation Decoder Loss:  0.33540696
Encoder Loss:  0.05356356  || Decoder Loss:  0.03383766 Validation Decoder Loss:  0.33564484
Encoder Loss:  0.053744994  || Decoder Loss:  0.03380195 Validation Decoder Loss:  0.33584034
Encoder Loss:  0.053058762  || Decoder Loss:  0.033764526 Validation Decoder Loss:  0.33604485
Encoder Loss:  0.053057823  || Decoder Loss:  0.033725433 Validation Decoder Loss:  0.33625364
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33625364
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_103 (Conv3D (None, 227, 10, 19, 1)    203       
_________________________________________________________________
reshape_103 (Reshape)        (None, 2270, 19, 1)       0         
=================================================================
Total params: 203
Trainable params: 203
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 2270, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 2607, 19, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3346292  || Decoder Loss:  0.05018364 Validation Decoder Loss:  0.35280246
Encoder Loss:  0.33416814  || Decoder Loss:  0.050817385 Validation Decoder Loss:  0.3527357
Encoder Loss:  0.33343646  || Decoder Loss:  0.051867533 Validation Decoder Loss:  0.352633
Encoder Loss:  0.3321825  || Decoder Loss:  0.053663235 Validation Decoder Loss:  0.3526916
Encoder Loss:  0.32970485  || Decoder Loss:  0.057064634 Validation Decoder Loss:  0.35352695
Encoder Loss:  0.3233025  || Decoder Loss:  0.06507292 Validation Decoder Loss:  0.35883605
Encoder Loss:  0.2929096  || Decoder Loss:  0.09740287 Validation Decoder Loss:  0.4411507
Encoder Loss:  0.15070073  || Decoder Loss:  0.20973022 Validation Decoder Loss:  0.3906634
Encoder Loss:  0.09226849  || Decoder Loss:  0.072116956 Validation Decoder Loss:  0.37419418
Encoder Loss:  0.08583957  || Decoder Loss:  0.056672543 Validation Decoder Loss:  0.3667822
Encoder Loss:  0.083847545  || Decoder Loss:  0.05065984 Validation Decoder Loss:  0.35975766
Encoder Loss:  0.08266459  || Decoder Loss:  0.046622645 Validation Decoder Loss:  0.35360792
Encoder Loss:  0.081651755  || Decoder Loss:  0.04365283 Validation Decoder Loss:  0.34876364
Encoder Loss:  0.0807488  || Decoder Loss:  0.041442584 Validation Decoder Loss:  0.344988
Encoder Loss:  0.07967274  || Decoder Loss:  0.039822295 Validation Decoder Loss:  0.34217536
Encoder Loss:  0.07575726  || Decoder Loss:  0.03862681 Validation Decoder Loss:  0.33992827
Encoder Loss:  0.05088985  || Decoder Loss:  0.037686493 Validation Decoder Loss:  0.33782104
Encoder Loss:  0.050182745  || Decoder Loss:  0.03729011 Validation Decoder Loss:  0.33673432
Encoder Loss:  0.04929308  || Decoder Loss:  0.037095554 Validation Decoder Loss:  0.33574343
Encoder Loss:  0.04887126  || Decoder Loss:  0.036828622 Validation Decoder Loss:  0.33490792
Encoder Loss:  0.048720237  || Decoder Loss:  0.036513016 Validation Decoder Loss:  0.33429298
Encoder Loss:  0.04853593  || Decoder Loss:  0.03624333 Validation Decoder Loss:  0.333825
Encoder Loss:  0.048417207  || Decoder Loss:  0.036023416 Validation Decoder Loss:  0.33346832
Encoder Loss:  0.048388656  || Decoder Loss:  0.035850897 Validation Decoder Loss:  0.33319542
Encoder Loss:  0.048293244  || Decoder Loss:  0.03569345 Validation Decoder Loss:  0.3329841
Encoder Loss:  0.048180047  || Decoder Loss:  0.035555575 Validation Decoder Loss:  0.33282292
Encoder Loss:  0.048086632  || Decoder Loss:  0.03543337 Validation Decoder Loss:  0.3327
Encoder Loss:  0.04799369  || Decoder Loss:  0.035322387 Validation Decoder Loss:  0.3326086
Encoder Loss:  0.047923766  || Decoder Loss:  0.03522158 Validation Decoder Loss:  0.33254117
Encoder Loss:  0.047830425  || Decoder Loss:  0.035129067 Validation Decoder Loss:  0.3324929
Encoder Loss:  0.047756992  || Decoder Loss:  0.035042617 Validation Decoder Loss:  0.3324573
Encoder Loss:  0.047673594  || Decoder Loss:  0.034963455 Validation Decoder Loss:  0.33243564
Encoder Loss:  0.047612365  || Decoder Loss:  0.034888603 Validation Decoder Loss:  0.33242327
Encoder Loss:  0.04750115  || Decoder Loss:  0.03481912 Validation Decoder Loss:  0.3324156
Encoder Loss:  0.047435254  || Decoder Loss:  0.034754187 Validation Decoder Loss:  0.33241418
Encoder Loss:  0.047376394  || Decoder Loss:  0.03469361 Validation Decoder Loss:  0.3324172
Encoder Loss:  0.047317423  || Decoder Loss:  0.034636356 Validation Decoder Loss:  0.3324235
Encoder Loss:  0.04724709  || Decoder Loss:  0.03458254 Validation Decoder Loss:  0.33243042
Encoder Loss:  0.047197595  || Decoder Loss:  0.034532003 Validation Decoder Loss:  0.3324389
Encoder Loss:  0.04715686  || Decoder Loss:  0.034484494 Validation Decoder Loss:  0.33244887
Model: siamese_net_lr_0.0007041951202625233 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33244887
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 207, 10, 19, 1)    37        
_________________________________________________________________
reshape_104 (Reshape)        (None, 2070, 19, 1)       0         
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 2070, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 2607, 19, 1)       539       
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184803
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.05781961 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.0578196 Validation Decoder Loss:  0.361848
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184806
Encoder Loss:  0.44955486  || Decoder Loss:  0.057819605 Validation Decoder Loss:  0.36184803
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.361848
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 514, 5, 19, 1)     74        
_________________________________________________________________
reshape_105 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 2570, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [3.79550519e-05 4.50432410e-01 9.37811468e-01 6.19643702e-01
 1.83734935e-01 1.60000000e+01 2.57000000e+03]
Optimized Validation Decoder Loss: 0.31451117992401123











Optimizing at level  2
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 400, 5, 19, 1)     23        
_________________________________________________________________
dropout_318 (Dropout)        (None, 400, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 514, 5, 19, 1)     116       
_________________________________________________________________
reshape_106 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_320 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_322 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20043816  || Decoder Loss:  0.06215339 Validation Decoder Loss:  0.36298692
Encoder Loss:  0.20064464  || Decoder Loss:  0.06334319 Validation Decoder Loss:  0.362552
Encoder Loss:  0.20077582  || Decoder Loss:  0.0644974 Validation Decoder Loss:  0.36151263
Encoder Loss:  0.19489063  || Decoder Loss:  0.055991363 Validation Decoder Loss:  0.32667074
Encoder Loss:  0.18158796  || Decoder Loss:  0.03567352 Validation Decoder Loss:  0.32595587
Encoder Loss:  0.1802364  || Decoder Loss:  0.035469424 Validation Decoder Loss:  0.32698128
Encoder Loss:  0.17787951  || Decoder Loss:  0.03532006 Validation Decoder Loss:  0.32870945
Encoder Loss:  0.14952423  || Decoder Loss:  0.03522353 Validation Decoder Loss:  0.32872635
Encoder Loss:  0.04179857  || Decoder Loss:  0.035127252 Validation Decoder Loss:  0.32884216
Encoder Loss:  0.04084032  || Decoder Loss:  0.035038743 Validation Decoder Loss:  0.32895774
Encoder Loss:  0.04079635  || Decoder Loss:  0.03497068 Validation Decoder Loss:  0.3290682
Encoder Loss:  0.04077312  || Decoder Loss:  0.034927115 Validation Decoder Loss:  0.32918948
Encoder Loss:  0.040752858  || Decoder Loss:  0.034900136 Validation Decoder Loss:  0.32932788
Encoder Loss:  0.040740434  || Decoder Loss:  0.034880728 Validation Decoder Loss:  0.3294808
Encoder Loss:  0.040730495  || Decoder Loss:  0.03486444 Validation Decoder Loss:  0.32964516
Encoder Loss:  0.040721353  || Decoder Loss:  0.0348498 Validation Decoder Loss:  0.3298181
Encoder Loss:  0.040712915  || Decoder Loss:  0.034836393 Validation Decoder Loss:  0.32999828
Encoder Loss:  0.04070524  || Decoder Loss:  0.03482395 Validation Decoder Loss:  0.33018357
Encoder Loss:  0.040698107  || Decoder Loss:  0.03481235 Validation Decoder Loss:  0.33037263
Encoder Loss:  0.040691372  || Decoder Loss:  0.034801427 Validation Decoder Loss:  0.33056468
Encoder Loss:  0.040684987  || Decoder Loss:  0.034791056 Validation Decoder Loss:  0.33075884
Encoder Loss:  0.040678915  || Decoder Loss:  0.03478116 Validation Decoder Loss:  0.33095476
Encoder Loss:  0.04067312  || Decoder Loss:  0.03477171 Validation Decoder Loss:  0.33115244
Encoder Loss:  0.04066762  || Decoder Loss:  0.03476271 Validation Decoder Loss:  0.33135247
Encoder Loss:  0.040662363  || Decoder Loss:  0.034754187 Validation Decoder Loss:  0.33155525
Encoder Loss:  0.040657476  || Decoder Loss:  0.034746155 Validation Decoder Loss:  0.3317607
Encoder Loss:  0.040652882  || Decoder Loss:  0.034738723 Validation Decoder Loss:  0.33196774
Encoder Loss:  0.04064872  || Decoder Loss:  0.034731913 Validation Decoder Loss:  0.33217397
Encoder Loss:  0.04064494  || Decoder Loss:  0.034725744 Validation Decoder Loss:  0.33237606
Encoder Loss:  0.04064156  || Decoder Loss:  0.034720227 Validation Decoder Loss:  0.33257028
Encoder Loss:  0.04063857  || Decoder Loss:  0.03471536 Validation Decoder Loss:  0.33275273
Encoder Loss:  0.04063596  || Decoder Loss:  0.034711078 Validation Decoder Loss:  0.33291954
Encoder Loss:  0.040633656  || Decoder Loss:  0.03470733 Validation Decoder Loss:  0.3330677
Encoder Loss:  0.04063164  || Decoder Loss:  0.034704044 Validation Decoder Loss:  0.3331961
Encoder Loss:  0.040629864  || Decoder Loss:  0.034701157 Validation Decoder Loss:  0.33330554
Encoder Loss:  0.040628303  || Decoder Loss:  0.034698587 Validation Decoder Loss:  0.33339754
Encoder Loss:  0.040626913  || Decoder Loss:  0.03469633 Validation Decoder Loss:  0.33347464
Encoder Loss:  0.04062567  || Decoder Loss:  0.034694325 Validation Decoder Loss:  0.3335393
Encoder Loss:  0.040624585  || Decoder Loss:  0.03469253 Validation Decoder Loss:  0.33359423
Encoder Loss:  0.04062359  || Decoder Loss:  0.034690928 Validation Decoder Loss:  0.3336406
Model: siamese_net_lr_0.0005686948544575208 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33364064
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 182, 5, 19, 1)     120       
_________________________________________________________________
dropout_324 (Dropout)        (None, 182, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 514, 5, 19, 1)     334       
_________________________________________________________________
reshape_107 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_326 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_328 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35994193  || Decoder Loss:  0.08224836 Validation Decoder Loss:  0.36249015
Encoder Loss:  0.35977823  || Decoder Loss:  0.08249295 Validation Decoder Loss:  0.36261183
Encoder Loss:  0.3595836  || Decoder Loss:  0.08278334 Validation Decoder Loss:  0.36274594
Encoder Loss:  0.35937783  || Decoder Loss:  0.08308998 Validation Decoder Loss:  0.36288452
Encoder Loss:  0.35916838  || Decoder Loss:  0.08340189 Validation Decoder Loss:  0.36302507
Encoder Loss:  0.3589573  || Decoder Loss:  0.08371596 Validation Decoder Loss:  0.36316675
Encoder Loss:  0.3587451  || Decoder Loss:  0.08403134 Validation Decoder Loss:  0.36330962
Encoder Loss:  0.358532  || Decoder Loss:  0.08434786 Validation Decoder Loss:  0.36345375
Encoder Loss:  0.35831803  || Decoder Loss:  0.084665455 Validation Decoder Loss:  0.3635993
Encoder Loss:  0.35810316  || Decoder Loss:  0.084984116 Validation Decoder Loss:  0.3637463
Encoder Loss:  0.35788733  || Decoder Loss:  0.08530389 Validation Decoder Loss:  0.36389476
Encoder Loss:  0.35767058  || Decoder Loss:  0.08562474 Validation Decoder Loss:  0.3640447
Encoder Loss:  0.35745287  || Decoder Loss:  0.08594671 Validation Decoder Loss:  0.36419615
Encoder Loss:  0.3572342  || Decoder Loss:  0.0862698 Validation Decoder Loss:  0.36434913
Encoder Loss:  0.3570146  || Decoder Loss:  0.08659402 Validation Decoder Loss:  0.36450362
Encoder Loss:  0.356794  || Decoder Loss:  0.08691939 Validation Decoder Loss:  0.3646597
Encoder Loss:  0.35657236  || Decoder Loss:  0.08724593 Validation Decoder Loss:  0.36481732
Encoder Loss:  0.35634974  || Decoder Loss:  0.08757363 Validation Decoder Loss:  0.3649766
Encoder Loss:  0.3561261  || Decoder Loss:  0.0879025 Validation Decoder Loss:  0.36513758
Encoder Loss:  0.35590136  || Decoder Loss:  0.088232584 Validation Decoder Loss:  0.36530018
Encoder Loss:  0.35567567  || Decoder Loss:  0.08856388 Validation Decoder Loss:  0.36546445
Encoder Loss:  0.35544887  || Decoder Loss:  0.08889639 Validation Decoder Loss:  0.36563045
Encoder Loss:  0.3552209  || Decoder Loss:  0.08923013 Validation Decoder Loss:  0.36579818
Encoder Loss:  0.35499188  || Decoder Loss:  0.08956512 Validation Decoder Loss:  0.36596763
Encoder Loss:  0.35476172  || Decoder Loss:  0.08990136 Validation Decoder Loss:  0.36613888
Encoder Loss:  0.35453048  || Decoder Loss:  0.09023885 Validation Decoder Loss:  0.36631197
Encoder Loss:  0.35429806  || Decoder Loss:  0.09057763 Validation Decoder Loss:  0.36648685
Encoder Loss:  0.35406452  || Decoder Loss:  0.09091768 Validation Decoder Loss:  0.36666358
Encoder Loss:  0.35382974  || Decoder Loss:  0.09125904 Validation Decoder Loss:  0.3668422
Encoder Loss:  0.35359383  || Decoder Loss:  0.0916017 Validation Decoder Loss:  0.36702275
Encoder Loss:  0.35335666  || Decoder Loss:  0.09194568 Validation Decoder Loss:  0.36720523
Encoder Loss:  0.35311827  || Decoder Loss:  0.09229099 Validation Decoder Loss:  0.36738974
Encoder Loss:  0.3528787  || Decoder Loss:  0.09263764 Validation Decoder Loss:  0.36757618
Encoder Loss:  0.35263777  || Decoder Loss:  0.09298563 Validation Decoder Loss:  0.3677647
Encoder Loss:  0.3523956  || Decoder Loss:  0.09333499 Validation Decoder Loss:  0.36795527
Encoder Loss:  0.3521522  || Decoder Loss:  0.093685694 Validation Decoder Loss:  0.3681479
Encoder Loss:  0.35190743  || Decoder Loss:  0.09403777 Validation Decoder Loss:  0.36834267
Encoder Loss:  0.35166138  || Decoder Loss:  0.094391264 Validation Decoder Loss:  0.36853948
Encoder Loss:  0.351414  || Decoder Loss:  0.09474612 Validation Decoder Loss:  0.36873847
Encoder Loss:  0.35116518  || Decoder Loss:  0.09510239 Validation Decoder Loss:  0.36893958
Model: siamese_net_lr_0.00012675834983953002 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36893958
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 188, 5, 19, 1)     126       
_________________________________________________________________
dropout_330 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 514, 5, 19, 1)     328       
_________________________________________________________________
reshape_108 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_328"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_332 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_334 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09374455  || Decoder Loss:  0.08567116 Validation Decoder Loss:  0.33129898
Encoder Loss:  0.038123436  || Decoder Loss:  0.0354045 Validation Decoder Loss:  0.33141506
Encoder Loss:  0.03652168  || Decoder Loss:  0.035205934 Validation Decoder Loss:  0.33087814
Encoder Loss:  0.03592384  || Decoder Loss:  0.035113577 Validation Decoder Loss:  0.3309164
Encoder Loss:  0.035547134  || Decoder Loss:  0.035069462 Validation Decoder Loss:  0.3309521
Encoder Loss:  0.035522502  || Decoder Loss:  0.035053488 Validation Decoder Loss:  0.3309638
Encoder Loss:  0.0354931  || Decoder Loss:  0.03504168 Validation Decoder Loss:  0.33096382
Encoder Loss:  0.03545253  || Decoder Loss:  0.035030626 Validation Decoder Loss:  0.3309623
Encoder Loss:  0.035439163  || Decoder Loss:  0.0350199 Validation Decoder Loss:  0.33097064
Encoder Loss:  0.035426747  || Decoder Loss:  0.035007954 Validation Decoder Loss:  0.33098683
Encoder Loss:  0.035411857  || Decoder Loss:  0.03499346 Validation Decoder Loss:  0.33100894
Encoder Loss:  0.035395227  || Decoder Loss:  0.034976624 Validation Decoder Loss:  0.33104205
Encoder Loss:  0.035380818  || Decoder Loss:  0.03496206 Validation Decoder Loss:  0.33107042
Encoder Loss:  0.035370387  || Decoder Loss:  0.034952193 Validation Decoder Loss:  0.33109596
Encoder Loss:  0.035364293  || Decoder Loss:  0.034945834 Validation Decoder Loss:  0.3311296
Encoder Loss:  0.035358682  || Decoder Loss:  0.03494054 Validation Decoder Loss:  0.3311709
Encoder Loss:  0.035354387  || Decoder Loss:  0.03493599 Validation Decoder Loss:  0.3312075
Encoder Loss:  0.035350215  || Decoder Loss:  0.034932356 Validation Decoder Loss:  0.3312359
Encoder Loss:  0.03534741  || Decoder Loss:  0.03492974 Validation Decoder Loss:  0.33125603
Encoder Loss:  0.035345428  || Decoder Loss:  0.03492752 Validation Decoder Loss:  0.3312732
Encoder Loss:  0.0353436  || Decoder Loss:  0.03492563 Validation Decoder Loss:  0.331292
Encoder Loss:  0.03534189  || Decoder Loss:  0.03492374 Validation Decoder Loss:  0.33130872
Encoder Loss:  0.035339937  || Decoder Loss:  0.034921955 Validation Decoder Loss:  0.33132702
Encoder Loss:  0.03533832  || Decoder Loss:  0.034920312 Validation Decoder Loss:  0.33134264
Encoder Loss:  0.035336893  || Decoder Loss:  0.034918815 Validation Decoder Loss:  0.3313576
Encoder Loss:  0.035335507  || Decoder Loss:  0.03491728 Validation Decoder Loss:  0.3313721
Encoder Loss:  0.03533427  || Decoder Loss:  0.034916088 Validation Decoder Loss:  0.33138627
Encoder Loss:  0.035333168  || Decoder Loss:  0.034914896 Validation Decoder Loss:  0.33139867
Encoder Loss:  0.035331886  || Decoder Loss:  0.03491369 Validation Decoder Loss:  0.33141226
Encoder Loss:  0.03533114  || Decoder Loss:  0.034912847 Validation Decoder Loss:  0.33142152
Encoder Loss:  0.03532995  || Decoder Loss:  0.034911692 Validation Decoder Loss:  0.33143258
Encoder Loss:  0.03532925  || Decoder Loss:  0.034910914 Validation Decoder Loss:  0.33144373
Encoder Loss:  0.035328317  || Decoder Loss:  0.034909945 Validation Decoder Loss:  0.33145273
Encoder Loss:  0.035327453  || Decoder Loss:  0.034908902 Validation Decoder Loss:  0.33146688
Encoder Loss:  0.035326272  || Decoder Loss:  0.03490798 Validation Decoder Loss:  0.33147603
Encoder Loss:  0.03532497  || Decoder Loss:  0.03490662 Validation Decoder Loss:  0.33148623
Encoder Loss:  0.03532424  || Decoder Loss:  0.03490581 Validation Decoder Loss:  0.33149815
Encoder Loss:  0.035323586  || Decoder Loss:  0.0349051 Validation Decoder Loss:  0.33150518
Encoder Loss:  0.03532243  || Decoder Loss:  0.034903944 Validation Decoder Loss:  0.33151454
Encoder Loss:  0.035321806  || Decoder Loss:  0.034903232 Validation Decoder Loss:  0.33152357
Model: siamese_net_lr_0.000632064637783296 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33152354
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_336 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_109 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_338 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_340 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17809308  || Decoder Loss:  0.05476754 Validation Decoder Loss:  0.33211076
Encoder Loss:  0.049533386  || Decoder Loss:  0.035418846 Validation Decoder Loss:  0.33216634
Encoder Loss:  0.047469206  || Decoder Loss:  0.035409547 Validation Decoder Loss:  0.33208007
Encoder Loss:  0.04683414  || Decoder Loss:  0.035403866 Validation Decoder Loss:  0.33208305
Encoder Loss:  0.04681868  || Decoder Loss:  0.035394467 Validation Decoder Loss:  0.3320698
Encoder Loss:  0.04681015  || Decoder Loss:  0.035382174 Validation Decoder Loss:  0.33213332
Encoder Loss:  0.046800274  || Decoder Loss:  0.03536407 Validation Decoder Loss:  0.332098
Encoder Loss:  0.04679773  || Decoder Loss:  0.035345994 Validation Decoder Loss:  0.3322618
Encoder Loss:  0.04678415  || Decoder Loss:  0.035325956 Validation Decoder Loss:  0.33233505
Encoder Loss:  0.046770062  || Decoder Loss:  0.03530592 Validation Decoder Loss:  0.33230984
Encoder Loss:  0.046754733  || Decoder Loss:  0.035291005 Validation Decoder Loss:  0.33233893
Encoder Loss:  0.04674933  || Decoder Loss:  0.03527955 Validation Decoder Loss:  0.3324678
Encoder Loss:  0.046747502  || Decoder Loss:  0.03526857 Validation Decoder Loss:  0.33256552
Encoder Loss:  0.046746947  || Decoder Loss:  0.035264675 Validation Decoder Loss:  0.33275083
Encoder Loss:  0.046746988  || Decoder Loss:  0.035262477 Validation Decoder Loss:  0.33256713
Encoder Loss:  0.046748027  || Decoder Loss:  0.035265893 Validation Decoder Loss:  0.33274716
Encoder Loss:  0.046746954  || Decoder Loss:  0.03526855 Validation Decoder Loss:  0.3327078
Encoder Loss:  0.046747718  || Decoder Loss:  0.0352759 Validation Decoder Loss:  0.33275715
Encoder Loss:  0.046749484  || Decoder Loss:  0.035284087 Validation Decoder Loss:  0.3329003
Encoder Loss:  0.046750225  || Decoder Loss:  0.035290517 Validation Decoder Loss:  0.33305266
Encoder Loss:  0.04675123  || Decoder Loss:  0.03530611 Validation Decoder Loss:  0.33303538
Encoder Loss:  0.046752434  || Decoder Loss:  0.035310067 Validation Decoder Loss:  0.33309117
Encoder Loss:  0.046751827  || Decoder Loss:  0.035310987 Validation Decoder Loss:  0.33324605
Encoder Loss:  0.046752702  || Decoder Loss:  0.03531178 Validation Decoder Loss:  0.33317465
Encoder Loss:  0.046753123  || Decoder Loss:  0.03531418 Validation Decoder Loss:  0.33316
Encoder Loss:  0.046752006  || Decoder Loss:  0.0353152 Validation Decoder Loss:  0.33311364
Encoder Loss:  0.046912063  || Decoder Loss:  0.03527973 Validation Decoder Loss:  0.33284736
Encoder Loss:  0.046744365  || Decoder Loss:  0.035276696 Validation Decoder Loss:  0.33288398
Encoder Loss:  0.046744075  || Decoder Loss:  0.035278346 Validation Decoder Loss:  0.33295095
Encoder Loss:  0.04674515  || Decoder Loss:  0.03528363 Validation Decoder Loss:  0.33304784
Encoder Loss:  0.046746682  || Decoder Loss:  0.035291757 Validation Decoder Loss:  0.3331568
Encoder Loss:  0.04674802  || Decoder Loss:  0.035299033 Validation Decoder Loss:  0.3332349
Encoder Loss:  0.04674922  || Decoder Loss:  0.035304446 Validation Decoder Loss:  0.33326876
Encoder Loss:  0.046749603  || Decoder Loss:  0.03530673 Validation Decoder Loss:  0.33307388
Encoder Loss:  0.04691931  || Decoder Loss:  0.035274856 Validation Decoder Loss:  0.33286294
Encoder Loss:  0.046742927  || Decoder Loss:  0.03527257 Validation Decoder Loss:  0.33289844
Encoder Loss:  0.046742905  || Decoder Loss:  0.035273775 Validation Decoder Loss:  0.3329534
Encoder Loss:  0.04674385  || Decoder Loss:  0.03527804 Validation Decoder Loss:  0.33303845
Encoder Loss:  0.046745215  || Decoder Loss:  0.035285097 Validation Decoder Loss:  0.33314294
Encoder Loss:  0.04674683  || Decoder Loss:  0.035293423 Validation Decoder Loss:  0.33323544
Model: siamese_net_lr_0.000879057008670549 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33323544
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_342 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 514, 5, 19, 1)     190       
_________________________________________________________________
reshape_110 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_344 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_346 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3289839  || Decoder Loss:  0.07566831 Validation Decoder Loss:  0.35377622
Encoder Loss:  0.32838288  || Decoder Loss:  0.07685038 Validation Decoder Loss:  0.35420674
Encoder Loss:  0.32770112  || Decoder Loss:  0.07795929 Validation Decoder Loss:  0.3544271
Encoder Loss:  0.32671124  || Decoder Loss:  0.078905985 Validation Decoder Loss:  0.3543604
Encoder Loss:  0.3251566  || Decoder Loss:  0.07971742 Validation Decoder Loss:  0.35402024
Encoder Loss:  0.32309517  || Decoder Loss:  0.08042713 Validation Decoder Loss:  0.3534962
Encoder Loss:  0.32069072  || Decoder Loss:  0.081025906 Validation Decoder Loss:  0.3528186
Encoder Loss:  0.3180609  || Decoder Loss:  0.08148386 Validation Decoder Loss:  0.35191846
Encoder Loss:  0.3152219  || Decoder Loss:  0.08163012 Validation Decoder Loss:  0.35043618
Encoder Loss:  0.31177932  || Decoder Loss:  0.07989362 Validation Decoder Loss:  0.34291616
Encoder Loss:  0.30029362  || Decoder Loss:  0.045366496 Validation Decoder Loss:  0.32440364
Encoder Loss:  0.2942137  || Decoder Loss:  0.035321914 Validation Decoder Loss:  0.3270544
Encoder Loss:  0.2899371  || Decoder Loss:  0.035210896 Validation Decoder Loss:  0.32730728
Encoder Loss:  0.28508407  || Decoder Loss:  0.03518717 Validation Decoder Loss:  0.32736155
Encoder Loss:  0.27968046  || Decoder Loss:  0.035177473 Validation Decoder Loss:  0.32740787
Encoder Loss:  0.27374047  || Decoder Loss:  0.035172563 Validation Decoder Loss:  0.3274469
Encoder Loss:  0.26723123  || Decoder Loss:  0.035169706 Validation Decoder Loss:  0.327478
Encoder Loss:  0.26013458  || Decoder Loss:  0.03516791 Validation Decoder Loss:  0.3275012
Encoder Loss:  0.25251442  || Decoder Loss:  0.035166852 Validation Decoder Loss:  0.32751638
Encoder Loss:  0.24448723  || Decoder Loss:  0.03516659 Validation Decoder Loss:  0.3275227
Encoder Loss:  0.23612347  || Decoder Loss:  0.03516733 Validation Decoder Loss:  0.32752082
Encoder Loss:  0.22737549  || Decoder Loss:  0.03516927 Validation Decoder Loss:  0.32751423
Encoder Loss:  0.21801709  || Decoder Loss:  0.035172448 Validation Decoder Loss:  0.32750946
Encoder Loss:  0.20739439  || Decoder Loss:  0.035176817 Validation Decoder Loss:  0.3275131
Encoder Loss:  0.19226748  || Decoder Loss:  0.035182547 Validation Decoder Loss:  0.32752934
Encoder Loss:  0.13992739  || Decoder Loss:  0.035189446 Validation Decoder Loss:  0.32754976
Encoder Loss:  0.05471386  || Decoder Loss:  0.03519273 Validation Decoder Loss:  0.32754618
Encoder Loss:  0.050963286  || Decoder Loss:  0.035190962 Validation Decoder Loss:  0.3275429
Encoder Loss:  0.05041362  || Decoder Loss:  0.035189558 Validation Decoder Loss:  0.327541
Encoder Loss:  0.049856577  || Decoder Loss:  0.03518884 Validation Decoder Loss:  0.32754046
Encoder Loss:  0.04928875  || Decoder Loss:  0.035188675 Validation Decoder Loss:  0.32754073
Encoder Loss:  0.048707686  || Decoder Loss:  0.035188884 Validation Decoder Loss:  0.32754177
Encoder Loss:  0.048113413  || Decoder Loss:  0.03518939 Validation Decoder Loss:  0.32754344
Encoder Loss:  0.0475613  || Decoder Loss:  0.035189997 Validation Decoder Loss:  0.32754597
Encoder Loss:  0.047212467  || Decoder Loss:  0.035190422 Validation Decoder Loss:  0.32754946
Encoder Loss:  0.047077123  || Decoder Loss:  0.035190407 Validation Decoder Loss:  0.3275534
Encoder Loss:  0.04703591  || Decoder Loss:  0.0351901 Validation Decoder Loss:  0.32755822
Encoder Loss:  0.04702582  || Decoder Loss:  0.035189454 Validation Decoder Loss:  0.32756317
Encoder Loss:  0.047036048  || Decoder Loss:  0.03518873 Validation Decoder Loss:  0.32756895
Encoder Loss:  0.04702374  || Decoder Loss:  0.035188086 Validation Decoder Loss:  0.32757455
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.0003764590259788075 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32757455
Started Optimization Process
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_348 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_111 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_340"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_350 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_352 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13048661  || Decoder Loss:  0.094604455 Validation Decoder Loss:  0.37032357
Encoder Loss:  0.13444799  || Decoder Loss:  0.09981255 Validation Decoder Loss:  0.37329924
Encoder Loss:  0.13850139  || Decoder Loss:  0.10532714 Validation Decoder Loss:  0.37331897
Encoder Loss:  0.085156776  || Decoder Loss:  0.046313357 Validation Decoder Loss:  0.3304354
Encoder Loss:  0.059119415  || Decoder Loss:  0.035394732 Validation Decoder Loss:  0.33160114
Encoder Loss:  0.042866997  || Decoder Loss:  0.03544346 Validation Decoder Loss:  0.33163083
Encoder Loss:  0.042745978  || Decoder Loss:  0.035443645 Validation Decoder Loss:  0.3316493
Encoder Loss:  0.042638455  || Decoder Loss:  0.035443757 Validation Decoder Loss:  0.33167267
Encoder Loss:  0.042480227  || Decoder Loss:  0.035443712 Validation Decoder Loss:  0.33170283
Encoder Loss:  0.04231003  || Decoder Loss:  0.035443354 Validation Decoder Loss:  0.33173963
Encoder Loss:  0.042087484  || Decoder Loss:  0.035442714 Validation Decoder Loss:  0.33178443
Encoder Loss:  0.04178807  || Decoder Loss:  0.0354417 Validation Decoder Loss:  0.3318386
Encoder Loss:  0.041344646  || Decoder Loss:  0.035440143 Validation Decoder Loss:  0.33190027
Encoder Loss:  0.04061879  || Decoder Loss:  0.03543787 Validation Decoder Loss:  0.33196217
Encoder Loss:  0.039151654  || Decoder Loss:  0.035434317 Validation Decoder Loss:  0.33201987
Encoder Loss:  0.03748697  || Decoder Loss:  0.035428334 Validation Decoder Loss:  0.33209217
Encoder Loss:  0.037420046  || Decoder Loss:  0.035424978 Validation Decoder Loss:  0.33211392
Encoder Loss:  0.037415344  || Decoder Loss:  0.03542215 Validation Decoder Loss:  0.33213452
Encoder Loss:  0.037410997  || Decoder Loss:  0.03541906 Validation Decoder Loss:  0.3321589
Encoder Loss:  0.037406866  || Decoder Loss:  0.035415582 Validation Decoder Loss:  0.33218837
Encoder Loss:  0.037402015  || Decoder Loss:  0.03541159 Validation Decoder Loss:  0.3322249
Encoder Loss:  0.037396148  || Decoder Loss:  0.03540698 Validation Decoder Loss:  0.33227032
Encoder Loss:  0.037389692  || Decoder Loss:  0.03540172 Validation Decoder Loss:  0.3323254
Encoder Loss:  0.037383195  || Decoder Loss:  0.03539595 Validation Decoder Loss:  0.3323889
Encoder Loss:  0.03737502  || Decoder Loss:  0.03538989 Validation Decoder Loss:  0.33245686
Encoder Loss:  0.03736591  || Decoder Loss:  0.035383917 Validation Decoder Loss:  0.3325221
Encoder Loss:  0.037352532  || Decoder Loss:  0.035378266 Validation Decoder Loss:  0.33257926
Encoder Loss:  0.037238646  || Decoder Loss:  0.035373293 Validation Decoder Loss:  0.3326211
Encoder Loss:  0.037144538  || Decoder Loss:  0.035369433 Validation Decoder Loss:  0.33265057
Encoder Loss:  0.03713878  || Decoder Loss:  0.035365455 Validation Decoder Loss:  0.33267263
Encoder Loss:  0.037133526  || Decoder Loss:  0.03536148 Validation Decoder Loss:  0.33269012
Encoder Loss:  0.037130427  || Decoder Loss:  0.03535768 Validation Decoder Loss:  0.3327044
Encoder Loss:  0.037126873  || Decoder Loss:  0.03535394 Validation Decoder Loss:  0.33271718
Encoder Loss:  0.03712288  || Decoder Loss:  0.03535027 Validation Decoder Loss:  0.33272892
Encoder Loss:  0.03711959  || Decoder Loss:  0.03534665 Validation Decoder Loss:  0.33273983
Encoder Loss:  0.037117053  || Decoder Loss:  0.03534304 Validation Decoder Loss:  0.33275014
Encoder Loss:  0.03711327  || Decoder Loss:  0.03533941 Validation Decoder Loss:  0.3327596
Encoder Loss:  0.03710948  || Decoder Loss:  0.035335705 Validation Decoder Loss:  0.33276844
Encoder Loss:  0.03710592  || Decoder Loss:  0.03533185 Validation Decoder Loss:  0.33277646
Encoder Loss:  0.03710279  || Decoder Loss:  0.035327837 Validation Decoder Loss:  0.33278275
Model: siamese_net_lr_0.0003051246584498132 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33278275
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 286, 5, 19, 1)     35        
_________________________________________________________________
dropout_354 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_112 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_344"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_356 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_358 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3178261  || Decoder Loss:  0.09032211 Validation Decoder Loss:  0.3664393
Encoder Loss:  0.3170931  || Decoder Loss:  0.09206384 Validation Decoder Loss:  0.36740172
Encoder Loss:  0.31635574  || Decoder Loss:  0.09379868 Validation Decoder Loss:  0.36824465
Encoder Loss:  0.3156079  || Decoder Loss:  0.0955346 Validation Decoder Loss:  0.36897725
Encoder Loss:  0.31483987  || Decoder Loss:  0.09728408 Validation Decoder Loss:  0.3696156
Encoder Loss:  0.31403968  || Decoder Loss:  0.099047735 Validation Decoder Loss:  0.37015983
Encoder Loss:  0.31318593  || Decoder Loss:  0.100785166 Validation Decoder Loss:  0.37059957
Encoder Loss:  0.31215328  || Decoder Loss:  0.102051094 Validation Decoder Loss:  0.36983493
Encoder Loss:  0.29889083  || Decoder Loss:  0.055799633 Validation Decoder Loss:  0.33584893
Encoder Loss:  0.29210937  || Decoder Loss:  0.03521455 Validation Decoder Loss:  0.3352579
Encoder Loss:  0.29048836  || Decoder Loss:  0.035210982 Validation Decoder Loss:  0.3350113
Encoder Loss:  0.288737  || Decoder Loss:  0.03521299 Validation Decoder Loss:  0.3347131
Encoder Loss:  0.28681892  || Decoder Loss:  0.0352181 Validation Decoder Loss:  0.33436358
Encoder Loss:  0.28468156  || Decoder Loss:  0.03522568 Validation Decoder Loss:  0.33396637
Encoder Loss:  0.28224602  || Decoder Loss:  0.035235662 Validation Decoder Loss:  0.3335305
Encoder Loss:  0.27938402  || Decoder Loss:  0.03524801 Validation Decoder Loss:  0.33307007
Encoder Loss:  0.27587247  || Decoder Loss:  0.035262633 Validation Decoder Loss:  0.3325976
Encoder Loss:  0.27125084  || Decoder Loss:  0.03527961 Validation Decoder Loss:  0.33212152
Encoder Loss:  0.2641649  || Decoder Loss:  0.03529984 Validation Decoder Loss:  0.3316598
Encoder Loss:  0.24530573  || Decoder Loss:  0.035325434 Validation Decoder Loss:  0.33125877
Encoder Loss:  0.10456459  || Decoder Loss:  0.03535106 Validation Decoder Loss:  0.33112606
Encoder Loss:  0.047107205  || Decoder Loss:  0.035353757 Validation Decoder Loss:  0.33116913
Encoder Loss:  0.04657781  || Decoder Loss:  0.035352025 Validation Decoder Loss:  0.33121714
Encoder Loss:  0.046509452  || Decoder Loss:  0.03535023 Validation Decoder Loss:  0.33126342
Encoder Loss:  0.046370503  || Decoder Loss:  0.03534836 Validation Decoder Loss:  0.33130878
Encoder Loss:  0.046374667  || Decoder Loss:  0.035346456 Validation Decoder Loss:  0.33135253
Encoder Loss:  0.046387244  || Decoder Loss:  0.03534452 Validation Decoder Loss:  0.33139646
Encoder Loss:  0.046420664  || Decoder Loss:  0.03534261 Validation Decoder Loss:  0.33144107
Encoder Loss:  0.046452176  || Decoder Loss:  0.035340704 Validation Decoder Loss:  0.33148614
Encoder Loss:  0.04640121  || Decoder Loss:  0.035338767 Validation Decoder Loss:  0.33153182
Encoder Loss:  0.04643224  || Decoder Loss:  0.035336815 Validation Decoder Loss:  0.3315754
Encoder Loss:  0.046366166  || Decoder Loss:  0.035334833 Validation Decoder Loss:  0.3316176
Encoder Loss:  0.046397023  || Decoder Loss:  0.035332844 Validation Decoder Loss:  0.33165863
Encoder Loss:  0.046330962  || Decoder Loss:  0.035330817 Validation Decoder Loss:  0.33170152
Encoder Loss:  0.046365544  || Decoder Loss:  0.035328746 Validation Decoder Loss:  0.3317464
Encoder Loss:  0.046389703  || Decoder Loss:  0.0353267 Validation Decoder Loss:  0.33178884
Encoder Loss:  0.04633289  || Decoder Loss:  0.035324637 Validation Decoder Loss:  0.33182722
Encoder Loss:  0.046354733  || Decoder Loss:  0.035322502 Validation Decoder Loss:  0.33186096
Encoder Loss:  0.04635261  || Decoder Loss:  0.03532033 Validation Decoder Loss:  0.3318929
Encoder Loss:  0.04634376  || Decoder Loss:  0.035318166 Validation Decoder Loss:  0.33192652
Model: siamese_net_lr_0.0002556831427496413 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33192652
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_360 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 514, 5, 19, 1)     190       
_________________________________________________________________
reshape_113 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_362 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_364 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32716143  || Decoder Loss:  0.07566711 Validation Decoder Loss:  0.3537752
Encoder Loss:  0.32657468  || Decoder Loss:  0.07684651 Validation Decoder Loss:  0.3542052
Encoder Loss:  0.32590806  || Decoder Loss:  0.077953264 Validation Decoder Loss:  0.35442618
Encoder Loss:  0.32493737  || Decoder Loss:  0.07889854 Validation Decoder Loss:  0.35436168
Encoder Loss:  0.32340804  || Decoder Loss:  0.07970882 Validation Decoder Loss:  0.35402447
Encoder Loss:  0.32137588  || Decoder Loss:  0.080417894 Validation Decoder Loss:  0.35350358
Encoder Loss:  0.31900293  || Decoder Loss:  0.08101677 Validation Decoder Loss:  0.35283032
Encoder Loss:  0.31640533  || Decoder Loss:  0.08147662 Validation Decoder Loss:  0.3519381
Encoder Loss:  0.31360018  || Decoder Loss:  0.081633225 Validation Decoder Loss:  0.35048276
Encoder Loss:  0.3102142  || Decoder Loss:  0.080029525 Validation Decoder Loss:  0.3435542
Encoder Loss:  0.29867053  || Decoder Loss:  0.04588098 Validation Decoder Loss:  0.32925606
Encoder Loss:  0.29244798  || Decoder Loss:  0.035278033 Validation Decoder Loss:  0.32709152
Encoder Loss:  0.2882352  || Decoder Loss:  0.035194885 Validation Decoder Loss:  0.3273574
Encoder Loss:  0.28344867  || Decoder Loss:  0.035179008 Validation Decoder Loss:  0.32743233
Encoder Loss:  0.2781167  || Decoder Loss:  0.03517245 Validation Decoder Loss:  0.32748154
Encoder Loss:  0.27225572  || Decoder Loss:  0.035169005 Validation Decoder Loss:  0.32751992
Encoder Loss:  0.2658344  || Decoder Loss:  0.0351669 Validation Decoder Loss:  0.32754874
Encoder Loss:  0.25883284  || Decoder Loss:  0.035165407 Validation Decoder Loss:  0.32756865
Encoder Loss:  0.25131074  || Decoder Loss:  0.035164304 Validation Decoder Loss:  0.32758006
Encoder Loss:  0.2433827  || Decoder Loss:  0.035163585 Validation Decoder Loss:  0.32758275
Encoder Loss:  0.23512232  || Decoder Loss:  0.035163406 Validation Decoder Loss:  0.32757705
Encoder Loss:  0.22648987  || Decoder Loss:  0.03516403 Validation Decoder Loss:  0.3275661
Encoder Loss:  0.21727577  || Decoder Loss:  0.03516573 Validation Decoder Loss:  0.3275562
Encoder Loss:  0.20688233  || Decoder Loss:  0.0351689 Validation Decoder Loss:  0.32755396
Encoder Loss:  0.19251585  || Decoder Loss:  0.035174083 Validation Decoder Loss:  0.3275641
Encoder Loss:  0.14603958  || Decoder Loss:  0.035181277 Validation Decoder Loss:  0.32758343
Encoder Loss:  0.05680765  || Decoder Loss:  0.035185862 Validation Decoder Loss:  0.32758164
Encoder Loss:  0.05092289  || Decoder Loss:  0.035185255 Validation Decoder Loss:  0.3275764
Encoder Loss:  0.050341252  || Decoder Loss:  0.035184834 Validation Decoder Loss:  0.32757494
Encoder Loss:  0.049795665  || Decoder Loss:  0.035184853 Validation Decoder Loss:  0.32757562
Encoder Loss:  0.049239006  || Decoder Loss:  0.035185173 Validation Decoder Loss:  0.3275779
Encoder Loss:  0.04866839  || Decoder Loss:  0.035185695 Validation Decoder Loss:  0.3275813
Encoder Loss:  0.04808586  || Decoder Loss:  0.035186384 Validation Decoder Loss:  0.32758543
Encoder Loss:  0.047522087  || Decoder Loss:  0.03518717 Validation Decoder Loss:  0.3275903
Encoder Loss:  0.047152907  || Decoder Loss:  0.035187777 Validation Decoder Loss:  0.32759604
Encoder Loss:  0.046996385  || Decoder Loss:  0.03518799 Validation Decoder Loss:  0.32760218
Encoder Loss:  0.046945438  || Decoder Loss:  0.03518783 Validation Decoder Loss:  0.32760888
Encoder Loss:  0.04694283  || Decoder Loss:  0.03518729 Validation Decoder Loss:  0.32761574
Encoder Loss:  0.04694826  || Decoder Loss:  0.03518672 Validation Decoder Loss:  0.32762307
Encoder Loss:  0.046937976  || Decoder Loss:  0.035186194 Validation Decoder Loss:  0.32763022
Model: siamese_net_lr_0.0003755624165343663 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32763022
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_366 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 514, 5, 19, 1)     385       
_________________________________________________________________
reshape_114 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_352"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_368 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_370 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41519845  || Decoder Loss:  0.06727715 Validation Decoder Loss:  0.36043632
Encoder Loss:  0.4094763  || Decoder Loss:  0.073789194 Validation Decoder Loss:  0.36171076
Encoder Loss:  0.40224302  || Decoder Loss:  0.08202516 Validation Decoder Loss:  0.36462158
Encoder Loss:  0.39335927  || Decoder Loss:  0.092049025 Validation Decoder Loss:  0.36988717
Encoder Loss:  0.38259673  || Decoder Loss:  0.103526704 Validation Decoder Loss:  0.37644303
Encoder Loss:  0.36979073  || Decoder Loss:  0.07618917 Validation Decoder Loss:  0.3328398
Encoder Loss:  0.3547742  || Decoder Loss:  0.035377968 Validation Decoder Loss:  0.32948512
Encoder Loss:  0.33726558  || Decoder Loss:  0.035376173 Validation Decoder Loss:  0.32992956
Encoder Loss:  0.3167325  || Decoder Loss:  0.035397157 Validation Decoder Loss:  0.33032084
Encoder Loss:  0.29214433  || Decoder Loss:  0.03541285 Validation Decoder Loss:  0.3306888
Encoder Loss:  0.26103243  || Decoder Loss:  0.03542363 Validation Decoder Loss:  0.33107394
Encoder Loss:  0.19453429  || Decoder Loss:  0.035428308 Validation Decoder Loss:  0.33147347
Encoder Loss:  0.052845392  || Decoder Loss:  0.035421237 Validation Decoder Loss:  0.33154
Encoder Loss:  0.050183687  || Decoder Loss:  0.035419915 Validation Decoder Loss:  0.3315396
Encoder Loss:  0.0500702  || Decoder Loss:  0.035424225 Validation Decoder Loss:  0.3315364
Encoder Loss:  0.050024986  || Decoder Loss:  0.03542921 Validation Decoder Loss:  0.3315353
Encoder Loss:  0.050018135  || Decoder Loss:  0.03542891 Validation Decoder Loss:  0.33153427
Encoder Loss:  0.050014876  || Decoder Loss:  0.03542854 Validation Decoder Loss:  0.33153242
Encoder Loss:  0.05001959  || Decoder Loss:  0.035427816 Validation Decoder Loss:  0.33153164
Encoder Loss:  0.050005943  || Decoder Loss:  0.035426818 Validation Decoder Loss:  0.33153033
Encoder Loss:  0.05000392  || Decoder Loss:  0.03542633 Validation Decoder Loss:  0.33152926
Encoder Loss:  0.050005153  || Decoder Loss:  0.0354259 Validation Decoder Loss:  0.33152726
Encoder Loss:  0.050004613  || Decoder Loss:  0.035425242 Validation Decoder Loss:  0.33152574
Encoder Loss:  0.05000334  || Decoder Loss:  0.035424814 Validation Decoder Loss:  0.33152425
Encoder Loss:  0.050003126  || Decoder Loss:  0.035424326 Validation Decoder Loss:  0.33152238
Encoder Loss:  0.05000309  || Decoder Loss:  0.035423823 Validation Decoder Loss:  0.33152035
Encoder Loss:  0.050004005  || Decoder Loss:  0.03542348 Validation Decoder Loss:  0.33151808
Encoder Loss:  0.050003603  || Decoder Loss:  0.035423167 Validation Decoder Loss:  0.3315155
Encoder Loss:  0.05000361  || Decoder Loss:  0.035422966 Validation Decoder Loss:  0.3315123
Encoder Loss:  0.05000278  || Decoder Loss:  0.035422713 Validation Decoder Loss:  0.33150905
Encoder Loss:  0.050005894  || Decoder Loss:  0.035422668 Validation Decoder Loss:  0.33150464
Encoder Loss:  0.050006166  || Decoder Loss:  0.035423335 Validation Decoder Loss:  0.3314991
Encoder Loss:  0.050003737  || Decoder Loss:  0.035423793 Validation Decoder Loss:  0.33149338
Encoder Loss:  0.05000234  || Decoder Loss:  0.03542362 Validation Decoder Loss:  0.33148694
Encoder Loss:  0.050002307  || Decoder Loss:  0.035423275 Validation Decoder Loss:  0.3314783
Encoder Loss:  0.05000194  || Decoder Loss:  0.035422824 Validation Decoder Loss:  0.3314664
Encoder Loss:  0.050003897  || Decoder Loss:  0.035422396 Validation Decoder Loss:  0.33144876
Encoder Loss:  0.050005022  || Decoder Loss:  0.03542254 Validation Decoder Loss:  0.33142617
Encoder Loss:  0.050002053  || Decoder Loss:  0.035421852 Validation Decoder Loss:  0.33148658
Encoder Loss:  0.050003238  || Decoder Loss:  0.03541771 Validation Decoder Loss:  0.331607
Model: siamese_net_lr_0.0007142799614464638 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33160698
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 286, 5, 19, 1)     98        
_________________________________________________________________
dropout_372 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_115 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_374 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_376 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2509129  || Decoder Loss:  0.0960782 Validation Decoder Loss:  0.3719049
Encoder Loss:  0.24681355  || Decoder Loss:  0.099595934 Validation Decoder Loss:  0.32484317
Encoder Loss:  0.15522797  || Decoder Loss:  0.035489462 Validation Decoder Loss:  0.33153248
Encoder Loss:  0.0673412  || Decoder Loss:  0.03544905 Validation Decoder Loss:  0.33169734
Encoder Loss:  0.0663302  || Decoder Loss:  0.035446715 Validation Decoder Loss:  0.33176196
Encoder Loss:  0.064907655  || Decoder Loss:  0.035446174 Validation Decoder Loss:  0.33181727
Encoder Loss:  0.062577  || Decoder Loss:  0.03544524 Validation Decoder Loss:  0.3318944
Encoder Loss:  0.05669657  || Decoder Loss:  0.035441995 Validation Decoder Loss:  0.33197314
Encoder Loss:  0.044922125  || Decoder Loss:  0.035434112 Validation Decoder Loss:  0.33207938
Encoder Loss:  0.04413029  || Decoder Loss:  0.03542844 Validation Decoder Loss:  0.33210757
Encoder Loss:  0.044116087  || Decoder Loss:  0.035424273 Validation Decoder Loss:  0.3321299
Encoder Loss:  0.044103567  || Decoder Loss:  0.035420172 Validation Decoder Loss:  0.3321511
Encoder Loss:  0.044090662  || Decoder Loss:  0.035416078 Validation Decoder Loss:  0.3321718
Encoder Loss:  0.04407775  || Decoder Loss:  0.035411943 Validation Decoder Loss:  0.33219182
Encoder Loss:  0.044066258  || Decoder Loss:  0.035407793 Validation Decoder Loss:  0.33221126
Encoder Loss:  0.04404996  || Decoder Loss:  0.035403647 Validation Decoder Loss:  0.3322289
Encoder Loss:  0.044031847  || Decoder Loss:  0.035399467 Validation Decoder Loss:  0.33224148
Encoder Loss:  0.04388966  || Decoder Loss:  0.035395473 Validation Decoder Loss:  0.33224267
Encoder Loss:  0.043146707  || Decoder Loss:  0.035392854 Validation Decoder Loss:  0.33221552
Encoder Loss:  0.04312252  || Decoder Loss:  0.03539072 Validation Decoder Loss:  0.33217555
Encoder Loss:  0.043110657  || Decoder Loss:  0.03538848 Validation Decoder Loss:  0.3321907
Encoder Loss:  0.043100726  || Decoder Loss:  0.035385314 Validation Decoder Loss:  0.33227244
Encoder Loss:  0.0431038  || Decoder Loss:  0.035381414 Validation Decoder Loss:  0.33234715
Encoder Loss:  0.043099996  || Decoder Loss:  0.035376962 Validation Decoder Loss:  0.33240026
Encoder Loss:  0.04309426  || Decoder Loss:  0.0353721 Validation Decoder Loss:  0.33244416
Encoder Loss:  0.043092553  || Decoder Loss:  0.035367034 Validation Decoder Loss:  0.33248445
Encoder Loss:  0.043087784  || Decoder Loss:  0.03536189 Validation Decoder Loss:  0.33251923
Encoder Loss:  0.043083295  || Decoder Loss:  0.035356835 Validation Decoder Loss:  0.33255035
Encoder Loss:  0.043079183  || Decoder Loss:  0.03535222 Validation Decoder Loss:  0.33257776
Encoder Loss:  0.043076146  || Decoder Loss:  0.035347816 Validation Decoder Loss:  0.332601
Encoder Loss:  0.043075226  || Decoder Loss:  0.035343714 Validation Decoder Loss:  0.33261877
Encoder Loss:  0.043069433  || Decoder Loss:  0.03533989 Validation Decoder Loss:  0.33263266
Encoder Loss:  0.04306705  || Decoder Loss:  0.03533617 Validation Decoder Loss:  0.33264303
Encoder Loss:  0.043066923  || Decoder Loss:  0.035332378 Validation Decoder Loss:  0.33265024
Encoder Loss:  0.043062128  || Decoder Loss:  0.035328504 Validation Decoder Loss:  0.33265257
Encoder Loss:  0.04306129  || Decoder Loss:  0.035324585 Validation Decoder Loss:  0.33265132
Encoder Loss:  0.043057702  || Decoder Loss:  0.035320327 Validation Decoder Loss:  0.33264735
Encoder Loss:  0.04305046  || Decoder Loss:  0.035316125 Validation Decoder Loss:  0.3326394
Encoder Loss:  0.04304864  || Decoder Loss:  0.0353113 Validation Decoder Loss:  0.33262956
Encoder Loss:  0.043051418  || Decoder Loss:  0.035306092 Validation Decoder Loss:  0.3326189
Model: siamese_net_lr_0.0005142160431748693 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33261886
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 186, 5, 19, 1)     124       
_________________________________________________________________
dropout_378 (Dropout)        (None, 186, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 514, 5, 19, 1)     330       
_________________________________________________________________
reshape_116 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_380 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_382 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.116098225  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.3624504
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307208 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.116098225  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609824  || Decoder Loss:  0.083072096 Validation Decoder Loss:  0.36245042
Encoder Loss:  0.11609823  || Decoder Loss:  0.08307209 Validation Decoder Loss:  0.36245042
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36245042
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_384 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 514, 5, 19, 1)     60        
_________________________________________________________________
reshape_117 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_364"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_386 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_388 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445365  || Decoder Loss:  0.040445365 Validation Decoder Loss:  0.34678772
Encoder Loss:  0.040445372  || Decoder Loss:  0.040445372 Validation Decoder Loss:  0.34678772
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34678772
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_390 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 514, 5, 19, 1)     190       
_________________________________________________________________
reshape_118 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_392 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_394 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40717274  || Decoder Loss:  0.07640835 Validation Decoder Loss:  0.35439003
Encoder Loss:  0.40390885  || Decoder Loss:  0.07914782 Validation Decoder Loss:  0.35460243
Encoder Loss:  0.39786217  || Decoder Loss:  0.08122006 Validation Decoder Loss:  0.35321492
Encoder Loss:  0.38853127  || Decoder Loss:  0.0819494 Validation Decoder Loss:  0.3478977
Encoder Loss:  0.37752768  || Decoder Loss:  0.048846222 Validation Decoder Loss:  0.33175266
Encoder Loss:  0.3641966  || Decoder Loss:  0.0353137 Validation Decoder Loss:  0.32806998
Encoder Loss:  0.34518623  || Decoder Loss:  0.03518011 Validation Decoder Loss:  0.32782915
Encoder Loss:  0.31727934  || Decoder Loss:  0.03519007 Validation Decoder Loss:  0.3278683
Encoder Loss:  0.278085  || Decoder Loss:  0.0352055 Validation Decoder Loss:  0.32792354
Encoder Loss:  0.14830215  || Decoder Loss:  0.035225175 Validation Decoder Loss:  0.32792693
Encoder Loss:  0.06383732  || Decoder Loss:  0.035223734 Validation Decoder Loss:  0.32781208
Encoder Loss:  0.060973298  || Decoder Loss:  0.03521466 Validation Decoder Loss:  0.3277868
Encoder Loss:  0.05833662  || Decoder Loss:  0.03520993 Validation Decoder Loss:  0.3277822
Encoder Loss:  0.055202547  || Decoder Loss:  0.03520969 Validation Decoder Loss:  0.32778713
Encoder Loss:  0.051799268  || Decoder Loss:  0.035212327 Validation Decoder Loss:  0.32781523
Encoder Loss:  0.051158287  || Decoder Loss:  0.035211977 Validation Decoder Loss:  0.32788202
Encoder Loss:  0.050705675  || Decoder Loss:  0.035209935 Validation Decoder Loss:  0.32790834
Encoder Loss:  0.05082669  || Decoder Loss:  0.03520783 Validation Decoder Loss:  0.32792473
Encoder Loss:  0.050908003  || Decoder Loss:  0.0352059 Validation Decoder Loss:  0.32793188
Encoder Loss:  0.050817523  || Decoder Loss:  0.035204127 Validation Decoder Loss:  0.32794327
Encoder Loss:  0.05081206  || Decoder Loss:  0.035201937 Validation Decoder Loss:  0.3279565
Encoder Loss:  0.05068009  || Decoder Loss:  0.035199534 Validation Decoder Loss:  0.32797104
Encoder Loss:  0.050818138  || Decoder Loss:  0.035196252 Validation Decoder Loss:  0.3279888
Encoder Loss:  0.0507001  || Decoder Loss:  0.035192348 Validation Decoder Loss:  0.3280185
Encoder Loss:  0.05080136  || Decoder Loss:  0.035186145 Validation Decoder Loss:  0.32807565
Encoder Loss:  0.05071076  || Decoder Loss:  0.035175644 Validation Decoder Loss:  0.3282745
Encoder Loss:  0.050672922  || Decoder Loss:  0.035153877 Validation Decoder Loss:  0.32878786
Encoder Loss:  0.050711207  || Decoder Loss:  0.035117086 Validation Decoder Loss:  0.32953894
Encoder Loss:  0.050678574  || Decoder Loss:  0.035062417 Validation Decoder Loss:  0.33059937
Encoder Loss:  0.050674666  || Decoder Loss:  0.034994986 Validation Decoder Loss:  0.33198816
Encoder Loss:  0.050671026  || Decoder Loss:  0.034936942 Validation Decoder Loss:  0.3333941
Encoder Loss:  0.050743517  || Decoder Loss:  0.034898087 Validation Decoder Loss:  0.33457035
Encoder Loss:  0.050709434  || Decoder Loss:  0.034877226 Validation Decoder Loss:  0.33543473
Encoder Loss:  0.05071342  || Decoder Loss:  0.03486712 Validation Decoder Loss:  0.33602786
Encoder Loss:  0.050768  || Decoder Loss:  0.034862034 Validation Decoder Loss:  0.33639914
Encoder Loss:  0.05066087  || Decoder Loss:  0.03485956 Validation Decoder Loss:  0.33665395
Encoder Loss:  0.05072238  || Decoder Loss:  0.034857757 Validation Decoder Loss:  0.3368062
Encoder Loss:  0.050693437  || Decoder Loss:  0.034856603 Validation Decoder Loss:  0.33690757
Encoder Loss:  0.05068931  || Decoder Loss:  0.03485558 Validation Decoder Loss:  0.3369849
Encoder Loss:  0.050773572  || Decoder Loss:  0.03485446 Validation Decoder Loss:  0.33702415
Model: siamese_net_lr_0.0009583040430331412 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33702415
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 190, 5, 19, 1)     128       
_________________________________________________________________
dropout_396 (Dropout)        (None, 190, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 514, 5, 19, 1)     326       
_________________________________________________________________
reshape_119 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_398 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_400 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07796843  || Decoder Loss:  0.07796843 Validation Decoder Loss:  0.33747777
Encoder Loss:  0.03612393  || Decoder Loss:  0.03612393 Validation Decoder Loss:  0.32741743
Encoder Loss:  0.035202596  || Decoder Loss:  0.035202596 Validation Decoder Loss:  0.3271556
Encoder Loss:  0.035021327  || Decoder Loss:  0.035021327 Validation Decoder Loss:  0.32766563
Encoder Loss:  0.03493402  || Decoder Loss:  0.03493402 Validation Decoder Loss:  0.32796
Encoder Loss:  0.03490651  || Decoder Loss:  0.03490651 Validation Decoder Loss:  0.32819328
Encoder Loss:  0.034886107  || Decoder Loss:  0.034886107 Validation Decoder Loss:  0.32845885
Encoder Loss:  0.03486572  || Decoder Loss:  0.03486572 Validation Decoder Loss:  0.32876658
Encoder Loss:  0.03484411  || Decoder Loss:  0.03484411 Validation Decoder Loss:  0.32918736
Encoder Loss:  0.034820706  || Decoder Loss:  0.034820706 Validation Decoder Loss:  0.32974225
Encoder Loss:  0.03479556  || Decoder Loss:  0.03479556 Validation Decoder Loss:  0.33035743
Encoder Loss:  0.03476931  || Decoder Loss:  0.03476931 Validation Decoder Loss:  0.3311668
Encoder Loss:  0.034743164  || Decoder Loss:  0.034743164 Validation Decoder Loss:  0.3320349
Encoder Loss:  0.034718767  || Decoder Loss:  0.034718767 Validation Decoder Loss:  0.33304942
Encoder Loss:  0.034697715  || Decoder Loss:  0.034697715 Validation Decoder Loss:  0.33407712
Encoder Loss:  0.034681957  || Decoder Loss:  0.034681957 Validation Decoder Loss:  0.33501315
Encoder Loss:  0.0346715  || Decoder Loss:  0.0346715 Validation Decoder Loss:  0.33586448
Encoder Loss:  0.034665417  || Decoder Loss:  0.034665417 Validation Decoder Loss:  0.33666605
Encoder Loss:  0.034662087  || Decoder Loss:  0.034662087 Validation Decoder Loss:  0.33717415
Encoder Loss:  0.034660023  || Decoder Loss:  0.034660023 Validation Decoder Loss:  0.33747125
Encoder Loss:  0.03465851  || Decoder Loss:  0.03465851 Validation Decoder Loss:  0.3376794
Encoder Loss:  0.034657236  || Decoder Loss:  0.034657236 Validation Decoder Loss:  0.33781934
Encoder Loss:  0.03465618  || Decoder Loss:  0.03465618 Validation Decoder Loss:  0.33791068
Encoder Loss:  0.034655288  || Decoder Loss:  0.034655288 Validation Decoder Loss:  0.33796835
Encoder Loss:  0.03465451  || Decoder Loss:  0.03465451 Validation Decoder Loss:  0.33800316
Encoder Loss:  0.03465383  || Decoder Loss:  0.03465383 Validation Decoder Loss:  0.3380231
Encoder Loss:  0.034653198  || Decoder Loss:  0.034653198 Validation Decoder Loss:  0.33803406
Encoder Loss:  0.034652665  || Decoder Loss:  0.034652665 Validation Decoder Loss:  0.33804
Encoder Loss:  0.03465214  || Decoder Loss:  0.03465214 Validation Decoder Loss:  0.3380435
Encoder Loss:  0.034651667  || Decoder Loss:  0.034651667 Validation Decoder Loss:  0.33804616
Encoder Loss:  0.03465127  || Decoder Loss:  0.03465127 Validation Decoder Loss:  0.3380488
Encoder Loss:  0.03465086  || Decoder Loss:  0.03465086 Validation Decoder Loss:  0.3380518
Encoder Loss:  0.0346505  || Decoder Loss:  0.0346505 Validation Decoder Loss:  0.33805537
Encoder Loss:  0.034650117  || Decoder Loss:  0.034650117 Validation Decoder Loss:  0.3380594
Encoder Loss:  0.03464978  || Decoder Loss:  0.03464978 Validation Decoder Loss:  0.33806378
Encoder Loss:  0.034649465  || Decoder Loss:  0.034649465 Validation Decoder Loss:  0.33806854
Encoder Loss:  0.034649175  || Decoder Loss:  0.034649175 Validation Decoder Loss:  0.3380735
Encoder Loss:  0.03464886  || Decoder Loss:  0.03464886 Validation Decoder Loss:  0.33807862
Encoder Loss:  0.034648575  || Decoder Loss:  0.034648575 Validation Decoder Loss:  0.3380838
Encoder Loss:  0.034648288  || Decoder Loss:  0.034648288 Validation Decoder Loss:  0.3380891
2019-11-23 04:26:57.160471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_0.0009942480641396518 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3380891
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 64, 5, 19, 1)      2         
_________________________________________________________________
dropout_402 (Dropout)        (None, 64, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 514, 5, 19, 1)     200       
_________________________________________________________________
reshape_120 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_376"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_404 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_406 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34341508  || Decoder Loss:  0.07889943 Validation Decoder Loss:  0.35486072
Encoder Loss:  0.3392729  || Decoder Loss:  0.08237717 Validation Decoder Loss:  0.35376766
Encoder Loss:  0.32628793  || Decoder Loss:  0.074870475 Validation Decoder Loss:  0.3218446
Encoder Loss:  0.298974  || Decoder Loss:  0.03532482 Validation Decoder Loss:  0.3280121
Encoder Loss:  0.27632487  || Decoder Loss:  0.03517545 Validation Decoder Loss:  0.3278405
Encoder Loss:  0.24990104  || Decoder Loss:  0.035191726 Validation Decoder Loss:  0.32773945
Encoder Loss:  0.2137498  || Decoder Loss:  0.03521982 Validation Decoder Loss:  0.32778752
Encoder Loss:  0.15595762  || Decoder Loss:  0.035275787 Validation Decoder Loss:  0.32861137
Encoder Loss:  0.0676055  || Decoder Loss:  0.035371866 Validation Decoder Loss:  0.3305094
Encoder Loss:  0.04849001  || Decoder Loss:  0.035379354 Validation Decoder Loss:  0.33089718
Encoder Loss:  0.04819674  || Decoder Loss:  0.035367712 Validation Decoder Loss:  0.33109942
Encoder Loss:  0.04780182  || Decoder Loss:  0.03535521 Validation Decoder Loss:  0.3312555
Encoder Loss:  0.047576614  || Decoder Loss:  0.035343606 Validation Decoder Loss:  0.33140922
Encoder Loss:  0.04755019  || Decoder Loss:  0.03533493 Validation Decoder Loss:  0.33157948
Encoder Loss:  0.047280982  || Decoder Loss:  0.035327066 Validation Decoder Loss:  0.3317808
Encoder Loss:  0.04738699  || Decoder Loss:  0.03531691 Validation Decoder Loss:  0.33211818
Encoder Loss:  0.04729004  || Decoder Loss:  0.035305846 Validation Decoder Loss:  0.3324589
Encoder Loss:  0.047292665  || Decoder Loss:  0.03529592 Validation Decoder Loss:  0.3325623
Encoder Loss:  0.04743043  || Decoder Loss:  0.035284597 Validation Decoder Loss:  0.33259094
Encoder Loss:  0.047338653  || Decoder Loss:  0.03526948 Validation Decoder Loss:  0.3326217
Encoder Loss:  0.04725735  || Decoder Loss:  0.035248693 Validation Decoder Loss:  0.33264762
Encoder Loss:  0.04738957  || Decoder Loss:  0.03522189 Validation Decoder Loss:  0.33268288
Encoder Loss:  0.047282852  || Decoder Loss:  0.035192188 Validation Decoder Loss:  0.33273554
Encoder Loss:  0.0473381  || Decoder Loss:  0.035163704 Validation Decoder Loss:  0.33280617
Encoder Loss:  0.0473207  || Decoder Loss:  0.035139073 Validation Decoder Loss:  0.33287996
Encoder Loss:  0.047377497  || Decoder Loss:  0.03511937 Validation Decoder Loss:  0.33295953
Encoder Loss:  0.04727317  || Decoder Loss:  0.035104465 Validation Decoder Loss:  0.333058
Encoder Loss:  0.0473378  || Decoder Loss:  0.03509355 Validation Decoder Loss:  0.33311436
Encoder Loss:  0.0473079  || Decoder Loss:  0.035085678 Validation Decoder Loss:  0.33317918
Encoder Loss:  0.04725232  || Decoder Loss:  0.035079814 Validation Decoder Loss:  0.33323306
Encoder Loss:  0.047229458  || Decoder Loss:  0.035075344 Validation Decoder Loss:  0.3332687
Encoder Loss:  0.04727876  || Decoder Loss:  0.03507171 Validation Decoder Loss:  0.33331764
Encoder Loss:  0.047266215  || Decoder Loss:  0.03506862 Validation Decoder Loss:  0.33334926
Encoder Loss:  0.04731274  || Decoder Loss:  0.035065923 Validation Decoder Loss:  0.33335972
Encoder Loss:  0.047300506  || Decoder Loss:  0.035063483 Validation Decoder Loss:  0.3333727
Encoder Loss:  0.047400787  || Decoder Loss:  0.035061218 Validation Decoder Loss:  0.33340615
Encoder Loss:  0.04718893  || Decoder Loss:  0.035059117 Validation Decoder Loss:  0.3334103
Encoder Loss:  0.04732095  || Decoder Loss:  0.03505704 Validation Decoder Loss:  0.33340472
Encoder Loss:  0.04727903  || Decoder Loss:  0.035055056 Validation Decoder Loss:  0.33341944
Encoder Loss:  0.04731187  || Decoder Loss:  0.03505314 Validation Decoder Loss:  0.3334255
Model: siamese_net_lr_0.0006966135615634047 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3334255
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 286, 5, 19, 1)     98        
_________________________________________________________________
dropout_408 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_121 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_410 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_412 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.3673359
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.3673359
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.3673359
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.3673359
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218166 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.092181645 Validation Decoder Loss:  0.36733592
Encoder Loss:  0.2646095  || Decoder Loss:  0.09218165 Validation Decoder Loss:  0.36733592
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36733592
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_155 (Conv3D (None, 64, 5, 19, 1)      2         
_________________________________________________________________
dropout_414 (Dropout)        (None, 64, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_156 (Conv3D (None, 514, 5, 19, 1)     326       
_________________________________________________________________
reshape_122 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_416 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_418 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.078910924  || Decoder Loss:  0.078910924 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.3566114
Encoder Loss:  0.07891092  || Decoder Loss:  0.07891092 Validation Decoder Loss:  0.35661137
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35661137
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_158 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_420 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_159 (Conv3D (None, 514, 5, 19, 1)     385       
_________________________________________________________________
reshape_123 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_422 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_424 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15132089  || Decoder Loss:  0.06604929 Validation Decoder Loss:  0.3604291
Encoder Loss:  0.15284705  || Decoder Loss:  0.06885557 Validation Decoder Loss:  0.36051455
Encoder Loss:  0.15458041  || Decoder Loss:  0.07204193 Validation Decoder Loss:  0.36092615
Encoder Loss:  0.1564944  || Decoder Loss:  0.075561546 Validation Decoder Loss:  0.36165228
Encoder Loss:  0.15859671  || Decoder Loss:  0.079430535 Validation Decoder Loss:  0.36272094
Encoder Loss:  0.16089362  || Decoder Loss:  0.08366336 Validation Decoder Loss:  0.36420882
Encoder Loss:  0.16338532  || Decoder Loss:  0.08826651 Validation Decoder Loss:  0.36619794
Encoder Loss:  0.16605543  || Decoder Loss:  0.09322281 Validation Decoder Loss:  0.36872357
Encoder Loss:  0.16883902  || Decoder Loss:  0.098449305 Validation Decoder Loss:  0.37166828
Encoder Loss:  0.17144671  || Decoder Loss:  0.10356507 Validation Decoder Loss:  0.37409595
Encoder Loss:  0.16894859  || Decoder Loss:  0.10206069 Validation Decoder Loss:  0.33658186
Encoder Loss:  0.118968315  || Decoder Loss:  0.03797657 Validation Decoder Loss:  0.33034784
Encoder Loss:  0.11541622  || Decoder Loss:  0.035327036 Validation Decoder Loss:  0.3288458
Encoder Loss:  0.11378211  || Decoder Loss:  0.035336994 Validation Decoder Loss:  0.3290807
Encoder Loss:  0.1120505  || Decoder Loss:  0.03534953 Validation Decoder Loss:  0.32926744
Encoder Loss:  0.11021321  || Decoder Loss:  0.035360564 Validation Decoder Loss:  0.32944846
Encoder Loss:  0.108262874  || Decoder Loss:  0.035370316 Validation Decoder Loss:  0.32962778
Encoder Loss:  0.10618952  || Decoder Loss:  0.035378862 Validation Decoder Loss:  0.32980448
Encoder Loss:  0.10398009  || Decoder Loss:  0.035386335 Validation Decoder Loss:  0.3299785
Encoder Loss:  0.1016172  || Decoder Loss:  0.035392817 Validation Decoder Loss:  0.33014965
Encoder Loss:  0.09907723  || Decoder Loss:  0.03539836 Validation Decoder Loss:  0.33031833
Encoder Loss:  0.09632742  || Decoder Loss:  0.03540301 Validation Decoder Loss:  0.3304857
Encoder Loss:  0.09332017  || Decoder Loss:  0.035406794 Validation Decoder Loss:  0.33065504
Encoder Loss:  0.08998124  || Decoder Loss:  0.035409678 Validation Decoder Loss:  0.33083382
Encoder Loss:  0.08617647  || Decoder Loss:  0.035411555 Validation Decoder Loss:  0.33103424
Encoder Loss:  0.08156963  || Decoder Loss:  0.035412204 Validation Decoder Loss:  0.3312628
Encoder Loss:  0.074168704  || Decoder Loss:  0.035411466 Validation Decoder Loss:  0.3315017
Encoder Loss:  0.047616556  || Decoder Loss:  0.035409287 Validation Decoder Loss:  0.33165148
Encoder Loss:  0.039328583  || Decoder Loss:  0.035406783 Validation Decoder Loss:  0.3316613
Encoder Loss:  0.039037738  || Decoder Loss:  0.035404295 Validation Decoder Loss:  0.3316691
Encoder Loss:  0.039085373  || Decoder Loss:  0.03540178 Validation Decoder Loss:  0.331676
Encoder Loss:  0.03907555  || Decoder Loss:  0.035399236 Validation Decoder Loss:  0.33168232
Encoder Loss:  0.039007165  || Decoder Loss:  0.035396673 Validation Decoder Loss:  0.33168787
Encoder Loss:  0.039031602  || Decoder Loss:  0.03539408 Validation Decoder Loss:  0.33169353
Encoder Loss:  0.03897334  || Decoder Loss:  0.03539164 Validation Decoder Loss:  0.33169842
Encoder Loss:  0.03904384  || Decoder Loss:  0.03538929 Validation Decoder Loss:  0.33170387
Encoder Loss:  0.039062593  || Decoder Loss:  0.03538701 Validation Decoder Loss:  0.33170998
Encoder Loss:  0.039056186  || Decoder Loss:  0.03538491 Validation Decoder Loss:  0.33171576
Encoder Loss:  0.039070714  || Decoder Loss:  0.03538299 Validation Decoder Loss:  0.3317215
Encoder Loss:  0.03902605  || Decoder Loss:  0.035381254 Validation Decoder Loss:  0.33172625
Model: siamese_net_lr_0.00033957182343436094 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33172625
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_161 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_426 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_162 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_124 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_392"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_428 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_430 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33365119  || Decoder Loss:  0.072940014 Validation Decoder Loss:  0.35760835
Encoder Loss:  0.29872018  || Decoder Loss:  0.054813333 Validation Decoder Loss:  0.3309927
Encoder Loss:  0.09352879  || Decoder Loss:  0.03533263 Validation Decoder Loss:  0.33110428
Encoder Loss:  0.075160734  || Decoder Loss:  0.035172347 Validation Decoder Loss:  0.33083683
Encoder Loss:  0.07321917  || Decoder Loss:  0.03509111 Validation Decoder Loss:  0.3308468
Encoder Loss:  0.07048524  || Decoder Loss:  0.03504138 Validation Decoder Loss:  0.3308956
Encoder Loss:  0.059110865  || Decoder Loss:  0.035014503 Validation Decoder Loss:  0.3310307
Encoder Loss:  0.05046672  || Decoder Loss:  0.034996368 Validation Decoder Loss:  0.33099467
Encoder Loss:  0.048631392  || Decoder Loss:  0.03498803 Validation Decoder Loss:  0.33097926
Encoder Loss:  0.047748618  || Decoder Loss:  0.034979712 Validation Decoder Loss:  0.33097488
Encoder Loss:  0.047045283  || Decoder Loss:  0.034971565 Validation Decoder Loss:  0.33098227
Encoder Loss:  0.046856526  || Decoder Loss:  0.03496384 Validation Decoder Loss:  0.33097982
Encoder Loss:  0.046883292  || Decoder Loss:  0.034956858 Validation Decoder Loss:  0.33096957
Encoder Loss:  0.046808362  || Decoder Loss:  0.034950066 Validation Decoder Loss:  0.33097062
Encoder Loss:  0.0468318  || Decoder Loss:  0.03494371 Validation Decoder Loss:  0.3309664
Encoder Loss:  0.046824593  || Decoder Loss:  0.034937784 Validation Decoder Loss:  0.33096808
Encoder Loss:  0.046826772  || Decoder Loss:  0.034932494 Validation Decoder Loss:  0.3309713
Encoder Loss:  0.046815142  || Decoder Loss:  0.034927823 Validation Decoder Loss:  0.33097866
Encoder Loss:  0.046831217  || Decoder Loss:  0.034924008 Validation Decoder Loss:  0.33098742
Encoder Loss:  0.046832897  || Decoder Loss:  0.03492105 Validation Decoder Loss:  0.33099592
Encoder Loss:  0.046855804  || Decoder Loss:  0.034918662 Validation Decoder Loss:  0.33100432
Encoder Loss:  0.046796437  || Decoder Loss:  0.03491649 Validation Decoder Loss:  0.3310156
Encoder Loss:  0.046805706  || Decoder Loss:  0.034914676 Validation Decoder Loss:  0.331027
Encoder Loss:  0.046779346  || Decoder Loss:  0.034912962 Validation Decoder Loss:  0.33103383
Encoder Loss:  0.04678491  || Decoder Loss:  0.03491167 Validation Decoder Loss:  0.3310442
Encoder Loss:  0.046749853  || Decoder Loss:  0.03491058 Validation Decoder Loss:  0.33104685
Encoder Loss:  0.04676871  || Decoder Loss:  0.03490956 Validation Decoder Loss:  0.3310523
Encoder Loss:  0.046776794  || Decoder Loss:  0.034908596 Validation Decoder Loss:  0.33105862
Encoder Loss:  0.046750974  || Decoder Loss:  0.034907755 Validation Decoder Loss:  0.33106574
Encoder Loss:  0.046727523  || Decoder Loss:  0.03490716 Validation Decoder Loss:  0.33107126
Encoder Loss:  0.046711747  || Decoder Loss:  0.034906384 Validation Decoder Loss:  0.33107704
Encoder Loss:  0.046725564  || Decoder Loss:  0.034905747 Validation Decoder Loss:  0.33108932
Encoder Loss:  0.04673369  || Decoder Loss:  0.034905046 Validation Decoder Loss:  0.3310905
Encoder Loss:  0.04669455  || Decoder Loss:  0.034904614 Validation Decoder Loss:  0.33108675
Encoder Loss:  0.04669554  || Decoder Loss:  0.03490424 Validation Decoder Loss:  0.33108294
Encoder Loss:  0.0467087  || Decoder Loss:  0.034904093 Validation Decoder Loss:  0.33109334
Encoder Loss:  0.046689134  || Decoder Loss:  0.034903478 Validation Decoder Loss:  0.3310882
Encoder Loss:  0.046691727  || Decoder Loss:  0.03490308 Validation Decoder Loss:  0.33110768
Encoder Loss:  0.046681665  || Decoder Loss:  0.03490256 Validation Decoder Loss:  0.33111626
Encoder Loss:  0.046687823  || Decoder Loss:  0.034902178 Validation Decoder Loss:  0.33110344
Model: siamese_net_lr_0.00064766759114068 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33110344
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_164 (Conv3D (None, 286, 5, 19, 1)     161       
_________________________________________________________________
dropout_432 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_165 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_125 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_434 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_436 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2601309  || Decoder Loss:  0.10095749 Validation Decoder Loss:  0.37664968
Encoder Loss:  0.23159942  || Decoder Loss:  0.07349425 Validation Decoder Loss:  0.33107784
Encoder Loss:  0.07898357  || Decoder Loss:  0.035476264 Validation Decoder Loss:  0.3317335
Encoder Loss:  0.0643898  || Decoder Loss:  0.03547176 Validation Decoder Loss:  0.33182725
Encoder Loss:  0.0609952  || Decoder Loss:  0.03546471 Validation Decoder Loss:  0.33199465
Encoder Loss:  0.051980425  || Decoder Loss:  0.035451435 Validation Decoder Loss:  0.33221716
Encoder Loss:  0.04494601  || Decoder Loss:  0.0354395 Validation Decoder Loss:  0.3324505
Encoder Loss:  0.044877753  || Decoder Loss:  0.035429884 Validation Decoder Loss:  0.33257067
Encoder Loss:  0.044861622  || Decoder Loss:  0.035421927 Validation Decoder Loss:  0.33263528
Encoder Loss:  0.04484522  || Decoder Loss:  0.03541434 Validation Decoder Loss:  0.33267677
Encoder Loss:  0.044825897  || Decoder Loss:  0.03540691 Validation Decoder Loss:  0.3327085
Encoder Loss:  0.044793952  || Decoder Loss:  0.035399597 Validation Decoder Loss:  0.33273676
Encoder Loss:  0.044709254  || Decoder Loss:  0.035392452 Validation Decoder Loss:  0.33276433
Encoder Loss:  0.043998424  || Decoder Loss:  0.035385586 Validation Decoder Loss:  0.33278757
Encoder Loss:  0.04365075  || Decoder Loss:  0.035379943 Validation Decoder Loss:  0.33279222
Encoder Loss:  0.04364096  || Decoder Loss:  0.035375044 Validation Decoder Loss:  0.33279395
Encoder Loss:  0.043627292  || Decoder Loss:  0.035370514 Validation Decoder Loss:  0.33279347
Encoder Loss:  0.04361943  || Decoder Loss:  0.03536624 Validation Decoder Loss:  0.33279267
Encoder Loss:  0.043614928  || Decoder Loss:  0.03536223 Validation Decoder Loss:  0.33279103
Encoder Loss:  0.04360774  || Decoder Loss:  0.03535847 Validation Decoder Loss:  0.3327885
Encoder Loss:  0.043603994  || Decoder Loss:  0.035354875 Validation Decoder Loss:  0.33278736
Encoder Loss:  0.04359973  || Decoder Loss:  0.035351444 Validation Decoder Loss:  0.3327868
Encoder Loss:  0.043600187  || Decoder Loss:  0.035348088 Validation Decoder Loss:  0.33278787
Encoder Loss:  0.043594126  || Decoder Loss:  0.035344817 Validation Decoder Loss:  0.33278978
Encoder Loss:  0.043592043  || Decoder Loss:  0.035341572 Validation Decoder Loss:  0.3327923
Encoder Loss:  0.04359417  || Decoder Loss:  0.035338286 Validation Decoder Loss:  0.33279467
Encoder Loss:  0.043586005  || Decoder Loss:  0.03533491 Validation Decoder Loss:  0.33279416
Encoder Loss:  0.043592177  || Decoder Loss:  0.035331074 Validation Decoder Loss:  0.3327918
Encoder Loss:  0.043577556  || Decoder Loss:  0.035326913 Validation Decoder Loss:  0.3327831
Encoder Loss:  0.043582935  || Decoder Loss:  0.035321847 Validation Decoder Loss:  0.3327642
Encoder Loss:  0.04357402  || Decoder Loss:  0.035315644 Validation Decoder Loss:  0.3327309
Encoder Loss:  0.043569952  || Decoder Loss:  0.035307422 Validation Decoder Loss:  0.33268434
Encoder Loss:  0.043564215  || Decoder Loss:  0.03529565 Validation Decoder Loss:  0.33271673
Encoder Loss:  0.043551415  || Decoder Loss:  0.03528156 Validation Decoder Loss:  0.3328932
Encoder Loss:  0.043536764  || Decoder Loss:  0.035258234 Validation Decoder Loss:  0.3330017
Encoder Loss:  0.04353576  || Decoder Loss:  0.035232175 Validation Decoder Loss:  0.33283466
Encoder Loss:  0.043523956  || Decoder Loss:  0.035214446 Validation Decoder Loss:  0.33260456
Encoder Loss:  0.043517467  || Decoder Loss:  0.035201453 Validation Decoder Loss:  0.33249637
Encoder Loss:  0.043503255  || Decoder Loss:  0.035191514 Validation Decoder Loss:  0.33244318
Encoder Loss:  0.043506917  || Decoder Loss:  0.035183944 Validation Decoder Loss:  0.33241075
Model: siamese_net_lr_0.0007026142725269808 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33241075
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_167 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_438 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_168 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_126 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_440 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_442 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28890905  || Decoder Loss:  0.072937444 Validation Decoder Loss:  0.35761303
Encoder Loss:  0.2569391  || Decoder Loss:  0.054874256 Validation Decoder Loss:  0.33101556
Encoder Loss:  0.0836307  || Decoder Loss:  0.03533616 Validation Decoder Loss:  0.33112612
Encoder Loss:  0.06846028  || Decoder Loss:  0.035175562 Validation Decoder Loss:  0.3308326
Encoder Loss:  0.06662568  || Decoder Loss:  0.035093416 Validation Decoder Loss:  0.33084595
Encoder Loss:  0.06448332  || Decoder Loss:  0.03504296 Validation Decoder Loss:  0.33089313
Encoder Loss:  0.056175724  || Decoder Loss:  0.035015512 Validation Decoder Loss:  0.3310566
Encoder Loss:  0.04845961  || Decoder Loss:  0.0349956 Validation Decoder Loss:  0.33103162
Encoder Loss:  0.04634333  || Decoder Loss:  0.03498695 Validation Decoder Loss:  0.33102584
Encoder Loss:  0.045527358  || Decoder Loss:  0.03497819 Validation Decoder Loss:  0.33102816
Encoder Loss:  0.044917684  || Decoder Loss:  0.034969836 Validation Decoder Loss:  0.33103347
Encoder Loss:  0.044849038  || Decoder Loss:  0.034962274 Validation Decoder Loss:  0.33102745
Encoder Loss:  0.044804297  || Decoder Loss:  0.03495523 Validation Decoder Loss:  0.33102733
Encoder Loss:  0.044748686  || Decoder Loss:  0.034948334 Validation Decoder Loss:  0.33103138
Encoder Loss:  0.044810615  || Decoder Loss:  0.0349421 Validation Decoder Loss:  0.3310244
Encoder Loss:  0.0447821  || Decoder Loss:  0.034936298 Validation Decoder Loss:  0.33102477
Encoder Loss:  0.04483354  || Decoder Loss:  0.034931265 Validation Decoder Loss:  0.3310169
Encoder Loss:  0.044837605  || Decoder Loss:  0.03492736 Validation Decoder Loss:  0.3310005
Encoder Loss:  0.044731732  || Decoder Loss:  0.034923755 Validation Decoder Loss:  0.33100396
Encoder Loss:  0.04479629  || Decoder Loss:  0.034920983 Validation Decoder Loss:  0.33100316
Encoder Loss:  0.04472179  || Decoder Loss:  0.03491845 Validation Decoder Loss:  0.3310141
Encoder Loss:  0.044754528  || Decoder Loss:  0.034916352 Validation Decoder Loss:  0.3310227
Encoder Loss:  0.044722136  || Decoder Loss:  0.034914553 Validation Decoder Loss:  0.3310329
Encoder Loss:  0.044703003  || Decoder Loss:  0.034913007 Validation Decoder Loss:  0.33103785
Encoder Loss:  0.044705335  || Decoder Loss:  0.034911834 Validation Decoder Loss:  0.33104286
Encoder Loss:  0.04469946  || Decoder Loss:  0.03491069 Validation Decoder Loss:  0.3310461
Encoder Loss:  0.044695076  || Decoder Loss:  0.03490975 Validation Decoder Loss:  0.33105618
Encoder Loss:  0.04469933  || Decoder Loss:  0.03490864 Validation Decoder Loss:  0.33106115
Encoder Loss:  0.044692706  || Decoder Loss:  0.0349078 Validation Decoder Loss:  0.33106935
Encoder Loss:  0.04469007  || Decoder Loss:  0.034907054 Validation Decoder Loss:  0.3310697
Encoder Loss:  0.044685937  || Decoder Loss:  0.034906488 Validation Decoder Loss:  0.3310718
Encoder Loss:  0.044665094  || Decoder Loss:  0.034905966 Validation Decoder Loss:  0.33106774
Encoder Loss:  0.04467325  || Decoder Loss:  0.034905594 Validation Decoder Loss:  0.33107427
Encoder Loss:  0.044658054  || Decoder Loss:  0.03490498 Validation Decoder Loss:  0.33107802
Encoder Loss:  0.04467055  || Decoder Loss:  0.034904636 Validation Decoder Loss:  0.33106944
Encoder Loss:  0.044662368  || Decoder Loss:  0.034904417 Validation Decoder Loss:  0.33107507
Encoder Loss:  0.044655304  || Decoder Loss:  0.03490381 Validation Decoder Loss:  0.33108872
Encoder Loss:  0.04464224  || Decoder Loss:  0.034903258 Validation Decoder Loss:  0.331093
Encoder Loss:  0.04464539  || Decoder Loss:  0.03490298 Validation Decoder Loss:  0.3310806
Encoder Loss:  0.044643745  || Decoder Loss:  0.03490308 Validation Decoder Loss:  0.33107966
Model: siamese_net_lr_0.0006471980789154902 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33107966
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_170 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_444 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_171 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_127 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_404"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_446 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_448 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16545622  || Decoder Loss:  0.056433607 Validation Decoder Loss:  0.33203647
Encoder Loss:  0.04962286  || Decoder Loss:  0.035419755 Validation Decoder Loss:  0.33214593
Encoder Loss:  0.045672163  || Decoder Loss:  0.035409044 Validation Decoder Loss:  0.3321019
Encoder Loss:  0.04489578  || Decoder Loss:  0.035404798 Validation Decoder Loss:  0.33210465
Encoder Loss:  0.044880018  || Decoder Loss:  0.035395913 Validation Decoder Loss:  0.3321046
Encoder Loss:  0.04487094  || Decoder Loss:  0.035385206 Validation Decoder Loss:  0.3321126
Encoder Loss:  0.044860825  || Decoder Loss:  0.035370603 Validation Decoder Loss:  0.3322106
Encoder Loss:  0.0448553  || Decoder Loss:  0.035352517 Validation Decoder Loss:  0.33232075
Encoder Loss:  0.04483989  || Decoder Loss:  0.035332464 Validation Decoder Loss:  0.3323075
Encoder Loss:  0.04483627  || Decoder Loss:  0.03531533 Validation Decoder Loss:  0.3323238
Encoder Loss:  0.044822052  || Decoder Loss:  0.035300642 Validation Decoder Loss:  0.3322869
Encoder Loss:  0.044809114  || Decoder Loss:  0.035287656 Validation Decoder Loss:  0.3323775
Encoder Loss:  0.044804085  || Decoder Loss:  0.035279136 Validation Decoder Loss:  0.3324757
Encoder Loss:  0.04480157  || Decoder Loss:  0.035271786 Validation Decoder Loss:  0.33255923
Encoder Loss:  0.04479994  || Decoder Loss:  0.035268337 Validation Decoder Loss:  0.33262336
Encoder Loss:  0.04479959  || Decoder Loss:  0.035266742 Validation Decoder Loss:  0.33269256
Encoder Loss:  0.044802576  || Decoder Loss:  0.035274718 Validation Decoder Loss:  0.33272225
Encoder Loss:  0.04480361  || Decoder Loss:  0.035276502 Validation Decoder Loss:  0.3327486
Encoder Loss:  0.04480513  || Decoder Loss:  0.035284594 Validation Decoder Loss:  0.33276194
Encoder Loss:  0.04480673  || Decoder Loss:  0.03529062 Validation Decoder Loss:  0.33286867
Encoder Loss:  0.044808645  || Decoder Loss:  0.03529716 Validation Decoder Loss:  0.33302036
Encoder Loss:  0.044810716  || Decoder Loss:  0.035306666 Validation Decoder Loss:  0.33312035
Encoder Loss:  0.04481232  || Decoder Loss:  0.035312306 Validation Decoder Loss:  0.33318517
Encoder Loss:  0.0448123  || Decoder Loss:  0.035312656 Validation Decoder Loss:  0.33306777
Encoder Loss:  0.044817366  || Decoder Loss:  0.035275184 Validation Decoder Loss:  0.3327575
Encoder Loss:  0.044801492  || Decoder Loss:  0.035280786 Validation Decoder Loss:  0.3329093
Encoder Loss:  0.04480421  || Decoder Loss:  0.03529018 Validation Decoder Loss:  0.33307672
Encoder Loss:  0.044807706  || Decoder Loss:  0.03530141 Validation Decoder Loss:  0.33316383
Encoder Loss:  0.04481127  || Decoder Loss:  0.035308644 Validation Decoder Loss:  0.33307412
Encoder Loss:  0.044811554  || Decoder Loss:  0.035311278 Validation Decoder Loss:  0.3330734
Encoder Loss:  0.044811897  || Decoder Loss:  0.035311773 Validation Decoder Loss:  0.33309802
Encoder Loss:  0.04481111  || Decoder Loss:  0.035307888 Validation Decoder Loss:  0.33306026
Encoder Loss:  0.04481134  || Decoder Loss:  0.035311453 Validation Decoder Loss:  0.3330738
Encoder Loss:  0.04480932  || Decoder Loss:  0.035305213 Validation Decoder Loss:  0.33316115
Encoder Loss:  0.04481162  || Decoder Loss:  0.035311535 Validation Decoder Loss:  0.33308506
Encoder Loss:  0.044816256  || Decoder Loss:  0.035289664 Validation Decoder Loss:  0.33284268
Encoder Loss:  0.044806585  || Decoder Loss:  0.035298843 Validation Decoder Loss:  0.33297703
Encoder Loss:  0.044809207  || Decoder Loss:  0.0353071 Validation Decoder Loss:  0.33304888
Encoder Loss:  0.044810154  || Decoder Loss:  0.03530925 Validation Decoder Loss:  0.33308154
Encoder Loss:  0.04480945  || Decoder Loss:  0.03530602 Validation Decoder Loss:  0.33321035
Model: siamese_net_lr_0.0007972522994632988 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33321035
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_173 (Conv3D (None, 284, 5, 19, 1)     159       
_________________________________________________________________
dropout_450 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_174 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_128 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_452 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_454 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26497698  || Decoder Loss:  0.08288928 Validation Decoder Loss:  0.33158213
Encoder Loss:  0.07420289  || Decoder Loss:  0.03546384 Validation Decoder Loss:  0.3319797
Encoder Loss:  0.055216994  || Decoder Loss:  0.03544204 Validation Decoder Loss:  0.33239844
Encoder Loss:  0.04689572  || Decoder Loss:  0.03542921 Validation Decoder Loss:  0.33246398
Encoder Loss:  0.04679263  || Decoder Loss:  0.03541638 Validation Decoder Loss:  0.33246088
Encoder Loss:  0.046128653  || Decoder Loss:  0.03540413 Validation Decoder Loss:  0.3324539
Encoder Loss:  0.045230735  || Decoder Loss:  0.035394296 Validation Decoder Loss:  0.3324343
Encoder Loss:  0.045206428  || Decoder Loss:  0.035385624 Validation Decoder Loss:  0.3324286
Encoder Loss:  0.045202684  || Decoder Loss:  0.03537755 Validation Decoder Loss:  0.3324378
Encoder Loss:  0.045200247  || Decoder Loss:  0.03536999 Validation Decoder Loss:  0.33246738
Encoder Loss:  0.04518458  || Decoder Loss:  0.035362873 Validation Decoder Loss:  0.3325165
Encoder Loss:  0.04519275  || Decoder Loss:  0.035356075 Validation Decoder Loss:  0.33258677
Encoder Loss:  0.045173522  || Decoder Loss:  0.035349883 Validation Decoder Loss:  0.3326638
Encoder Loss:  0.045166437  || Decoder Loss:  0.03534383 Validation Decoder Loss:  0.3327462
Encoder Loss:  0.04517787  || Decoder Loss:  0.035336424 Validation Decoder Loss:  0.3328002
Encoder Loss:  0.045190662  || Decoder Loss:  0.035321496 Validation Decoder Loss:  0.33276337
Encoder Loss:  0.045146674  || Decoder Loss:  0.03528453 Validation Decoder Loss:  0.33269697
Encoder Loss:  0.04511986  || Decoder Loss:  0.035193227 Validation Decoder Loss:  0.3331559
Encoder Loss:  0.045079306  || Decoder Loss:  0.035069387 Validation Decoder Loss:  0.3338261
Encoder Loss:  0.04507121  || Decoder Loss:  0.03503546 Validation Decoder Loss:  0.33396426
Encoder Loss:  0.04505777  || Decoder Loss:  0.035011567 Validation Decoder Loss:  0.33401
Encoder Loss:  0.045046136  || Decoder Loss:  0.034976188 Validation Decoder Loss:  0.33409843
Encoder Loss:  0.045036465  || Decoder Loss:  0.03495369 Validation Decoder Loss:  0.33413613
Encoder Loss:  0.045016356  || Decoder Loss:  0.03492269 Validation Decoder Loss:  0.33417374
Encoder Loss:  0.04501561  || Decoder Loss:  0.034878157 Validation Decoder Loss:  0.33422947
Encoder Loss:  0.044984028  || Decoder Loss:  0.034835752 Validation Decoder Loss:  0.33425686
Encoder Loss:  0.04496598  || Decoder Loss:  0.0347857 Validation Decoder Loss:  0.3342109
Encoder Loss:  0.0449457  || Decoder Loss:  0.034731194 Validation Decoder Loss:  0.33427888
Encoder Loss:  0.044942036  || Decoder Loss:  0.03471834 Validation Decoder Loss:  0.33423513
Encoder Loss:  0.044945408  || Decoder Loss:  0.034705013 Validation Decoder Loss:  0.33426493
Encoder Loss:  0.044935673  || Decoder Loss:  0.03469403 Validation Decoder Loss:  0.3343643
Encoder Loss:  0.04494376  || Decoder Loss:  0.034709953 Validation Decoder Loss:  0.33430117
Encoder Loss:  0.044922408  || Decoder Loss:  0.03466674 Validation Decoder Loss:  0.33442742
Encoder Loss:  0.044929527  || Decoder Loss:  0.034665424 Validation Decoder Loss:  0.33449107
Encoder Loss:  0.044929776  || Decoder Loss:  0.03469414 Validation Decoder Loss:  0.33443105
Encoder Loss:  0.044932123  || Decoder Loss:  0.03467582 Validation Decoder Loss:  0.33449674
Encoder Loss:  0.044941116  || Decoder Loss:  0.03469655 Validation Decoder Loss:  0.33446747
Encoder Loss:  0.044929404  || Decoder Loss:  0.034695543 Validation Decoder Loss:  0.33456135
Encoder Loss:  0.044933744  || Decoder Loss:  0.03470867 Validation Decoder Loss:  0.33455065
Encoder Loss:  0.044940304  || Decoder Loss:  0.034724373 Validation Decoder Loss:  0.33456585
Model: siamese_net_lr_0.000778807066666168 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33456585
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_176 (Conv3D (None, 400, 5, 19, 1)     212       
_________________________________________________________________
dropout_456 (Dropout)        (None, 400, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_177 (Conv3D (None, 514, 5, 19, 1)     116       
_________________________________________________________________
reshape_129 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_412"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_458 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_460 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19866535  || Decoder Loss:  0.06952406 Validation Decoder Loss:  0.35895187
Encoder Loss:  0.19850525  || Decoder Loss:  0.07429675 Validation Decoder Loss:  0.33287472
Encoder Loss:  0.15987018  || Decoder Loss:  0.03615321 Validation Decoder Loss:  0.3312534
Encoder Loss:  0.060091294  || Decoder Loss:  0.03539 Validation Decoder Loss:  0.3315586
Encoder Loss:  0.05616454  || Decoder Loss:  0.03527777 Validation Decoder Loss:  0.33124137
Encoder Loss:  0.05579264  || Decoder Loss:  0.0352015 Validation Decoder Loss:  0.33119905
Encoder Loss:  0.05539556  || Decoder Loss:  0.035144556 Validation Decoder Loss:  0.33118603
Encoder Loss:  0.05454501  || Decoder Loss:  0.035100967 Validation Decoder Loss:  0.33110029
Encoder Loss:  0.048775207  || Decoder Loss:  0.03507698 Validation Decoder Loss:  0.330913
Encoder Loss:  0.04106108  || Decoder Loss:  0.035061523 Validation Decoder Loss:  0.3309379
Encoder Loss:  0.040920783  || Decoder Loss:  0.03504664 Validation Decoder Loss:  0.33095363
Encoder Loss:  0.04090684  || Decoder Loss:  0.035037197 Validation Decoder Loss:  0.3309668
Encoder Loss:  0.040886693  || Decoder Loss:  0.035030164 Validation Decoder Loss:  0.33097875
Encoder Loss:  0.04088547  || Decoder Loss:  0.035024136 Validation Decoder Loss:  0.330988
Encoder Loss:  0.04086986  || Decoder Loss:  0.035018362 Validation Decoder Loss:  0.33099726
Encoder Loss:  0.040873498  || Decoder Loss:  0.03501271 Validation Decoder Loss:  0.33100528
Encoder Loss:  0.040862307  || Decoder Loss:  0.035006784 Validation Decoder Loss:  0.3310143
Encoder Loss:  0.040858623  || Decoder Loss:  0.03500066 Validation Decoder Loss:  0.33102393
Encoder Loss:  0.04085031  || Decoder Loss:  0.034994077 Validation Decoder Loss:  0.3310346
Encoder Loss:  0.040836543  || Decoder Loss:  0.03498693 Validation Decoder Loss:  0.3310482
Encoder Loss:  0.040826246  || Decoder Loss:  0.03497928 Validation Decoder Loss:  0.33106372
Encoder Loss:  0.04075195  || Decoder Loss:  0.03497094 Validation Decoder Loss:  0.3310828
Encoder Loss:  0.04066677  || Decoder Loss:  0.034962095 Validation Decoder Loss:  0.33110732
Encoder Loss:  0.040651053  || Decoder Loss:  0.034952924 Validation Decoder Loss:  0.33113766
Encoder Loss:  0.04064207  || Decoder Loss:  0.034943618 Validation Decoder Loss:  0.33117357
Encoder Loss:  0.040634647  || Decoder Loss:  0.03493438 Validation Decoder Loss:  0.33121425
Encoder Loss:  0.040627643  || Decoder Loss:  0.034925323 Validation Decoder Loss:  0.3312595
Encoder Loss:  0.04062098  || Decoder Loss:  0.034916483 Validation Decoder Loss:  0.33130956
Encoder Loss:  0.040614348  || Decoder Loss:  0.034907695 Validation Decoder Loss:  0.33136588
Encoder Loss:  0.040607814  || Decoder Loss:  0.03489877 Validation Decoder Loss:  0.33142987
Encoder Loss:  0.040601783  || Decoder Loss:  0.034889515 Validation Decoder Loss:  0.3315036
Encoder Loss:  0.04059563  || Decoder Loss:  0.034879766 Validation Decoder Loss:  0.33159015
Encoder Loss:  0.040588997  || Decoder Loss:  0.034869205 Validation Decoder Loss:  0.331706
Encoder Loss:  0.040581692  || Decoder Loss:  0.03485756 Validation Decoder Loss:  0.33187133
Encoder Loss:  0.04057475  || Decoder Loss:  0.03484635 Validation Decoder Loss:  0.33205703
Encoder Loss:  0.040569454  || Decoder Loss:  0.03483787 Validation Decoder Loss:  0.33222523
Encoder Loss:  0.040566426  || Decoder Loss:  0.03483302 Validation Decoder Loss:  0.33233523
Encoder Loss:  0.040564794  || Decoder Loss:  0.034830406 Validation Decoder Loss:  0.3323905
Encoder Loss:  0.040563613  || Decoder Loss:  0.034828644 Validation Decoder Loss:  0.3324165
Encoder Loss:  0.04056275  || Decoder Loss:  0.034827195 Validation Decoder Loss:  0.33243048
Model: siamese_net_lr_0.0004835475334073291 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33243048
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_179 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_462 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_180 (Conv3D (None, 514, 5, 19, 1)     385       
_________________________________________________________________
reshape_130 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_416"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_464 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_466 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076352  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500037 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068955
Encoder Loss:  0.30076355  || Decoder Loss:  0.06500036 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Encoder Loss:  0.30076355  || Decoder Loss:  0.065000355 Validation Decoder Loss:  0.36068958
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36068958
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_182 (Conv3D (None, 286, 5, 19, 1)     224       
_________________________________________________________________
dropout_468 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_183 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_131 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_470 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_472 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25169605  || Decoder Loss:  0.09913118 Validation Decoder Loss:  0.37528175
Encoder Loss:  0.24700905  || Decoder Loss:  0.10733539 Validation Decoder Loss:  0.33894458
Encoder Loss:  0.15701462  || Decoder Loss:  0.035792522 Validation Decoder Loss:  0.33134893
Encoder Loss:  0.061770197  || Decoder Loss:  0.03554093 Validation Decoder Loss:  0.33143896
Encoder Loss:  0.059934393  || Decoder Loss:  0.035525598 Validation Decoder Loss:  0.33162326
Encoder Loss:  0.057677966  || Decoder Loss:  0.035508923 Validation Decoder Loss:  0.3318165
Encoder Loss:  0.054425515  || Decoder Loss:  0.03549025 Validation Decoder Loss:  0.3320741
Encoder Loss:  0.048944212  || Decoder Loss:  0.035465807 Validation Decoder Loss:  0.3323853
Encoder Loss:  0.044555686  || Decoder Loss:  0.035456188 Validation Decoder Loss:  0.3325044
Encoder Loss:  0.044445004  || Decoder Loss:  0.035449237 Validation Decoder Loss:  0.33253
Encoder Loss:  0.044443306  || Decoder Loss:  0.035442427 Validation Decoder Loss:  0.33254063
Encoder Loss:  0.044440836  || Decoder Loss:  0.035435833 Validation Decoder Loss:  0.3325497
Encoder Loss:  0.04442998  || Decoder Loss:  0.035429437 Validation Decoder Loss:  0.3325592
Encoder Loss:  0.044415217  || Decoder Loss:  0.03542324 Validation Decoder Loss:  0.33256906
Encoder Loss:  0.04441374  || Decoder Loss:  0.03541728 Validation Decoder Loss:  0.3325793
Encoder Loss:  0.0443941  || Decoder Loss:  0.035411507 Validation Decoder Loss:  0.33259055
Encoder Loss:  0.044360753  || Decoder Loss:  0.035405915 Validation Decoder Loss:  0.3326028
Encoder Loss:  0.04430541  || Decoder Loss:  0.035400517 Validation Decoder Loss:  0.33261636
Encoder Loss:  0.044117335  || Decoder Loss:  0.035395157 Validation Decoder Loss:  0.3326325
Encoder Loss:  0.043574635  || Decoder Loss:  0.035389785 Validation Decoder Loss:  0.33265013
Encoder Loss:  0.04327191  || Decoder Loss:  0.035384875 Validation Decoder Loss:  0.33266217
Encoder Loss:  0.043210372  || Decoder Loss:  0.035381116 Validation Decoder Loss:  0.3326642
Encoder Loss:  0.043208603  || Decoder Loss:  0.035378087 Validation Decoder Loss:  0.33266392
Encoder Loss:  0.043202624  || Decoder Loss:  0.03537537 Validation Decoder Loss:  0.33266407
Encoder Loss:  0.04319906  || Decoder Loss:  0.035372857 Validation Decoder Loss:  0.33266538
Encoder Loss:  0.043194342  || Decoder Loss:  0.03537049 Validation Decoder Loss:  0.3326674
Encoder Loss:  0.043189682  || Decoder Loss:  0.035368286 Validation Decoder Loss:  0.33267045
Encoder Loss:  0.04318816  || Decoder Loss:  0.035366222 Validation Decoder Loss:  0.3326744
Encoder Loss:  0.043182593  || Decoder Loss:  0.035364274 Validation Decoder Loss:  0.33267885
Encoder Loss:  0.043180846  || Decoder Loss:  0.03536241 Validation Decoder Loss:  0.33268428
Encoder Loss:  0.043178786  || Decoder Loss:  0.03536063 Validation Decoder Loss:  0.33269048
Encoder Loss:  0.04317703  || Decoder Loss:  0.03535891 Validation Decoder Loss:  0.33269703
Encoder Loss:  0.04317451  || Decoder Loss:  0.035357136 Validation Decoder Loss:  0.33270416
Encoder Loss:  0.04317239  || Decoder Loss:  0.035355274 Validation Decoder Loss:  0.3327093
Encoder Loss:  0.04316856  || Decoder Loss:  0.03535322 Validation Decoder Loss:  0.3327117
Encoder Loss:  0.043168046  || Decoder Loss:  0.035350785 Validation Decoder Loss:  0.3327111
Encoder Loss:  0.043165855  || Decoder Loss:  0.035347734 Validation Decoder Loss:  0.33270517
Encoder Loss:  0.043161254  || Decoder Loss:  0.035343982 Validation Decoder Loss:  0.33268708
Encoder Loss:  0.043159053  || Decoder Loss:  0.035339404 Validation Decoder Loss:  0.3326558
Encoder Loss:  0.04315541  || Decoder Loss:  0.035333857 Validation Decoder Loss:  0.3326074
Model: siamese_net_lr_0.0005432599771157639 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3326074
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_185 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_474 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_186 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_132 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_476 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_478 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3120118  || Decoder Loss:  0.07294644 Validation Decoder Loss:  0.35758758
Encoder Loss:  0.27808923  || Decoder Loss:  0.05466241 Validation Decoder Loss:  0.33105803
Encoder Loss:  0.08781602  || Decoder Loss:  0.03533666 Validation Decoder Loss:  0.33111686
Encoder Loss:  0.07198752  || Decoder Loss:  0.03517619 Validation Decoder Loss:  0.33083415
Encoder Loss:  0.069940224  || Decoder Loss:  0.03509355 Validation Decoder Loss:  0.3308462
Encoder Loss:  0.06757528  || Decoder Loss:  0.035042927 Validation Decoder Loss:  0.33089232
Encoder Loss:  0.058187947  || Decoder Loss:  0.03501533 Validation Decoder Loss:  0.33106723
Encoder Loss:  0.050163984  || Decoder Loss:  0.034995265 Validation Decoder Loss:  0.33102491
Encoder Loss:  0.047615577  || Decoder Loss:  0.03498734 Validation Decoder Loss:  0.33101922
Encoder Loss:  0.046786133  || Decoder Loss:  0.034978606 Validation Decoder Loss:  0.3310176
Encoder Loss:  0.046043288  || Decoder Loss:  0.034970295 Validation Decoder Loss:  0.33102414
Encoder Loss:  0.04583635  || Decoder Loss:  0.034962542 Validation Decoder Loss:  0.33102545
Encoder Loss:  0.045802917  || Decoder Loss:  0.03495519 Validation Decoder Loss:  0.33102924
Encoder Loss:  0.045811534  || Decoder Loss:  0.03494821 Validation Decoder Loss:  0.33103234
Encoder Loss:  0.045794245  || Decoder Loss:  0.034941673 Validation Decoder Loss:  0.33103615
Encoder Loss:  0.045812216  || Decoder Loss:  0.034935836 Validation Decoder Loss:  0.33103442
Encoder Loss:  0.045783207  || Decoder Loss:  0.034930598 Validation Decoder Loss:  0.331036
Encoder Loss:  0.045741316  || Decoder Loss:  0.034926094 Validation Decoder Loss:  0.33104092
Encoder Loss:  0.045781948  || Decoder Loss:  0.034922644 Validation Decoder Loss:  0.33103222
Encoder Loss:  0.045784485  || Decoder Loss:  0.03491984 Validation Decoder Loss:  0.33103424
Encoder Loss:  0.045761004  || Decoder Loss:  0.034917675 Validation Decoder Loss:  0.33103013
Encoder Loss:  0.045787457  || Decoder Loss:  0.034915872 Validation Decoder Loss:  0.33103424
Encoder Loss:  0.04578804  || Decoder Loss:  0.03491425 Validation Decoder Loss:  0.33103547
Encoder Loss:  0.045779523  || Decoder Loss:  0.034912907 Validation Decoder Loss:  0.33103675
Encoder Loss:  0.04575621  || Decoder Loss:  0.034911793 Validation Decoder Loss:  0.33104122
Encoder Loss:  0.045744423  || Decoder Loss:  0.03491069 Validation Decoder Loss:  0.33104888
Encoder Loss:  0.04573098  || Decoder Loss:  0.03490964 Validation Decoder Loss:  0.33105174
Encoder Loss:  0.04575837  || Decoder Loss:  0.03490893 Validation Decoder Loss:  0.33104753
Encoder Loss:  0.045730706  || Decoder Loss:  0.034908213 Validation Decoder Loss:  0.33106118
Encoder Loss:  0.045728076  || Decoder Loss:  0.034907218 Validation Decoder Loss:  0.33107036
Encoder Loss:  0.045718297  || Decoder Loss:  0.034906395 Validation Decoder Loss:  0.33107644
Encoder Loss:  0.045728754  || Decoder Loss:  0.034905814 Validation Decoder Loss:  0.33107907
Encoder Loss:  0.045699596  || Decoder Loss:  0.034905292 Validation Decoder Loss:  0.33107626
Encoder Loss:  0.045699686  || Decoder Loss:  0.03490491 Validation Decoder Loss:  0.33107826
Encoder Loss:  0.04572262  || Decoder Loss:  0.034904473 Validation Decoder Loss:  0.33107448
Encoder Loss:  0.045704197  || Decoder Loss:  0.0349041 Validation Decoder Loss:  0.3310861
Encoder Loss:  0.0457006  || Decoder Loss:  0.034903664 Validation Decoder Loss:  0.3310778
Encoder Loss:  0.04569881  || Decoder Loss:  0.034903564 Validation Decoder Loss:  0.3310789
Encoder Loss:  0.04570218  || Decoder Loss:  0.034903225 Validation Decoder Loss:  0.33108336
Encoder Loss:  0.045694675  || Decoder Loss:  0.034902833 Validation Decoder Loss:  0.3310902
Model: siamese_net_lr_0.0006496456696940499 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3310902
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_188 (Conv3D (None, 386, 5, 19, 1)     135       
_________________________________________________________________
dropout_480 (Dropout)        (None, 386, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_189 (Conv3D (None, 514, 5, 19, 1)     130       
_________________________________________________________________
reshape_133 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_428"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_482 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_484 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26971743  || Decoder Loss:  0.069674484 Validation Decoder Loss:  0.3624407
Encoder Loss:  0.2696432  || Decoder Loss:  0.070028275 Validation Decoder Loss:  0.3622676
Encoder Loss:  0.2695506  || Decoder Loss:  0.07045862 Validation Decoder Loss:  0.36204612
Encoder Loss:  0.26944697  || Decoder Loss:  0.07092835 Validation Decoder Loss:  0.36177844
Encoder Loss:  0.26933414  || Decoder Loss:  0.07142565 Validation Decoder Loss:  0.36146405
Encoder Loss:  0.26921165  || Decoder Loss:  0.07194977 Validation Decoder Loss:  0.3611048
Encoder Loss:  0.26907802  || Decoder Loss:  0.07250369 Validation Decoder Loss:  0.3607025
Encoder Loss:  0.2689311  || Decoder Loss:  0.07309197 Validation Decoder Loss:  0.360259
Encoder Loss:  0.26876813  || Decoder Loss:  0.07372057 Validation Decoder Loss:  0.3597749
Encoder Loss:  0.26858565  || Decoder Loss:  0.07439696 Validation Decoder Loss:  0.35924995
Encoder Loss:  0.2683788  || Decoder Loss:  0.07513066 Validation Decoder Loss:  0.35868374
Encoder Loss:  0.2681409  || Decoder Loss:  0.07593394 Validation Decoder Loss:  0.35807717
Encoder Loss:  0.26786274  || Decoder Loss:  0.076823086 Validation Decoder Loss:  0.3574341
Encoder Loss:  0.2675305  || Decoder Loss:  0.07782001 Validation Decoder Loss:  0.35676235
Encoder Loss:  0.26712343  || Decoder Loss:  0.078955084 Validation Decoder Loss:  0.35607648
Encoder Loss:  0.26660794  || Decoder Loss:  0.08027113 Validation Decoder Loss:  0.35540175
Encoder Loss:  0.26592728  || Decoder Loss:  0.08182955 Validation Decoder Loss:  0.3547819
Encoder Loss:  0.26497674  || Decoder Loss:  0.08371691 Validation Decoder Loss:  0.3542766
Encoder Loss:  0.26354092  || Decoder Loss:  0.08603798 Validation Decoder Loss:  0.35392588
Encoder Loss:  0.2610955  || Decoder Loss:  0.08879568 Validation Decoder Loss:  0.35347366
Encoder Loss:  0.25597578  || Decoder Loss:  0.09089877 Validation Decoder Loss:  0.35019153
Encoder Loss:  0.240834  || Decoder Loss:  0.08265202 Validation Decoder Loss:  0.33884284
Encoder Loss:  0.19663452  || Decoder Loss:  0.046628054 Validation Decoder Loss:  0.33788934
Encoder Loss:  0.10667998  || Decoder Loss:  0.03765156 Validation Decoder Loss:  0.3328792
Encoder Loss:  0.094191276  || Decoder Loss:  0.03591969 Validation Decoder Loss:  0.33250695
Encoder Loss:  0.0768477  || Decoder Loss:  0.035601024 Validation Decoder Loss:  0.33205986
Encoder Loss:  0.073925115  || Decoder Loss:  0.03555207 Validation Decoder Loss:  0.33213073
Encoder Loss:  0.07232732  || Decoder Loss:  0.03551858 Validation Decoder Loss:  0.3322575
Encoder Loss:  0.07397632  || Decoder Loss:  0.03550069 Validation Decoder Loss:  0.33237475
Encoder Loss:  0.072925895  || Decoder Loss:  0.035487466 Validation Decoder Loss:  0.3324599
Encoder Loss:  0.07298428  || Decoder Loss:  0.035478737 Validation Decoder Loss:  0.33252525
Encoder Loss:  0.072881415  || Decoder Loss:  0.03547151 Validation Decoder Loss:  0.33257133
Encoder Loss:  0.07300098  || Decoder Loss:  0.035465308 Validation Decoder Loss:  0.33259556
Encoder Loss:  0.07252056  || Decoder Loss:  0.03546048 Validation Decoder Loss:  0.3326196
Encoder Loss:  0.07251944  || Decoder Loss:  0.035456195 Validation Decoder Loss:  0.33263966
Encoder Loss:  0.072446376  || Decoder Loss:  0.035452403 Validation Decoder Loss:  0.3326661
Encoder Loss:  0.07250197  || Decoder Loss:  0.035448596 Validation Decoder Loss:  0.33269048
Encoder Loss:  0.07207318  || Decoder Loss:  0.03544507 Validation Decoder Loss:  0.3327261
Encoder Loss:  0.07203767  || Decoder Loss:  0.035441656 Validation Decoder Loss:  0.3327626
Encoder Loss:  0.07197206  || Decoder Loss:  0.035438024 Validation Decoder Loss:  0.33279854
Model: siamese_net_lr_0.0007649365865311662 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33279854
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_191 (Conv3D (None, 132, 5, 19, 1)     7         
_________________________________________________________________
dropout_486 (Dropout)        (None, 132, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_192 (Conv3D (None, 514, 5, 19, 1)     384       
_________________________________________________________________
reshape_134 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_488 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_490 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07776161  || Decoder Loss:  0.07041141 Validation Decoder Loss:  0.3620425
Encoder Loss:  0.08619794  || Decoder Loss:  0.07920239 Validation Decoder Loss:  0.36390853
Encoder Loss:  0.09567529  || Decoder Loss:  0.08907989 Validation Decoder Loss:  0.36804056
Encoder Loss:  0.10590787  || Decoder Loss:  0.09975218 Validation Decoder Loss:  0.3741302
Encoder Loss:  0.08669255  || Decoder Loss:  0.08035434 Validation Decoder Loss:  0.32654494
Encoder Loss:  0.042701647  || Decoder Loss:  0.035661872 Validation Decoder Loss:  0.32700795
Encoder Loss:  0.04234007  || Decoder Loss:  0.03557874 Validation Decoder Loss:  0.32745314
Encoder Loss:  0.041953634  || Decoder Loss:  0.03549767 Validation Decoder Loss:  0.32802093
Encoder Loss:  0.041537862  || Decoder Loss:  0.035416808 Validation Decoder Loss:  0.32854426
Encoder Loss:  0.04109439  || Decoder Loss:  0.035343412 Validation Decoder Loss:  0.3289642
Encoder Loss:  0.04061854  || Decoder Loss:  0.03528414 Validation Decoder Loss:  0.3293891
Encoder Loss:  0.040084  || Decoder Loss:  0.035237547 Validation Decoder Loss:  0.3298232
Encoder Loss:  0.03943251  || Decoder Loss:  0.035198376 Validation Decoder Loss:  0.33026588
Encoder Loss:  0.038590085  || Decoder Loss:  0.035163578 Validation Decoder Loss:  0.33061135
Encoder Loss:  0.037521224  || Decoder Loss:  0.035131775 Validation Decoder Loss:  0.33106163
Encoder Loss:  0.03611382  || Decoder Loss:  0.035103086 Validation Decoder Loss:  0.3313291
Encoder Loss:  0.035407655  || Decoder Loss:  0.035084367 Validation Decoder Loss:  0.33134544
Encoder Loss:  0.035394598  || Decoder Loss:  0.03507165 Validation Decoder Loss:  0.3313645
Encoder Loss:  0.03538456  || Decoder Loss:  0.035061937 Validation Decoder Loss:  0.3313981
Encoder Loss:  0.03537735  || Decoder Loss:  0.03505442 Validation Decoder Loss:  0.3314377
Encoder Loss:  0.035370935  || Decoder Loss:  0.035048347 Validation Decoder Loss:  0.33147764
Encoder Loss:  0.035365235  || Decoder Loss:  0.035043065 Validation Decoder Loss:  0.3315168
Encoder Loss:  0.035359893  || Decoder Loss:  0.035037946 Validation Decoder Loss:  0.33155662
Encoder Loss:  0.035354577  || Decoder Loss:  0.035032593 Validation Decoder Loss:  0.33160198
Encoder Loss:  0.03534895  || Decoder Loss:  0.035027117 Validation Decoder Loss:  0.33164775
Encoder Loss:  0.035343453  || Decoder Loss:  0.035021607 Validation Decoder Loss:  0.3316997
Encoder Loss:  0.03533777  || Decoder Loss:  0.035015874 Validation Decoder Loss:  0.3317594
Encoder Loss:  0.035331704  || Decoder Loss:  0.035009943 Validation Decoder Loss:  0.33182
Encoder Loss:  0.035325814  || Decoder Loss:  0.035004098 Validation Decoder Loss:  0.3318823
Encoder Loss:  0.035320178  || Decoder Loss:  0.03499857 Validation Decoder Loss:  0.33193675
Encoder Loss:  0.035315145  || Decoder Loss:  0.0349935 Validation Decoder Loss:  0.33198708
Encoder Loss:  0.035310708  || Decoder Loss:  0.034988984 Validation Decoder Loss:  0.33202752
Encoder Loss:  0.035306647  || Decoder Loss:  0.034984875 Validation Decoder Loss:  0.33206588
Encoder Loss:  0.035303004  || Decoder Loss:  0.034981158 Validation Decoder Loss:  0.33209386
Encoder Loss:  0.035299763  || Decoder Loss:  0.03497785 Validation Decoder Loss:  0.33211738
Encoder Loss:  0.03529659  || Decoder Loss:  0.034974612 Validation Decoder Loss:  0.33213875
Encoder Loss:  0.035293404  || Decoder Loss:  0.034971345 Validation Decoder Loss:  0.33216006
Encoder Loss:  0.035290442  || Decoder Loss:  0.034968313 Validation Decoder Loss:  0.33217686
Encoder Loss:  0.035287347  || Decoder Loss:  0.034965154 Validation Decoder Loss:  0.33219528
Encoder Loss:  0.035284508  || Decoder Loss:  0.034962222 Validation Decoder Loss:  0.33221072
Model: siamese_net_lr_7.061092985291827e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33221072
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_194 (Conv3D (None, 284, 5, 19, 1)     222       
_________________________________________________________________
dropout_492 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_195 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_135 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_494 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_496 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17621791  || Decoder Loss:  0.07345268 Validation Decoder Loss:  0.33096683
Encoder Loss:  0.054548092  || Decoder Loss:  0.03551033 Validation Decoder Loss:  0.3316434
Encoder Loss:  0.044832107  || Decoder Loss:  0.035448726 Validation Decoder Loss:  0.3323813
Encoder Loss:  0.042923078  || Decoder Loss:  0.035427395 Validation Decoder Loss:  0.33237937
Encoder Loss:  0.042870056  || Decoder Loss:  0.035408493 Validation Decoder Loss:  0.33242536
Encoder Loss:  0.042140502  || Decoder Loss:  0.035391435 Validation Decoder Loss:  0.3324851
Encoder Loss:  0.041830823  || Decoder Loss:  0.035379283 Validation Decoder Loss:  0.3325628
Encoder Loss:  0.041819893  || Decoder Loss:  0.03537015 Validation Decoder Loss:  0.33263123
Encoder Loss:  0.04181419  || Decoder Loss:  0.035363298 Validation Decoder Loss:  0.33266306
Encoder Loss:  0.0418084  || Decoder Loss:  0.035355423 Validation Decoder Loss:  0.33268905
Encoder Loss:  0.041792188  || Decoder Loss:  0.035328146 Validation Decoder Loss:  0.33232802
Encoder Loss:  0.04175428  || Decoder Loss:  0.035260033 Validation Decoder Loss:  0.33288145
Encoder Loss:  0.041718666  || Decoder Loss:  0.035196416 Validation Decoder Loss:  0.33312398
Encoder Loss:  0.04171268  || Decoder Loss:  0.035185818 Validation Decoder Loss:  0.33321768
Encoder Loss:  0.04171237  || Decoder Loss:  0.03518522 Validation Decoder Loss:  0.33323604
Encoder Loss:  0.041712113  || Decoder Loss:  0.03518468 Validation Decoder Loss:  0.33324492
Encoder Loss:  0.041712467  || Decoder Loss:  0.035185315 Validation Decoder Loss:  0.33324552
Encoder Loss:  0.04171238  || Decoder Loss:  0.035185292 Validation Decoder Loss:  0.33323827
Encoder Loss:  0.0417125  || Decoder Loss:  0.035185385 Validation Decoder Loss:  0.3332369
Encoder Loss:  0.04171354  || Decoder Loss:  0.035187256 Validation Decoder Loss:  0.3332019
Encoder Loss:  0.041718055  || Decoder Loss:  0.035195693 Validation Decoder Loss:  0.33282164
Encoder Loss:  0.04171927  || Decoder Loss:  0.035198245 Validation Decoder Loss:  0.33321545
Encoder Loss:  0.041722156  || Decoder Loss:  0.03520334 Validation Decoder Loss:  0.33319503
Encoder Loss:  0.04172598  || Decoder Loss:  0.035210438 Validation Decoder Loss:  0.3331627
Encoder Loss:  0.04173214  || Decoder Loss:  0.035221502 Validation Decoder Loss:  0.33311844
Encoder Loss:  0.04174401  || Decoder Loss:  0.035242826 Validation Decoder Loss:  0.33306628
Encoder Loss:  0.041758016  || Decoder Loss:  0.035268 Validation Decoder Loss:  0.33298874
Encoder Loss:  0.0417699  || Decoder Loss:  0.035289522 Validation Decoder Loss:  0.33294487
Encoder Loss:  0.041780714  || Decoder Loss:  0.03530888 Validation Decoder Loss:  0.33286983
Encoder Loss:  0.04178608  || Decoder Loss:  0.035318594 Validation Decoder Loss:  0.33282006
Encoder Loss:  0.04178785  || Decoder Loss:  0.035321847 Validation Decoder Loss:  0.33280575
Encoder Loss:  0.04178964  || Decoder Loss:  0.03532494 Validation Decoder Loss:  0.33275038
Encoder Loss:  0.041790165  || Decoder Loss:  0.035325922 Validation Decoder Loss:  0.3327608
Encoder Loss:  0.04179142  || Decoder Loss:  0.03532806 Validation Decoder Loss:  0.33274165
Encoder Loss:  0.041790966  || Decoder Loss:  0.035327468 Validation Decoder Loss:  0.33272535
Encoder Loss:  0.041791815  || Decoder Loss:  0.035328884 Validation Decoder Loss:  0.33271185
Encoder Loss:  0.041792024  || Decoder Loss:  0.03532929 Validation Decoder Loss:  0.33272213
Encoder Loss:  0.041784853  || Decoder Loss:  0.035313174 Validation Decoder Loss:  0.3326432
Encoder Loss:  0.041787256  || Decoder Loss:  0.035320833 Validation Decoder Loss:  0.3326426
Encoder Loss:  0.04179118  || Decoder Loss:  0.035327896 Validation Decoder Loss:  0.33263204
Model: siamese_net_lr_0.0004775129133488849 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33263204
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_197 (Conv3D (None, 220, 5, 19, 1)     95        
_________________________________________________________________
dropout_498 (Dropout)        (None, 220, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_198 (Conv3D (None, 514, 5, 19, 1)     77        
_________________________________________________________________
reshape_136 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 172
Trainable params: 172
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_500 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_502 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3217012  || Decoder Loss:  0.05290918 Validation Decoder Loss:  0.35322213
Encoder Loss:  0.31850728  || Decoder Loss:  0.053682417 Validation Decoder Loss:  0.3531142
Encoder Loss:  0.30997232  || Decoder Loss:  0.054500636 Validation Decoder Loss:  0.35264584
Encoder Loss:  0.2981199  || Decoder Loss:  0.055319533 Validation Decoder Loss:  0.35087976
Encoder Loss:  0.28288957  || Decoder Loss:  0.05143057 Validation Decoder Loss:  0.33365512
Encoder Loss:  0.26151478  || Decoder Loss:  0.035462603 Validation Decoder Loss:  0.3304731
Encoder Loss:  0.23190887  || Decoder Loss:  0.035323158 Validation Decoder Loss:  0.3306045
Encoder Loss:  0.10556915  || Decoder Loss:  0.035350002 Validation Decoder Loss:  0.33119714
Encoder Loss:  0.07046725  || Decoder Loss:  0.035269767 Validation Decoder Loss:  0.33086544
Encoder Loss:  0.07017453  || Decoder Loss:  0.035199583 Validation Decoder Loss:  0.33069178
Encoder Loss:  0.069871366  || Decoder Loss:  0.035145413 Validation Decoder Loss:  0.33062166
Encoder Loss:  0.0696107  || Decoder Loss:  0.03510312 Validation Decoder Loss:  0.3305915
Encoder Loss:  0.06929328  || Decoder Loss:  0.03506815 Validation Decoder Loss:  0.33057964
Encoder Loss:  0.068900034  || Decoder Loss:  0.0350409 Validation Decoder Loss:  0.33058572
Encoder Loss:  0.06853357  || Decoder Loss:  0.03502174 Validation Decoder Loss:  0.330604
Encoder Loss:  0.06813021  || Decoder Loss:  0.035009004 Validation Decoder Loss:  0.33061844
Encoder Loss:  0.06766899  || Decoder Loss:  0.035000384 Validation Decoder Loss:  0.33063236
Encoder Loss:  0.06716122  || Decoder Loss:  0.03499395 Validation Decoder Loss:  0.330643
Encoder Loss:  0.06657916  || Decoder Loss:  0.03498868 Validation Decoder Loss:  0.33064407
Encoder Loss:  0.06576435  || Decoder Loss:  0.034984004 Validation Decoder Loss:  0.33065408
Encoder Loss:  0.06352583  || Decoder Loss:  0.034979567 Validation Decoder Loss:  0.3306738
Encoder Loss:  0.051698424  || Decoder Loss:  0.034974538 Validation Decoder Loss:  0.33076218
Encoder Loss:  0.04909135  || Decoder Loss:  0.0349684 Validation Decoder Loss:  0.33081472
Encoder Loss:  0.047211472  || Decoder Loss:  0.0349627 Validation Decoder Loss:  0.33086014
Encoder Loss:  0.046149053  || Decoder Loss:  0.03495785 Validation Decoder Loss:  0.33087802
Encoder Loss:  0.045910407  || Decoder Loss:  0.034953896 Validation Decoder Loss:  0.33088183
Encoder Loss:  0.04586855  || Decoder Loss:  0.034950163 Validation Decoder Loss:  0.33088613
Encoder Loss:  0.045861248  || Decoder Loss:  0.034946505 Validation Decoder Loss:  0.33088928
Encoder Loss:  0.045846287  || Decoder Loss:  0.03494291 Validation Decoder Loss:  0.3308931
Encoder Loss:  0.04584963  || Decoder Loss:  0.034939386 Validation Decoder Loss:  0.33089578
Encoder Loss:  0.045837007  || Decoder Loss:  0.03493593 Validation Decoder Loss:  0.3308988
Encoder Loss:  0.04582716  || Decoder Loss:  0.034932543 Validation Decoder Loss:  0.33090195
Encoder Loss:  0.04583015  || Decoder Loss:  0.034929253 Validation Decoder Loss:  0.33090448
Encoder Loss:  0.04582741  || Decoder Loss:  0.03492609 Validation Decoder Loss:  0.33090717
Encoder Loss:  0.045825038  || Decoder Loss:  0.034923084 Validation Decoder Loss:  0.33091027
Encoder Loss:  0.0458191  || Decoder Loss:  0.034920223 Validation Decoder Loss:  0.33091396
Encoder Loss:  0.0458232  || Decoder Loss:  0.034917552 Validation Decoder Loss:  0.3309173
Encoder Loss:  0.04581214  || Decoder Loss:  0.034915067 Validation Decoder Loss:  0.3309215
Encoder Loss:  0.045802325  || Decoder Loss:  0.034912784 Validation Decoder Loss:  0.33092654
Encoder Loss:  0.045809485  || Decoder Loss:  0.034910705 Validation Decoder Loss:  0.33093148
Model: siamese_net_lr_0.0003926630094444099 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3309315
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_200 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_504 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_201 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_137 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_444"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_506 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_508 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33400738  || Decoder Loss:  0.07283058 Validation Decoder Loss:  0.3587715
Encoder Loss:  0.31699842  || Decoder Loss:  0.06958098 Validation Decoder Loss:  0.32276577
Encoder Loss:  0.22956568  || Decoder Loss:  0.035385106 Validation Decoder Loss:  0.33210146
Encoder Loss:  0.07649487  || Decoder Loss:  0.035234585 Validation Decoder Loss:  0.33175457
Encoder Loss:  0.07539613  || Decoder Loss:  0.035164665 Validation Decoder Loss:  0.33152735
Encoder Loss:  0.074239805  || Decoder Loss:  0.03511 Validation Decoder Loss:  0.33132154
Encoder Loss:  0.07273776  || Decoder Loss:  0.035071243 Validation Decoder Loss:  0.33116344
Encoder Loss:  0.07088802  || Decoder Loss:  0.03505037 Validation Decoder Loss:  0.3310967
Encoder Loss:  0.06859165  || Decoder Loss:  0.03504074 Validation Decoder Loss:  0.33110604
Encoder Loss:  0.06547542  || Decoder Loss:  0.03503464 Validation Decoder Loss:  0.33116853
Encoder Loss:  0.06037302  || Decoder Loss:  0.035029195 Validation Decoder Loss:  0.33129686
Encoder Loss:  0.055592608  || Decoder Loss:  0.03501962 Validation Decoder Loss:  0.33141586
Encoder Loss:  0.053834613  || Decoder Loss:  0.0350114 Validation Decoder Loss:  0.3314418
Encoder Loss:  0.052095808  || Decoder Loss:  0.035007652 Validation Decoder Loss:  0.3314559
Encoder Loss:  0.050247222  || Decoder Loss:  0.03500573 Validation Decoder Loss:  0.3314588
Encoder Loss:  0.048441958  || Decoder Loss:  0.03500531 Validation Decoder Loss:  0.33145052
Encoder Loss:  0.04780657  || Decoder Loss:  0.03500444 Validation Decoder Loss:  0.33146435
Encoder Loss:  0.047553502  || Decoder Loss:  0.03500205 Validation Decoder Loss:  0.33148286
Encoder Loss:  0.04733952  || Decoder Loss:  0.034999546 Validation Decoder Loss:  0.33150342
Encoder Loss:  0.047136102  || Decoder Loss:  0.034996893 Validation Decoder Loss:  0.33153006
Encoder Loss:  0.046966746  || Decoder Loss:  0.03499395 Validation Decoder Loss:  0.33156586
Encoder Loss:  0.046854943  || Decoder Loss:  0.03499034 Validation Decoder Loss:  0.33160117
Encoder Loss:  0.046804924  || Decoder Loss:  0.03498672 Validation Decoder Loss:  0.33163166
Encoder Loss:  0.046783358  || Decoder Loss:  0.034983203 Validation Decoder Loss:  0.3316617
Encoder Loss:  0.046763495  || Decoder Loss:  0.034979753 Validation Decoder Loss:  0.33169162
Encoder Loss:  0.046748076  || Decoder Loss:  0.03497651 Validation Decoder Loss:  0.33172157
Encoder Loss:  0.04673164  || Decoder Loss:  0.034973532 Validation Decoder Loss:  0.33175203
Encoder Loss:  0.04671838  || Decoder Loss:  0.03497074 Validation Decoder Loss:  0.33177662
Encoder Loss:  0.046708163  || Decoder Loss:  0.03496865 Validation Decoder Loss:  0.3317999
Encoder Loss:  0.04669584  || Decoder Loss:  0.034966882 Validation Decoder Loss:  0.33183476
Encoder Loss:  0.046682388  || Decoder Loss:  0.03496422 Validation Decoder Loss:  0.33188844
Encoder Loss:  0.04667105  || Decoder Loss:  0.034961153 Validation Decoder Loss:  0.3319431
Encoder Loss:  0.046657506  || Decoder Loss:  0.03495794 Validation Decoder Loss:  0.33199617
Encoder Loss:  0.04665029  || Decoder Loss:  0.034955814 Validation Decoder Loss:  0.3320522
Encoder Loss:  0.04664334  || Decoder Loss:  0.034952387 Validation Decoder Loss:  0.33212927
Encoder Loss:  0.04663885  || Decoder Loss:  0.03494894 Validation Decoder Loss:  0.33221972
Encoder Loss:  0.04663473  || Decoder Loss:  0.034945324 Validation Decoder Loss:  0.33230966
Encoder Loss:  0.046633173  || Decoder Loss:  0.03494127 Validation Decoder Loss:  0.33241114
Encoder Loss:  0.046630155  || Decoder Loss:  0.034937106 Validation Decoder Loss:  0.33250856
Encoder Loss:  0.046626803  || Decoder Loss:  0.03493413 Validation Decoder Loss:  0.3326183
Model: siamese_net_lr_0.0002570166360138493 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3326183
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_203 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_510 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_204 (Conv3D (None, 514, 5, 19, 1)     190       
_________________________________________________________________
reshape_138 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_512 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_514 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35420823  || Decoder Loss:  0.075775616 Validation Decoder Loss:  0.35387415
Encoder Loss:  0.35325143  || Decoder Loss:  0.07720253 Validation Decoder Loss:  0.3543491
Encoder Loss:  0.35210407  || Decoder Loss:  0.07849779 Validation Decoder Loss:  0.35447752
Encoder Loss:  0.35028133  || Decoder Loss:  0.07956764 Validation Decoder Loss:  0.35417703
Encoder Loss:  0.34756985  || Decoder Loss:  0.08047065 Validation Decoder Loss:  0.3535544
Encoder Loss:  0.34423217  || Decoder Loss:  0.081202276 Validation Decoder Loss:  0.3526758
Encoder Loss:  0.34051228  || Decoder Loss:  0.0816772 Validation Decoder Loss:  0.3513327
Encoder Loss:  0.336386  || Decoder Loss:  0.08109906 Validation Decoder Loss:  0.3471197
Encoder Loss:  0.32752022  || Decoder Loss:  0.053127375 Validation Decoder Loss:  0.3238489
Encoder Loss:  0.31971323  || Decoder Loss:  0.035281982 Validation Decoder Loss:  0.32766762
Encoder Loss:  0.3138694  || Decoder Loss:  0.035181783 Validation Decoder Loss:  0.32750067
Encoder Loss:  0.30697784  || Decoder Loss:  0.035171196 Validation Decoder Loss:  0.32756233
Encoder Loss:  0.29904234  || Decoder Loss:  0.035168603 Validation Decoder Loss:  0.3275848
Encoder Loss:  0.29003623  || Decoder Loss:  0.035168175 Validation Decoder Loss:  0.32760182
Encoder Loss:  0.279925  || Decoder Loss:  0.035168573 Validation Decoder Loss:  0.32761723
Encoder Loss:  0.26884627  || Decoder Loss:  0.0351697 Validation Decoder Loss:  0.32762605
Encoder Loss:  0.25700432  || Decoder Loss:  0.035171874 Validation Decoder Loss:  0.32761994
Encoder Loss:  0.24434681  || Decoder Loss:  0.035175312 Validation Decoder Loss:  0.32760185
Encoder Loss:  0.23018585  || Decoder Loss:  0.03518004 Validation Decoder Loss:  0.3275886
Encoder Loss:  0.21033956  || Decoder Loss:  0.035186242 Validation Decoder Loss:  0.32759786
Encoder Loss:  0.13095793  || Decoder Loss:  0.035193805 Validation Decoder Loss:  0.3276105
Encoder Loss:  0.054282483  || Decoder Loss:  0.03519487 Validation Decoder Loss:  0.32757866
Encoder Loss:  0.053078707  || Decoder Loss:  0.03519163 Validation Decoder Loss:  0.32756153
Encoder Loss:  0.052317243  || Decoder Loss:  0.035190042 Validation Decoder Loss:  0.32755902
Encoder Loss:  0.05153923  || Decoder Loss:  0.03518956 Validation Decoder Loss:  0.32756466
Encoder Loss:  0.050737467  || Decoder Loss:  0.035189766 Validation Decoder Loss:  0.3275746
Encoder Loss:  0.04991159  || Decoder Loss:  0.035190392 Validation Decoder Loss:  0.32758665
Encoder Loss:  0.04908061  || Decoder Loss:  0.03519134 Validation Decoder Loss:  0.32759997
Encoder Loss:  0.04847818  || Decoder Loss:  0.035192207 Validation Decoder Loss:  0.32761675
Encoder Loss:  0.04825623  || Decoder Loss:  0.035192434 Validation Decoder Loss:  0.32763577
Encoder Loss:  0.048295803  || Decoder Loss:  0.035192043 Validation Decoder Loss:  0.3276562
Encoder Loss:  0.04825628  || Decoder Loss:  0.03519138 Validation Decoder Loss:  0.32767445
Encoder Loss:  0.048240166  || Decoder Loss:  0.035190705 Validation Decoder Loss:  0.32769036
Encoder Loss:  0.048210166  || Decoder Loss:  0.035190128 Validation Decoder Loss:  0.32770467
Encoder Loss:  0.04822938  || Decoder Loss:  0.035189506 Validation Decoder Loss:  0.32771716
Encoder Loss:  0.04820238  || Decoder Loss:  0.03518901 Validation Decoder Loss:  0.32772824
Encoder Loss:  0.048201885  || Decoder Loss:  0.0351884 Validation Decoder Loss:  0.3277378
Encoder Loss:  0.048205003  || Decoder Loss:  0.03518788 Validation Decoder Loss:  0.32774603
Encoder Loss:  0.04821549  || Decoder Loss:  0.035187308 Validation Decoder Loss:  0.32775366
Encoder Loss:  0.048204258  || Decoder Loss:  0.03518671 Validation Decoder Loss:  0.32776064
Model: siamese_net_lr_0.00045944765135476053 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32776064
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_206 (Conv3D (None, 414, 5, 19, 1)     226       
_________________________________________________________________
dropout_516 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_207 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_139 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_518 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_520 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1384109  || Decoder Loss:  0.06177527 Validation Decoder Loss:  0.3530006
Encoder Loss:  0.13760705  || Decoder Loss:  0.06217313 Validation Decoder Loss:  0.3421315
Encoder Loss:  0.12406189  || Decoder Loss:  0.04779665 Validation Decoder Loss:  0.33120096
Encoder Loss:  0.101566  || Decoder Loss:  0.03516903 Validation Decoder Loss:  0.33067477
Encoder Loss:  0.047539886  || Decoder Loss:  0.03502484 Validation Decoder Loss:  0.33075058
Encoder Loss:  0.046938475  || Decoder Loss:  0.03497801 Validation Decoder Loss:  0.33063787
Encoder Loss:  0.04683266  || Decoder Loss:  0.03495197 Validation Decoder Loss:  0.33056465
Encoder Loss:  0.0467062  || Decoder Loss:  0.034934927 Validation Decoder Loss:  0.33051425
Encoder Loss:  0.046536308  || Decoder Loss:  0.03492173 Validation Decoder Loss:  0.33047646
Encoder Loss:  0.046275645  || Decoder Loss:  0.03491025 Validation Decoder Loss:  0.33044362
Encoder Loss:  0.045693345  || Decoder Loss:  0.0348996 Validation Decoder Loss:  0.33042043
Encoder Loss:  0.04217545  || Decoder Loss:  0.034889292 Validation Decoder Loss:  0.3304755
Encoder Loss:  0.038334537  || Decoder Loss:  0.03487952 Validation Decoder Loss:  0.3304708
Encoder Loss:  0.038308017  || Decoder Loss:  0.034870584 Validation Decoder Loss:  0.33046433
Encoder Loss:  0.03829574  || Decoder Loss:  0.03486196 Validation Decoder Loss:  0.33045745
Encoder Loss:  0.03827629  || Decoder Loss:  0.03485353 Validation Decoder Loss:  0.33045077
Encoder Loss:  0.038259603  || Decoder Loss:  0.03484516 Validation Decoder Loss:  0.33044475
Encoder Loss:  0.03824221  || Decoder Loss:  0.034836918 Validation Decoder Loss:  0.33044034
Encoder Loss:  0.038227446  || Decoder Loss:  0.03482888 Validation Decoder Loss:  0.3304378
Encoder Loss:  0.038209308  || Decoder Loss:  0.034821153 Validation Decoder Loss:  0.330437
Encoder Loss:  0.038187366  || Decoder Loss:  0.034813885 Validation Decoder Loss:  0.33043832
Encoder Loss:  0.038158324  || Decoder Loss:  0.03480724 Validation Decoder Loss:  0.33044225
Encoder Loss:  0.038129803  || Decoder Loss:  0.03480128 Validation Decoder Loss:  0.33044875
Encoder Loss:  0.038111825  || Decoder Loss:  0.034796022 Validation Decoder Loss:  0.3304577
Encoder Loss:  0.038100496  || Decoder Loss:  0.03479141 Validation Decoder Loss:  0.33046827
Encoder Loss:  0.03809308  || Decoder Loss:  0.034787387 Validation Decoder Loss:  0.3304792
Encoder Loss:  0.038087636  || Decoder Loss:  0.03478381 Validation Decoder Loss:  0.33049035
Encoder Loss:  0.038083345  || Decoder Loss:  0.034780618 Validation Decoder Loss:  0.33050075
Encoder Loss:  0.038079802  || Decoder Loss:  0.03477773 Validation Decoder Loss:  0.33051044
Encoder Loss:  0.038077027  || Decoder Loss:  0.034775086 Validation Decoder Loss:  0.3305194
Encoder Loss:  0.038074624  || Decoder Loss:  0.03477265 Validation Decoder Loss:  0.33052763
Encoder Loss:  0.038072444  || Decoder Loss:  0.034770444 Validation Decoder Loss:  0.33053526
Encoder Loss:  0.038070478  || Decoder Loss:  0.03476832 Validation Decoder Loss:  0.33054233
Encoder Loss:  0.038068622  || Decoder Loss:  0.03476636 Validation Decoder Loss:  0.3305488
Encoder Loss:  0.03806695  || Decoder Loss:  0.034764502 Validation Decoder Loss:  0.33055475
Encoder Loss:  0.038065303  || Decoder Loss:  0.03476275 Validation Decoder Loss:  0.3305603
Encoder Loss:  0.038063794  || Decoder Loss:  0.03476109 Validation Decoder Loss:  0.3305654
Encoder Loss:  0.038062327  || Decoder Loss:  0.034759507 Validation Decoder Loss:  0.33057007
Encoder Loss:  0.03806096  || Decoder Loss:  0.034757987 Validation Decoder Loss:  0.33057442
Encoder Loss:  0.038059603  || Decoder Loss:  0.03475653 Validation Decoder Loss:  0.33057848
Model: siamese_net_lr_0.0003754869596390036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33057848
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_209 (Conv3D (None, 370, 5, 19, 1)     56        
_________________________________________________________________
dropout_522 (Dropout)        (None, 370, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_210 (Conv3D (None, 514, 5, 19, 1)     146       
_________________________________________________________________
reshape_140 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_524 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_457"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_526 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20004435  || Decoder Loss:  0.07290889 Validation Decoder Loss:  0.3618543
Encoder Loss:  0.19466856  || Decoder Loss:  0.067497835 Validation Decoder Loss:  0.3359893
Encoder Loss:  0.10023487  || Decoder Loss:  0.03529829 Validation Decoder Loss:  0.33189923
Encoder Loss:  0.06042247  || Decoder Loss:  0.03528461 Validation Decoder Loss:  0.33156767
Encoder Loss:  0.059385933  || Decoder Loss:  0.035207998 Validation Decoder Loss:  0.33133012
Encoder Loss:  0.057586946  || Decoder Loss:  0.035152372 Validation Decoder Loss:  0.33117917
Encoder Loss:  0.05266718  || Decoder Loss:  0.03512803 Validation Decoder Loss:  0.3311203
Encoder Loss:  0.042906027  || Decoder Loss:  0.035116754 Validation Decoder Loss:  0.33103576
Encoder Loss:  0.04126421  || Decoder Loss:  0.03510629 Validation Decoder Loss:  0.33100963
Encoder Loss:  0.04111819  || Decoder Loss:  0.035098165 Validation Decoder Loss:  0.33098823
Encoder Loss:  0.04104849  || Decoder Loss:  0.035091434 Validation Decoder Loss:  0.3309684
Encoder Loss:  0.041013647  || Decoder Loss:  0.035085786 Validation Decoder Loss:  0.3309511
Encoder Loss:  0.040964875  || Decoder Loss:  0.035081003 Validation Decoder Loss:  0.33093375
Encoder Loss:  0.040918346  || Decoder Loss:  0.03507702 Validation Decoder Loss:  0.33091575
Encoder Loss:  0.040897068  || Decoder Loss:  0.03507364 Validation Decoder Loss:  0.33089864
Encoder Loss:  0.04088138  || Decoder Loss:  0.035070755 Validation Decoder Loss:  0.33088318
Encoder Loss:  0.04084556  || Decoder Loss:  0.035068307 Validation Decoder Loss:  0.33086878
Encoder Loss:  0.040753126  || Decoder Loss:  0.0350663 Validation Decoder Loss:  0.33085635
Encoder Loss:  0.04071117  || Decoder Loss:  0.035064477 Validation Decoder Loss:  0.33084556
Encoder Loss:  0.04070463  || Decoder Loss:  0.035062872 Validation Decoder Loss:  0.33083645
Encoder Loss:  0.040700607  || Decoder Loss:  0.03506146 Validation Decoder Loss:  0.33082867
Encoder Loss:  0.040697746  || Decoder Loss:  0.035060152 Validation Decoder Loss:  0.3308223
Encoder Loss:  0.0406962  || Decoder Loss:  0.03505892 Validation Decoder Loss:  0.33081716
Encoder Loss:  0.040695135  || Decoder Loss:  0.0350577 Validation Decoder Loss:  0.33081335
Encoder Loss:  0.040693432  || Decoder Loss:  0.03505652 Validation Decoder Loss:  0.33081046
Encoder Loss:  0.040694322  || Decoder Loss:  0.035055283 Validation Decoder Loss:  0.33080858
Encoder Loss:  0.04069201  || Decoder Loss:  0.035054013 Validation Decoder Loss:  0.33080742
Encoder Loss:  0.040689602  || Decoder Loss:  0.035052758 Validation Decoder Loss:  0.33080637
Encoder Loss:  0.04068949  || Decoder Loss:  0.03505133 Validation Decoder Loss:  0.33080602
Encoder Loss:  0.040687982  || Decoder Loss:  0.035049744 Validation Decoder Loss:  0.3308057
Encoder Loss:  0.04068894  || Decoder Loss:  0.035047915 Validation Decoder Loss:  0.33080608
Encoder Loss:  0.040684596  || Decoder Loss:  0.03504608 Validation Decoder Loss:  0.33080673
Encoder Loss:  0.04068398  || Decoder Loss:  0.03504431 Validation Decoder Loss:  0.33080852
Encoder Loss:  0.0406832  || Decoder Loss:  0.035042644 Validation Decoder Loss:  0.33081135
Encoder Loss:  0.040681884  || Decoder Loss:  0.035041045 Validation Decoder Loss:  0.33081454
Encoder Loss:  0.0406817  || Decoder Loss:  0.03503949 Validation Decoder Loss:  0.3308178
Encoder Loss:  0.040680267  || Decoder Loss:  0.035038076 Validation Decoder Loss:  0.33082184
Encoder Loss:  0.040678915  || Decoder Loss:  0.035036784 Validation Decoder Loss:  0.33082587
Encoder Loss:  0.04067825  || Decoder Loss:  0.035035513 Validation Decoder Loss:  0.33082974
Encoder Loss:  0.040677838  || Decoder Loss:  0.035034325 Validation Decoder Loss:  0.33083394
Model: siamese_net_lr_0.0005770117732769664 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33083394
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_212 (Conv3D (None, 416, 5, 19, 1)     39        
_________________________________________________________________
dropout_528 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_213 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_141 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_530 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_532 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19387239  || Decoder Loss:  0.055387314 Validation Decoder Loss:  0.3593381
Encoder Loss:  0.19378541  || Decoder Loss:  0.055664126 Validation Decoder Loss:  0.3583674
Encoder Loss:  0.19360071  || Decoder Loss:  0.055789005 Validation Decoder Loss:  0.357024
Encoder Loss:  0.19325387  || Decoder Loss:  0.05566727 Validation Decoder Loss:  0.35515243
Encoder Loss:  0.19258623  || Decoder Loss:  0.055051688 Validation Decoder Loss:  0.3522902
Encoder Loss:  0.1910925  || Decoder Loss:  0.053139266 Validation Decoder Loss:  0.3469032
Encoder Loss:  0.18614969  || Decoder Loss:  0.045730308 Validation Decoder Loss:  0.33216435
Encoder Loss:  0.17931062  || Decoder Loss:  0.035326235 Validation Decoder Loss:  0.33143204
Encoder Loss:  0.17878275  || Decoder Loss:  0.035108164 Validation Decoder Loss:  0.33061805
Encoder Loss:  0.17828758  || Decoder Loss:  0.035025313 Validation Decoder Loss:  0.32999414
Encoder Loss:  0.17774037  || Decoder Loss:  0.034976333 Validation Decoder Loss:  0.32953706
Encoder Loss:  0.177099  || Decoder Loss:  0.03495055 Validation Decoder Loss:  0.32924324
Encoder Loss:  0.17629485  || Decoder Loss:  0.0349349 Validation Decoder Loss:  0.32906574
Encoder Loss:  0.17520644  || Decoder Loss:  0.034926094 Validation Decoder Loss:  0.32897496
Encoder Loss:  0.17353663  || Decoder Loss:  0.03492412 Validation Decoder Loss:  0.32897657
Encoder Loss:  0.17007193  || Decoder Loss:  0.03492991 Validation Decoder Loss:  0.3291152
Encoder Loss:  0.14967202  || Decoder Loss:  0.03494471 Validation Decoder Loss:  0.32944298
Encoder Loss:  0.062420715  || Decoder Loss:  0.03495551 Validation Decoder Loss:  0.32952887
Encoder Loss:  0.0409855  || Decoder Loss:  0.034947995 Validation Decoder Loss:  0.32947433
Encoder Loss:  0.040618677  || Decoder Loss:  0.03493856 Validation Decoder Loss:  0.32942808
Encoder Loss:  0.040614553  || Decoder Loss:  0.034930207 Validation Decoder Loss:  0.3293903
Encoder Loss:  0.04061099  || Decoder Loss:  0.034922782 Validation Decoder Loss:  0.32935938
Encoder Loss:  0.04061096  || Decoder Loss:  0.03491606 Validation Decoder Loss:  0.3293342
Encoder Loss:  0.04060158  || Decoder Loss:  0.03490988 Validation Decoder Loss:  0.329314
Encoder Loss:  0.040603522  || Decoder Loss:  0.034904104 Validation Decoder Loss:  0.32929832
Encoder Loss:  0.040593896  || Decoder Loss:  0.034898646 Validation Decoder Loss:  0.32928666
Encoder Loss:  0.040602244  || Decoder Loss:  0.03489342 Validation Decoder Loss:  0.3292789
Encoder Loss:  0.040589754  || Decoder Loss:  0.034888342 Validation Decoder Loss:  0.32927406
Encoder Loss:  0.04058877  || Decoder Loss:  0.03488337 Validation Decoder Loss:  0.32927212
Encoder Loss:  0.04057801  || Decoder Loss:  0.03487843 Validation Decoder Loss:  0.32927275
Encoder Loss:  0.040582787  || Decoder Loss:  0.03487353 Validation Decoder Loss:  0.32927585
Encoder Loss:  0.04057692  || Decoder Loss:  0.034868598 Validation Decoder Loss:  0.3292812
Encoder Loss:  0.040572595  || Decoder Loss:  0.034863688 Validation Decoder Loss:  0.32928863
Encoder Loss:  0.040569734  || Decoder Loss:  0.03485872 Validation Decoder Loss:  0.3292979
Encoder Loss:  0.0405627  || Decoder Loss:  0.03485374 Validation Decoder Loss:  0.32930878
Encoder Loss:  0.040561408  || Decoder Loss:  0.034848727 Validation Decoder Loss:  0.32932127
Encoder Loss:  0.040555615  || Decoder Loss:  0.034843728 Validation Decoder Loss:  0.32933488
Encoder Loss:  0.040553693  || Decoder Loss:  0.03483874 Validation Decoder Loss:  0.32934985
Encoder Loss:  0.04055189  || Decoder Loss:  0.034833834 Validation Decoder Loss:  0.3293661
Encoder Loss:  0.040546387  || Decoder Loss:  0.034828965 Validation Decoder Loss:  0.32938302
Model: siamese_net_lr_0.00016937778465427465 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32938302
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_215 (Conv3D (None, 370, 5, 19, 1)     245       
_________________________________________________________________
dropout_534 (Dropout)        (None, 370, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_216 (Conv3D (None, 514, 5, 19, 1)     146       
_________________________________________________________________
reshape_142 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_536 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_538 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17205183  || Decoder Loss:  0.080090255 Validation Decoder Loss:  0.3631267
Encoder Loss:  0.17461796  || Decoder Loss:  0.08690951 Validation Decoder Loss:  0.36287552
Encoder Loss:  0.14801265  || Decoder Loss:  0.057771713 Validation Decoder Loss:  0.3333336
Encoder Loss:  0.08004754  || Decoder Loss:  0.035477106 Validation Decoder Loss:  0.3317713
Encoder Loss:  0.04988747  || Decoder Loss:  0.035496518 Validation Decoder Loss:  0.3316911
Encoder Loss:  0.049582873  || Decoder Loss:  0.0354541 Validation Decoder Loss:  0.3316405
Encoder Loss:  0.04924474  || Decoder Loss:  0.035412442 Validation Decoder Loss:  0.3316291
Encoder Loss:  0.048742533  || Decoder Loss:  0.035371047 Validation Decoder Loss:  0.33164966
Encoder Loss:  0.047871687  || Decoder Loss:  0.035329755 Validation Decoder Loss:  0.3316509
Encoder Loss:  0.04498504  || Decoder Loss:  0.03529058 Validation Decoder Loss:  0.3315457
Encoder Loss:  0.039810278  || Decoder Loss:  0.03525685 Validation Decoder Loss:  0.3314432
Encoder Loss:  0.039684493  || Decoder Loss:  0.03522181 Validation Decoder Loss:  0.33136463
Encoder Loss:  0.03965111  || Decoder Loss:  0.035188824 Validation Decoder Loss:  0.33129203
Encoder Loss:  0.039624296  || Decoder Loss:  0.03515776 Validation Decoder Loss:  0.33122563
Encoder Loss:  0.03959182  || Decoder Loss:  0.035129484 Validation Decoder Loss:  0.33116782
Encoder Loss:  0.039570484  || Decoder Loss:  0.035105344 Validation Decoder Loss:  0.33112416
Encoder Loss:  0.039549015  || Decoder Loss:  0.03508632 Validation Decoder Loss:  0.33110082
Encoder Loss:  0.03953288  || Decoder Loss:  0.035072062 Validation Decoder Loss:  0.33110142
Encoder Loss:  0.039519392  || Decoder Loss:  0.03506088 Validation Decoder Loss:  0.33112222
Encoder Loss:  0.03950195  || Decoder Loss:  0.035051033 Validation Decoder Loss:  0.33116072
Encoder Loss:  0.039491784  || Decoder Loss:  0.035041608 Validation Decoder Loss:  0.3312105
Encoder Loss:  0.03947343  || Decoder Loss:  0.035032257 Validation Decoder Loss:  0.3312692
Encoder Loss:  0.03945517  || Decoder Loss:  0.035022993 Validation Decoder Loss:  0.33133465
Encoder Loss:  0.03943654  || Decoder Loss:  0.03501385 Validation Decoder Loss:  0.33140615
Encoder Loss:  0.039415244  || Decoder Loss:  0.03500497 Validation Decoder Loss:  0.33148348
Encoder Loss:  0.039388396  || Decoder Loss:  0.034996435 Validation Decoder Loss:  0.3315652
Encoder Loss:  0.03936348  || Decoder Loss:  0.03498833 Validation Decoder Loss:  0.33164895
Encoder Loss:  0.039336115  || Decoder Loss:  0.03498087 Validation Decoder Loss:  0.3317346
Encoder Loss:  0.039324466  || Decoder Loss:  0.034974 Validation Decoder Loss:  0.33182025
Encoder Loss:  0.039326258  || Decoder Loss:  0.03496799 Validation Decoder Loss:  0.33190358
Encoder Loss:  0.039315566  || Decoder Loss:  0.03496287 Validation Decoder Loss:  0.33198416
Encoder Loss:  0.03931086  || Decoder Loss:  0.03495873 Validation Decoder Loss:  0.33206078
Encoder Loss:  0.03930662  || Decoder Loss:  0.034955435 Validation Decoder Loss:  0.33213383
Encoder Loss:  0.03930793  || Decoder Loss:  0.034952898 Validation Decoder Loss:  0.3321963
Encoder Loss:  0.03930514  || Decoder Loss:  0.034950864 Validation Decoder Loss:  0.33224732
Encoder Loss:  0.039303467  || Decoder Loss:  0.03494916 Validation Decoder Loss:  0.3322863
Encoder Loss:  0.039314587  || Decoder Loss:  0.034947664 Validation Decoder Loss:  0.33231145
Encoder Loss:  0.039301407  || Decoder Loss:  0.034946 Validation Decoder Loss:  0.3323293
Encoder Loss:  0.039295617  || Decoder Loss:  0.03494458 Validation Decoder Loss:  0.3323403
Encoder Loss:  0.039291225  || Decoder Loss:  0.03494326 Validation Decoder Loss:  0.33234715
Model: siamese_net_lr_0.00043562025316039717 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33234715
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_218 (Conv3D (None, 354, 5, 19, 1)     229       
_________________________________________________________________
dropout_540 (Dropout)        (None, 354, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_219 (Conv3D (None, 514, 5, 19, 1)     162       
_________________________________________________________________
reshape_143 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_542 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_469"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_544 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2918151  || Decoder Loss:  0.082394645 Validation Decoder Loss:  0.36239642
Encoder Loss:  0.2914103  || Decoder Loss:  0.08350557 Validation Decoder Loss:  0.3627185
Encoder Loss:  0.29092947  || Decoder Loss:  0.084783055 Validation Decoder Loss:  0.36299056
Encoder Loss:  0.29039147  || Decoder Loss:  0.086157285 Validation Decoder Loss:  0.36322173
Encoder Loss:  0.28978294  || Decoder Loss:  0.08764401 Validation Decoder Loss:  0.363435
Encoder Loss:  0.28908157  || Decoder Loss:  0.089272305 Validation Decoder Loss:  0.36365482
Encoder Loss:  0.28825393  || Decoder Loss:  0.09107945 Validation Decoder Loss:  0.36390463
Encoder Loss:  0.2872469  || Decoder Loss:  0.093111016 Validation Decoder Loss:  0.36419946
Encoder Loss:  0.28596857  || Decoder Loss:  0.095411226 Validation Decoder Loss:  0.36451393
Encoder Loss:  0.28423238  || Decoder Loss:  0.097956456 Validation Decoder Loss:  0.3646086
Encoder Loss:  0.28151387  || Decoder Loss:  0.100151256 Validation Decoder Loss:  0.36257693
Encoder Loss:  0.27251518  || Decoder Loss:  0.088416174 Validation Decoder Loss:  0.35342965
Encoder Loss:  0.24757391  || Decoder Loss:  0.038794074 Validation Decoder Loss:  0.329159
Encoder Loss:  0.2318278  || Decoder Loss:  0.035855263 Validation Decoder Loss:  0.33031
Encoder Loss:  0.19635747  || Decoder Loss:  0.0356004 Validation Decoder Loss:  0.3321033
Encoder Loss:  0.10053467  || Decoder Loss:  0.03551071 Validation Decoder Loss:  0.33324108
Encoder Loss:  0.080234244  || Decoder Loss:  0.03546127 Validation Decoder Loss:  0.33278298
Encoder Loss:  0.06898675  || Decoder Loss:  0.035429947 Validation Decoder Loss:  0.3327427
Encoder Loss:  0.06970253  || Decoder Loss:  0.03540051 Validation Decoder Loss:  0.33261362
Encoder Loss:  0.06991501  || Decoder Loss:  0.035374388 Validation Decoder Loss:  0.3324595
Encoder Loss:  0.06961679  || Decoder Loss:  0.035350464 Validation Decoder Loss:  0.33230925
Encoder Loss:  0.06918574  || Decoder Loss:  0.035328075 Validation Decoder Loss:  0.33216345
Encoder Loss:  0.0687098  || Decoder Loss:  0.035306644 Validation Decoder Loss:  0.33201873
Encoder Loss:  0.06834394  || Decoder Loss:  0.035286058 Validation Decoder Loss:  0.33187294
Encoder Loss:  0.067998365  || Decoder Loss:  0.035266094 Validation Decoder Loss:  0.33172283
Encoder Loss:  0.06763677  || Decoder Loss:  0.03524675 Validation Decoder Loss:  0.33156914
Encoder Loss:  0.06716041  || Decoder Loss:  0.035228044 Validation Decoder Loss:  0.33142012
Encoder Loss:  0.06669853  || Decoder Loss:  0.035210196 Validation Decoder Loss:  0.33128816
Encoder Loss:  0.06618099  || Decoder Loss:  0.03519333 Validation Decoder Loss:  0.33119285
Encoder Loss:  0.065539025  || Decoder Loss:  0.035177592 Validation Decoder Loss:  0.33115545
Encoder Loss:  0.0648543  || Decoder Loss:  0.03516283 Validation Decoder Loss:  0.33116856
Encoder Loss:  0.063957475  || Decoder Loss:  0.035148755 Validation Decoder Loss:  0.3312024
Encoder Loss:  0.06281762  || Decoder Loss:  0.03513529 Validation Decoder Loss:  0.3312199
Encoder Loss:  0.061192766  || Decoder Loss:  0.03512271 Validation Decoder Loss:  0.33121136
Encoder Loss:  0.05866383  || Decoder Loss:  0.03511134 Validation Decoder Loss:  0.33117568
Encoder Loss:  0.05439052  || Decoder Loss:  0.035101693 Validation Decoder Loss:  0.3311031
Encoder Loss:  0.047615465  || Decoder Loss:  0.035093993 Validation Decoder Loss:  0.33103365
Encoder Loss:  0.045772865  || Decoder Loss:  0.035085358 Validation Decoder Loss:  0.3310503
Encoder Loss:  0.04573422  || Decoder Loss:  0.035076246 Validation Decoder Loss:  0.33104843
Encoder Loss:  0.04571402  || Decoder Loss:  0.035068437 Validation Decoder Loss:  0.33105344
Model: siamese_net_lr_0.0006597696884348545 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33105344
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_221 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_546 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_222 (Conv3D (None, 514, 5, 19, 1)     328       
_________________________________________________________________
reshape_144 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_548 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_473"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_550 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25238076  || Decoder Loss:  0.090332516 Validation Decoder Loss:  0.3710208
Encoder Loss:  0.23933007  || Decoder Loss:  0.08680207 Validation Decoder Loss:  0.32928687
Encoder Loss:  0.11077469  || Decoder Loss:  0.035429962 Validation Decoder Loss:  0.3316881
Encoder Loss:  0.06855277  || Decoder Loss:  0.03528746 Validation Decoder Loss:  0.3310545
Encoder Loss:  0.066871  || Decoder Loss:  0.035197824 Validation Decoder Loss:  0.33081365
Encoder Loss:  0.06444862  || Decoder Loss:  0.035137843 Validation Decoder Loss:  0.3308094
Encoder Loss:  0.060859267  || Decoder Loss:  0.03509573 Validation Decoder Loss:  0.33084604
Encoder Loss:  0.05544925  || Decoder Loss:  0.03507199 Validation Decoder Loss:  0.33087495
Encoder Loss:  0.047325954  || Decoder Loss:  0.035058863 Validation Decoder Loss:  0.3308817
Encoder Loss:  0.04400649  || Decoder Loss:  0.03504916 Validation Decoder Loss:  0.33089155
Encoder Loss:  0.04400367  || Decoder Loss:  0.035039753 Validation Decoder Loss:  0.33089948
Encoder Loss:  0.0439707  || Decoder Loss:  0.035031077 Validation Decoder Loss:  0.3309064
Encoder Loss:  0.043875266  || Decoder Loss:  0.035022736 Validation Decoder Loss:  0.33091268
Encoder Loss:  0.04324959  || Decoder Loss:  0.03501476 Validation Decoder Loss:  0.33091623
Encoder Loss:  0.043068837  || Decoder Loss:  0.03500679 Validation Decoder Loss:  0.33092368
Encoder Loss:  0.043050352  || Decoder Loss:  0.03499904 Validation Decoder Loss:  0.33093202
Encoder Loss:  0.04303799  || Decoder Loss:  0.034991413 Validation Decoder Loss:  0.3309415
Encoder Loss:  0.043028418  || Decoder Loss:  0.034983832 Validation Decoder Loss:  0.3309521
Encoder Loss:  0.0430197  || Decoder Loss:  0.03497635 Validation Decoder Loss:  0.3309642
Encoder Loss:  0.043011617  || Decoder Loss:  0.03496907 Validation Decoder Loss:  0.33097786
Encoder Loss:  0.0430039  || Decoder Loss:  0.03496213 Validation Decoder Loss:  0.33099324
Encoder Loss:  0.042997755  || Decoder Loss:  0.034955814 Validation Decoder Loss:  0.33101004
Encoder Loss:  0.042991105  || Decoder Loss:  0.034950387 Validation Decoder Loss:  0.33102745
Encoder Loss:  0.042991705  || Decoder Loss:  0.03494595 Validation Decoder Loss:  0.33104396
Encoder Loss:  0.042980086  || Decoder Loss:  0.034942504 Validation Decoder Loss:  0.33105838
Encoder Loss:  0.042976018  || Decoder Loss:  0.03493996 Validation Decoder Loss:  0.33107042
Encoder Loss:  0.04297127  || Decoder Loss:  0.034937978 Validation Decoder Loss:  0.33108032
Encoder Loss:  0.042970672  || Decoder Loss:  0.034936406 Validation Decoder Loss:  0.33108965
Encoder Loss:  0.042967778  || Decoder Loss:  0.034934983 Validation Decoder Loss:  0.33109856
Encoder Loss:  0.04296621  || Decoder Loss:  0.034933835 Validation Decoder Loss:  0.33110803
Encoder Loss:  0.042963773  || Decoder Loss:  0.034932703 Validation Decoder Loss:  0.33111775
Encoder Loss:  0.042959183  || Decoder Loss:  0.034931686 Validation Decoder Loss:  0.3311275
Encoder Loss:  0.042968284  || Decoder Loss:  0.034930617 Validation Decoder Loss:  0.33113626
Encoder Loss:  0.042960387  || Decoder Loss:  0.03492957 Validation Decoder Loss:  0.33114457
Encoder Loss:  0.042959947  || Decoder Loss:  0.034928605 Validation Decoder Loss:  0.33115238
Encoder Loss:  0.042953014  || Decoder Loss:  0.034927722 Validation Decoder Loss:  0.33116007
Encoder Loss:  0.042951364  || Decoder Loss:  0.034926835 Validation Decoder Loss:  0.33116767
Encoder Loss:  0.0429527  || Decoder Loss:  0.03492593 Validation Decoder Loss:  0.33117518
Encoder Loss:  0.042953588  || Decoder Loss:  0.03492502 Validation Decoder Loss:  0.33118218
Encoder Loss:  0.04295307  || Decoder Loss:  0.034924164 Validation Decoder Loss:  0.3311895
Model: siamese_net_lr_0.000546164908339134 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33118954
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_224 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_552 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_225 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_145 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_476"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_554 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_556 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20492424  || Decoder Loss:  0.06764089 Validation Decoder Loss:  0.3310759
Encoder Loss:  0.07795837  || Decoder Loss:  0.035325456 Validation Decoder Loss:  0.3308872
Encoder Loss:  0.055771757  || Decoder Loss:  0.03512728 Validation Decoder Loss:  0.33082464
Encoder Loss:  0.05299756  || Decoder Loss:  0.035042927 Validation Decoder Loss:  0.33093965
Encoder Loss:  0.04615476  || Decoder Loss:  0.03500596 Validation Decoder Loss:  0.33108717
Encoder Loss:  0.04268913  || Decoder Loss:  0.034984823 Validation Decoder Loss:  0.33104205
Encoder Loss:  0.041628815  || Decoder Loss:  0.034973323 Validation Decoder Loss:  0.3310429
Encoder Loss:  0.041318234  || Decoder Loss:  0.03496102 Validation Decoder Loss:  0.3310506
Encoder Loss:  0.041296016  || Decoder Loss:  0.03494938 Validation Decoder Loss:  0.3310638
Encoder Loss:  0.041281313  || Decoder Loss:  0.034938812 Validation Decoder Loss:  0.33108306
Encoder Loss:  0.041264944  || Decoder Loss:  0.034929678 Validation Decoder Loss:  0.3311055
Encoder Loss:  0.04126164  || Decoder Loss:  0.034922615 Validation Decoder Loss:  0.33112186
Encoder Loss:  0.041252863  || Decoder Loss:  0.034917492 Validation Decoder Loss:  0.33113247
Encoder Loss:  0.041235995  || Decoder Loss:  0.034913708 Validation Decoder Loss:  0.33114168
Encoder Loss:  0.041232977  || Decoder Loss:  0.03491087 Validation Decoder Loss:  0.33114657
Encoder Loss:  0.041226313  || Decoder Loss:  0.03490876 Validation Decoder Loss:  0.33114895
Encoder Loss:  0.041222602  || Decoder Loss:  0.03490715 Validation Decoder Loss:  0.33115044
Encoder Loss:  0.041226007  || Decoder Loss:  0.034905884 Validation Decoder Loss:  0.33114773
Encoder Loss:  0.04122206  || Decoder Loss:  0.034905016 Validation Decoder Loss:  0.3311446
Encoder Loss:  0.04121735  || Decoder Loss:  0.03490429 Validation Decoder Loss:  0.3311413
Encoder Loss:  0.041216373  || Decoder Loss:  0.034903727 Validation Decoder Loss:  0.33113587
Encoder Loss:  0.0412128  || Decoder Loss:  0.03490329 Validation Decoder Loss:  0.3311291
Encoder Loss:  0.041216776  || Decoder Loss:  0.034903154 Validation Decoder Loss:  0.33111486
Encoder Loss:  0.041220106  || Decoder Loss:  0.034903277 Validation Decoder Loss:  0.33109128
Encoder Loss:  0.041214146  || Decoder Loss:  0.0349038 Validation Decoder Loss:  0.33106825
Encoder Loss:  0.041218452  || Decoder Loss:  0.03490433 Validation Decoder Loss:  0.33102953
Encoder Loss:  0.04121325  || Decoder Loss:  0.034904994 Validation Decoder Loss:  0.33099258
Encoder Loss:  0.041213106  || Decoder Loss:  0.034905657 Validation Decoder Loss:  0.3309464
Encoder Loss:  0.041211773  || Decoder Loss:  0.034906182 Validation Decoder Loss:  0.33089077
Encoder Loss:  0.041211065  || Decoder Loss:  0.034906622 Validation Decoder Loss:  0.3308342
Encoder Loss:  0.041209336  || Decoder Loss:  0.034906577 Validation Decoder Loss:  0.3307675
Encoder Loss:  0.04120995  || Decoder Loss:  0.034906156 Validation Decoder Loss:  0.33070087
Encoder Loss:  0.041206792  || Decoder Loss:  0.03490547 Validation Decoder Loss:  0.33064848
Encoder Loss:  0.041207872  || Decoder Loss:  0.034903973 Validation Decoder Loss:  0.33055454
Encoder Loss:  0.0412039  || Decoder Loss:  0.034901537 Validation Decoder Loss:  0.33048695
Encoder Loss:  0.041200615  || Decoder Loss:  0.03489987 Validation Decoder Loss:  0.3304463
Encoder Loss:  0.04120389  || Decoder Loss:  0.034897782 Validation Decoder Loss:  0.33040524
Encoder Loss:  0.04119803  || Decoder Loss:  0.03489503 Validation Decoder Loss:  0.330325
Encoder Loss:  0.041197777  || Decoder Loss:  0.034892138 Validation Decoder Loss:  0.33028936
Encoder Loss:  0.041194595  || Decoder Loss:  0.03489094 Validation Decoder Loss:  0.33025998
Model: siamese_net_lr_0.0005674332114090787 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33025998
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_227 (Conv3D (None, 414, 5, 19, 1)     100       
_________________________________________________________________
dropout_558 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_228 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_146 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_560 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_562 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07428036  || Decoder Loss:  0.057392888 Validation Decoder Loss:  0.3532388
Encoder Loss:  0.06760991  || Decoder Loss:  0.05063825 Validation Decoder Loss:  0.3287934
Encoder Loss:  0.045888446  || Decoder Loss:  0.035212643 Validation Decoder Loss:  0.33073032
Encoder Loss:  0.038075007  || Decoder Loss:  0.035018492 Validation Decoder Loss:  0.33059752
Encoder Loss:  0.03795989  || Decoder Loss:  0.034967955 Validation Decoder Loss:  0.33051205
Encoder Loss:  0.037906934  || Decoder Loss:  0.034941826 Validation Decoder Loss:  0.33047724
Encoder Loss:  0.037827883  || Decoder Loss:  0.03492384 Validation Decoder Loss:  0.33046693
Encoder Loss:  0.037707426  || Decoder Loss:  0.03490906 Validation Decoder Loss:  0.33047357
Encoder Loss:  0.03709384  || Decoder Loss:  0.03489557 Validation Decoder Loss:  0.33049247
Encoder Loss:  0.035592597  || Decoder Loss:  0.034882683 Validation Decoder Loss:  0.33049318
Encoder Loss:  0.03557843  || Decoder Loss:  0.034870885 Validation Decoder Loss:  0.33048055
Encoder Loss:  0.0355664  || Decoder Loss:  0.034859475 Validation Decoder Loss:  0.3304705
Encoder Loss:  0.0355552  || Decoder Loss:  0.034848396 Validation Decoder Loss:  0.3304636
Encoder Loss:  0.035544474  || Decoder Loss:  0.0348377 Validation Decoder Loss:  0.33046
Encoder Loss:  0.035534725  || Decoder Loss:  0.03482752 Validation Decoder Loss:  0.3304602
Encoder Loss:  0.035525702  || Decoder Loss:  0.034818072 Validation Decoder Loss:  0.33046442
Encoder Loss:  0.03551755  || Decoder Loss:  0.03480956 Validation Decoder Loss:  0.33047247
Encoder Loss:  0.0355104  || Decoder Loss:  0.03480207 Validation Decoder Loss:  0.33048362
Encoder Loss:  0.035504207  || Decoder Loss:  0.034795593 Validation Decoder Loss:  0.3304966
Encoder Loss:  0.035498857  || Decoder Loss:  0.034789994 Validation Decoder Loss:  0.3305101
Encoder Loss:  0.035494156  || Decoder Loss:  0.034785084 Validation Decoder Loss:  0.33052322
Encoder Loss:  0.03548997  || Decoder Loss:  0.034780733 Validation Decoder Loss:  0.3305354
Encoder Loss:  0.035486218  || Decoder Loss:  0.034776796 Validation Decoder Loss:  0.3305466
Encoder Loss:  0.03548278  || Decoder Loss:  0.034773212 Validation Decoder Loss:  0.3305568
Encoder Loss:  0.03547965  || Decoder Loss:  0.034769934 Validation Decoder Loss:  0.33056617
Encoder Loss:  0.035476733  || Decoder Loss:  0.034766883 Validation Decoder Loss:  0.3305747
Encoder Loss:  0.035474017  || Decoder Loss:  0.034764055 Validation Decoder Loss:  0.33058244
Encoder Loss:  0.03547149  || Decoder Loss:  0.0347614 Validation Decoder Loss:  0.3305896
Encoder Loss:  0.035469107  || Decoder Loss:  0.03475891 Validation Decoder Loss:  0.3305962
Encoder Loss:  0.035466865  || Decoder Loss:  0.034756556 Validation Decoder Loss:  0.3306024
Encoder Loss:  0.03546475  || Decoder Loss:  0.03475433 Validation Decoder Loss:  0.33060825
Encoder Loss:  0.03546275  || Decoder Loss:  0.034752235 Validation Decoder Loss:  0.33061385
Encoder Loss:  0.035460837  || Decoder Loss:  0.03475026 Validation Decoder Loss:  0.33061934
Encoder Loss:  0.03545905  || Decoder Loss:  0.034748353 Validation Decoder Loss:  0.33062452
Encoder Loss:  0.035457324  || Decoder Loss:  0.034746572 Validation Decoder Loss:  0.3306294
Encoder Loss:  0.035455678  || Decoder Loss:  0.03474487 Validation Decoder Loss:  0.3306337
Encoder Loss:  0.035454158  || Decoder Loss:  0.034743253 Validation Decoder Loss:  0.3306374
Encoder Loss:  0.03545266  || Decoder Loss:  0.034741722 Validation Decoder Loss:  0.33064055
Encoder Loss:  0.03545127  || Decoder Loss:  0.03474028 Validation Decoder Loss:  0.33064342
Encoder Loss:  0.035449956  || Decoder Loss:  0.03473891 Validation Decoder Loss:  0.3306461
Model: siamese_net_lr_0.0005132624482192873 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306461
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_230 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_564 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_231 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_147 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_566 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_568 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25239086  || Decoder Loss:  0.09380872 Validation Decoder Loss:  0.36936265
Encoder Loss:  0.25225323  || Decoder Loss:  0.097050495 Validation Decoder Loss:  0.37128204
Encoder Loss:  0.25204343  || Decoder Loss:  0.10044736 Validation Decoder Loss:  0.3731612
Encoder Loss:  0.25165322  || Decoder Loss:  0.104048155 Validation Decoder Loss:  0.3749314
Encoder Loss:  0.2481643  || Decoder Loss:  0.10217535 Validation Decoder Loss:  0.3431664
Encoder Loss:  0.21303421  || Decoder Loss:  0.035411924 Validation Decoder Loss:  0.331369
Encoder Loss:  0.20424135  || Decoder Loss:  0.03530323 Validation Decoder Loss:  0.3310267
Encoder Loss:  0.124078795  || Decoder Loss:  0.035413876 Validation Decoder Loss:  0.33150685
Encoder Loss:  0.068058856  || Decoder Loss:  0.03544836 Validation Decoder Loss:  0.33151355
Encoder Loss:  0.067736775  || Decoder Loss:  0.03544885 Validation Decoder Loss:  0.3315224
Encoder Loss:  0.06741743  || Decoder Loss:  0.03544921 Validation Decoder Loss:  0.33153272
Encoder Loss:  0.06711971  || Decoder Loss:  0.03544949 Validation Decoder Loss:  0.3315434
Encoder Loss:  0.06671379  || Decoder Loss:  0.03544967 Validation Decoder Loss:  0.33155733
Encoder Loss:  0.06637111  || Decoder Loss:  0.035449732 Validation Decoder Loss:  0.3315724
Encoder Loss:  0.06592531  || Decoder Loss:  0.03544961 Validation Decoder Loss:  0.3315897
Encoder Loss:  0.06542598  || Decoder Loss:  0.03544937 Validation Decoder Loss:  0.33160996
Encoder Loss:  0.06486725  || Decoder Loss:  0.035448957 Validation Decoder Loss:  0.3316332
Encoder Loss:  0.06415138  || Decoder Loss:  0.035448357 Validation Decoder Loss:  0.33166182
Encoder Loss:  0.063382186  || Decoder Loss:  0.035447516 Validation Decoder Loss:  0.33169466
Encoder Loss:  0.0623766  || Decoder Loss:  0.035446323 Validation Decoder Loss:  0.33173394
Encoder Loss:  0.061096497  || Decoder Loss:  0.035444673 Validation Decoder Loss:  0.33178008
Encoder Loss:  0.059344005  || Decoder Loss:  0.035442468 Validation Decoder Loss:  0.3318335
Encoder Loss:  0.056750607  || Decoder Loss:  0.035439603 Validation Decoder Loss:  0.33189183
Encoder Loss:  0.05286329  || Decoder Loss:  0.035435915 Validation Decoder Loss:  0.33194864
Encoder Loss:  0.047529846  || Decoder Loss:  0.03543078 Validation Decoder Loss:  0.33199012
Encoder Loss:  0.044178076  || Decoder Loss:  0.035425223 Validation Decoder Loss:  0.3320148
Encoder Loss:  0.044120308  || Decoder Loss:  0.035422396 Validation Decoder Loss:  0.33202857
Encoder Loss:  0.043976273  || Decoder Loss:  0.0354197 Validation Decoder Loss:  0.3320434
Encoder Loss:  0.043381117  || Decoder Loss:  0.035416923 Validation Decoder Loss:  0.33205965
Encoder Loss:  0.043179404  || Decoder Loss:  0.035414044 Validation Decoder Loss:  0.33207732
Encoder Loss:  0.04317598  || Decoder Loss:  0.035411015 Validation Decoder Loss:  0.33209848
Encoder Loss:  0.043173805  || Decoder Loss:  0.035407618 Validation Decoder Loss:  0.332126
Encoder Loss:  0.04317222  || Decoder Loss:  0.0354037 Validation Decoder Loss:  0.332164
Encoder Loss:  0.04316958  || Decoder Loss:  0.035399027 Validation Decoder Loss:  0.33221596
Encoder Loss:  0.043166574  || Decoder Loss:  0.03539356 Validation Decoder Loss:  0.33228275
Encoder Loss:  0.04316355  || Decoder Loss:  0.035387594 Validation Decoder Loss:  0.33236063
Encoder Loss:  0.04316027  || Decoder Loss:  0.035381705 Validation Decoder Loss:  0.33244044
Encoder Loss:  0.04315752  || Decoder Loss:  0.035376463 Validation Decoder Loss:  0.3325117
Encoder Loss:  0.043155264  || Decoder Loss:  0.035371978 Validation Decoder Loss:  0.3325686
Encoder Loss:  0.04315288  || Decoder Loss:  0.03536811 Validation Decoder Loss:  0.33261082
Model: siamese_net_lr_0.00019893735245481907 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33261085
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_233 (Conv3D (None, 414, 5, 19, 1)     163       
_________________________________________________________________
dropout_570 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_234 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_148 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_488"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_572 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_574 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08489496  || Decoder Loss:  0.05923888 Validation Decoder Loss:  0.33811462
Encoder Loss:  0.056175712  || Decoder Loss:  0.037815396 Validation Decoder Loss:  0.33068603
Encoder Loss:  0.03933637  || Decoder Loss:  0.03497469 Validation Decoder Loss:  0.33043814
Encoder Loss:  0.039123453  || Decoder Loss:  0.034925994 Validation Decoder Loss:  0.33038706
Encoder Loss:  0.037519883  || Decoder Loss:  0.03489889 Validation Decoder Loss:  0.330446
Encoder Loss:  0.03605703  || Decoder Loss:  0.034877267 Validation Decoder Loss:  0.3304321
Encoder Loss:  0.036021248  || Decoder Loss:  0.034857795 Validation Decoder Loss:  0.33042374
Encoder Loss:  0.03598529  || Decoder Loss:  0.034840155 Validation Decoder Loss:  0.3304217
Encoder Loss:  0.035959113  || Decoder Loss:  0.034824263 Validation Decoder Loss:  0.33042654
Encoder Loss:  0.035916418  || Decoder Loss:  0.034810375 Validation Decoder Loss:  0.33043855
Encoder Loss:  0.03589616  || Decoder Loss:  0.034798805 Validation Decoder Loss:  0.33045667
Encoder Loss:  0.035886303  || Decoder Loss:  0.03478954 Validation Decoder Loss:  0.33047774
Encoder Loss:  0.0358792  || Decoder Loss:  0.034782153 Validation Decoder Loss:  0.33049867
Encoder Loss:  0.035873443  || Decoder Loss:  0.034776103 Validation Decoder Loss:  0.33051735
Encoder Loss:  0.035868652  || Decoder Loss:  0.03477097 Validation Decoder Loss:  0.3305333
Encoder Loss:  0.035864603  || Decoder Loss:  0.034766514 Validation Decoder Loss:  0.33054662
Encoder Loss:  0.03586125  || Decoder Loss:  0.034762587 Validation Decoder Loss:  0.33055788
Encoder Loss:  0.035857547  || Decoder Loss:  0.034759067 Validation Decoder Loss:  0.3305674
Encoder Loss:  0.035854697  || Decoder Loss:  0.034755893 Validation Decoder Loss:  0.33057553
Encoder Loss:  0.035852317  || Decoder Loss:  0.034752995 Validation Decoder Loss:  0.3305826
Encoder Loss:  0.035849392  || Decoder Loss:  0.034750354 Validation Decoder Loss:  0.3305888
Encoder Loss:  0.03584729  || Decoder Loss:  0.034747925 Validation Decoder Loss:  0.33059442
Encoder Loss:  0.035845254  || Decoder Loss:  0.03474569 Validation Decoder Loss:  0.33059955
Encoder Loss:  0.035843268  || Decoder Loss:  0.034743622 Validation Decoder Loss:  0.3306043
Encoder Loss:  0.03584178  || Decoder Loss:  0.03474174 Validation Decoder Loss:  0.3306088
Encoder Loss:  0.035839867  || Decoder Loss:  0.034740005 Validation Decoder Loss:  0.330613
Encoder Loss:  0.035838395  || Decoder Loss:  0.034738373 Validation Decoder Loss:  0.330617
Encoder Loss:  0.035836916  || Decoder Loss:  0.034736875 Validation Decoder Loss:  0.33062094
Encoder Loss:  0.03583575  || Decoder Loss:  0.034735482 Validation Decoder Loss:  0.3306246
Encoder Loss:  0.035834633  || Decoder Loss:  0.0347342 Validation Decoder Loss:  0.33062822
Encoder Loss:  0.03583345  || Decoder Loss:  0.034733 Validation Decoder Loss:  0.3306317
Encoder Loss:  0.035832297  || Decoder Loss:  0.034731865 Validation Decoder Loss:  0.33063504
Encoder Loss:  0.03583127  || Decoder Loss:  0.034730837 Validation Decoder Loss:  0.33063835
Encoder Loss:  0.035830468  || Decoder Loss:  0.03472985 Validation Decoder Loss:  0.3306415
Encoder Loss:  0.0358296  || Decoder Loss:  0.03472896 Validation Decoder Loss:  0.33064455
Encoder Loss:  0.03582897  || Decoder Loss:  0.03472809 Validation Decoder Loss:  0.33064753
Encoder Loss:  0.0358281  || Decoder Loss:  0.034727313 Validation Decoder Loss:  0.33065042
Encoder Loss:  0.03582731  || Decoder Loss:  0.03472656 Validation Decoder Loss:  0.33065325
Encoder Loss:  0.03582668  || Decoder Loss:  0.034725867 Validation Decoder Loss:  0.33065605
Encoder Loss:  0.035825998  || Decoder Loss:  0.034725204 Validation Decoder Loss:  0.3306586
Model: siamese_net_lr_0.0008512298780026012 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306586
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_236 (Conv3D (None, 286, 5, 19, 1)     224       
_________________________________________________________________
dropout_576 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_237 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_149 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_578 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_580 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22751886  || Decoder Loss:  0.06242611 Validation Decoder Loss:  0.33240873
Encoder Loss:  0.058369823  || Decoder Loss:  0.035443436 Validation Decoder Loss:  0.3325094
Encoder Loss:  0.051200002  || Decoder Loss:  0.035420034 Validation Decoder Loss:  0.33255047
Encoder Loss:  0.050916772  || Decoder Loss:  0.035393268 Validation Decoder Loss:  0.33260295
Encoder Loss:  0.04925559  || Decoder Loss:  0.03537228 Validation Decoder Loss:  0.3325542
Encoder Loss:  0.04903589  || Decoder Loss:  0.035353184 Validation Decoder Loss:  0.33264232
Encoder Loss:  0.049014516  || Decoder Loss:  0.035328776 Validation Decoder Loss:  0.3324917
Encoder Loss:  0.04899236  || Decoder Loss:  0.035301525 Validation Decoder Loss:  0.3324117
Encoder Loss:  0.048980027  || Decoder Loss:  0.035283938 Validation Decoder Loss:  0.33259153
Encoder Loss:  0.049000252  || Decoder Loss:  0.035280395 Validation Decoder Loss:  0.33269778
Encoder Loss:  0.04897106  || Decoder Loss:  0.035267524 Validation Decoder Loss:  0.33273393
Encoder Loss:  0.04896951  || Decoder Loss:  0.035249222 Validation Decoder Loss:  0.33325437
Encoder Loss:  0.04897022  || Decoder Loss:  0.03521567 Validation Decoder Loss:  0.33341372
Encoder Loss:  0.04895129  || Decoder Loss:  0.035190895 Validation Decoder Loss:  0.33291313
Encoder Loss:  0.04894586  || Decoder Loss:  0.035152636 Validation Decoder Loss:  0.3332862
Encoder Loss:  0.048924927  || Decoder Loss:  0.03507985 Validation Decoder Loss:  0.33347115
Encoder Loss:  0.048917715  || Decoder Loss:  0.035012115 Validation Decoder Loss:  0.33347967
Encoder Loss:  0.048904303  || Decoder Loss:  0.034920037 Validation Decoder Loss:  0.33346468
Encoder Loss:  0.048896454  || Decoder Loss:  0.03481185 Validation Decoder Loss:  0.33377844
Encoder Loss:  0.04889927  || Decoder Loss:  0.034771256 Validation Decoder Loss:  0.33410257
Encoder Loss:  0.048905794  || Decoder Loss:  0.0347486 Validation Decoder Loss:  0.3341514
Encoder Loss:  0.048902318  || Decoder Loss:  0.03478487 Validation Decoder Loss:  0.3342574
Encoder Loss:  0.048890527  || Decoder Loss:  0.03478502 Validation Decoder Loss:  0.3344351
Encoder Loss:  0.04888631  || Decoder Loss:  0.034753352 Validation Decoder Loss:  0.3343909
Encoder Loss:  0.048894085  || Decoder Loss:  0.034761235 Validation Decoder Loss:  0.33459082
Encoder Loss:  0.048897184  || Decoder Loss:  0.034774385 Validation Decoder Loss:  0.33459413
Encoder Loss:  0.04888504  || Decoder Loss:  0.034777116 Validation Decoder Loss:  0.33467162
Encoder Loss:  0.048887912  || Decoder Loss:  0.03477328 Validation Decoder Loss:  0.33476216
Encoder Loss:  0.04888805  || Decoder Loss:  0.03480319 Validation Decoder Loss:  0.33478934
Encoder Loss:  0.04889149  || Decoder Loss:  0.034788508 Validation Decoder Loss:  0.33490255
Encoder Loss:  0.04888315  || Decoder Loss:  0.03478612 Validation Decoder Loss:  0.33489826
Encoder Loss:  0.04888606  || Decoder Loss:  0.034808975 Validation Decoder Loss:  0.33490646
Encoder Loss:  0.04888482  || Decoder Loss:  0.03482085 Validation Decoder Loss:  0.33483368
Encoder Loss:  0.048880182  || Decoder Loss:  0.034794625 Validation Decoder Loss:  0.33490193
Encoder Loss:  0.048876062  || Decoder Loss:  0.03482326 Validation Decoder Loss:  0.33480084
Encoder Loss:  0.04887764  || Decoder Loss:  0.034840032 Validation Decoder Loss:  0.33467352
Encoder Loss:  0.04887764  || Decoder Loss:  0.034849923 Validation Decoder Loss:  0.3346882
Encoder Loss:  0.048880026  || Decoder Loss:  0.034923423 Validation Decoder Loss:  0.33452865
Encoder Loss:  0.048878506  || Decoder Loss:  0.034906756 Validation Decoder Loss:  0.33461088
Encoder Loss:  0.048877887  || Decoder Loss:  0.03493868 Validation Decoder Loss:  0.3344627
Model: siamese_net_lr_0.0006966715919447235 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3344627
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_239 (Conv3D (None, 284, 5, 19, 1)     33        
_________________________________________________________________
dropout_582 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_240 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_150 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_584 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_586 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20160708  || Decoder Loss:  0.09199072 Validation Decoder Loss:  0.36826468
Encoder Loss:  0.20307365  || Decoder Loss:  0.09679676 Validation Decoder Loss:  0.3705529
Encoder Loss:  0.20430608  || Decoder Loss:  0.10140714 Validation Decoder Loss:  0.3700857
Encoder Loss:  0.16460036  || Decoder Loss:  0.04211528 Validation Decoder Loss:  0.3315541
Encoder Loss:  0.15784578  || Decoder Loss:  0.035240013 Validation Decoder Loss:  0.3314282
Encoder Loss:  0.15457328  || Decoder Loss:  0.035253942 Validation Decoder Loss:  0.331153
Encoder Loss:  0.14747047  || Decoder Loss:  0.035290793 Validation Decoder Loss:  0.33082026
Encoder Loss:  0.06332159  || Decoder Loss:  0.03533398 Validation Decoder Loss:  0.33066913
Encoder Loss:  0.040668987  || Decoder Loss:  0.03533459 Validation Decoder Loss:  0.33069658
Encoder Loss:  0.04066861  || Decoder Loss:  0.035330925 Validation Decoder Loss:  0.33073288
Encoder Loss:  0.040664077  || Decoder Loss:  0.035326995 Validation Decoder Loss:  0.33078033
Encoder Loss:  0.040660217  || Decoder Loss:  0.03532238 Validation Decoder Loss:  0.33084297
Encoder Loss:  0.040654253  || Decoder Loss:  0.035317395 Validation Decoder Loss:  0.33092335
Encoder Loss:  0.0406479  || Decoder Loss:  0.03531223 Validation Decoder Loss:  0.33102217
Encoder Loss:  0.040643927  || Decoder Loss:  0.035306696 Validation Decoder Loss:  0.33113676
Encoder Loss:  0.040638924  || Decoder Loss:  0.035300605 Validation Decoder Loss:  0.33126062
Encoder Loss:  0.04063543  || Decoder Loss:  0.03529445 Validation Decoder Loss:  0.33138597
Encoder Loss:  0.040630575  || Decoder Loss:  0.035288088 Validation Decoder Loss:  0.3315054
Encoder Loss:  0.040626217  || Decoder Loss:  0.03528168 Validation Decoder Loss:  0.33161288
Encoder Loss:  0.04062202  || Decoder Loss:  0.03527513 Validation Decoder Loss:  0.33170474
Encoder Loss:  0.040617734  || Decoder Loss:  0.035268303 Validation Decoder Loss:  0.3317799
Encoder Loss:  0.04061312  || Decoder Loss:  0.035261177 Validation Decoder Loss:  0.33183855
Encoder Loss:  0.040608257  || Decoder Loss:  0.035253495 Validation Decoder Loss:  0.33188283
Encoder Loss:  0.04060298  || Decoder Loss:  0.035245217 Validation Decoder Loss:  0.33191442
Encoder Loss:  0.040597145  || Decoder Loss:  0.03523616 Validation Decoder Loss:  0.33193484
Encoder Loss:  0.040590655  || Decoder Loss:  0.03522609 Validation Decoder Loss:  0.33194605
Encoder Loss:  0.040583376  || Decoder Loss:  0.03521471 Validation Decoder Loss:  0.3319494
Encoder Loss:  0.040575027  || Decoder Loss:  0.035201654 Validation Decoder Loss:  0.33194792
Encoder Loss:  0.040565304  || Decoder Loss:  0.035186365 Validation Decoder Loss:  0.33194625
Encoder Loss:  0.040553745  || Decoder Loss:  0.035168216 Validation Decoder Loss:  0.33195662
Encoder Loss:  0.040539686  || Decoder Loss:  0.03514618 Validation Decoder Loss:  0.33200938
Encoder Loss:  0.04052228  || Decoder Loss:  0.03511884 Validation Decoder Loss:  0.33216512
Encoder Loss:  0.040500406  || Decoder Loss:  0.0350845 Validation Decoder Loss:  0.3324588
Encoder Loss:  0.040472418  || Decoder Loss:  0.03504056 Validation Decoder Loss:  0.33284658
Encoder Loss:  0.04043594  || Decoder Loss:  0.034983303 Validation Decoder Loss:  0.3334654
Encoder Loss:  0.040387567  || Decoder Loss:  0.034907375 Validation Decoder Loss:  0.3344955
Encoder Loss:  0.040323406  || Decoder Loss:  0.034806676 Validation Decoder Loss:  0.33575675
Encoder Loss:  0.04026539  || Decoder Loss:  0.034715537 Validation Decoder Loss:  0.33731624
Encoder Loss:  0.04023969  || Decoder Loss:  0.03467525 Validation Decoder Loss:  0.33807898
Encoder Loss:  0.040228043  || Decoder Loss:  0.03465696 Validation Decoder Loss:  0.33828893
Model: siamese_net_lr_0.00034492549864493746 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3382889
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_242 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_588 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_243 (Conv3D (None, 514, 5, 19, 1)     125       
_________________________________________________________________
reshape_151 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_500"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_590 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_592 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11624543  || Decoder Loss:  0.057610817 Validation Decoder Loss:  0.35483742
Encoder Loss:  0.11636295  || Decoder Loss:  0.058294978 Validation Decoder Loss:  0.35569227
Encoder Loss:  0.115880296  || Decoder Loss:  0.058801338 Validation Decoder Loss:  0.35659522
Encoder Loss:  0.11497412  || Decoder Loss:  0.059205037 Validation Decoder Loss:  0.35715497
Encoder Loss:  0.11375314  || Decoder Loss:  0.05944739 Validation Decoder Loss:  0.3573203
Encoder Loss:  0.11204781  || Decoder Loss:  0.059201304 Validation Decoder Loss:  0.3560151
Encoder Loss:  0.10244072  || Decoder Loss:  0.04957106 Validation Decoder Loss:  0.32875472
Encoder Loss:  0.088620804  || Decoder Loss:  0.03492818 Validation Decoder Loss:  0.32936725
Encoder Loss:  0.08697925  || Decoder Loss:  0.034802143 Validation Decoder Loss:  0.32946366
Encoder Loss:  0.08537735  || Decoder Loss:  0.0347915 Validation Decoder Loss:  0.32948792
Encoder Loss:  0.083632536  || Decoder Loss:  0.03478246 Validation Decoder Loss:  0.32949585
Encoder Loss:  0.0815509  || Decoder Loss:  0.03477466 Validation Decoder Loss:  0.3294927
Encoder Loss:  0.07835065  || Decoder Loss:  0.034769207 Validation Decoder Loss:  0.32947388
Encoder Loss:  0.05767994  || Decoder Loss:  0.03476673 Validation Decoder Loss:  0.3294465
Encoder Loss:  0.03834707  || Decoder Loss:  0.034758665 Validation Decoder Loss:  0.32960075
Encoder Loss:  0.03821977  || Decoder Loss:  0.034746096 Validation Decoder Loss:  0.3297695
Encoder Loss:  0.038211796  || Decoder Loss:  0.034733556 Validation Decoder Loss:  0.32994828
Encoder Loss:  0.038214315  || Decoder Loss:  0.03472109 Validation Decoder Loss:  0.33013695
Encoder Loss:  0.038216833  || Decoder Loss:  0.034708608 Validation Decoder Loss:  0.3303354
Encoder Loss:  0.038105816  || Decoder Loss:  0.03469606 Validation Decoder Loss:  0.3305489
Encoder Loss:  0.038031545  || Decoder Loss:  0.034683518 Validation Decoder Loss:  0.33077502
Encoder Loss:  0.038035933  || Decoder Loss:  0.03467134 Validation Decoder Loss:  0.33101016
Encoder Loss:  0.03797556  || Decoder Loss:  0.034659788 Validation Decoder Loss:  0.3312566
Encoder Loss:  0.037987478  || Decoder Loss:  0.034649014 Validation Decoder Loss:  0.33151004
Encoder Loss:  0.03793213  || Decoder Loss:  0.034639172 Validation Decoder Loss:  0.33177084
Encoder Loss:  0.037946872  || Decoder Loss:  0.034630142 Validation Decoder Loss:  0.3320346
Encoder Loss:  0.037888784  || Decoder Loss:  0.03462191 Validation Decoder Loss:  0.33229887
Encoder Loss:  0.037895333  || Decoder Loss:  0.03461438 Validation Decoder Loss:  0.33256197
Encoder Loss:  0.03785642  || Decoder Loss:  0.034607492 Validation Decoder Loss:  0.33282015
Encoder Loss:  0.03785506  || Decoder Loss:  0.034601178 Validation Decoder Loss:  0.33307368
Encoder Loss:  0.037798394  || Decoder Loss:  0.03459542 Validation Decoder Loss:  0.33331946
Encoder Loss:  0.03777256  || Decoder Loss:  0.034590147 Validation Decoder Loss:  0.33355734
Encoder Loss:  0.0377544  || Decoder Loss:  0.034585383 Validation Decoder Loss:  0.3337851
Encoder Loss:  0.037724856  || Decoder Loss:  0.034581047 Validation Decoder Loss:  0.33400184
Encoder Loss:  0.037708506  || Decoder Loss:  0.034577116 Validation Decoder Loss:  0.33420548
Encoder Loss:  0.037673425  || Decoder Loss:  0.034573536 Validation Decoder Loss:  0.33439752
Encoder Loss:  0.037652805  || Decoder Loss:  0.034570247 Validation Decoder Loss:  0.33457598
Encoder Loss:  0.037629556  || Decoder Loss:  0.034567222 Validation Decoder Loss:  0.3347413
Encoder Loss:  0.037638593  || Decoder Loss:  0.034564406 Validation Decoder Loss:  0.33489108
Encoder Loss:  0.037634145  || Decoder Loss:  0.034561828 Validation Decoder Loss:  0.33502483
Model: siamese_net_lr_0.0005914253281216589 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33502483
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_245 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_594 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_246 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_152 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_596 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_598 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19399205  || Decoder Loss:  0.07338395 Validation Decoder Loss:  0.35472542
Encoder Loss:  0.123433866  || Decoder Loss:  0.041267212 Validation Decoder Loss:  0.33148563
Encoder Loss:  0.05432391  || Decoder Loss:  0.03523212 Validation Decoder Loss:  0.33082658
Encoder Loss:  0.053159617  || Decoder Loss:  0.03512241 Validation Decoder Loss:  0.33079982
Encoder Loss:  0.051768743  || Decoder Loss:  0.03505892 Validation Decoder Loss:  0.33086902
Encoder Loss:  0.049211968  || Decoder Loss:  0.035023462 Validation Decoder Loss:  0.33100584
Encoder Loss:  0.04435398  || Decoder Loss:  0.035000023 Validation Decoder Loss:  0.33108222
Encoder Loss:  0.042077467  || Decoder Loss:  0.034987405 Validation Decoder Loss:  0.3310363
Encoder Loss:  0.041208126  || Decoder Loss:  0.03497961 Validation Decoder Loss:  0.33103243
Encoder Loss:  0.040823504  || Decoder Loss:  0.034970466 Validation Decoder Loss:  0.33103746
Encoder Loss:  0.040526118  || Decoder Loss:  0.03496109 Validation Decoder Loss:  0.33105433
Encoder Loss:  0.040489975  || Decoder Loss:  0.034951925 Validation Decoder Loss:  0.33106908
Encoder Loss:  0.040471844  || Decoder Loss:  0.034943517 Validation Decoder Loss:  0.33107707
Encoder Loss:  0.04046692  || Decoder Loss:  0.034936342 Validation Decoder Loss:  0.33108085
Encoder Loss:  0.040458776  || Decoder Loss:  0.03493025 Validation Decoder Loss:  0.331083
Encoder Loss:  0.04044756  || Decoder Loss:  0.03492528 Validation Decoder Loss:  0.3310839
Encoder Loss:  0.040441178  || Decoder Loss:  0.034921426 Validation Decoder Loss:  0.3310823
Encoder Loss:  0.04043685  || Decoder Loss:  0.034918536 Validation Decoder Loss:  0.33108523
Encoder Loss:  0.040422935  || Decoder Loss:  0.034915872 Validation Decoder Loss:  0.33108854
Encoder Loss:  0.04042223  || Decoder Loss:  0.0349138 Validation Decoder Loss:  0.33109462
Encoder Loss:  0.04041893  || Decoder Loss:  0.03491203 Validation Decoder Loss:  0.33109805
Encoder Loss:  0.040419392  || Decoder Loss:  0.03491061 Validation Decoder Loss:  0.3311072
Encoder Loss:  0.0404117  || Decoder Loss:  0.034909394 Validation Decoder Loss:  0.3311081
Encoder Loss:  0.04041534  || Decoder Loss:  0.034908447 Validation Decoder Loss:  0.3311158
Encoder Loss:  0.04040636  || Decoder Loss:  0.034907214 Validation Decoder Loss:  0.33111584
Encoder Loss:  0.040407732  || Decoder Loss:  0.034906756 Validation Decoder Loss:  0.3311164
Encoder Loss:  0.040402822  || Decoder Loss:  0.03490608 Validation Decoder Loss:  0.33111718
Encoder Loss:  0.040399726  || Decoder Loss:  0.0349053 Validation Decoder Loss:  0.33113682
Encoder Loss:  0.040401384  || Decoder Loss:  0.034904495 Validation Decoder Loss:  0.33113322
Encoder Loss:  0.040400732  || Decoder Loss:  0.034904245 Validation Decoder Loss:  0.33112967
Encoder Loss:  0.040395107  || Decoder Loss:  0.034903787 Validation Decoder Loss:  0.33112073
Encoder Loss:  0.040393066  || Decoder Loss:  0.034903914 Validation Decoder Loss:  0.3311138
Encoder Loss:  0.040394556  || Decoder Loss:  0.034904093 Validation Decoder Loss:  0.33108103
Encoder Loss:  0.040391125  || Decoder Loss:  0.034904476 Validation Decoder Loss:  0.33104828
Encoder Loss:  0.040391017  || Decoder Loss:  0.034904953 Validation Decoder Loss:  0.3310005
Encoder Loss:  0.040390436  || Decoder Loss:  0.034905564 Validation Decoder Loss:  0.3309354
Encoder Loss:  0.04038872  || Decoder Loss:  0.034905836 Validation Decoder Loss:  0.33087158
Encoder Loss:  0.04038795  || Decoder Loss:  0.034905642 Validation Decoder Loss:  0.33079827
Encoder Loss:  0.040387377  || Decoder Loss:  0.034904923 Validation Decoder Loss:  0.33068275
Encoder Loss:  0.040384278  || Decoder Loss:  0.034903634 Validation Decoder Loss:  0.33061752
Model: siamese_net_lr_0.00040919508625906646 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33061752
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_248 (Conv3D (None, 312, 5, 19, 1)     187       
_________________________________________________________________
dropout_600 (Dropout)        (None, 312, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_249 (Conv3D (None, 514, 5, 19, 1)     204       
_________________________________________________________________
reshape_153 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_602 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_604 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15988564  || Decoder Loss:  0.09144757 Validation Decoder Loss:  0.36577743
Encoder Loss:  0.15997125  || Decoder Loss:  0.091603994 Validation Decoder Loss:  0.3658583
Encoder Loss:  0.1600533  || Decoder Loss:  0.09175399 Validation Decoder Loss:  0.36593637
Encoder Loss:  0.16013253  || Decoder Loss:  0.09189884 Validation Decoder Loss:  0.36601198
Encoder Loss:  0.1602093  || Decoder Loss:  0.09203942 Validation Decoder Loss:  0.36608547
Encoder Loss:  0.16028413  || Decoder Loss:  0.09217644 Validation Decoder Loss:  0.36615717
Encoder Loss:  0.16035734  || Decoder Loss:  0.092310555 Validation Decoder Loss:  0.36622742
Encoder Loss:  0.16042921  || Decoder Loss:  0.09244217 Validation Decoder Loss:  0.36629638
Encoder Loss:  0.16050003  || Decoder Loss:  0.09257191 Validation Decoder Loss:  0.36636436
Encoder Loss:  0.16056986  || Decoder Loss:  0.09269997 Validation Decoder Loss:  0.36643153
Encoder Loss:  0.16063893  || Decoder Loss:  0.09282675 Validation Decoder Loss:  0.366498
Encoder Loss:  0.16070746  || Decoder Loss:  0.092952535 Validation Decoder Loss:  0.36656395
Encoder Loss:  0.16077548  || Decoder Loss:  0.093077555 Validation Decoder Loss:  0.36662942
Encoder Loss:  0.16084333  || Decoder Loss:  0.093201965 Validation Decoder Loss:  0.36669463
Encoder Loss:  0.16091076  || Decoder Loss:  0.09332595 Validation Decoder Loss:  0.36675957
Encoder Loss:  0.16097799  || Decoder Loss:  0.093449585 Validation Decoder Loss:  0.36682433
Encoder Loss:  0.16104512  || Decoder Loss:  0.09357302 Validation Decoder Loss:  0.366889
Encoder Loss:  0.16111217  || Decoder Loss:  0.093696415 Validation Decoder Loss:  0.3669536
Encoder Loss:  0.16117918  || Decoder Loss:  0.09381971 Validation Decoder Loss:  0.3670182
Encoder Loss:  0.16124617  || Decoder Loss:  0.09394308 Validation Decoder Loss:  0.36708277
Encoder Loss:  0.16131325  || Decoder Loss:  0.094066545 Validation Decoder Loss:  0.36714745
Encoder Loss:  0.16138029  || Decoder Loss:  0.0941901 Validation Decoder Loss:  0.3672122
Encoder Loss:  0.16144744  || Decoder Loss:  0.09431383 Validation Decoder Loss:  0.3672771
Encoder Loss:  0.16151458  || Decoder Loss:  0.09443773 Validation Decoder Loss:  0.3673421
Encoder Loss:  0.16158186  || Decoder Loss:  0.094561905 Validation Decoder Loss:  0.36740732
Encoder Loss:  0.16164927  || Decoder Loss:  0.09468626 Validation Decoder Loss:  0.36747262
Encoder Loss:  0.16171673  || Decoder Loss:  0.09481096 Validation Decoder Loss:  0.3675382
Encoder Loss:  0.16178444  || Decoder Loss:  0.094935864 Validation Decoder Loss:  0.36760393
Encoder Loss:  0.16185215  || Decoder Loss:  0.095061086 Validation Decoder Loss:  0.3676699
Encoder Loss:  0.16192012  || Decoder Loss:  0.09518654 Validation Decoder Loss:  0.3677361
Encoder Loss:  0.161988  || Decoder Loss:  0.09531235 Validation Decoder Loss:  0.36780256
Encoder Loss:  0.16205622  || Decoder Loss:  0.09543847 Validation Decoder Loss:  0.3678692
Encoder Loss:  0.1621245  || Decoder Loss:  0.09556487 Validation Decoder Loss:  0.36793613
Encoder Loss:  0.16219297  || Decoder Loss:  0.0956917 Validation Decoder Loss:  0.36800325
Encoder Loss:  0.1622616  || Decoder Loss:  0.09581883 Validation Decoder Loss:  0.36807063
Encoder Loss:  0.16233033  || Decoder Loss:  0.095946275 Validation Decoder Loss:  0.36813825
Encoder Loss:  0.1623992  || Decoder Loss:  0.09607404 Validation Decoder Loss:  0.36820614
Encoder Loss:  0.16246831  || Decoder Loss:  0.09620213 Validation Decoder Loss:  0.36827433
Encoder Loss:  0.16253756  || Decoder Loss:  0.09633069 Validation Decoder Loss:  0.36834267
Encoder Loss:  0.16260687  || Decoder Loss:  0.09645954 Validation Decoder Loss:  0.36841133
Model: siamese_net_lr_1.060975349069752e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3684113
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_251 (Conv3D (None, 286, 5, 19, 1)     224       
_________________________________________________________________
dropout_606 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_252 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_154 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_512"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_608 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_610 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.053509455  || Decoder Loss:  0.053509455 Validation Decoder Loss:  0.3360304
Encoder Loss:  0.035251845  || Decoder Loss:  0.035251845 Validation Decoder Loss:  0.33571482
Encoder Loss:  0.035168495  || Decoder Loss:  0.035168495 Validation Decoder Loss:  0.33552384
Encoder Loss:  0.035132144  || Decoder Loss:  0.035132144 Validation Decoder Loss:  0.3358613
Encoder Loss:  0.035110265  || Decoder Loss:  0.035110265 Validation Decoder Loss:  0.33651263
Encoder Loss:  0.03509118  || Decoder Loss:  0.03509118 Validation Decoder Loss:  0.33671242
Encoder Loss:  0.035065427  || Decoder Loss:  0.035065427 Validation Decoder Loss:  0.33706665
Encoder Loss:  0.035012037  || Decoder Loss:  0.035012037 Validation Decoder Loss:  0.33688128
Encoder Loss:  0.034935582  || Decoder Loss:  0.034935582 Validation Decoder Loss:  0.33685338
Encoder Loss:  0.03488407  || Decoder Loss:  0.03488407 Validation Decoder Loss:  0.33694428
Encoder Loss:  0.03486334  || Decoder Loss:  0.03486334 Validation Decoder Loss:  0.3370661
Encoder Loss:  0.0348455  || Decoder Loss:  0.0348455 Validation Decoder Loss:  0.33729178
Encoder Loss:  0.034833  || Decoder Loss:  0.034833 Validation Decoder Loss:  0.33756053
Encoder Loss:  0.03482044  || Decoder Loss:  0.03482044 Validation Decoder Loss:  0.33780766
Encoder Loss:  0.034810126  || Decoder Loss:  0.034810126 Validation Decoder Loss:  0.3380614
Encoder Loss:  0.0348016  || Decoder Loss:  0.0348016 Validation Decoder Loss:  0.33825028
Encoder Loss:  0.034794506  || Decoder Loss:  0.034794506 Validation Decoder Loss:  0.33838844
Encoder Loss:  0.034788333  || Decoder Loss:  0.034788333 Validation Decoder Loss:  0.3384964
Encoder Loss:  0.03478261  || Decoder Loss:  0.03478261 Validation Decoder Loss:  0.33859268
Encoder Loss:  0.034776997  || Decoder Loss:  0.034776997 Validation Decoder Loss:  0.3386885
Encoder Loss:  0.034771297  || Decoder Loss:  0.034771297 Validation Decoder Loss:  0.33878875
Encoder Loss:  0.03476547  || Decoder Loss:  0.03476547 Validation Decoder Loss:  0.33889723
Encoder Loss:  0.034759313  || Decoder Loss:  0.034759313 Validation Decoder Loss:  0.33901638
Encoder Loss:  0.034752857  || Decoder Loss:  0.034752857 Validation Decoder Loss:  0.339149
Encoder Loss:  0.03474604  || Decoder Loss:  0.03474604 Validation Decoder Loss:  0.33929688
Encoder Loss:  0.034738876  || Decoder Loss:  0.034738876 Validation Decoder Loss:  0.33945918
Encoder Loss:  0.03473135  || Decoder Loss:  0.03473135 Validation Decoder Loss:  0.33963272
Encoder Loss:  0.03472354  || Decoder Loss:  0.03472354 Validation Decoder Loss:  0.3398112
Encoder Loss:  0.03471553  || Decoder Loss:  0.03471553 Validation Decoder Loss:  0.3399858
Encoder Loss:  0.034707457  || Decoder Loss:  0.034707457 Validation Decoder Loss:  0.34014636
Encoder Loss:  0.034699466  || Decoder Loss:  0.034699466 Validation Decoder Loss:  0.340284
Encoder Loss:  0.034691714  || Decoder Loss:  0.034691714 Validation Decoder Loss:  0.3403923
Encoder Loss:  0.03468442  || Decoder Loss:  0.03468442 Validation Decoder Loss:  0.34046698
Encoder Loss:  0.03467763  || Decoder Loss:  0.03467763 Validation Decoder Loss:  0.3405038
Encoder Loss:  0.03467143  || Decoder Loss:  0.03467143 Validation Decoder Loss:  0.34049904
Encoder Loss:  0.03466588  || Decoder Loss:  0.03466588 Validation Decoder Loss:  0.3404527
Encoder Loss:  0.03466093  || Decoder Loss:  0.03466093 Validation Decoder Loss:  0.34036946
Encoder Loss:  0.034656562  || Decoder Loss:  0.034656562 Validation Decoder Loss:  0.3402586
Encoder Loss:  0.034652673  || Decoder Loss:  0.034652673 Validation Decoder Loss:  0.3401317
Encoder Loss:  0.03464921  || Decoder Loss:  0.03464921 Validation Decoder Loss:  0.34000027
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34000027
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_254 (Conv3D (None, 400, 5, 19, 1)     23        
_________________________________________________________________
dropout_612 (Dropout)        (None, 400, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_255 (Conv3D (None, 514, 5, 19, 1)     116       
_________________________________________________________________
reshape_155 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_614 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_616 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15658446  || Decoder Loss:  0.061872113 Validation Decoder Loss:  0.36311215
Encoder Loss:  0.15682094  || Decoder Loss:  0.062405292 Validation Decoder Loss:  0.36306065
Encoder Loss:  0.157051  || Decoder Loss:  0.06293247 Validation Decoder Loss:  0.36293328
Encoder Loss:  0.15727343  || Decoder Loss:  0.06345346 Validation Decoder Loss:  0.36273628
Encoder Loss:  0.15748417  || Decoder Loss:  0.063965455 Validation Decoder Loss:  0.36246318
Encoder Loss:  0.15766898  || Decoder Loss:  0.06445182 Validation Decoder Loss:  0.36207712
Encoder Loss:  0.1577762  || Decoder Loss:  0.06484549 Validation Decoder Loss:  0.36140603
Encoder Loss:  0.15741049  || Decoder Loss:  0.06461209 Validation Decoder Loss:  0.35790497
Encoder Loss:  0.14088115  || Decoder Loss:  0.04240911 Validation Decoder Loss:  0.32474613
Encoder Loss:  0.13574152  || Decoder Loss:  0.03572859 Validation Decoder Loss:  0.32510778
Encoder Loss:  0.13541774  || Decoder Loss:  0.035634372 Validation Decoder Loss:  0.32559577
Encoder Loss:  0.13506824  || Decoder Loss:  0.03554973 Validation Decoder Loss:  0.3261817
Encoder Loss:  0.13467889  || Decoder Loss:  0.03547066 Validation Decoder Loss:  0.32681322
Encoder Loss:  0.13423185  || Decoder Loss:  0.035396434 Validation Decoder Loss:  0.32743803
Encoder Loss:  0.13369766  || Decoder Loss:  0.03532753 Validation Decoder Loss:  0.32800436
Encoder Loss:  0.13301755  || Decoder Loss:  0.035265077 Validation Decoder Loss:  0.32847473
Encoder Loss:  0.13204211  || Decoder Loss:  0.035210926 Validation Decoder Loss:  0.3288344
Encoder Loss:  0.13015693  || Decoder Loss:  0.03516729 Validation Decoder Loss:  0.32908714
Encoder Loss:  0.12015566  || Decoder Loss:  0.03513627 Validation Decoder Loss:  0.32925317
Encoder Loss:  0.06141006  || Decoder Loss:  0.03511149 Validation Decoder Loss:  0.32937986
Encoder Loss:  0.039302364  || Decoder Loss:  0.03507651 Validation Decoder Loss:  0.3295041
Encoder Loss:  0.0390134  || Decoder Loss:  0.035040412 Validation Decoder Loss:  0.32962734
Encoder Loss:  0.038987827  || Decoder Loss:  0.035006676 Validation Decoder Loss:  0.32974678
Encoder Loss:  0.038961247  || Decoder Loss:  0.03497564 Validation Decoder Loss:  0.32986104
Encoder Loss:  0.03894428  || Decoder Loss:  0.034947593 Validation Decoder Loss:  0.32997063
Encoder Loss:  0.038925037  || Decoder Loss:  0.03492271 Validation Decoder Loss:  0.33007693
Encoder Loss:  0.038907968  || Decoder Loss:  0.03490089 Validation Decoder Loss:  0.3301819
Encoder Loss:  0.038894277  || Decoder Loss:  0.034881964 Validation Decoder Loss:  0.33028758
Encoder Loss:  0.0388841  || Decoder Loss:  0.03486563 Validation Decoder Loss:  0.3303953
Encoder Loss:  0.038873848  || Decoder Loss:  0.034851544 Validation Decoder Loss:  0.3305062
Encoder Loss:  0.03886573  || Decoder Loss:  0.034839287 Validation Decoder Loss:  0.3306206
Encoder Loss:  0.038855806  || Decoder Loss:  0.034828633 Validation Decoder Loss:  0.33073866
Encoder Loss:  0.038847513  || Decoder Loss:  0.034819156 Validation Decoder Loss:  0.33085984
Encoder Loss:  0.0388418  || Decoder Loss:  0.034810673 Validation Decoder Loss:  0.33098358
Encoder Loss:  0.038838673  || Decoder Loss:  0.03480297 Validation Decoder Loss:  0.33110902
Encoder Loss:  0.038847774  || Decoder Loss:  0.03479601 Validation Decoder Loss:  0.33123565
Encoder Loss:  0.038843505  || Decoder Loss:  0.034789585 Validation Decoder Loss:  0.3313625
Encoder Loss:  0.038824774  || Decoder Loss:  0.034783605 Validation Decoder Loss:  0.3314891
Encoder Loss:  0.03881526  || Decoder Loss:  0.034778018 Validation Decoder Loss:  0.3316147
Encoder Loss:  0.03880993  || Decoder Loss:  0.034772735 Validation Decoder Loss:  0.33173835
Model: siamese_net_lr_0.0002569660259699857 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33173835
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_257 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_618 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_258 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_156 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_620 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_622 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15458278  || Decoder Loss:  0.072251946 Validation Decoder Loss:  0.35922092
Encoder Loss:  0.15335739  || Decoder Loss:  0.07462327 Validation Decoder Loss:  0.3465429
Encoder Loss:  0.10326223  || Decoder Loss:  0.038844626 Validation Decoder Loss:  0.33217016
Encoder Loss:  0.05036163  || Decoder Loss:  0.035299953 Validation Decoder Loss:  0.3310296
Encoder Loss:  0.048141673  || Decoder Loss:  0.035164762 Validation Decoder Loss:  0.33078247
Encoder Loss:  0.047277726  || Decoder Loss:  0.03507897 Validation Decoder Loss:  0.33080387
Encoder Loss:  0.046463203  || Decoder Loss:  0.035029978 Validation Decoder Loss:  0.3308565
Encoder Loss:  0.042913407  || Decoder Loss:  0.035008058 Validation Decoder Loss:  0.33106008
Encoder Loss:  0.040380307  || Decoder Loss:  0.03499105 Validation Decoder Loss:  0.33097804
Encoder Loss:  0.039118316  || Decoder Loss:  0.03498234 Validation Decoder Loss:  0.33098537
Encoder Loss:  0.038847145  || Decoder Loss:  0.034972664 Validation Decoder Loss:  0.331
Encoder Loss:  0.03878341  || Decoder Loss:  0.03496414 Validation Decoder Loss:  0.33099407
Encoder Loss:  0.03873772  || Decoder Loss:  0.034956794 Validation Decoder Loss:  0.3309943
Encoder Loss:  0.038714286  || Decoder Loss:  0.03494985 Validation Decoder Loss:  0.33099636
Encoder Loss:  0.038698245  || Decoder Loss:  0.03494339 Validation Decoder Loss:  0.3309999
Encoder Loss:  0.03867594  || Decoder Loss:  0.034937356 Validation Decoder Loss:  0.33100626
Encoder Loss:  0.0387064  || Decoder Loss:  0.0349322 Validation Decoder Loss:  0.330996
Encoder Loss:  0.03867556  || Decoder Loss:  0.03492763 Validation Decoder Loss:  0.33099625
Encoder Loss:  0.03864779  || Decoder Loss:  0.03492339 Validation Decoder Loss:  0.33100358
Encoder Loss:  0.038659137  || Decoder Loss:  0.034919795 Validation Decoder Loss:  0.33100465
Encoder Loss:  0.038629517  || Decoder Loss:  0.034916755 Validation Decoder Loss:  0.33101434
Encoder Loss:  0.038633335  || Decoder Loss:  0.03491412 Validation Decoder Loss:  0.33102867
Encoder Loss:  0.03862716  || Decoder Loss:  0.034912106 Validation Decoder Loss:  0.3310344
Encoder Loss:  0.03864445  || Decoder Loss:  0.0349106 Validation Decoder Loss:  0.33104602
Encoder Loss:  0.03863508  || Decoder Loss:  0.03490927 Validation Decoder Loss:  0.33104935
Encoder Loss:  0.038608197  || Decoder Loss:  0.034908246 Validation Decoder Loss:  0.33105773
Encoder Loss:  0.0386224  || Decoder Loss:  0.034907397 Validation Decoder Loss:  0.33106393
Encoder Loss:  0.038633537  || Decoder Loss:  0.034906656 Validation Decoder Loss:  0.331077
Encoder Loss:  0.03861406  || Decoder Loss:  0.03490596 Validation Decoder Loss:  0.33108217
Encoder Loss:  0.038611006  || Decoder Loss:  0.03490545 Validation Decoder Loss:  0.33108526
Encoder Loss:  0.038622607  || Decoder Loss:  0.034904957 Validation Decoder Loss:  0.33109534
Encoder Loss:  0.038602177  || Decoder Loss:  0.034904417 Validation Decoder Loss:  0.3311
Encoder Loss:  0.038603164  || Decoder Loss:  0.034903966 Validation Decoder Loss:  0.33110473
Encoder Loss:  0.038597804  || Decoder Loss:  0.034903556 Validation Decoder Loss:  0.33110785
Encoder Loss:  0.038607705  || Decoder Loss:  0.034903184 Validation Decoder Loss:  0.331113
Encoder Loss:  0.03859464  || Decoder Loss:  0.034902826 Validation Decoder Loss:  0.33111277
Encoder Loss:  0.03860371  || Decoder Loss:  0.034902547 Validation Decoder Loss:  0.33111554
Encoder Loss:  0.03860115  || Decoder Loss:  0.034902252 Validation Decoder Loss:  0.33111286
Encoder Loss:  0.038599  || Decoder Loss:  0.034902006 Validation Decoder Loss:  0.3311156
Encoder Loss:  0.03859837  || Decoder Loss:  0.034901846 Validation Decoder Loss:  0.33111244
Model: siamese_net_lr_0.0009758209059113178 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33111244
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_260 (Conv3D (None, 220, 5, 19, 1)     32        
_________________________________________________________________
dropout_624 (Dropout)        (None, 220, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_261 (Conv3D (None, 514, 5, 19, 1)     296       
_________________________________________________________________
reshape_157 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_626 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_628 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37198356  || Decoder Loss:  0.09274344 Validation Decoder Loss:  0.3708577
Encoder Loss:  0.36321828  || Decoder Loss:  0.104138546 Validation Decoder Loss:  0.37877727
Encoder Loss:  0.35212556  || Decoder Loss:  0.10234002 Validation Decoder Loss:  0.35991234
Encoder Loss:  0.3348924  || Decoder Loss:  0.05503225 Validation Decoder Loss:  0.32973406
Encoder Loss:  0.31139863  || Decoder Loss:  0.035732828 Validation Decoder Loss:  0.33104825
Encoder Loss:  0.13728762  || Decoder Loss:  0.035536703 Validation Decoder Loss:  0.33145547
Encoder Loss:  0.04899877  || Decoder Loss:  0.035444483 Validation Decoder Loss:  0.33106878
Encoder Loss:  0.048976358  || Decoder Loss:  0.0353847 Validation Decoder Loss:  0.33076093
Encoder Loss:  0.048973173  || Decoder Loss:  0.035338704 Validation Decoder Loss:  0.3305004
Encoder Loss:  0.048970822  || Decoder Loss:  0.035300575 Validation Decoder Loss:  0.33027387
Encoder Loss:  0.048967987  || Decoder Loss:  0.035267666 Validation Decoder Loss:  0.33007842
Encoder Loss:  0.04896668  || Decoder Loss:  0.035238937 Validation Decoder Loss:  0.32991865
Encoder Loss:  0.048964318  || Decoder Loss:  0.035213597 Validation Decoder Loss:  0.329803
Encoder Loss:  0.048962835  || Decoder Loss:  0.03519057 Validation Decoder Loss:  0.32973576
Encoder Loss:  0.048961293  || Decoder Loss:  0.035168424 Validation Decoder Loss:  0.3297092
Encoder Loss:  0.048959464  || Decoder Loss:  0.035146467 Validation Decoder Loss:  0.32970816
Encoder Loss:  0.048958283  || Decoder Loss:  0.03512543 Validation Decoder Loss:  0.32971922
Encoder Loss:  0.048957  || Decoder Loss:  0.035106715 Validation Decoder Loss:  0.32973486
Encoder Loss:  0.04895581  || Decoder Loss:  0.03509161 Validation Decoder Loss:  0.32975128
Encoder Loss:  0.048955604  || Decoder Loss:  0.035080504 Validation Decoder Loss:  0.32976565
Encoder Loss:  0.04895444  || Decoder Loss:  0.03507276 Validation Decoder Loss:  0.329777
Encoder Loss:  0.048954524  || Decoder Loss:  0.03506724 Validation Decoder Loss:  0.32978517
Encoder Loss:  0.048953824  || Decoder Loss:  0.03506292 Validation Decoder Loss:  0.329791
Encoder Loss:  0.048953366  || Decoder Loss:  0.03505913 Validation Decoder Loss:  0.32979548
Encoder Loss:  0.048953008  || Decoder Loss:  0.03505551 Validation Decoder Loss:  0.32979912
Encoder Loss:  0.048952952  || Decoder Loss:  0.035051912 Validation Decoder Loss:  0.32980263
Encoder Loss:  0.048952505  || Decoder Loss:  0.03504823 Validation Decoder Loss:  0.32980618
Encoder Loss:  0.048951887  || Decoder Loss:  0.035044424 Validation Decoder Loss:  0.3298102
Encoder Loss:  0.04895157  || Decoder Loss:  0.035040412 Validation Decoder Loss:  0.3298149
Encoder Loss:  0.048951253  || Decoder Loss:  0.035036143 Validation Decoder Loss:  0.32982022
Encoder Loss:  0.04895083  || Decoder Loss:  0.035031535 Validation Decoder Loss:  0.32982668
Encoder Loss:  0.04895036  || Decoder Loss:  0.035026465 Validation Decoder Loss:  0.32983434
Encoder Loss:  0.048949953  || Decoder Loss:  0.035020843 Validation Decoder Loss:  0.3298437
Encoder Loss:  0.048949517  || Decoder Loss:  0.03501461 Validation Decoder Loss:  0.3298547
Encoder Loss:  0.048949026  || Decoder Loss:  0.035007905 Validation Decoder Loss:  0.32986754
Encoder Loss:  0.048948545  || Decoder Loss:  0.03500105 Validation Decoder Loss:  0.32988182
Encoder Loss:  0.04894806  || Decoder Loss:  0.03499457 Validation Decoder Loss:  0.3298962
Encoder Loss:  0.04894762  || Decoder Loss:  0.03498871 Validation Decoder Loss:  0.32990944
Encoder Loss:  0.04894723  || Decoder Loss:  0.034983497 Validation Decoder Loss:  0.3299206
Encoder Loss:  0.04894687  || Decoder Loss:  0.034978703 Validation Decoder Loss:  0.32992998
Model: siamese_net_lr_0.0008411714167285317 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32992998
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_263 (Conv3D (None, 416, 5, 19, 1)     102       
_________________________________________________________________
dropout_630 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_264 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_158 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_632 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_634 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06536761  || Decoder Loss:  0.05693558 Validation Decoder Loss:  0.35696763
Encoder Loss:  0.06495726  || Decoder Loss:  0.05655648 Validation Decoder Loss:  0.35194108
Encoder Loss:  0.06209227  || Decoder Loss:  0.053681582 Validation Decoder Loss:  0.3407821
Encoder Loss:  0.05054085  || Decoder Loss:  0.04196966 Validation Decoder Loss:  0.32996374
Encoder Loss:  0.042172227  || Decoder Loss:  0.035136607 Validation Decoder Loss:  0.33090383
Encoder Loss:  0.03667421  || Decoder Loss:  0.035077106 Validation Decoder Loss:  0.33069295
Encoder Loss:  0.036529582  || Decoder Loss:  0.035026044 Validation Decoder Loss:  0.33064565
Encoder Loss:  0.036491975  || Decoder Loss:  0.03499566 Validation Decoder Loss:  0.33059394
Encoder Loss:  0.03646549  || Decoder Loss:  0.034974877 Validation Decoder Loss:  0.33054882
Encoder Loss:  0.036444113  || Decoder Loss:  0.03495969 Validation Decoder Loss:  0.33051527
Encoder Loss:  0.03642459  || Decoder Loss:  0.034947757 Validation Decoder Loss:  0.33049294
Encoder Loss:  0.03640367  || Decoder Loss:  0.034937747 Validation Decoder Loss:  0.33047903
Encoder Loss:  0.036384672  || Decoder Loss:  0.03492891 Validation Decoder Loss:  0.3304705
Encoder Loss:  0.036362484  || Decoder Loss:  0.034920774 Validation Decoder Loss:  0.3304664
Encoder Loss:  0.03633744  || Decoder Loss:  0.034913126 Validation Decoder Loss:  0.33046538
Encoder Loss:  0.036303665  || Decoder Loss:  0.034905773 Validation Decoder Loss:  0.33046693
Encoder Loss:  0.036248695  || Decoder Loss:  0.03489862 Validation Decoder Loss:  0.33047065
Encoder Loss:  0.03565047  || Decoder Loss:  0.034891512 Validation Decoder Loss:  0.33047262
Encoder Loss:  0.035247743  || Decoder Loss:  0.03488433 Validation Decoder Loss:  0.33046424
Encoder Loss:  0.03523662  || Decoder Loss:  0.03487711 Validation Decoder Loss:  0.33045614
Encoder Loss:  0.035228606  || Decoder Loss:  0.034869913 Validation Decoder Loss:  0.33044904
Encoder Loss:  0.035219803  || Decoder Loss:  0.03486271 Validation Decoder Loss:  0.33044302
Encoder Loss:  0.035211906  || Decoder Loss:  0.03485554 Validation Decoder Loss:  0.33043808
Encoder Loss:  0.03520377  || Decoder Loss:  0.03484848 Validation Decoder Loss:  0.3304344
Encoder Loss:  0.035195604  || Decoder Loss:  0.03484156 Validation Decoder Loss:  0.33043236
Encoder Loss:  0.035188347  || Decoder Loss:  0.034834906 Validation Decoder Loss:  0.3304322
Encoder Loss:  0.035181604  || Decoder Loss:  0.03482856 Validation Decoder Loss:  0.33043396
Encoder Loss:  0.03517499  || Decoder Loss:  0.03482262 Validation Decoder Loss:  0.3304376
Encoder Loss:  0.035169113  || Decoder Loss:  0.0348171 Validation Decoder Loss:  0.33044294
Encoder Loss:  0.035164125  || Decoder Loss:  0.03481207 Validation Decoder Loss:  0.33044976
Encoder Loss:  0.03515961  || Decoder Loss:  0.03480749 Validation Decoder Loss:  0.3304575
Encoder Loss:  0.035155315  || Decoder Loss:  0.034803312 Validation Decoder Loss:  0.33046594
Encoder Loss:  0.035151623  || Decoder Loss:  0.034799494 Validation Decoder Loss:  0.33047464
Encoder Loss:  0.03514816  || Decoder Loss:  0.034796044 Validation Decoder Loss:  0.3304833
Encoder Loss:  0.035144895  || Decoder Loss:  0.03479282 Validation Decoder Loss:  0.33049166
Encoder Loss:  0.035141967  || Decoder Loss:  0.03478985 Validation Decoder Loss:  0.33049983
Encoder Loss:  0.03513912  || Decoder Loss:  0.03478705 Validation Decoder Loss:  0.33050755
Encoder Loss:  0.0351366  || Decoder Loss:  0.034784455 Validation Decoder Loss:  0.3305151
Encoder Loss:  0.035134155  || Decoder Loss:  0.03478202 Validation Decoder Loss:  0.33052218
Encoder Loss:  0.03513196  || Decoder Loss:  0.034779705 Validation Decoder Loss:  0.33052891
Model: siamese_net_lr_0.0002806496206585264 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33052891
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_266 (Conv3D (None, 166, 5, 19, 1)     104       
_________________________________________________________________
dropout_636 (Dropout)        (None, 166, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_267 (Conv3D (None, 514, 5, 19, 1)     185       
_________________________________________________________________
reshape_159 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_638 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_640 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3516  || Decoder Loss:  0.08802359 Validation Decoder Loss:  0.3631413
Encoder Loss:  0.3473644  || Decoder Loss:  0.09281457 Validation Decoder Loss:  0.36424887
Encoder Loss:  0.34080374  || Decoder Loss:  0.094491646 Validation Decoder Loss:  0.33189738
Encoder Loss:  0.31990394  || Decoder Loss:  0.03595776 Validation Decoder Loss:  0.33057994
Encoder Loss:  0.2770551  || Decoder Loss:  0.03532222 Validation Decoder Loss:  0.33099416
Encoder Loss:  0.10062294  || Decoder Loss:  0.035252564 Validation Decoder Loss:  0.33121246
Encoder Loss:  0.07836178  || Decoder Loss:  0.03518194 Validation Decoder Loss:  0.33094758
Encoder Loss:  0.077376254  || Decoder Loss:  0.035137903 Validation Decoder Loss:  0.33083838
Encoder Loss:  0.07629495  || Decoder Loss:  0.035109185 Validation Decoder Loss:  0.33081365
Encoder Loss:  0.07503066  || Decoder Loss:  0.035086863 Validation Decoder Loss:  0.33081868
Encoder Loss:  0.07351771  || Decoder Loss:  0.035068836 Validation Decoder Loss:  0.33083895
Encoder Loss:  0.07187521  || Decoder Loss:  0.035053853 Validation Decoder Loss:  0.33086538
Encoder Loss:  0.07001127  || Decoder Loss:  0.035041288 Validation Decoder Loss:  0.33090052
Encoder Loss:  0.06793557  || Decoder Loss:  0.03503089 Validation Decoder Loss:  0.3309418
Encoder Loss:  0.06549325  || Decoder Loss:  0.03502234 Validation Decoder Loss:  0.33099243
Encoder Loss:  0.062478207  || Decoder Loss:  0.035014726 Validation Decoder Loss:  0.33104783
Encoder Loss:  0.05844125  || Decoder Loss:  0.03500739 Validation Decoder Loss:  0.33109665
Encoder Loss:  0.054082833  || Decoder Loss:  0.03499987 Validation Decoder Loss:  0.3311206
Encoder Loss:  0.05208385  || Decoder Loss:  0.034992028 Validation Decoder Loss:  0.3311342
Encoder Loss:  0.050977383  || Decoder Loss:  0.03498415 Validation Decoder Loss:  0.33115208
Encoder Loss:  0.050094463  || Decoder Loss:  0.034975704 Validation Decoder Loss:  0.33117348
Encoder Loss:  0.049365148  || Decoder Loss:  0.034966778 Validation Decoder Loss:  0.3311994
Encoder Loss:  0.04878579  || Decoder Loss:  0.034958035 Validation Decoder Loss:  0.33122706
Encoder Loss:  0.048411403  || Decoder Loss:  0.034949325 Validation Decoder Loss:  0.33125466
Encoder Loss:  0.048255526  || Decoder Loss:  0.034940645 Validation Decoder Loss:  0.33128482
Encoder Loss:  0.048188135  || Decoder Loss:  0.03493202 Validation Decoder Loss:  0.33131787
Encoder Loss:  0.04813792  || Decoder Loss:  0.03492353 Validation Decoder Loss:  0.33135176
Encoder Loss:  0.048107658  || Decoder Loss:  0.03491539 Validation Decoder Loss:  0.33138323
Encoder Loss:  0.04808813  || Decoder Loss:  0.034907773 Validation Decoder Loss:  0.33140963
Encoder Loss:  0.048068732  || Decoder Loss:  0.03490088 Validation Decoder Loss:  0.33143276
Encoder Loss:  0.048050214  || Decoder Loss:  0.034894593 Validation Decoder Loss:  0.33145946
Encoder Loss:  0.048034742  || Decoder Loss:  0.034888666 Validation Decoder Loss:  0.3314933
Encoder Loss:  0.04801769  || Decoder Loss:  0.03488302 Validation Decoder Loss:  0.33153132
Encoder Loss:  0.04800296  || Decoder Loss:  0.03487746 Validation Decoder Loss:  0.33157247
Encoder Loss:  0.047987953  || Decoder Loss:  0.03487198 Validation Decoder Loss:  0.331618
Encoder Loss:  0.04797533  || Decoder Loss:  0.034866437 Validation Decoder Loss:  0.33166972
Encoder Loss:  0.047962636  || Decoder Loss:  0.034860663 Validation Decoder Loss:  0.33173093
Encoder Loss:  0.047953617  || Decoder Loss:  0.03485464 Validation Decoder Loss:  0.3318053
Encoder Loss:  0.047945652  || Decoder Loss:  0.034848392 Validation Decoder Loss:  0.3318946
Encoder Loss:  0.047937933  || Decoder Loss:  0.034841884 Validation Decoder Loss:  0.33199963
Model: siamese_net_lr_0.00016974478444363125 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33199963
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_269 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_642 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_270 (Conv3D (None, 514, 5, 19, 1)     394       
_________________________________________________________________
reshape_160 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_644 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_646 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33900774  || Decoder Loss:  0.07258622 Validation Decoder Loss:  0.3619027
Encoder Loss:  0.3194833  || Decoder Loss:  0.07375491 Validation Decoder Loss:  0.32930073
Encoder Loss:  0.20263086  || Decoder Loss:  0.035465837 Validation Decoder Loss:  0.331803
Encoder Loss:  0.08533714  || Decoder Loss:  0.03534297 Validation Decoder Loss:  0.33126414
Encoder Loss:  0.08301626  || Decoder Loss:  0.035246905 Validation Decoder Loss:  0.33094814
Encoder Loss:  0.080407  || Decoder Loss:  0.03518175 Validation Decoder Loss:  0.33084914
Encoder Loss:  0.07715306  || Decoder Loss:  0.035133738 Validation Decoder Loss:  0.33083597
Encoder Loss:  0.07323503  || Decoder Loss:  0.035099223 Validation Decoder Loss:  0.33084393
Encoder Loss:  0.06828819  || Decoder Loss:  0.0350766 Validation Decoder Loss:  0.33085942
Encoder Loss:  0.058051556  || Decoder Loss:  0.035061263 Validation Decoder Loss:  0.33088094
Encoder Loss:  0.047381856  || Decoder Loss:  0.03505205 Validation Decoder Loss:  0.33088413
Encoder Loss:  0.047026485  || Decoder Loss:  0.035045814 Validation Decoder Loss:  0.33088762
Encoder Loss:  0.04697808  || Decoder Loss:  0.035040446 Validation Decoder Loss:  0.3308996
Encoder Loss:  0.04697507  || Decoder Loss:  0.035035115 Validation Decoder Loss:  0.3309131
Encoder Loss:  0.04696667  || Decoder Loss:  0.035029553 Validation Decoder Loss:  0.3309251
Encoder Loss:  0.046960033  || Decoder Loss:  0.03502383 Validation Decoder Loss:  0.3309347
Encoder Loss:  0.04695105  || Decoder Loss:  0.035017934 Validation Decoder Loss:  0.33094114
Encoder Loss:  0.04695374  || Decoder Loss:  0.035011876 Validation Decoder Loss:  0.33094656
Encoder Loss:  0.046965715  || Decoder Loss:  0.03500546 Validation Decoder Loss:  0.33094925
Encoder Loss:  0.04693856  || Decoder Loss:  0.034998987 Validation Decoder Loss:  0.33095318
Encoder Loss:  0.046934944  || Decoder Loss:  0.034992456 Validation Decoder Loss:  0.33096057
Encoder Loss:  0.046932988  || Decoder Loss:  0.034985613 Validation Decoder Loss:  0.3309698
Encoder Loss:  0.046935286  || Decoder Loss:  0.034978885 Validation Decoder Loss:  0.33098412
Encoder Loss:  0.046922974  || Decoder Loss:  0.034972344 Validation Decoder Loss:  0.33099884
Encoder Loss:  0.04692798  || Decoder Loss:  0.034965876 Validation Decoder Loss:  0.33101547
Encoder Loss:  0.046908706  || Decoder Loss:  0.03495965 Validation Decoder Loss:  0.33103764
Encoder Loss:  0.046899572  || Decoder Loss:  0.034954023 Validation Decoder Loss:  0.33105868
Encoder Loss:  0.046894006  || Decoder Loss:  0.03494903 Validation Decoder Loss:  0.33108008
Encoder Loss:  0.04689927  || Decoder Loss:  0.03494419 Validation Decoder Loss:  0.33110258
Encoder Loss:  0.046880975  || Decoder Loss:  0.03494024 Validation Decoder Loss:  0.33112785
Encoder Loss:  0.04688265  || Decoder Loss:  0.034936372 Validation Decoder Loss:  0.33115757
Encoder Loss:  0.04688077  || Decoder Loss:  0.034932893 Validation Decoder Loss:  0.3311833
Encoder Loss:  0.04687912  || Decoder Loss:  0.03493009 Validation Decoder Loss:  0.3312081
Encoder Loss:  0.046880428  || Decoder Loss:  0.034926698 Validation Decoder Loss:  0.33123934
Encoder Loss:  0.046874613  || Decoder Loss:  0.034923896 Validation Decoder Loss:  0.3312695
Encoder Loss:  0.046869792  || Decoder Loss:  0.034921166 Validation Decoder Loss:  0.3313007
Encoder Loss:  0.046869006  || Decoder Loss:  0.03491875 Validation Decoder Loss:  0.33132452
Encoder Loss:  0.046859857  || Decoder Loss:  0.034916405 Validation Decoder Loss:  0.3313616
Encoder Loss:  0.04685647  || Decoder Loss:  0.034914345 Validation Decoder Loss:  0.3313886
Encoder Loss:  0.04685538  || Decoder Loss:  0.03491256 Validation Decoder Loss:  0.3314116
Model: siamese_net_lr_0.00027459014964816085 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3314116
Model: "sequential_538"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_272 (Conv3D (None, 432, 5, 19, 1)     307       
_________________________________________________________________
dropout_648 (Dropout)        (None, 432, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_273 (Conv3D (None, 514, 5, 19, 1)     84        
_________________________________________________________________
reshape_161 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_650 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_652 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14426403  || Decoder Loss:  0.04747432 Validation Decoder Loss:  0.33012837
Encoder Loss:  0.051205333  || Decoder Loss:  0.035519198 Validation Decoder Loss:  0.33115274
Encoder Loss:  0.041998148  || Decoder Loss:  0.03516552 Validation Decoder Loss:  0.33135623
Encoder Loss:  0.041811623  || Decoder Loss:  0.034974106 Validation Decoder Loss:  0.33208227
Encoder Loss:  0.041623592  || Decoder Loss:  0.03481225 Validation Decoder Loss:  0.3334236
Encoder Loss:  0.0412298  || Decoder Loss:  0.034688238 Validation Decoder Loss:  0.33462837
Encoder Loss:  0.04117846  || Decoder Loss:  0.03465418 Validation Decoder Loss:  0.3348971
Encoder Loss:  0.041165255  || Decoder Loss:  0.034648567 Validation Decoder Loss:  0.33496496
Encoder Loss:  0.0411587  || Decoder Loss:  0.034644224 Validation Decoder Loss:  0.33498988
Encoder Loss:  0.04115384  || Decoder Loss:  0.034640614 Validation Decoder Loss:  0.33500895
Encoder Loss:  0.041151043  || Decoder Loss:  0.034636978 Validation Decoder Loss:  0.3350283
Encoder Loss:  0.04114911  || Decoder Loss:  0.034633588 Validation Decoder Loss:  0.33504155
Encoder Loss:  0.04114726  || Decoder Loss:  0.034630254 Validation Decoder Loss:  0.33505642
Encoder Loss:  0.041145783  || Decoder Loss:  0.034627143 Validation Decoder Loss:  0.33506453
Encoder Loss:  0.04114446  || Decoder Loss:  0.03462484 Validation Decoder Loss:  0.33506656
Encoder Loss:  0.04114373  || Decoder Loss:  0.034623075 Validation Decoder Loss:  0.335069
Encoder Loss:  0.04114366  || Decoder Loss:  0.034622986 Validation Decoder Loss:  0.33505896
Encoder Loss:  0.041144207  || Decoder Loss:  0.03462429 Validation Decoder Loss:  0.33501983
Encoder Loss:  0.04114739  || Decoder Loss:  0.034629144 Validation Decoder Loss:  0.3349874
Encoder Loss:  0.041150182  || Decoder Loss:  0.034634747 Validation Decoder Loss:  0.33494174
Encoder Loss:  0.041154798  || Decoder Loss:  0.034642816 Validation Decoder Loss:  0.3348649
Encoder Loss:  0.041161146  || Decoder Loss:  0.034654424 Validation Decoder Loss:  0.33478612
Encoder Loss:  0.04117017  || Decoder Loss:  0.034670137 Validation Decoder Loss:  0.33468655
Encoder Loss:  0.04118413  || Decoder Loss:  0.034694158 Validation Decoder Loss:  0.3345197
Encoder Loss:  0.041202024  || Decoder Loss:  0.034725912 Validation Decoder Loss:  0.33439133
Encoder Loss:  0.041213375  || Decoder Loss:  0.034745064 Validation Decoder Loss:  0.33431152
Encoder Loss:  0.041230746  || Decoder Loss:  0.034775168 Validation Decoder Loss:  0.3341604
Encoder Loss:  0.04128645  || Decoder Loss:  0.034871742 Validation Decoder Loss:  0.33384633
Encoder Loss:  0.04132559  || Decoder Loss:  0.034940366 Validation Decoder Loss:  0.33355898
Encoder Loss:  0.041330427  || Decoder Loss:  0.03494873 Validation Decoder Loss:  0.33348298
Encoder Loss:  0.041346326  || Decoder Loss:  0.034977123 Validation Decoder Loss:  0.33325842
Encoder Loss:  0.041346278  || Decoder Loss:  0.034977186 Validation Decoder Loss:  0.33320826
Encoder Loss:  0.04135951  || Decoder Loss:  0.035000056 Validation Decoder Loss:  0.3330829
Encoder Loss:  0.041359648  || Decoder Loss:  0.0350004 Validation Decoder Loss:  0.3330835
Encoder Loss:  0.041361026  || Decoder Loss:  0.035002653 Validation Decoder Loss:  0.3328595
Encoder Loss:  0.041359678  || Decoder Loss:  0.035000563 Validation Decoder Loss:  0.33284158
Encoder Loss:  0.04136509  || Decoder Loss:  0.035010133 Validation Decoder Loss:  0.33283892
Encoder Loss:  0.04136487  || Decoder Loss:  0.035008162 Validation Decoder Loss:  0.33262366
Encoder Loss:  0.04136542  || Decoder Loss:  0.03501077 Validation Decoder Loss:  0.33276546
Encoder Loss:  0.04136827  || Decoder Loss:  0.035015788 Validation Decoder Loss:  0.3327225
Model: siamese_net_lr_0.0006263627195656354 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3327225
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_275 (Conv3D (None, 66, 5, 19, 1)      4         
_________________________________________________________________
dropout_654 (Dropout)        (None, 66, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_276 (Conv3D (None, 514, 5, 19, 1)     450       
_________________________________________________________________
reshape_162 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_656 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_658 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27775043  || Decoder Loss:  0.047740564 Validation Decoder Loss:  0.3579353
Encoder Loss:  0.27774346  || Decoder Loss:  0.047792908 Validation Decoder Loss:  0.35776275
Encoder Loss:  0.2777364  || Decoder Loss:  0.04784679 Validation Decoder Loss:  0.35758817
Encoder Loss:  0.27772933  || Decoder Loss:  0.04790069 Validation Decoder Loss:  0.35741216
Encoder Loss:  0.27772224  || Decoder Loss:  0.04795461 Validation Decoder Loss:  0.357235
Encoder Loss:  0.2777152  || Decoder Loss:  0.048008543 Validation Decoder Loss:  0.357057
Encoder Loss:  0.2777082  || Decoder Loss:  0.04806249 Validation Decoder Loss:  0.35687822
Encoder Loss:  0.2777011  || Decoder Loss:  0.048116475 Validation Decoder Loss:  0.3566988
Encoder Loss:  0.27769405  || Decoder Loss:  0.04817046 Validation Decoder Loss:  0.35651886
Encoder Loss:  0.27768704  || Decoder Loss:  0.048224505 Validation Decoder Loss:  0.3563385
Encoder Loss:  0.27768  || Decoder Loss:  0.04827858 Validation Decoder Loss:  0.35615784
Encoder Loss:  0.277673  || Decoder Loss:  0.048332695 Validation Decoder Loss:  0.35597682
Encoder Loss:  0.27766597  || Decoder Loss:  0.048386864 Validation Decoder Loss:  0.35579562
Encoder Loss:  0.27765897  || Decoder Loss:  0.04844111 Validation Decoder Loss:  0.3556142
Encoder Loss:  0.2776519  || Decoder Loss:  0.048495416 Validation Decoder Loss:  0.3554325
Encoder Loss:  0.27764493  || Decoder Loss:  0.04854979 Validation Decoder Loss:  0.35525072
Encoder Loss:  0.27763787  || Decoder Loss:  0.04860423 Validation Decoder Loss:  0.35506874
Encoder Loss:  0.27763087  || Decoder Loss:  0.048658762 Validation Decoder Loss:  0.35488665
Encoder Loss:  0.27762383  || Decoder Loss:  0.048713382 Validation Decoder Loss:  0.35470426
Encoder Loss:  0.27761683  || Decoder Loss:  0.048768107 Validation Decoder Loss:  0.3545218
Encoder Loss:  0.27760974  || Decoder Loss:  0.04882293 Validation Decoder Loss:  0.35433906
Encoder Loss:  0.27760264  || Decoder Loss:  0.048877865 Validation Decoder Loss:  0.35415614
Encoder Loss:  0.2775956  || Decoder Loss:  0.04893291 Validation Decoder Loss:  0.353973
Encoder Loss:  0.27758855  || Decoder Loss:  0.04898808 Validation Decoder Loss:  0.35378963
Encoder Loss:  0.27758145  || Decoder Loss:  0.049043365 Validation Decoder Loss:  0.35360608
Encoder Loss:  0.27757442  || Decoder Loss:  0.0490988 Validation Decoder Loss:  0.35342228
Encoder Loss:  0.27756727  || Decoder Loss:  0.04915438 Validation Decoder Loss:  0.35323822
Encoder Loss:  0.27756017  || Decoder Loss:  0.049210105 Validation Decoder Loss:  0.35305408
Encoder Loss:  0.27755302  || Decoder Loss:  0.049265966 Validation Decoder Loss:  0.35286972
Encoder Loss:  0.27754596  || Decoder Loss:  0.049322005 Validation Decoder Loss:  0.35268527
Encoder Loss:  0.27753875  || Decoder Loss:  0.049378213 Validation Decoder Loss:  0.3525007
Encoder Loss:  0.2775316  || Decoder Loss:  0.04943458 Validation Decoder Loss:  0.35231614
Encoder Loss:  0.2775244  || Decoder Loss:  0.049491122 Validation Decoder Loss:  0.35213155
Encoder Loss:  0.27751723  || Decoder Loss:  0.04954786 Validation Decoder Loss:  0.351947
Encoder Loss:  0.27750993  || Decoder Loss:  0.049604774 Validation Decoder Loss:  0.35176256
Encoder Loss:  0.27750272  || Decoder Loss:  0.049661875 Validation Decoder Loss:  0.35157827
Encoder Loss:  0.2774955  || Decoder Loss:  0.04971917 Validation Decoder Loss:  0.35139418
Encoder Loss:  0.27748817  || Decoder Loss:  0.049776673 Validation Decoder Loss:  0.3512103
Encoder Loss:  0.2774809  || Decoder Loss:  0.049834374 Validation Decoder Loss:  0.35102674
Encoder Loss:  0.2774736  || Decoder Loss:  0.049892288 Validation Decoder Loss:  0.35084355
Model: siamese_net_lr_1.1936934218172515e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35084355
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_278 (Conv3D (None, 112, 5, 19, 1)     50        
_________________________________________________________________
dropout_660 (Dropout)        (None, 112, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_279 (Conv3D (None, 514, 5, 19, 1)     404       
_________________________________________________________________
reshape_163 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_662 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_664 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14973338  || Decoder Loss:  0.061466593 Validation Decoder Loss:  0.3645689
Encoder Loss:  0.1498233  || Decoder Loss:  0.06163716 Validation Decoder Loss:  0.36445704
Encoder Loss:  0.14993073  || Decoder Loss:  0.061841015 Validation Decoder Loss:  0.36433783
Encoder Loss:  0.1500449  || Decoder Loss:  0.062057666 Validation Decoder Loss:  0.36421865
Encoder Loss:  0.1501618  || Decoder Loss:  0.062279467 Validation Decoder Loss:  0.36410165
Encoder Loss:  0.15028027  || Decoder Loss:  0.06250428 Validation Decoder Loss:  0.36398786
Encoder Loss:  0.15040006  || Decoder Loss:  0.06273153 Validation Decoder Loss:  0.36387804
Encoder Loss:  0.1505211  || Decoder Loss:  0.062961146 Validation Decoder Loss:  0.36377287
Encoder Loss:  0.15064338  || Decoder Loss:  0.06319312 Validation Decoder Loss:  0.36367267
Encoder Loss:  0.15076695  || Decoder Loss:  0.0634275 Validation Decoder Loss:  0.3635773
Encoder Loss:  0.15089184  || Decoder Loss:  0.06366433 Validation Decoder Loss:  0.36348668
Encoder Loss:  0.15101804  || Decoder Loss:  0.06390366 Validation Decoder Loss:  0.3634003
Encoder Loss:  0.15114558  || Decoder Loss:  0.0641455 Validation Decoder Loss:  0.3633179
Encoder Loss:  0.15127447  || Decoder Loss:  0.06438991 Validation Decoder Loss:  0.36323923
Encoder Loss:  0.15140477  || Decoder Loss:  0.0646369 Validation Decoder Loss:  0.363164
Encoder Loss:  0.15153642  || Decoder Loss:  0.064886495 Validation Decoder Loss:  0.363092
Encoder Loss:  0.15166947  || Decoder Loss:  0.0651387 Validation Decoder Loss:  0.3630231
Encoder Loss:  0.1518039  || Decoder Loss:  0.065393515 Validation Decoder Loss:  0.3629571
Encoder Loss:  0.15193972  || Decoder Loss:  0.06565096 Validation Decoder Loss:  0.36289388
Encoder Loss:  0.15207694  || Decoder Loss:  0.065911055 Validation Decoder Loss:  0.3628334
Encoder Loss:  0.15221559  || Decoder Loss:  0.06617381 Validation Decoder Loss:  0.3627755
Encoder Loss:  0.15235561  || Decoder Loss:  0.0664392 Validation Decoder Loss:  0.36272007
Encoder Loss:  0.15249705  || Decoder Loss:  0.06670726 Validation Decoder Loss:  0.3626671
Encoder Loss:  0.15263993  || Decoder Loss:  0.06697799 Validation Decoder Loss:  0.36261648
Encoder Loss:  0.15278417  || Decoder Loss:  0.0672514 Validation Decoder Loss:  0.36256814
Encoder Loss:  0.15292984  || Decoder Loss:  0.067527495 Validation Decoder Loss:  0.36252198
Encoder Loss:  0.15307695  || Decoder Loss:  0.06780627 Validation Decoder Loss:  0.36247796
Encoder Loss:  0.15322547  || Decoder Loss:  0.06808776 Validation Decoder Loss:  0.36243606
Encoder Loss:  0.15337542  || Decoder Loss:  0.068371944 Validation Decoder Loss:  0.3623961
Encoder Loss:  0.15352678  || Decoder Loss:  0.06865884 Validation Decoder Loss:  0.3623581
Encoder Loss:  0.1536796  || Decoder Loss:  0.06894848 Validation Decoder Loss:  0.36232197
Encoder Loss:  0.1538338  || Decoder Loss:  0.069240846 Validation Decoder Loss:  0.36228767
Encoder Loss:  0.15398946  || Decoder Loss:  0.069535956 Validation Decoder Loss:  0.36225516
Encoder Loss:  0.15414658  || Decoder Loss:  0.06983381 Validation Decoder Loss:  0.36222434
Encoder Loss:  0.15430516  || Decoder Loss:  0.070134446 Validation Decoder Loss:  0.3621952
Encoder Loss:  0.15446517  || Decoder Loss:  0.070437856 Validation Decoder Loss:  0.36216772
Encoder Loss:  0.15462664  || Decoder Loss:  0.07074406 Validation Decoder Loss:  0.36214188
Encoder Loss:  0.15478958  || Decoder Loss:  0.071053095 Validation Decoder Loss:  0.36211765
Encoder Loss:  0.15495397  || Decoder Loss:  0.07136493 Validation Decoder Loss:  0.3620951
Encoder Loss:  0.15511987  || Decoder Loss:  0.0716796 Validation Decoder Loss:  0.36207417
Model: siamese_net_lr_0.00010955132172136378 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36207417
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_281 (Conv3D (None, 354, 5, 19, 1)     292       
_________________________________________________________________
dropout_666 (Dropout)        (None, 354, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_282 (Conv3D (None, 514, 5, 19, 1)     162       
_________________________________________________________________
reshape_164 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_668 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_670 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33963627  || Decoder Loss:  0.08075336 Validation Decoder Loss:  0.36253467
Encoder Loss:  0.3388574  || Decoder Loss:  0.081914425 Validation Decoder Loss:  0.36289054
Encoder Loss:  0.3379432  || Decoder Loss:  0.08324906 Validation Decoder Loss:  0.36320227
Encoder Loss:  0.33693507  || Decoder Loss:  0.0846837 Validation Decoder Loss:  0.36347777
Encoder Loss:  0.33581445  || Decoder Loss:  0.086234026 Validation Decoder Loss:  0.36373857
Encoder Loss:  0.33454853  || Decoder Loss:  0.087929726 Validation Decoder Loss:  0.3640074
Encoder Loss:  0.3330906  || Decoder Loss:  0.08980989 Validation Decoder Loss:  0.36430705
Encoder Loss:  0.3313709  || Decoder Loss:  0.09192493 Validation Decoder Loss:  0.36465758
Encoder Loss:  0.32927865  || Decoder Loss:  0.0943346 Validation Decoder Loss:  0.36506075
Encoder Loss:  0.32662266  || Decoder Loss:  0.09707778 Validation Decoder Loss:  0.3654106
Encoder Loss:  0.3230171  || Decoder Loss:  0.09994523 Validation Decoder Loss:  0.36486262
Encoder Loss:  0.31716692  || Decoder Loss:  0.09963951 Validation Decoder Loss:  0.35072517
Encoder Loss:  0.29896447  || Decoder Loss:  0.051365558 Validation Decoder Loss:  0.33991316
Encoder Loss:  0.28087312  || Decoder Loss:  0.036143795 Validation Decoder Loss:  0.3300661
Encoder Loss:  0.24958761  || Decoder Loss:  0.035651486 Validation Decoder Loss:  0.33245003
Encoder Loss:  0.16999608  || Decoder Loss:  0.03555407 Validation Decoder Loss:  0.3328709
Encoder Loss:  0.07699564  || Decoder Loss:  0.03548784 Validation Decoder Loss:  0.33299357
Encoder Loss:  0.07344586  || Decoder Loss:  0.035453968 Validation Decoder Loss:  0.33310854
Encoder Loss:  0.07429285  || Decoder Loss:  0.03542427 Validation Decoder Loss:  0.3330726
Encoder Loss:  0.07552564  || Decoder Loss:  0.03539775 Validation Decoder Loss:  0.33294162
Encoder Loss:  0.07520016  || Decoder Loss:  0.03537352 Validation Decoder Loss:  0.3328009
Encoder Loss:  0.07403629  || Decoder Loss:  0.03535152 Validation Decoder Loss:  0.33268273
Encoder Loss:  0.073438875  || Decoder Loss:  0.035330523 Validation Decoder Loss:  0.33256263
Encoder Loss:  0.072924614  || Decoder Loss:  0.035310537 Validation Decoder Loss:  0.33244085
Encoder Loss:  0.07237835  || Decoder Loss:  0.03529127 Validation Decoder Loss:  0.33232275
Encoder Loss:  0.0718446  || Decoder Loss:  0.0352726 Validation Decoder Loss:  0.33220387
Encoder Loss:  0.07130749  || Decoder Loss:  0.035254344 Validation Decoder Loss:  0.33207947
Encoder Loss:  0.07073534  || Decoder Loss:  0.035236612 Validation Decoder Loss:  0.3319484
Encoder Loss:  0.07007302  || Decoder Loss:  0.03521942 Validation Decoder Loss:  0.3318108
Encoder Loss:  0.06935734  || Decoder Loss:  0.035202954 Validation Decoder Loss:  0.33166873
Encoder Loss:  0.06858766  || Decoder Loss:  0.03518728 Validation Decoder Loss:  0.3315292
Encoder Loss:  0.06773972  || Decoder Loss:  0.0351725 Validation Decoder Loss:  0.3314095
Encoder Loss:  0.066758595  || Decoder Loss:  0.035158705 Validation Decoder Loss:  0.33133596
Encoder Loss:  0.06559632  || Decoder Loss:  0.035145815 Validation Decoder Loss:  0.3313192
Encoder Loss:  0.06408004  || Decoder Loss:  0.035133723 Validation Decoder Loss:  0.33133858
Encoder Loss:  0.06211117  || Decoder Loss:  0.035122417 Validation Decoder Loss:  0.33133805
Encoder Loss:  0.05934385  || Decoder Loss:  0.035112206 Validation Decoder Loss:  0.3312925
Encoder Loss:  0.05499737  || Decoder Loss:  0.035103586 Validation Decoder Loss:  0.33121234
Encoder Loss:  0.049274288  || Decoder Loss:  0.035096366 Validation Decoder Loss:  0.3311381
Encoder Loss:  0.048189625  || Decoder Loss:  0.03508678 Validation Decoder Loss:  0.3311466
Model: siamese_net_lr_0.0006368910736187381 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3311466
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_284 (Conv3D (None, 414, 5, 19, 1)     226       
_________________________________________________________________
dropout_672 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_285 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_165 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_674 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_676 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10184308  || Decoder Loss:  0.062051434 Validation Decoder Loss:  0.3483262
Encoder Loss:  0.09024994  || Decoder Loss:  0.050697014 Validation Decoder Loss:  0.3302365
Encoder Loss:  0.055868436  || Decoder Loss:  0.035087377 Validation Decoder Loss:  0.3307664
Encoder Loss:  0.04122528  || Decoder Loss:  0.034972783 Validation Decoder Loss:  0.33058602
Encoder Loss:  0.0410863  || Decoder Loss:  0.03493573 Validation Decoder Loss:  0.33049166
Encoder Loss:  0.040890485  || Decoder Loss:  0.034913912 Validation Decoder Loss:  0.3304349
Encoder Loss:  0.04004036  || Decoder Loss:  0.034896106 Validation Decoder Loss:  0.33044782
Encoder Loss:  0.03679295  || Decoder Loss:  0.034880124 Validation Decoder Loss:  0.33046284
Encoder Loss:  0.036671154  || Decoder Loss:  0.03486637 Validation Decoder Loss:  0.3304559
Encoder Loss:  0.03664866  || Decoder Loss:  0.03485382 Validation Decoder Loss:  0.33044827
Encoder Loss:  0.036630835  || Decoder Loss:  0.034841917 Validation Decoder Loss:  0.33044338
Encoder Loss:  0.03661077  || Decoder Loss:  0.034830566 Validation Decoder Loss:  0.33044025
Encoder Loss:  0.03659229  || Decoder Loss:  0.03481987 Validation Decoder Loss:  0.3304405
Encoder Loss:  0.036578566  || Decoder Loss:  0.034810055 Validation Decoder Loss:  0.33044398
Encoder Loss:  0.036563408  || Decoder Loss:  0.03480135 Validation Decoder Loss:  0.33045146
Encoder Loss:  0.036531948  || Decoder Loss:  0.03479389 Validation Decoder Loss:  0.3304627
Encoder Loss:  0.036516123  || Decoder Loss:  0.034787606 Validation Decoder Loss:  0.33047682
Encoder Loss:  0.036507443  || Decoder Loss:  0.03478234 Validation Decoder Loss:  0.33049193
Encoder Loss:  0.036501523  || Decoder Loss:  0.03477785 Validation Decoder Loss:  0.33050615
Encoder Loss:  0.036496997  || Decoder Loss:  0.03477395 Validation Decoder Loss:  0.33051956
Encoder Loss:  0.036493264  || Decoder Loss:  0.034770496 Validation Decoder Loss:  0.33053133
Encoder Loss:  0.03649014  || Decoder Loss:  0.03476741 Validation Decoder Loss:  0.33054167
Encoder Loss:  0.03648739  || Decoder Loss:  0.03476461 Validation Decoder Loss:  0.33055085
Encoder Loss:  0.036484852  || Decoder Loss:  0.03476204 Validation Decoder Loss:  0.33055893
Encoder Loss:  0.036482543  || Decoder Loss:  0.034759652 Validation Decoder Loss:  0.33056605
Encoder Loss:  0.03648039  || Decoder Loss:  0.03475744 Validation Decoder Loss:  0.3305725
Encoder Loss:  0.036478397  || Decoder Loss:  0.03475538 Validation Decoder Loss:  0.3305782
Encoder Loss:  0.036476508  || Decoder Loss:  0.034753446 Validation Decoder Loss:  0.33058333
Encoder Loss:  0.036474727  || Decoder Loss:  0.034751613 Validation Decoder Loss:  0.33058804
Encoder Loss:  0.03647304  || Decoder Loss:  0.034749884 Validation Decoder Loss:  0.33059233
Encoder Loss:  0.0364714  || Decoder Loss:  0.03474825 Validation Decoder Loss:  0.3305963
Encoder Loss:  0.0364699  || Decoder Loss:  0.034746677 Validation Decoder Loss:  0.3306
Encoder Loss:  0.03646855  || Decoder Loss:  0.034745213 Validation Decoder Loss:  0.33060357
Encoder Loss:  0.036467288  || Decoder Loss:  0.034743793 Validation Decoder Loss:  0.33060694
Encoder Loss:  0.03646611  || Decoder Loss:  0.034742463 Validation Decoder Loss:  0.33061016
Encoder Loss:  0.036464978  || Decoder Loss:  0.034741193 Validation Decoder Loss:  0.33061326
Encoder Loss:  0.036463905  || Decoder Loss:  0.03473996 Validation Decoder Loss:  0.33061624
Encoder Loss:  0.036462877  || Decoder Loss:  0.034738813 Validation Decoder Loss:  0.33061913
Encoder Loss:  0.036461886  || Decoder Loss:  0.034737702 Validation Decoder Loss:  0.33062202
Encoder Loss:  0.03646092  || Decoder Loss:  0.034736644 Validation Decoder Loss:  0.3306248
Model: siamese_net_lr_0.000587576666846711 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306248
Model: "sequential_558"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_287 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_678 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_288 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_166 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_680 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_682 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752063
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752063
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.09234667 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752063
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752063
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.09234666 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.3675206
Encoder Loss:  0.38434833  || Decoder Loss:  0.092346646 Validation Decoder Loss:  0.36752057
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3675206
Model: "sequential_562"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_290 (Conv3D (None, 286, 5, 19, 1)     35        
_________________________________________________________________
dropout_684 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_291 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_167 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_686 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_688 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34661213  || Decoder Loss:  0.07162453 Validation Decoder Loss:  0.33427045
Encoder Loss:  0.1120789  || Decoder Loss:  0.0354083 Validation Decoder Loss:  0.33200026
Encoder Loss:  0.048415083  || Decoder Loss:  0.035435453 Validation Decoder Loss:  0.33217373
Encoder Loss:  0.04837729  || Decoder Loss:  0.035418436 Validation Decoder Loss:  0.33212593
Encoder Loss:  0.048361417  || Decoder Loss:  0.035402462 Validation Decoder Loss:  0.3321036
Encoder Loss:  0.048350897  || Decoder Loss:  0.03538878 Validation Decoder Loss:  0.33212933
Encoder Loss:  0.04834497  || Decoder Loss:  0.03537809 Validation Decoder Loss:  0.3321659
Encoder Loss:  0.04834158  || Decoder Loss:  0.035368834 Validation Decoder Loss:  0.332152
Encoder Loss:  0.048335508  || Decoder Loss:  0.03535914 Validation Decoder Loss:  0.33205593
Encoder Loss:  0.048334375  || Decoder Loss:  0.03534889 Validation Decoder Loss:  0.33190107
Encoder Loss:  0.048333853  || Decoder Loss:  0.03533787 Validation Decoder Loss:  0.33174753
Encoder Loss:  0.048328158  || Decoder Loss:  0.03532349 Validation Decoder Loss:  0.33160755
Encoder Loss:  0.04832351  || Decoder Loss:  0.03530278 Validation Decoder Loss:  0.33144775
Encoder Loss:  0.048399504  || Decoder Loss:  0.035325147 Validation Decoder Loss:  0.33164746
Encoder Loss:  0.04832516  || Decoder Loss:  0.035302676 Validation Decoder Loss:  0.3314504
Encoder Loss:  0.048320726  || Decoder Loss:  0.035261974 Validation Decoder Loss:  0.33204228
Encoder Loss:  0.048313122  || Decoder Loss:  0.03520755 Validation Decoder Loss:  0.33194852
Encoder Loss:  0.048310876  || Decoder Loss:  0.03516797 Validation Decoder Loss:  0.33205646
Encoder Loss:  0.0483048  || Decoder Loss:  0.035130266 Validation Decoder Loss:  0.33214343
Encoder Loss:  0.04831975  || Decoder Loss:  0.03513481 Validation Decoder Loss:  0.33206484
Encoder Loss:  0.04831237  || Decoder Loss:  0.035160746 Validation Decoder Loss:  0.33209705
Encoder Loss:  0.048304323  || Decoder Loss:  0.035125192 Validation Decoder Loss:  0.33223444
Encoder Loss:  0.04833604  || Decoder Loss:  0.035220012 Validation Decoder Loss:  0.33218503
Encoder Loss:  0.048326157  || Decoder Loss:  0.03522176 Validation Decoder Loss:  0.33234492
Encoder Loss:  0.04831543  || Decoder Loss:  0.035180956 Validation Decoder Loss:  0.33231157
Encoder Loss:  0.048308887  || Decoder Loss:  0.0351369 Validation Decoder Loss:  0.33234245
Encoder Loss:  0.048302785  || Decoder Loss:  0.035098273 Validation Decoder Loss:  0.33236548
Encoder Loss:  0.048309535  || Decoder Loss:  0.0351088 Validation Decoder Loss:  0.33257958
Encoder Loss:  0.048304614  || Decoder Loss:  0.035089683 Validation Decoder Loss:  0.3326015
Encoder Loss:  0.04829797  || Decoder Loss:  0.03504427 Validation Decoder Loss:  0.332618
Encoder Loss:  0.048300993  || Decoder Loss:  0.035033677 Validation Decoder Loss:  0.3327391
Encoder Loss:  0.048300058  || Decoder Loss:  0.03501437 Validation Decoder Loss:  0.3328387
Encoder Loss:  0.048293006  || Decoder Loss:  0.034985777 Validation Decoder Loss:  0.33284527
Encoder Loss:  0.048295315  || Decoder Loss:  0.034984514 Validation Decoder Loss:  0.33297074
Encoder Loss:  0.04829103  || Decoder Loss:  0.034958836 Validation Decoder Loss:  0.33299193
Encoder Loss:  0.048287783  || Decoder Loss:  0.034947306 Validation Decoder Loss:  0.3330208
Encoder Loss:  0.048285227  || Decoder Loss:  0.034927797 Validation Decoder Loss:  0.3329931
Encoder Loss:  0.048285212  || Decoder Loss:  0.03491666 Validation Decoder Loss:  0.3329937
Encoder Loss:  0.048287187  || Decoder Loss:  0.034907233 Validation Decoder Loss:  0.3329393
Encoder Loss:  0.048285387  || Decoder Loss:  0.034919202 Validation Decoder Loss:  0.3329764
Model: siamese_net_lr_0.0009932879697018364 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33297637
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_293 (Conv3D (None, 348, 5, 19, 1)     97        
_________________________________________________________________
dropout_690 (Dropout)        (None, 348, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_294 (Conv3D (None, 514, 5, 19, 1)     168       
_________________________________________________________________
reshape_168 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_692 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_569"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_694 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38551566  || Decoder Loss:  0.079506785 Validation Decoder Loss:  0.36073238
Encoder Loss:  0.3848302  || Decoder Loss:  0.08028425 Validation Decoder Loss:  0.360936
Encoder Loss:  0.38404194  || Decoder Loss:  0.081163846 Validation Decoder Loss:  0.3610586
Encoder Loss:  0.38319346  || Decoder Loss:  0.08209126 Validation Decoder Loss:  0.36109692
Encoder Loss:  0.38227284  || Decoder Loss:  0.0830741 Validation Decoder Loss:  0.36105198
Encoder Loss:  0.3812569  || Decoder Loss:  0.08412914 Validation Decoder Loss:  0.3609196
Encoder Loss:  0.38011238  || Decoder Loss:  0.08527876 Validation Decoder Loss:  0.36069998
Encoder Loss:  0.3787868  || Decoder Loss:  0.08655351 Validation Decoder Loss:  0.36040413
Encoder Loss:  0.37719253  || Decoder Loss:  0.087995894 Validation Decoder Loss:  0.36005223
Encoder Loss:  0.3751667  || Decoder Loss:  0.08966282 Validation Decoder Loss:  0.35967943
Encoder Loss:  0.3723642  || Decoder Loss:  0.09160167 Validation Decoder Loss:  0.35924724
Encoder Loss:  0.36788917  || Decoder Loss:  0.093515374 Validation Decoder Loss:  0.3576383
Encoder Loss:  0.3583341  || Decoder Loss:  0.08847677 Validation Decoder Loss:  0.33550113
Encoder Loss:  0.3237766  || Decoder Loss:  0.04387186 Validation Decoder Loss:  0.33321726
Encoder Loss:  0.15056726  || Decoder Loss:  0.03582738 Validation Decoder Loss:  0.33127227
Encoder Loss:  0.101078235  || Decoder Loss:  0.035564367 Validation Decoder Loss:  0.33165473
Encoder Loss:  0.101822436  || Decoder Loss:  0.03552584 Validation Decoder Loss:  0.331892
Encoder Loss:  0.10460417  || Decoder Loss:  0.03550959 Validation Decoder Loss:  0.3320217
Encoder Loss:  0.10082814  || Decoder Loss:  0.035501998 Validation Decoder Loss:  0.33210897
Encoder Loss:  0.09891303  || Decoder Loss:  0.03549731 Validation Decoder Loss:  0.33217305
Encoder Loss:  0.09871105  || Decoder Loss:  0.035494126 Validation Decoder Loss:  0.33221745
Encoder Loss:  0.09829668  || Decoder Loss:  0.035491366 Validation Decoder Loss:  0.33225405
Encoder Loss:  0.09686929  || Decoder Loss:  0.035488844 Validation Decoder Loss:  0.3322847
Encoder Loss:  0.096663624  || Decoder Loss:  0.03548655 Validation Decoder Loss:  0.3323111
Encoder Loss:  0.09651248  || Decoder Loss:  0.035484225 Validation Decoder Loss:  0.33233264
Encoder Loss:  0.09562173  || Decoder Loss:  0.03548179 Validation Decoder Loss:  0.3323506
Encoder Loss:  0.0950066  || Decoder Loss:  0.035479464 Validation Decoder Loss:  0.33236617
Encoder Loss:  0.09429895  || Decoder Loss:  0.035477147 Validation Decoder Loss:  0.33238116
Encoder Loss:  0.09351542  || Decoder Loss:  0.035474893 Validation Decoder Loss:  0.33239797
Encoder Loss:  0.092689455  || Decoder Loss:  0.03547284 Validation Decoder Loss:  0.3324185
Encoder Loss:  0.09160903  || Decoder Loss:  0.03547055 Validation Decoder Loss:  0.33244526
Encoder Loss:  0.090655014  || Decoder Loss:  0.035468273 Validation Decoder Loss:  0.3324755
Encoder Loss:  0.088992685  || Decoder Loss:  0.035465796 Validation Decoder Loss:  0.33250913
Encoder Loss:  0.08755836  || Decoder Loss:  0.035462905 Validation Decoder Loss:  0.33254302
Encoder Loss:  0.08465146  || Decoder Loss:  0.035459254 Validation Decoder Loss:  0.33257788
Encoder Loss:  0.08075388  || Decoder Loss:  0.035454653 Validation Decoder Loss:  0.33261046
Encoder Loss:  0.07389096  || Decoder Loss:  0.0354482 Validation Decoder Loss:  0.33263385
Encoder Loss:  0.061143313  || Decoder Loss:  0.035437852 Validation Decoder Loss:  0.33263725
Encoder Loss:  0.050742965  || Decoder Loss:  0.035425622 Validation Decoder Loss:  0.33274984
Encoder Loss:  0.050094128  || Decoder Loss:  0.035419594 Validation Decoder Loss:  0.3327981
Model: siamese_net_lr_0.000636620954946841 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33279806
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_296 (Conv3D (None, 220, 5, 19, 1)     32        
_________________________________________________________________
dropout_696 (Dropout)        (None, 220, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_297 (Conv3D (None, 514, 5, 19, 1)     77        
_________________________________________________________________
reshape_169 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 109
Trainable params: 109
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_698 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_700 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29370275  || Decoder Loss:  0.050024975 Validation Decoder Loss:  0.35837162
Encoder Loss:  0.27979442  || Decoder Loss:  0.05025383 Validation Decoder Loss:  0.35958695
Encoder Loss:  0.25073007  || Decoder Loss:  0.042806197 Validation Decoder Loss:  0.33285534
Encoder Loss:  0.2201445  || Decoder Loss:  0.03499434 Validation Decoder Loss:  0.3319713
Encoder Loss:  0.18903145  || Decoder Loss:  0.03483827 Validation Decoder Loss:  0.3313256
Encoder Loss:  0.09311778  || Decoder Loss:  0.034699634 Validation Decoder Loss:  0.33080792
Encoder Loss:  0.04528924  || Decoder Loss:  0.034573637 Validation Decoder Loss:  0.33091602
Encoder Loss:  0.045083687  || Decoder Loss:  0.034474898 Validation Decoder Loss:  0.33101052
Encoder Loss:  0.044930693  || Decoder Loss:  0.034429573 Validation Decoder Loss:  0.33112594
Encoder Loss:  0.044787396  || Decoder Loss:  0.034409694 Validation Decoder Loss:  0.33121473
Encoder Loss:  0.044659525  || Decoder Loss:  0.034397647 Validation Decoder Loss:  0.33128282
Encoder Loss:  0.044597033  || Decoder Loss:  0.0343882 Validation Decoder Loss:  0.3313494
Encoder Loss:  0.044599384  || Decoder Loss:  0.03437955 Validation Decoder Loss:  0.33140987
Encoder Loss:  0.044601455  || Decoder Loss:  0.034371227 Validation Decoder Loss:  0.33146828
Encoder Loss:  0.044589773  || Decoder Loss:  0.03436293 Validation Decoder Loss:  0.3315279
Encoder Loss:  0.044572286  || Decoder Loss:  0.0343548 Validation Decoder Loss:  0.3315903
Encoder Loss:  0.044585183  || Decoder Loss:  0.034347318 Validation Decoder Loss:  0.33164972
Encoder Loss:  0.04455977  || Decoder Loss:  0.034340613 Validation Decoder Loss:  0.33171332
Encoder Loss:  0.044574264  || Decoder Loss:  0.034334946 Validation Decoder Loss:  0.3317715
Encoder Loss:  0.044559773  || Decoder Loss:  0.034330133 Validation Decoder Loss:  0.33183065
Encoder Loss:  0.04456852  || Decoder Loss:  0.034326293 Validation Decoder Loss:  0.3318823
Encoder Loss:  0.044564757  || Decoder Loss:  0.034323197 Validation Decoder Loss:  0.33193338
Encoder Loss:  0.04454664  || Decoder Loss:  0.034320574 Validation Decoder Loss:  0.33198768
Encoder Loss:  0.04455795  || Decoder Loss:  0.03431858 Validation Decoder Loss:  0.33203328
Encoder Loss:  0.04456336  || Decoder Loss:  0.034316957 Validation Decoder Loss:  0.33207655
Encoder Loss:  0.044552226  || Decoder Loss:  0.034315366 Validation Decoder Loss:  0.33212078
Encoder Loss:  0.0445573  || Decoder Loss:  0.034313887 Validation Decoder Loss:  0.33216032
Encoder Loss:  0.04454405  || Decoder Loss:  0.034312457 Validation Decoder Loss:  0.33220348
Encoder Loss:  0.044548154  || Decoder Loss:  0.0343111 Validation Decoder Loss:  0.33224678
Encoder Loss:  0.04454253  || Decoder Loss:  0.034309737 Validation Decoder Loss:  0.3322964
Encoder Loss:  0.04454637  || Decoder Loss:  0.034308657 Validation Decoder Loss:  0.33234152
Encoder Loss:  0.04453335  || Decoder Loss:  0.034307502 Validation Decoder Loss:  0.33240128
Encoder Loss:  0.044535946  || Decoder Loss:  0.03430663 Validation Decoder Loss:  0.3324567
Encoder Loss:  0.044537  || Decoder Loss:  0.0343058 Validation Decoder Loss:  0.33252582
Encoder Loss:  0.04454027  || Decoder Loss:  0.03430487 Validation Decoder Loss:  0.332605
Encoder Loss:  0.044530496  || Decoder Loss:  0.03430405 Validation Decoder Loss:  0.33269638
Encoder Loss:  0.044541836  || Decoder Loss:  0.03430326 Validation Decoder Loss:  0.33279943
Encoder Loss:  0.044527635  || Decoder Loss:  0.03430217 Validation Decoder Loss:  0.3329339
Encoder Loss:  0.04451459  || Decoder Loss:  0.034301057 Validation Decoder Loss:  0.33308887
Encoder Loss:  0.044533864  || Decoder Loss:  0.03429993 Validation Decoder Loss:  0.33327246
Model: siamese_net_lr_0.0008602721689224516 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33327246
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_299 (Conv3D (None, 284, 5, 19, 1)     222       
_________________________________________________________________
dropout_702 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_300 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_170 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_704 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_706 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23351783  || Decoder Loss:  0.061561495 Validation Decoder Loss:  0.33188364
Encoder Loss:  0.058746886  || Decoder Loss:  0.035446394 Validation Decoder Loss:  0.33247542
Encoder Loss:  0.052481826  || Decoder Loss:  0.035423707 Validation Decoder Loss:  0.33251065
Encoder Loss:  0.05225791  || Decoder Loss:  0.035398472 Validation Decoder Loss:  0.33259714
Encoder Loss:  0.050548296  || Decoder Loss:  0.035376817 Validation Decoder Loss:  0.332614
Encoder Loss:  0.05017722  || Decoder Loss:  0.035360612 Validation Decoder Loss:  0.33265477
Encoder Loss:  0.05014404  || Decoder Loss:  0.035336837 Validation Decoder Loss:  0.3324769
Encoder Loss:  0.050130595  || Decoder Loss:  0.035307717 Validation Decoder Loss:  0.33262643
Encoder Loss:  0.050103802  || Decoder Loss:  0.03528686 Validation Decoder Loss:  0.33266652
Encoder Loss:  0.05009644  || Decoder Loss:  0.03528534 Validation Decoder Loss:  0.33290604
Encoder Loss:  0.050097633  || Decoder Loss:  0.035280894 Validation Decoder Loss:  0.3329446
Encoder Loss:  0.05009828  || Decoder Loss:  0.035269216 Validation Decoder Loss:  0.33306634
Encoder Loss:  0.0500891  || Decoder Loss:  0.035248596 Validation Decoder Loss:  0.3332492
Encoder Loss:  0.050089423  || Decoder Loss:  0.035221327 Validation Decoder Loss:  0.33331
Encoder Loss:  0.05007294  || Decoder Loss:  0.035195924 Validation Decoder Loss:  0.33269995
Encoder Loss:  0.050061196  || Decoder Loss:  0.035153054 Validation Decoder Loss:  0.33316982
Encoder Loss:  0.050051216  || Decoder Loss:  0.035085708 Validation Decoder Loss:  0.33334887
Encoder Loss:  0.05004289  || Decoder Loss:  0.035017043 Validation Decoder Loss:  0.33334947
Encoder Loss:  0.050046876  || Decoder Loss:  0.034946803 Validation Decoder Loss:  0.33342677
Encoder Loss:  0.05004588  || Decoder Loss:  0.034885023 Validation Decoder Loss:  0.3333244
Encoder Loss:  0.05004702  || Decoder Loss:  0.034837455 Validation Decoder Loss:  0.333309
Encoder Loss:  0.050043244  || Decoder Loss:  0.03482723 Validation Decoder Loss:  0.3334819
Encoder Loss:  0.05005326  || Decoder Loss:  0.034877643 Validation Decoder Loss:  0.33358753
Encoder Loss:  0.050045673  || Decoder Loss:  0.034910817 Validation Decoder Loss:  0.33382323
Encoder Loss:  0.05004411  || Decoder Loss:  0.034895528 Validation Decoder Loss:  0.333999
Encoder Loss:  0.050041962  || Decoder Loss:  0.03490496 Validation Decoder Loss:  0.33403224
Encoder Loss:  0.050034437  || Decoder Loss:  0.03490288 Validation Decoder Loss:  0.33402443
Encoder Loss:  0.050037917  || Decoder Loss:  0.03491656 Validation Decoder Loss:  0.33414748
Encoder Loss:  0.05003699  || Decoder Loss:  0.034912687 Validation Decoder Loss:  0.33409995
Encoder Loss:  0.05002783  || Decoder Loss:  0.034929052 Validation Decoder Loss:  0.33414578
Encoder Loss:  0.05002914  || Decoder Loss:  0.03492043 Validation Decoder Loss:  0.33422077
Encoder Loss:  0.050029203  || Decoder Loss:  0.034917258 Validation Decoder Loss:  0.33422774
Encoder Loss:  0.050024528  || Decoder Loss:  0.03493258 Validation Decoder Loss:  0.33420157
Encoder Loss:  0.050028488  || Decoder Loss:  0.03493811 Validation Decoder Loss:  0.33418792
Encoder Loss:  0.050023895  || Decoder Loss:  0.034947153 Validation Decoder Loss:  0.33414632
Encoder Loss:  0.050025754  || Decoder Loss:  0.034962196 Validation Decoder Loss:  0.33413106
Encoder Loss:  0.050023004  || Decoder Loss:  0.034969024 Validation Decoder Loss:  0.33405644
Encoder Loss:  0.050024163  || Decoder Loss:  0.034976676 Validation Decoder Loss:  0.33405405
Encoder Loss:  0.05001658  || Decoder Loss:  0.034997154 Validation Decoder Loss:  0.33392623
Encoder Loss:  0.050017294  || Decoder Loss:  0.03501465 Validation Decoder Loss:  0.33390236
Model: siamese_net_lr_0.0007215877025787213 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33390236
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_302 (Conv3D (None, 92, 5, 19, 1)      30        
_________________________________________________________________
dropout_708 (Dropout)        (None, 92, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_303 (Conv3D (None, 514, 5, 19, 1)     333       
_________________________________________________________________
reshape_171 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 363
Trainable params: 363
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 2570, 19, 1)       39        
_________________________________________________________________
dropout_710 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 2570, 19, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_712 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39857188  || Decoder Loss:  0.079892285 Validation Decoder Loss:  0.35926014
Encoder Loss:  0.39826286  || Decoder Loss:  0.080256335 Validation Decoder Loss:  0.35942218
Encoder Loss:  0.3979732  || Decoder Loss:  0.080597274 Validation Decoder Loss:  0.3595765
Encoder Loss:  0.39769784  || Decoder Loss:  0.08092176 Validation Decoder Loss:  0.35972565
Encoder Loss:  0.39743182  || Decoder Loss:  0.081234924 Validation Decoder Loss:  0.3598716
Encoder Loss:  0.39717233  || Decoder Loss:  0.081540324 Validation Decoder Loss:  0.36001563
Encoder Loss:  0.3969168  || Decoder Loss:  0.08184076 Validation Decoder Loss:  0.3601589
Encoder Loss:  0.39666396  || Decoder Loss:  0.08213802 Validation Decoder Loss:  0.3603021
Encoder Loss:  0.396413  || Decoder Loss:  0.08243342 Validation Decoder Loss:  0.36044574
Encoder Loss:  0.3961623  || Decoder Loss:  0.08272785 Validation Decoder Loss:  0.36059022
Encoder Loss:  0.39591205  || Decoder Loss:  0.08302191 Validation Decoder Loss:  0.3607357
Encoder Loss:  0.39566144  || Decoder Loss:  0.08331594 Validation Decoder Loss:  0.36088246
Encoder Loss:  0.3954108  || Decoder Loss:  0.083610386 Validation Decoder Loss:  0.36103052
Encoder Loss:  0.39515954  || Decoder Loss:  0.083905175 Validation Decoder Loss:  0.36118
Encoder Loss:  0.39490765  || Decoder Loss:  0.08420063 Validation Decoder Loss:  0.36133093
Encoder Loss:  0.39465535  || Decoder Loss:  0.084496796 Validation Decoder Loss:  0.36148337
Encoder Loss:  0.39440215  || Decoder Loss:  0.084793694 Validation Decoder Loss:  0.36163732
Encoder Loss:  0.39414823  || Decoder Loss:  0.085091375 Validation Decoder Loss:  0.36179283
Encoder Loss:  0.39389366  || Decoder Loss:  0.08538988 Validation Decoder Loss:  0.36194986
Encoder Loss:  0.393638  || Decoder Loss:  0.08568917 Validation Decoder Loss:  0.36210853
Encoder Loss:  0.39338183  || Decoder Loss:  0.085989274 Validation Decoder Loss:  0.36226875
Encoder Loss:  0.39312473  || Decoder Loss:  0.086290255 Validation Decoder Loss:  0.36243048
Encoder Loss:  0.39286667  || Decoder Loss:  0.08659199 Validation Decoder Loss:  0.36259395
Encoder Loss:  0.39260808  || Decoder Loss:  0.08689465 Validation Decoder Loss:  0.3627589
Encoder Loss:  0.39234844  || Decoder Loss:  0.08719806 Validation Decoder Loss:  0.36292553
Encoder Loss:  0.39208803  || Decoder Loss:  0.08750238 Validation Decoder Loss:  0.36309367
Encoder Loss:  0.39182693  || Decoder Loss:  0.08780746 Validation Decoder Loss:  0.36326343
Encoder Loss:  0.39156508  || Decoder Loss:  0.08811337 Validation Decoder Loss:  0.36343473
Encoder Loss:  0.3913024  || Decoder Loss:  0.08842005 Validation Decoder Loss:  0.36360762
Encoder Loss:  0.39103854  || Decoder Loss:  0.0887276 Validation Decoder Loss:  0.36378208
Encoder Loss:  0.3907746  || Decoder Loss:  0.08903595 Validation Decoder Loss:  0.3639581
Encoder Loss:  0.39050922  || Decoder Loss:  0.08934511 Validation Decoder Loss:  0.36413565
Encoder Loss:  0.39024317  || Decoder Loss:  0.08965502 Validation Decoder Loss:  0.36431485
Encoder Loss:  0.38997638  || Decoder Loss:  0.089965776 Validation Decoder Loss:  0.36449552
Encoder Loss:  0.3897089  || Decoder Loss:  0.090277225 Validation Decoder Loss:  0.36467773
Encoder Loss:  0.38944045  || Decoder Loss:  0.09058949 Validation Decoder Loss:  0.36486143
Encoder Loss:  0.3891711  || Decoder Loss:  0.09090257 Validation Decoder Loss:  0.36504662
Encoder Loss:  0.38890117  || Decoder Loss:  0.091216385 Validation Decoder Loss:  0.36523336
Encoder Loss:  0.3886306  || Decoder Loss:  0.09153094 Validation Decoder Loss:  0.3654216
Encoder Loss:  0.38835868  || Decoder Loss:  0.091846205 Validation Decoder Loss:  0.36561134
Model: siamese_net_lr_6.587454428900701e-06 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36561134
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_305 (Conv3D (None, 284, 5, 19, 1)     96        
_________________________________________________________________
dropout_714 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_306 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_172 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_716 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_585"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_718 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11862285  || Decoder Loss:  0.09478671 Validation Decoder Loss:  0.37055415
Encoder Loss:  0.12340439  || Decoder Loss:  0.10047802 Validation Decoder Loss:  0.37379572
Encoder Loss:  0.12256179  || Decoder Loss:  0.1002324 Validation Decoder Loss:  0.3239835
Encoder Loss:  0.06136416  || Decoder Loss:  0.035393532 Validation Decoder Loss:  0.3307953
Encoder Loss:  0.04372186  || Decoder Loss:  0.035437573 Validation Decoder Loss:  0.33159363
Encoder Loss:  0.04033611  || Decoder Loss:  0.035446443 Validation Decoder Loss:  0.3316113
Encoder Loss:  0.040269766  || Decoder Loss:  0.035446893 Validation Decoder Loss:  0.33163223
Encoder Loss:  0.040179342  || Decoder Loss:  0.03544715 Validation Decoder Loss:  0.33165947
Encoder Loss:  0.04005546  || Decoder Loss:  0.035447095 Validation Decoder Loss:  0.33169317
Encoder Loss:  0.039898112  || Decoder Loss:  0.035446674 Validation Decoder Loss:  0.33173698
Encoder Loss:  0.039688427  || Decoder Loss:  0.035445824 Validation Decoder Loss:  0.3317917
Encoder Loss:  0.03936476  || Decoder Loss:  0.035444323 Validation Decoder Loss:  0.33186167
Encoder Loss:  0.03878743  || Decoder Loss:  0.035441563 Validation Decoder Loss:  0.33194637
Encoder Loss:  0.037526485  || Decoder Loss:  0.035436247 Validation Decoder Loss:  0.3320204
Encoder Loss:  0.036764447  || Decoder Loss:  0.035430163 Validation Decoder Loss:  0.33207148
Encoder Loss:  0.03675624  || Decoder Loss:  0.035427228 Validation Decoder Loss:  0.33208764
Encoder Loss:  0.03675216  || Decoder Loss:  0.03542415 Validation Decoder Loss:  0.3321067
Encoder Loss:  0.03674834  || Decoder Loss:  0.03542094 Validation Decoder Loss:  0.33212984
Encoder Loss:  0.036744267  || Decoder Loss:  0.035417467 Validation Decoder Loss:  0.33215788
Encoder Loss:  0.03673913  || Decoder Loss:  0.0354135 Validation Decoder Loss:  0.3321924
Encoder Loss:  0.036733713  || Decoder Loss:  0.03540897 Validation Decoder Loss:  0.33223534
Encoder Loss:  0.03672671  || Decoder Loss:  0.03540371 Validation Decoder Loss:  0.3322884
Encoder Loss:  0.036717795  || Decoder Loss:  0.035397764 Validation Decoder Loss:  0.3323519
Encoder Loss:  0.036675125  || Decoder Loss:  0.03539132 Validation Decoder Loss:  0.3324229
Encoder Loss:  0.0365638  || Decoder Loss:  0.03538519 Validation Decoder Loss:  0.33249146
Encoder Loss:  0.0365571  || Decoder Loss:  0.03537958 Validation Decoder Loss:  0.3325513
Encoder Loss:  0.036552045  || Decoder Loss:  0.035374496 Validation Decoder Loss:  0.33259848
Encoder Loss:  0.03654757  || Decoder Loss:  0.03536983 Validation Decoder Loss:  0.33263338
Encoder Loss:  0.03654338  || Decoder Loss:  0.035365414 Validation Decoder Loss:  0.33265907
Encoder Loss:  0.03653926  || Decoder Loss:  0.035361186 Validation Decoder Loss:  0.33267862
Encoder Loss:  0.036535446  || Decoder Loss:  0.035357077 Validation Decoder Loss:  0.33269462
Encoder Loss:  0.03653172  || Decoder Loss:  0.03535307 Validation Decoder Loss:  0.33270842
Encoder Loss:  0.036528006  || Decoder Loss:  0.03534912 Validation Decoder Loss:  0.33272082
Encoder Loss:  0.036524367  || Decoder Loss:  0.03534517 Validation Decoder Loss:  0.33273223
Encoder Loss:  0.03652065  || Decoder Loss:  0.0353412 Validation Decoder Loss:  0.33274275
Encoder Loss:  0.03651694  || Decoder Loss:  0.035337165 Validation Decoder Loss:  0.3327523
Encoder Loss:  0.036513057  || Decoder Loss:  0.035332967 Validation Decoder Loss:  0.33276072
Encoder Loss:  0.036509015  || Decoder Loss:  0.035328556 Validation Decoder Loss:  0.33276767
Encoder Loss:  0.0365047  || Decoder Loss:  0.03532388 Validation Decoder Loss:  0.33277255
Encoder Loss:  0.036500085  || Decoder Loss:  0.035318848 Validation Decoder Loss:  0.3327745
Model: siamese_net_lr_0.0003299162058098172 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3327745
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_308 (Conv3D (None, 78, 5, 19, 1)      16        
_________________________________________________________________
dropout_720 (Dropout)        (None, 78, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_309 (Conv3D (None, 514, 5, 19, 1)     438       
_________________________________________________________________
reshape_173 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_722 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_724 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25485566  || Decoder Loss:  0.05033478 Validation Decoder Loss:  0.35416427
Encoder Loss:  0.25461283  || Decoder Loss:  0.053045698 Validation Decoder Loss:  0.34868747
Encoder Loss:  0.25424263  || Decoder Loss:  0.056967203 Validation Decoder Loss:  0.34270987
Encoder Loss:  0.25369212  || Decoder Loss:  0.06210126 Validation Decoder Loss:  0.33825704
Encoder Loss:  0.2528502  || Decoder Loss:  0.06824058 Validation Decoder Loss:  0.3358067
Encoder Loss:  0.2514642  || Decoder Loss:  0.07485094 Validation Decoder Loss:  0.3347934
Encoder Loss:  0.24884148  || Decoder Loss:  0.080434024 Validation Decoder Loss:  0.33319628
Encoder Loss:  0.24221632  || Decoder Loss:  0.078916974 Validation Decoder Loss:  0.3220552
Encoder Loss:  0.22127327  || Decoder Loss:  0.047721658 Validation Decoder Loss:  0.33304477
Encoder Loss:  0.20851818  || Decoder Loss:  0.035806015 Validation Decoder Loss:  0.33631176
Encoder Loss:  0.20031467  || Decoder Loss:  0.03519795 Validation Decoder Loss:  0.33122975
Encoder Loss:  0.19167739  || Decoder Loss:  0.03508978 Validation Decoder Loss:  0.330352
Encoder Loss:  0.18232937  || Decoder Loss:  0.035063695 Validation Decoder Loss:  0.33035222
Encoder Loss:  0.1720586  || Decoder Loss:  0.035043776 Validation Decoder Loss:  0.33049002
Encoder Loss:  0.16041254  || Decoder Loss:  0.035025004 Validation Decoder Loss:  0.3306354
Encoder Loss:  0.1450282  || Decoder Loss:  0.035007704 Validation Decoder Loss:  0.33077353
Encoder Loss:  0.09070486  || Decoder Loss:  0.034992088 Validation Decoder Loss:  0.3308912
Encoder Loss:  0.046112005  || Decoder Loss:  0.034978632 Validation Decoder Loss:  0.3308806
Encoder Loss:  0.043310247  || Decoder Loss:  0.034967467 Validation Decoder Loss:  0.33084473
Encoder Loss:  0.043120828  || Decoder Loss:  0.0349581 Validation Decoder Loss:  0.33080795
Encoder Loss:  0.043115377  || Decoder Loss:  0.034950133 Validation Decoder Loss:  0.33077624
Encoder Loss:  0.043109164  || Decoder Loss:  0.034943238 Validation Decoder Loss:  0.33074933
Encoder Loss:  0.043103684  || Decoder Loss:  0.034937147 Validation Decoder Loss:  0.3307266
Encoder Loss:  0.043100018  || Decoder Loss:  0.03493163 Validation Decoder Loss:  0.33070743
Encoder Loss:  0.043095555  || Decoder Loss:  0.03492653 Validation Decoder Loss:  0.33069134
Encoder Loss:  0.0430912  || Decoder Loss:  0.034921724 Validation Decoder Loss:  0.3306778
Encoder Loss:  0.043088228  || Decoder Loss:  0.034917146 Validation Decoder Loss:  0.3306664
Encoder Loss:  0.04308585  || Decoder Loss:  0.03491276 Validation Decoder Loss:  0.33065677
Encoder Loss:  0.043083485  || Decoder Loss:  0.034908507 Validation Decoder Loss:  0.33064854
Encoder Loss:  0.043080397  || Decoder Loss:  0.034904364 Validation Decoder Loss:  0.33064157
Encoder Loss:  0.043078452  || Decoder Loss:  0.03490033 Validation Decoder Loss:  0.3306356
Encoder Loss:  0.043076992  || Decoder Loss:  0.034896385 Validation Decoder Loss:  0.33063054
Encoder Loss:  0.043074947  || Decoder Loss:  0.034892514 Validation Decoder Loss:  0.33062616
Encoder Loss:  0.04307307  || Decoder Loss:  0.03488873 Validation Decoder Loss:  0.33062243
Encoder Loss:  0.04307146  || Decoder Loss:  0.034885 Validation Decoder Loss:  0.3306193
Encoder Loss:  0.04306996  || Decoder Loss:  0.034881346 Validation Decoder Loss:  0.3306166
Encoder Loss:  0.04306745  || Decoder Loss:  0.034877747 Validation Decoder Loss:  0.33061436
Encoder Loss:  0.043066114  || Decoder Loss:  0.034874212 Validation Decoder Loss:  0.33061254
Encoder Loss:  0.043064628  || Decoder Loss:  0.03487073 Validation Decoder Loss:  0.33061108
Encoder Loss:  0.043062318  || Decoder Loss:  0.034867294 Validation Decoder Loss:  0.33060995
Model: siamese_net_lr_0.0009772162056031566 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33060995
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_311 (Conv3D (None, 388, 5, 19, 1)     263       
_________________________________________________________________
dropout_726 (Dropout)        (None, 388, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_312 (Conv3D (None, 514, 5, 19, 1)     128       
_________________________________________________________________
reshape_174 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_728 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_730 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.114209265  || Decoder Loss:  0.047117885 Validation Decoder Loss:  0.33027282
Encoder Loss:  0.044138547  || Decoder Loss:  0.034919318 Validation Decoder Loss:  0.33015704
Encoder Loss:  0.03998126  || Decoder Loss:  0.034865428 Validation Decoder Loss:  0.33007503
Encoder Loss:  0.039930314  || Decoder Loss:  0.034830067 Validation Decoder Loss:  0.33001167
Encoder Loss:  0.03992174  || Decoder Loss:  0.034807965 Validation Decoder Loss:  0.33002326
Encoder Loss:  0.03989795  || Decoder Loss:  0.034794465 Validation Decoder Loss:  0.3300504
Encoder Loss:  0.03987468  || Decoder Loss:  0.034785166 Validation Decoder Loss:  0.3300681
Encoder Loss:  0.039729528  || Decoder Loss:  0.034778167 Validation Decoder Loss:  0.330078
Encoder Loss:  0.0397223  || Decoder Loss:  0.034772586 Validation Decoder Loss:  0.3300832
Encoder Loss:  0.039718468  || Decoder Loss:  0.03476802 Validation Decoder Loss:  0.33008638
Encoder Loss:  0.039715406  || Decoder Loss:  0.03476414 Validation Decoder Loss:  0.33008957
Encoder Loss:  0.039713103  || Decoder Loss:  0.03476081 Validation Decoder Loss:  0.33009237
Encoder Loss:  0.0397112  || Decoder Loss:  0.034757957 Validation Decoder Loss:  0.3300952
Encoder Loss:  0.03970952  || Decoder Loss:  0.034755476 Validation Decoder Loss:  0.33009818
Encoder Loss:  0.039708048  || Decoder Loss:  0.03475325 Validation Decoder Loss:  0.33010143
Encoder Loss:  0.039706912  || Decoder Loss:  0.034751296 Validation Decoder Loss:  0.3301047
Encoder Loss:  0.039705712  || Decoder Loss:  0.034749564 Validation Decoder Loss:  0.3301078
Encoder Loss:  0.039704844  || Decoder Loss:  0.03474804 Validation Decoder Loss:  0.33011052
Encoder Loss:  0.039703988  || Decoder Loss:  0.03474665 Validation Decoder Loss:  0.33011287
Encoder Loss:  0.039703038  || Decoder Loss:  0.034745455 Validation Decoder Loss:  0.33011526
Encoder Loss:  0.039702233  || Decoder Loss:  0.034744315 Validation Decoder Loss:  0.3301192
Encoder Loss:  0.0397015  || Decoder Loss:  0.034743216 Validation Decoder Loss:  0.3301271
Encoder Loss:  0.039700665  || Decoder Loss:  0.034742173 Validation Decoder Loss:  0.33014512
Encoder Loss:  0.039699975  || Decoder Loss:  0.0347411 Validation Decoder Loss:  0.33015952
Encoder Loss:  0.03969908  || Decoder Loss:  0.034739904 Validation Decoder Loss:  0.33019993
Encoder Loss:  0.039699133  || Decoder Loss:  0.034739632 Validation Decoder Loss:  0.33018318
Encoder Loss:  0.039697476  || Decoder Loss:  0.03473782 Validation Decoder Loss:  0.3302477
Encoder Loss:  0.039696384  || Decoder Loss:  0.03473615 Validation Decoder Loss:  0.3302926
Encoder Loss:  0.039695956  || Decoder Loss:  0.034735437 Validation Decoder Loss:  0.33027202
Encoder Loss:  0.039694894  || Decoder Loss:  0.034734175 Validation Decoder Loss:  0.33034173
Encoder Loss:  0.039694175  || Decoder Loss:  0.034733113 Validation Decoder Loss:  0.33036572
Encoder Loss:  0.039693914  || Decoder Loss:  0.034732707 Validation Decoder Loss:  0.33038223
Encoder Loss:  0.039693214  || Decoder Loss:  0.03473177 Validation Decoder Loss:  0.33039638
Encoder Loss:  0.03969297  || Decoder Loss:  0.03473145 Validation Decoder Loss:  0.3303493
Encoder Loss:  0.03974138  || Decoder Loss:  0.03473469 Validation Decoder Loss:  0.33022928
Encoder Loss:  0.039695017  || Decoder Loss:  0.034734536 Validation Decoder Loss:  0.33023804
Encoder Loss:  0.039694823  || Decoder Loss:  0.034734175 Validation Decoder Loss:  0.33024427
Encoder Loss:  0.03969464  || Decoder Loss:  0.034733843 Validation Decoder Loss:  0.33025116
Encoder Loss:  0.039694365  || Decoder Loss:  0.03473347 Validation Decoder Loss:  0.33025956
Encoder Loss:  0.039694127  || Decoder Loss:  0.034733064 Validation Decoder Loss:  0.3302703
Model: siamese_net_lr_0.0007001707311061979 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3302703
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_314 (Conv3D (None, 106, 5, 19, 1)     44        
_________________________________________________________________
dropout_732 (Dropout)        (None, 106, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_315 (Conv3D (None, 514, 5, 19, 1)     305       
_________________________________________________________________
reshape_175 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_734 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_597"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_736 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3940371  || Decoder Loss:  0.08695856 Validation Decoder Loss:  0.36329865
Encoder Loss:  0.39337417  || Decoder Loss:  0.087706566 Validation Decoder Loss:  0.36376488
Encoder Loss:  0.39273357  || Decoder Loss:  0.088429734 Validation Decoder Loss:  0.3642172
Encoder Loss:  0.3921118  || Decoder Loss:  0.089130156 Validation Decoder Loss:  0.36465713
Encoder Loss:  0.39150494  || Decoder Loss:  0.08981132 Validation Decoder Loss:  0.36508632
Encoder Loss:  0.39091069  || Decoder Loss:  0.090476625 Validation Decoder Loss:  0.36550647
Encoder Loss:  0.39032662  || Decoder Loss:  0.0911288 Validation Decoder Loss:  0.36591968
Encoder Loss:  0.38974988  || Decoder Loss:  0.09177034 Validation Decoder Loss:  0.36632812
Encoder Loss:  0.3891794  || Decoder Loss:  0.09240331 Validation Decoder Loss:  0.36673355
Encoder Loss:  0.3886132  || Decoder Loss:  0.09302959 Validation Decoder Loss:  0.36713725
Encoder Loss:  0.38805008  || Decoder Loss:  0.09365057 Validation Decoder Loss:  0.36754018
Encoder Loss:  0.38748875  || Decoder Loss:  0.09426768 Validation Decoder Loss:  0.3679431
Encoder Loss:  0.38692814  || Decoder Loss:  0.09488184 Validation Decoder Loss:  0.3683465
Encoder Loss:  0.38636762  || Decoder Loss:  0.095494 Validation Decoder Loss:  0.36875087
Encoder Loss:  0.38580638  || Decoder Loss:  0.0961049 Validation Decoder Loss:  0.36915645
Encoder Loss:  0.38524356  || Decoder Loss:  0.09671515 Validation Decoder Loss:  0.36956352
Encoder Loss:  0.38467902  || Decoder Loss:  0.09732521 Validation Decoder Loss:  0.3699723
Encoder Loss:  0.38411182  || Decoder Loss:  0.097935475 Validation Decoder Loss:  0.3703828
Encoder Loss:  0.38354197  || Decoder Loss:  0.098546304 Validation Decoder Loss:  0.37079507
Encoder Loss:  0.38296872  || Decoder Loss:  0.09915791 Validation Decoder Loss:  0.37120908
Encoder Loss:  0.3823922  || Decoder Loss:  0.09977042 Validation Decoder Loss:  0.3716249
Encoder Loss:  0.3818117  || Decoder Loss:  0.10038407 Validation Decoder Loss:  0.3720423
Encoder Loss:  0.3812274  || Decoder Loss:  0.10099882 Validation Decoder Loss:  0.37246132
Encoder Loss:  0.38063848  || Decoder Loss:  0.10161476 Validation Decoder Loss:  0.37288177
Encoder Loss:  0.3800449  || Decoder Loss:  0.102231815 Validation Decoder Loss:  0.3733034
Encoder Loss:  0.37944645  || Decoder Loss:  0.10285006 Validation Decoder Loss:  0.373726
Encoder Loss:  0.378843  || Decoder Loss:  0.10346928 Validation Decoder Loss:  0.3741493
Encoder Loss:  0.37823433  || Decoder Loss:  0.10408932 Validation Decoder Loss:  0.37457293
Encoder Loss:  0.37761998  || Decoder Loss:  0.10471001 Validation Decoder Loss:  0.37499663
Encoder Loss:  0.37699977  || Decoder Loss:  0.10533107 Validation Decoder Loss:  0.3754199
Encoder Loss:  0.3763737  || Decoder Loss:  0.105952166 Validation Decoder Loss:  0.37584233
Encoder Loss:  0.3757415  || Decoder Loss:  0.10657289 Validation Decoder Loss:  0.37626308
Encoder Loss:  0.37510243  || Decoder Loss:  0.10719269 Validation Decoder Loss:  0.3766816
Encoder Loss:  0.37445664  || Decoder Loss:  0.107811034 Validation Decoder Loss:  0.3770969
Encoder Loss:  0.37380368  || Decoder Loss:  0.10842707 Validation Decoder Loss:  0.37750804
Encoder Loss:  0.3731433  || Decoder Loss:  0.10904 Validation Decoder Loss:  0.37791365
Encoder Loss:  0.37247512  || Decoder Loss:  0.10964856 Validation Decoder Loss:  0.37831232
Encoder Loss:  0.37179902  || Decoder Loss:  0.11025132 Validation Decoder Loss:  0.3787021
Encoder Loss:  0.37111443  || Decoder Loss:  0.1108467 Validation Decoder Loss:  0.3790807
Encoder Loss:  0.37042114  || Decoder Loss:  0.11143241 Validation Decoder Loss:  0.37944534
Model: siamese_net_lr_2.763992595040459e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37944537
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_317 (Conv3D (None, 416, 5, 19, 1)     165       
_________________________________________________________________
dropout_738 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_318 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_176 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_740 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_742 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08764765  || Decoder Loss:  0.05880446 Validation Decoder Loss:  0.35763925
Encoder Loss:  0.08772447  || Decoder Loss:  0.05891267 Validation Decoder Loss:  0.35727763
Encoder Loss:  0.08779149  || Decoder Loss:  0.059009995 Validation Decoder Loss:  0.35690415
Encoder Loss:  0.08784968  || Decoder Loss:  0.05909758 Validation Decoder Loss:  0.3565182
Encoder Loss:  0.08789911  || Decoder Loss:  0.05917571 Validation Decoder Loss:  0.3561193
Encoder Loss:  0.087939814  || Decoder Loss:  0.05924448 Validation Decoder Loss:  0.35570693
Encoder Loss:  0.08797155  || Decoder Loss:  0.05930375 Validation Decoder Loss:  0.35528022
Encoder Loss:  0.08799393  || Decoder Loss:  0.05935318 Validation Decoder Loss:  0.35483822
Encoder Loss:  0.08800656  || Decoder Loss:  0.059392318 Validation Decoder Loss:  0.3543797
Encoder Loss:  0.08800864  || Decoder Loss:  0.059420567 Validation Decoder Loss:  0.3539033
Encoder Loss:  0.08799951  || Decoder Loss:  0.05943706 Validation Decoder Loss:  0.3534075
Encoder Loss:  0.0879781  || Decoder Loss:  0.05944084 Validation Decoder Loss:  0.35289058
Encoder Loss:  0.08794322  || Decoder Loss:  0.059430674 Validation Decoder Loss:  0.35235068
Encoder Loss:  0.08789349  || Decoder Loss:  0.059405163 Validation Decoder Loss:  0.3517858
Encoder Loss:  0.087827384  || Decoder Loss:  0.059362575 Validation Decoder Loss:  0.35119385
Encoder Loss:  0.087743  || Decoder Loss:  0.059301063 Validation Decoder Loss:  0.3505726
Encoder Loss:  0.0876382  || Decoder Loss:  0.05921831 Validation Decoder Loss:  0.3499198
Encoder Loss:  0.087510586  || Decoder Loss:  0.059111804 Validation Decoder Loss:  0.34923297
Encoder Loss:  0.08735735  || Decoder Loss:  0.058978602 Validation Decoder Loss:  0.34850973
Encoder Loss:  0.08717539  || Decoder Loss:  0.058815327 Validation Decoder Loss:  0.34774768
Encoder Loss:  0.08696097  || Decoder Loss:  0.058618132 Validation Decoder Loss:  0.34694445
Encoder Loss:  0.08671011  || Decoder Loss:  0.058382705 Validation Decoder Loss:  0.3460974
Encoder Loss:  0.08641809  || Decoder Loss:  0.058104083 Validation Decoder Loss:  0.3452037
Encoder Loss:  0.0860797  || Decoder Loss:  0.057776656 Validation Decoder Loss:  0.34426004
Encoder Loss:  0.08568887  || Decoder Loss:  0.05739404 Validation Decoder Loss:  0.343263
Encoder Loss:  0.085239  || Decoder Loss:  0.05694904 Validation Decoder Loss:  0.34220907
Encoder Loss:  0.08472238  || Decoder Loss:  0.056433696 Validation Decoder Loss:  0.34109485
Encoder Loss:  0.08413069  || Decoder Loss:  0.055838887 Validation Decoder Loss:  0.3399174
Encoder Loss:  0.08345452  || Decoder Loss:  0.05515481 Validation Decoder Loss:  0.33867484
Encoder Loss:  0.08268401  || Decoder Loss:  0.054370772 Validation Decoder Loss:  0.3373669
Encoder Loss:  0.081808664  || Decoder Loss:  0.05347567 Validation Decoder Loss:  0.33599615
Encoder Loss:  0.08081797  || Decoder Loss:  0.052458405 Validation Decoder Loss:  0.33456948
Encoder Loss:  0.079702646  || Decoder Loss:  0.05130912 Validation Decoder Loss:  0.33310032
Encoder Loss:  0.078455575  || Decoder Loss:  0.050020542 Validation Decoder Loss:  0.3316115
Encoder Loss:  0.07707463  || Decoder Loss:  0.04859061 Validation Decoder Loss:  0.33013886
Encoder Loss:  0.0755657  || Decoder Loss:  0.047026254 Validation Decoder Loss:  0.3287351
Encoder Loss:  0.07394739  || Decoder Loss:  0.0453482 Validation Decoder Loss:  0.32747293
Encoder Loss:  0.07225615  || Decoder Loss:  0.043596663 Validation Decoder Loss:  0.32644415
Encoder Loss:  0.07055036  || Decoder Loss:  0.041835748 Validation Decoder Loss:  0.32575086
Encoder Loss:  0.06891015  || Decoder Loss:  0.040153395 Validation Decoder Loss:  0.32548353
Model: siamese_net_lr_4.1129919446106984e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32548353
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_320 (Conv3D (None, 414, 5, 19, 1)     226       
_________________________________________________________________
dropout_744 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_321 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_177 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_746 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_748 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058507577  || Decoder Loss:  0.058507577 Validation Decoder Loss:  0.3466379
Encoder Loss:  0.036135614  || Decoder Loss:  0.036135614 Validation Decoder Loss:  0.3294924
Encoder Loss:  0.03464611  || Decoder Loss:  0.03464611 Validation Decoder Loss:  0.32927772
Encoder Loss:  0.034611687  || Decoder Loss:  0.034611687 Validation Decoder Loss:  0.32919487
Encoder Loss:  0.0345903  || Decoder Loss:  0.0345903 Validation Decoder Loss:  0.3291433
Encoder Loss:  0.034572896  || Decoder Loss:  0.034572896 Validation Decoder Loss:  0.32910502
Encoder Loss:  0.034557354  || Decoder Loss:  0.034557354 Validation Decoder Loss:  0.329075
Encoder Loss:  0.034542896  || Decoder Loss:  0.034542896 Validation Decoder Loss:  0.3290518
Encoder Loss:  0.03452935  || Decoder Loss:  0.03452935 Validation Decoder Loss:  0.32903695
Encoder Loss:  0.03451705  || Decoder Loss:  0.03451705 Validation Decoder Loss:  0.32903424
Encoder Loss:  0.034506395  || Decoder Loss:  0.034506395 Validation Decoder Loss:  0.32904303
Encoder Loss:  0.034497526  || Decoder Loss:  0.034497526 Validation Decoder Loss:  0.32905772
Encoder Loss:  0.03449022  || Decoder Loss:  0.03449022 Validation Decoder Loss:  0.3290743
Encoder Loss:  0.03448422  || Decoder Loss:  0.03448422 Validation Decoder Loss:  0.3290906
Encoder Loss:  0.034479238  || Decoder Loss:  0.034479238 Validation Decoder Loss:  0.32910573
Encoder Loss:  0.034475077  || Decoder Loss:  0.034475077 Validation Decoder Loss:  0.32911944
Encoder Loss:  0.034471545  || Decoder Loss:  0.034471545 Validation Decoder Loss:  0.3291316
Encoder Loss:  0.034468524  || Decoder Loss:  0.034468524 Validation Decoder Loss:  0.32914227
Encoder Loss:  0.034465913  || Decoder Loss:  0.034465913 Validation Decoder Loss:  0.32915163
Encoder Loss:  0.03446363  || Decoder Loss:  0.03446363 Validation Decoder Loss:  0.32915986
Encoder Loss:  0.034461603  || Decoder Loss:  0.034461603 Validation Decoder Loss:  0.32916707
Encoder Loss:  0.034459773  || Decoder Loss:  0.034459773 Validation Decoder Loss:  0.3291734
Encoder Loss:  0.034458138  || Decoder Loss:  0.034458138 Validation Decoder Loss:  0.32917905
Encoder Loss:  0.034456674  || Decoder Loss:  0.034456674 Validation Decoder Loss:  0.32918411
Encoder Loss:  0.03445534  || Decoder Loss:  0.03445534 Validation Decoder Loss:  0.3291887
Encoder Loss:  0.034454104  || Decoder Loss:  0.034454104 Validation Decoder Loss:  0.32919282
Encoder Loss:  0.03445297  || Decoder Loss:  0.03445297 Validation Decoder Loss:  0.3291966
Encoder Loss:  0.034451947  || Decoder Loss:  0.034451947 Validation Decoder Loss:  0.32920006
Encoder Loss:  0.03445098  || Decoder Loss:  0.03445098 Validation Decoder Loss:  0.32920328
Encoder Loss:  0.03445011  || Decoder Loss:  0.03445011 Validation Decoder Loss:  0.3292063
Encoder Loss:  0.034449294  || Decoder Loss:  0.034449294 Validation Decoder Loss:  0.32920903
Encoder Loss:  0.03444852  || Decoder Loss:  0.03444852 Validation Decoder Loss:  0.32921165
Encoder Loss:  0.03444783  || Decoder Loss:  0.03444783 Validation Decoder Loss:  0.3292141
Encoder Loss:  0.034447167  || Decoder Loss:  0.034447167 Validation Decoder Loss:  0.32921645
Encoder Loss:  0.03444657  || Decoder Loss:  0.03444657 Validation Decoder Loss:  0.32921863
Encoder Loss:  0.034446012  || Decoder Loss:  0.034446012 Validation Decoder Loss:  0.32922077
Encoder Loss:  0.034445483  || Decoder Loss:  0.034445483 Validation Decoder Loss:  0.32922274
Encoder Loss:  0.03444499  || Decoder Loss:  0.03444499 Validation Decoder Loss:  0.32922465
Encoder Loss:  0.03444454  || Decoder Loss:  0.03444454 Validation Decoder Loss:  0.32922646
Encoder Loss:  0.034444124  || Decoder Loss:  0.034444124 Validation Decoder Loss:  0.32922822
Model: siamese_net_lr_0.0009944409295345599 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32922822
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_323 (Conv3D (None, 286, 5, 19, 1)     161       
_________________________________________________________________
dropout_750 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_324 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_178 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_608"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_752 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_754 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37861198  || Decoder Loss:  0.09692792 Validation Decoder Loss:  0.37172356
Encoder Loss:  0.37288716  || Decoder Loss:  0.10302703 Validation Decoder Loss:  0.3753422
Encoder Loss:  0.36517602  || Decoder Loss:  0.1103032 Validation Decoder Loss:  0.37902278
Encoder Loss:  0.3496765  || Decoder Loss:  0.0648274 Validation Decoder Loss:  0.33106726
Encoder Loss:  0.28369373  || Decoder Loss:  0.035418488 Validation Decoder Loss:  0.33148116
Encoder Loss:  0.08880858  || Decoder Loss:  0.03547583 Validation Decoder Loss:  0.3316537
Encoder Loss:  0.087681964  || Decoder Loss:  0.03547342 Validation Decoder Loss:  0.33167768
Encoder Loss:  0.08607501  || Decoder Loss:  0.035471287 Validation Decoder Loss:  0.33171016
Encoder Loss:  0.084107615  || Decoder Loss:  0.035468668 Validation Decoder Loss:  0.33175355
Encoder Loss:  0.081673995  || Decoder Loss:  0.03546566 Validation Decoder Loss:  0.33179379
Encoder Loss:  0.07806637  || Decoder Loss:  0.035462305 Validation Decoder Loss:  0.3318447
Encoder Loss:  0.07211153  || Decoder Loss:  0.03545849 Validation Decoder Loss:  0.3319041
Encoder Loss:  0.06045249  || Decoder Loss:  0.03545417 Validation Decoder Loss:  0.33195376
Encoder Loss:  0.05202348  || Decoder Loss:  0.035449635 Validation Decoder Loss:  0.33203816
Encoder Loss:  0.05171788  || Decoder Loss:  0.03544326 Validation Decoder Loss:  0.332107
Encoder Loss:  0.05170752  || Decoder Loss:  0.03543768 Validation Decoder Loss:  0.3321871
Encoder Loss:  0.051683497  || Decoder Loss:  0.03543298 Validation Decoder Loss:  0.3322676
Encoder Loss:  0.051656857  || Decoder Loss:  0.03542875 Validation Decoder Loss:  0.33234012
Encoder Loss:  0.051617857  || Decoder Loss:  0.035424758 Validation Decoder Loss:  0.33240414
Encoder Loss:  0.051490013  || Decoder Loss:  0.03542091 Validation Decoder Loss:  0.33246273
Encoder Loss:  0.05107657  || Decoder Loss:  0.035417024 Validation Decoder Loss:  0.33251637
Encoder Loss:  0.050411314  || Decoder Loss:  0.03541332 Validation Decoder Loss:  0.33256197
Encoder Loss:  0.049866103  || Decoder Loss:  0.035410177 Validation Decoder Loss:  0.33259737
Encoder Loss:  0.049735542  || Decoder Loss:  0.0354074 Validation Decoder Loss:  0.33262122
Encoder Loss:  0.049618267  || Decoder Loss:  0.035404712 Validation Decoder Loss:  0.33264002
Encoder Loss:  0.04954118  || Decoder Loss:  0.03540207 Validation Decoder Loss:  0.33265573
Encoder Loss:  0.049548853  || Decoder Loss:  0.035399422 Validation Decoder Loss:  0.33266908
Encoder Loss:  0.04956329  || Decoder Loss:  0.035396844 Validation Decoder Loss:  0.33268154
Encoder Loss:  0.049549617  || Decoder Loss:  0.035394296 Validation Decoder Loss:  0.33269286
Encoder Loss:  0.049509343  || Decoder Loss:  0.035391808 Validation Decoder Loss:  0.33270353
Encoder Loss:  0.049532704  || Decoder Loss:  0.03538939 Validation Decoder Loss:  0.3327135
Encoder Loss:  0.04952172  || Decoder Loss:  0.035387024 Validation Decoder Loss:  0.33272287
Encoder Loss:  0.049523093  || Decoder Loss:  0.035384692 Validation Decoder Loss:  0.3327319
Encoder Loss:  0.049514603  || Decoder Loss:  0.03538242 Validation Decoder Loss:  0.33274066
Encoder Loss:  0.049510077  || Decoder Loss:  0.03538018 Validation Decoder Loss:  0.33274913
Encoder Loss:  0.04951088  || Decoder Loss:  0.035377994 Validation Decoder Loss:  0.33275783
Encoder Loss:  0.049540475  || Decoder Loss:  0.035375856 Validation Decoder Loss:  0.33276573
Encoder Loss:  0.049512316  || Decoder Loss:  0.035373762 Validation Decoder Loss:  0.332774
Encoder Loss:  0.04951647  || Decoder Loss:  0.03537172 Validation Decoder Loss:  0.3327819
Encoder Loss:  0.049511164  || Decoder Loss:  0.035369717 Validation Decoder Loss:  0.33278966
Model: siamese_net_lr_0.0006035853297682198 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33278966
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_326 (Conv3D (None, 414, 5, 19, 1)     226       
_________________________________________________________________
dropout_756 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_327 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_179 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_612"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_758 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_760 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35064206  || Decoder Loss:  0.063248225 Validation Decoder Loss:  0.35999358
Encoder Loss:  0.35026014  || Decoder Loss:  0.06373097 Validation Decoder Loss:  0.35959584
Encoder Loss:  0.3498732  || Decoder Loss:  0.064213164 Validation Decoder Loss:  0.35917747
Encoder Loss:  0.34947568  || Decoder Loss:  0.06470077 Validation Decoder Loss:  0.3587401
Encoder Loss:  0.34906533  || Decoder Loss:  0.0651964 Validation Decoder Loss:  0.35828602
Encoder Loss:  0.34863907  || Decoder Loss:  0.0657022 Validation Decoder Loss:  0.35781744
Encoder Loss:  0.3481949  || Decoder Loss:  0.066220015 Validation Decoder Loss:  0.357336
Encoder Loss:  0.34772918  || Decoder Loss:  0.06675153 Validation Decoder Loss:  0.3568427
Encoder Loss:  0.34723905  || Decoder Loss:  0.06729819 Validation Decoder Loss:  0.3563372
Encoder Loss:  0.34672078  || Decoder Loss:  0.067861095 Validation Decoder Loss:  0.35581845
Encoder Loss:  0.3461706  || Decoder Loss:  0.06844071 Validation Decoder Loss:  0.35528407
Encoder Loss:  0.34558362  || Decoder Loss:  0.06903659 Validation Decoder Loss:  0.35473
Encoder Loss:  0.34495446  || Decoder Loss:  0.0696468 Validation Decoder Loss:  0.35414994
Encoder Loss:  0.34427616  || Decoder Loss:  0.07026643 Validation Decoder Loss:  0.3535332
Encoder Loss:  0.34353977  || Decoder Loss:  0.070885636 Validation Decoder Loss:  0.35286164
Encoder Loss:  0.34273434  || Decoder Loss:  0.07148419 Validation Decoder Loss:  0.3521032
Encoder Loss:  0.3418423  || Decoder Loss:  0.072020166 Validation Decoder Loss:  0.35119435
Encoder Loss:  0.34083492  || Decoder Loss:  0.07239807 Validation Decoder Loss:  0.34998602
Encoder Loss:  0.3396504  || Decoder Loss:  0.07235719 Validation Decoder Loss:  0.34804422
Encoder Loss:  0.3380729  || Decoder Loss:  0.07083238 Validation Decoder Loss:  0.34313297
Encoder Loss:  0.33321834  || Decoder Loss:  0.052559957 Validation Decoder Loss:  0.32909298
Encoder Loss:  0.32845756  || Decoder Loss:  0.035618782 Validation Decoder Loss:  0.3295326
Encoder Loss:  0.32668725  || Decoder Loss:  0.035590906 Validation Decoder Loss:  0.32961762
Encoder Loss:  0.32469723  || Decoder Loss:  0.035567585 Validation Decoder Loss:  0.32971513
Encoder Loss:  0.3224418  || Decoder Loss:  0.035547066 Validation Decoder Loss:  0.32982147
Encoder Loss:  0.31986228  || Decoder Loss:  0.035528414 Validation Decoder Loss:  0.32993424
Encoder Loss:  0.31688264  || Decoder Loss:  0.03551112 Validation Decoder Loss:  0.33005175
Encoder Loss:  0.3134016  || Decoder Loss:  0.03549502 Validation Decoder Loss:  0.3301725
Encoder Loss:  0.3092828  || Decoder Loss:  0.035480075 Validation Decoder Loss:  0.3302951
Encoder Loss:  0.3043375  || Decoder Loss:  0.035466403 Validation Decoder Loss:  0.3304184
Encoder Loss:  0.29830024  || Decoder Loss:  0.035454124 Validation Decoder Loss:  0.33054143
Encoder Loss:  0.29078412  || Decoder Loss:  0.035443302 Validation Decoder Loss:  0.33066404
Encoder Loss:  0.2812089  || Decoder Loss:  0.035433702 Validation Decoder Loss:  0.33078772
Encoder Loss:  0.2686712  || Decoder Loss:  0.035424978 Validation Decoder Loss:  0.33091682
Encoder Loss:  0.25170052  || Decoder Loss:  0.03541654 Validation Decoder Loss:  0.33106074
Encoder Loss:  0.22779436  || Decoder Loss:  0.035407744 Validation Decoder Loss:  0.33123595
Encoder Loss:  0.19282727  || Decoder Loss:  0.035397634 Validation Decoder Loss:  0.33145535
Encoder Loss:  0.14277706  || Decoder Loss:  0.03538483 Validation Decoder Loss:  0.33170182
Encoder Loss:  0.08745055  || Decoder Loss:  0.035368253 Validation Decoder Loss:  0.3318658
Encoder Loss:  0.07923694  || Decoder Loss:  0.035352625 Validation Decoder Loss:  0.33181512
Model: siamese_net_lr_6.381457233274536e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33181512
Model: "sequential_614"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_329 (Conv3D (None, 388, 5, 19, 1)     200       
_________________________________________________________________
dropout_762 (Dropout)        (None, 388, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_330 (Conv3D (None, 514, 5, 19, 1)     128       
_________________________________________________________________
reshape_180 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_764 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_766 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19669388  || Decoder Loss:  0.047886632 Validation Decoder Loss:  0.3302976
Encoder Loss:  0.060666863  || Decoder Loss:  0.034932233 Validation Decoder Loss:  0.33019787
Encoder Loss:  0.0454319  || Decoder Loss:  0.034878008 Validation Decoder Loss:  0.3301183
Encoder Loss:  0.045183826  || Decoder Loss:  0.034839116 Validation Decoder Loss:  0.33004832
Encoder Loss:  0.044845354  || Decoder Loss:  0.03481314 Validation Decoder Loss:  0.33004153
Encoder Loss:  0.04483819  || Decoder Loss:  0.034797743 Validation Decoder Loss:  0.33006895
Encoder Loss:  0.0448341  || Decoder Loss:  0.03478745 Validation Decoder Loss:  0.33008933
Encoder Loss:  0.044830646  || Decoder Loss:  0.03477981 Validation Decoder Loss:  0.3301012
Encoder Loss:  0.044828504  || Decoder Loss:  0.03477378 Validation Decoder Loss:  0.330108
Encoder Loss:  0.044826444  || Decoder Loss:  0.034768827 Validation Decoder Loss:  0.33011222
Encoder Loss:  0.04482499  || Decoder Loss:  0.03476467 Validation Decoder Loss:  0.33011526
Encoder Loss:  0.044824142  || Decoder Loss:  0.034761075 Validation Decoder Loss:  0.33011764
Encoder Loss:  0.04482297  || Decoder Loss:  0.034757923 Validation Decoder Loss:  0.33011985
Encoder Loss:  0.044822283  || Decoder Loss:  0.034755226 Validation Decoder Loss:  0.3301224
Encoder Loss:  0.04482181  || Decoder Loss:  0.034752827 Validation Decoder Loss:  0.3301253
Encoder Loss:  0.044821486  || Decoder Loss:  0.0347507 Validation Decoder Loss:  0.3301289
Encoder Loss:  0.04482049  || Decoder Loss:  0.03474879 Validation Decoder Loss:  0.33013302
Encoder Loss:  0.04482044  || Decoder Loss:  0.034746982 Validation Decoder Loss:  0.33013842
Encoder Loss:  0.04481957  || Decoder Loss:  0.034745436 Validation Decoder Loss:  0.33014536
Encoder Loss:  0.044819154  || Decoder Loss:  0.034743898 Validation Decoder Loss:  0.33015347
Encoder Loss:  0.044818215  || Decoder Loss:  0.034742348 Validation Decoder Loss:  0.33016816
Encoder Loss:  0.044817492  || Decoder Loss:  0.034740746 Validation Decoder Loss:  0.33018923
Encoder Loss:  0.044816863  || Decoder Loss:  0.034738697 Validation Decoder Loss:  0.3302344
Encoder Loss:  0.044819232  || Decoder Loss:  0.03473634 Validation Decoder Loss:  0.33015978
Encoder Loss:  0.04481655  || Decoder Loss:  0.034739014 Validation Decoder Loss:  0.3301767
Encoder Loss:  0.0448159  || Decoder Loss:  0.03473731 Validation Decoder Loss:  0.33021188
Encoder Loss:  0.04481486  || Decoder Loss:  0.034734942 Validation Decoder Loss:  0.33028486
Encoder Loss:  0.0448135  || Decoder Loss:  0.034731187 Validation Decoder Loss:  0.33042464
Encoder Loss:  0.044812094  || Decoder Loss:  0.034727015 Validation Decoder Loss:  0.33041906
Encoder Loss:  0.04481108  || Decoder Loss:  0.03472512 Validation Decoder Loss:  0.3306465
Encoder Loss:  0.044809565  || Decoder Loss:  0.034721177 Validation Decoder Loss:  0.3307712
Encoder Loss:  0.044810012  || Decoder Loss:  0.03472107 Validation Decoder Loss:  0.33051875
Encoder Loss:  0.044808883  || Decoder Loss:  0.034719083 Validation Decoder Loss:  0.33078834
Encoder Loss:  0.044808522  || Decoder Loss:  0.034717783 Validation Decoder Loss:  0.3306986
Encoder Loss:  0.04480895  || Decoder Loss:  0.034718793 Validation Decoder Loss:  0.33088952
Encoder Loss:  0.04480761  || Decoder Loss:  0.034715995 Validation Decoder Loss:  0.33092618
Encoder Loss:  0.044811502  || Decoder Loss:  0.03472202 Validation Decoder Loss:  0.33043897
Encoder Loss:  0.044812452  || Decoder Loss:  0.03472668 Validation Decoder Loss:  0.33065778
Encoder Loss:  0.044808913  || Decoder Loss:  0.03471954 Validation Decoder Loss:  0.3308261
Encoder Loss:  0.044807803  || Decoder Loss:  0.034716617 Validation Decoder Loss:  0.3309119
Model: siamese_net_lr_0.0006257474672551347 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33091193
Model: "sequential_618"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_332 (Conv3D (None, 416, 5, 19, 1)     39        
_________________________________________________________________
dropout_768 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_333 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_181 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_770 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_621"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_772 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08387306  || Decoder Loss:  0.055340387 Validation Decoder Loss:  0.35957706
Encoder Loss:  0.084033795  || Decoder Loss:  0.05555456 Validation Decoder Loss:  0.35901996
Encoder Loss:  0.08413789  || Decoder Loss:  0.05570711 Validation Decoder Loss:  0.35831523
Encoder Loss:  0.08417297  || Decoder Loss:  0.05578493 Validation Decoder Loss:  0.3574543
Encoder Loss:  0.08411606  || Decoder Loss:  0.05576367 Validation Decoder Loss:  0.35640606
Encoder Loss:  0.08392581  || Decoder Loss:  0.055598646 Validation Decoder Loss:  0.35510066
Encoder Loss:  0.08352429  || Decoder Loss:  0.055205844 Validation Decoder Loss:  0.35340342
Encoder Loss:  0.08275281  || Decoder Loss:  0.054413415 Validation Decoder Loss:  0.35105073
Encoder Loss:  0.081238225  || Decoder Loss:  0.05281724 Validation Decoder Loss:  0.34744298
Encoder Loss:  0.077892296  || Decoder Loss:  0.049238086 Validation Decoder Loss:  0.34069514
Encoder Loss:  0.06971862  || Decoder Loss:  0.040428128 Validation Decoder Loss:  0.33195192
Encoder Loss:  0.06489646  || Decoder Loss:  0.035254117 Validation Decoder Loss:  0.33173537
Encoder Loss:  0.06476199  || Decoder Loss:  0.03516499 Validation Decoder Loss:  0.33116648
Encoder Loss:  0.06464683  || Decoder Loss:  0.03510107 Validation Decoder Loss:  0.3306989
Encoder Loss:  0.064537115  || Decoder Loss:  0.03504826 Validation Decoder Loss:  0.33029258
Encoder Loss:  0.064432785  || Decoder Loss:  0.035007674 Validation Decoder Loss:  0.32994068
Encoder Loss:  0.06433281  || Decoder Loss:  0.034979936 Validation Decoder Loss:  0.32965076
Encoder Loss:  0.06423209  || Decoder Loss:  0.034961503 Validation Decoder Loss:  0.32942683
Encoder Loss:  0.064124204  || Decoder Loss:  0.034948234 Validation Decoder Loss:  0.32926095
Encoder Loss:  0.06400386  || Decoder Loss:  0.03493828 Validation Decoder Loss:  0.3291408
Encoder Loss:  0.0638654  || Decoder Loss:  0.0349311 Validation Decoder Loss:  0.32905793
Encoder Loss:  0.063700445  || Decoder Loss:  0.034926616 Validation Decoder Loss:  0.32900947
Encoder Loss:  0.06349493  || Decoder Loss:  0.034924977 Validation Decoder Loss:  0.32899842
Encoder Loss:  0.06322186  || Decoder Loss:  0.03492647 Validation Decoder Loss:  0.3290348
Encoder Loss:  0.06282011  || Decoder Loss:  0.03493158 Validation Decoder Loss:  0.32913777
Encoder Loss:  0.06212538  || Decoder Loss:  0.034941055 Validation Decoder Loss:  0.329338
Encoder Loss:  0.060559455  || Decoder Loss:  0.034955412 Validation Decoder Loss:  0.32968155
Encoder Loss:  0.054640993  || Decoder Loss:  0.034972474 Validation Decoder Loss:  0.33017978
Encoder Loss:  0.039184224  || Decoder Loss:  0.034980427 Validation Decoder Loss:  0.33040795
Encoder Loss:  0.036179293  || Decoder Loss:  0.034974597 Validation Decoder Loss:  0.33043408
Encoder Loss:  0.036172275  || Decoder Loss:  0.034968115 Validation Decoder Loss:  0.33045822
Encoder Loss:  0.036159918  || Decoder Loss:  0.03496227 Validation Decoder Loss:  0.33047783
Encoder Loss:  0.03615211  || Decoder Loss:  0.034956917 Validation Decoder Loss:  0.3304924
Encoder Loss:  0.036147837  || Decoder Loss:  0.034951948 Validation Decoder Loss:  0.3305025
Encoder Loss:  0.036140557  || Decoder Loss:  0.03494727 Validation Decoder Loss:  0.3305077
Encoder Loss:  0.036138136  || Decoder Loss:  0.03494281 Validation Decoder Loss:  0.33050942
Encoder Loss:  0.03612718  || Decoder Loss:  0.0349385 Validation Decoder Loss:  0.33050686
Encoder Loss:  0.036126643  || Decoder Loss:  0.034934305 Validation Decoder Loss:  0.33050233
Encoder Loss:  0.036122944  || Decoder Loss:  0.03493019 Validation Decoder Loss:  0.33049664
Encoder Loss:  0.036117967  || Decoder Loss:  0.034926113 Validation Decoder Loss:  0.3304901
Model: siamese_net_lr_0.00011917022119179398 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3304901
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_335 (Conv3D (None, 414, 5, 19, 1)     352       
_________________________________________________________________
dropout_774 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_336 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_182 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_624"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_776 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_778 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30166364  || Decoder Loss:  0.06361097 Validation Decoder Loss:  0.36148402
Encoder Loss:  0.29980427  || Decoder Loss:  0.06695968 Validation Decoder Loss:  0.35751593
Encoder Loss:  0.29650018  || Decoder Loss:  0.07113162 Validation Decoder Loss:  0.3482678
Encoder Loss:  0.2767032  || Decoder Loss:  0.040340766 Validation Decoder Loss:  0.3291018
Encoder Loss:  0.235745  || Decoder Loss:  0.035528366 Validation Decoder Loss:  0.3315854
Encoder Loss:  0.08272978  || Decoder Loss:  0.035401087 Validation Decoder Loss:  0.33234525
Encoder Loss:  0.068615064  || Decoder Loss:  0.035325993 Validation Decoder Loss:  0.33210808
Encoder Loss:  0.06814087  || Decoder Loss:  0.035265636 Validation Decoder Loss:  0.33189765
Encoder Loss:  0.067638986  || Decoder Loss:  0.035213742 Validation Decoder Loss:  0.33173433
Encoder Loss:  0.067138255  || Decoder Loss:  0.035171136 Validation Decoder Loss:  0.33162895
Encoder Loss:  0.06653899  || Decoder Loss:  0.035135493 Validation Decoder Loss:  0.33157963
Encoder Loss:  0.06582583  || Decoder Loss:  0.035104558 Validation Decoder Loss:  0.3315536
Encoder Loss:  0.064814575  || Decoder Loss:  0.03507841 Validation Decoder Loss:  0.33147573
Encoder Loss:  0.0628936  || Decoder Loss:  0.03505814 Validation Decoder Loss:  0.33129567
Encoder Loss:  0.05767314  || Decoder Loss:  0.035043105 Validation Decoder Loss:  0.33114514
Encoder Loss:  0.0470133  || Decoder Loss:  0.03502437 Validation Decoder Loss:  0.33126155
Encoder Loss:  0.045758467  || Decoder Loss:  0.03500609 Validation Decoder Loss:  0.3313049
Encoder Loss:  0.045742154  || Decoder Loss:  0.034993626 Validation Decoder Loss:  0.33134994
Encoder Loss:  0.045722608  || Decoder Loss:  0.034983102 Validation Decoder Loss:  0.33139938
Encoder Loss:  0.045703124  || Decoder Loss:  0.034973394 Validation Decoder Loss:  0.33145666
Encoder Loss:  0.04568582  || Decoder Loss:  0.034963798 Validation Decoder Loss:  0.33152097
Encoder Loss:  0.04566242  || Decoder Loss:  0.034954023 Validation Decoder Loss:  0.33159533
Encoder Loss:  0.045641083  || Decoder Loss:  0.034943745 Validation Decoder Loss:  0.33168
Encoder Loss:  0.04561242  || Decoder Loss:  0.034932807 Validation Decoder Loss:  0.3317786
Encoder Loss:  0.04558517  || Decoder Loss:  0.03492088 Validation Decoder Loss:  0.33189303
Encoder Loss:  0.045551527  || Decoder Loss:  0.03490786 Validation Decoder Loss:  0.33202606
Encoder Loss:  0.04550758  || Decoder Loss:  0.034893528 Validation Decoder Loss:  0.33218205
Encoder Loss:  0.045459326  || Decoder Loss:  0.034877773 Validation Decoder Loss:  0.33236414
Encoder Loss:  0.045398336  || Decoder Loss:  0.034860454 Validation Decoder Loss:  0.33258557
Encoder Loss:  0.04535076  || Decoder Loss:  0.034841593 Validation Decoder Loss:  0.33287078
Encoder Loss:  0.045315653  || Decoder Loss:  0.03482238 Validation Decoder Loss:  0.3332122
Encoder Loss:  0.045286924  || Decoder Loss:  0.034805063 Validation Decoder Loss:  0.33356273
Encoder Loss:  0.045255758  || Decoder Loss:  0.034791596 Validation Decoder Loss:  0.33387285
Encoder Loss:  0.04521005  || Decoder Loss:  0.034782458 Validation Decoder Loss:  0.33409637
Encoder Loss:  0.045164242  || Decoder Loss:  0.034776222 Validation Decoder Loss:  0.3342315
Encoder Loss:  0.045122374  || Decoder Loss:  0.034771588 Validation Decoder Loss:  0.3343116
Encoder Loss:  0.045096837  || Decoder Loss:  0.034767754 Validation Decoder Loss:  0.33436716
Encoder Loss:  0.04508969  || Decoder Loss:  0.034763858 Validation Decoder Loss:  0.33440906
Encoder Loss:  0.045087323  || Decoder Loss:  0.03476024 Validation Decoder Loss:  0.33444235
Encoder Loss:  0.045085173  || Decoder Loss:  0.034756888 Validation Decoder Loss:  0.33446947
Model: siamese_net_lr_0.00030628629051027557 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33446947
Model: "sequential_626"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_338 (Conv3D (None, 400, 5, 19, 1)     23        
_________________________________________________________________
dropout_780 (Dropout)        (None, 400, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_339 (Conv3D (None, 514, 5, 19, 1)     116       
_________________________________________________________________
reshape_183 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_782 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_784 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2535974  || Decoder Loss:  0.062209286 Validation Decoder Loss:  0.36294872
Encoder Loss:  0.2534009  || Decoder Loss:  0.063530184 Validation Decoder Loss:  0.36239582
Encoder Loss:  0.25304633  || Decoder Loss:  0.06473575 Validation Decoder Loss:  0.36062658
Encoder Loss:  0.24348035  || Decoder Loss:  0.046510223 Validation Decoder Loss:  0.32580084
Encoder Loss:  0.23690042  || Decoder Loss:  0.035623807 Validation Decoder Loss:  0.3260718
Encoder Loss:  0.23424898  || Decoder Loss:  0.035478536 Validation Decoder Loss:  0.3269083
Encoder Loss:  0.21993864  || Decoder Loss:  0.03534467 Validation Decoder Loss:  0.32768726
Encoder Loss:  0.058361843  || Decoder Loss:  0.035237517 Validation Decoder Loss:  0.32797983
Encoder Loss:  0.043125506  || Decoder Loss:  0.03512894 Validation Decoder Loss:  0.3281244
Encoder Loss:  0.043074522  || Decoder Loss:  0.035035767 Validation Decoder Loss:  0.32826442
Encoder Loss:  0.043049082  || Decoder Loss:  0.034977585 Validation Decoder Loss:  0.32838038
Encoder Loss:  0.04304084  || Decoder Loss:  0.034947332 Validation Decoder Loss:  0.32848516
Encoder Loss:  0.043016218  || Decoder Loss:  0.03492791 Validation Decoder Loss:  0.32858855
Encoder Loss:  0.043007784  || Decoder Loss:  0.034911707 Validation Decoder Loss:  0.32869604
Encoder Loss:  0.04300061  || Decoder Loss:  0.034896743 Validation Decoder Loss:  0.3288096
Encoder Loss:  0.04299404  || Decoder Loss:  0.034882545 Validation Decoder Loss:  0.32892948
Encoder Loss:  0.04298747  || Decoder Loss:  0.034869052 Validation Decoder Loss:  0.32905585
Encoder Loss:  0.042981483  || Decoder Loss:  0.0348562 Validation Decoder Loss:  0.3291884
Encoder Loss:  0.04297572  || Decoder Loss:  0.034843937 Validation Decoder Loss:  0.32932684
Encoder Loss:  0.0429703  || Decoder Loss:  0.03483219 Validation Decoder Loss:  0.32947075
Encoder Loss:  0.042964965  || Decoder Loss:  0.034820817 Validation Decoder Loss:  0.3296204
Encoder Loss:  0.042959847  || Decoder Loss:  0.034809753 Validation Decoder Loss:  0.32977602
Encoder Loss:  0.04295482  || Decoder Loss:  0.034798924 Validation Decoder Loss:  0.32993838
Encoder Loss:  0.04294985  || Decoder Loss:  0.03478832 Validation Decoder Loss:  0.33010846
Encoder Loss:  0.042945027  || Decoder Loss:  0.034777988 Validation Decoder Loss:  0.33028698
Encoder Loss:  0.042940423  || Decoder Loss:  0.034767985 Validation Decoder Loss:  0.3304744
Encoder Loss:  0.04293595  || Decoder Loss:  0.034758393 Validation Decoder Loss:  0.33067173
Encoder Loss:  0.04293181  || Decoder Loss:  0.034749325 Validation Decoder Loss:  0.33088043
Encoder Loss:  0.04292793  || Decoder Loss:  0.034740902 Validation Decoder Loss:  0.33110017
Encoder Loss:  0.042924337  || Decoder Loss:  0.03473326 Validation Decoder Loss:  0.33133084
Encoder Loss:  0.042921156  || Decoder Loss:  0.034726486 Validation Decoder Loss:  0.33157203
Encoder Loss:  0.042918466  || Decoder Loss:  0.034720708 Validation Decoder Loss:  0.3318209
Encoder Loss:  0.042916264  || Decoder Loss:  0.034715887 Validation Decoder Loss:  0.33207077
Encoder Loss:  0.04291437  || Decoder Loss:  0.03471205 Validation Decoder Loss:  0.33231485
Encoder Loss:  0.042912975  || Decoder Loss:  0.034709036 Validation Decoder Loss:  0.33254263
Encoder Loss:  0.04291183  || Decoder Loss:  0.03470663 Validation Decoder Loss:  0.33274758
Encoder Loss:  0.042910922  || Decoder Loss:  0.034704607 Validation Decoder Loss:  0.33292624
Encoder Loss:  0.04291008  || Decoder Loss:  0.034702867 Validation Decoder Loss:  0.33307892
Encoder Loss:  0.042909354  || Decoder Loss:  0.034701284 Validation Decoder Loss:  0.33320767
Encoder Loss:  0.04290873  || Decoder Loss:  0.03469985 Validation Decoder Loss:  0.33331636
Model: siamese_net_lr_0.0006298358095313746 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33331633
Model: "sequential_630"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_341 (Conv3D (None, 386, 5, 19, 1)     198       
_________________________________________________________________
dropout_786 (Dropout)        (None, 386, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_342 (Conv3D (None, 514, 5, 19, 1)     130       
_________________________________________________________________
reshape_184 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_788 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_633"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_790 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25754008  || Decoder Loss:  0.071809225 Validation Decoder Loss:  0.36239934
Encoder Loss:  0.25753206  || Decoder Loss:  0.071864 Validation Decoder Loss:  0.36237553
Encoder Loss:  0.25752246  || Decoder Loss:  0.071928896 Validation Decoder Loss:  0.3623489
Encoder Loss:  0.2575123  || Decoder Loss:  0.071997344 Validation Decoder Loss:  0.36232087
Encoder Loss:  0.25750193  || Decoder Loss:  0.07206687 Validation Decoder Loss:  0.3622918
Encoder Loss:  0.25749144  || Decoder Loss:  0.072136864 Validation Decoder Loss:  0.3622618
Encoder Loss:  0.2574809  || Decoder Loss:  0.072207086 Validation Decoder Loss:  0.362231
Encoder Loss:  0.2574702  || Decoder Loss:  0.07227753 Validation Decoder Loss:  0.36219928
Encoder Loss:  0.25745946  || Decoder Loss:  0.07234815 Validation Decoder Loss:  0.3621667
Encoder Loss:  0.25744867  || Decoder Loss:  0.072418995 Validation Decoder Loss:  0.3621333
Encoder Loss:  0.25743777  || Decoder Loss:  0.07249003 Validation Decoder Loss:  0.36209905
Encoder Loss:  0.2574268  || Decoder Loss:  0.07256129 Validation Decoder Loss:  0.36206397
Encoder Loss:  0.25741574  || Decoder Loss:  0.07263275 Validation Decoder Loss:  0.36202812
Encoder Loss:  0.25740463  || Decoder Loss:  0.07270444 Validation Decoder Loss:  0.3619914
Encoder Loss:  0.2573934  || Decoder Loss:  0.07277637 Validation Decoder Loss:  0.36195406
Encoder Loss:  0.2573821  || Decoder Loss:  0.072848506 Validation Decoder Loss:  0.361916
Encoder Loss:  0.25737068  || Decoder Loss:  0.072920896 Validation Decoder Loss:  0.36187723
Encoder Loss:  0.25735924  || Decoder Loss:  0.07299352 Validation Decoder Loss:  0.3618379
Encoder Loss:  0.25734764  || Decoder Loss:  0.07306639 Validation Decoder Loss:  0.361798
Encoder Loss:  0.257336  || Decoder Loss:  0.0731395 Validation Decoder Loss:  0.36175746
Encoder Loss:  0.25732425  || Decoder Loss:  0.073212884 Validation Decoder Loss:  0.3617164
Encoder Loss:  0.25731242  || Decoder Loss:  0.07328652 Validation Decoder Loss:  0.3616748
Encoder Loss:  0.25730044  || Decoder Loss:  0.07336041 Validation Decoder Loss:  0.36163265
Encoder Loss:  0.25728843  || Decoder Loss:  0.073434584 Validation Decoder Loss:  0.36159
Encoder Loss:  0.25727633  || Decoder Loss:  0.07350904 Validation Decoder Loss:  0.3615468
Encoder Loss:  0.2572641  || Decoder Loss:  0.07358377 Validation Decoder Loss:  0.36150312
Encoder Loss:  0.2572518  || Decoder Loss:  0.073658764 Validation Decoder Loss:  0.3614589
Encoder Loss:  0.25723937  || Decoder Loss:  0.07373407 Validation Decoder Loss:  0.3614142
Encoder Loss:  0.25722682  || Decoder Loss:  0.07380967 Validation Decoder Loss:  0.361369
Encoder Loss:  0.2572142  || Decoder Loss:  0.07388557 Validation Decoder Loss:  0.3613233
Encoder Loss:  0.25720146  || Decoder Loss:  0.07396177 Validation Decoder Loss:  0.36127716
Encoder Loss:  0.25718862  || Decoder Loss:  0.07403831 Validation Decoder Loss:  0.36123052
Encoder Loss:  0.25717565  || Decoder Loss:  0.07411514 Validation Decoder Loss:  0.3611834
Encoder Loss:  0.25716263  || Decoder Loss:  0.07419229 Validation Decoder Loss:  0.3611359
Encoder Loss:  0.2571495  || Decoder Loss:  0.074269794 Validation Decoder Loss:  0.36108795
Encoder Loss:  0.25713617  || Decoder Loss:  0.07434763 Validation Decoder Loss:  0.36103964
Encoder Loss:  0.25712278  || Decoder Loss:  0.0744258 Validation Decoder Loss:  0.36099082
Encoder Loss:  0.25710922  || Decoder Loss:  0.074504316 Validation Decoder Loss:  0.3609417
Encoder Loss:  0.2570956  || Decoder Loss:  0.07458318 Validation Decoder Loss:  0.36089218
Encoder Loss:  0.2570818  || Decoder Loss:  0.07466241 Validation Decoder Loss:  0.3608423
Model: siamese_net_lr_9.640532677688723e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36084226
Model: "sequential_634"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_344 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_792 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_345 (Conv3D (None, 514, 5, 19, 1)     328       
_________________________________________________________________
reshape_185 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_636"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_794 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_796 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17654762  || Decoder Loss:  0.05879 Validation Decoder Loss:  0.330884
Encoder Loss:  0.06258464  || Decoder Loss:  0.03510984 Validation Decoder Loss:  0.33076224
Encoder Loss:  0.045251325  || Decoder Loss:  0.03503421 Validation Decoder Loss:  0.33080226
Encoder Loss:  0.04435277  || Decoder Loss:  0.03500399 Validation Decoder Loss:  0.3308078
Encoder Loss:  0.04430744  || Decoder Loss:  0.034979116 Validation Decoder Loss:  0.33081537
Encoder Loss:  0.04429083  || Decoder Loss:  0.034959108 Validation Decoder Loss:  0.33083224
Encoder Loss:  0.044287138  || Decoder Loss:  0.034947805 Validation Decoder Loss:  0.33086517
Encoder Loss:  0.044283558  || Decoder Loss:  0.034942932 Validation Decoder Loss:  0.3308928
Encoder Loss:  0.044282727  || Decoder Loss:  0.0349388 Validation Decoder Loss:  0.33091587
Encoder Loss:  0.044277873  || Decoder Loss:  0.03493421 Validation Decoder Loss:  0.33093888
Encoder Loss:  0.044280257  || Decoder Loss:  0.034931082 Validation Decoder Loss:  0.3309592
Encoder Loss:  0.044281233  || Decoder Loss:  0.034928773 Validation Decoder Loss:  0.33097696
Encoder Loss:  0.044279147  || Decoder Loss:  0.0349251 Validation Decoder Loss:  0.3309992
Encoder Loss:  0.0442803  || Decoder Loss:  0.034923576 Validation Decoder Loss:  0.3310197
Encoder Loss:  0.04427322  || Decoder Loss:  0.03492067 Validation Decoder Loss:  0.33104283
Encoder Loss:  0.044275407  || Decoder Loss:  0.034919154 Validation Decoder Loss:  0.33106118
Encoder Loss:  0.044276934  || Decoder Loss:  0.03491648 Validation Decoder Loss:  0.33108324
Encoder Loss:  0.044270262  || Decoder Loss:  0.03491458 Validation Decoder Loss:  0.33111116
Encoder Loss:  0.044270314  || Decoder Loss:  0.034911666 Validation Decoder Loss:  0.33115482
Encoder Loss:  0.044269446  || Decoder Loss:  0.034908928 Validation Decoder Loss:  0.33118403
Encoder Loss:  0.044271145  || Decoder Loss:  0.034907978 Validation Decoder Loss:  0.3311944
Encoder Loss:  0.044268917  || Decoder Loss:  0.034905963 Validation Decoder Loss:  0.33121467
Encoder Loss:  0.04426618  || Decoder Loss:  0.034904297 Validation Decoder Loss:  0.3312496
Encoder Loss:  0.044267707  || Decoder Loss:  0.034903258 Validation Decoder Loss:  0.33131465
Encoder Loss:  0.04426822  || Decoder Loss:  0.034904085 Validation Decoder Loss:  0.3312459
Encoder Loss:  0.044267584  || Decoder Loss:  0.034900602 Validation Decoder Loss:  0.33133432
Encoder Loss:  0.044263136  || Decoder Loss:  0.034898147 Validation Decoder Loss:  0.3313582
Encoder Loss:  0.044264622  || Decoder Loss:  0.034897275 Validation Decoder Loss:  0.33138788
Encoder Loss:  0.044260707  || Decoder Loss:  0.034896117 Validation Decoder Loss:  0.3313914
Encoder Loss:  0.044259477  || Decoder Loss:  0.034893952 Validation Decoder Loss:  0.33139968
Encoder Loss:  0.044260267  || Decoder Loss:  0.034894265 Validation Decoder Loss:  0.33140874
Encoder Loss:  0.044258982  || Decoder Loss:  0.03489253 Validation Decoder Loss:  0.33151013
Encoder Loss:  0.044259783  || Decoder Loss:  0.034891937 Validation Decoder Loss:  0.3314973
Encoder Loss:  0.044257298  || Decoder Loss:  0.034890056 Validation Decoder Loss:  0.33151543
Encoder Loss:  0.044256523  || Decoder Loss:  0.034888245 Validation Decoder Loss:  0.33153978
Encoder Loss:  0.04425183  || Decoder Loss:  0.034885123 Validation Decoder Loss:  0.3316552
Encoder Loss:  0.044253297  || Decoder Loss:  0.0348841 Validation Decoder Loss:  0.3316539
Encoder Loss:  0.04425142  || Decoder Loss:  0.03488313 Validation Decoder Loss:  0.33167332
Encoder Loss:  0.044246774  || Decoder Loss:  0.03488041 Validation Decoder Loss:  0.33178583
Encoder Loss:  0.04424614  || Decoder Loss:  0.034879033 Validation Decoder Loss:  0.3318536
Model: siamese_net_lr_0.0006148607562904711 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3318536
Model: "sequential_638"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_347 (Conv3D (None, 188, 5, 19, 1)     126       
_________________________________________________________________
dropout_798 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_348 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_186 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 267
Trainable params: 267
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_640"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_800 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_802 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25959685  || Decoder Loss:  0.07598713 Validation Decoder Loss:  0.36036223
Encoder Loss:  0.25728512  || Decoder Loss:  0.080533415 Validation Decoder Loss:  0.35809588
Encoder Loss:  0.23342086  || Decoder Loss:  0.06659935 Validation Decoder Loss:  0.32754523
Encoder Loss:  0.17835079  || Decoder Loss:  0.035444375 Validation Decoder Loss:  0.33152315
Encoder Loss:  0.06505707  || Decoder Loss:  0.035292167 Validation Decoder Loss:  0.33147866
Encoder Loss:  0.059521228  || Decoder Loss:  0.035183996 Validation Decoder Loss:  0.33118194
Encoder Loss:  0.058819123  || Decoder Loss:  0.03511734 Validation Decoder Loss:  0.33114147
Encoder Loss:  0.058157753  || Decoder Loss:  0.03506348 Validation Decoder Loss:  0.33113992
Encoder Loss:  0.05732287  || Decoder Loss:  0.035027225 Validation Decoder Loss:  0.33115795
Encoder Loss:  0.05260714  || Decoder Loss:  0.0350065 Validation Decoder Loss:  0.3313376
Encoder Loss:  0.04670177  || Decoder Loss:  0.03498896 Validation Decoder Loss:  0.3312676
Encoder Loss:  0.04515539  || Decoder Loss:  0.034983966 Validation Decoder Loss:  0.33119795
Encoder Loss:  0.044528145  || Decoder Loss:  0.034978617 Validation Decoder Loss:  0.33115494
Encoder Loss:  0.044183206  || Decoder Loss:  0.034972977 Validation Decoder Loss:  0.3311221
Encoder Loss:  0.043936566  || Decoder Loss:  0.034967266 Validation Decoder Loss:  0.33110893
Encoder Loss:  0.043758262  || Decoder Loss:  0.03496126 Validation Decoder Loss:  0.33111823
Encoder Loss:  0.043575536  || Decoder Loss:  0.034954432 Validation Decoder Loss:  0.3311497
Encoder Loss:  0.043446943  || Decoder Loss:  0.03494798 Validation Decoder Loss:  0.33117276
Encoder Loss:  0.043493986  || Decoder Loss:  0.03494216 Validation Decoder Loss:  0.33119333
Encoder Loss:  0.043478385  || Decoder Loss:  0.03493644 Validation Decoder Loss:  0.3312157
Encoder Loss:  0.04343518  || Decoder Loss:  0.034931373 Validation Decoder Loss:  0.33122587
Encoder Loss:  0.04347475  || Decoder Loss:  0.0349264 Validation Decoder Loss:  0.33124173
Encoder Loss:  0.043412782  || Decoder Loss:  0.03492175 Validation Decoder Loss:  0.33125308
Encoder Loss:  0.04342529  || Decoder Loss:  0.034917742 Validation Decoder Loss:  0.3312629
Encoder Loss:  0.04346819  || Decoder Loss:  0.034914054 Validation Decoder Loss:  0.3312717
Encoder Loss:  0.043458235  || Decoder Loss:  0.03491097 Validation Decoder Loss:  0.33128133
Encoder Loss:  0.04341355  || Decoder Loss:  0.034908056 Validation Decoder Loss:  0.33129412
Encoder Loss:  0.043459672  || Decoder Loss:  0.034905687 Validation Decoder Loss:  0.33131272
Encoder Loss:  0.043493185  || Decoder Loss:  0.034903668 Validation Decoder Loss:  0.33132195
Encoder Loss:  0.04340328  || Decoder Loss:  0.034901753 Validation Decoder Loss:  0.33133256
Encoder Loss:  0.04340223  || Decoder Loss:  0.034900445 Validation Decoder Loss:  0.33133876
Encoder Loss:  0.04342301  || Decoder Loss:  0.03489892 Validation Decoder Loss:  0.33135596
Encoder Loss:  0.043377906  || Decoder Loss:  0.03489728 Validation Decoder Loss:  0.33136886
Encoder Loss:  0.043464355  || Decoder Loss:  0.03489673 Validation Decoder Loss:  0.33135906
Encoder Loss:  0.043431826  || Decoder Loss:  0.034896 Validation Decoder Loss:  0.33136192
Encoder Loss:  0.04339552  || Decoder Loss:  0.034895517 Validation Decoder Loss:  0.3313492
Encoder Loss:  0.04337461  || Decoder Loss:  0.034894902 Validation Decoder Loss:  0.33135805
Encoder Loss:  0.043380514  || Decoder Loss:  0.034894127 Validation Decoder Loss:  0.33136934
Encoder Loss:  0.043359417  || Decoder Loss:  0.034893323 Validation Decoder Loss:  0.33138052
Encoder Loss:  0.043342337  || Decoder Loss:  0.03489267 Validation Decoder Loss:  0.3313902
Model: siamese_net_lr_0.0007458693203033984 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3313902
Model: "sequential_642"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_350 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_804 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_351 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_187 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_806 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_808 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36900434  || Decoder Loss:  0.071442336 Validation Decoder Loss:  0.36035544
Encoder Loss:  0.36793834  || Decoder Loss:  0.07266914 Validation Decoder Loss:  0.36001325
Encoder Loss:  0.3665717  || Decoder Loss:  0.07389315 Validation Decoder Loss:  0.3591742
Encoder Loss:  0.36247304  || Decoder Loss:  0.07479018 Validation Decoder Loss:  0.3584404
Encoder Loss:  0.3536544  || Decoder Loss:  0.07535458 Validation Decoder Loss:  0.35760316
Encoder Loss:  0.34247547  || Decoder Loss:  0.07473522 Validation Decoder Loss:  0.35149407
Encoder Loss:  0.32651052  || Decoder Loss:  0.04425683 Validation Decoder Loss:  0.32372433
Encoder Loss:  0.3118021  || Decoder Loss:  0.035463996 Validation Decoder Loss:  0.32600084
Encoder Loss:  0.29338855  || Decoder Loss:  0.035348024 Validation Decoder Loss:  0.3282861
Encoder Loss:  0.22875357  || Decoder Loss:  0.03529636 Validation Decoder Loss:  0.33205575
Encoder Loss:  0.08217276  || Decoder Loss:  0.035260927 Validation Decoder Loss:  0.33208728
Encoder Loss:  0.08193864  || Decoder Loss:  0.03523262 Validation Decoder Loss:  0.33198702
Encoder Loss:  0.08154126  || Decoder Loss:  0.03520828 Validation Decoder Loss:  0.3319003
Encoder Loss:  0.081221245  || Decoder Loss:  0.035185948 Validation Decoder Loss:  0.33181483
Encoder Loss:  0.08085088  || Decoder Loss:  0.03516505 Validation Decoder Loss:  0.3317362
Encoder Loss:  0.080493145  || Decoder Loss:  0.035145476 Validation Decoder Loss:  0.33165622
Encoder Loss:  0.08009116  || Decoder Loss:  0.035127275 Validation Decoder Loss:  0.33157578
Encoder Loss:  0.079629995  || Decoder Loss:  0.035110414 Validation Decoder Loss:  0.33149907
Encoder Loss:  0.07917093  || Decoder Loss:  0.035095092 Validation Decoder Loss:  0.331424
Encoder Loss:  0.0786362  || Decoder Loss:  0.03508164 Validation Decoder Loss:  0.33135617
Encoder Loss:  0.07808167  || Decoder Loss:  0.035070434 Validation Decoder Loss:  0.33129612
Encoder Loss:  0.07751064  || Decoder Loss:  0.035061702 Validation Decoder Loss:  0.33124337
Encoder Loss:  0.0768211  || Decoder Loss:  0.035055187 Validation Decoder Loss:  0.33120543
Encoder Loss:  0.076139405  || Decoder Loss:  0.035050463 Validation Decoder Loss:  0.33117428
Encoder Loss:  0.075370476  || Decoder Loss:  0.035047088 Validation Decoder Loss:  0.33115208
Encoder Loss:  0.07448981  || Decoder Loss:  0.035044383 Validation Decoder Loss:  0.33114117
Encoder Loss:  0.073589854  || Decoder Loss:  0.035042126 Validation Decoder Loss:  0.33113402
Encoder Loss:  0.07256763  || Decoder Loss:  0.03504011 Validation Decoder Loss:  0.33112964
Encoder Loss:  0.07141461  || Decoder Loss:  0.035038244 Validation Decoder Loss:  0.3311305
Encoder Loss:  0.07011047  || Decoder Loss:  0.03503647 Validation Decoder Loss:  0.33113545
Encoder Loss:  0.06867275  || Decoder Loss:  0.035034727 Validation Decoder Loss:  0.33114144
Encoder Loss:  0.06703336  || Decoder Loss:  0.035033133 Validation Decoder Loss:  0.3311513
Encoder Loss:  0.065190546  || Decoder Loss:  0.03503151 Validation Decoder Loss:  0.33117184
Encoder Loss:  0.063148856  || Decoder Loss:  0.035029653 Validation Decoder Loss:  0.3312018
Encoder Loss:  0.061007556  || Decoder Loss:  0.035027467 Validation Decoder Loss:  0.33124188
Encoder Loss:  0.059015185  || Decoder Loss:  0.03502452 Validation Decoder Loss:  0.33128557
Encoder Loss:  0.057287354  || Decoder Loss:  0.035021108 Validation Decoder Loss:  0.33132765
Encoder Loss:  0.055981606  || Decoder Loss:  0.035017554 Validation Decoder Loss:  0.33136696
Encoder Loss:  0.05485513  || Decoder Loss:  0.03501417 Validation Decoder Loss:  0.33139908
Encoder Loss:  0.053941723  || Decoder Loss:  0.035011187 Validation Decoder Loss:  0.3314272
Model: siamese_net_lr_0.0001614397261725555 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33142722
Model: "sequential_646"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_353 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_810 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_354 (Conv3D (None, 514, 5, 19, 1)     31        
_________________________________________________________________
reshape_188 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 91
Trainable params: 91
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_812 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_649"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_814 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1795616  || Decoder Loss:  0.039163303 Validation Decoder Loss:  0.33436418
Encoder Loss:  0.16880675  || Decoder Loss:  0.039179113 Validation Decoder Loss:  0.33164692
Encoder Loss:  0.15061727  || Decoder Loss:  0.035306603 Validation Decoder Loss:  0.32995486
Encoder Loss:  0.12822613  || Decoder Loss:  0.03521736 Validation Decoder Loss:  0.32947612
Encoder Loss:  0.057832602  || Decoder Loss:  0.035272572 Validation Decoder Loss:  0.32952958
Encoder Loss:  0.047521643  || Decoder Loss:  0.035153933 Validation Decoder Loss:  0.32942164
Encoder Loss:  0.047058955  || Decoder Loss:  0.035039686 Validation Decoder Loss:  0.32940567
Encoder Loss:  0.04655377  || Decoder Loss:  0.03498577 Validation Decoder Loss:  0.32939404
Encoder Loss:  0.044829268  || Decoder Loss:  0.034961876 Validation Decoder Loss:  0.32937002
Encoder Loss:  0.042624164  || Decoder Loss:  0.034944892 Validation Decoder Loss:  0.32936072
Encoder Loss:  0.042359985  || Decoder Loss:  0.034934748 Validation Decoder Loss:  0.3293701
Encoder Loss:  0.042226214  || Decoder Loss:  0.034927834 Validation Decoder Loss:  0.32937306
Encoder Loss:  0.042088017  || Decoder Loss:  0.03492208 Validation Decoder Loss:  0.32936814
Encoder Loss:  0.041946784  || Decoder Loss:  0.034916762 Validation Decoder Loss:  0.32935718
Encoder Loss:  0.04178233  || Decoder Loss:  0.034911647 Validation Decoder Loss:  0.32934412
Encoder Loss:  0.04157761  || Decoder Loss:  0.034906115 Validation Decoder Loss:  0.3293288
Encoder Loss:  0.041358832  || Decoder Loss:  0.03489992 Validation Decoder Loss:  0.32931352
Encoder Loss:  0.04119074  || Decoder Loss:  0.03489356 Validation Decoder Loss:  0.32930338
Encoder Loss:  0.041000996  || Decoder Loss:  0.034887444 Validation Decoder Loss:  0.32929283
Encoder Loss:  0.04087861  || Decoder Loss:  0.034881417 Validation Decoder Loss:  0.32929003
Encoder Loss:  0.04082181  || Decoder Loss:  0.03487653 Validation Decoder Loss:  0.3292927
Encoder Loss:  0.040753555  || Decoder Loss:  0.034872435 Validation Decoder Loss:  0.3292945
Encoder Loss:  0.040712733  || Decoder Loss:  0.034867905 Validation Decoder Loss:  0.32929742
Encoder Loss:  0.04069279  || Decoder Loss:  0.034863777 Validation Decoder Loss:  0.32930112
Encoder Loss:  0.040677894  || Decoder Loss:  0.03485996 Validation Decoder Loss:  0.32930708
Encoder Loss:  0.04066762  || Decoder Loss:  0.03485654 Validation Decoder Loss:  0.32931474
Encoder Loss:  0.040654346  || Decoder Loss:  0.034853406 Validation Decoder Loss:  0.32932287
Encoder Loss:  0.040646996  || Decoder Loss:  0.03485039 Validation Decoder Loss:  0.32933298
Encoder Loss:  0.040652663  || Decoder Loss:  0.0348478 Validation Decoder Loss:  0.32934764
Encoder Loss:  0.040644545  || Decoder Loss:  0.034845814 Validation Decoder Loss:  0.32936108
Encoder Loss:  0.040656373  || Decoder Loss:  0.034844402 Validation Decoder Loss:  0.32938007
Encoder Loss:  0.040638424  || Decoder Loss:  0.034842756 Validation Decoder Loss:  0.32939586
Encoder Loss:  0.040641773  || Decoder Loss:  0.034841426 Validation Decoder Loss:  0.3294142
Encoder Loss:  0.04064073  || Decoder Loss:  0.034840107 Validation Decoder Loss:  0.32943696
Encoder Loss:  0.04063294  || Decoder Loss:  0.034839056 Validation Decoder Loss:  0.32945824
Encoder Loss:  0.040634975  || Decoder Loss:  0.03483805 Validation Decoder Loss:  0.32948312
Encoder Loss:  0.040615577  || Decoder Loss:  0.03483656 Validation Decoder Loss:  0.3295102
Encoder Loss:  0.040622987  || Decoder Loss:  0.03483541 Validation Decoder Loss:  0.32954252
Encoder Loss:  0.040613163  || Decoder Loss:  0.034835175 Validation Decoder Loss:  0.32957935
Encoder Loss:  0.0405997  || Decoder Loss:  0.034833647 Validation Decoder Loss:  0.32960963
Model: siamese_net_lr_0.00025437085511405814 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32960963
Model: "sequential_650"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_356 (Conv3D (None, 400, 5, 19, 1)     338       
_________________________________________________________________
dropout_816 (Dropout)        (None, 400, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_357 (Conv3D (None, 514, 5, 19, 1)     116       
_________________________________________________________________
reshape_189 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_652"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_272 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_818 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_273 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_653"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_272 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_820 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_273 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08110574  || Decoder Loss:  0.069713295 Validation Decoder Loss:  0.360494
Encoder Loss:  0.072698124  || Decoder Loss:  0.061569486 Validation Decoder Loss:  0.32879245
Encoder Loss:  0.04139582  || Decoder Loss:  0.03549398 Validation Decoder Loss:  0.33257502
Encoder Loss:  0.036961973  || Decoder Loss:  0.035316233 Validation Decoder Loss:  0.33200777
Encoder Loss:  0.036789916  || Decoder Loss:  0.03520918 Validation Decoder Loss:  0.33154932
Encoder Loss:  0.036644567  || Decoder Loss:  0.035133325 Validation Decoder Loss:  0.33148283
Encoder Loss:  0.03637698  || Decoder Loss:  0.0350823 Validation Decoder Loss:  0.33112377
Encoder Loss:  0.035622936  || Decoder Loss:  0.03505364 Validation Decoder Loss:  0.3310802
Encoder Loss:  0.035551682  || Decoder Loss:  0.035027552 Validation Decoder Loss:  0.3311016
Encoder Loss:  0.035536394  || Decoder Loss:  0.03501394 Validation Decoder Loss:  0.33112603
Encoder Loss:  0.035526272  || Decoder Loss:  0.035004683 Validation Decoder Loss:  0.33115193
Encoder Loss:  0.03551728  || Decoder Loss:  0.034996882 Validation Decoder Loss:  0.33117825
Encoder Loss:  0.03550874  || Decoder Loss:  0.034989417 Validation Decoder Loss:  0.3312042
Encoder Loss:  0.03550099  || Decoder Loss:  0.034982055 Validation Decoder Loss:  0.33123296
Encoder Loss:  0.03549313  || Decoder Loss:  0.034974374 Validation Decoder Loss:  0.33126426
Encoder Loss:  0.035484746  || Decoder Loss:  0.034966253 Validation Decoder Loss:  0.3312996
Encoder Loss:  0.035475798  || Decoder Loss:  0.03495752 Validation Decoder Loss:  0.3313394
Encoder Loss:  0.0354667  || Decoder Loss:  0.03494816 Validation Decoder Loss:  0.33138576
Encoder Loss:  0.03545643  || Decoder Loss:  0.034937944 Validation Decoder Loss:  0.33144087
Encoder Loss:  0.03544589  || Decoder Loss:  0.034926873 Validation Decoder Loss:  0.33150685
Encoder Loss:  0.03543333  || Decoder Loss:  0.034914624 Validation Decoder Loss:  0.3315891
Encoder Loss:  0.035420388  || Decoder Loss:  0.03490098 Validation Decoder Loss:  0.33169174
Encoder Loss:  0.03540568  || Decoder Loss:  0.034885462 Validation Decoder Loss:  0.3318263
Encoder Loss:  0.035388455  || Decoder Loss:  0.034867834 Validation Decoder Loss:  0.332004
Encoder Loss:  0.035368692  || Decoder Loss:  0.034848277 Validation Decoder Loss:  0.33222875
Encoder Loss:  0.035349917  || Decoder Loss:  0.03482807 Validation Decoder Loss:  0.33251488
Encoder Loss:  0.035331316  || Decoder Loss:  0.034809634 Validation Decoder Loss:  0.33285365
Encoder Loss:  0.035318658  || Decoder Loss:  0.034796365 Validation Decoder Loss:  0.3331523
Encoder Loss:  0.035312027  || Decoder Loss:  0.03478977 Validation Decoder Loss:  0.33331487
Encoder Loss:  0.035308715  || Decoder Loss:  0.03478674 Validation Decoder Loss:  0.3333835
Encoder Loss:  0.035307035  || Decoder Loss:  0.03478489 Validation Decoder Loss:  0.33340704
Encoder Loss:  0.035305563  || Decoder Loss:  0.034783527 Validation Decoder Loss:  0.3334226
Encoder Loss:  0.035304178  || Decoder Loss:  0.034782242 Validation Decoder Loss:  0.3334306
Encoder Loss:  0.035302438  || Decoder Loss:  0.034781147 Validation Decoder Loss:  0.3334372
Encoder Loss:  0.03530092  || Decoder Loss:  0.034780208 Validation Decoder Loss:  0.33345082
Encoder Loss:  0.035298992  || Decoder Loss:  0.034779187 Validation Decoder Loss:  0.3334551
Encoder Loss:  0.03529266  || Decoder Loss:  0.034778193 Validation Decoder Loss:  0.33345756
Encoder Loss:  0.03528833  || Decoder Loss:  0.034776613 Validation Decoder Loss:  0.33346152
Encoder Loss:  0.03528618  || Decoder Loss:  0.034774937 Validation Decoder Loss:  0.33346683
Encoder Loss:  0.035284445  || Decoder Loss:  0.03477343 Validation Decoder Loss:  0.33347303
Model: siamese_net_lr_0.0005959030195080232 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33347303
Model: "sequential_654"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_359 (Conv3D (None, 298, 5, 19, 1)     47        
_________________________________________________________________
dropout_822 (Dropout)        (None, 298, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_360 (Conv3D (None, 514, 5, 19, 1)     218       
_________________________________________________________________
reshape_190 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 265
Trainable params: 265
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_656"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_274 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_824 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_275 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_657"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_274 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_826 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_275 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31325486  || Decoder Loss:  0.08961967 Validation Decoder Loss:  0.36487466
Encoder Loss:  0.31169614  || Decoder Loss:  0.09321878 Validation Decoder Loss:  0.36514974
Encoder Loss:  0.30973813  || Decoder Loss:  0.09649284 Validation Decoder Loss:  0.36339608
Encoder Loss:  0.29679188  || Decoder Loss:  0.062262002 Validation Decoder Loss:  0.33206487
Encoder Loss:  0.27527472  || Decoder Loss:  0.035652958 Validation Decoder Loss:  0.33267713
Encoder Loss:  0.08542804  || Decoder Loss:  0.03555912 Validation Decoder Loss:  0.3324802
Encoder Loss:  0.08377215  || Decoder Loss:  0.035485603 Validation Decoder Loss:  0.3321463
Encoder Loss:  0.083141476  || Decoder Loss:  0.035432007 Validation Decoder Loss:  0.33186638
Encoder Loss:  0.083108924  || Decoder Loss:  0.0353873 Validation Decoder Loss:  0.33162493
Encoder Loss:  0.08041587  || Decoder Loss:  0.03534673 Validation Decoder Loss:  0.33141392
Encoder Loss:  0.076431654  || Decoder Loss:  0.035307247 Validation Decoder Loss:  0.33123404
Encoder Loss:  0.06566452  || Decoder Loss:  0.035266396 Validation Decoder Loss:  0.3310853
Encoder Loss:  0.04627897  || Decoder Loss:  0.035227302 Validation Decoder Loss:  0.33099258
Encoder Loss:  0.04604645  || Decoder Loss:  0.035195176 Validation Decoder Loss:  0.33092034
Encoder Loss:  0.046016913  || Decoder Loss:  0.03516444 Validation Decoder Loss:  0.33088893
Encoder Loss:  0.0460036  || Decoder Loss:  0.03513384 Validation Decoder Loss:  0.33088493
Encoder Loss:  0.045994993  || Decoder Loss:  0.035104558 Validation Decoder Loss:  0.3308944
Encoder Loss:  0.045992576  || Decoder Loss:  0.03507917 Validation Decoder Loss:  0.33091184
Encoder Loss:  0.045980077  || Decoder Loss:  0.035059754 Validation Decoder Loss:  0.33093196
Encoder Loss:  0.04597257  || Decoder Loss:  0.035046283 Validation Decoder Loss:  0.33095053
Encoder Loss:  0.045967735  || Decoder Loss:  0.03503713 Validation Decoder Loss:  0.33096516
Encoder Loss:  0.045964986  || Decoder Loss:  0.03503043 Validation Decoder Loss:  0.3309753
Encoder Loss:  0.045961924  || Decoder Loss:  0.035024878 Validation Decoder Loss:  0.33098212
Encoder Loss:  0.04595827  || Decoder Loss:  0.03501983 Validation Decoder Loss:  0.33098704
Encoder Loss:  0.045956027  || Decoder Loss:  0.035015006 Validation Decoder Loss:  0.33099094
Encoder Loss:  0.045953527  || Decoder Loss:  0.035010286 Validation Decoder Loss:  0.33099455
Encoder Loss:  0.04595137  || Decoder Loss:  0.035005637 Validation Decoder Loss:  0.3309983
Encoder Loss:  0.045949105  || Decoder Loss:  0.03500103 Validation Decoder Loss:  0.3310024
Encoder Loss:  0.04594741  || Decoder Loss:  0.034996483 Validation Decoder Loss:  0.33100706
Encoder Loss:  0.045945402  || Decoder Loss:  0.034992002 Validation Decoder Loss:  0.33101216
Encoder Loss:  0.045944065  || Decoder Loss:  0.0349876 Validation Decoder Loss:  0.33101767
Encoder Loss:  0.04594232  || Decoder Loss:  0.03498328 Validation Decoder Loss:  0.33102363
Encoder Loss:  0.045940906  || Decoder Loss:  0.03497904 Validation Decoder Loss:  0.33102977
Encoder Loss:  0.045939468  || Decoder Loss:  0.03497491 Validation Decoder Loss:  0.3310363
Encoder Loss:  0.045938067  || Decoder Loss:  0.034970876 Validation Decoder Loss:  0.331043
Encoder Loss:  0.045937486  || Decoder Loss:  0.03496694 Validation Decoder Loss:  0.33104995
Encoder Loss:  0.045936123  || Decoder Loss:  0.034963116 Validation Decoder Loss:  0.331057
Encoder Loss:  0.045934748  || Decoder Loss:  0.034959424 Validation Decoder Loss:  0.3310643
Encoder Loss:  0.04593405  || Decoder Loss:  0.034955837 Validation Decoder Loss:  0.33107173
Encoder Loss:  0.045933418  || Decoder Loss:  0.03495242 Validation Decoder Loss:  0.33107933
Model: siamese_net_lr_0.0006013874403574129 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3310793
Model: "sequential_658"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_362 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_828 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_363 (Conv3D (None, 514, 5, 19, 1)     152       
_________________________________________________________________
reshape_191 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 212
Trainable params: 212
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_660"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_276 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_830 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_277 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_661"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_276 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_832 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_277 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39591745  || Decoder Loss:  0.066946365 Validation Decoder Loss:  0.3387922
Encoder Loss:  0.3329558  || Decoder Loss:  0.04567787 Validation Decoder Loss:  0.32852578
Encoder Loss:  0.14894363  || Decoder Loss:  0.03507261 Validation Decoder Loss:  0.32947916
Encoder Loss:  0.07541348  || Decoder Loss:  0.03506279 Validation Decoder Loss:  0.32959145
Encoder Loss:  0.07283752  || Decoder Loss:  0.035022102 Validation Decoder Loss:  0.32976085
Encoder Loss:  0.0698359  || Decoder Loss:  0.03499107 Validation Decoder Loss:  0.3299303
Encoder Loss:  0.06602201  || Decoder Loss:  0.034967434 Validation Decoder Loss:  0.3300745
Encoder Loss:  0.061515946  || Decoder Loss:  0.034947995 Validation Decoder Loss:  0.33019906
Encoder Loss:  0.056728277  || Decoder Loss:  0.03493145 Validation Decoder Loss:  0.3303166
Encoder Loss:  0.05301744  || Decoder Loss:  0.034918055 Validation Decoder Loss:  0.33039945
Encoder Loss:  0.050748944  || Decoder Loss:  0.03490651 Validation Decoder Loss:  0.33044076
Encoder Loss:  0.05008243  || Decoder Loss:  0.034893397 Validation Decoder Loss:  0.33043224
Encoder Loss:  0.050020386  || Decoder Loss:  0.03487752 Validation Decoder Loss:  0.3304282
Encoder Loss:  0.049961142  || Decoder Loss:  0.034859955 Validation Decoder Loss:  0.33043242
Encoder Loss:  0.049954776  || Decoder Loss:  0.03483984 Validation Decoder Loss:  0.33045244
Encoder Loss:  0.04993104  || Decoder Loss:  0.034817506 Validation Decoder Loss:  0.33049807
Encoder Loss:  0.04995757  || Decoder Loss:  0.03479997 Validation Decoder Loss:  0.33053318
Encoder Loss:  0.049920954  || Decoder Loss:  0.034788586 Validation Decoder Loss:  0.33054566
Encoder Loss:  0.049902365  || Decoder Loss:  0.034780312 Validation Decoder Loss:  0.33055016
Encoder Loss:  0.04993732  || Decoder Loss:  0.03477384 Validation Decoder Loss:  0.33055362
Encoder Loss:  0.04990311  || Decoder Loss:  0.034768574 Validation Decoder Loss:  0.33055693
Encoder Loss:  0.04994273  || Decoder Loss:  0.034764167 Validation Decoder Loss:  0.33055934
Encoder Loss:  0.04989399  || Decoder Loss:  0.03476035 Validation Decoder Loss:  0.33056098
Encoder Loss:  0.04988848  || Decoder Loss:  0.034757007 Validation Decoder Loss:  0.3305625
Encoder Loss:  0.049913287  || Decoder Loss:  0.03475405 Validation Decoder Loss:  0.33056417
Encoder Loss:  0.0498865  || Decoder Loss:  0.034751415 Validation Decoder Loss:  0.33056542
Encoder Loss:  0.049917728  || Decoder Loss:  0.034749053 Validation Decoder Loss:  0.33056664
Encoder Loss:  0.04989546  || Decoder Loss:  0.034746893 Validation Decoder Loss:  0.33056772
Encoder Loss:  0.049889218  || Decoder Loss:  0.034744956 Validation Decoder Loss:  0.33056867
Encoder Loss:  0.049898203  || Decoder Loss:  0.034743186 Validation Decoder Loss:  0.33056965
Encoder Loss:  0.04987225  || Decoder Loss:  0.034741543 Validation Decoder Loss:  0.3305704
Encoder Loss:  0.049878076  || Decoder Loss:  0.03474004 Validation Decoder Loss:  0.3305714
Encoder Loss:  0.049871877  || Decoder Loss:  0.034738656 Validation Decoder Loss:  0.330572
Encoder Loss:  0.049874596  || Decoder Loss:  0.034737416 Validation Decoder Loss:  0.33057335
Encoder Loss:  0.049867872  || Decoder Loss:  0.03473626 Validation Decoder Loss:  0.3305746
Encoder Loss:  0.049886856  || Decoder Loss:  0.034735173 Validation Decoder Loss:  0.33057588
Encoder Loss:  0.04987431  || Decoder Loss:  0.034734216 Validation Decoder Loss:  0.33057785
Encoder Loss:  0.049882345  || Decoder Loss:  0.03473328 Validation Decoder Loss:  0.33057907
Encoder Loss:  0.049881317  || Decoder Loss:  0.034732442 Validation Decoder Loss:  0.3305807
Encoder Loss:  0.04988001  || Decoder Loss:  0.034731664 Validation Decoder Loss:  0.33058256
Model: siamese_net_lr_0.0003201350775132391 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33058256
Model: "sequential_662"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_365 (Conv3D (None, 284, 5, 19, 1)     159       
_________________________________________________________________
dropout_834 (Dropout)        (None, 284, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_366 (Conv3D (None, 514, 5, 19, 1)     232       
_________________________________________________________________
reshape_192 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_664"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_278 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_836 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_279 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_665"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_278 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_838 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_279 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25045967  || Decoder Loss:  0.06640485 Validation Decoder Loss:  0.33160457
Encoder Loss:  0.069536954  || Decoder Loss:  0.0354581 Validation Decoder Loss:  0.33215186
Encoder Loss:  0.050240487  || Decoder Loss:  0.035432506 Validation Decoder Loss:  0.33238503
Encoder Loss:  0.050178632  || Decoder Loss:  0.035408136 Validation Decoder Loss:  0.33251444
Encoder Loss:  0.04849804  || Decoder Loss:  0.035385292 Validation Decoder Loss:  0.33258665
Encoder Loss:  0.048226  || Decoder Loss:  0.035365958 Validation Decoder Loss:  0.3326515
Encoder Loss:  0.048188366  || Decoder Loss:  0.035347227 Validation Decoder Loss:  0.33271825
Encoder Loss:  0.04817286  || Decoder Loss:  0.035324715 Validation Decoder Loss:  0.33274174
Encoder Loss:  0.048185717  || Decoder Loss:  0.035293985 Validation Decoder Loss:  0.33262804
Encoder Loss:  0.048165597  || Decoder Loss:  0.0352609 Validation Decoder Loss:  0.33243862
Encoder Loss:  0.048160262  || Decoder Loss:  0.03523388 Validation Decoder Loss:  0.33235455
Encoder Loss:  0.04815795  || Decoder Loss:  0.035217296 Validation Decoder Loss:  0.33229533
Encoder Loss:  0.048146505  || Decoder Loss:  0.03520439 Validation Decoder Loss:  0.3322605
Encoder Loss:  0.04813412  || Decoder Loss:  0.03519492 Validation Decoder Loss:  0.3322383
Encoder Loss:  0.048116207  || Decoder Loss:  0.03518857 Validation Decoder Loss:  0.33221596
Encoder Loss:  0.0481221  || Decoder Loss:  0.035184596 Validation Decoder Loss:  0.3322112
Encoder Loss:  0.048115555  || Decoder Loss:  0.035180446 Validation Decoder Loss:  0.33221716
Encoder Loss:  0.04811796  || Decoder Loss:  0.03517698 Validation Decoder Loss:  0.33223403
Encoder Loss:  0.048115473  || Decoder Loss:  0.035173923 Validation Decoder Loss:  0.33224875
Encoder Loss:  0.04811801  || Decoder Loss:  0.035171863 Validation Decoder Loss:  0.33226937
Encoder Loss:  0.048113123  || Decoder Loss:  0.03516871 Validation Decoder Loss:  0.33229423
Encoder Loss:  0.04811506  || Decoder Loss:  0.035167094 Validation Decoder Loss:  0.33229494
Encoder Loss:  0.048115492  || Decoder Loss:  0.03516452 Validation Decoder Loss:  0.33233166
Encoder Loss:  0.048113342  || Decoder Loss:  0.035161313 Validation Decoder Loss:  0.33235407
Encoder Loss:  0.048111323  || Decoder Loss:  0.035159506 Validation Decoder Loss:  0.3323782
Encoder Loss:  0.048115812  || Decoder Loss:  0.035156596 Validation Decoder Loss:  0.33244514
Encoder Loss:  0.048122853  || Decoder Loss:  0.035155628 Validation Decoder Loss:  0.33242384
Encoder Loss:  0.048113212  || Decoder Loss:  0.03515288 Validation Decoder Loss:  0.33245552
Encoder Loss:  0.048114967  || Decoder Loss:  0.035150614 Validation Decoder Loss:  0.33258152
Encoder Loss:  0.048120428  || Decoder Loss:  0.035149503 Validation Decoder Loss:  0.33249694
Encoder Loss:  0.048105635  || Decoder Loss:  0.03514785 Validation Decoder Loss:  0.33247867
Encoder Loss:  0.04811594  || Decoder Loss:  0.03514699 Validation Decoder Loss:  0.33252662
Encoder Loss:  0.04811039  || Decoder Loss:  0.03514443 Validation Decoder Loss:  0.33251303
Encoder Loss:  0.048108123  || Decoder Loss:  0.03514272 Validation Decoder Loss:  0.33252287
Encoder Loss:  0.04810659  || Decoder Loss:  0.035142146 Validation Decoder Loss:  0.33254805
Encoder Loss:  0.04811419  || Decoder Loss:  0.03513719 Validation Decoder Loss:  0.33269066
Encoder Loss:  0.048112307  || Decoder Loss:  0.035137143 Validation Decoder Loss:  0.3326212
Encoder Loss:  0.04811146  || Decoder Loss:  0.035134457 Validation Decoder Loss:  0.33263636
Encoder Loss:  0.04810483  || Decoder Loss:  0.035134282 Validation Decoder Loss:  0.33262727
Encoder Loss:  0.048109423  || Decoder Loss:  0.03513133 Validation Decoder Loss:  0.332673
Model: siamese_net_lr_0.0005673251249725292 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33267304
Model: "sequential_666"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_368 (Conv3D (None, 370, 5, 19, 1)     182       
_________________________________________________________________
dropout_840 (Dropout)        (None, 370, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_369 (Conv3D (None, 514, 5, 19, 1)     146       
_________________________________________________________________
reshape_193 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_668"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_280 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_842 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_281 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_669"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_280 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_844 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_281 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14476518  || Decoder Loss:  0.08015233 Validation Decoder Loss:  0.36225206
Encoder Loss:  0.1252777  || Decoder Loss:  0.06183606 Validation Decoder Loss:  0.3329584
Encoder Loss:  0.052285198  || Decoder Loss:  0.035466824 Validation Decoder Loss:  0.33109424
Encoder Loss:  0.046453882  || Decoder Loss:  0.03539236 Validation Decoder Loss:  0.33103544
Encoder Loss:  0.045937352  || Decoder Loss:  0.035320073 Validation Decoder Loss:  0.3312666
Encoder Loss:  0.043087006  || Decoder Loss:  0.03525557 Validation Decoder Loss:  0.33137864
Encoder Loss:  0.038362168  || Decoder Loss:  0.035203915 Validation Decoder Loss:  0.3312252
Encoder Loss:  0.03829106  || Decoder Loss:  0.03515814 Validation Decoder Loss:  0.33111733
Encoder Loss:  0.038250748  || Decoder Loss:  0.035124198 Validation Decoder Loss:  0.33104336
Encoder Loss:  0.03822343  || Decoder Loss:  0.03510149 Validation Decoder Loss:  0.33101314
Encoder Loss:  0.03820925  || Decoder Loss:  0.035086397 Validation Decoder Loss:  0.33101934
Encoder Loss:  0.03819655  || Decoder Loss:  0.035074495 Validation Decoder Loss:  0.33105165
Encoder Loss:  0.03818639  || Decoder Loss:  0.03506352 Validation Decoder Loss:  0.33109957
Encoder Loss:  0.038166717  || Decoder Loss:  0.035052866 Validation Decoder Loss:  0.33115637
Encoder Loss:  0.03815471  || Decoder Loss:  0.035042416 Validation Decoder Loss:  0.33122337
Encoder Loss:  0.038143165  || Decoder Loss:  0.035032306 Validation Decoder Loss:  0.33129525
Encoder Loss:  0.03815029  || Decoder Loss:  0.03502243 Validation Decoder Loss:  0.33136517
Encoder Loss:  0.03810906  || Decoder Loss:  0.03501259 Validation Decoder Loss:  0.33144158
Encoder Loss:  0.038096897  || Decoder Loss:  0.03500309 Validation Decoder Loss:  0.33151498
Encoder Loss:  0.038066365  || Decoder Loss:  0.03499437 Validation Decoder Loss:  0.33159608
Encoder Loss:  0.038044795  || Decoder Loss:  0.034986928 Validation Decoder Loss:  0.3316772
Encoder Loss:  0.038019262  || Decoder Loss:  0.03498088 Validation Decoder Loss:  0.33176136
Encoder Loss:  0.038006768  || Decoder Loss:  0.03497616 Validation Decoder Loss:  0.3318389
Encoder Loss:  0.03799721  || Decoder Loss:  0.034972444 Validation Decoder Loss:  0.3319089
Encoder Loss:  0.037991937  || Decoder Loss:  0.0349694 Validation Decoder Loss:  0.3319673
Encoder Loss:  0.037987515  || Decoder Loss:  0.034966774 Validation Decoder Loss:  0.33201212
Encoder Loss:  0.03798397  || Decoder Loss:  0.034964386 Validation Decoder Loss:  0.3320456
Encoder Loss:  0.03798094  || Decoder Loss:  0.03496208 Validation Decoder Loss:  0.3320701
Encoder Loss:  0.037978083  || Decoder Loss:  0.034959845 Validation Decoder Loss:  0.3320871
Encoder Loss:  0.037975613  || Decoder Loss:  0.034957662 Validation Decoder Loss:  0.33209735
Encoder Loss:  0.037973452  || Decoder Loss:  0.034955524 Validation Decoder Loss:  0.33210582
Encoder Loss:  0.03797097  || Decoder Loss:  0.03495337 Validation Decoder Loss:  0.33211225
Encoder Loss:  0.03796871  || Decoder Loss:  0.03495121 Validation Decoder Loss:  0.33211666
Encoder Loss:  0.03796662  || Decoder Loss:  0.03494901 Validation Decoder Loss:  0.3321257
Encoder Loss:  0.03796446  || Decoder Loss:  0.034946773 Validation Decoder Loss:  0.33212817
Encoder Loss:  0.037962593  || Decoder Loss:  0.034944598 Validation Decoder Loss:  0.332134
Encoder Loss:  0.037960425  || Decoder Loss:  0.034942366 Validation Decoder Loss:  0.33213893
Encoder Loss:  0.037958566  || Decoder Loss:  0.034940124 Validation Decoder Loss:  0.33214155
Encoder Loss:  0.03795655  || Decoder Loss:  0.03493789 Validation Decoder Loss:  0.33214638
Encoder Loss:  0.037955053  || Decoder Loss:  0.034935668 Validation Decoder Loss:  0.33214146
Model: siamese_net_lr_0.0006909951338381588 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33214146
Model: "sequential_670"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_371 (Conv3D (None, 164, 5, 19, 1)     102       
_________________________________________________________________
dropout_846 (Dropout)        (None, 164, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_372 (Conv3D (None, 514, 5, 19, 1)     26        
_________________________________________________________________
reshape_194 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 128
Trainable params: 128
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_672"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_282 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_848 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_283 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_673"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_282 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_850 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_283 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40725207  || Decoder Loss:  0.03908701 Validation Decoder Loss:  0.33404538
Encoder Loss:  0.40409672  || Decoder Loss:  0.039482616 Validation Decoder Loss:  0.3328318
Encoder Loss:  0.39790994  || Decoder Loss:  0.03998326 Validation Decoder Loss:  0.33162224
Encoder Loss:  0.38792145  || Decoder Loss:  0.040556822 Validation Decoder Loss:  0.33053195
Encoder Loss:  0.3736881  || Decoder Loss:  0.04107654 Validation Decoder Loss:  0.329614
Encoder Loss:  0.3552693  || Decoder Loss:  0.041309096 Validation Decoder Loss:  0.32862118
Encoder Loss:  0.3333898  || Decoder Loss:  0.040654093 Validation Decoder Loss:  0.32638332
Encoder Loss:  0.30885565  || Decoder Loss:  0.036304843 Validation Decoder Loss:  0.32801297
Encoder Loss:  0.281914  || Decoder Loss:  0.03482789 Validation Decoder Loss:  0.32779205
Encoder Loss:  0.24909842  || Decoder Loss:  0.034958314 Validation Decoder Loss:  0.32799244
Encoder Loss:  0.19910294  || Decoder Loss:  0.03512432 Validation Decoder Loss:  0.32867998
Encoder Loss:  0.09691204  || Decoder Loss:  0.03527467 Validation Decoder Loss:  0.32964516
Encoder Loss:  0.06495397  || Decoder Loss:  0.03529113 Validation Decoder Loss:  0.32956228
Encoder Loss:  0.063192986  || Decoder Loss:  0.035281528 Validation Decoder Loss:  0.3295922
Encoder Loss:  0.06292255  || Decoder Loss:  0.03527061 Validation Decoder Loss:  0.3296719
Encoder Loss:  0.062361285  || Decoder Loss:  0.035258867 Validation Decoder Loss:  0.32977012
Encoder Loss:  0.06205608  || Decoder Loss:  0.035247844 Validation Decoder Loss:  0.32982463
Encoder Loss:  0.061728902  || Decoder Loss:  0.03523827 Validation Decoder Loss:  0.32984665
Encoder Loss:  0.061327167  || Decoder Loss:  0.035230104 Validation Decoder Loss:  0.32986063
Encoder Loss:  0.06098509  || Decoder Loss:  0.035223 Validation Decoder Loss:  0.3298685
Encoder Loss:  0.06061853  || Decoder Loss:  0.03521666 Validation Decoder Loss:  0.3298743
Encoder Loss:  0.060318213  || Decoder Loss:  0.035211075 Validation Decoder Loss:  0.32987523
Encoder Loss:  0.059901837  || Decoder Loss:  0.03520594 Validation Decoder Loss:  0.32987046
Encoder Loss:  0.059587497  || Decoder Loss:  0.035201315 Validation Decoder Loss:  0.32985917
Encoder Loss:  0.05930025  || Decoder Loss:  0.03519702 Validation Decoder Loss:  0.32984245
Encoder Loss:  0.0589254  || Decoder Loss:  0.035193104 Validation Decoder Loss:  0.3298235
Encoder Loss:  0.058641013  || Decoder Loss:  0.03518947 Validation Decoder Loss:  0.3298024
Encoder Loss:  0.05831921  || Decoder Loss:  0.03518612 Validation Decoder Loss:  0.32978165
Encoder Loss:  0.05798008  || Decoder Loss:  0.035182923 Validation Decoder Loss:  0.32976148
Encoder Loss:  0.05770738  || Decoder Loss:  0.035179958 Validation Decoder Loss:  0.3297431
Encoder Loss:  0.05745047  || Decoder Loss:  0.035177123 Validation Decoder Loss:  0.32972616
Encoder Loss:  0.05715476  || Decoder Loss:  0.035174426 Validation Decoder Loss:  0.3297118
Encoder Loss:  0.056912746  || Decoder Loss:  0.035171892 Validation Decoder Loss:  0.3296962
Encoder Loss:  0.056637462  || Decoder Loss:  0.035169408 Validation Decoder Loss:  0.32968178
Encoder Loss:  0.056390937  || Decoder Loss:  0.03516705 Validation Decoder Loss:  0.3296661
Encoder Loss:  0.056146517  || Decoder Loss:  0.035164755 Validation Decoder Loss:  0.32965124
Encoder Loss:  0.055908896  || Decoder Loss:  0.035162546 Validation Decoder Loss:  0.3296371
Encoder Loss:  0.05568525  || Decoder Loss:  0.035160385 Validation Decoder Loss:  0.32962257
Encoder Loss:  0.05544981  || Decoder Loss:  0.03515823 Validation Decoder Loss:  0.32960945
Encoder Loss:  0.0552274  || Decoder Loss:  0.03515616 Validation Decoder Loss:  0.3295966
Model: siamese_net_lr_0.0005301270612757964 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3295966
Model: "sequential_674"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_374 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_852 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_375 (Conv3D (None, 514, 5, 19, 1)     31        
_________________________________________________________________
reshape_195 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 91
Trainable params: 91
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_676"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_284 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_854 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_285 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_677"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_284 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_856 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_285 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.133738  || Decoder Loss:  0.03558124 Validation Decoder Loss:  0.32959735
Encoder Loss:  0.042300485  || Decoder Loss:  0.034909733 Validation Decoder Loss:  0.32922915
Encoder Loss:  0.041831817  || Decoder Loss:  0.03479472 Validation Decoder Loss:  0.329101
Encoder Loss:  0.04177254  || Decoder Loss:  0.034773976 Validation Decoder Loss:  0.32906836
Encoder Loss:  0.041742574  || Decoder Loss:  0.034759525 Validation Decoder Loss:  0.32905486
Encoder Loss:  0.04156642  || Decoder Loss:  0.034743935 Validation Decoder Loss:  0.32904777
Encoder Loss:  0.04159665  || Decoder Loss:  0.03472881 Validation Decoder Loss:  0.32907474
Encoder Loss:  0.04158522  || Decoder Loss:  0.034713637 Validation Decoder Loss:  0.32912368
Encoder Loss:  0.04156341  || Decoder Loss:  0.03470026 Validation Decoder Loss:  0.32920793
Encoder Loss:  0.04143548  || Decoder Loss:  0.034687363 Validation Decoder Loss:  0.32927686
Encoder Loss:  0.04133061  || Decoder Loss:  0.03467437 Validation Decoder Loss:  0.3293661
Encoder Loss:  0.041451763  || Decoder Loss:  0.034665193 Validation Decoder Loss:  0.3294554
Encoder Loss:  0.04138986  || Decoder Loss:  0.034654185 Validation Decoder Loss:  0.32953194
Encoder Loss:  0.041370302  || Decoder Loss:  0.034644905 Validation Decoder Loss:  0.3295874
Encoder Loss:  0.041348282  || Decoder Loss:  0.034637395 Validation Decoder Loss:  0.32964668
Encoder Loss:  0.04130493  || Decoder Loss:  0.03463088 Validation Decoder Loss:  0.3296811
Encoder Loss:  0.04127755  || Decoder Loss:  0.03462255 Validation Decoder Loss:  0.32973737
Encoder Loss:  0.04130054  || Decoder Loss:  0.03461621 Validation Decoder Loss:  0.3297946
Encoder Loss:  0.041229744  || Decoder Loss:  0.034606483 Validation Decoder Loss:  0.32985306
Encoder Loss:  0.041233994  || Decoder Loss:  0.03459476 Validation Decoder Loss:  0.32993278
Encoder Loss:  0.041243542  || Decoder Loss:  0.03458256 Validation Decoder Loss:  0.33001977
Encoder Loss:  0.041157536  || Decoder Loss:  0.034566056 Validation Decoder Loss:  0.33012357
Encoder Loss:  0.041154534  || Decoder Loss:  0.034548238 Validation Decoder Loss:  0.33025405
Encoder Loss:  0.041157164  || Decoder Loss:  0.034529757 Validation Decoder Loss:  0.33041093
Encoder Loss:  0.041141275  || Decoder Loss:  0.034510437 Validation Decoder Loss:  0.33060047
Encoder Loss:  0.041095167  || Decoder Loss:  0.034490794 Validation Decoder Loss:  0.3308054
Encoder Loss:  0.041097417  || Decoder Loss:  0.034472283 Validation Decoder Loss:  0.33103025
Encoder Loss:  0.04108807  || Decoder Loss:  0.0344547 Validation Decoder Loss:  0.33127168
Encoder Loss:  0.041022386  || Decoder Loss:  0.03443686 Validation Decoder Loss:  0.33151305
Encoder Loss:  0.041008968  || Decoder Loss:  0.03441897 Validation Decoder Loss:  0.33178133
Encoder Loss:  0.041001655  || Decoder Loss:  0.034401774 Validation Decoder Loss:  0.33202967
Encoder Loss:  0.04100082  || Decoder Loss:  0.034384605 Validation Decoder Loss:  0.33229136
Encoder Loss:  0.0409761  || Decoder Loss:  0.034367174 Validation Decoder Loss:  0.33256978
Encoder Loss:  0.040943775  || Decoder Loss:  0.034348793 Validation Decoder Loss:  0.33286303
Encoder Loss:  0.040945195  || Decoder Loss:  0.03433056 Validation Decoder Loss:  0.3332013
Encoder Loss:  0.040917315  || Decoder Loss:  0.03431343 Validation Decoder Loss:  0.33349454
Encoder Loss:  0.040883392  || Decoder Loss:  0.034297377 Validation Decoder Loss:  0.33377036
Encoder Loss:  0.04087773  || Decoder Loss:  0.03428112 Validation Decoder Loss:  0.3340429
Encoder Loss:  0.040851485  || Decoder Loss:  0.034265194 Validation Decoder Loss:  0.33433476
Encoder Loss:  0.04083571  || Decoder Loss:  0.034249727 Validation Decoder Loss:  0.33464617
Model: siamese_net_lr_0.0007262255623396601 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33464617
Model: "sequential_678"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_377 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_858 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_378 (Conv3D (None, 514, 5, 19, 1)     273       
_________________________________________________________________
reshape_196 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 333
Trainable params: 333
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_680"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_286 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_860 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_287 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_681"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_286 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_862 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_287 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2440792  || Decoder Loss:  0.089208156 Validation Decoder Loss:  0.36260146
Encoder Loss:  0.24146381  || Decoder Loss:  0.09128881 Validation Decoder Loss:  0.35878062
Encoder Loss:  0.2333272  || Decoder Loss:  0.08369343 Validation Decoder Loss:  0.33591014
Encoder Loss:  0.20621523  || Decoder Loss:  0.042164013 Validation Decoder Loss:  0.32907265
Encoder Loss:  0.17317724  || Decoder Loss:  0.035297226 Validation Decoder Loss:  0.33086988
Encoder Loss:  0.06599784  || Decoder Loss:  0.03532233 Validation Decoder Loss:  0.3308562
Encoder Loss:  0.0658375  || Decoder Loss:  0.03531308 Validation Decoder Loss:  0.3308019
Encoder Loss:  0.065158136  || Decoder Loss:  0.035304505 Validation Decoder Loss:  0.33077195
Encoder Loss:  0.06442819  || Decoder Loss:  0.035295747 Validation Decoder Loss:  0.33074287
Encoder Loss:  0.063453935  || Decoder Loss:  0.03528654 Validation Decoder Loss:  0.33072755
Encoder Loss:  0.06242974  || Decoder Loss:  0.035276648 Validation Decoder Loss:  0.33070725
Encoder Loss:  0.061159793  || Decoder Loss:  0.035265177 Validation Decoder Loss:  0.33068144
Encoder Loss:  0.059629336  || Decoder Loss:  0.035250906 Validation Decoder Loss:  0.3306461
Encoder Loss:  0.057736296  || Decoder Loss:  0.035231102 Validation Decoder Loss:  0.33059734
Encoder Loss:  0.055282127  || Decoder Loss:  0.035200235 Validation Decoder Loss:  0.33053112
Encoder Loss:  0.051922683  || Decoder Loss:  0.03514865 Validation Decoder Loss:  0.33047777
Encoder Loss:  0.04749244  || Decoder Loss:  0.035075683 Validation Decoder Loss:  0.3304929
Encoder Loss:  0.044028282  || Decoder Loss:  0.035015702 Validation Decoder Loss:  0.3305279
Encoder Loss:  0.043901667  || Decoder Loss:  0.034988716 Validation Decoder Loss:  0.33054894
Encoder Loss:  0.04388254  || Decoder Loss:  0.034975715 Validation Decoder Loss:  0.33054668
Encoder Loss:  0.043864593  || Decoder Loss:  0.034965646 Validation Decoder Loss:  0.3305351
Encoder Loss:  0.04384271  || Decoder Loss:  0.03495658 Validation Decoder Loss:  0.33052152
Encoder Loss:  0.0438059  || Decoder Loss:  0.03494804 Validation Decoder Loss:  0.3305083
Encoder Loss:  0.0436859  || Decoder Loss:  0.034939796 Validation Decoder Loss:  0.3304963
Encoder Loss:  0.042935956  || Decoder Loss:  0.034931663 Validation Decoder Loss:  0.33048618
Encoder Loss:  0.04271322  || Decoder Loss:  0.03492347 Validation Decoder Loss:  0.33047575
Encoder Loss:  0.04269774  || Decoder Loss:  0.034915194 Validation Decoder Loss:  0.33046538
Encoder Loss:  0.042691074  || Decoder Loss:  0.034906693 Validation Decoder Loss:  0.33045596
Encoder Loss:  0.04268462  || Decoder Loss:  0.034897897 Validation Decoder Loss:  0.3304474
Encoder Loss:  0.04267844  || Decoder Loss:  0.03488876 Validation Decoder Loss:  0.33043975
Encoder Loss:  0.04267275  || Decoder Loss:  0.034879252 Validation Decoder Loss:  0.33043307
Encoder Loss:  0.042666517  || Decoder Loss:  0.03486934 Validation Decoder Loss:  0.33042753
Encoder Loss:  0.042659946  || Decoder Loss:  0.034859072 Validation Decoder Loss:  0.33042347
Encoder Loss:  0.04265301  || Decoder Loss:  0.034848582 Validation Decoder Loss:  0.3304212
Encoder Loss:  0.04264719  || Decoder Loss:  0.034837957 Validation Decoder Loss:  0.3304214
Encoder Loss:  0.04264109  || Decoder Loss:  0.034827467 Validation Decoder Loss:  0.3304246
Encoder Loss:  0.042635582  || Decoder Loss:  0.03481738 Validation Decoder Loss:  0.33043137
Encoder Loss:  0.042630933  || Decoder Loss:  0.034807935 Validation Decoder Loss:  0.33044177
Encoder Loss:  0.04262414  || Decoder Loss:  0.034799352 Validation Decoder Loss:  0.3304557
Encoder Loss:  0.042619668  || Decoder Loss:  0.03479173 Validation Decoder Loss:  0.330472
Model: siamese_net_lr_0.00029015818703570804 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.330472
Model: "sequential_682"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_380 (Conv3D (None, 220, 5, 19, 1)     32        
_________________________________________________________________
dropout_864 (Dropout)        (None, 220, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_381 (Conv3D (None, 514, 5, 19, 1)     296       
_________________________________________________________________
reshape_197 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 328
Trainable params: 328
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_684"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_288 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_866 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_289 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_685"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_288 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_868 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_289 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33164138  || Decoder Loss:  0.0927085 Validation Decoder Loss:  0.37080818
Encoder Loss:  0.32583782  || Decoder Loss:  0.10401761 Validation Decoder Loss:  0.37867165
Encoder Loss:  0.3178248  || Decoder Loss:  0.110248625 Validation Decoder Loss:  0.37206376
Encoder Loss:  0.30471632  || Decoder Loss:  0.1035209 Validation Decoder Loss:  0.37666887
Encoder Loss:  0.27367964  || Decoder Loss:  0.04151514 Validation Decoder Loss:  0.33777082
Encoder Loss:  0.13103503  || Decoder Loss:  0.03739905 Validation Decoder Loss:  0.33600977
Encoder Loss:  0.04730515  || Decoder Loss:  0.03669739 Validation Decoder Loss:  0.33500057
Encoder Loss:  0.047214225  || Decoder Loss:  0.036372855 Validation Decoder Loss:  0.33437747
Encoder Loss:  0.047173966  || Decoder Loss:  0.03617396 Validation Decoder Loss:  0.33393228
Encoder Loss:  0.047145337  || Decoder Loss:  0.036035415 Validation Decoder Loss:  0.33358932
Encoder Loss:  0.047123622  || Decoder Loss:  0.03593151 Validation Decoder Loss:  0.33331135
Encoder Loss:  0.047106873  || Decoder Loss:  0.035849687 Validation Decoder Loss:  0.33307752
Encoder Loss:  0.047093328  || Decoder Loss:  0.035782978 Validation Decoder Loss:  0.33287546
Encoder Loss:  0.047081944  || Decoder Loss:  0.035727125 Validation Decoder Loss:  0.3326978
Encoder Loss:  0.047072064  || Decoder Loss:  0.035679385 Validation Decoder Loss:  0.33253944
Encoder Loss:  0.047063984  || Decoder Loss:  0.035637885 Validation Decoder Loss:  0.3323964
Encoder Loss:  0.047056165  || Decoder Loss:  0.03560133 Validation Decoder Loss:  0.33226573
Encoder Loss:  0.047049306  || Decoder Loss:  0.03556873 Validation Decoder Loss:  0.33214515
Encoder Loss:  0.0470438  || Decoder Loss:  0.03553937 Validation Decoder Loss:  0.33203262
Encoder Loss:  0.047037926  || Decoder Loss:  0.03551271 Validation Decoder Loss:  0.33192703
Encoder Loss:  0.047032904  || Decoder Loss:  0.035488307 Validation Decoder Loss:  0.33182746
Encoder Loss:  0.047028817  || Decoder Loss:  0.035465833 Validation Decoder Loss:  0.33173317
Encoder Loss:  0.047024317  || Decoder Loss:  0.03544502 Validation Decoder Loss:  0.33164367
Encoder Loss:  0.047020055  || Decoder Loss:  0.035425633 Validation Decoder Loss:  0.33155817
Encoder Loss:  0.047016293  || Decoder Loss:  0.03540748 Validation Decoder Loss:  0.33147603
Encoder Loss:  0.047012754  || Decoder Loss:  0.03539044 Validation Decoder Loss:  0.33139682
Encoder Loss:  0.04700937  || Decoder Loss:  0.035374388 Validation Decoder Loss:  0.3313203
Encoder Loss:  0.047006216  || Decoder Loss:  0.035359193 Validation Decoder Loss:  0.33124623
Encoder Loss:  0.04700318  || Decoder Loss:  0.035344783 Validation Decoder Loss:  0.33117425
Encoder Loss:  0.047000285  || Decoder Loss:  0.035331067 Validation Decoder Loss:  0.33110386
Encoder Loss:  0.04699755  || Decoder Loss:  0.03531802 Validation Decoder Loss:  0.33103484
Encoder Loss:  0.046994988  || Decoder Loss:  0.035305552 Validation Decoder Loss:  0.3309671
Encoder Loss:  0.04699254  || Decoder Loss:  0.035293616 Validation Decoder Loss:  0.3309008
Encoder Loss:  0.046990175  || Decoder Loss:  0.03528221 Validation Decoder Loss:  0.33083582
Encoder Loss:  0.046987925  || Decoder Loss:  0.035271276 Validation Decoder Loss:  0.3307717
Encoder Loss:  0.04698576  || Decoder Loss:  0.035260797 Validation Decoder Loss:  0.3307078
Encoder Loss:  0.046983674  || Decoder Loss:  0.03525075 Validation Decoder Loss:  0.33064377
Encoder Loss:  0.04698171  || Decoder Loss:  0.035241127 Validation Decoder Loss:  0.33057946
Encoder Loss:  0.046979796  || Decoder Loss:  0.035231926 Validation Decoder Loss:  0.33051497
Encoder Loss:  0.04697798  || Decoder Loss:  0.03522311 Validation Decoder Loss:  0.3304496
Model: siamese_net_lr_0.0008351642959901716 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3304496
Model: "sequential_686"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_383 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_870 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_384 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_198 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 204
Trainable params: 204
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_688"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_290 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_872 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_291 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_689"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_290 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_874 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_291 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17992721  || Decoder Loss:  0.054702964 Validation Decoder Loss:  0.33099562
Encoder Loss:  0.059220333  || Decoder Loss:  0.03511099 Validation Decoder Loss:  0.33089158
Encoder Loss:  0.046970457  || Decoder Loss:  0.035007734 Validation Decoder Loss:  0.33103067
Encoder Loss:  0.043052413  || Decoder Loss:  0.03497864 Validation Decoder Loss:  0.3310194
Encoder Loss:  0.042605985  || Decoder Loss:  0.034959115 Validation Decoder Loss:  0.33103368
Encoder Loss:  0.042574253  || Decoder Loss:  0.03494275 Validation Decoder Loss:  0.33105442
Encoder Loss:  0.04256185  || Decoder Loss:  0.03493019 Validation Decoder Loss:  0.33107862
Encoder Loss:  0.042549696  || Decoder Loss:  0.034921907 Validation Decoder Loss:  0.33109894
Encoder Loss:  0.042545483  || Decoder Loss:  0.034916867 Validation Decoder Loss:  0.33111316
Encoder Loss:  0.04254286  || Decoder Loss:  0.034913607 Validation Decoder Loss:  0.33111936
Encoder Loss:  0.042543806  || Decoder Loss:  0.03491135 Validation Decoder Loss:  0.3311139
Encoder Loss:  0.042541612  || Decoder Loss:  0.034909755 Validation Decoder Loss:  0.33110148
Encoder Loss:  0.042548265  || Decoder Loss:  0.034908682 Validation Decoder Loss:  0.33108696
Encoder Loss:  0.042534254  || Decoder Loss:  0.034907803 Validation Decoder Loss:  0.33107996
Encoder Loss:  0.042540777  || Decoder Loss:  0.034907192 Validation Decoder Loss:  0.33107287
Encoder Loss:  0.042529188  || Decoder Loss:  0.034906846 Validation Decoder Loss:  0.33107108
Encoder Loss:  0.042526126  || Decoder Loss:  0.034906562 Validation Decoder Loss:  0.33106744
Encoder Loss:  0.04252689  || Decoder Loss:  0.034906622 Validation Decoder Loss:  0.33105746
Encoder Loss:  0.04253479  || Decoder Loss:  0.034907117 Validation Decoder Loss:  0.33102626
Encoder Loss:  0.042529527  || Decoder Loss:  0.034907788 Validation Decoder Loss:  0.33098936
Encoder Loss:  0.042529885  || Decoder Loss:  0.034908634 Validation Decoder Loss:  0.33093327
Encoder Loss:  0.042523056  || Decoder Loss:  0.03490931 Validation Decoder Loss:  0.33088392
Encoder Loss:  0.04252687  || Decoder Loss:  0.03490976 Validation Decoder Loss:  0.33080792
Encoder Loss:  0.04252246  || Decoder Loss:  0.034909897 Validation Decoder Loss:  0.33075404
Encoder Loss:  0.04252119  || Decoder Loss:  0.034909498 Validation Decoder Loss:  0.33068496
Encoder Loss:  0.04251666  || Decoder Loss:  0.03490882 Validation Decoder Loss:  0.3306482
Encoder Loss:  0.042523503  || Decoder Loss:  0.03490806 Validation Decoder Loss:  0.3306312
Encoder Loss:  0.04251678  || Decoder Loss:  0.03490677 Validation Decoder Loss:  0.33056486
Encoder Loss:  0.042515587  || Decoder Loss:  0.03490525 Validation Decoder Loss:  0.33052093
Encoder Loss:  0.042516664  || Decoder Loss:  0.034903914 Validation Decoder Loss:  0.3305155
Encoder Loss:  0.04251723  || Decoder Loss:  0.034902133 Validation Decoder Loss:  0.33049446
Encoder Loss:  0.042510334  || Decoder Loss:  0.034899604 Validation Decoder Loss:  0.3304227
Encoder Loss:  0.04250586  || Decoder Loss:  0.03489677 Validation Decoder Loss:  0.33037323
Encoder Loss:  0.042509567  || Decoder Loss:  0.03489481 Validation Decoder Loss:  0.33037627
Encoder Loss:  0.04250844  || Decoder Loss:  0.03489451 Validation Decoder Loss:  0.33037192
Encoder Loss:  0.042507682  || Decoder Loss:  0.03489215 Validation Decoder Loss:  0.33032
Encoder Loss:  0.042510822  || Decoder Loss:  0.034890033 Validation Decoder Loss:  0.3303008
Encoder Loss:  0.042503882  || Decoder Loss:  0.0348868 Validation Decoder Loss:  0.3302703
Encoder Loss:  0.04251081  || Decoder Loss:  0.034886844 Validation Decoder Loss:  0.3304423
Encoder Loss:  0.04250608  || Decoder Loss:  0.034890015 Validation Decoder Loss:  0.3303776
Model: siamese_net_lr_0.001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3303776
Model: "sequential_690"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_386 (Conv3D (None, 432, 5, 19, 1)     307       
_________________________________________________________________
dropout_876 (Dropout)        (None, 432, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_387 (Conv3D (None, 514, 5, 19, 1)     84        
_________________________________________________________________
reshape_199 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_692"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_292 (Conv2D)          (None, 2580, 19, 1)       29        
_________________________________________________________________
dropout_878 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_293 (Conv2D)          (None, 2570, 19, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_693"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_292 (Conv2D (None, 2590, 19, 1)       22        
_________________________________________________________________
dropout_880 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_293 (Conv2D (None, 2607, 19, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2599513  || Decoder Loss:  0.060183316 Validation Decoder Loss:  0.350901
Encoder Loss:  0.2575435  || Decoder Loss:  0.06719531 Validation Decoder Loss:  0.33649608
Encoder Loss:  0.20798874  || Decoder Loss:  0.03756165 Validation Decoder Loss:  0.33085322
Encoder Loss:  0.06346021  || Decoder Loss:  0.035877224 Validation Decoder Loss:  0.3303603
Encoder Loss:  0.06322794  || Decoder Loss:  0.035709634 Validation Decoder Loss:  0.3305671
Encoder Loss:  0.06267981  || Decoder Loss:  0.035560813 Validation Decoder Loss:  0.33079576
Encoder Loss:  0.061968748  || Decoder Loss:  0.03543119 Validation Decoder Loss:  0.33104104
Encoder Loss:  0.06031064  || Decoder Loss:  0.035318986 Validation Decoder Loss:  0.33125806
Encoder Loss:  0.04948242  || Decoder Loss:  0.03522 Validation Decoder Loss:  0.3318802
Encoder Loss:  0.044022046  || Decoder Loss:  0.0351315 Validation Decoder Loss:  0.33200437
Encoder Loss:  0.043946926  || Decoder Loss:  0.03506087 Validation Decoder Loss:  0.33215314
Encoder Loss:  0.043909427  || Decoder Loss:  0.03499751 Validation Decoder Loss:  0.33231992
Encoder Loss:  0.043858685  || Decoder Loss:  0.0349407 Validation Decoder Loss:  0.33251733
Encoder Loss:  0.043826457  || Decoder Loss:  0.03488965 Validation Decoder Loss:  0.33274937
Encoder Loss:  0.04378986  || Decoder Loss:  0.03484336 Validation Decoder Loss:  0.33301222
Encoder Loss:  0.04375293  || Decoder Loss:  0.03480122 Validation Decoder Loss:  0.3332978
Encoder Loss:  0.04371568  || Decoder Loss:  0.03476336 Validation Decoder Loss:  0.33358732
Encoder Loss:  0.0436834  || Decoder Loss:  0.034730684 Validation Decoder Loss:  0.3338663
Encoder Loss:  0.043656044  || Decoder Loss:  0.034704015 Validation Decoder Loss:  0.33417344
Encoder Loss:  0.04363526  || Decoder Loss:  0.034683492 Validation Decoder Loss:  0.33455038
Encoder Loss:  0.043618847  || Decoder Loss:  0.034668714 Validation Decoder Loss:  0.33491766
Encoder Loss:  0.04359005  || Decoder Loss:  0.034658443 Validation Decoder Loss:  0.33519676
Encoder Loss:  0.04356199  || Decoder Loss:  0.03465139 Validation Decoder Loss:  0.3353867
Encoder Loss:  0.04354949  || Decoder Loss:  0.034646496 Validation Decoder Loss:  0.3355157
Encoder Loss:  0.043495674  || Decoder Loss:  0.034642544 Validation Decoder Loss:  0.33561388
Encoder Loss:  0.04348751  || Decoder Loss:  0.034640156 Validation Decoder Loss:  0.33565986
Encoder Loss:  0.043411974  || Decoder Loss:  0.034638334 Validation Decoder Loss:  0.3356955
Encoder Loss:  0.04341827  || Decoder Loss:  0.034637865 Validation Decoder Loss:  0.3356908
Encoder Loss:  0.043351498  || Decoder Loss:  0.034638163 Validation Decoder Loss:  0.3356824
Encoder Loss:  0.043334648  || Decoder Loss:  0.034638647 Validation Decoder Loss:  0.3356505
Encoder Loss:  0.04332401  || Decoder Loss:  0.034639552 Validation Decoder Loss:  0.33560455
Encoder Loss:  0.043296956  || Decoder Loss:  0.034640767 Validation Decoder Loss:  0.3355685
Encoder Loss:  0.043270253  || Decoder Loss:  0.034641016 Validation Decoder Loss:  0.33554912
Encoder Loss:  0.043253068  || Decoder Loss:  0.0346406 Validation Decoder Loss:  0.33553863
Encoder Loss:  0.043242704  || Decoder Loss:  0.034639824 Validation Decoder Loss:  0.33553565
Encoder Loss:  0.043236542  || Decoder Loss:  0.0346388 Validation Decoder Loss:  0.335535
Encoder Loss:  0.0432328  || Decoder Loss:  0.034637775 Validation Decoder Loss:  0.33553243
Encoder Loss:  0.043228477  || Decoder Loss:  0.034636725 Validation Decoder Loss:  0.33553016
Encoder Loss:  0.04322445  || Decoder Loss:  0.03463562 Validation Decoder Loss:  0.33552676
Encoder Loss:  0.043220982  || Decoder Loss:  0.034634475 Validation Decoder Loss:  0.33552292
Model: siamese_net_lr_0.0005027352903094345 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3355229
Model: "sequential_694"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_389 (Conv3D (None, 416, 5, 19, 1)     39        
_________________________________________________________________
dropout_882 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_390 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_200 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_696"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_294 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_884 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_295 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_697"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_294 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_886 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_295 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24485792  || Decoder Loss:  0.048694897 Validation Decoder Loss:  0.3297509
Encoder Loss:  0.14360018  || Decoder Loss:  0.034969088 Validation Decoder Loss:  0.33020997
Encoder Loss:  0.042914726  || Decoder Loss:  0.034927372 Validation Decoder Loss:  0.3300646
Encoder Loss:  0.042880774  || Decoder Loss:  0.03488765 Validation Decoder Loss:  0.33000737
Encoder Loss:  0.04286603  || Decoder Loss:  0.034856595 Validation Decoder Loss:  0.32999143
Encoder Loss:  0.042853545  || Decoder Loss:  0.034830377 Validation Decoder Loss:  0.330004
Encoder Loss:  0.042843875  || Decoder Loss:  0.03481015 Validation Decoder Loss:  0.3300382
Encoder Loss:  0.042836837  || Decoder Loss:  0.03479593 Validation Decoder Loss:  0.3300821
Encoder Loss:  0.04283161  || Decoder Loss:  0.034785513 Validation Decoder Loss:  0.33012727
Encoder Loss:  0.04282771  || Decoder Loss:  0.034777433 Validation Decoder Loss:  0.3301714
Encoder Loss:  0.042824697  || Decoder Loss:  0.03477092 Validation Decoder Loss:  0.33021334
Encoder Loss:  0.042821866  || Decoder Loss:  0.034765504 Validation Decoder Loss:  0.3302509
Encoder Loss:  0.042819615  || Decoder Loss:  0.03476095 Validation Decoder Loss:  0.3302809
Encoder Loss:  0.042817563  || Decoder Loss:  0.034756973 Validation Decoder Loss:  0.3303033
Encoder Loss:  0.042818308  || Decoder Loss:  0.034753546 Validation Decoder Loss:  0.33031663
Encoder Loss:  0.042817205  || Decoder Loss:  0.034750544 Validation Decoder Loss:  0.3303266
Encoder Loss:  0.04281586  || Decoder Loss:  0.03474797 Validation Decoder Loss:  0.33033136
Encoder Loss:  0.04281573  || Decoder Loss:  0.034745716 Validation Decoder Loss:  0.3303352
Encoder Loss:  0.042814266  || Decoder Loss:  0.034743782 Validation Decoder Loss:  0.33033803
Encoder Loss:  0.042818017  || Decoder Loss:  0.034742173 Validation Decoder Loss:  0.33034608
Encoder Loss:  0.04281274  || Decoder Loss:  0.034740746 Validation Decoder Loss:  0.33035076
Encoder Loss:  0.042812742  || Decoder Loss:  0.03473944 Validation Decoder Loss:  0.33035004
Encoder Loss:  0.04281284  || Decoder Loss:  0.03473823 Validation Decoder Loss:  0.33034477
Encoder Loss:  0.042809743  || Decoder Loss:  0.03473715 Validation Decoder Loss:  0.33034337
Encoder Loss:  0.042809386  || Decoder Loss:  0.034736097 Validation Decoder Loss:  0.33033377
Encoder Loss:  0.04281189  || Decoder Loss:  0.034735367 Validation Decoder Loss:  0.3303436
Encoder Loss:  0.042809524  || Decoder Loss:  0.0347345 Validation Decoder Loss:  0.3303367
Encoder Loss:  0.042807817  || Decoder Loss:  0.034733694 Validation Decoder Loss:  0.33034003
Encoder Loss:  0.042809848  || Decoder Loss:  0.034732986 Validation Decoder Loss:  0.33033216
Encoder Loss:  0.042832505  || Decoder Loss:  0.034733478 Validation Decoder Loss:  0.33042002
Encoder Loss:  0.04280646  || Decoder Loss:  0.03473324 Validation Decoder Loss:  0.3304345
Encoder Loss:  0.042813014  || Decoder Loss:  0.034732714 Validation Decoder Loss:  0.3304322
Encoder Loss:  0.04280675  || Decoder Loss:  0.03473228 Validation Decoder Loss:  0.3304426
Encoder Loss:  0.042807736  || Decoder Loss:  0.034731835 Validation Decoder Loss:  0.330439
Encoder Loss:  0.042806663  || Decoder Loss:  0.034731403 Validation Decoder Loss:  0.33044606
Encoder Loss:  0.042806614  || Decoder Loss:  0.034731034 Validation Decoder Loss:  0.33044064
Encoder Loss:  0.042812843  || Decoder Loss:  0.034730617 Validation Decoder Loss:  0.33043846
Encoder Loss:  0.042817846  || Decoder Loss:  0.034730747 Validation Decoder Loss:  0.33048505
Encoder Loss:  0.042805642  || Decoder Loss:  0.034730602 Validation Decoder Loss:  0.33049828
Encoder Loss:  0.042806778  || Decoder Loss:  0.03473031 Validation Decoder Loss:  0.33049428
Model: siamese_net_lr_0.0007653144901866751 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33049428
Model: "sequential_698"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_392 (Conv3D (None, 416, 5, 19, 1)     354       
_________________________________________________________________
dropout_888 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_393 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_201 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_700"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_296 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_890 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_297 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_701"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_296 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_892 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_297 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11433619  || Decoder Loss:  0.0601644 Validation Decoder Loss:  0.36017585
Encoder Loss:  0.11467945  || Decoder Loss:  0.060811147 Validation Decoder Loss:  0.3585461
Encoder Loss:  0.11494479  || Decoder Loss:  0.061387457 Validation Decoder Loss:  0.35660535
Encoder Loss:  0.11509457  || Decoder Loss:  0.061857022 Validation Decoder Loss:  0.35427922
Encoder Loss:  0.11505321  || Decoder Loss:  0.06213983 Validation Decoder Loss:  0.35144255
Encoder Loss:  0.11467471  || Decoder Loss:  0.062075943 Validation Decoder Loss:  0.3478762
Encoder Loss:  0.113660686  || Decoder Loss:  0.061330557 Validation Decoder Loss:  0.34320205
Encoder Loss:  0.111350015  || Decoder Loss:  0.059148453 Validation Decoder Loss:  0.3367594
Encoder Loss:  0.106172346  || Decoder Loss:  0.053715166 Validation Decoder Loss:  0.32797122
Encoder Loss:  0.09581028  || Decoder Loss:  0.042355713 Validation Decoder Loss:  0.32646093
Encoder Loss:  0.0890924  || Decoder Loss:  0.03557188 Validation Decoder Loss:  0.33106315
Encoder Loss:  0.08764074  || Decoder Loss:  0.035438254 Validation Decoder Loss:  0.3309578
Encoder Loss:  0.08563489  || Decoder Loss:  0.03539468 Validation Decoder Loss:  0.33094376
Encoder Loss:  0.08248069  || Decoder Loss:  0.035345986 Validation Decoder Loss:  0.33101022
Encoder Loss:  0.07705722  || Decoder Loss:  0.03528999 Validation Decoder Loss:  0.3311472
Encoder Loss:  0.06679987  || Decoder Loss:  0.03522749 Validation Decoder Loss:  0.33134776
Encoder Loss:  0.048361287  || Decoder Loss:  0.03516321 Validation Decoder Loss:  0.33158857
Encoder Loss:  0.042642392  || Decoder Loss:  0.03511373 Validation Decoder Loss:  0.3314518
Encoder Loss:  0.04255117  || Decoder Loss:  0.035084497 Validation Decoder Loss:  0.331333
Encoder Loss:  0.042503677  || Decoder Loss:  0.035064172 Validation Decoder Loss:  0.33124667
Encoder Loss:  0.042454243  || Decoder Loss:  0.03504711 Validation Decoder Loss:  0.33118296
Encoder Loss:  0.042410288  || Decoder Loss:  0.0350319 Validation Decoder Loss:  0.33113265
Encoder Loss:  0.042365737  || Decoder Loss:  0.035018265 Validation Decoder Loss:  0.331091
Encoder Loss:  0.042324547  || Decoder Loss:  0.03500609 Validation Decoder Loss:  0.33105463
Encoder Loss:  0.042282127  || Decoder Loss:  0.03499521 Validation Decoder Loss:  0.3310215
Encoder Loss:  0.042241205  || Decoder Loss:  0.034985553 Validation Decoder Loss:  0.33099046
Encoder Loss:  0.042194877  || Decoder Loss:  0.034976985 Validation Decoder Loss:  0.33096144
Encoder Loss:  0.042150207  || Decoder Loss:  0.034969382 Validation Decoder Loss:  0.3309337
Encoder Loss:  0.042104255  || Decoder Loss:  0.034962613 Validation Decoder Loss:  0.33090687
Encoder Loss:  0.04205787  || Decoder Loss:  0.034956586 Validation Decoder Loss:  0.33088017
Encoder Loss:  0.042008802  || Decoder Loss:  0.034951147 Validation Decoder Loss:  0.33085346
Encoder Loss:  0.041953225  || Decoder Loss:  0.034946218 Validation Decoder Loss:  0.33082712
Encoder Loss:  0.041897126  || Decoder Loss:  0.034941707 Validation Decoder Loss:  0.33080015
Encoder Loss:  0.04183372  || Decoder Loss:  0.034937516 Validation Decoder Loss:  0.33077294
Encoder Loss:  0.041765843  || Decoder Loss:  0.03493359 Validation Decoder Loss:  0.330745
Encoder Loss:  0.041687638  || Decoder Loss:  0.03492982 Validation Decoder Loss:  0.33071637
Encoder Loss:  0.04159772  || Decoder Loss:  0.034926247 Validation Decoder Loss:  0.33068728
Encoder Loss:  0.041492444  || Decoder Loss:  0.034922708 Validation Decoder Loss:  0.33065742
Encoder Loss:  0.041359525  || Decoder Loss:  0.034919232 Validation Decoder Loss:  0.33062705
Encoder Loss:  0.04117964  || Decoder Loss:  0.03491576 Validation Decoder Loss:  0.3305962
Model: siamese_net_lr_0.000121961915358297 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3305962
Model: "sequential_702"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_395 (Conv3D (None, 188, 5, 19, 1)     126       
_________________________________________________________________
dropout_894 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_396 (Conv3D (None, 514, 5, 19, 1)     141       
_________________________________________________________________
reshape_202 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 267
Trainable params: 267
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_704"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_896 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_705"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_298 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_898 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_299 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419191 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419191 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419191 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.361075
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880179  || Decoder Loss:  0.07419193 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419192 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419191 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.07419191 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Encoder Loss:  0.08880177  || Decoder Loss:  0.074191935 Validation Decoder Loss:  0.36107498
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36107498
Model: "sequential_706"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_398 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_900 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_399 (Conv3D (None, 514, 5, 19, 1)     394       
_________________________________________________________________
reshape_203 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_708"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_300 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_902 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_709"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_300 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_904 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_301 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25293452  || Decoder Loss:  0.07375181 Validation Decoder Loss:  0.36245322
Encoder Loss:  0.23204714  || Decoder Loss:  0.0645946 Validation Decoder Loss:  0.33001173
Encoder Loss:  0.108146705  || Decoder Loss:  0.03542541 Validation Decoder Loss:  0.33159328
Encoder Loss:  0.06851285  || Decoder Loss:  0.035300523 Validation Decoder Loss:  0.33108526
Encoder Loss:  0.06667432  || Decoder Loss:  0.03521014 Validation Decoder Loss:  0.3308713
Encoder Loss:  0.064360075  || Decoder Loss:  0.035149246 Validation Decoder Loss:  0.33083463
Encoder Loss:  0.061468612  || Decoder Loss:  0.03510548 Validation Decoder Loss:  0.33084267
Encoder Loss:  0.057844624  || Decoder Loss:  0.035077795 Validation Decoder Loss:  0.33086154
Encoder Loss:  0.05018682  || Decoder Loss:  0.035060473 Validation Decoder Loss:  0.33088666
Encoder Loss:  0.043352347  || Decoder Loss:  0.035050683 Validation Decoder Loss:  0.3308875
Encoder Loss:  0.04315503  || Decoder Loss:  0.03504424 Validation Decoder Loss:  0.33088878
Encoder Loss:  0.04312219  || Decoder Loss:  0.03503876 Validation Decoder Loss:  0.3308972
Encoder Loss:  0.043119486  || Decoder Loss:  0.035033073 Validation Decoder Loss:  0.33090863
Encoder Loss:  0.043123264  || Decoder Loss:  0.03502705 Validation Decoder Loss:  0.3309216
Encoder Loss:  0.0431146  || Decoder Loss:  0.035020694 Validation Decoder Loss:  0.33093324
Encoder Loss:  0.043104034  || Decoder Loss:  0.0350141 Validation Decoder Loss:  0.33094156
Encoder Loss:  0.043093204  || Decoder Loss:  0.035007264 Validation Decoder Loss:  0.33094478
Encoder Loss:  0.043082718  || Decoder Loss:  0.035000294 Validation Decoder Loss:  0.33094686
Encoder Loss:  0.043079004  || Decoder Loss:  0.034993056 Validation Decoder Loss:  0.3309496
Encoder Loss:  0.04308605  || Decoder Loss:  0.034985665 Validation Decoder Loss:  0.33095935
Encoder Loss:  0.043064438  || Decoder Loss:  0.03497846 Validation Decoder Loss:  0.3309734
Encoder Loss:  0.043060943  || Decoder Loss:  0.03497149 Validation Decoder Loss:  0.3309921
Encoder Loss:  0.043051988  || Decoder Loss:  0.034964833 Validation Decoder Loss:  0.3310125
Encoder Loss:  0.04305471  || Decoder Loss:  0.03495859 Validation Decoder Loss:  0.33103582
Encoder Loss:  0.043039918  || Decoder Loss:  0.03495291 Validation Decoder Loss:  0.3310604
Encoder Loss:  0.043040004  || Decoder Loss:  0.03494765 Validation Decoder Loss:  0.3310874
Encoder Loss:  0.043030787  || Decoder Loss:  0.034943234 Validation Decoder Loss:  0.3311121
Encoder Loss:  0.043033827  || Decoder Loss:  0.034938764 Validation Decoder Loss:  0.33114517
Encoder Loss:  0.043030586  || Decoder Loss:  0.034934454 Validation Decoder Loss:  0.3311793
Encoder Loss:  0.04302529  || Decoder Loss:  0.034931097 Validation Decoder Loss:  0.33120838
Encoder Loss:  0.04302445  || Decoder Loss:  0.03492761 Validation Decoder Loss:  0.33123693
Encoder Loss:  0.043015394  || Decoder Loss:  0.03492488 Validation Decoder Loss:  0.3312701
Encoder Loss:  0.04301161  || Decoder Loss:  0.03492215 Validation Decoder Loss:  0.33129686
Encoder Loss:  0.043007765  || Decoder Loss:  0.034919996 Validation Decoder Loss:  0.33132517
Encoder Loss:  0.043005515  || Decoder Loss:  0.034918413 Validation Decoder Loss:  0.3313434
Encoder Loss:  0.04300373  || Decoder Loss:  0.034916114 Validation Decoder Loss:  0.33138087
Encoder Loss:  0.043000635  || Decoder Loss:  0.034913782 Validation Decoder Loss:  0.33140233
Encoder Loss:  0.042999692  || Decoder Loss:  0.034911413 Validation Decoder Loss:  0.3314494
Encoder Loss:  0.04299591  || Decoder Loss:  0.034910146 Validation Decoder Loss:  0.3314719
Encoder Loss:  0.04299543  || Decoder Loss:  0.03490933 Validation Decoder Loss:  0.33147663
Model: siamese_net_lr_0.00030564625137750515 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33147663
Model: "sequential_710"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_401 (Conv3D (None, 98, 5, 19, 1)      36        
_________________________________________________________________
dropout_906 (Dropout)        (None, 98, 5, 19, 1)      0         
_________________________________________________________________
conv3d_transpose_402 (Conv3D (None, 514, 5, 19, 1)     321       
_________________________________________________________________
reshape_204 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 357
Trainable params: 357
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_712"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_302 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_908 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_713"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_302 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_910 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_303 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2679553  || Decoder Loss:  0.082866654 Validation Decoder Loss:  0.36069474
Encoder Loss:  0.26787692  || Decoder Loss:  0.083683446 Validation Decoder Loss:  0.36124903
Encoder Loss:  0.26778218  || Decoder Loss:  0.08465762 Validation Decoder Loss:  0.36187142
Encoder Loss:  0.26768047  || Decoder Loss:  0.08569212 Validation Decoder Loss:  0.36252892
Encoder Loss:  0.267575  || Decoder Loss:  0.08675074 Validation Decoder Loss:  0.36321473
Encoder Loss:  0.26746657  || Decoder Loss:  0.08782307 Validation Decoder Loss:  0.36392617
Encoder Loss:  0.26735505  || Decoder Loss:  0.08890634 Validation Decoder Loss:  0.36466038
Encoder Loss:  0.26724008  || Decoder Loss:  0.0899996 Validation Decoder Loss:  0.3654151
Encoder Loss:  0.2671211  || Decoder Loss:  0.0911024 Validation Decoder Loss:  0.36618853
Encoder Loss:  0.2669976  || Decoder Loss:  0.09221433 Validation Decoder Loss:  0.3669791
Encoder Loss:  0.26686874  || Decoder Loss:  0.09333494 Validation Decoder Loss:  0.3677855
Encoder Loss:  0.2667337  || Decoder Loss:  0.09446391 Validation Decoder Loss:  0.36860687
Encoder Loss:  0.26659167  || Decoder Loss:  0.09560092 Validation Decoder Loss:  0.36944222
Encoder Loss:  0.26644167  || Decoder Loss:  0.0967458 Validation Decoder Loss:  0.37029076
Encoder Loss:  0.2662828  || Decoder Loss:  0.09789841 Validation Decoder Loss:  0.37115145
Encoder Loss:  0.26611397  || Decoder Loss:  0.09905852 Validation Decoder Loss:  0.372023
Encoder Loss:  0.26593387  || Decoder Loss:  0.10022557 Validation Decoder Loss:  0.37290353
Encoder Loss:  0.26574093  || Decoder Loss:  0.1013985 Validation Decoder Loss:  0.37379068
Encoder Loss:  0.265533  || Decoder Loss:  0.10257549 Validation Decoder Loss:  0.37468112
Encoder Loss:  0.26530755  || Decoder Loss:  0.10375372 Validation Decoder Loss:  0.37557027
Encoder Loss:  0.26506105  || Decoder Loss:  0.10492902 Validation Decoder Loss:  0.37645167
Encoder Loss:  0.2647889  || Decoder Loss:  0.10609526 Validation Decoder Loss:  0.37731618
Encoder Loss:  0.26448494  || Decoder Loss:  0.10724333 Validation Decoder Loss:  0.37815064
Encoder Loss:  0.26414073  || Decoder Loss:  0.10835977 Validation Decoder Loss:  0.37893587
Encoder Loss:  0.26374424  || Decoder Loss:  0.10942417 Validation Decoder Loss:  0.37964314
Encoder Loss:  0.26327798  || Decoder Loss:  0.1104048 Validation Decoder Loss:  0.38022763
Encoder Loss:  0.2627153  || Decoder Loss:  0.11125049 Validation Decoder Loss:  0.38061577
Encoder Loss:  0.2620138  || Decoder Loss:  0.11187506 Validation Decoder Loss:  0.38067958
Encoder Loss:  0.26110047  || Decoder Loss:  0.11212393 Validation Decoder Loss:  0.38018128
Encoder Loss:  0.2598392  || Decoder Loss:  0.11169645 Validation Decoder Loss:  0.37863934
Encoder Loss:  0.2579425  || Decoder Loss:  0.10993646 Validation Decoder Loss:  0.37494993
Encoder Loss:  0.25468478  || Decoder Loss:  0.10514405 Validation Decoder Loss:  0.3660889
Encoder Loss:  0.24763197  || Decoder Loss:  0.09151722 Validation Decoder Loss:  0.34190804
Encoder Loss:  0.22977771  || Decoder Loss:  0.052250303 Validation Decoder Loss:  0.35098308
Encoder Loss:  0.22157496  || Decoder Loss:  0.036888815 Validation Decoder Loss:  0.3255945
Encoder Loss:  0.21887079  || Decoder Loss:  0.0356787 Validation Decoder Loss:  0.3345676
Encoder Loss:  0.21600881  || Decoder Loss:  0.0354331 Validation Decoder Loss:  0.32993245
Encoder Loss:  0.21230406  || Decoder Loss:  0.035373185 Validation Decoder Loss:  0.33181116
Encoder Loss:  0.20694628  || Decoder Loss:  0.03535253 Validation Decoder Loss:  0.33157223
Encoder Loss:  0.19813189  || Decoder Loss:  0.035335537 Validation Decoder Loss:  0.3314519
Model: siamese_net_lr_0.0004331520273762234 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3314519
Model: "sequential_714"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_404 (Conv3D (None, 188, 5, 19, 1)     63        
_________________________________________________________________
dropout_912 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_405 (Conv3D (None, 514, 5, 19, 1)     328       
_________________________________________________________________
reshape_205 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_716"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_304 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_914 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_717"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_304 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_916 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_305 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12060693  || Decoder Loss:  0.07245943 Validation Decoder Loss:  0.33203918
Encoder Loss:  0.046715155  || Decoder Loss:  0.035226125 Validation Decoder Loss:  0.3307614
Encoder Loss:  0.04181058  || Decoder Loss:  0.035087086 Validation Decoder Loss:  0.33083773
Encoder Loss:  0.038338844  || Decoder Loss:  0.035042886 Validation Decoder Loss:  0.3308717
Encoder Loss:  0.038048137  || Decoder Loss:  0.03502021 Validation Decoder Loss:  0.33088553
Encoder Loss:  0.037928846  || Decoder Loss:  0.035002124 Validation Decoder Loss:  0.3308934
Encoder Loss:  0.037909377  || Decoder Loss:  0.034986205 Validation Decoder Loss:  0.33090213
Encoder Loss:  0.03789231  || Decoder Loss:  0.03497174 Validation Decoder Loss:  0.33092308
Encoder Loss:  0.037881542  || Decoder Loss:  0.034959093 Validation Decoder Loss:  0.33095112
Encoder Loss:  0.037868805  || Decoder Loss:  0.034949362 Validation Decoder Loss:  0.33097956
Encoder Loss:  0.037866488  || Decoder Loss:  0.034942843 Validation Decoder Loss:  0.33100647
Encoder Loss:  0.037862603  || Decoder Loss:  0.034938533 Validation Decoder Loss:  0.33103314
Encoder Loss:  0.037855722  || Decoder Loss:  0.034935366 Validation Decoder Loss:  0.3310538
Encoder Loss:  0.037854716  || Decoder Loss:  0.034932896 Validation Decoder Loss:  0.3310681
Encoder Loss:  0.03785212  || Decoder Loss:  0.03493093 Validation Decoder Loss:  0.33107883
Encoder Loss:  0.03785088  || Decoder Loss:  0.034929037 Validation Decoder Loss:  0.33109337
Encoder Loss:  0.03784765  || Decoder Loss:  0.034927294 Validation Decoder Loss:  0.33111227
Encoder Loss:  0.037847355  || Decoder Loss:  0.03492539 Validation Decoder Loss:  0.33113247
Encoder Loss:  0.03784542  || Decoder Loss:  0.034923736 Validation Decoder Loss:  0.33115166
Encoder Loss:  0.037843753  || Decoder Loss:  0.034922116 Validation Decoder Loss:  0.33117
Encoder Loss:  0.0378438  || Decoder Loss:  0.03492057 Validation Decoder Loss:  0.33118743
Encoder Loss:  0.03784185  || Decoder Loss:  0.034919176 Validation Decoder Loss:  0.3312038
Encoder Loss:  0.037839476  || Decoder Loss:  0.03491796 Validation Decoder Loss:  0.33121875
Encoder Loss:  0.037840016  || Decoder Loss:  0.034916844 Validation Decoder Loss:  0.33123237
Encoder Loss:  0.037839178  || Decoder Loss:  0.034915626 Validation Decoder Loss:  0.33124802
Encoder Loss:  0.03783839  || Decoder Loss:  0.034914423 Validation Decoder Loss:  0.33126152
Encoder Loss:  0.037837613  || Decoder Loss:  0.03491318 Validation Decoder Loss:  0.33127594
Encoder Loss:  0.037837263  || Decoder Loss:  0.034912124 Validation Decoder Loss:  0.33129185
Encoder Loss:  0.037836  || Decoder Loss:  0.034911055 Validation Decoder Loss:  0.33130878
Encoder Loss:  0.037834357  || Decoder Loss:  0.034909908 Validation Decoder Loss:  0.3313194
Encoder Loss:  0.0378335  || Decoder Loss:  0.0349086 Validation Decoder Loss:  0.331334
Encoder Loss:  0.037833765  || Decoder Loss:  0.03490731 Validation Decoder Loss:  0.33135268
Encoder Loss:  0.037833456  || Decoder Loss:  0.03490648 Validation Decoder Loss:  0.33136064
Encoder Loss:  0.037830517  || Decoder Loss:  0.03490525 Validation Decoder Loss:  0.33137518
Encoder Loss:  0.03782972  || Decoder Loss:  0.034903247 Validation Decoder Loss:  0.33140892
Encoder Loss:  0.037828565  || Decoder Loss:  0.03490253 Validation Decoder Loss:  0.3314139
Encoder Loss:  0.0378287  || Decoder Loss:  0.034901503 Validation Decoder Loss:  0.33143866
Encoder Loss:  0.037826713  || Decoder Loss:  0.034900974 Validation Decoder Loss:  0.3314308
Encoder Loss:  0.0378274  || Decoder Loss:  0.034900416 Validation Decoder Loss:  0.3314487
Encoder Loss:  0.03782782  || Decoder Loss:  0.034899596 Validation Decoder Loss:  0.331449
Model: siamese_net_lr_0.0008214936077909614 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.331449
Model: "sequential_718"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_407 (Conv3D (None, 416, 5, 19, 1)     354       
_________________________________________________________________
dropout_918 (Dropout)        (None, 416, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_408 (Conv3D (None, 514, 5, 19, 1)     100       
_________________________________________________________________
reshape_206 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_720"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_306 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_920 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_721"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_306 (Conv2D (None, 2570, 19, 1)       2         
_________________________________________________________________
dropout_922 (Dropout)        (None, 2570, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_307 (Conv2D (None, 2607, 19, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984334 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984334 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984334 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984334 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.05984335 Validation Decoder Loss:  0.3615638
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.36156383
Encoder Loss:  0.21654427  || Decoder Loss:  0.059843346 Validation Decoder Loss:  0.3615638
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36156383
Model: "sequential_722"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_410 (Conv3D (None, 188, 5, 19, 1)     126       
_________________________________________________________________
dropout_924 (Dropout)        (None, 188, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_411 (Conv3D (None, 514, 5, 19, 1)     328       
_________________________________________________________________
reshape_207 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_724"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_308 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_926 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_725"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_308 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_928 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_309 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19604798  || Decoder Loss:  0.07396582 Validation Decoder Loss:  0.33234656
Encoder Loss:  0.059271134  || Decoder Loss:  0.035279077 Validation Decoder Loss:  0.33090594
Encoder Loss:  0.04804416  || Decoder Loss:  0.03512285 Validation Decoder Loss:  0.3308888
Encoder Loss:  0.042860955  || Decoder Loss:  0.03506715 Validation Decoder Loss:  0.330922
Encoder Loss:  0.042155415  || Decoder Loss:  0.035048828 Validation Decoder Loss:  0.33092412
Encoder Loss:  0.042075418  || Decoder Loss:  0.035034202 Validation Decoder Loss:  0.33093375
Encoder Loss:  0.042054147  || Decoder Loss:  0.035019156 Validation Decoder Loss:  0.33095098
Encoder Loss:  0.04202838  || Decoder Loss:  0.035001107 Validation Decoder Loss:  0.33097675
Encoder Loss:  0.04200416  || Decoder Loss:  0.034981713 Validation Decoder Loss:  0.33100876
Encoder Loss:  0.041994184  || Decoder Loss:  0.034965765 Validation Decoder Loss:  0.33103627
Encoder Loss:  0.041989308  || Decoder Loss:  0.034954738 Validation Decoder Loss:  0.3310586
Encoder Loss:  0.041981436  || Decoder Loss:  0.034947682 Validation Decoder Loss:  0.3310939
Encoder Loss:  0.041977644  || Decoder Loss:  0.03494228 Validation Decoder Loss:  0.33113527
Encoder Loss:  0.04197693  || Decoder Loss:  0.034938198 Validation Decoder Loss:  0.33115977
Encoder Loss:  0.04197745  || Decoder Loss:  0.03493536 Validation Decoder Loss:  0.33117276
Encoder Loss:  0.041974414  || Decoder Loss:  0.03493321 Validation Decoder Loss:  0.33118698
Encoder Loss:  0.041974626  || Decoder Loss:  0.03493134 Validation Decoder Loss:  0.33120728
Encoder Loss:  0.04197047  || Decoder Loss:  0.034929752 Validation Decoder Loss:  0.33122867
Encoder Loss:  0.041968822  || Decoder Loss:  0.034928355 Validation Decoder Loss:  0.33124584
Encoder Loss:  0.041965734  || Decoder Loss:  0.034927245 Validation Decoder Loss:  0.33125922
Encoder Loss:  0.04196572  || Decoder Loss:  0.034926157 Validation Decoder Loss:  0.3312719
Encoder Loss:  0.041965228  || Decoder Loss:  0.034925215 Validation Decoder Loss:  0.33128327
Encoder Loss:  0.041960824  || Decoder Loss:  0.03492458 Validation Decoder Loss:  0.3312921
Encoder Loss:  0.04196085  || Decoder Loss:  0.03492379 Validation Decoder Loss:  0.33130065
Encoder Loss:  0.041959826  || Decoder Loss:  0.034923125 Validation Decoder Loss:  0.33130825
Encoder Loss:  0.041959997  || Decoder Loss:  0.03492234 Validation Decoder Loss:  0.33131605
Encoder Loss:  0.041958667  || Decoder Loss:  0.03492162 Validation Decoder Loss:  0.3313224
Encoder Loss:  0.041957784  || Decoder Loss:  0.03492091 Validation Decoder Loss:  0.3313275
Encoder Loss:  0.041956726  || Decoder Loss:  0.034920204 Validation Decoder Loss:  0.331332
Encoder Loss:  0.041956898  || Decoder Loss:  0.03491947 Validation Decoder Loss:  0.33133566
Encoder Loss:  0.041956607  || Decoder Loss:  0.034918617 Validation Decoder Loss:  0.3313403
Encoder Loss:  0.0419547  || Decoder Loss:  0.034917675 Validation Decoder Loss:  0.3313445
Encoder Loss:  0.04195402  || Decoder Loss:  0.034916773 Validation Decoder Loss:  0.33134967
Encoder Loss:  0.04195312  || Decoder Loss:  0.034915637 Validation Decoder Loss:  0.33135512
Encoder Loss:  0.041952554  || Decoder Loss:  0.03491438 Validation Decoder Loss:  0.33136442
Encoder Loss:  0.041951224  || Decoder Loss:  0.034912977 Validation Decoder Loss:  0.33137614
Encoder Loss:  0.041950755  || Decoder Loss:  0.034911267 Validation Decoder Loss:  0.33139202
Encoder Loss:  0.041949164  || Decoder Loss:  0.03490943 Validation Decoder Loss:  0.33141348
Encoder Loss:  0.041947212  || Decoder Loss:  0.03490767 Validation Decoder Loss:  0.33143574
Encoder Loss:  0.041946374  || Decoder Loss:  0.034905825 Validation Decoder Loss:  0.33146322
Model: siamese_net_lr_0.000860499689196408 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33146322
Model: "sequential_726"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_413 (Conv3D (None, 122, 5, 19, 1)     60        
_________________________________________________________________
dropout_930 (Dropout)        (None, 122, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_414 (Conv3D (None, 514, 5, 19, 1)     394       
_________________________________________________________________
reshape_208 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_728"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_310 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_932 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_729"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_310 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_934 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_311 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25820136  || Decoder Loss:  0.07738909 Validation Decoder Loss:  0.3644817
Encoder Loss:  0.1845725  || Decoder Loss:  0.04558217 Validation Decoder Loss:  0.33181894
Encoder Loss:  0.069825076  || Decoder Loss:  0.03531246 Validation Decoder Loss:  0.33103162
Encoder Loss:  0.06711497  || Decoder Loss:  0.035191383 Validation Decoder Loss:  0.3308307
Encoder Loss:  0.06371323  || Decoder Loss:  0.035118643 Validation Decoder Loss:  0.330828
Encoder Loss:  0.059037402  || Decoder Loss:  0.03507685 Validation Decoder Loss:  0.33085087
Encoder Loss:  0.048886184  || Decoder Loss:  0.03505566 Validation Decoder Loss:  0.330874
Encoder Loss:  0.043509416  || Decoder Loss:  0.035045143 Validation Decoder Loss:  0.33088356
Encoder Loss:  0.043394547  || Decoder Loss:  0.035037674 Validation Decoder Loss:  0.33090037
Encoder Loss:  0.043379053  || Decoder Loss:  0.035030533 Validation Decoder Loss:  0.3309157
Encoder Loss:  0.043388594  || Decoder Loss:  0.035023186 Validation Decoder Loss:  0.33092672
Encoder Loss:  0.04335546  || Decoder Loss:  0.03501557 Validation Decoder Loss:  0.33093274
Encoder Loss:  0.043356407  || Decoder Loss:  0.035007615 Validation Decoder Loss:  0.33093256
Encoder Loss:  0.043353796  || Decoder Loss:  0.034999132 Validation Decoder Loss:  0.33093125
Encoder Loss:  0.043331772  || Decoder Loss:  0.03499034 Validation Decoder Loss:  0.3309394
Encoder Loss:  0.043332595  || Decoder Loss:  0.03498134 Validation Decoder Loss:  0.33096373
Encoder Loss:  0.043325435  || Decoder Loss:  0.03497264 Validation Decoder Loss:  0.33099365
Encoder Loss:  0.04331509  || Decoder Loss:  0.034964528 Validation Decoder Loss:  0.3310259
Encoder Loss:  0.04331778  || Decoder Loss:  0.034957144 Validation Decoder Loss:  0.3310568
Encoder Loss:  0.04330904  || Decoder Loss:  0.03495054 Validation Decoder Loss:  0.33108634
Encoder Loss:  0.043306742  || Decoder Loss:  0.034944903 Validation Decoder Loss:  0.33111632
Encoder Loss:  0.043289885  || Decoder Loss:  0.034940362 Validation Decoder Loss:  0.33114666
Encoder Loss:  0.04328806  || Decoder Loss:  0.034936544 Validation Decoder Loss:  0.33116925
Encoder Loss:  0.043285985  || Decoder Loss:  0.03493301 Validation Decoder Loss:  0.33119443
Encoder Loss:  0.043282  || Decoder Loss:  0.03492981 Validation Decoder Loss:  0.3312227
Encoder Loss:  0.04327272  || Decoder Loss:  0.034926854 Validation Decoder Loss:  0.33124715
Encoder Loss:  0.043267176  || Decoder Loss:  0.034924436 Validation Decoder Loss:  0.33127296
Encoder Loss:  0.043264657  || Decoder Loss:  0.034922205 Validation Decoder Loss:  0.33129627
Encoder Loss:  0.043260876  || Decoder Loss:  0.03492005 Validation Decoder Loss:  0.3313188
Encoder Loss:  0.043257475  || Decoder Loss:  0.03491843 Validation Decoder Loss:  0.3313396
Encoder Loss:  0.043255307  || Decoder Loss:  0.034917463 Validation Decoder Loss:  0.3313549
Encoder Loss:  0.043254513  || Decoder Loss:  0.034916557 Validation Decoder Loss:  0.3313734
Encoder Loss:  0.043254126  || Decoder Loss:  0.034915492 Validation Decoder Loss:  0.3313864
Encoder Loss:  0.04325279  || Decoder Loss:  0.03491481 Validation Decoder Loss:  0.33139497
Encoder Loss:  0.04325433  || Decoder Loss:  0.034914386 Validation Decoder Loss:  0.33139768
Encoder Loss:  0.043254815  || Decoder Loss:  0.034913667 Validation Decoder Loss:  0.3314116
Encoder Loss:  0.043253638  || Decoder Loss:  0.034912083 Validation Decoder Loss:  0.33142686
Encoder Loss:  0.043254353  || Decoder Loss:  0.034911506 Validation Decoder Loss:  0.33143112
Encoder Loss:  0.043254636  || Decoder Loss:  0.034910843 Validation Decoder Loss:  0.33143204
Encoder Loss:  0.043251663  || Decoder Loss:  0.03491096 Validation Decoder Loss:  0.33143514
Model: siamese_net_lr_0.000395902722746975 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33143514
Model: "sequential_730"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_416 (Conv3D (None, 286, 5, 19, 1)     224       
_________________________________________________________________
dropout_936 (Dropout)        (None, 286, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_417 (Conv3D (None, 514, 5, 19, 1)     230       
_________________________________________________________________
reshape_209 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 454
Trainable params: 454
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_732"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_312 (Conv2D)          (None, 2600, 19, 1)       9         
_________________________________________________________________
dropout_938 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 2570, 19, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_733"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_312 (Conv2D (None, 2600, 19, 1)       32        
_________________________________________________________________
dropout_940 (Dropout)        (None, 2600, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_313 (Conv2D (None, 2607, 19, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23013453  || Decoder Loss:  0.09292009 Validation Decoder Loss:  0.33128345
Encoder Loss:  0.07344668  || Decoder Loss:  0.035490584 Validation Decoder Loss:  0.33165044
Encoder Loss:  0.054064065  || Decoder Loss:  0.03545488 Validation Decoder Loss:  0.33248103
Encoder Loss:  0.04488703  || Decoder Loss:  0.03544727 Validation Decoder Loss:  0.3324924
Encoder Loss:  0.043787584  || Decoder Loss:  0.035434727 Validation Decoder Loss:  0.3324862
Encoder Loss:  0.043758355  || Decoder Loss:  0.035421725 Validation Decoder Loss:  0.33247635
Encoder Loss:  0.04372919  || Decoder Loss:  0.035409886 Validation Decoder Loss:  0.33246616
Encoder Loss:  0.043672845  || Decoder Loss:  0.03539888 Validation Decoder Loss:  0.3324566
Encoder Loss:  0.04321105  || Decoder Loss:  0.035388235 Validation Decoder Loss:  0.33244187
Encoder Loss:  0.042654645  || Decoder Loss:  0.035378776 Validation Decoder Loss:  0.33242437
Encoder Loss:  0.04261582  || Decoder Loss:  0.035370916 Validation Decoder Loss:  0.33241504
Encoder Loss:  0.042606186  || Decoder Loss:  0.03536248 Validation Decoder Loss:  0.33243525
Encoder Loss:  0.04259547  || Decoder Loss:  0.03535238 Validation Decoder Loss:  0.33248606
Encoder Loss:  0.042577796  || Decoder Loss:  0.035339393 Validation Decoder Loss:  0.33248878
Encoder Loss:  0.04256792  || Decoder Loss:  0.035321753 Validation Decoder Loss:  0.33240098
Encoder Loss:  0.042557802  || Decoder Loss:  0.035298195 Validation Decoder Loss:  0.33243358
Encoder Loss:  0.04253594  || Decoder Loss:  0.035269406 Validation Decoder Loss:  0.33261427
Encoder Loss:  0.042519957  || Decoder Loss:  0.03524 Validation Decoder Loss:  0.3328871
Encoder Loss:  0.04250436  || Decoder Loss:  0.035217386 Validation Decoder Loss:  0.33317024
Encoder Loss:  0.042506732  || Decoder Loss:  0.03520855 Validation Decoder Loss:  0.33329388
Encoder Loss:  0.042509064  || Decoder Loss:  0.035212155 Validation Decoder Loss:  0.33334774
Encoder Loss:  0.042501047  || Decoder Loss:  0.03521348 Validation Decoder Loss:  0.3333664
Encoder Loss:  0.0425084  || Decoder Loss:  0.035212222 Validation Decoder Loss:  0.33338135
Encoder Loss:  0.042506486  || Decoder Loss:  0.0352167 Validation Decoder Loss:  0.3333614
Encoder Loss:  0.04249951  || Decoder Loss:  0.03520655 Validation Decoder Loss:  0.33336246
Encoder Loss:  0.04250326  || Decoder Loss:  0.035192844 Validation Decoder Loss:  0.3333717
Encoder Loss:  0.04249661  || Decoder Loss:  0.035187714 Validation Decoder Loss:  0.33336994
Encoder Loss:  0.04248517  || Decoder Loss:  0.035181165 Validation Decoder Loss:  0.3333614
Encoder Loss:  0.04247483  || Decoder Loss:  0.035167735 Validation Decoder Loss:  0.3333821
Encoder Loss:  0.04248633  || Decoder Loss:  0.03515318 Validation Decoder Loss:  0.33340046
Encoder Loss:  0.042469062  || Decoder Loss:  0.035151973 Validation Decoder Loss:  0.33339894
Encoder Loss:  0.04246003  || Decoder Loss:  0.035128526 Validation Decoder Loss:  0.333416
Encoder Loss:  0.042446427  || Decoder Loss:  0.035116762 Validation Decoder Loss:  0.33344582
Encoder Loss:  0.042459283  || Decoder Loss:  0.035112087 Validation Decoder Loss:  0.333431
Encoder Loss:  0.042441405  || Decoder Loss:  0.035093024 Validation Decoder Loss:  0.33344406
Encoder Loss:  0.0424178  || Decoder Loss:  0.03506729 Validation Decoder Loss:  0.3334784
Encoder Loss:  0.042410657  || Decoder Loss:  0.03504391 Validation Decoder Loss:  0.33360067
Encoder Loss:  0.042399388  || Decoder Loss:  0.035009995 Validation Decoder Loss:  0.33363277
Encoder Loss:  0.042376556  || Decoder Loss:  0.034969393 Validation Decoder Loss:  0.33374822
Encoder Loss:  0.04236495  || Decoder Loss:  0.034933515 Validation Decoder Loss:  0.3336498
Model: siamese_net_lr_0.0006603327448890519 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3336498
Model: "sequential_734"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_419 (Conv3D (None, 414, 5, 19, 1)     37        
_________________________________________________________________
dropout_942 (Dropout)        (None, 414, 5, 19, 1)     0         
_________________________________________________________________
conv3d_transpose_420 (Conv3D (None, 514, 5, 19, 1)     102       
_________________________________________________________________
reshape_210 (Reshape)        (None, 2570, 19, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_736"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_314 (Conv2D)          (None, 2590, 19, 1)       19        
_________________________________________________________________
dropout_944 (Dropout)        (None, 2590, 19, 1)       0         
_________________________________________________________________
conv2d_315 (Conv2D)          (None, 2570, 19, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_737"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_314 (Conv2D (None, 2580, 19, 1)       12        
_________________________________________________________________
dropout_946 (Dropout)        (None, 2580, 19, 1)       0         
_________________________________________________________________
conv2d_transpose_315 (Conv2D (None, 2607, 19, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40429622  || Decoder Loss:  0.054831963 Validation Decoder Loss:  0.3277578
Encoder Loss:  0.27905175  || Decoder Loss:  0.03553942 Validation Decoder Loss:  0.33077008
Encoder Loss:  0.04946599  || Decoder Loss:  0.035305306 Validation Decoder Loss:  0.33022597
Encoder Loss:  0.04938228  || Decoder Loss:  0.035143387 Validation Decoder Loss:  0.3301725
Encoder Loss:  0.04937659  || Decoder Loss:  0.035063136 Validation Decoder Loss:  0.33022955
Encoder Loss:  0.04937501  || Decoder Loss:  0.03503013 Validation Decoder Loss:  0.33035403
Encoder Loss:  0.049373657  || Decoder Loss:  0.035005234 Validation Decoder Loss:  0.33054152
Encoder Loss:  0.049372483  || Decoder Loss:  0.03498172 Validation Decoder Loss:  0.33081406
Encoder Loss:  0.04937131  || Decoder Loss:  0.034957457 Validation Decoder Loss:  0.33122772
Encoder Loss:  0.04936976  || Decoder Loss:  0.034931414 Validation Decoder Loss:  0.33182454
Encoder Loss:  0.04936842  || Decoder Loss:  0.034902472 Validation Decoder Loss:  0.3323503
Encoder Loss:  0.04936707  || Decoder Loss:  0.034868687 Validation Decoder Loss:  0.3324573
Encoder Loss:  0.049365416  || Decoder Loss:  0.034830023 Validation Decoder Loss:  0.33288732
Encoder Loss:  0.049363278  || Decoder Loss:  0.0347877 Validation Decoder Loss:  0.33439568
Encoder Loss:  0.049362842  || Decoder Loss:  0.03473921 Validation Decoder Loss:  0.3349122
Encoder Loss:  0.049360152  || Decoder Loss:  0.034700632 Validation Decoder Loss:  0.33657157
Encoder Loss:  0.049373068  || Decoder Loss:  0.03468582 Validation Decoder Loss:  0.33690906
Encoder Loss:  0.049359597  || Decoder Loss:  0.034679748 Validation Decoder Loss:  0.3369993
Encoder Loss:  0.049363796  || Decoder Loss:  0.034676682 Validation Decoder Loss:  0.33707565
Encoder Loss:  0.04936203  || Decoder Loss:  0.034674056 Validation Decoder Loss:  0.33713907
Encoder Loss:  0.049382266  || Decoder Loss:  0.03467257 Validation Decoder Loss:  0.33721218
Encoder Loss:  0.04936513  || Decoder Loss:  0.034674153 Validation Decoder Loss:  0.33728734
Encoder Loss:  0.04935825  || Decoder Loss:  0.03467187 Validation Decoder Loss:  0.3373326
Encoder Loss:  0.049360815  || Decoder Loss:  0.034670018 Validation Decoder Loss:  0.33735788
Encoder Loss:  0.049362436  || Decoder Loss:  0.03466923 Validation Decoder Loss:  0.3373503
Encoder Loss:  0.049365144  || Decoder Loss:  0.03466831 Validation Decoder Loss:  0.3373743
Encoder Loss:  0.04936099  || Decoder Loss:  0.03466595 Validation Decoder Loss:  0.33745238
Encoder Loss:  0.049361404  || Decoder Loss:  0.034664594 Validation Decoder Loss:  0.33743054
Encoder Loss:  0.04937428  || Decoder Loss:  0.034666788 Validation Decoder Loss:  0.33739477
Encoder Loss:  0.04936147  || Decoder Loss:  0.034664202 Validation Decoder Loss:  0.33740908
Encoder Loss:  0.04936329  || Decoder Loss:  0.03466465 Validation Decoder Loss:  0.33730102
Encoder Loss:  0.049363  || Decoder Loss:  0.034663714 Validation Decoder Loss:  0.33728087
Encoder Loss:  0.049361225  || Decoder Loss:  0.034662314 Validation Decoder Loss:  0.337353
Encoder Loss:  0.049361736  || Decoder Loss:  0.034661293 Validation Decoder Loss:  0.3371904
Encoder Loss:  0.04936488  || Decoder Loss:  0.034661584 Validation Decoder Loss:  0.33714235
Encoder Loss:  0.049363922  || Decoder Loss:  0.03466141 Validation Decoder Loss:  0.33727914
Encoder Loss:  0.049359716  || Decoder Loss:  0.034660265 Validation Decoder Loss:  0.33726847
Encoder Loss:  0.049377557  || Decoder Loss:  0.034663737 Validation Decoder Loss:  0.337005
Encoder Loss:  0.04935876  || Decoder Loss:  0.034662046 Validation Decoder Loss:  0.33734238
Encoder Loss:  0.049358405  || Decoder Loss:  0.0346596 Validation Decoder Loss:  0.33733764
Model: siamese_net_lr_0.0007025202376695329 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3373376
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.31451117992401123 2
[(514, 5, 19, 1)] [(2570, 19, 1)]
[(2570, 19, 1)] [(2570, 19, 1)]
[(2607, 19, 1)] [(2570, 19, 1)]
