Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-21 09:12:39.005516: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-21 09:12:39.022517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-21 09:12:39.022687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 09:12:39.023791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-21 09:12:39.024883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-21 09:12:39.025102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-21 09:12:39.026052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-21 09:12:39.026560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-21 09:12:39.028664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-21 09:12:39.029814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-21 09:12:39.030033: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-21 09:12:39.060032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-21 09:12:39.061332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c39aff5b20 executing computations on platform Host. Devices:
2019-11-21 09:12:39.061375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-21 09:12:39.063429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-21 09:12:39.063487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 09:12:39.063512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-21 09:12:39.063536: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-21 09:12:39.063559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-21 09:12:39.063583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-21 09:12:39.063606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-21 09:12:39.063630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-21 09:12:39.067318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-21 09:12:39.067378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-21 09:12:39.296761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-21 09:12:39.296798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-21 09:12:39.296803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-21 09:12:39.298533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-21 09:12:39.300246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c39b8a6620 executing computations on platform CUDA. Devices:
2019-11-21 09:12:39.300273: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-21 09:12:39.690456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 2607, 20)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 344, 5, 20, 1)     93        
_________________________________________________________________
reshape (Reshape)            (None, 1720, 20, 1)       0         
=================================================================
Total params: 93
Trainable params: 93
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1720, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41841483  || Decoder Loss:  0.0773654 Validation Decoder Loss:  0.35999265
Encoder Loss:  0.28891307  || Decoder Loss:  0.2461579 Validation Decoder Loss:  0.84229
Encoder Loss:  0.11578072  || Decoder Loss:  0.24038146 Validation Decoder Loss:  0.54238427
Encoder Loss:  0.07596194  || Decoder Loss:  0.05520713 Validation Decoder Loss:  0.34384656
Encoder Loss:  0.060342327  || Decoder Loss:  0.035970446 Validation Decoder Loss:  0.3316639
Encoder Loss:  0.05295483  || Decoder Loss:  0.03424334 Validation Decoder Loss:  0.33483118
Encoder Loss:  0.05369127  || Decoder Loss:  0.03353968 Validation Decoder Loss:  0.33435392
Encoder Loss:  0.05203624  || Decoder Loss:  0.032999393 Validation Decoder Loss:  0.33409327
Encoder Loss:  0.051181737  || Decoder Loss:  0.03280158 Validation Decoder Loss:  0.33445877
Encoder Loss:  0.051952146  || Decoder Loss:  0.03277683 Validation Decoder Loss:  0.3347812
Encoder Loss:  0.050869834  || Decoder Loss:  0.032576483 Validation Decoder Loss:  0.3348438
Encoder Loss:  0.051269997  || Decoder Loss:  0.03253134 Validation Decoder Loss:  0.33495927
Encoder Loss:  0.05062727  || Decoder Loss:  0.032446884 Validation Decoder Loss:  0.3353637
Encoder Loss:  0.050160155  || Decoder Loss:  0.032397624 Validation Decoder Loss:  0.33550715
Encoder Loss:  0.05030039  || Decoder Loss:  0.032282047 Validation Decoder Loss:  0.3352619
Encoder Loss:  0.050011996  || Decoder Loss:  0.03220579 Validation Decoder Loss:  0.33532935
Encoder Loss:  0.04997681  || Decoder Loss:  0.03215859 Validation Decoder Loss:  0.3353179
Encoder Loss:  0.050527543  || Decoder Loss:  0.03210652 Validation Decoder Loss:  0.33546966
Encoder Loss:  0.050934706  || Decoder Loss:  0.03205223 Validation Decoder Loss:  0.3354117
Encoder Loss:  0.05082743  || Decoder Loss:  0.03198589 Validation Decoder Loss:  0.3355364
Encoder Loss:  0.05027335  || Decoder Loss:  0.03192627 Validation Decoder Loss:  0.3353449
Encoder Loss:  0.050228097  || Decoder Loss:  0.03188852 Validation Decoder Loss:  0.3353905
Encoder Loss:  0.05020802  || Decoder Loss:  0.031862322 Validation Decoder Loss:  0.33544368
Encoder Loss:  0.049981866  || Decoder Loss:  0.031830214 Validation Decoder Loss:  0.33539635
Encoder Loss:  0.049973793  || Decoder Loss:  0.031815983 Validation Decoder Loss:  0.33543426
Encoder Loss:  0.049820717  || Decoder Loss:  0.031802356 Validation Decoder Loss:  0.33550188
Encoder Loss:  0.049981225  || Decoder Loss:  0.0317679 Validation Decoder Loss:  0.33575618
Encoder Loss:  0.04999787  || Decoder Loss:  0.031730827 Validation Decoder Loss:  0.33586812
Encoder Loss:  0.049845662  || Decoder Loss:  0.031706512 Validation Decoder Loss:  0.33559993
Encoder Loss:  0.049920723  || Decoder Loss:  0.031685602 Validation Decoder Loss:  0.33585364
Encoder Loss:  0.05021493  || Decoder Loss:  0.031642355 Validation Decoder Loss:  0.33595625
Encoder Loss:  0.050053705  || Decoder Loss:  0.031612027 Validation Decoder Loss:  0.3358814
Encoder Loss:  0.050054297  || Decoder Loss:  0.03160112 Validation Decoder Loss:  0.33565867
Encoder Loss:  0.049830824  || Decoder Loss:  0.031582125 Validation Decoder Loss:  0.33583418
Encoder Loss:  0.050300226  || Decoder Loss:  0.03154875 Validation Decoder Loss:  0.33613986
Encoder Loss:  0.049906746  || Decoder Loss:  0.031510968 Validation Decoder Loss:  0.33546072
Encoder Loss:  0.049877275  || Decoder Loss:  0.03149943 Validation Decoder Loss:  0.3357951
Encoder Loss:  0.049666576  || Decoder Loss:  0.031472154 Validation Decoder Loss:  0.33542973
Encoder Loss:  0.050131965  || Decoder Loss:  0.031491186 Validation Decoder Loss:  0.3361311
Encoder Loss:  0.050711293  || Decoder Loss:  0.031444855 Validation Decoder Loss:  0.33593276
Model: siamese_net_lr_0.011304138812262672 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33593276
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 107, 10, 20, 1)    89        
_________________________________________________________________
reshape_1 (Reshape)          (None, 1070, 20, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 1070, 20, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 20, 1)       1539      
=================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28269774  || Decoder Loss:  0.07604196 Validation Decoder Loss:  0.37415227
Encoder Loss:  0.26843348  || Decoder Loss:  0.33243206 Validation Decoder Loss:  1.0861051
Encoder Loss:  0.22913966  || Decoder Loss:  0.40847558 Validation Decoder Loss:  0.9804367
Encoder Loss:  0.21430273  || Decoder Loss:  0.3779963 Validation Decoder Loss:  0.5846455
Encoder Loss:  0.10287071  || Decoder Loss:  0.10313848 Validation Decoder Loss:  0.32933217
Encoder Loss:  0.0703824  || Decoder Loss:  0.030762501 Validation Decoder Loss:  0.36851123
Encoder Loss:  0.07130069  || Decoder Loss:  0.029036034 Validation Decoder Loss:  0.35463274
Encoder Loss:  0.08951185  || Decoder Loss:  0.03324348 Validation Decoder Loss:  0.3682465
Encoder Loss:  0.0730223  || Decoder Loss:  0.034432888 Validation Decoder Loss:  0.3402558
Encoder Loss:  0.07280393  || Decoder Loss:  0.03112072 Validation Decoder Loss:  0.34442124
Encoder Loss:  0.06576883  || Decoder Loss:  0.026461862 Validation Decoder Loss:  0.35618627
Encoder Loss:  0.07835831  || Decoder Loss:  0.029330827 Validation Decoder Loss:  0.3600303
Encoder Loss:  0.074602574  || Decoder Loss:  0.029934024 Validation Decoder Loss:  0.3526469
Encoder Loss:  0.06403451  || Decoder Loss:  0.029221095 Validation Decoder Loss:  0.35632557
Encoder Loss:  0.06688618  || Decoder Loss:  0.040432356 Validation Decoder Loss:  0.34873104
Encoder Loss:  0.06262053  || Decoder Loss:  0.0412049 Validation Decoder Loss:  0.38119254
Encoder Loss:  0.061474238  || Decoder Loss:  0.0423118 Validation Decoder Loss:  0.36836302
Encoder Loss:  0.061775237  || Decoder Loss:  0.045711514 Validation Decoder Loss:  0.3614063
Encoder Loss:  0.06547171  || Decoder Loss:  0.048441153 Validation Decoder Loss:  0.36335438
Encoder Loss:  0.056891695  || Decoder Loss:  0.043443132 Validation Decoder Loss:  0.34411848
Encoder Loss:  0.055202555  || Decoder Loss:  0.04349865 Validation Decoder Loss:  0.34934595
Encoder Loss:  0.06087512  || Decoder Loss:  0.04719872 Validation Decoder Loss:  0.33296785
Encoder Loss:  0.055119686  || Decoder Loss:  0.043843973 Validation Decoder Loss:  0.33066434
Encoder Loss:  0.05137317  || Decoder Loss:  0.04308603 Validation Decoder Loss:  0.33859557
Encoder Loss:  0.05059638  || Decoder Loss:  0.042634483 Validation Decoder Loss:  0.34116408
Encoder Loss:  0.049516045  || Decoder Loss:  0.040138584 Validation Decoder Loss:  0.3457024
Encoder Loss:  0.052007098  || Decoder Loss:  0.04105582 Validation Decoder Loss:  0.34771597
Encoder Loss:  0.049519084  || Decoder Loss:  0.04035425 Validation Decoder Loss:  0.34736013
Encoder Loss:  0.04842602  || Decoder Loss:  0.03896228 Validation Decoder Loss:  0.34545672
Encoder Loss:  0.048164453  || Decoder Loss:  0.038074788 Validation Decoder Loss:  0.3461097
Encoder Loss:  0.051495958  || Decoder Loss:  0.038420666 Validation Decoder Loss:  0.35149586
Encoder Loss:  0.047764435  || Decoder Loss:  0.037970103 Validation Decoder Loss:  0.35276216
Encoder Loss:  0.048930656  || Decoder Loss:  0.0382701 Validation Decoder Loss:  0.35656565
Encoder Loss:  0.051142074  || Decoder Loss:  0.03869165 Validation Decoder Loss:  0.35167575
Encoder Loss:  0.05297646  || Decoder Loss:  0.039389566 Validation Decoder Loss:  0.34896457
Encoder Loss:  0.050875887  || Decoder Loss:  0.03865264 Validation Decoder Loss:  0.35218275
Encoder Loss:  0.049945332  || Decoder Loss:  0.039150838 Validation Decoder Loss:  0.34696174
Encoder Loss:  0.04731382  || Decoder Loss:  0.0376241 Validation Decoder Loss:  0.3469211
Encoder Loss:  0.051645946  || Decoder Loss:  0.03787064 Validation Decoder Loss:  0.34871107
Encoder Loss:  0.051444773  || Decoder Loss:  0.038002983 Validation Decoder Loss:  0.34852448
Model: siamese_net_lr_0.790874661929334 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34852448
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 254, 5, 20, 1)     129       
_________________________________________________________________
reshape_2 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.111266196  || Decoder Loss:  0.06488833 Validation Decoder Loss:  0.32876498
Encoder Loss:  0.051813804  || Decoder Loss:  0.036240224 Validation Decoder Loss:  0.32981983
Encoder Loss:  0.05161861  || Decoder Loss:  0.036598522 Validation Decoder Loss:  0.33028483
Encoder Loss:  0.049779896  || Decoder Loss:  0.036481027 Validation Decoder Loss:  0.3303864
Encoder Loss:  0.050870925  || Decoder Loss:  0.03686128 Validation Decoder Loss:  0.3305661
Encoder Loss:  0.04984084  || Decoder Loss:  0.036675602 Validation Decoder Loss:  0.33175045
Encoder Loss:  0.050868154  || Decoder Loss:  0.036735833 Validation Decoder Loss:  0.33303073
Encoder Loss:  0.050365515  || Decoder Loss:  0.036397222 Validation Decoder Loss:  0.33232856
Encoder Loss:  0.04961961  || Decoder Loss:  0.03633163 Validation Decoder Loss:  0.33379236
Encoder Loss:  0.04902749  || Decoder Loss:  0.036054038 Validation Decoder Loss:  0.33261764
Encoder Loss:  0.04898351  || Decoder Loss:  0.035941944 Validation Decoder Loss:  0.33528674
Encoder Loss:  0.05666355  || Decoder Loss:  0.03667687 Validation Decoder Loss:  0.3332206
Encoder Loss:  0.048533816  || Decoder Loss:  0.03585355 Validation Decoder Loss:  0.33457756
Encoder Loss:  0.049416494  || Decoder Loss:  0.03592095 Validation Decoder Loss:  0.33429837
Encoder Loss:  0.04958439  || Decoder Loss:  0.035837818 Validation Decoder Loss:  0.33385414
Encoder Loss:  0.049400624  || Decoder Loss:  0.035742577 Validation Decoder Loss:  0.33386838
Encoder Loss:  0.04875665  || Decoder Loss:  0.035715908 Validation Decoder Loss:  0.3334829
Encoder Loss:  0.049257856  || Decoder Loss:  0.035715144 Validation Decoder Loss:  0.3331244
Encoder Loss:  0.048918772  || Decoder Loss:  0.035629455 Validation Decoder Loss:  0.33327848
Encoder Loss:  0.05006656  || Decoder Loss:  0.03563668 Validation Decoder Loss:  0.33351025
Encoder Loss:  0.048714396  || Decoder Loss:  0.035592414 Validation Decoder Loss:  0.33289707
Encoder Loss:  0.048776843  || Decoder Loss:  0.035543896 Validation Decoder Loss:  0.33339936
Encoder Loss:  0.048580095  || Decoder Loss:  0.035547063 Validation Decoder Loss:  0.33370447
Encoder Loss:  0.04876014  || Decoder Loss:  0.03552245 Validation Decoder Loss:  0.33245957
Encoder Loss:  0.048768748  || Decoder Loss:  0.03550896 Validation Decoder Loss:  0.33271474
Encoder Loss:  0.04840848  || Decoder Loss:  0.03544195 Validation Decoder Loss:  0.33207238
Encoder Loss:  0.05057131  || Decoder Loss:  0.035559624 Validation Decoder Loss:  0.3336866
Encoder Loss:  0.048483945  || Decoder Loss:  0.0354494 Validation Decoder Loss:  0.33331087
Encoder Loss:  0.048503537  || Decoder Loss:  0.03545188 Validation Decoder Loss:  0.333601
Encoder Loss:  0.049145326  || Decoder Loss:  0.035459112 Validation Decoder Loss:  0.33404392
Encoder Loss:  0.048604418  || Decoder Loss:  0.03543611 Validation Decoder Loss:  0.33275044
Encoder Loss:  0.048474938  || Decoder Loss:  0.035468962 Validation Decoder Loss:  0.33251557
Encoder Loss:  0.049728714  || Decoder Loss:  0.035469193 Validation Decoder Loss:  0.33314705
Encoder Loss:  0.048531085  || Decoder Loss:  0.035436098 Validation Decoder Loss:  0.3337878
Encoder Loss:  0.04914864  || Decoder Loss:  0.03543915 Validation Decoder Loss:  0.333601
Encoder Loss:  0.048581906  || Decoder Loss:  0.03543707 Validation Decoder Loss:  0.33436286
Encoder Loss:  0.048329987  || Decoder Loss:  0.03538799 Validation Decoder Loss:  0.3336912
Encoder Loss:  0.04924556  || Decoder Loss:  0.03542939 Validation Decoder Loss:  0.33408934
Encoder Loss:  0.048411813  || Decoder Loss:  0.03539385 Validation Decoder Loss:  0.33330548
Encoder Loss:  0.048468016  || Decoder Loss:  0.035406783 Validation Decoder Loss:  0.33372825
Model: siamese_net_lr_0.5130190452054623 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33372825
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 295, 6, 20, 1)     339       
_________________________________________________________________
reshape_3 (Reshape)          (None, 1770, 20, 1)       0         
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 1770, 20, 1)       839       
=================================================================
Total params: 839
Trainable params: 839
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 20, 1)       839       
=================================================================
Total params: 839
Trainable params: 839
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.089622  || Decoder Loss:  0.06991828 Validation Decoder Loss:  0.31076276
Encoder Loss:  0.04820131  || Decoder Loss:  0.03746232 Validation Decoder Loss:  0.3289007
Encoder Loss:  0.046457533  || Decoder Loss:  0.036921076 Validation Decoder Loss:  0.33029515
Encoder Loss:  0.046398047  || Decoder Loss:  0.036879808 Validation Decoder Loss:  0.3324021
Encoder Loss:  0.04474086  || Decoder Loss:  0.036439635 Validation Decoder Loss:  0.3346015
Encoder Loss:  0.044173695  || Decoder Loss:  0.036381498 Validation Decoder Loss:  0.33298928
Encoder Loss:  0.0450112  || Decoder Loss:  0.036732756 Validation Decoder Loss:  0.3317365
Encoder Loss:  0.04378549  || Decoder Loss:  0.036225077 Validation Decoder Loss:  0.342052
Encoder Loss:  0.045137137  || Decoder Loss:  0.03718986 Validation Decoder Loss:  0.33257684
Encoder Loss:  0.04307671  || Decoder Loss:  0.03585472 Validation Decoder Loss:  0.34451044
Encoder Loss:  0.043076385  || Decoder Loss:  0.035769142 Validation Decoder Loss:  0.34835202
Encoder Loss:  0.043048225  || Decoder Loss:  0.03560082 Validation Decoder Loss:  0.34099072
Encoder Loss:  0.04329835  || Decoder Loss:  0.03591307 Validation Decoder Loss:  0.33865064
Encoder Loss:  0.0432459  || Decoder Loss:  0.03601818 Validation Decoder Loss:  0.3414435
Encoder Loss:  0.04281422  || Decoder Loss:  0.03579713 Validation Decoder Loss:  0.3395679
Encoder Loss:  0.04267815  || Decoder Loss:  0.035462826 Validation Decoder Loss:  0.33942026
Encoder Loss:  0.04310172  || Decoder Loss:  0.035987113 Validation Decoder Loss:  0.3394481
Encoder Loss:  0.042937294  || Decoder Loss:  0.035666868 Validation Decoder Loss:  0.3397324
Encoder Loss:  0.043032147  || Decoder Loss:  0.03573608 Validation Decoder Loss:  0.3398303
Encoder Loss:  0.043262135  || Decoder Loss:  0.035811886 Validation Decoder Loss:  0.33940285
Encoder Loss:  0.04264459  || Decoder Loss:  0.035435416 Validation Decoder Loss:  0.34026843
Encoder Loss:  0.042661194  || Decoder Loss:  0.035443805 Validation Decoder Loss:  0.33948475
Encoder Loss:  0.042975258  || Decoder Loss:  0.035690024 Validation Decoder Loss:  0.33978623
Encoder Loss:  0.042562786  || Decoder Loss:  0.03533691 Validation Decoder Loss:  0.33968237
Encoder Loss:  0.04387851  || Decoder Loss:  0.036140252 Validation Decoder Loss:  0.3395781
Encoder Loss:  0.042643767  || Decoder Loss:  0.03541333 Validation Decoder Loss:  0.33951163
Encoder Loss:  0.042626992  || Decoder Loss:  0.03546407 Validation Decoder Loss:  0.3397961
Encoder Loss:  0.042666405  || Decoder Loss:  0.035375502 Validation Decoder Loss:  0.339481
Encoder Loss:  0.04279694  || Decoder Loss:  0.035559367 Validation Decoder Loss:  0.3397118
Encoder Loss:  0.04249602  || Decoder Loss:  0.035139494 Validation Decoder Loss:  0.33922586
Encoder Loss:  0.042730063  || Decoder Loss:  0.03559871 Validation Decoder Loss:  0.3395322
Encoder Loss:  0.042473592  || Decoder Loss:  0.035080012 Validation Decoder Loss:  0.33940792
Encoder Loss:  0.042725854  || Decoder Loss:  0.03567009 Validation Decoder Loss:  0.33874398
Encoder Loss:  0.042554714  || Decoder Loss:  0.03522939 Validation Decoder Loss:  0.3398234
Encoder Loss:  0.0425493  || Decoder Loss:  0.03526522 Validation Decoder Loss:  0.33927408
Encoder Loss:  0.042591095  || Decoder Loss:  0.035289735 Validation Decoder Loss:  0.34003276
Encoder Loss:  0.043052793  || Decoder Loss:  0.035499614 Validation Decoder Loss:  0.3389805
Encoder Loss:  0.042407867  || Decoder Loss:  0.035136275 Validation Decoder Loss:  0.34016207
Encoder Loss:  0.04247425  || Decoder Loss:  0.03525849 Validation Decoder Loss:  0.33908704
Encoder Loss:  0.042524118  || Decoder Loss:  0.03513032 Validation Decoder Loss:  0.34063715
Model: siamese_net_lr_0.01696364852125937 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34063715
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 514, 5, 20, 1)     452       
_________________________________________________________________
reshape_4 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 452
Trainable params: 452
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.091158554  || Decoder Loss:  0.038285926 Validation Decoder Loss:  0.33869177
Encoder Loss:  0.063392974  || Decoder Loss:  0.036363516 Validation Decoder Loss:  0.3394566
Encoder Loss:  0.055563916  || Decoder Loss:  0.03590574 Validation Decoder Loss:  0.33874702
Encoder Loss:  0.0502462  || Decoder Loss:  0.03557172 Validation Decoder Loss:  0.33827522
Encoder Loss:  0.046867743  || Decoder Loss:  0.035356868 Validation Decoder Loss:  0.33810097
Encoder Loss:  0.047072645  || Decoder Loss:  0.035329025 Validation Decoder Loss:  0.33775944
Encoder Loss:  0.048325423  || Decoder Loss:  0.035378154 Validation Decoder Loss:  0.3375255
Encoder Loss:  0.046965774  || Decoder Loss:  0.03528162 Validation Decoder Loss:  0.33712974
Encoder Loss:  0.04721998  || Decoder Loss:  0.035282444 Validation Decoder Loss:  0.33722612
Encoder Loss:  0.048291806  || Decoder Loss:  0.035351366 Validation Decoder Loss:  0.33847106
Encoder Loss:  0.05342468  || Decoder Loss:  0.035748597 Validation Decoder Loss:  0.33688852
Encoder Loss:  0.046878435  || Decoder Loss:  0.035292048 Validation Decoder Loss:  0.33732206
Encoder Loss:  0.046860732  || Decoder Loss:  0.035284624 Validation Decoder Loss:  0.3373617
Encoder Loss:  0.047347542  || Decoder Loss:  0.035289302 Validation Decoder Loss:  0.33751577
Encoder Loss:  0.047956463  || Decoder Loss:  0.035347626 Validation Decoder Loss:  0.33720788
Encoder Loss:  0.046929065  || Decoder Loss:  0.03526952 Validation Decoder Loss:  0.33677065
Encoder Loss:  0.04682024  || Decoder Loss:  0.035257563 Validation Decoder Loss:  0.3367523
Encoder Loss:  0.047736663  || Decoder Loss:  0.035302684 Validation Decoder Loss:  0.3367588
Encoder Loss:  0.048179187  || Decoder Loss:  0.03537664 Validation Decoder Loss:  0.33628786
Encoder Loss:  0.04691431  || Decoder Loss:  0.03526085 Validation Decoder Loss:  0.3365659
Encoder Loss:  0.047018386  || Decoder Loss:  0.035273097 Validation Decoder Loss:  0.3365415
Encoder Loss:  0.047213353  || Decoder Loss:  0.0352757 Validation Decoder Loss:  0.3366735
Encoder Loss:  0.047693655  || Decoder Loss:  0.035305217 Validation Decoder Loss:  0.33709264
Encoder Loss:  0.047442116  || Decoder Loss:  0.03529984 Validation Decoder Loss:  0.33714277
Encoder Loss:  0.04814304  || Decoder Loss:  0.03531541 Validation Decoder Loss:  0.33884344
Encoder Loss:  0.049912635  || Decoder Loss:  0.035522085 Validation Decoder Loss:  0.3368703
Encoder Loss:  0.047003616  || Decoder Loss:  0.035279244 Validation Decoder Loss:  0.3359277
Encoder Loss:  0.048636194  || Decoder Loss:  0.035404593 Validation Decoder Loss:  0.33496892
Encoder Loss:  0.046841636  || Decoder Loss:  0.035259787 Validation Decoder Loss:  0.3365186
Encoder Loss:  0.04691346  || Decoder Loss:  0.035273246 Validation Decoder Loss:  0.33634588
Encoder Loss:  0.04716689  || Decoder Loss:  0.03528162 Validation Decoder Loss:  0.336202
Encoder Loss:  0.047251683  || Decoder Loss:  0.03528975 Validation Decoder Loss:  0.33623308
Encoder Loss:  0.0473946  || Decoder Loss:  0.035293233 Validation Decoder Loss:  0.336341
Encoder Loss:  0.04710078  || Decoder Loss:  0.035274263 Validation Decoder Loss:  0.3358515
Encoder Loss:  0.047090422  || Decoder Loss:  0.035262797 Validation Decoder Loss:  0.3360104
Encoder Loss:  0.050530642  || Decoder Loss:  0.035470974 Validation Decoder Loss:  0.3367322
Encoder Loss:  0.04777386  || Decoder Loss:  0.035334233 Validation Decoder Loss:  0.3363061
Encoder Loss:  0.04680906  || Decoder Loss:  0.035265364 Validation Decoder Loss:  0.33591235
Encoder Loss:  0.046946716  || Decoder Loss:  0.035265878 Validation Decoder Loss:  0.33571222
Encoder Loss:  0.04702239  || Decoder Loss:  0.035264574 Validation Decoder Loss:  0.3358869
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.18651542018842607 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3358869
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 127, 10, 20, 1)    385       
_________________________________________________________________
reshape_5 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08071058  || Decoder Loss:  0.080679804 Validation Decoder Loss:  0.33250415
Encoder Loss:  0.053743836  || Decoder Loss:  0.037411164 Validation Decoder Loss:  0.3371215
Encoder Loss:  0.052379835  || Decoder Loss:  0.03734057 Validation Decoder Loss:  0.3382643
Encoder Loss:  0.05284108  || Decoder Loss:  0.037249874 Validation Decoder Loss:  0.3383639
Encoder Loss:  0.05070047  || Decoder Loss:  0.04114587 Validation Decoder Loss:  0.331936
Encoder Loss:  0.050836124  || Decoder Loss:  0.03841429 Validation Decoder Loss:  0.32504064
Encoder Loss:  0.04973456  || Decoder Loss:  0.037650574 Validation Decoder Loss:  0.32174772
Encoder Loss:  0.05287199  || Decoder Loss:  0.03826314 Validation Decoder Loss:  0.32130295
Encoder Loss:  0.049238514  || Decoder Loss:  0.037050534 Validation Decoder Loss:  0.32151753
Encoder Loss:  0.049664572  || Decoder Loss:  0.036949173 Validation Decoder Loss:  0.322164
Encoder Loss:  0.049990863  || Decoder Loss:  0.036877323 Validation Decoder Loss:  0.32168177
Encoder Loss:  0.04935101  || Decoder Loss:  0.036603477 Validation Decoder Loss:  0.32330775
Encoder Loss:  0.049683772  || Decoder Loss:  0.03648757 Validation Decoder Loss:  0.32431653
Encoder Loss:  0.04923696  || Decoder Loss:  0.036296867 Validation Decoder Loss:  0.3248976
Encoder Loss:  0.049495205  || Decoder Loss:  0.03621733 Validation Decoder Loss:  0.32515207
Encoder Loss:  0.049642645  || Decoder Loss:  0.036151774 Validation Decoder Loss:  0.3252436
Encoder Loss:  0.050264712  || Decoder Loss:  0.036130868 Validation Decoder Loss:  0.32566315
Encoder Loss:  0.051318232  || Decoder Loss:  0.036164895 Validation Decoder Loss:  0.32572198
Encoder Loss:  0.048897166  || Decoder Loss:  0.035922736 Validation Decoder Loss:  0.32645085
Encoder Loss:  0.04900733  || Decoder Loss:  0.035884 Validation Decoder Loss:  0.3266445
Encoder Loss:  0.05098827  || Decoder Loss:  0.03599128 Validation Decoder Loss:  0.32678
Encoder Loss:  0.04880518  || Decoder Loss:  0.03581487 Validation Decoder Loss:  0.32712653
Encoder Loss:  0.04931249  || Decoder Loss:  0.03581578 Validation Decoder Loss:  0.3276312
Encoder Loss:  0.049003974  || Decoder Loss:  0.03577493 Validation Decoder Loss:  0.32770377
Encoder Loss:  0.048855744  || Decoder Loss:  0.03573424 Validation Decoder Loss:  0.3285582
Encoder Loss:  0.049034625  || Decoder Loss:  0.035725735 Validation Decoder Loss:  0.32832187
Encoder Loss:  0.04897863  || Decoder Loss:  0.035701845 Validation Decoder Loss:  0.32871965
Encoder Loss:  0.04876428  || Decoder Loss:  0.035671897 Validation Decoder Loss:  0.32874382
Encoder Loss:  0.049723048  || Decoder Loss:  0.035700973 Validation Decoder Loss:  0.3290533
Encoder Loss:  0.048564468  || Decoder Loss:  0.035632487 Validation Decoder Loss:  0.32950628
Encoder Loss:  0.04859063  || Decoder Loss:  0.035618827 Validation Decoder Loss:  0.3294847
Encoder Loss:  0.048883963  || Decoder Loss:  0.035616722 Validation Decoder Loss:  0.32955754
Encoder Loss:  0.048866466  || Decoder Loss:  0.0356062 Validation Decoder Loss:  0.3299769
Encoder Loss:  0.048747726  || Decoder Loss:  0.035589818 Validation Decoder Loss:  0.32993683
Encoder Loss:  0.04882146  || Decoder Loss:  0.035580803 Validation Decoder Loss:  0.33020204
Encoder Loss:  0.04875914  || Decoder Loss:  0.03556567 Validation Decoder Loss:  0.33025622
Encoder Loss:  0.04877363  || Decoder Loss:  0.035560705 Validation Decoder Loss:  0.33046165
Encoder Loss:  0.048781246  || Decoder Loss:  0.03554906 Validation Decoder Loss:  0.33040166
Encoder Loss:  0.048716832  || Decoder Loss:  0.035539635 Validation Decoder Loss:  0.33060104
Encoder Loss:  0.048868652  || Decoder Loss:  0.035534035 Validation Decoder Loss:  0.33081213
Model: siamese_net_lr_0.5130194746304321 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33081216
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 254, 5, 20, 1)     66        
_________________________________________________________________
reshape_6 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15437956  || Decoder Loss:  0.04549817 Validation Decoder Loss:  0.33151662
Encoder Loss:  0.079583436  || Decoder Loss:  0.03814779 Validation Decoder Loss:  0.33250585
Encoder Loss:  0.06836577  || Decoder Loss:  0.04017002 Validation Decoder Loss:  0.33177406
Encoder Loss:  0.055684213  || Decoder Loss:  0.037787925 Validation Decoder Loss:  0.33266476
Encoder Loss:  0.05115757  || Decoder Loss:  0.037151445 Validation Decoder Loss:  0.3322096
Encoder Loss:  0.049585413  || Decoder Loss:  0.03678814 Validation Decoder Loss:  0.33217436
Encoder Loss:  0.059040222  || Decoder Loss:  0.037411347 Validation Decoder Loss:  0.33194974
Encoder Loss:  0.049634956  || Decoder Loss:  0.03649777 Validation Decoder Loss:  0.332196
Encoder Loss:  0.054768834  || Decoder Loss:  0.03688633 Validation Decoder Loss:  0.33142102
Encoder Loss:  0.05061265  || Decoder Loss:  0.0362946 Validation Decoder Loss:  0.33154088
Encoder Loss:  0.04911671  || Decoder Loss:  0.036073077 Validation Decoder Loss:  0.33176368
Encoder Loss:  0.049492642  || Decoder Loss:  0.035975136 Validation Decoder Loss:  0.33186918
Encoder Loss:  0.051552176  || Decoder Loss:  0.03616244 Validation Decoder Loss:  0.33120278
Encoder Loss:  0.048890185  || Decoder Loss:  0.035780832 Validation Decoder Loss:  0.33149946
Encoder Loss:  0.049709223  || Decoder Loss:  0.03578158 Validation Decoder Loss:  0.33145928
Encoder Loss:  0.04951535  || Decoder Loss:  0.035685115 Validation Decoder Loss:  0.3315179
Encoder Loss:  0.049475487  || Decoder Loss:  0.03563486 Validation Decoder Loss:  0.33131617
Encoder Loss:  0.051075716  || Decoder Loss:  0.03564129 Validation Decoder Loss:  0.3315997
Encoder Loss:  0.04942697  || Decoder Loss:  0.035535008 Validation Decoder Loss:  0.33178705
Encoder Loss:  0.049819842  || Decoder Loss:  0.035585374 Validation Decoder Loss:  0.3314405
Encoder Loss:  0.049212947  || Decoder Loss:  0.03549926 Validation Decoder Loss:  0.3314948
Encoder Loss:  0.049124654  || Decoder Loss:  0.035501923 Validation Decoder Loss:  0.33133823
Encoder Loss:  0.052854773  || Decoder Loss:  0.035577957 Validation Decoder Loss:  0.33148414
Encoder Loss:  0.048834037  || Decoder Loss:  0.035452563 Validation Decoder Loss:  0.33187574
Encoder Loss:  0.055681035  || Decoder Loss:  0.035551388 Validation Decoder Loss:  0.33120996
Encoder Loss:  0.04874286  || Decoder Loss:  0.0354713 Validation Decoder Loss:  0.3313503
Encoder Loss:  0.05009092  || Decoder Loss:  0.035471525 Validation Decoder Loss:  0.33133847
Encoder Loss:  0.048867792  || Decoder Loss:  0.035429467 Validation Decoder Loss:  0.3315133
Encoder Loss:  0.04951627  || Decoder Loss:  0.03543824 Validation Decoder Loss:  0.33133817
Encoder Loss:  0.04882618  || Decoder Loss:  0.035418384 Validation Decoder Loss:  0.33135417
Encoder Loss:  0.05146473  || Decoder Loss:  0.035446756 Validation Decoder Loss:  0.33144534
Encoder Loss:  0.048867486  || Decoder Loss:  0.03540577 Validation Decoder Loss:  0.33159822
Encoder Loss:  0.049925752  || Decoder Loss:  0.0354158 Validation Decoder Loss:  0.331481
Encoder Loss:  0.048774496  || Decoder Loss:  0.035400156 Validation Decoder Loss:  0.3314541
Encoder Loss:  0.048814736  || Decoder Loss:  0.035388414 Validation Decoder Loss:  0.331367
Encoder Loss:  0.049077183  || Decoder Loss:  0.035388116 Validation Decoder Loss:  0.3313372
Encoder Loss:  0.04884918  || Decoder Loss:  0.03537977 Validation Decoder Loss:  0.3314994
Encoder Loss:  0.04917354  || Decoder Loss:  0.035379782 Validation Decoder Loss:  0.3315155
Encoder Loss:  0.048810106  || Decoder Loss:  0.03536916 Validation Decoder Loss:  0.33152708
Encoder Loss:  0.048962105  || Decoder Loss:  0.035363372 Validation Decoder Loss:  0.33169276
Model: siamese_net_lr_0.5049701973079738 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33169276
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 254, 5, 20, 1)     192       
_________________________________________________________________
reshape_7 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10724797  || Decoder Loss:  0.05950775 Validation Decoder Loss:  0.3424707
Encoder Loss:  0.07447663  || Decoder Loss:  0.038062137 Validation Decoder Loss:  0.3308403
Encoder Loss:  0.06676684  || Decoder Loss:  0.037455004 Validation Decoder Loss:  0.33381057
Encoder Loss:  0.06553775  || Decoder Loss:  0.037143692 Validation Decoder Loss:  0.34329537
Encoder Loss:  0.05292353  || Decoder Loss:  0.036346834 Validation Decoder Loss:  0.34344733
Encoder Loss:  0.052577127  || Decoder Loss:  0.036217637 Validation Decoder Loss:  0.32983476
Encoder Loss:  0.052563258  || Decoder Loss:  0.03609726 Validation Decoder Loss:  0.331145
Encoder Loss:  0.051986013  || Decoder Loss:  0.035983782 Validation Decoder Loss:  0.33266938
Encoder Loss:  0.051722135  || Decoder Loss:  0.035890117 Validation Decoder Loss:  0.33092403
Encoder Loss:  0.051419124  || Decoder Loss:  0.03821323 Validation Decoder Loss:  0.32431892
Encoder Loss:  0.05108078  || Decoder Loss:  0.03634678 Validation Decoder Loss:  0.32452643
Encoder Loss:  0.051328164  || Decoder Loss:  0.03626266 Validation Decoder Loss:  0.3244518
Encoder Loss:  0.05119278  || Decoder Loss:  0.0361348 Validation Decoder Loss:  0.3249624
Encoder Loss:  0.053841256  || Decoder Loss:  0.036299378 Validation Decoder Loss:  0.325029
Encoder Loss:  0.051279683  || Decoder Loss:  0.0359716 Validation Decoder Loss:  0.3257119
Encoder Loss:  0.050594345  || Decoder Loss:  0.0358233 Validation Decoder Loss:  0.32594323
Encoder Loss:  0.0510469  || Decoder Loss:  0.035797097 Validation Decoder Loss:  0.32639802
Encoder Loss:  0.051007077  || Decoder Loss:  0.03573395 Validation Decoder Loss:  0.32664314
Encoder Loss:  0.05154943  || Decoder Loss:  0.03573006 Validation Decoder Loss:  0.32650423
Encoder Loss:  0.050676964  || Decoder Loss:  0.035623357 Validation Decoder Loss:  0.32677147
Encoder Loss:  0.052090243  || Decoder Loss:  0.035658523 Validation Decoder Loss:  0.326617
Encoder Loss:  0.052214947  || Decoder Loss:  0.035630606 Validation Decoder Loss:  0.3265028
Encoder Loss:  0.051130977  || Decoder Loss:  0.0355499 Validation Decoder Loss:  0.32691044
Encoder Loss:  0.05198961  || Decoder Loss:  0.03555618 Validation Decoder Loss:  0.32672507
Encoder Loss:  0.05038946  || Decoder Loss:  0.03546763 Validation Decoder Loss:  0.3268707
Encoder Loss:  0.05051669  || Decoder Loss:  0.0354517 Validation Decoder Loss:  0.32694167
Encoder Loss:  0.051011097  || Decoder Loss:  0.03544528 Validation Decoder Loss:  0.3270288
Encoder Loss:  0.050559968  || Decoder Loss:  0.035414007 Validation Decoder Loss:  0.32711238
Encoder Loss:  0.051129322  || Decoder Loss:  0.035422936 Validation Decoder Loss:  0.32715058
Encoder Loss:  0.05050113  || Decoder Loss:  0.035380572 Validation Decoder Loss:  0.32720554
Encoder Loss:  0.050721012  || Decoder Loss:  0.03537865 Validation Decoder Loss:  0.32730004
Encoder Loss:  0.050986424  || Decoder Loss:  0.035386723 Validation Decoder Loss:  0.32735977
Encoder Loss:  0.050560374  || Decoder Loss:  0.035364058 Validation Decoder Loss:  0.32745314
Encoder Loss:  0.050580267  || Decoder Loss:  0.03535757 Validation Decoder Loss:  0.32749295
Encoder Loss:  0.050575346  || Decoder Loss:  0.035352387 Validation Decoder Loss:  0.32759348
Encoder Loss:  0.050573807  || Decoder Loss:  0.035344027 Validation Decoder Loss:  0.32764912
Encoder Loss:  0.05051749  || Decoder Loss:  0.03533486 Validation Decoder Loss:  0.3276889
Encoder Loss:  0.05097173  || Decoder Loss:  0.035337128 Validation Decoder Loss:  0.32775718
Encoder Loss:  0.050507866  || Decoder Loss:  0.035315108 Validation Decoder Loss:  0.32779527
Encoder Loss:  0.050712563  || Decoder Loss:  0.035317518 Validation Decoder Loss:  0.32780904
Model: siamese_net_lr_0.4210949819801495 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32780904
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 127, 10, 20, 1)    129       
_________________________________________________________________
reshape_8 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15287663  || Decoder Loss:  0.037507493 Validation Decoder Loss:  0.3300553
Encoder Loss:  0.06907316  || Decoder Loss:  0.03547708 Validation Decoder Loss:  0.3299852
Encoder Loss:  0.062220085  || Decoder Loss:  0.035191443 Validation Decoder Loss:  0.329986
Encoder Loss:  0.057683922  || Decoder Loss:  0.035423428 Validation Decoder Loss:  0.3289287
Encoder Loss:  0.056277476  || Decoder Loss:  0.03481484 Validation Decoder Loss:  0.3308818
Encoder Loss:  0.054674182  || Decoder Loss:  0.03516576 Validation Decoder Loss:  0.33093864
Encoder Loss:  0.053947017  || Decoder Loss:  0.035921253 Validation Decoder Loss:  0.33104974
Encoder Loss:  0.0524925  || Decoder Loss:  0.035384063 Validation Decoder Loss:  0.33199042
Encoder Loss:  0.053325024  || Decoder Loss:  0.035479486 Validation Decoder Loss:  0.3324113
Encoder Loss:  0.052750044  || Decoder Loss:  0.03550242 Validation Decoder Loss:  0.33278775
Encoder Loss:  0.05108376  || Decoder Loss:  0.03544951 Validation Decoder Loss:  0.33317566
Encoder Loss:  0.051871475  || Decoder Loss:  0.03547447 Validation Decoder Loss:  0.33381867
Encoder Loss:  0.051374882  || Decoder Loss:  0.035447836 Validation Decoder Loss:  0.3339321
Encoder Loss:  0.05202498  || Decoder Loss:  0.0354551 Validation Decoder Loss:  0.3339132
Encoder Loss:  0.05094199  || Decoder Loss:  0.03540871 Validation Decoder Loss:  0.33401805
Encoder Loss:  0.05079997  || Decoder Loss:  0.035390683 Validation Decoder Loss:  0.33429787
Encoder Loss:  0.050919835  || Decoder Loss:  0.035379097 Validation Decoder Loss:  0.334248
Encoder Loss:  0.05086262  || Decoder Loss:  0.035361763 Validation Decoder Loss:  0.33462104
Encoder Loss:  0.051291224  || Decoder Loss:  0.035350185 Validation Decoder Loss:  0.33491102
Encoder Loss:  0.051061325  || Decoder Loss:  0.03533865 Validation Decoder Loss:  0.33471537
Encoder Loss:  0.050478753  || Decoder Loss:  0.035331093 Validation Decoder Loss:  0.33482376
Encoder Loss:  0.050810166  || Decoder Loss:  0.035331197 Validation Decoder Loss:  0.33453673
Encoder Loss:  0.050578557  || Decoder Loss:  0.03532112 Validation Decoder Loss:  0.3347149
Encoder Loss:  0.05070671  || Decoder Loss:  0.035322536 Validation Decoder Loss:  0.33444405
Encoder Loss:  0.05063333  || Decoder Loss:  0.035315324 Validation Decoder Loss:  0.3345861
Encoder Loss:  0.050699335  || Decoder Loss:  0.035310827 Validation Decoder Loss:  0.3346151
Encoder Loss:  0.050563976  || Decoder Loss:  0.035301615 Validation Decoder Loss:  0.33462733
Encoder Loss:  0.05054781  || Decoder Loss:  0.035299078 Validation Decoder Loss:  0.3344871
Encoder Loss:  0.05079091  || Decoder Loss:  0.035308164 Validation Decoder Loss:  0.33455476
Encoder Loss:  0.050449964  || Decoder Loss:  0.035296068 Validation Decoder Loss:  0.33460766
Encoder Loss:  0.05083825  || Decoder Loss:  0.035297908 Validation Decoder Loss:  0.3344131
Encoder Loss:  0.051098447  || Decoder Loss:  0.03530009 Validation Decoder Loss:  0.33465916
Encoder Loss:  0.05035199  || Decoder Loss:  0.035288032 Validation Decoder Loss:  0.3347627
Encoder Loss:  0.0503884  || Decoder Loss:  0.035289105 Validation Decoder Loss:  0.33459046
Encoder Loss:  0.05122397  || Decoder Loss:  0.035297588 Validation Decoder Loss:  0.33455753
Encoder Loss:  0.050334558  || Decoder Loss:  0.03528414 Validation Decoder Loss:  0.3344699
Encoder Loss:  0.05036881  || Decoder Loss:  0.035284992 Validation Decoder Loss:  0.33431822
Encoder Loss:  0.051123433  || Decoder Loss:  0.035289396 Validation Decoder Loss:  0.3345129
Encoder Loss:  0.05039878  || Decoder Loss:  0.035277195 Validation Decoder Loss:  0.33452398
Encoder Loss:  0.050564755  || Decoder Loss:  0.035277218 Validation Decoder Loss:  0.33494386
Model: siamese_net_lr_0.09846691761734347 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33494386
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 254, 5, 20, 1)     129       
_________________________________________________________________
reshape_9 (Reshape)          (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.109372966  || Decoder Loss:  0.44726032 Validation Decoder Loss:  1.5348656
Encoder Loss:  0.063543804  || Decoder Loss:  0.50406325 Validation Decoder Loss:  1.2435207
Encoder Loss:  0.053874113  || Decoder Loss:  0.47573254 Validation Decoder Loss:  0.3691948
Encoder Loss:  0.05418183  || Decoder Loss:  0.46203285 Validation Decoder Loss:  0.97264004
Encoder Loss:  0.051180687  || Decoder Loss:  0.49466932 Validation Decoder Loss:  1.0820147
Encoder Loss:  0.051731434  || Decoder Loss:  0.487804 Validation Decoder Loss:  1.2087662
Encoder Loss:  0.051165532  || Decoder Loss:  0.47603813 Validation Decoder Loss:  0.72142255
Encoder Loss:  0.0557611  || Decoder Loss:  0.48179862 Validation Decoder Loss:  1.1051612
Encoder Loss:  0.052297235  || Decoder Loss:  0.5017511 Validation Decoder Loss:  1.0410504
Encoder Loss:  0.051716436  || Decoder Loss:  0.49148434 Validation Decoder Loss:  1.0006576
Encoder Loss:  0.05100567  || Decoder Loss:  0.48909405 Validation Decoder Loss:  1.0188465
Encoder Loss:  0.05093035  || Decoder Loss:  0.48692012 Validation Decoder Loss:  1.020668
Encoder Loss:  0.051056277  || Decoder Loss:  0.44861907 Validation Decoder Loss:  0.80372596
Encoder Loss:  0.050589953  || Decoder Loss:  0.49756378 Validation Decoder Loss:  0.9626398
Encoder Loss:  0.05087345  || Decoder Loss:  0.48111627 Validation Decoder Loss:  0.40368092
Encoder Loss:  0.05088297  || Decoder Loss:  0.49855274 Validation Decoder Loss:  1.0464127
Encoder Loss:  0.050521035  || Decoder Loss:  0.4575887 Validation Decoder Loss:  1.0672069
Encoder Loss:  0.050916944  || Decoder Loss:  0.49475387 Validation Decoder Loss:  1.0804555
Encoder Loss:  0.05166574  || Decoder Loss:  0.48538166 Validation Decoder Loss:  1.0095699
Encoder Loss:  0.050378747  || Decoder Loss:  0.47990972 Validation Decoder Loss:  0.89925605
Encoder Loss:  0.05092118  || Decoder Loss:  0.49181172 Validation Decoder Loss:  0.9360272
Encoder Loss:  0.05038787  || Decoder Loss:  0.49724114 Validation Decoder Loss:  0.9629066
Encoder Loss:  0.050806202  || Decoder Loss:  0.49184787 Validation Decoder Loss:  1.0722616
Encoder Loss:  0.05057253  || Decoder Loss:  0.42740166 Validation Decoder Loss:  0.88822925
Encoder Loss:  0.05113787  || Decoder Loss:  0.49558792 Validation Decoder Loss:  0.57627076
Encoder Loss:  0.050534133  || Decoder Loss:  0.46728677 Validation Decoder Loss:  1.4063762
Encoder Loss:  0.05045474  || Decoder Loss:  0.4836426 Validation Decoder Loss:  0.7694652
Encoder Loss:  0.05094157  || Decoder Loss:  0.47355518 Validation Decoder Loss:  0.9033768
Encoder Loss:  0.050507218  || Decoder Loss:  0.4715706 Validation Decoder Loss:  0.9133589
Encoder Loss:  0.05091293  || Decoder Loss:  0.49436966 Validation Decoder Loss:  1.0293137
Encoder Loss:  0.050372895  || Decoder Loss:  0.31130823 Validation Decoder Loss:  0.59143674
Encoder Loss:  0.05034002  || Decoder Loss:  0.0937052 Validation Decoder Loss:  0.41317993
Encoder Loss:  0.050584625  || Decoder Loss:  0.06780356 Validation Decoder Loss:  0.38035053
Encoder Loss:  0.050537042  || Decoder Loss:  0.05434225 Validation Decoder Loss:  0.38453442
Encoder Loss:  0.050314456  || Decoder Loss:  0.047268886 Validation Decoder Loss:  0.36937946
Encoder Loss:  0.050430015  || Decoder Loss:  0.04672861 Validation Decoder Loss:  0.367398
Encoder Loss:  0.050352637  || Decoder Loss:  0.043504525 Validation Decoder Loss:  0.35883474
Encoder Loss:  0.05048625  || Decoder Loss:  0.042358775 Validation Decoder Loss:  0.37185162
Encoder Loss:  0.050350696  || Decoder Loss:  0.040932484 Validation Decoder Loss:  0.3868882
Encoder Loss:  0.050917316  || Decoder Loss:  0.046583384 Validation Decoder Loss:  0.36795926
Model: siamese_net_lr_0.9636529244166591 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36795923
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 257, 10, 20, 1)    31        
_________________________________________________________________
reshape_10 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22482373  || Decoder Loss:  0.03587468 Validation Decoder Loss:  0.331176
Encoder Loss:  0.14271507  || Decoder Loss:  0.035586827 Validation Decoder Loss:  0.33145612
Encoder Loss:  0.069556266  || Decoder Loss:  0.035549432 Validation Decoder Loss:  0.3314793
Encoder Loss:  0.06350492  || Decoder Loss:  0.035479177 Validation Decoder Loss:  0.3314193
Encoder Loss:  0.05693293  || Decoder Loss:  0.035443794 Validation Decoder Loss:  0.3313991
Encoder Loss:  0.055974312  || Decoder Loss:  0.035421513 Validation Decoder Loss:  0.3313794
Encoder Loss:  0.06176286  || Decoder Loss:  0.03544432 Validation Decoder Loss:  0.33141208
Encoder Loss:  0.05394539  || Decoder Loss:  0.035406362 Validation Decoder Loss:  0.33138305
Encoder Loss:  0.055297002  || Decoder Loss:  0.035404697 Validation Decoder Loss:  0.33144104
Encoder Loss:  0.050296787  || Decoder Loss:  0.035383698 Validation Decoder Loss:  0.3314128
Encoder Loss:  0.05063243  || Decoder Loss:  0.03538663 Validation Decoder Loss:  0.33145034
Encoder Loss:  0.04859647  || Decoder Loss:  0.0353787 Validation Decoder Loss:  0.33142763
Encoder Loss:  0.046049047  || Decoder Loss:  0.03537256 Validation Decoder Loss:  0.33143362
Encoder Loss:  0.049391657  || Decoder Loss:  0.03537228 Validation Decoder Loss:  0.33143353
Encoder Loss:  0.046333  || Decoder Loss:  0.03535777 Validation Decoder Loss:  0.331437
Encoder Loss:  0.047516618  || Decoder Loss:  0.035354227 Validation Decoder Loss:  0.3314366
Encoder Loss:  0.045096412  || Decoder Loss:  0.035341226 Validation Decoder Loss:  0.33143365
Encoder Loss:  0.045198873  || Decoder Loss:  0.035340823 Validation Decoder Loss:  0.33143649
Encoder Loss:  0.044964608  || Decoder Loss:  0.03533949 Validation Decoder Loss:  0.33144248
Encoder Loss:  0.04393397  || Decoder Loss:  0.03533324 Validation Decoder Loss:  0.33144748
Encoder Loss:  0.04420083  || Decoder Loss:  0.03533351 Validation Decoder Loss:  0.3314575
Encoder Loss:  0.045255166  || Decoder Loss:  0.035340413 Validation Decoder Loss:  0.33143586
Encoder Loss:  0.043676615  || Decoder Loss:  0.035329003 Validation Decoder Loss:  0.33143508
Encoder Loss:  0.043921728  || Decoder Loss:  0.035328206 Validation Decoder Loss:  0.33144015
Encoder Loss:  0.043751344  || Decoder Loss:  0.035327945 Validation Decoder Loss:  0.33144838
Encoder Loss:  0.04358426  || Decoder Loss:  0.03532699 Validation Decoder Loss:  0.33143166
Encoder Loss:  0.043609187  || Decoder Loss:  0.035326384 Validation Decoder Loss:  0.3314349
Encoder Loss:  0.043702364  || Decoder Loss:  0.03532679 Validation Decoder Loss:  0.33143544
Encoder Loss:  0.044410445  || Decoder Loss:  0.035332784 Validation Decoder Loss:  0.33143556
Encoder Loss:  0.043492895  || Decoder Loss:  0.035322867 Validation Decoder Loss:  0.33143097
Encoder Loss:  0.048834193  || Decoder Loss:  0.035348736 Validation Decoder Loss:  0.33143115
Encoder Loss:  0.04358919  || Decoder Loss:  0.035325337 Validation Decoder Loss:  0.33143136
Encoder Loss:  0.04346882  || Decoder Loss:  0.035324425 Validation Decoder Loss:  0.33142823
Encoder Loss:  0.043390468  || Decoder Loss:  0.03532569 Validation Decoder Loss:  0.33142775
Encoder Loss:  0.043351874  || Decoder Loss:  0.03532675 Validation Decoder Loss:  0.3314224
Encoder Loss:  0.04331871  || Decoder Loss:  0.035328023 Validation Decoder Loss:  0.3314212
Encoder Loss:  0.043435864  || Decoder Loss:  0.03532895 Validation Decoder Loss:  0.33141655
Encoder Loss:  0.043608952  || Decoder Loss:  0.035330765 Validation Decoder Loss:  0.33142123
Encoder Loss:  0.043468237  || Decoder Loss:  0.03533032 Validation Decoder Loss:  0.33141467
Encoder Loss:  0.043278076  || Decoder Loss:  0.03533071 Validation Decoder Loss:  0.33141094
Model: siamese_net_lr_0.33014180409209154 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33141088
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 254, 5, 20, 1)     129       
_________________________________________________________________
reshape_11 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11196569  || Decoder Loss:  0.44884473 Validation Decoder Loss:  0.6628454
Encoder Loss:  0.06887252  || Decoder Loss:  0.20822918 Validation Decoder Loss:  0.39536265
Encoder Loss:  0.061449073  || Decoder Loss:  0.041161414 Validation Decoder Loss:  0.33144057
Encoder Loss:  0.055730466  || Decoder Loss:  0.034344114 Validation Decoder Loss:  0.31293803
Encoder Loss:  0.05450707  || Decoder Loss:  0.032416537 Validation Decoder Loss:  0.32086763
Encoder Loss:  0.053797502  || Decoder Loss:  0.03136987 Validation Decoder Loss:  0.33750972
Encoder Loss:  0.053525817  || Decoder Loss:  0.02978993 Validation Decoder Loss:  0.33515656
Encoder Loss:  0.052247807  || Decoder Loss:  0.030562837 Validation Decoder Loss:  0.33168593
Encoder Loss:  0.052209087  || Decoder Loss:  0.031173231 Validation Decoder Loss:  0.3332464
Encoder Loss:  0.05092202  || Decoder Loss:  0.03133288 Validation Decoder Loss:  0.3338216
Encoder Loss:  0.05136914  || Decoder Loss:  0.032065175 Validation Decoder Loss:  0.33660325
Encoder Loss:  0.05048922  || Decoder Loss:  0.032008756 Validation Decoder Loss:  0.3387178
Encoder Loss:  0.050376426  || Decoder Loss:  0.032092728 Validation Decoder Loss:  0.3406251
Encoder Loss:  0.050262712  || Decoder Loss:  0.03217043 Validation Decoder Loss:  0.34004766
Encoder Loss:  0.051016036  || Decoder Loss:  0.03253449 Validation Decoder Loss:  0.33990908
Encoder Loss:  0.050339833  || Decoder Loss:  0.03190404 Validation Decoder Loss:  0.34042096
Encoder Loss:  0.050575387  || Decoder Loss:  0.032190092 Validation Decoder Loss:  0.34317684
Encoder Loss:  0.05086121  || Decoder Loss:  0.03227846 Validation Decoder Loss:  0.33830506
Encoder Loss:  0.053031925  || Decoder Loss:  0.032835428 Validation Decoder Loss:  0.34080878
Encoder Loss:  0.050113596  || Decoder Loss:  0.0317983 Validation Decoder Loss:  0.34042245
Encoder Loss:  0.050790656  || Decoder Loss:  0.032165565 Validation Decoder Loss:  0.34103897
Encoder Loss:  0.050585248  || Decoder Loss:  0.03204566 Validation Decoder Loss:  0.33996028
Encoder Loss:  0.050421234  || Decoder Loss:  0.03186451 Validation Decoder Loss:  0.34184974
Encoder Loss:  0.050170697  || Decoder Loss:  0.0318528 Validation Decoder Loss:  0.3408484
Encoder Loss:  0.050071202  || Decoder Loss:  0.031947374 Validation Decoder Loss:  0.3425143
Encoder Loss:  0.05157714  || Decoder Loss:  0.032433204 Validation Decoder Loss:  0.34334517
Encoder Loss:  0.05171151  || Decoder Loss:  0.032410458 Validation Decoder Loss:  0.3407731
Encoder Loss:  0.049974516  || Decoder Loss:  0.031583004 Validation Decoder Loss:  0.34166116
Encoder Loss:  0.051343303  || Decoder Loss:  0.032200396 Validation Decoder Loss:  0.34061685
Encoder Loss:  0.050070748  || Decoder Loss:  0.031771675 Validation Decoder Loss:  0.3407508
Encoder Loss:  0.050293464  || Decoder Loss:  0.032229472 Validation Decoder Loss:  0.34040308
Encoder Loss:  0.049979925  || Decoder Loss:  0.03184531 Validation Decoder Loss:  0.341529
Encoder Loss:  0.05023858  || Decoder Loss:  0.031913966 Validation Decoder Loss:  0.3385188
Encoder Loss:  0.05039736  || Decoder Loss:  0.031702396 Validation Decoder Loss:  0.33924055
Encoder Loss:  0.050101094  || Decoder Loss:  0.031677537 Validation Decoder Loss:  0.34091938
Encoder Loss:  0.05120491  || Decoder Loss:  0.032509614 Validation Decoder Loss:  0.3406796
Encoder Loss:  0.049933683  || Decoder Loss:  0.03195189 Validation Decoder Loss:  0.3420287
Encoder Loss:  0.05309681  || Decoder Loss:  0.033491373 Validation Decoder Loss:  0.34076494
Encoder Loss:  0.04992305  || Decoder Loss:  0.03195739 Validation Decoder Loss:  0.3401994
Encoder Loss:  0.050047226  || Decoder Loss:  0.032108117 Validation Decoder Loss:  0.3389681
Model: siamese_net_lr_0.23268622213997833 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3389681
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 127, 10, 20, 1)    385       
_________________________________________________________________
reshape_12 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187045 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187045 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837093  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187052 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187067 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187045 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187045 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187052 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318707 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837093  || Decoder Loss:  0.043187045 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.3265281
Encoder Loss:  0.19837095  || Decoder Loss:  0.04318706 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.32652813
Encoder Loss:  0.19837095  || Decoder Loss:  0.043187056 Validation Decoder Loss:  0.3265281
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3265281
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 127, 10, 20, 1)    129       
_________________________________________________________________
reshape_13 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576113  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798978
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576113  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576111  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576113  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576111  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576111  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576111  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576113  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576111  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576113  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.09319557 Validation Decoder Loss:  0.36798975
Encoder Loss:  0.19576108  || Decoder Loss:  0.093195565 Validation Decoder Loss:  0.36798975
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36798975
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 514, 5, 20, 1)     200       
_________________________________________________________________
reshape_14 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.113973744  || Decoder Loss:  0.04470409 Validation Decoder Loss:  0.32958183
Encoder Loss:  0.059779122  || Decoder Loss:  0.035184547 Validation Decoder Loss:  0.3294981
Encoder Loss:  0.052249715  || Decoder Loss:  0.035910543 Validation Decoder Loss:  0.329674
Encoder Loss:  0.050461315  || Decoder Loss:  0.035752427 Validation Decoder Loss:  0.3293258
Encoder Loss:  0.049857464  || Decoder Loss:  0.03592728 Validation Decoder Loss:  0.33021784
Encoder Loss:  0.047649313  || Decoder Loss:  0.035742577 Validation Decoder Loss:  0.33074126
Encoder Loss:  0.04909274  || Decoder Loss:  0.035691116 Validation Decoder Loss:  0.33078223
Encoder Loss:  0.048429035  || Decoder Loss:  0.03559165 Validation Decoder Loss:  0.3307687
Encoder Loss:  0.047111496  || Decoder Loss:  0.03563615 Validation Decoder Loss:  0.33079535
Encoder Loss:  0.04775773  || Decoder Loss:  0.035662748 Validation Decoder Loss:  0.33121803
Encoder Loss:  0.046877198  || Decoder Loss:  0.03562036 Validation Decoder Loss:  0.3311782
Encoder Loss:  0.04824822  || Decoder Loss:  0.03569238 Validation Decoder Loss:  0.33142155
Encoder Loss:  0.04743643  || Decoder Loss:  0.035709757 Validation Decoder Loss:  0.33145583
Encoder Loss:  0.047503337  || Decoder Loss:  0.035633657 Validation Decoder Loss:  0.33135486
Encoder Loss:  0.04643537  || Decoder Loss:  0.03562355 Validation Decoder Loss:  0.33138493
Encoder Loss:  0.04529398  || Decoder Loss:  0.03557717 Validation Decoder Loss:  0.33132556
Encoder Loss:  0.048256654  || Decoder Loss:  0.035632983 Validation Decoder Loss:  0.33129442
Encoder Loss:  0.04640114  || Decoder Loss:  0.03558272 Validation Decoder Loss:  0.3314488
Encoder Loss:  0.050342277  || Decoder Loss:  0.035675734 Validation Decoder Loss:  0.3314667
Encoder Loss:  0.04640193  || Decoder Loss:  0.03560239 Validation Decoder Loss:  0.3314215
Encoder Loss:  0.0448666  || Decoder Loss:  0.035559732 Validation Decoder Loss:  0.33139205
Encoder Loss:  0.045908634  || Decoder Loss:  0.03555438 Validation Decoder Loss:  0.3312932
Encoder Loss:  0.04529597  || Decoder Loss:  0.035517357 Validation Decoder Loss:  0.33130962
Encoder Loss:  0.046039466  || Decoder Loss:  0.035562795 Validation Decoder Loss:  0.33134472
Encoder Loss:  0.04785522  || Decoder Loss:  0.035561465 Validation Decoder Loss:  0.33134985
Encoder Loss:  0.045474816  || Decoder Loss:  0.035532456 Validation Decoder Loss:  0.33135587
Encoder Loss:  0.04297044  || Decoder Loss:  0.03548241 Validation Decoder Loss:  0.33134064
Encoder Loss:  0.042425446  || Decoder Loss:  0.035431992 Validation Decoder Loss:  0.3313354
Encoder Loss:  0.042522363  || Decoder Loss:  0.035481457 Validation Decoder Loss:  0.331334
Encoder Loss:  0.042493798  || Decoder Loss:  0.03544956 Validation Decoder Loss:  0.33133486
Encoder Loss:  0.042626105  || Decoder Loss:  0.035476156 Validation Decoder Loss:  0.33123925
Encoder Loss:  0.042613626  || Decoder Loss:  0.035421077 Validation Decoder Loss:  0.33125293
Encoder Loss:  0.042520534  || Decoder Loss:  0.035476122 Validation Decoder Loss:  0.33127287
Encoder Loss:  0.04239735  || Decoder Loss:  0.035397425 Validation Decoder Loss:  0.33129966
Encoder Loss:  0.042559348  || Decoder Loss:  0.035470754 Validation Decoder Loss:  0.3313471
Encoder Loss:  0.04249449  || Decoder Loss:  0.035400726 Validation Decoder Loss:  0.33137393
Encoder Loss:  0.04236345  || Decoder Loss:  0.03546477 Validation Decoder Loss:  0.33138797
Encoder Loss:  0.042326275  || Decoder Loss:  0.035392646 Validation Decoder Loss:  0.3313173
Encoder Loss:  0.042534083  || Decoder Loss:  0.035450112 Validation Decoder Loss:  0.33134657
Encoder Loss:  0.042382125  || Decoder Loss:  0.035401553 Validation Decoder Loss:  0.33136237
Model: siamese_net_lr_0.35169655841036807 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33136237
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 257, 10, 20, 1)    1165      
_________________________________________________________________
reshape_15 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,165
Trainable params: 1,165
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29214883  || Decoder Loss:  0.46627894 Validation Decoder Loss:  0.83549976
Encoder Loss:  0.25087225  || Decoder Loss:  0.39785793 Validation Decoder Loss:  0.44363433
Encoder Loss:  0.06719939  || Decoder Loss:  0.072887234 Validation Decoder Loss:  0.32997632
Encoder Loss:  0.05926302  || Decoder Loss:  0.052462947 Validation Decoder Loss:  0.34575927
Encoder Loss:  0.04959796  || Decoder Loss:  0.047157 Validation Decoder Loss:  0.34258294
Encoder Loss:  0.04632842  || Decoder Loss:  0.042994842 Validation Decoder Loss:  0.32742372
Encoder Loss:  0.045328416  || Decoder Loss:  0.041117325 Validation Decoder Loss:  0.3289541
Encoder Loss:  0.044882327  || Decoder Loss:  0.040264934 Validation Decoder Loss:  0.3400584
Encoder Loss:  0.044666193  || Decoder Loss:  0.03973463 Validation Decoder Loss:  0.33969405
Encoder Loss:  0.044758692  || Decoder Loss:  0.039460648 Validation Decoder Loss:  0.33931443
Encoder Loss:  0.04436588  || Decoder Loss:  0.039253287 Validation Decoder Loss:  0.3390404
Encoder Loss:  0.04420408  || Decoder Loss:  0.038874265 Validation Decoder Loss:  0.3298952
Encoder Loss:  0.04428026  || Decoder Loss:  0.038878787 Validation Decoder Loss:  0.33883807
Encoder Loss:  0.043939374  || Decoder Loss:  0.03853066 Validation Decoder Loss:  0.33084708
Encoder Loss:  0.04413523  || Decoder Loss:  0.038449913 Validation Decoder Loss:  0.33633155
Encoder Loss:  0.04511752  || Decoder Loss:  0.039434906 Validation Decoder Loss:  0.3392843
Encoder Loss:  0.04406173  || Decoder Loss:  0.03870147 Validation Decoder Loss:  0.33075356
Encoder Loss:  0.043920618  || Decoder Loss:  0.03841663 Validation Decoder Loss:  0.33820266
Encoder Loss:  0.04369597  || Decoder Loss:  0.038110167 Validation Decoder Loss:  0.33784053
Encoder Loss:  0.045572795  || Decoder Loss:  0.039147772 Validation Decoder Loss:  0.34162843
Encoder Loss:  0.04607587  || Decoder Loss:  0.04063633 Validation Decoder Loss:  0.33915025
Encoder Loss:  0.044032697  || Decoder Loss:  0.038824964 Validation Decoder Loss:  0.33802256
Encoder Loss:  0.04366063  || Decoder Loss:  0.03807515 Validation Decoder Loss:  0.3377176
Encoder Loss:  0.0434791  || Decoder Loss:  0.037770007 Validation Decoder Loss:  0.33752838
Encoder Loss:  0.04494851  || Decoder Loss:  0.038735054 Validation Decoder Loss:  0.3384024
Encoder Loss:  0.04396337  || Decoder Loss:  0.038351938 Validation Decoder Loss:  0.33107102
Encoder Loss:  0.04347044  || Decoder Loss:  0.03777364 Validation Decoder Loss:  0.33783704
Encoder Loss:  0.04338162  || Decoder Loss:  0.037531134 Validation Decoder Loss:  0.33750948
Encoder Loss:  0.043444723  || Decoder Loss:  0.037501115 Validation Decoder Loss:  0.3375324
Encoder Loss:  0.043372937  || Decoder Loss:  0.03741397 Validation Decoder Loss:  0.33735615
Encoder Loss:  0.043506823  || Decoder Loss:  0.037499297 Validation Decoder Loss:  0.3374771
Encoder Loss:  0.043492876  || Decoder Loss:  0.03745543 Validation Decoder Loss:  0.33741528
Encoder Loss:  0.04340487  || Decoder Loss:  0.03740144 Validation Decoder Loss:  0.3376304
Encoder Loss:  0.043277226  || Decoder Loss:  0.03721441 Validation Decoder Loss:  0.3372748
Encoder Loss:  0.043338552  || Decoder Loss:  0.037195336 Validation Decoder Loss:  0.3377965
Encoder Loss:  0.04440497  || Decoder Loss:  0.03807345 Validation Decoder Loss:  0.33767766
Encoder Loss:  0.043560877  || Decoder Loss:  0.037614785 Validation Decoder Loss:  0.33760196
Encoder Loss:  0.043230664  || Decoder Loss:  0.03713258 Validation Decoder Loss:  0.33782548
Encoder Loss:  0.04340935  || Decoder Loss:  0.037180025 Validation Decoder Loss:  0.33783317
Encoder Loss:  0.043252822  || Decoder Loss:  0.037086543 Validation Decoder Loss:  0.33763832
Model: siamese_net_lr_0.5629609402614354 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33763832
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 257, 10, 20, 1)    409       
_________________________________________________________________
reshape_16 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07290524  || Decoder Loss:  0.03820963 Validation Decoder Loss:  0.33062285
Encoder Loss:  0.05361892  || Decoder Loss:  0.036799066 Validation Decoder Loss:  0.3314392
Encoder Loss:  0.0509299  || Decoder Loss:  0.036491096 Validation Decoder Loss:  0.33137387
Encoder Loss:  0.049760405  || Decoder Loss:  0.036149684 Validation Decoder Loss:  0.3312759
Encoder Loss:  0.048813034  || Decoder Loss:  0.036124837 Validation Decoder Loss:  0.33137417
Encoder Loss:  0.048240114  || Decoder Loss:  0.036029022 Validation Decoder Loss:  0.3313293
Encoder Loss:  0.045540582  || Decoder Loss:  0.035729587 Validation Decoder Loss:  0.33147553
Encoder Loss:  0.046994895  || Decoder Loss:  0.03591822 Validation Decoder Loss:  0.33130383
Encoder Loss:  0.051153746  || Decoder Loss:  0.036010757 Validation Decoder Loss:  0.33143985
Encoder Loss:  0.046111085  || Decoder Loss:  0.03585843 Validation Decoder Loss:  0.33138156
Encoder Loss:  0.048385076  || Decoder Loss:  0.03589313 Validation Decoder Loss:  0.33136326
Encoder Loss:  0.04597848  || Decoder Loss:  0.03573021 Validation Decoder Loss:  0.33145452
Encoder Loss:  0.04575324  || Decoder Loss:  0.035718575 Validation Decoder Loss:  0.33136198
Encoder Loss:  0.047867198  || Decoder Loss:  0.035840746 Validation Decoder Loss:  0.3315128
Encoder Loss:  0.04714361  || Decoder Loss:  0.035776213 Validation Decoder Loss:  0.33146852
Encoder Loss:  0.046217624  || Decoder Loss:  0.035716496 Validation Decoder Loss:  0.33144867
Encoder Loss:  0.04589891  || Decoder Loss:  0.035682607 Validation Decoder Loss:  0.33137938
Encoder Loss:  0.045034897  || Decoder Loss:  0.03566006 Validation Decoder Loss:  0.33147007
Encoder Loss:  0.045049578  || Decoder Loss:  0.03563457 Validation Decoder Loss:  0.3313682
Encoder Loss:  0.045957655  || Decoder Loss:  0.03565283 Validation Decoder Loss:  0.33143052
Encoder Loss:  0.045311827  || Decoder Loss:  0.035621732 Validation Decoder Loss:  0.3313632
Encoder Loss:  0.045983486  || Decoder Loss:  0.035631005 Validation Decoder Loss:  0.33146998
Encoder Loss:  0.046426903  || Decoder Loss:  0.03566855 Validation Decoder Loss:  0.33137774
Encoder Loss:  0.045159057  || Decoder Loss:  0.035602514 Validation Decoder Loss:  0.33143994
Encoder Loss:  0.04448013  || Decoder Loss:  0.035555236 Validation Decoder Loss:  0.33138925
Encoder Loss:  0.044380393  || Decoder Loss:  0.03550589 Validation Decoder Loss:  0.3312691
Encoder Loss:  0.045283183  || Decoder Loss:  0.03558825 Validation Decoder Loss:  0.3315332
Encoder Loss:  0.043892007  || Decoder Loss:  0.035481717 Validation Decoder Loss:  0.33145553
Encoder Loss:  0.042925727  || Decoder Loss:  0.035444733 Validation Decoder Loss:  0.33142787
Encoder Loss:  0.042914085  || Decoder Loss:  0.035462692 Validation Decoder Loss:  0.3313464
Encoder Loss:  0.042834498  || Decoder Loss:  0.035434064 Validation Decoder Loss:  0.33134514
Encoder Loss:  0.042755917  || Decoder Loss:  0.03542352 Validation Decoder Loss:  0.33146223
Encoder Loss:  0.04287117  || Decoder Loss:  0.035394754 Validation Decoder Loss:  0.33138338
Encoder Loss:  0.04307018  || Decoder Loss:  0.035420507 Validation Decoder Loss:  0.33137923
Encoder Loss:  0.04271788  || Decoder Loss:  0.03540528 Validation Decoder Loss:  0.33133626
Encoder Loss:  0.042678714  || Decoder Loss:  0.035387658 Validation Decoder Loss:  0.33137855
Encoder Loss:  0.0426751  || Decoder Loss:  0.03538487 Validation Decoder Loss:  0.33134472
Encoder Loss:  0.04274891  || Decoder Loss:  0.03537957 Validation Decoder Loss:  0.33138832
Encoder Loss:  0.042667832  || Decoder Loss:  0.035376366 Validation Decoder Loss:  0.3313331
Encoder Loss:  0.043307707  || Decoder Loss:  0.035434064 Validation Decoder Loss:  0.33147982
Model: siamese_net_lr_0.34081155860503526 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33147985
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 257, 10, 20, 1)    263       
_________________________________________________________________
reshape_17 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15130866  || Decoder Loss:  0.038583316 Validation Decoder Loss:  0.33009934
Encoder Loss:  0.06403291  || Decoder Loss:  0.03518163 Validation Decoder Loss:  0.32991746
Encoder Loss:  0.054403964  || Decoder Loss:  0.035561204 Validation Decoder Loss:  0.32975227
Encoder Loss:  0.045553688  || Decoder Loss:  0.03559756 Validation Decoder Loss:  0.32995987
Encoder Loss:  0.044275824  || Decoder Loss:  0.035503037 Validation Decoder Loss:  0.33017665
Encoder Loss:  0.04436203  || Decoder Loss:  0.03548582 Validation Decoder Loss:  0.3302729
Encoder Loss:  0.044143677  || Decoder Loss:  0.035484128 Validation Decoder Loss:  0.3305148
Encoder Loss:  0.043058433  || Decoder Loss:  0.035408996 Validation Decoder Loss:  0.33065248
Encoder Loss:  0.04319605  || Decoder Loss:  0.035412945 Validation Decoder Loss:  0.33077484
Encoder Loss:  0.04279734  || Decoder Loss:  0.035370838 Validation Decoder Loss:  0.33097047
Encoder Loss:  0.04287485  || Decoder Loss:  0.0353997 Validation Decoder Loss:  0.33110735
Encoder Loss:  0.0429274  || Decoder Loss:  0.035410002 Validation Decoder Loss:  0.33093837
Encoder Loss:  0.04300941  || Decoder Loss:  0.035405133 Validation Decoder Loss:  0.33146572
Encoder Loss:  0.04656115  || Decoder Loss:  0.035702378 Validation Decoder Loss:  0.33135307
Encoder Loss:  0.043056954  || Decoder Loss:  0.035412177 Validation Decoder Loss:  0.3313583
Encoder Loss:  0.042731382  || Decoder Loss:  0.035413787 Validation Decoder Loss:  0.3313066
Encoder Loss:  0.04271858  || Decoder Loss:  0.035394996 Validation Decoder Loss:  0.33129197
Encoder Loss:  0.04358975  || Decoder Loss:  0.035480596 Validation Decoder Loss:  0.33155382
Encoder Loss:  0.054149196  || Decoder Loss:  0.03608194 Validation Decoder Loss:  0.33135897
Encoder Loss:  0.043306038  || Decoder Loss:  0.035450436 Validation Decoder Loss:  0.3312141
Encoder Loss:  0.042731654  || Decoder Loss:  0.035429057 Validation Decoder Loss:  0.3312176
Encoder Loss:  0.042728003  || Decoder Loss:  0.035420727 Validation Decoder Loss:  0.33117136
Encoder Loss:  0.04271868  || Decoder Loss:  0.035398964 Validation Decoder Loss:  0.3312244
Encoder Loss:  0.042721633  || Decoder Loss:  0.03541759 Validation Decoder Loss:  0.3311913
Encoder Loss:  0.042720996  || Decoder Loss:  0.035402708 Validation Decoder Loss:  0.33103314
Encoder Loss:  0.04289062  || Decoder Loss:  0.03541454 Validation Decoder Loss:  0.33118516
Encoder Loss:  0.042930245  || Decoder Loss:  0.03540033 Validation Decoder Loss:  0.33087096
Encoder Loss:  0.05180063  || Decoder Loss:  0.035776455 Validation Decoder Loss:  0.33151805
Encoder Loss:  0.042942382  || Decoder Loss:  0.03542807 Validation Decoder Loss:  0.33130163
Encoder Loss:  0.042710975  || Decoder Loss:  0.035399638 Validation Decoder Loss:  0.33132324
Encoder Loss:  0.042721257  || Decoder Loss:  0.03541006 Validation Decoder Loss:  0.33126172
Encoder Loss:  0.042727515  || Decoder Loss:  0.03539238 Validation Decoder Loss:  0.3311596
Encoder Loss:  0.04272778  || Decoder Loss:  0.03540878 Validation Decoder Loss:  0.3311656
Encoder Loss:  0.042732853  || Decoder Loss:  0.035384525 Validation Decoder Loss:  0.33117053
Encoder Loss:  0.04270944  || Decoder Loss:  0.03536129 Validation Decoder Loss:  0.33119595
Encoder Loss:  0.042860843  || Decoder Loss:  0.03541689 Validation Decoder Loss:  0.33115736
Encoder Loss:  0.044634353  || Decoder Loss:  0.035402525 Validation Decoder Loss:  0.33111566
Encoder Loss:  0.04676896  || Decoder Loss:  0.035534836 Validation Decoder Loss:  0.33125383
Encoder Loss:  0.042727415  || Decoder Loss:  0.035388455 Validation Decoder Loss:  0.33115536
Encoder Loss:  0.042716946  || Decoder Loss:  0.03540713 Validation Decoder Loss:  0.33115417
Model: siamese_net_lr_0.28368697290478895 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33115414
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_18 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07730727  || Decoder Loss:  0.041168027 Validation Decoder Loss:  0.34120423
Encoder Loss:  0.052842226  || Decoder Loss:  0.037732292 Validation Decoder Loss:  0.33999205
Encoder Loss:  0.05058542  || Decoder Loss:  0.036901135 Validation Decoder Loss:  0.34154338
Encoder Loss:  0.04843741  || Decoder Loss:  0.0367422 Validation Decoder Loss:  0.3373323
Encoder Loss:  0.046042595  || Decoder Loss:  0.036247086 Validation Decoder Loss:  0.33830553
Encoder Loss:  0.043723516  || Decoder Loss:  0.035919115 Validation Decoder Loss:  0.33716643
Encoder Loss:  0.04306982  || Decoder Loss:  0.035777137 Validation Decoder Loss:  0.33712018
Encoder Loss:  0.042998925  || Decoder Loss:  0.035749458 Validation Decoder Loss:  0.3370129
Encoder Loss:  0.04294527  || Decoder Loss:  0.035698786 Validation Decoder Loss:  0.33716196
Encoder Loss:  0.04295804  || Decoder Loss:  0.035687145 Validation Decoder Loss:  0.33688265
Encoder Loss:  0.042817164  || Decoder Loss:  0.03564303 Validation Decoder Loss:  0.33667237
Encoder Loss:  0.043422874  || Decoder Loss:  0.03570782 Validation Decoder Loss:  0.33672878
Encoder Loss:  0.0450402  || Decoder Loss:  0.03595974 Validation Decoder Loss:  0.3388929
Encoder Loss:  0.047299877  || Decoder Loss:  0.03643434 Validation Decoder Loss:  0.33677238
Encoder Loss:  0.04290617  || Decoder Loss:  0.035662998 Validation Decoder Loss:  0.33666515
Encoder Loss:  0.04312761  || Decoder Loss:  0.035680927 Validation Decoder Loss:  0.33662617
Encoder Loss:  0.04275196  || Decoder Loss:  0.03561029 Validation Decoder Loss:  0.3365233
Encoder Loss:  0.042852346  || Decoder Loss:  0.03560929 Validation Decoder Loss:  0.3362648
Encoder Loss:  0.042892437  || Decoder Loss:  0.035608552 Validation Decoder Loss:  0.33628935
Encoder Loss:  0.043389507  || Decoder Loss:  0.035686586 Validation Decoder Loss:  0.33648393
Encoder Loss:  0.04296703  || Decoder Loss:  0.03560938 Validation Decoder Loss:  0.33614498
Encoder Loss:  0.04301168  || Decoder Loss:  0.035597812 Validation Decoder Loss:  0.33619398
Encoder Loss:  0.04293374  || Decoder Loss:  0.035585485 Validation Decoder Loss:  0.33616364
Encoder Loss:  0.043093737  || Decoder Loss:  0.035597086 Validation Decoder Loss:  0.33608645
Encoder Loss:  0.04383166  || Decoder Loss:  0.035725325 Validation Decoder Loss:  0.3368562
Encoder Loss:  0.042876408  || Decoder Loss:  0.035579618 Validation Decoder Loss:  0.33590102
Encoder Loss:  0.04274476  || Decoder Loss:  0.035514835 Validation Decoder Loss:  0.33591208
Encoder Loss:  0.045135498  || Decoder Loss:  0.035953213 Validation Decoder Loss:  0.33564886
Encoder Loss:  0.04286638  || Decoder Loss:  0.035531737 Validation Decoder Loss:  0.33596873
Encoder Loss:  0.042984057  || Decoder Loss:  0.035558704 Validation Decoder Loss:  0.3358649
Encoder Loss:  0.04294509  || Decoder Loss:  0.035526905 Validation Decoder Loss:  0.3357275
Encoder Loss:  0.043045145  || Decoder Loss:  0.035542443 Validation Decoder Loss:  0.33583564
Encoder Loss:  0.043069888  || Decoder Loss:  0.035542373 Validation Decoder Loss:  0.3357018
Encoder Loss:  0.043182597  || Decoder Loss:  0.035548832 Validation Decoder Loss:  0.33587533
Encoder Loss:  0.044817716  || Decoder Loss:  0.03580316 Validation Decoder Loss:  0.33574972
Encoder Loss:  0.04270627  || Decoder Loss:  0.035478313 Validation Decoder Loss:  0.33534396
Encoder Loss:  0.04297752  || Decoder Loss:  0.035509557 Validation Decoder Loss:  0.3357492
Encoder Loss:  0.0427656  || Decoder Loss:  0.03547639 Validation Decoder Loss:  0.3352571
Encoder Loss:  0.042720266  || Decoder Loss:  0.035457328 Validation Decoder Loss:  0.3351699
Encoder Loss:  0.04310289  || Decoder Loss:  0.03550166 Validation Decoder Loss:  0.3349298
Model: siamese_net_lr_0.3161360679699891 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33492982
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 514, 5, 20, 1)     11        
_________________________________________________________________
reshape_19 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.064000316  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.03576595 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765957 Validation Decoder Loss:  0.33151
Encoder Loss:  0.06400032  || Decoder Loss:  0.035765953 Validation Decoder Loss:  0.33151
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33151
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 257, 10, 20, 1)    137       
_________________________________________________________________
reshape_20 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687517  || Decoder Loss:  0.035687517 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687514  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.035687506  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03568751  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33044392
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 514, 5, 20, 1)     452       
_________________________________________________________________
reshape_21 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 452
Trainable params: 452
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11250987  || Decoder Loss:  0.11079585 Validation Decoder Loss:  0.34804508
Encoder Loss:  0.05455543  || Decoder Loss:  0.03927571 Validation Decoder Loss:  0.3434553
Encoder Loss:  0.048224993  || Decoder Loss:  0.037721444 Validation Decoder Loss:  0.345214
Encoder Loss:  0.04281407  || Decoder Loss:  0.036265332 Validation Decoder Loss:  0.3435265
Encoder Loss:  0.042765327  || Decoder Loss:  0.03603652 Validation Decoder Loss:  0.34241378
Encoder Loss:  0.04271184  || Decoder Loss:  0.03589308 Validation Decoder Loss:  0.34188855
Encoder Loss:  0.04270443  || Decoder Loss:  0.03583704 Validation Decoder Loss:  0.34121403
Encoder Loss:  0.044132177  || Decoder Loss:  0.036158685 Validation Decoder Loss:  0.34231365
Encoder Loss:  0.046513654  || Decoder Loss:  0.03685383 Validation Decoder Loss:  0.34385422
Encoder Loss:  0.04268691  || Decoder Loss:  0.03583905 Validation Decoder Loss:  0.34083906
Encoder Loss:  0.042584825  || Decoder Loss:  0.035730757 Validation Decoder Loss:  0.34043723
Encoder Loss:  0.04257486  || Decoder Loss:  0.0356871 Validation Decoder Loss:  0.34017986
Encoder Loss:  0.042578932  || Decoder Loss:  0.03567425 Validation Decoder Loss:  0.3399835
Encoder Loss:  0.042523317  || Decoder Loss:  0.035629768 Validation Decoder Loss:  0.33969533
Encoder Loss:  0.04253356  || Decoder Loss:  0.035623144 Validation Decoder Loss:  0.33960944
Encoder Loss:  0.0424451  || Decoder Loss:  0.03558002 Validation Decoder Loss:  0.3394171
Encoder Loss:  0.042827107  || Decoder Loss:  0.035657633 Validation Decoder Loss:  0.33918548
Encoder Loss:  0.042738084  || Decoder Loss:  0.035660937 Validation Decoder Loss:  0.33926532
Encoder Loss:  0.045581322  || Decoder Loss:  0.036307123 Validation Decoder Loss:  0.34945297
Encoder Loss:  0.044105493  || Decoder Loss:  0.036263883 Validation Decoder Loss:  0.33935422
Encoder Loss:  0.042457398  || Decoder Loss:  0.035584766 Validation Decoder Loss:  0.33916724
Encoder Loss:  0.04243362  || Decoder Loss:  0.03554777 Validation Decoder Loss:  0.3390199
Encoder Loss:  0.042472705  || Decoder Loss:  0.035546042 Validation Decoder Loss:  0.33898568
Encoder Loss:  0.042491075  || Decoder Loss:  0.035530373 Validation Decoder Loss:  0.3387313
Encoder Loss:  0.04292428  || Decoder Loss:  0.035602976 Validation Decoder Loss:  0.33926427
Encoder Loss:  0.044492863  || Decoder Loss:  0.03605068 Validation Decoder Loss:  0.3382691
Encoder Loss:  0.043117147  || Decoder Loss:  0.03566304 Validation Decoder Loss:  0.33832842
Encoder Loss:  0.042431474  || Decoder Loss:  0.035499748 Validation Decoder Loss:  0.33819613
Encoder Loss:  0.0428611  || Decoder Loss:  0.03558873 Validation Decoder Loss:  0.33828148
Encoder Loss:  0.042435378  || Decoder Loss:  0.035469968 Validation Decoder Loss:  0.33865166
Encoder Loss:  0.04335827  || Decoder Loss:  0.03567101 Validation Decoder Loss:  0.33854944
Encoder Loss:  0.042588048  || Decoder Loss:  0.035503563 Validation Decoder Loss:  0.3380744
Encoder Loss:  0.04252488  || Decoder Loss:  0.03546684 Validation Decoder Loss:  0.3381191
Encoder Loss:  0.042400178  || Decoder Loss:  0.03543458 Validation Decoder Loss:  0.33798936
Encoder Loss:  0.04244776  || Decoder Loss:  0.03543013 Validation Decoder Loss:  0.33801365
Encoder Loss:  0.042648964  || Decoder Loss:  0.03548429 Validation Decoder Loss:  0.3379112
Encoder Loss:  0.042815804  || Decoder Loss:  0.035492558 Validation Decoder Loss:  0.3375366
Encoder Loss:  0.042540833  || Decoder Loss:  0.0354177 Validation Decoder Loss:  0.3379661
Encoder Loss:  0.043522183  || Decoder Loss:  0.035609648 Validation Decoder Loss:  0.33685362
Encoder Loss:  0.04243146  || Decoder Loss:  0.03539959 Validation Decoder Loss:  0.3375234
Model: siamese_net_lr_0.22537101484017014 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33752343
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_22 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.038539916  || Decoder Loss:  0.035793 Validation Decoder Loss:  0.33072418
Encoder Loss:  0.035897244  || Decoder Loss:  0.035300653 Validation Decoder Loss:  0.33127463
Encoder Loss:  0.03585441  || Decoder Loss:  0.035278607 Validation Decoder Loss:  0.33114687
Encoder Loss:  0.035870623  || Decoder Loss:  0.035289396 Validation Decoder Loss:  0.33146977
Encoder Loss:  0.03583337  || Decoder Loss:  0.035295073 Validation Decoder Loss:  0.3317991
Encoder Loss:  0.035815336  || Decoder Loss:  0.035298493 Validation Decoder Loss:  0.33196455
Encoder Loss:  0.035879258  || Decoder Loss:  0.035304062 Validation Decoder Loss:  0.33247268
Encoder Loss:  0.035900883  || Decoder Loss:  0.03531964 Validation Decoder Loss:  0.33387613
Encoder Loss:  0.035798967  || Decoder Loss:  0.035317495 Validation Decoder Loss:  0.33343726
Encoder Loss:  0.035806667  || Decoder Loss:  0.035316598 Validation Decoder Loss:  0.3335107
Encoder Loss:  0.03581505  || Decoder Loss:  0.0353221 Validation Decoder Loss:  0.3335427
Encoder Loss:  0.035820693  || Decoder Loss:  0.035315305 Validation Decoder Loss:  0.33388802
Encoder Loss:  0.035778318  || Decoder Loss:  0.035312846 Validation Decoder Loss:  0.3338721
Encoder Loss:  0.035788458  || Decoder Loss:  0.035318684 Validation Decoder Loss:  0.33431756
Encoder Loss:  0.03577577  || Decoder Loss:  0.03531749 Validation Decoder Loss:  0.33604783
Encoder Loss:  0.03577096  || Decoder Loss:  0.03531142 Validation Decoder Loss:  0.33573076
Encoder Loss:  0.035777718  || Decoder Loss:  0.035307884 Validation Decoder Loss:  0.33565006
Encoder Loss:  0.03588427  || Decoder Loss:  0.035317037 Validation Decoder Loss:  0.33622852
Encoder Loss:  0.03575933  || Decoder Loss:  0.035295933 Validation Decoder Loss:  0.33592072
Encoder Loss:  0.03575838  || Decoder Loss:  0.035287436 Validation Decoder Loss:  0.33602816
Encoder Loss:  0.035747696  || Decoder Loss:  0.03528128 Validation Decoder Loss:  0.3359524
Encoder Loss:  0.035771865  || Decoder Loss:  0.0352819 Validation Decoder Loss:  0.33602563
Encoder Loss:  0.035730604  || Decoder Loss:  0.03527549 Validation Decoder Loss:  0.33587873
Encoder Loss:  0.035730384  || Decoder Loss:  0.03527225 Validation Decoder Loss:  0.33582097
Encoder Loss:  0.03572361  || Decoder Loss:  0.035268337 Validation Decoder Loss:  0.33572876
Encoder Loss:  0.035722975  || Decoder Loss:  0.035266694 Validation Decoder Loss:  0.33570966
Encoder Loss:  0.035719994  || Decoder Loss:  0.035261653 Validation Decoder Loss:  0.33572453
Encoder Loss:  0.03573818  || Decoder Loss:  0.035260126 Validation Decoder Loss:  0.3357873
Encoder Loss:  0.0357167  || Decoder Loss:  0.035263825 Validation Decoder Loss:  0.33562374
Encoder Loss:  0.035729613  || Decoder Loss:  0.03525959 Validation Decoder Loss:  0.33576918
Encoder Loss:  0.03583044  || Decoder Loss:  0.035278667 Validation Decoder Loss:  0.3361994
Encoder Loss:  0.035794478  || Decoder Loss:  0.03527852 Validation Decoder Loss:  0.33591056
Encoder Loss:  0.03571934  || Decoder Loss:  0.035266686 Validation Decoder Loss:  0.33569148
Encoder Loss:  0.035717916  || Decoder Loss:  0.03526557 Validation Decoder Loss:  0.3355598
Encoder Loss:  0.035720944  || Decoder Loss:  0.03526352 Validation Decoder Loss:  0.33544123
Encoder Loss:  0.035723764  || Decoder Loss:  0.035264865 Validation Decoder Loss:  0.33541772
Encoder Loss:  0.03572197  || Decoder Loss:  0.035263125 Validation Decoder Loss:  0.33542937
Encoder Loss:  0.03572547  || Decoder Loss:  0.03526307 Validation Decoder Loss:  0.335401
Encoder Loss:  0.03575741  || Decoder Loss:  0.03526417 Validation Decoder Loss:  0.33541554
Encoder Loss:  0.03571679  || Decoder Loss:  0.035261523 Validation Decoder Loss:  0.33538532
Model: siamese_net_lr_0.02356598156727797 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3353853
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 514, 5, 20, 1)     200       
_________________________________________________________________
reshape_23 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.041839346  || Decoder Loss:  0.03561832 Validation Decoder Loss:  0.33366388
Encoder Loss:  0.037355516  || Decoder Loss:  0.035160944 Validation Decoder Loss:  0.33742845
Encoder Loss:  0.03703892  || Decoder Loss:  0.03498983 Validation Decoder Loss:  0.33633077
Encoder Loss:  0.03678288  || Decoder Loss:  0.03481552 Validation Decoder Loss:  0.3383291
Encoder Loss:  0.035911623  || Decoder Loss:  0.03468614 Validation Decoder Loss:  0.33788443
Encoder Loss:  0.035579644  || Decoder Loss:  0.03455366 Validation Decoder Loss:  0.3389573
Encoder Loss:  0.03562026  || Decoder Loss:  0.034579094 Validation Decoder Loss:  0.33710492
Encoder Loss:  0.035674762  || Decoder Loss:  0.034744166 Validation Decoder Loss:  0.33569473
Encoder Loss:  0.03569295  || Decoder Loss:  0.03478319 Validation Decoder Loss:  0.3355233
Encoder Loss:  0.03572725  || Decoder Loss:  0.034814056 Validation Decoder Loss:  0.33524054
Encoder Loss:  0.035731778  || Decoder Loss:  0.0348342 Validation Decoder Loss:  0.33568
Encoder Loss:  0.03576  || Decoder Loss:  0.03486646 Validation Decoder Loss:  0.33581844
Encoder Loss:  0.03577589  || Decoder Loss:  0.034883924 Validation Decoder Loss:  0.33588558
Encoder Loss:  0.035798036  || Decoder Loss:  0.0349005 Validation Decoder Loss:  0.33643234
Encoder Loss:  0.035821307  || Decoder Loss:  0.034939207 Validation Decoder Loss:  0.33677018
Encoder Loss:  0.035835475  || Decoder Loss:  0.03494893 Validation Decoder Loss:  0.33690667
Encoder Loss:  0.03585471  || Decoder Loss:  0.03496916 Validation Decoder Loss:  0.336955
Encoder Loss:  0.03644603  || Decoder Loss:  0.03497249 Validation Decoder Loss:  0.3366708
Encoder Loss:  0.0360094  || Decoder Loss:  0.034966215 Validation Decoder Loss:  0.33722088
Encoder Loss:  0.035837077  || Decoder Loss:  0.034963716 Validation Decoder Loss:  0.337106
Encoder Loss:  0.03585509  || Decoder Loss:  0.034979526 Validation Decoder Loss:  0.33715653
Encoder Loss:  0.035874423  || Decoder Loss:  0.035000946 Validation Decoder Loss:  0.33708808
Encoder Loss:  0.035895832  || Decoder Loss:  0.03502499 Validation Decoder Loss:  0.33704978
Encoder Loss:  0.035921454  || Decoder Loss:  0.03505014 Validation Decoder Loss:  0.33681262
Encoder Loss:  0.035914525  || Decoder Loss:  0.035040833 Validation Decoder Loss:  0.3371418
Encoder Loss:  0.03590789  || Decoder Loss:  0.035031453 Validation Decoder Loss:  0.3369986
Encoder Loss:  0.036176454  || Decoder Loss:  0.035135865 Validation Decoder Loss:  0.33615997
Encoder Loss:  0.036394626  || Decoder Loss:  0.035157703 Validation Decoder Loss:  0.3358299
Encoder Loss:  0.036040284  || Decoder Loss:  0.035184037 Validation Decoder Loss:  0.33545673
Encoder Loss:  0.03603924  || Decoder Loss:  0.035179295 Validation Decoder Loss:  0.33559072
Encoder Loss:  0.036040768  || Decoder Loss:  0.035181668 Validation Decoder Loss:  0.33553958
Encoder Loss:  0.03604606  || Decoder Loss:  0.035184685 Validation Decoder Loss:  0.33543637
Encoder Loss:  0.03604396  || Decoder Loss:  0.035172302 Validation Decoder Loss:  0.33572698
Encoder Loss:  0.036063388  || Decoder Loss:  0.03519154 Validation Decoder Loss:  0.3354191
Encoder Loss:  0.036084708  || Decoder Loss:  0.035145815 Validation Decoder Loss:  0.33613575
Encoder Loss:  0.03596818  || Decoder Loss:  0.03509932 Validation Decoder Loss:  0.33640146
Encoder Loss:  0.035991263  || Decoder Loss:  0.03512857 Validation Decoder Loss:  0.33591112
Encoder Loss:  0.03602248  || Decoder Loss:  0.035152692 Validation Decoder Loss:  0.3360495
Encoder Loss:  0.036012337  || Decoder Loss:  0.035135027 Validation Decoder Loss:  0.33598423
Encoder Loss:  0.036101867  || Decoder Loss:  0.035179347 Validation Decoder Loss:  0.33569777
Model: siamese_net_lr_0.12936048607568493 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33569777
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 514, 5, 20, 1)     263       
_________________________________________________________________
reshape_24 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09918603  || Decoder Loss:  0.036863886 Validation Decoder Loss:  0.3298956
Encoder Loss:  0.06743441  || Decoder Loss:  0.0378776 Validation Decoder Loss:  0.32955378
Encoder Loss:  0.06243955  || Decoder Loss:  0.03524094 Validation Decoder Loss:  0.33014318
Encoder Loss:  0.058126632  || Decoder Loss:  0.035264086 Validation Decoder Loss:  0.3307603
Encoder Loss:  0.052436404  || Decoder Loss:  0.03526927 Validation Decoder Loss:  0.33131367
Encoder Loss:  0.048411757  || Decoder Loss:  0.035365272 Validation Decoder Loss:  0.33308184
Encoder Loss:  0.05138081  || Decoder Loss:  0.03569335 Validation Decoder Loss:  0.33325148
Encoder Loss:  0.044957384  || Decoder Loss:  0.035454735 Validation Decoder Loss:  0.33332175
Encoder Loss:  0.04258781  || Decoder Loss:  0.03543972 Validation Decoder Loss:  0.3331446
Encoder Loss:  0.042427205  || Decoder Loss:  0.035378933 Validation Decoder Loss:  0.33328223
Encoder Loss:  0.042459562  || Decoder Loss:  0.035435986 Validation Decoder Loss:  0.3333456
Encoder Loss:  0.043268908  || Decoder Loss:  0.035403863 Validation Decoder Loss:  0.333374
Encoder Loss:  0.042480983  || Decoder Loss:  0.035428904 Validation Decoder Loss:  0.33345377
Encoder Loss:  0.042524613  || Decoder Loss:  0.035363056 Validation Decoder Loss:  0.3334045
Encoder Loss:  0.042547513  || Decoder Loss:  0.035422545 Validation Decoder Loss:  0.33352494
Encoder Loss:  0.042410027  || Decoder Loss:  0.03535711 Validation Decoder Loss:  0.33356142
Encoder Loss:  0.04253795  || Decoder Loss:  0.03541884 Validation Decoder Loss:  0.3334435
Encoder Loss:  0.042918235  || Decoder Loss:  0.035398524 Validation Decoder Loss:  0.33349842
Encoder Loss:  0.044269815  || Decoder Loss:  0.035472278 Validation Decoder Loss:  0.33342618
Encoder Loss:  0.04318098  || Decoder Loss:  0.035495605 Validation Decoder Loss:  0.3337139
Encoder Loss:  0.042394143  || Decoder Loss:  0.03534863 Validation Decoder Loss:  0.33345857
Encoder Loss:  0.042427626  || Decoder Loss:  0.035426322 Validation Decoder Loss:  0.3337131
Encoder Loss:  0.042511128  || Decoder Loss:  0.035351258 Validation Decoder Loss:  0.3335596
Encoder Loss:  0.042457405  || Decoder Loss:  0.035388075 Validation Decoder Loss:  0.33338177
Encoder Loss:  0.042445187  || Decoder Loss:  0.035429474 Validation Decoder Loss:  0.3335172
Encoder Loss:  0.042960957  || Decoder Loss:  0.03537531 Validation Decoder Loss:  0.33295926
Encoder Loss:  0.04582883  || Decoder Loss:  0.035598658 Validation Decoder Loss:  0.33347532
Encoder Loss:  0.042936735  || Decoder Loss:  0.03543274 Validation Decoder Loss:  0.33407307
Encoder Loss:  0.042382292  || Decoder Loss:  0.035388336 Validation Decoder Loss:  0.3340457
Encoder Loss:  0.04238897  || Decoder Loss:  0.035423674 Validation Decoder Loss:  0.33425534
Encoder Loss:  0.04236321  || Decoder Loss:  0.035354003 Validation Decoder Loss:  0.33408815
Encoder Loss:  0.042429205  || Decoder Loss:  0.03538528 Validation Decoder Loss:  0.3343481
Encoder Loss:  0.04242882  || Decoder Loss:  0.035416972 Validation Decoder Loss:  0.33437306
Encoder Loss:  0.042496644  || Decoder Loss:  0.03535626 Validation Decoder Loss:  0.33405578
Encoder Loss:  0.04420761  || Decoder Loss:  0.035490718 Validation Decoder Loss:  0.3343066
Encoder Loss:  0.043461937  || Decoder Loss:  0.035486583 Validation Decoder Loss:  0.33466846
Encoder Loss:  0.042537965  || Decoder Loss:  0.035348777 Validation Decoder Loss:  0.33453417
Encoder Loss:  0.042452186  || Decoder Loss:  0.035395723 Validation Decoder Loss:  0.3347385
Encoder Loss:  0.042705104  || Decoder Loss:  0.03535922 Validation Decoder Loss:  0.3346105
Encoder Loss:  0.042430572  || Decoder Loss:  0.0354037 Validation Decoder Loss:  0.33439723
Model: siamese_net_lr_0.36955099368779304 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3343972
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 514, 5, 20, 1)     11        
_________________________________________________________________
reshape_25 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.048556246  || Decoder Loss:  0.03539096 Validation Decoder Loss:  0.33155507
Encoder Loss:  0.03874334  || Decoder Loss:  0.035229936 Validation Decoder Loss:  0.33026123
Encoder Loss:  0.037635244  || Decoder Loss:  0.035075832 Validation Decoder Loss:  0.3303352
Encoder Loss:  0.037696365  || Decoder Loss:  0.03513221 Validation Decoder Loss:  0.33078367
Encoder Loss:  0.038628586  || Decoder Loss:  0.035180993 Validation Decoder Loss:  0.33145532
Encoder Loss:  0.037955333  || Decoder Loss:  0.035117645 Validation Decoder Loss:  0.33147287
Encoder Loss:  0.037638858  || Decoder Loss:  0.035154365 Validation Decoder Loss:  0.33151615
Encoder Loss:  0.03756188  || Decoder Loss:  0.035173547 Validation Decoder Loss:  0.33156008
Encoder Loss:  0.037098467  || Decoder Loss:  0.03520403 Validation Decoder Loss:  0.33162266
Encoder Loss:  0.03713222  || Decoder Loss:  0.03526057 Validation Decoder Loss:  0.3315084
Encoder Loss:  0.037077498  || Decoder Loss:  0.035294153 Validation Decoder Loss:  0.33169168
Encoder Loss:  0.037459753  || Decoder Loss:  0.035285905 Validation Decoder Loss:  0.3314464
Encoder Loss:  0.036794674  || Decoder Loss:  0.035276573 Validation Decoder Loss:  0.3313407
Encoder Loss:  0.03635686  || Decoder Loss:  0.03527344 Validation Decoder Loss:  0.33144006
Encoder Loss:  0.03645616  || Decoder Loss:  0.035277642 Validation Decoder Loss:  0.33132005
Encoder Loss:  0.036502026  || Decoder Loss:  0.035278954 Validation Decoder Loss:  0.33141255
Encoder Loss:  0.036344312  || Decoder Loss:  0.03527651 Validation Decoder Loss:  0.33131903
Encoder Loss:  0.036413357  || Decoder Loss:  0.03527591 Validation Decoder Loss:  0.33129233
Encoder Loss:  0.03637397  || Decoder Loss:  0.035277966 Validation Decoder Loss:  0.33134043
Encoder Loss:  0.036275007  || Decoder Loss:  0.035277117 Validation Decoder Loss:  0.33134055
Encoder Loss:  0.036271576  || Decoder Loss:  0.035276752 Validation Decoder Loss:  0.33137587
Encoder Loss:  0.036255553  || Decoder Loss:  0.035276264 Validation Decoder Loss:  0.33139294
Encoder Loss:  0.036279727  || Decoder Loss:  0.035278257 Validation Decoder Loss:  0.33138153
Encoder Loss:  0.036252744  || Decoder Loss:  0.035277747 Validation Decoder Loss:  0.33138907
Encoder Loss:  0.036270164  || Decoder Loss:  0.03527841 Validation Decoder Loss:  0.33137733
Encoder Loss:  0.036258765  || Decoder Loss:  0.035278186 Validation Decoder Loss:  0.3313446
Encoder Loss:  0.03625541  || Decoder Loss:  0.035279024 Validation Decoder Loss:  0.3313515
Encoder Loss:  0.03624997  || Decoder Loss:  0.03527892 Validation Decoder Loss:  0.3313731
Encoder Loss:  0.036279485  || Decoder Loss:  0.0352789 Validation Decoder Loss:  0.33137035
Encoder Loss:  0.036268264  || Decoder Loss:  0.03527868 Validation Decoder Loss:  0.3313614
Encoder Loss:  0.036260594  || Decoder Loss:  0.0352796 Validation Decoder Loss:  0.33136973
Encoder Loss:  0.036248714  || Decoder Loss:  0.035280224 Validation Decoder Loss:  0.33136725
Encoder Loss:  0.036300153  || Decoder Loss:  0.03527898 Validation Decoder Loss:  0.33133
Encoder Loss:  0.036332626  || Decoder Loss:  0.03528172 Validation Decoder Loss:  0.33135107
Encoder Loss:  0.036271974  || Decoder Loss:  0.03528091 Validation Decoder Loss:  0.33140013
Encoder Loss:  0.036315806  || Decoder Loss:  0.035281543 Validation Decoder Loss:  0.33138928
Encoder Loss:  0.0362998  || Decoder Loss:  0.035281226 Validation Decoder Loss:  0.33135283
Encoder Loss:  0.03635989  || Decoder Loss:  0.035282064 Validation Decoder Loss:  0.33139223
Encoder Loss:  0.036348935  || Decoder Loss:  0.035281584 Validation Decoder Loss:  0.3313592
Encoder Loss:  0.036322497  || Decoder Loss:  0.035282955 Validation Decoder Loss:  0.33137628
Model: siamese_net_lr_0.00932836520843693 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33137628
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 257, 10, 20, 1)    1165      
_________________________________________________________________
reshape_26 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,165
Trainable params: 1,165
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.055164248  || Decoder Loss:  0.050585795 Validation Decoder Loss:  0.33477038
Encoder Loss:  0.038729325  || Decoder Loss:  0.03716663 Validation Decoder Loss:  0.3304481
Encoder Loss:  0.03788515  || Decoder Loss:  0.036410805 Validation Decoder Loss:  0.3311206
Encoder Loss:  0.03767784  || Decoder Loss:  0.03617209 Validation Decoder Loss:  0.33168417
Encoder Loss:  0.038236298  || Decoder Loss:  0.03663385 Validation Decoder Loss:  0.3309099
Encoder Loss:  0.037875835  || Decoder Loss:  0.036310483 Validation Decoder Loss:  0.33119473
Encoder Loss:  0.037848864  || Decoder Loss:  0.03626679 Validation Decoder Loss:  0.33140814
Encoder Loss:  0.03944002  || Decoder Loss:  0.037445866 Validation Decoder Loss:  0.3309099
Encoder Loss:  0.03967747  || Decoder Loss:  0.037715916 Validation Decoder Loss:  0.33469775
Encoder Loss:  0.037565805  || Decoder Loss:  0.036094222 Validation Decoder Loss:  0.3315479
Encoder Loss:  0.03741462  || Decoder Loss:  0.035924338 Validation Decoder Loss:  0.33123907
Encoder Loss:  0.037376493  || Decoder Loss:  0.035889436 Validation Decoder Loss:  0.33135635
Encoder Loss:  0.03739176  || Decoder Loss:  0.03588826 Validation Decoder Loss:  0.33138573
Encoder Loss:  0.037348002  || Decoder Loss:  0.03585217 Validation Decoder Loss:  0.3316025
Encoder Loss:  0.037424315  || Decoder Loss:  0.03589596 Validation Decoder Loss:  0.3313855
Encoder Loss:  0.037669588  || Decoder Loss:  0.036091965 Validation Decoder Loss:  0.33176133
Encoder Loss:  0.03730535  || Decoder Loss:  0.03580585 Validation Decoder Loss:  0.33203995
Encoder Loss:  0.037335895  || Decoder Loss:  0.03582255 Validation Decoder Loss:  0.33235317
Encoder Loss:  0.037310112  || Decoder Loss:  0.035801053 Validation Decoder Loss:  0.3322918
Encoder Loss:  0.038173426  || Decoder Loss:  0.03644575 Validation Decoder Loss:  0.331584
Encoder Loss:  0.03735449  || Decoder Loss:  0.035830032 Validation Decoder Loss:  0.33233318
Encoder Loss:  0.037448343  || Decoder Loss:  0.03588579 Validation Decoder Loss:  0.33196032
Encoder Loss:  0.03725047  || Decoder Loss:  0.035744388 Validation Decoder Loss:  0.33221954
Encoder Loss:  0.03741455  || Decoder Loss:  0.035862118 Validation Decoder Loss:  0.33199477
Encoder Loss:  0.037227165  || Decoder Loss:  0.035715304 Validation Decoder Loss:  0.3320088
Encoder Loss:  0.03722824  || Decoder Loss:  0.035715796 Validation Decoder Loss:  0.33189332
Encoder Loss:  0.037285913  || Decoder Loss:  0.035714623 Validation Decoder Loss:  0.33638227
Encoder Loss:  0.037421778  || Decoder Loss:  0.035887416 Validation Decoder Loss:  0.33364174
Encoder Loss:  0.03724393  || Decoder Loss:  0.035680104 Validation Decoder Loss:  0.3356497
Encoder Loss:  0.03729812  || Decoder Loss:  0.035778627 Validation Decoder Loss:  0.33306295
Encoder Loss:  0.03715305  || Decoder Loss:  0.03562576 Validation Decoder Loss:  0.33151516
Encoder Loss:  0.037136294  || Decoder Loss:  0.03562352 Validation Decoder Loss:  0.3356848
Encoder Loss:  0.03720872  || Decoder Loss:  0.03567164 Validation Decoder Loss:  0.33524442
Encoder Loss:  0.037591837  || Decoder Loss:  0.03592234 Validation Decoder Loss:  0.33403552
Encoder Loss:  0.037347812  || Decoder Loss:  0.035754047 Validation Decoder Loss:  0.33415687
Encoder Loss:  0.037131265  || Decoder Loss:  0.03559269 Validation Decoder Loss:  0.33513504
Encoder Loss:  0.037117697  || Decoder Loss:  0.035599586 Validation Decoder Loss:  0.3349961
Encoder Loss:  0.03714502  || Decoder Loss:  0.03560535 Validation Decoder Loss:  0.33508876
Encoder Loss:  0.037112974  || Decoder Loss:  0.035582922 Validation Decoder Loss:  0.3349728
Encoder Loss:  0.037137017  || Decoder Loss:  0.035596572 Validation Decoder Loss:  0.3349482
Model: siamese_net_lr_0.1338462685328862 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3349482
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_27 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32673985
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 257, 10, 20, 1)    137       
_________________________________________________________________
reshape_28 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687517 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687517 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.03568752 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481423  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481423  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687506 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481423  || Decoder Loss:  0.035687517 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687517 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481435  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481423  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481423  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748144  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.03748143  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.035687514 Validation Decoder Loss:  0.33044392
Encoder Loss:  0.037481427  || Decoder Loss:  0.03568751 Validation Decoder Loss:  0.33044392
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33044392
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 514, 5, 20, 1)     389       
_________________________________________________________________
reshape_29 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621196  || Decoder Loss:  0.03621196 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.03621195  || Decoder Loss:  0.03621195 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211956  || Decoder Loss:  0.036211956 Validation Decoder Loss:  0.33008236
Encoder Loss:  0.036211953  || Decoder Loss:  0.036211953 Validation Decoder Loss:  0.33008233
Encoder Loss:  0.036211964  || Decoder Loss:  0.036211964 Validation Decoder Loss:  0.33008233
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33008236
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 514, 5, 20, 1)     389       
_________________________________________________________________
reshape_30 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15361205  || Decoder Loss:  0.17971358 Validation Decoder Loss:  0.32940948
Encoder Loss:  0.051723424  || Decoder Loss:  0.040611945 Validation Decoder Loss:  0.33630416
Encoder Loss:  0.045449287  || Decoder Loss:  0.03837883 Validation Decoder Loss:  0.3385219
Encoder Loss:  0.043762293  || Decoder Loss:  0.037155375 Validation Decoder Loss:  0.33936742
Encoder Loss:  0.04492105  || Decoder Loss:  0.03731636 Validation Decoder Loss:  0.33944154
Encoder Loss:  0.04351734  || Decoder Loss:  0.036667027 Validation Decoder Loss:  0.34011722
Encoder Loss:  0.04374307  || Decoder Loss:  0.03657569 Validation Decoder Loss:  0.34004474
Encoder Loss:  0.05617695  || Decoder Loss:  0.041424293 Validation Decoder Loss:  0.3455232
Encoder Loss:  0.052601896  || Decoder Loss:  0.0412123 Validation Decoder Loss:  0.33905748
Encoder Loss:  0.043907747  || Decoder Loss:  0.037496034 Validation Decoder Loss:  0.3393214
Encoder Loss:  0.04352149  || Decoder Loss:  0.036800306 Validation Decoder Loss:  0.34012127
Encoder Loss:  0.043416604  || Decoder Loss:  0.0366096 Validation Decoder Loss:  0.3402471
Encoder Loss:  0.043406352  || Decoder Loss:  0.036514398 Validation Decoder Loss:  0.3405506
Encoder Loss:  0.04342766  || Decoder Loss:  0.036482926 Validation Decoder Loss:  0.34017944
Encoder Loss:  0.043768927  || Decoder Loss:  0.03657268 Validation Decoder Loss:  0.3397924
Encoder Loss:  0.043537315  || Decoder Loss:  0.036469292 Validation Decoder Loss:  0.33976343
Encoder Loss:  0.043329194  || Decoder Loss:  0.036345113 Validation Decoder Loss:  0.33946243
Encoder Loss:  0.04350142  || Decoder Loss:  0.036314964 Validation Decoder Loss:  0.34015238
Encoder Loss:  0.043498673  || Decoder Loss:  0.036360975 Validation Decoder Loss:  0.33965302
Encoder Loss:  0.043509673  || Decoder Loss:  0.036311273 Validation Decoder Loss:  0.33975238
Encoder Loss:  0.04524751  || Decoder Loss:  0.037072238 Validation Decoder Loss:  0.33976853
Encoder Loss:  0.043813813  || Decoder Loss:  0.03648037 Validation Decoder Loss:  0.33956647
Encoder Loss:  0.043565847  || Decoder Loss:  0.036383335 Validation Decoder Loss:  0.3392651
Encoder Loss:  0.04359733  || Decoder Loss:  0.03630311 Validation Decoder Loss:  0.3392732
Encoder Loss:  0.043381408  || Decoder Loss:  0.036184408 Validation Decoder Loss:  0.33878234
Encoder Loss:  0.04318684  || Decoder Loss:  0.036096275 Validation Decoder Loss:  0.33834165
Encoder Loss:  0.043592423  || Decoder Loss:  0.03620225 Validation Decoder Loss:  0.33861527
Encoder Loss:  0.043530818  || Decoder Loss:  0.036197674 Validation Decoder Loss:  0.33840013
Encoder Loss:  0.043149266  || Decoder Loss:  0.03600733 Validation Decoder Loss:  0.33767915
Encoder Loss:  0.043759853  || Decoder Loss:  0.03616667 Validation Decoder Loss:  0.33842504
Encoder Loss:  0.047720533  || Decoder Loss:  0.03777852 Validation Decoder Loss:  0.33861977
Encoder Loss:  0.04323532  || Decoder Loss:  0.03615264 Validation Decoder Loss:  0.33817178
Encoder Loss:  0.043109365  || Decoder Loss:  0.03597816 Validation Decoder Loss:  0.33753055
Encoder Loss:  0.043269824  || Decoder Loss:  0.03597832 Validation Decoder Loss:  0.33755147
Encoder Loss:  0.043296658  || Decoder Loss:  0.035989024 Validation Decoder Loss:  0.33737782
Encoder Loss:  0.043235883  || Decoder Loss:  0.035934433 Validation Decoder Loss:  0.33696836
Encoder Loss:  0.04383702  || Decoder Loss:  0.036145464 Validation Decoder Loss:  0.33757594
Encoder Loss:  0.043833613  || Decoder Loss:  0.036110073 Validation Decoder Loss:  0.33767748
Encoder Loss:  0.043123282  || Decoder Loss:  0.03591207 Validation Decoder Loss:  0.3369497
Encoder Loss:  0.043129172  || Decoder Loss:  0.035848863 Validation Decoder Loss:  0.33675057
Model: siamese_net_lr_0.4132265115155753 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33675057
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 514, 5, 20, 1)     74        
_________________________________________________________________
reshape_31 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.034896623  || Decoder Loss:  0.034896623 Validation Decoder Loss:  0.32966465
Encoder Loss:  0.034770574  || Decoder Loss:  0.034770574 Validation Decoder Loss:  0.32962883
Encoder Loss:  0.034735598  || Decoder Loss:  0.034735598 Validation Decoder Loss:  0.32967186
Encoder Loss:  0.034713566  || Decoder Loss:  0.034713566 Validation Decoder Loss:  0.3297361
Encoder Loss:  0.034698736  || Decoder Loss:  0.034698736 Validation Decoder Loss:  0.32979688
Encoder Loss:  0.034688294  || Decoder Loss:  0.034688294 Validation Decoder Loss:  0.32984757
Encoder Loss:  0.034680612  || Decoder Loss:  0.034680612 Validation Decoder Loss:  0.32988834
Encoder Loss:  0.034674764  || Decoder Loss:  0.034674764 Validation Decoder Loss:  0.3299212
Encoder Loss:  0.034670196  || Decoder Loss:  0.034670196 Validation Decoder Loss:  0.32994795
Encoder Loss:  0.03466649  || Decoder Loss:  0.03466649 Validation Decoder Loss:  0.3299703
Encoder Loss:  0.034663446  || Decoder Loss:  0.034663446 Validation Decoder Loss:  0.3299894
Encoder Loss:  0.034660887  || Decoder Loss:  0.034660887 Validation Decoder Loss:  0.33000612
Encoder Loss:  0.034658644  || Decoder Loss:  0.034658644 Validation Decoder Loss:  0.33002096
Encoder Loss:  0.034656744  || Decoder Loss:  0.034656744 Validation Decoder Loss:  0.3300344
Encoder Loss:  0.034655046  || Decoder Loss:  0.034655046 Validation Decoder Loss:  0.33004674
Encoder Loss:  0.034653526  || Decoder Loss:  0.034653526 Validation Decoder Loss:  0.33005816
Encoder Loss:  0.03465213  || Decoder Loss:  0.03465213 Validation Decoder Loss:  0.33006886
Encoder Loss:  0.034650885  || Decoder Loss:  0.034650885 Validation Decoder Loss:  0.3300789
Encoder Loss:  0.03464973  || Decoder Loss:  0.03464973 Validation Decoder Loss:  0.33008838
Encoder Loss:  0.034648653  || Decoder Loss:  0.034648653 Validation Decoder Loss:  0.33009744
Encoder Loss:  0.034647692  || Decoder Loss:  0.034647692 Validation Decoder Loss:  0.33010602
Encoder Loss:  0.034646768  || Decoder Loss:  0.034646768 Validation Decoder Loss:  0.3301142
Encoder Loss:  0.034645926  || Decoder Loss:  0.034645926 Validation Decoder Loss:  0.33012205
Encoder Loss:  0.034645084  || Decoder Loss:  0.034645084 Validation Decoder Loss:  0.33012956
Encoder Loss:  0.03464431  || Decoder Loss:  0.03464431 Validation Decoder Loss:  0.33013678
Encoder Loss:  0.034643624  || Decoder Loss:  0.034643624 Validation Decoder Loss:  0.33014372
Encoder Loss:  0.034642924  || Decoder Loss:  0.034642924 Validation Decoder Loss:  0.33015037
Encoder Loss:  0.03464228  || Decoder Loss:  0.03464228 Validation Decoder Loss:  0.33015683
Encoder Loss:  0.03464166  || Decoder Loss:  0.03464166 Validation Decoder Loss:  0.330163
Encoder Loss:  0.034641076  || Decoder Loss:  0.034641076 Validation Decoder Loss:  0.330169
Encoder Loss:  0.034640525  || Decoder Loss:  0.034640525 Validation Decoder Loss:  0.33017474
Encoder Loss:  0.03463999  || Decoder Loss:  0.03463999 Validation Decoder Loss:  0.33018032
Encoder Loss:  0.034639467  || Decoder Loss:  0.034639467 Validation Decoder Loss:  0.3301857
Encoder Loss:  0.034638945  || Decoder Loss:  0.034638945 Validation Decoder Loss:  0.33019096
Encoder Loss:  0.034638494  || Decoder Loss:  0.034638494 Validation Decoder Loss:  0.33019596
Encoder Loss:  0.034638047  || Decoder Loss:  0.034638047 Validation Decoder Loss:  0.33020085
Encoder Loss:  0.034637608  || Decoder Loss:  0.034637608 Validation Decoder Loss:  0.3302056
Encoder Loss:  0.034637168  || Decoder Loss:  0.034637168 Validation Decoder Loss:  0.3302102
Encoder Loss:  0.03463674  || Decoder Loss:  0.03463674 Validation Decoder Loss:  0.33021468
Encoder Loss:  0.034636363  || Decoder Loss:  0.034636363 Validation Decoder Loss:  0.330219
Model: siamese_net_lr_0.020865463750552336 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.330219
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 514, 5, 20, 1)     263       
_________________________________________________________________
reshape_32 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658067  || Decoder Loss:  0.036658067 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658056  || Decoder Loss:  0.036658056 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658067  || Decoder Loss:  0.036658067 Validation Decoder Loss:  0.3264791
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.036658064  || Decoder Loss:  0.036658064 Validation Decoder Loss:  0.32647914
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.3264791
Encoder Loss:  0.03665806  || Decoder Loss:  0.03665806 Validation Decoder Loss:  0.32647914
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32647914
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 514, 5, 20, 1)     11        
_________________________________________________________________
reshape_33 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23363626  || Decoder Loss:  0.03981679 Validation Decoder Loss:  0.33134604
Encoder Loss:  0.1724344  || Decoder Loss:  0.035745975 Validation Decoder Loss:  0.33117747
Encoder Loss:  0.114660256  || Decoder Loss:  0.035716835 Validation Decoder Loss:  0.33096585
Encoder Loss:  0.09795665  || Decoder Loss:  0.03568678 Validation Decoder Loss:  0.33077735
Encoder Loss:  0.10421114  || Decoder Loss:  0.03573435 Validation Decoder Loss:  0.33065373
Encoder Loss:  0.08216926  || Decoder Loss:  0.03581179 Validation Decoder Loss:  0.3306024
Encoder Loss:  0.086779654  || Decoder Loss:  0.0360322 Validation Decoder Loss:  0.33067626
Encoder Loss:  0.07587225  || Decoder Loss:  0.03593377 Validation Decoder Loss:  0.33059305
Encoder Loss:  0.07829191  || Decoder Loss:  0.036878664 Validation Decoder Loss:  0.33187065
Encoder Loss:  0.08121474  || Decoder Loss:  0.035465878 Validation Decoder Loss:  0.33009827
Encoder Loss:  0.080888316  || Decoder Loss:  0.03532428 Validation Decoder Loss:  0.33019638
Encoder Loss:  0.0825774  || Decoder Loss:  0.035601385 Validation Decoder Loss:  0.33082366
Encoder Loss:  0.063759394  || Decoder Loss:  0.03691397 Validation Decoder Loss:  0.33125806
Encoder Loss:  0.05182591  || Decoder Loss:  0.035680912 Validation Decoder Loss:  0.33128053
Encoder Loss:  0.05307076  || Decoder Loss:  0.03557896 Validation Decoder Loss:  0.3315563
Encoder Loss:  0.052778296  || Decoder Loss:  0.03549621 Validation Decoder Loss:  0.33144495
Encoder Loss:  0.052990567  || Decoder Loss:  0.035481792 Validation Decoder Loss:  0.33142543
Encoder Loss:  0.05797912  || Decoder Loss:  0.035648216 Validation Decoder Loss:  0.33153573
Encoder Loss:  0.050346013  || Decoder Loss:  0.035554286 Validation Decoder Loss:  0.3314749
Encoder Loss:  0.05144223  || Decoder Loss:  0.035569895 Validation Decoder Loss:  0.33146393
Encoder Loss:  0.050765127  || Decoder Loss:  0.035525218 Validation Decoder Loss:  0.33156377
Encoder Loss:  0.050288815  || Decoder Loss:  0.035510845 Validation Decoder Loss:  0.33154017
Encoder Loss:  0.050504867  || Decoder Loss:  0.03550935 Validation Decoder Loss:  0.3316776
Encoder Loss:  0.052608456  || Decoder Loss:  0.035545338 Validation Decoder Loss:  0.3315903
Encoder Loss:  0.0519806  || Decoder Loss:  0.03552061 Validation Decoder Loss:  0.33156383
Encoder Loss:  0.050689984  || Decoder Loss:  0.035477832 Validation Decoder Loss:  0.3315524
Encoder Loss:  0.05251041  || Decoder Loss:  0.035502043 Validation Decoder Loss:  0.33160204
Encoder Loss:  0.05043382  || Decoder Loss:  0.035453513 Validation Decoder Loss:  0.33164844
Encoder Loss:  0.0502986  || Decoder Loss:  0.035438124 Validation Decoder Loss:  0.33160973
Encoder Loss:  0.049987607  || Decoder Loss:  0.035424702 Validation Decoder Loss:  0.33162194
Encoder Loss:  0.053247146  || Decoder Loss:  0.035457656 Validation Decoder Loss:  0.33156726
Encoder Loss:  0.049749617  || Decoder Loss:  0.035430893 Validation Decoder Loss:  0.3316331
Encoder Loss:  0.049564887  || Decoder Loss:  0.035401158 Validation Decoder Loss:  0.33163822
Encoder Loss:  0.04969381  || Decoder Loss:  0.035406463 Validation Decoder Loss:  0.33161184
Encoder Loss:  0.050736226  || Decoder Loss:  0.035412755 Validation Decoder Loss:  0.33159906
Encoder Loss:  0.049789462  || Decoder Loss:  0.035395198 Validation Decoder Loss:  0.331574
Encoder Loss:  0.05074707  || Decoder Loss:  0.035404082 Validation Decoder Loss:  0.33153373
Encoder Loss:  0.05046645  || Decoder Loss:  0.035392374 Validation Decoder Loss:  0.3316083
Encoder Loss:  0.05335163  || Decoder Loss:  0.035423324 Validation Decoder Loss:  0.33158726
Encoder Loss:  0.049853634  || Decoder Loss:  0.03537903 Validation Decoder Loss:  0.3315923
Model: siamese_net_lr_0.51388952404199 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3315923
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 257, 10, 20, 1)    409       
_________________________________________________________________
reshape_34 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675607  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.03675606  || Decoder Loss:  0.03675606 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.036756065  || Decoder Loss:  0.036756065 Validation Decoder Loss:  0.3299045
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3299045
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 257, 10, 20, 1)    11        
_________________________________________________________________
reshape_35 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.035767447  || Decoder Loss:  0.035767447 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.035767447  || Decoder Loss:  0.035767447 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576746  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.035767447  || Decoder Loss:  0.035767447 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.03576745  || Decoder Loss:  0.03576745 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.035767447  || Decoder Loss:  0.035767447 Validation Decoder Loss:  0.33151364
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33151364
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 257, 10, 20, 1)    11        
_________________________________________________________________
reshape_36 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24549286  || Decoder Loss:  0.035281006 Validation Decoder Loss:  0.3287285
Encoder Loss:  0.22769654  || Decoder Loss:  0.03523745 Validation Decoder Loss:  0.32928118
Encoder Loss:  0.16582133  || Decoder Loss:  0.035255674 Validation Decoder Loss:  0.3306854
Encoder Loss:  0.09945706  || Decoder Loss:  0.035261866 Validation Decoder Loss:  0.33112276
Encoder Loss:  0.074410595  || Decoder Loss:  0.035298515 Validation Decoder Loss:  0.33148843
Encoder Loss:  0.049764  || Decoder Loss:  0.03529298 Validation Decoder Loss:  0.33146602
Encoder Loss:  0.046452217  || Decoder Loss:  0.03528802 Validation Decoder Loss:  0.3314789
Encoder Loss:  0.046832632  || Decoder Loss:  0.035273626 Validation Decoder Loss:  0.3314809
Encoder Loss:  0.048899963  || Decoder Loss:  0.035271004 Validation Decoder Loss:  0.33148688
Encoder Loss:  0.046921507  || Decoder Loss:  0.035274874 Validation Decoder Loss:  0.33148652
Encoder Loss:  0.07317644  || Decoder Loss:  0.0352967 Validation Decoder Loss:  0.33154392
Encoder Loss:  0.05007166  || Decoder Loss:  0.03527915 Validation Decoder Loss:  0.33148736
Encoder Loss:  0.046654172  || Decoder Loss:  0.035271917 Validation Decoder Loss:  0.33149773
Encoder Loss:  0.046366353  || Decoder Loss:  0.035269655 Validation Decoder Loss:  0.33149707
Encoder Loss:  0.046551265  || Decoder Loss:  0.035268154 Validation Decoder Loss:  0.33149964
Encoder Loss:  0.046602033  || Decoder Loss:  0.035272345 Validation Decoder Loss:  0.33150148
Encoder Loss:  0.046575174  || Decoder Loss:  0.035272412 Validation Decoder Loss:  0.33150637
Encoder Loss:  0.046779443  || Decoder Loss:  0.0352683 Validation Decoder Loss:  0.33151382
Encoder Loss:  0.046561133  || Decoder Loss:  0.03527204 Validation Decoder Loss:  0.3315296
Encoder Loss:  0.04662634  || Decoder Loss:  0.035264924 Validation Decoder Loss:  0.33153996
Encoder Loss:  0.046564847  || Decoder Loss:  0.03526745 Validation Decoder Loss:  0.33153993
Encoder Loss:  0.047168236  || Decoder Loss:  0.035264134 Validation Decoder Loss:  0.33154136
Encoder Loss:  0.0940896  || Decoder Loss:  0.03524878 Validation Decoder Loss:  0.33152992
Encoder Loss:  0.046056464  || Decoder Loss:  0.035270244 Validation Decoder Loss:  0.3315513
Encoder Loss:  0.046066638  || Decoder Loss:  0.03526476 Validation Decoder Loss:  0.33155203
Encoder Loss:  0.046113238  || Decoder Loss:  0.03526525 Validation Decoder Loss:  0.33154708
Encoder Loss:  0.046126496  || Decoder Loss:  0.03526053 Validation Decoder Loss:  0.3315394
Encoder Loss:  0.04604093  || Decoder Loss:  0.035263084 Validation Decoder Loss:  0.33152995
Encoder Loss:  0.046470392  || Decoder Loss:  0.035264414 Validation Decoder Loss:  0.3315254
Encoder Loss:  0.046434388  || Decoder Loss:  0.035261333 Validation Decoder Loss:  0.33152092
Encoder Loss:  0.04604595  || Decoder Loss:  0.035263326 Validation Decoder Loss:  0.33151674
Encoder Loss:  0.046605922  || Decoder Loss:  0.03526081 Validation Decoder Loss:  0.3315172
Encoder Loss:  0.04648355  || Decoder Loss:  0.03526195 Validation Decoder Loss:  0.33151737
Encoder Loss:  0.048309736  || Decoder Loss:  0.035268813 Validation Decoder Loss:  0.33151743
Encoder Loss:  0.048733383  || Decoder Loss:  0.035262033 Validation Decoder Loss:  0.33152366
Encoder Loss:  0.046308503  || Decoder Loss:  0.03526261 Validation Decoder Loss:  0.33152178
Encoder Loss:  0.04634873  || Decoder Loss:  0.035260938 Validation Decoder Loss:  0.33152056
Encoder Loss:  0.046813186  || Decoder Loss:  0.035260167 Validation Decoder Loss:  0.3315205
Encoder Loss:  0.04658673  || Decoder Loss:  0.035258435 Validation Decoder Loss:  0.3315208
Encoder Loss:  0.046375033  || Decoder Loss:  0.035262622 Validation Decoder Loss:  0.33152536
Model: siamese_net_lr_0.2722075355260249 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33152536
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 514, 5, 20, 1)     11        
_________________________________________________________________
reshape_37 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2590802  || Decoder Loss:  0.03572945 Validation Decoder Loss:  0.33132327
Encoder Loss:  0.24068998  || Decoder Loss:  0.03528123 Validation Decoder Loss:  0.33023715
Encoder Loss:  0.1365792  || Decoder Loss:  0.034934007 Validation Decoder Loss:  0.330024
Encoder Loss:  0.080118015  || Decoder Loss:  0.034893204 Validation Decoder Loss:  0.33007285
Encoder Loss:  0.078279234  || Decoder Loss:  0.034875315 Validation Decoder Loss:  0.3301443
Encoder Loss:  0.06543605  || Decoder Loss:  0.034864828 Validation Decoder Loss:  0.33019766
Encoder Loss:  0.067004725  || Decoder Loss:  0.034858435 Validation Decoder Loss:  0.33024603
Encoder Loss:  0.06541927  || Decoder Loss:  0.03485572 Validation Decoder Loss:  0.33030036
Encoder Loss:  0.068224184  || Decoder Loss:  0.034853548 Validation Decoder Loss:  0.33031896
Encoder Loss:  0.0696665  || Decoder Loss:  0.034853514 Validation Decoder Loss:  0.3303428
Encoder Loss:  0.061323166  || Decoder Loss:  0.034855425 Validation Decoder Loss:  0.33037496
Encoder Loss:  0.064393446  || Decoder Loss:  0.034859482 Validation Decoder Loss:  0.33039838
Encoder Loss:  0.06552547  || Decoder Loss:  0.034867056 Validation Decoder Loss:  0.3303985
Encoder Loss:  0.057397794  || Decoder Loss:  0.03487602 Validation Decoder Loss:  0.3304003
Encoder Loss:  0.057511438  || Decoder Loss:  0.034884874 Validation Decoder Loss:  0.33040136
Encoder Loss:  0.05890316  || Decoder Loss:  0.034892548 Validation Decoder Loss:  0.33042756
Encoder Loss:  0.055788092  || Decoder Loss:  0.034903422 Validation Decoder Loss:  0.33043993
Encoder Loss:  0.07372958  || Decoder Loss:  0.034914844 Validation Decoder Loss:  0.33048895
Encoder Loss:  0.06245949  || Decoder Loss:  0.03492738 Validation Decoder Loss:  0.3305263
Encoder Loss:  0.058373183  || Decoder Loss:  0.034936663 Validation Decoder Loss:  0.33056468
Encoder Loss:  0.06590932  || Decoder Loss:  0.034946244 Validation Decoder Loss:  0.33065045
Encoder Loss:  0.061314538  || Decoder Loss:  0.03495674 Validation Decoder Loss:  0.33073437
Encoder Loss:  0.055620827  || Decoder Loss:  0.034967393 Validation Decoder Loss:  0.33085898
Encoder Loss:  0.064586036  || Decoder Loss:  0.034998585 Validation Decoder Loss:  0.33126295
Encoder Loss:  0.05583373  || Decoder Loss:  0.03522409 Validation Decoder Loss:  0.33178264
Encoder Loss:  0.05465084  || Decoder Loss:  0.03531498 Validation Decoder Loss:  0.33097225
Encoder Loss:  0.060590733  || Decoder Loss:  0.035343036 Validation Decoder Loss:  0.33140475
Encoder Loss:  0.05358364  || Decoder Loss:  0.035363622 Validation Decoder Loss:  0.3313145
Encoder Loss:  0.04975113  || Decoder Loss:  0.035326846 Validation Decoder Loss:  0.33155245
Encoder Loss:  0.046690818  || Decoder Loss:  0.035326164 Validation Decoder Loss:  0.3315656
Encoder Loss:  0.04655479  || Decoder Loss:  0.035328776 Validation Decoder Loss:  0.3315197
Encoder Loss:  0.046873923  || Decoder Loss:  0.035330046 Validation Decoder Loss:  0.33158332
Encoder Loss:  0.045904946  || Decoder Loss:  0.03533436 Validation Decoder Loss:  0.3315899
Encoder Loss:  0.046099734  || Decoder Loss:  0.035332613 Validation Decoder Loss:  0.33159053
Encoder Loss:  0.045362182  || Decoder Loss:  0.035327047 Validation Decoder Loss:  0.3315649
Encoder Loss:  0.045508366  || Decoder Loss:  0.03532393 Validation Decoder Loss:  0.331563
Encoder Loss:  0.045328725  || Decoder Loss:  0.03532198 Validation Decoder Loss:  0.33155692
Encoder Loss:  0.0456885  || Decoder Loss:  0.035329353 Validation Decoder Loss:  0.3315451
Encoder Loss:  0.04553497  || Decoder Loss:  0.035319798 Validation Decoder Loss:  0.33155718
Encoder Loss:  0.04559182  || Decoder Loss:  0.035322472 Validation Decoder Loss:  0.3315786
Model: siamese_net_lr_0.14602651759611382 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3315786
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 514, 5, 20, 1)     137       
_________________________________________________________________
reshape_38 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686515  || Decoder Loss:  0.035686515 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686515  || Decoder Loss:  0.035686515 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041957
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686515  || Decoder Loss:  0.035686515 Validation Decoder Loss:  0.33041954
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33041954
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 127, 10, 20, 1)    385       
_________________________________________________________________
reshape_39 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09968993  || Decoder Loss:  0.11101035 Validation Decoder Loss:  0.33527038
Encoder Loss:  0.067749724  || Decoder Loss:  0.044209145 Validation Decoder Loss:  0.33239564
Encoder Loss:  0.06291487  || Decoder Loss:  0.041274842 Validation Decoder Loss:  0.33380443
Encoder Loss:  0.06016665  || Decoder Loss:  0.040441297 Validation Decoder Loss:  0.33544186
Encoder Loss:  0.056788553  || Decoder Loss:  0.039432757 Validation Decoder Loss:  0.3365243
Encoder Loss:  0.05640437  || Decoder Loss:  0.038976815 Validation Decoder Loss:  0.33537588
Encoder Loss:  0.055594694  || Decoder Loss:  0.03825228 Validation Decoder Loss:  0.33535224
Encoder Loss:  0.055351872  || Decoder Loss:  0.038143564 Validation Decoder Loss:  0.3354686
Encoder Loss:  0.05639864  || Decoder Loss:  0.03804231 Validation Decoder Loss:  0.33305836
Encoder Loss:  0.052979402  || Decoder Loss:  0.037260864 Validation Decoder Loss:  0.3306796
Encoder Loss:  0.05409036  || Decoder Loss:  0.037305392 Validation Decoder Loss:  0.3321717
Encoder Loss:  0.052436262  || Decoder Loss:  0.036999002 Validation Decoder Loss:  0.3307023
Encoder Loss:  0.05142154  || Decoder Loss:  0.0365438 Validation Decoder Loss:  0.32859635
Encoder Loss:  0.051241122  || Decoder Loss:  0.038069043 Validation Decoder Loss:  0.33300626
Encoder Loss:  0.05096807  || Decoder Loss:  0.04011748 Validation Decoder Loss:  0.33111918
Encoder Loss:  0.053264346  || Decoder Loss:  0.03853916 Validation Decoder Loss:  0.33805558
Encoder Loss:  0.05393054  || Decoder Loss:  0.03825826 Validation Decoder Loss:  0.33776563
Encoder Loss:  0.051223613  || Decoder Loss:  0.037627067 Validation Decoder Loss:  0.3383943
Encoder Loss:  0.053416606  || Decoder Loss:  0.037766706 Validation Decoder Loss:  0.336294
Encoder Loss:  0.050737362  || Decoder Loss:  0.037222903 Validation Decoder Loss:  0.33811682
Encoder Loss:  0.05126595  || Decoder Loss:  0.037093356 Validation Decoder Loss:  0.337036
Encoder Loss:  0.050915718  || Decoder Loss:  0.036940854 Validation Decoder Loss:  0.3380417
Encoder Loss:  0.050828427  || Decoder Loss:  0.036806528 Validation Decoder Loss:  0.33603746
Encoder Loss:  0.052234087  || Decoder Loss:  0.036929663 Validation Decoder Loss:  0.33780435
Encoder Loss:  0.051409505  || Decoder Loss:  0.03674905 Validation Decoder Loss:  0.33761948
Encoder Loss:  0.050681937  || Decoder Loss:  0.03657316 Validation Decoder Loss:  0.33669657
Encoder Loss:  0.051064275  || Decoder Loss:  0.03653445 Validation Decoder Loss:  0.3372815
Encoder Loss:  0.052891787  || Decoder Loss:  0.03666844 Validation Decoder Loss:  0.33708417
Encoder Loss:  0.05074901  || Decoder Loss:  0.036404613 Validation Decoder Loss:  0.33736938
Encoder Loss:  0.0540389  || Decoder Loss:  0.036674127 Validation Decoder Loss:  0.3373728
Encoder Loss:  0.050534975  || Decoder Loss:  0.03634051 Validation Decoder Loss:  0.3366934
Encoder Loss:  0.051018152  || Decoder Loss:  0.03636742 Validation Decoder Loss:  0.3357445
Encoder Loss:  0.050550602  || Decoder Loss:  0.036284763 Validation Decoder Loss:  0.33639932
Encoder Loss:  0.050912973  || Decoder Loss:  0.03621392 Validation Decoder Loss:  0.33658797
Encoder Loss:  0.050795685  || Decoder Loss:  0.036229867 Validation Decoder Loss:  0.33501858
Encoder Loss:  0.050670117  || Decoder Loss:  0.036182374 Validation Decoder Loss:  0.33701828
Encoder Loss:  0.050814427  || Decoder Loss:  0.036159758 Validation Decoder Loss:  0.33650506
Encoder Loss:  0.050589718  || Decoder Loss:  0.036069106 Validation Decoder Loss:  0.33664545
Encoder Loss:  0.05083496  || Decoder Loss:  0.03609565 Validation Decoder Loss:  0.33546436
Encoder Loss:  0.050589636  || Decoder Loss:  0.036046978 Validation Decoder Loss:  0.33656123
Model: siamese_net_lr_0.4659197968776595 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33656123
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 257, 10, 20, 1)    31        
_________________________________________________________________
reshape_40 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.042818833  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818822  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818822  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818822  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818837  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.042818833  || Decoder Loss:  0.03586724 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.04281883  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33169764
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 514, 5, 20, 1)     452       
_________________________________________________________________
reshape_41 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 452
Trainable params: 452
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0939232  || Decoder Loss:  0.0937205 Validation Decoder Loss:  0.40803027
Encoder Loss:  0.05461305  || Decoder Loss:  0.040178727 Validation Decoder Loss:  0.32395697
Encoder Loss:  0.052589763  || Decoder Loss:  0.0383267 Validation Decoder Loss:  0.3247037
Encoder Loss:  0.04974982  || Decoder Loss:  0.037135974 Validation Decoder Loss:  0.32658947
Encoder Loss:  0.05012174  || Decoder Loss:  0.037116602 Validation Decoder Loss:  0.32656848
Encoder Loss:  0.04981123  || Decoder Loss:  0.03689985 Validation Decoder Loss:  0.32707447
Encoder Loss:  0.054967795  || Decoder Loss:  0.03865159 Validation Decoder Loss:  0.3248543
Encoder Loss:  0.049967583  || Decoder Loss:  0.036913186 Validation Decoder Loss:  0.3270173
Encoder Loss:  0.0500794  || Decoder Loss:  0.036826707 Validation Decoder Loss:  0.327974
Encoder Loss:  0.050231222  || Decoder Loss:  0.036819838 Validation Decoder Loss:  0.32791936
Encoder Loss:  0.05020355  || Decoder Loss:  0.036713097 Validation Decoder Loss:  0.32718563
Encoder Loss:  0.0517782  || Decoder Loss:  0.037264578 Validation Decoder Loss:  0.32966834
Encoder Loss:  0.049421005  || Decoder Loss:  0.03636404 Validation Decoder Loss:  0.32990196
Encoder Loss:  0.04988874  || Decoder Loss:  0.03642285 Validation Decoder Loss:  0.33113042
Encoder Loss:  0.05040027  || Decoder Loss:  0.03664978 Validation Decoder Loss:  0.33172017
Encoder Loss:  0.049654506  || Decoder Loss:  0.03624847 Validation Decoder Loss:  0.33058318
Encoder Loss:  0.05116916  || Decoder Loss:  0.03671134 Validation Decoder Loss:  0.3329129
Encoder Loss:  0.049598128  || Decoder Loss:  0.036224794 Validation Decoder Loss:  0.33377254
Encoder Loss:  0.049611207  || Decoder Loss:  0.036149636 Validation Decoder Loss:  0.33414972
Encoder Loss:  0.04922952  || Decoder Loss:  0.036045384 Validation Decoder Loss:  0.33503938
Encoder Loss:  0.049984332  || Decoder Loss:  0.03616911 Validation Decoder Loss:  0.33513126
Encoder Loss:  0.05029902  || Decoder Loss:  0.036165968 Validation Decoder Loss:  0.33493772
Encoder Loss:  0.052383475  || Decoder Loss:  0.036472198 Validation Decoder Loss:  0.33589292
Encoder Loss:  0.049394295  || Decoder Loss:  0.035948016 Validation Decoder Loss:  0.3360659
Encoder Loss:  0.04935877  || Decoder Loss:  0.035908867 Validation Decoder Loss:  0.33683434
Encoder Loss:  0.049064104  || Decoder Loss:  0.0358499 Validation Decoder Loss:  0.33751583
Encoder Loss:  0.049270254  || Decoder Loss:  0.035830513 Validation Decoder Loss:  0.33790484
Encoder Loss:  0.050394945  || Decoder Loss:  0.035953373 Validation Decoder Loss:  0.33719307
Encoder Loss:  0.04910817  || Decoder Loss:  0.035769615 Validation Decoder Loss:  0.33818436
Encoder Loss:  0.04935806  || Decoder Loss:  0.035757408 Validation Decoder Loss:  0.3383154
Encoder Loss:  0.049546827  || Decoder Loss:  0.035756353 Validation Decoder Loss:  0.33841667
Encoder Loss:  0.049108252  || Decoder Loss:  0.035698462 Validation Decoder Loss:  0.33889198
Encoder Loss:  0.050423536  || Decoder Loss:  0.035818215 Validation Decoder Loss:  0.33860153
Encoder Loss:  0.049255982  || Decoder Loss:  0.03569606 Validation Decoder Loss:  0.33897626
Encoder Loss:  0.049296718  || Decoder Loss:  0.035669614 Validation Decoder Loss:  0.33929905
Encoder Loss:  0.04920677  || Decoder Loss:  0.035640385 Validation Decoder Loss:  0.3394041
Encoder Loss:  0.04944262  || Decoder Loss:  0.035650827 Validation Decoder Loss:  0.33939075
Encoder Loss:  0.049670644  || Decoder Loss:  0.03566005 Validation Decoder Loss:  0.33947176
Encoder Loss:  0.04909953  || Decoder Loss:  0.035592277 Validation Decoder Loss:  0.3397714
Encoder Loss:  0.049047917  || Decoder Loss:  0.035581294 Validation Decoder Loss:  0.33986837
Model: siamese_net_lr_0.6223039565245496 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33986834
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 257, 10, 20, 1)    787       
_________________________________________________________________
reshape_42 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06903521  || Decoder Loss:  0.06791014 Validation Decoder Loss:  0.34134012
Encoder Loss:  0.04248114  || Decoder Loss:  0.042119365 Validation Decoder Loss:  0.33556664
Encoder Loss:  0.041785598  || Decoder Loss:  0.04144269 Validation Decoder Loss:  0.33434606
Encoder Loss:  0.039696246  || Decoder Loss:  0.039426066 Validation Decoder Loss:  0.33413833
Encoder Loss:  0.038868498  || Decoder Loss:  0.038576595 Validation Decoder Loss:  0.3345069
Encoder Loss:  0.03888906  || Decoder Loss:  0.038622968 Validation Decoder Loss:  0.33374625
Encoder Loss:  0.03876474  || Decoder Loss:  0.03846425 Validation Decoder Loss:  0.33411002
Encoder Loss:  0.03863131  || Decoder Loss:  0.038315088 Validation Decoder Loss:  0.3337262
Encoder Loss:  0.03868988  || Decoder Loss:  0.038394183 Validation Decoder Loss:  0.3340942
Encoder Loss:  0.03778994  || Decoder Loss:  0.03754569 Validation Decoder Loss:  0.33393475
Encoder Loss:  0.037770893  || Decoder Loss:  0.037497662 Validation Decoder Loss:  0.33450335
Encoder Loss:  0.037513252  || Decoder Loss:  0.037266318 Validation Decoder Loss:  0.33440983
Encoder Loss:  0.037549686  || Decoder Loss:  0.037297785 Validation Decoder Loss:  0.33417225
Encoder Loss:  0.037501156  || Decoder Loss:  0.037247404 Validation Decoder Loss:  0.3340413
Encoder Loss:  0.037400283  || Decoder Loss:  0.037139855 Validation Decoder Loss:  0.33405656
Encoder Loss:  0.03766073  || Decoder Loss:  0.037382517 Validation Decoder Loss:  0.33439225
Encoder Loss:  0.037643448  || Decoder Loss:  0.03734784 Validation Decoder Loss:  0.3341052
Encoder Loss:  0.037447467  || Decoder Loss:  0.037172686 Validation Decoder Loss:  0.334805
Encoder Loss:  0.037031643  || Decoder Loss:  0.03679126 Validation Decoder Loss:  0.3339031
Encoder Loss:  0.037276514  || Decoder Loss:  0.03701866 Validation Decoder Loss:  0.3344364
Encoder Loss:  0.036955256  || Decoder Loss:  0.03671651 Validation Decoder Loss:  0.33422455
Encoder Loss:  0.036852315  || Decoder Loss:  0.03660945 Validation Decoder Loss:  0.3344696
Encoder Loss:  0.036826923  || Decoder Loss:  0.036589276 Validation Decoder Loss:  0.33440313
Encoder Loss:  0.036800094  || Decoder Loss:  0.036557484 Validation Decoder Loss:  0.33428898
Encoder Loss:  0.036689337  || Decoder Loss:  0.036447737 Validation Decoder Loss:  0.3342705
Encoder Loss:  0.036784872  || Decoder Loss:  0.03652937 Validation Decoder Loss:  0.3343824
Encoder Loss:  0.036618665  || Decoder Loss:  0.036378466 Validation Decoder Loss:  0.33402365
Encoder Loss:  0.03683847  || Decoder Loss:  0.036543734 Validation Decoder Loss:  0.33435583
Encoder Loss:  0.036632285  || Decoder Loss:  0.036393397 Validation Decoder Loss:  0.33441556
Encoder Loss:  0.036563247  || Decoder Loss:  0.036310717 Validation Decoder Loss:  0.33441365
Encoder Loss:  0.03646113  || Decoder Loss:  0.036222685 Validation Decoder Loss:  0.3342653
Encoder Loss:  0.03647038  || Decoder Loss:  0.03622427 Validation Decoder Loss:  0.3343146
Encoder Loss:  0.036370803  || Decoder Loss:  0.03613089 Validation Decoder Loss:  0.3341963
Encoder Loss:  0.03634284  || Decoder Loss:  0.036105674 Validation Decoder Loss:  0.33417764
Encoder Loss:  0.03629054  || Decoder Loss:  0.036044434 Validation Decoder Loss:  0.33458877
Encoder Loss:  0.03633749  || Decoder Loss:  0.036087237 Validation Decoder Loss:  0.33457124
Encoder Loss:  0.036288362  || Decoder Loss:  0.036037784 Validation Decoder Loss:  0.33422065
Encoder Loss:  0.036195703  || Decoder Loss:  0.035949953 Validation Decoder Loss:  0.33429033
Encoder Loss:  0.036220845  || Decoder Loss:  0.035978448 Validation Decoder Loss:  0.33407813
Encoder Loss:  0.036143538  || Decoder Loss:  0.035899345 Validation Decoder Loss:  0.33410418
Model: siamese_net_lr_0.511156326913516 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33410418
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 257, 10, 20, 1)    787       
_________________________________________________________________
reshape_43 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204707 Validation Decoder Loss:  0.32468757
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204708 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204708 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204707 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204707 Validation Decoder Loss:  0.32468757
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204708 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.32468757
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204708 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.32468757
Encoder Loss:  0.2180018  || Decoder Loss:  0.04204707 Validation Decoder Loss:  0.32468757
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047072 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.3246876
Encoder Loss:  0.2180018  || Decoder Loss:  0.042047076 Validation Decoder Loss:  0.32468757
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3246876
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_44 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11646754  || Decoder Loss:  0.13074905 Validation Decoder Loss:  0.32190102
Encoder Loss:  0.0678571  || Decoder Loss:  0.042444337 Validation Decoder Loss:  0.32288074
Encoder Loss:  0.06291487  || Decoder Loss:  0.040183496 Validation Decoder Loss:  0.3240824
Encoder Loss:  0.061243735  || Decoder Loss:  0.039668553 Validation Decoder Loss:  0.32347333
Encoder Loss:  0.061198816  || Decoder Loss:  0.03912828 Validation Decoder Loss:  0.32318485
Encoder Loss:  0.058062755  || Decoder Loss:  0.03860551 Validation Decoder Loss:  0.32412052
Encoder Loss:  0.057601724  || Decoder Loss:  0.038301572 Validation Decoder Loss:  0.3251925
Encoder Loss:  0.05692998  || Decoder Loss:  0.0381191 Validation Decoder Loss:  0.32544142
Encoder Loss:  0.052087057  || Decoder Loss:  0.037425626 Validation Decoder Loss:  0.32670194
Encoder Loss:  0.048070937  || Decoder Loss:  0.036959756 Validation Decoder Loss:  0.32885492
Encoder Loss:  0.047869664  || Decoder Loss:  0.036696512 Validation Decoder Loss:  0.32999396
Encoder Loss:  0.04784315  || Decoder Loss:  0.036567416 Validation Decoder Loss:  0.33101302
Encoder Loss:  0.04794265  || Decoder Loss:  0.036499705 Validation Decoder Loss:  0.3323656
Encoder Loss:  0.04801534  || Decoder Loss:  0.036408566 Validation Decoder Loss:  0.3329348
Encoder Loss:  0.047554065  || Decoder Loss:  0.036278386 Validation Decoder Loss:  0.3319068
Encoder Loss:  0.04807876  || Decoder Loss:  0.03630762 Validation Decoder Loss:  0.33198142
Encoder Loss:  0.047829095  || Decoder Loss:  0.036194757 Validation Decoder Loss:  0.33115023
Encoder Loss:  0.0480994  || Decoder Loss:  0.036217723 Validation Decoder Loss:  0.33127698
Encoder Loss:  0.04802365  || Decoder Loss:  0.036140006 Validation Decoder Loss:  0.33117473
Encoder Loss:  0.0481179  || Decoder Loss:  0.036141366 Validation Decoder Loss:  0.33304697
Encoder Loss:  0.04801493  || Decoder Loss:  0.036086824 Validation Decoder Loss:  0.33418363
Encoder Loss:  0.047778077  || Decoder Loss:  0.035991486 Validation Decoder Loss:  0.3340044
Encoder Loss:  0.047804147  || Decoder Loss:  0.035983887 Validation Decoder Loss:  0.33565736
Encoder Loss:  0.047627777  || Decoder Loss:  0.035899438 Validation Decoder Loss:  0.33745027
Encoder Loss:  0.04815313  || Decoder Loss:  0.03596246 Validation Decoder Loss:  0.33830732
Encoder Loss:  0.04773672  || Decoder Loss:  0.035844013 Validation Decoder Loss:  0.33887154
Encoder Loss:  0.047649633  || Decoder Loss:  0.035822283 Validation Decoder Loss:  0.33890373
Encoder Loss:  0.047773324  || Decoder Loss:  0.0357913 Validation Decoder Loss:  0.3391565
Encoder Loss:  0.04898448  || Decoder Loss:  0.03592757 Validation Decoder Loss:  0.33920088
Encoder Loss:  0.04764457  || Decoder Loss:  0.035744112 Validation Decoder Loss:  0.3389938
Encoder Loss:  0.04743988  || Decoder Loss:  0.03569449 Validation Decoder Loss:  0.3387711
Encoder Loss:  0.047578793  || Decoder Loss:  0.03569673 Validation Decoder Loss:  0.339032
Encoder Loss:  0.04748166  || Decoder Loss:  0.03565161 Validation Decoder Loss:  0.3385168
Encoder Loss:  0.047845062  || Decoder Loss:  0.035690602 Validation Decoder Loss:  0.33886197
Encoder Loss:  0.048025437  || Decoder Loss:  0.035676852 Validation Decoder Loss:  0.3388449
Encoder Loss:  0.047397237  || Decoder Loss:  0.035604443 Validation Decoder Loss:  0.33870625
Encoder Loss:  0.04744986  || Decoder Loss:  0.035595916 Validation Decoder Loss:  0.3388099
Encoder Loss:  0.047701564  || Decoder Loss:  0.035608415 Validation Decoder Loss:  0.33887574
Encoder Loss:  0.04734511  || Decoder Loss:  0.03556526 Validation Decoder Loss:  0.3388441
Encoder Loss:  0.04746328  || Decoder Loss:  0.035556115 Validation Decoder Loss:  0.33878034
Model: siamese_net_lr_0.6862090158889569 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33878034
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 514, 5, 20, 1)     452       
_________________________________________________________________
reshape_45 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 452
Trainable params: 452
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09498665  || Decoder Loss:  0.09450806 Validation Decoder Loss:  0.32056636
Encoder Loss:  0.03934341  || Decoder Loss:  0.03908982 Validation Decoder Loss:  0.32910675
Encoder Loss:  0.036653787  || Decoder Loss:  0.036518537 Validation Decoder Loss:  0.33106497
Encoder Loss:  0.03631477  || Decoder Loss:  0.03618179 Validation Decoder Loss:  0.33025157
Encoder Loss:  0.03643033  || Decoder Loss:  0.036289588 Validation Decoder Loss:  0.33266193
Encoder Loss:  0.036186453  || Decoder Loss:  0.03605105 Validation Decoder Loss:  0.33365723
Encoder Loss:  0.0360374  || Decoder Loss:  0.03590516 Validation Decoder Loss:  0.3342726
Encoder Loss:  0.03610096  || Decoder Loss:  0.035963055 Validation Decoder Loss:  0.33492815
Encoder Loss:  0.035858974  || Decoder Loss:  0.035730354 Validation Decoder Loss:  0.33601153
Encoder Loss:  0.036027327  || Decoder Loss:  0.035885286 Validation Decoder Loss:  0.33595234
Encoder Loss:  0.035936087  || Decoder Loss:  0.035798676 Validation Decoder Loss:  0.33638266
Encoder Loss:  0.036355305  || Decoder Loss:  0.03618802 Validation Decoder Loss:  0.33609727
Encoder Loss:  0.035767235  || Decoder Loss:  0.03563767 Validation Decoder Loss:  0.3374196
Encoder Loss:  0.035828628  || Decoder Loss:  0.035689536 Validation Decoder Loss:  0.33762524
Encoder Loss:  0.035707396  || Decoder Loss:  0.03557441 Validation Decoder Loss:  0.33843482
Encoder Loss:  0.035661258  || Decoder Loss:  0.03552924 Validation Decoder Loss:  0.339009
Encoder Loss:  0.03562073  || Decoder Loss:  0.035487916 Validation Decoder Loss:  0.33973235
Encoder Loss:  0.035596967  || Decoder Loss:  0.0354626 Validation Decoder Loss:  0.33956766
Encoder Loss:  0.0358346  || Decoder Loss:  0.035675973 Validation Decoder Loss:  0.3399079
Encoder Loss:  0.03556318  || Decoder Loss:  0.03543138 Validation Decoder Loss:  0.34062734
Encoder Loss:  0.035537522  || Decoder Loss:  0.035405777 Validation Decoder Loss:  0.3410073
Encoder Loss:  0.035539124  || Decoder Loss:  0.03540345 Validation Decoder Loss:  0.3412103
Encoder Loss:  0.035513133  || Decoder Loss:  0.035379857 Validation Decoder Loss:  0.341484
Encoder Loss:  0.03560215  || Decoder Loss:  0.035449274 Validation Decoder Loss:  0.34151128
Encoder Loss:  0.035528615  || Decoder Loss:  0.03538637 Validation Decoder Loss:  0.34166282
Encoder Loss:  0.035468142  || Decoder Loss:  0.035334364 Validation Decoder Loss:  0.34154105
Encoder Loss:  0.035435714  || Decoder Loss:  0.035303548 Validation Decoder Loss:  0.34096378
Encoder Loss:  0.035425913  || Decoder Loss:  0.035293113 Validation Decoder Loss:  0.3405038
Encoder Loss:  0.03546358  || Decoder Loss:  0.03532102 Validation Decoder Loss:  0.34030437
Encoder Loss:  0.03541116  || Decoder Loss:  0.035279933 Validation Decoder Loss:  0.33859283
Encoder Loss:  0.035408784  || Decoder Loss:  0.035273906 Validation Decoder Loss:  0.33806828
Encoder Loss:  0.035413157  || Decoder Loss:  0.035275184 Validation Decoder Loss:  0.33737248
Encoder Loss:  0.035403255  || Decoder Loss:  0.035266615 Validation Decoder Loss:  0.33680856
Encoder Loss:  0.035377394  || Decoder Loss:  0.03524298 Validation Decoder Loss:  0.3364216
Encoder Loss:  0.035402384  || Decoder Loss:  0.035262194 Validation Decoder Loss:  0.33614984
Encoder Loss:  0.035377525  || Decoder Loss:  0.03524206 Validation Decoder Loss:  0.33603397
Encoder Loss:  0.035354063  || Decoder Loss:  0.035222255 Validation Decoder Loss:  0.33603716
Encoder Loss:  0.03537703  || Decoder Loss:  0.035235524 Validation Decoder Loss:  0.33597392
Encoder Loss:  0.035352554  || Decoder Loss:  0.03522091 Validation Decoder Loss:  0.33610356
Encoder Loss:  0.035342366  || Decoder Loss:  0.035210375 Validation Decoder Loss:  0.3361562
Model: siamese_net_lr_0.6515597444029324 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3361562
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 514, 5, 20, 1)     200       
_________________________________________________________________
reshape_46 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 200
Trainable params: 200
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10479487  || Decoder Loss:  0.03585325 Validation Decoder Loss:  0.32964107
Encoder Loss:  0.043789417  || Decoder Loss:  0.035256732 Validation Decoder Loss:  0.32979846
Encoder Loss:  0.043746646  || Decoder Loss:  0.035230946 Validation Decoder Loss:  0.32986096
Encoder Loss:  0.043789994  || Decoder Loss:  0.03521393 Validation Decoder Loss:  0.3298834
Encoder Loss:  0.043553416  || Decoder Loss:  0.03519795 Validation Decoder Loss:  0.32986727
Encoder Loss:  0.043512426  || Decoder Loss:  0.035185333 Validation Decoder Loss:  0.3299253
Encoder Loss:  0.043645576  || Decoder Loss:  0.035174716 Validation Decoder Loss:  0.3299464
Encoder Loss:  0.043510728  || Decoder Loss:  0.035169054 Validation Decoder Loss:  0.32992435
Encoder Loss:  0.04327183  || Decoder Loss:  0.03516371 Validation Decoder Loss:  0.32991657
Encoder Loss:  0.043152776  || Decoder Loss:  0.03516006 Validation Decoder Loss:  0.3299264
Encoder Loss:  0.043183662  || Decoder Loss:  0.03516142 Validation Decoder Loss:  0.32991442
Encoder Loss:  0.043641947  || Decoder Loss:  0.035161868 Validation Decoder Loss:  0.32992792
Encoder Loss:  0.043234743  || Decoder Loss:  0.03516256 Validation Decoder Loss:  0.32989407
Encoder Loss:  0.043104902  || Decoder Loss:  0.03515867 Validation Decoder Loss:  0.32988542
Encoder Loss:  0.043617588  || Decoder Loss:  0.03515619 Validation Decoder Loss:  0.32984006
Encoder Loss:  0.043450017  || Decoder Loss:  0.03515382 Validation Decoder Loss:  0.32984257
Encoder Loss:  0.043047134  || Decoder Loss:  0.035152193 Validation Decoder Loss:  0.32982764
Encoder Loss:  0.043135352  || Decoder Loss:  0.0351545 Validation Decoder Loss:  0.3297904
Encoder Loss:  0.043181114  || Decoder Loss:  0.035153054 Validation Decoder Loss:  0.32978806
Encoder Loss:  0.04340349  || Decoder Loss:  0.035154846 Validation Decoder Loss:  0.32979298
Encoder Loss:  0.04330638  || Decoder Loss:  0.035157084 Validation Decoder Loss:  0.32981107
Encoder Loss:  0.042997774  || Decoder Loss:  0.03515859 Validation Decoder Loss:  0.3298061
Encoder Loss:  0.04277175  || Decoder Loss:  0.03515915 Validation Decoder Loss:  0.32981074
Encoder Loss:  0.043148395  || Decoder Loss:  0.035161544 Validation Decoder Loss:  0.32979113
Encoder Loss:  0.043697577  || Decoder Loss:  0.03516514 Validation Decoder Loss:  0.32979795
Encoder Loss:  0.043237947  || Decoder Loss:  0.035164822 Validation Decoder Loss:  0.32980382
Encoder Loss:  0.043201853  || Decoder Loss:  0.03516728 Validation Decoder Loss:  0.32980573
Encoder Loss:  0.04292447  || Decoder Loss:  0.035168942 Validation Decoder Loss:  0.32983214
Encoder Loss:  0.04277691  || Decoder Loss:  0.035171207 Validation Decoder Loss:  0.32983297
Encoder Loss:  0.04289315  || Decoder Loss:  0.03517313 Validation Decoder Loss:  0.3298364
Encoder Loss:  0.043109342  || Decoder Loss:  0.035171863 Validation Decoder Loss:  0.32984096
Encoder Loss:  0.042983957  || Decoder Loss:  0.0351726 Validation Decoder Loss:  0.32983246
Encoder Loss:  0.043018177  || Decoder Loss:  0.035173114 Validation Decoder Loss:  0.3298493
Encoder Loss:  0.0426888  || Decoder Loss:  0.03517615 Validation Decoder Loss:  0.32986844
Encoder Loss:  0.043002907  || Decoder Loss:  0.035182245 Validation Decoder Loss:  0.32987422
Encoder Loss:  0.042966474  || Decoder Loss:  0.0351835 Validation Decoder Loss:  0.329891
Encoder Loss:  0.04274632  || Decoder Loss:  0.035187777 Validation Decoder Loss:  0.3299089
Encoder Loss:  0.042666845  || Decoder Loss:  0.035189573 Validation Decoder Loss:  0.3299116
Encoder Loss:  0.0428195  || Decoder Loss:  0.035190895 Validation Decoder Loss:  0.32992092
Encoder Loss:  0.04285972  || Decoder Loss:  0.035193846 Validation Decoder Loss:  0.32995006
Model: siamese_net_lr_0.007993764722122945 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32995006
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 257, 10, 20, 1)    11        
_________________________________________________________________
reshape_47 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.03576747 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151358
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.03576747 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.33151358
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821223  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.2082122  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.03576746 Validation Decoder Loss:  0.33151364
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767466 Validation Decoder Loss:  0.3315136
Encoder Loss:  0.20821218  || Decoder Loss:  0.035767462 Validation Decoder Loss:  0.33151364
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33151364
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_48 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2220991  || Decoder Loss:  0.08053041 Validation Decoder Loss:  0.3523563
Encoder Loss:  0.05421248  || Decoder Loss:  0.035514068 Validation Decoder Loss:  0.33162254
Encoder Loss:  0.049890205  || Decoder Loss:  0.03530971 Validation Decoder Loss:  0.33164847
Encoder Loss:  0.048121214  || Decoder Loss:  0.035264816 Validation Decoder Loss:  0.3318783
Encoder Loss:  0.048801973  || Decoder Loss:  0.03519285 Validation Decoder Loss:  0.33272603
Encoder Loss:  0.0472676  || Decoder Loss:  0.035185095 Validation Decoder Loss:  0.33400828
Encoder Loss:  0.045856882  || Decoder Loss:  0.03519754 Validation Decoder Loss:  0.33319914
Encoder Loss:  0.045812856  || Decoder Loss:  0.035199158 Validation Decoder Loss:  0.3332758
Encoder Loss:  0.04659801  || Decoder Loss:  0.03521721 Validation Decoder Loss:  0.3341112
Encoder Loss:  0.045906592  || Decoder Loss:  0.035238508 Validation Decoder Loss:  0.33453766
Encoder Loss:  0.04593507  || Decoder Loss:  0.035257272 Validation Decoder Loss:  0.33422387
Encoder Loss:  0.04571204  || Decoder Loss:  0.035335798 Validation Decoder Loss:  0.33409888
Encoder Loss:  0.045639817  || Decoder Loss:  0.035354104 Validation Decoder Loss:  0.33435443
Encoder Loss:  0.045998998  || Decoder Loss:  0.035370965 Validation Decoder Loss:  0.33437678
Encoder Loss:  0.047571674  || Decoder Loss:  0.035463113 Validation Decoder Loss:  0.33488026
Encoder Loss:  0.045619078  || Decoder Loss:  0.035356775 Validation Decoder Loss:  0.3348484
Encoder Loss:  0.04763479  || Decoder Loss:  0.035455804 Validation Decoder Loss:  0.3338983
Encoder Loss:  0.04815529  || Decoder Loss:  0.03549207 Validation Decoder Loss:  0.33551437
Encoder Loss:  0.04552979  || Decoder Loss:  0.035352334 Validation Decoder Loss:  0.3348331
Encoder Loss:  0.045536228  || Decoder Loss:  0.03535168 Validation Decoder Loss:  0.33469856
Encoder Loss:  0.045542296  || Decoder Loss:  0.03535702 Validation Decoder Loss:  0.33459425
Encoder Loss:  0.045560617  || Decoder Loss:  0.03535688 Validation Decoder Loss:  0.3344558
Encoder Loss:  0.04618374  || Decoder Loss:  0.03537747 Validation Decoder Loss:  0.33443856
Encoder Loss:  0.047104746  || Decoder Loss:  0.03540615 Validation Decoder Loss:  0.33445692
Encoder Loss:  0.05270728  || Decoder Loss:  0.035572674 Validation Decoder Loss:  0.33525908
Encoder Loss:  0.04551644  || Decoder Loss:  0.03535214 Validation Decoder Loss:  0.33459106
Encoder Loss:  0.045532364  || Decoder Loss:  0.035345368 Validation Decoder Loss:  0.33454624
Encoder Loss:  0.045520373  || Decoder Loss:  0.03534352 Validation Decoder Loss:  0.3345204
Encoder Loss:  0.045506407  || Decoder Loss:  0.03534092 Validation Decoder Loss:  0.33446348
Encoder Loss:  0.04551377  || Decoder Loss:  0.03533944 Validation Decoder Loss:  0.3343745
Encoder Loss:  0.045960836  || Decoder Loss:  0.035342973 Validation Decoder Loss:  0.33441687
Encoder Loss:  0.045609903  || Decoder Loss:  0.035341874 Validation Decoder Loss:  0.33428538
Encoder Loss:  0.04589667  || Decoder Loss:  0.035334483 Validation Decoder Loss:  0.33429062
Encoder Loss:  0.045889508  || Decoder Loss:  0.035326663 Validation Decoder Loss:  0.33450708
Encoder Loss:  0.045711618  || Decoder Loss:  0.03532666 Validation Decoder Loss:  0.33439046
Encoder Loss:  0.045566853  || Decoder Loss:  0.035321657 Validation Decoder Loss:  0.33436078
Encoder Loss:  0.053631186  || Decoder Loss:  0.035602286 Validation Decoder Loss:  0.3351795
Encoder Loss:  0.04549495  || Decoder Loss:  0.03535392 Validation Decoder Loss:  0.33478826
Encoder Loss:  0.045484547  || Decoder Loss:  0.035287995 Validation Decoder Loss:  0.33527434
Encoder Loss:  0.04549508  || Decoder Loss:  0.035334565 Validation Decoder Loss:  0.3345484
Model: siamese_net_lr_0.2234924723899081 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33454838
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 514, 5, 20, 1)     74        
_________________________________________________________________
reshape_49 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15672876  || Decoder Loss:  0.1707061 Validation Decoder Loss:  0.33145896
Encoder Loss:  0.093806565  || Decoder Loss:  0.041396666 Validation Decoder Loss:  0.33129358
Encoder Loss:  0.07937797  || Decoder Loss:  0.04532184 Validation Decoder Loss:  0.33146533
Encoder Loss:  0.07422104  || Decoder Loss:  0.04239862 Validation Decoder Loss:  0.331286
Encoder Loss:  0.06471702  || Decoder Loss:  0.043443408 Validation Decoder Loss:  0.331374
Encoder Loss:  0.062377725  || Decoder Loss:  0.039226074 Validation Decoder Loss:  0.33103698
Encoder Loss:  0.05891807  || Decoder Loss:  0.04090542 Validation Decoder Loss:  0.33185005
Encoder Loss:  0.05901596  || Decoder Loss:  0.040179208 Validation Decoder Loss:  0.3317386
Encoder Loss:  0.05470785  || Decoder Loss:  0.038732048 Validation Decoder Loss:  0.3312409
Encoder Loss:  0.05078566  || Decoder Loss:  0.038290173 Validation Decoder Loss:  0.33176544
Encoder Loss:  0.04961738  || Decoder Loss:  0.03783231 Validation Decoder Loss:  0.33134738
Encoder Loss:  0.04952381  || Decoder Loss:  0.037583273 Validation Decoder Loss:  0.33127022
Encoder Loss:  0.049421463  || Decoder Loss:  0.037351586 Validation Decoder Loss:  0.3312564
Encoder Loss:  0.049412236  || Decoder Loss:  0.037029028 Validation Decoder Loss:  0.331294
Encoder Loss:  0.051734485  || Decoder Loss:  0.037223253 Validation Decoder Loss:  0.33111387
Encoder Loss:  0.057574585  || Decoder Loss:  0.03832383 Validation Decoder Loss:  0.331515
Encoder Loss:  0.049272023  || Decoder Loss:  0.037078522 Validation Decoder Loss:  0.33123124
Encoder Loss:  0.04918928  || Decoder Loss:  0.03670839 Validation Decoder Loss:  0.33119124
Encoder Loss:  0.049147166  || Decoder Loss:  0.03648404 Validation Decoder Loss:  0.33140394
Encoder Loss:  0.04910847  || Decoder Loss:  0.036373664 Validation Decoder Loss:  0.33114505
Encoder Loss:  0.04977439  || Decoder Loss:  0.036460392 Validation Decoder Loss:  0.3314122
Encoder Loss:  0.053342894  || Decoder Loss:  0.03706294 Validation Decoder Loss:  0.33132663
Encoder Loss:  0.049049053  || Decoder Loss:  0.03629547 Validation Decoder Loss:  0.33129478
Encoder Loss:  0.050800327  || Decoder Loss:  0.03647165 Validation Decoder Loss:  0.33126682
Encoder Loss:  0.049016576  || Decoder Loss:  0.036131702 Validation Decoder Loss:  0.33129984
Encoder Loss:  0.049013853  || Decoder Loss:  0.035985555 Validation Decoder Loss:  0.33137867
Encoder Loss:  0.04974023  || Decoder Loss:  0.036084786 Validation Decoder Loss:  0.33127695
Encoder Loss:  0.054201335  || Decoder Loss:  0.036510315 Validation Decoder Loss:  0.33145285
Encoder Loss:  0.049001016  || Decoder Loss:  0.035996195 Validation Decoder Loss:  0.33133036
Encoder Loss:  0.049130898  || Decoder Loss:  0.03590512 Validation Decoder Loss:  0.3314193
Encoder Loss:  0.04900193  || Decoder Loss:  0.03582759 Validation Decoder Loss:  0.3315017
Encoder Loss:  0.04980071  || Decoder Loss:  0.035886776 Validation Decoder Loss:  0.33140457
Encoder Loss:  0.048978776  || Decoder Loss:  0.035771046 Validation Decoder Loss:  0.33140427
Encoder Loss:  0.049137365  || Decoder Loss:  0.03573492 Validation Decoder Loss:  0.33155793
Encoder Loss:  0.04894069  || Decoder Loss:  0.03570975 Validation Decoder Loss:  0.3314073
Encoder Loss:  0.05273758  || Decoder Loss:  0.035886947 Validation Decoder Loss:  0.33140147
Encoder Loss:  0.048952803  || Decoder Loss:  0.035690166 Validation Decoder Loss:  0.33140102
Encoder Loss:  0.0499069  || Decoder Loss:  0.035688292 Validation Decoder Loss:  0.33144295
Encoder Loss:  0.04999452  || Decoder Loss:  0.035713404 Validation Decoder Loss:  0.33143222
Encoder Loss:  0.04892339  || Decoder Loss:  0.03560173 Validation Decoder Loss:  0.33142012
Model: siamese_net_lr_0.7426784150095909 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33142012
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 257, 10, 20, 1)    409       
_________________________________________________________________
reshape_50 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 409
Trainable params: 409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352671  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352673  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.03675607 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352671  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352673  || Decoder Loss:  0.03675608 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.32990453
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.3299045
Encoder Loss:  0.21352671  || Decoder Loss:  0.036756076 Validation Decoder Loss:  0.32990453
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3299045
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 514, 5, 20, 1)     74        
_________________________________________________________________
reshape_51 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15784849  || Decoder Loss:  0.15448575 Validation Decoder Loss:  0.3340643
Encoder Loss:  0.036633953  || Decoder Loss:  0.035126314 Validation Decoder Loss:  0.33189857
Encoder Loss:  0.035974327  || Decoder Loss:  0.03484806 Validation Decoder Loss:  0.33222604
Encoder Loss:  0.03689476  || Decoder Loss:  0.035534002 Validation Decoder Loss:  0.33176708
Encoder Loss:  0.036820542  || Decoder Loss:  0.035871 Validation Decoder Loss:  0.33178726
Encoder Loss:  0.037103254  || Decoder Loss:  0.03621726 Validation Decoder Loss:  0.3321766
Encoder Loss:  0.037174  || Decoder Loss:  0.036205567 Validation Decoder Loss:  0.33181435
Encoder Loss:  0.037088957  || Decoder Loss:  0.036205813 Validation Decoder Loss:  0.3316503
Encoder Loss:  0.036545213  || Decoder Loss:  0.035870396 Validation Decoder Loss:  0.33178756
Encoder Loss:  0.036728546  || Decoder Loss:  0.03597344 Validation Decoder Loss:  0.3317634
Encoder Loss:  0.036785383  || Decoder Loss:  0.035962883 Validation Decoder Loss:  0.33232343
Encoder Loss:  0.036621843  || Decoder Loss:  0.035853792 Validation Decoder Loss:  0.33201033
Encoder Loss:  0.036738347  || Decoder Loss:  0.035911676 Validation Decoder Loss:  0.33169872
Encoder Loss:  0.036493443  || Decoder Loss:  0.035815142 Validation Decoder Loss:  0.33214778
Encoder Loss:  0.036517706  || Decoder Loss:  0.035833977 Validation Decoder Loss:  0.33218235
Encoder Loss:  0.036448408  || Decoder Loss:  0.035772417 Validation Decoder Loss:  0.331761
Encoder Loss:  0.03663231  || Decoder Loss:  0.035888508 Validation Decoder Loss:  0.3316241
Encoder Loss:  0.03639984  || Decoder Loss:  0.03568335 Validation Decoder Loss:  0.33225864
Encoder Loss:  0.036538813  || Decoder Loss:  0.035828743 Validation Decoder Loss:  0.33220503
Encoder Loss:  0.036297847  || Decoder Loss:  0.035664998 Validation Decoder Loss:  0.3321368
Encoder Loss:  0.0364599  || Decoder Loss:  0.0357596 Validation Decoder Loss:  0.33183008
Encoder Loss:  0.03640743  || Decoder Loss:  0.035739172 Validation Decoder Loss:  0.33181715
Encoder Loss:  0.03629892  || Decoder Loss:  0.03572325 Validation Decoder Loss:  0.33180127
Encoder Loss:  0.036447126  || Decoder Loss:  0.035745583 Validation Decoder Loss:  0.332314
Encoder Loss:  0.036369693  || Decoder Loss:  0.035773393 Validation Decoder Loss:  0.33180186
Encoder Loss:  0.03613271  || Decoder Loss:  0.03554349 Validation Decoder Loss:  0.33183137
Encoder Loss:  0.035891145  || Decoder Loss:  0.03540003 Validation Decoder Loss:  0.33183497
Encoder Loss:  0.0360715  || Decoder Loss:  0.035611406 Validation Decoder Loss:  0.3317271
Encoder Loss:  0.035916265  || Decoder Loss:  0.035508998 Validation Decoder Loss:  0.33198237
Encoder Loss:  0.03584189  || Decoder Loss:  0.035488084 Validation Decoder Loss:  0.33172303
Encoder Loss:  0.03576318  || Decoder Loss:  0.035408366 Validation Decoder Loss:  0.33172897
Encoder Loss:  0.035753075  || Decoder Loss:  0.035399508 Validation Decoder Loss:  0.3317057
Encoder Loss:  0.03574793  || Decoder Loss:  0.035395723 Validation Decoder Loss:  0.33179665
Encoder Loss:  0.03572146  || Decoder Loss:  0.035366774 Validation Decoder Loss:  0.33177048
Encoder Loss:  0.035715446  || Decoder Loss:  0.035361808 Validation Decoder Loss:  0.33178884
Encoder Loss:  0.03568813  || Decoder Loss:  0.035336245 Validation Decoder Loss:  0.3318944
Encoder Loss:  0.035698794  || Decoder Loss:  0.035346605 Validation Decoder Loss:  0.33183312
Encoder Loss:  0.035670277  || Decoder Loss:  0.035309225 Validation Decoder Loss:  0.33184505
Encoder Loss:  0.035923917  || Decoder Loss:  0.035372574 Validation Decoder Loss:  0.33177716
Encoder Loss:  0.0357339  || Decoder Loss:  0.03536453 Validation Decoder Loss:  0.33182436
Model: siamese_net_lr_0.5772204339184904 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33182436
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 257, 10, 20, 1)    263       
_________________________________________________________________
reshape_52 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.03666237 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.3265136
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.3265136
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.3265136
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.24838011  || Decoder Loss:  0.03666237 Validation Decoder Loss:  0.3265136
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662366 Validation Decoder Loss:  0.32651362
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.03666237 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.24838011  || Decoder Loss:  0.036662363 Validation Decoder Loss:  0.32651365
Encoder Loss:  0.2483801  || Decoder Loss:  0.03666237 Validation Decoder Loss:  0.32651365
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32651365
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_53 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673982
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668103  || Decoder Loss:  0.03668103 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681034  || Decoder Loss:  0.036681034 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681045  || Decoder Loss:  0.036681045 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.03668104  || Decoder Loss:  0.03668104 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.036681037  || Decoder Loss:  0.036681037 Validation Decoder Loss:  0.32673985
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32673985
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 257, 10, 20, 1)    31        
_________________________________________________________________
reshape_54 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867237  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867233  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867237  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867237  || Decoder Loss:  0.035867237 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867233  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33169764
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 127, 10, 20, 1)    385       
_________________________________________________________________
reshape_55 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10847846  || Decoder Loss:  0.42192027 Validation Decoder Loss:  0.6724274
Encoder Loss:  0.06478027  || Decoder Loss:  0.3038945 Validation Decoder Loss:  0.643548
Encoder Loss:  0.057190467  || Decoder Loss:  0.053550314 Validation Decoder Loss:  0.48501354
Encoder Loss:  0.055408083  || Decoder Loss:  0.04720203 Validation Decoder Loss:  0.41881996
Encoder Loss:  0.053233806  || Decoder Loss:  0.043760248 Validation Decoder Loss:  0.3877522
Encoder Loss:  0.053080603  || Decoder Loss:  0.041066572 Validation Decoder Loss:  0.3797317
Encoder Loss:  0.05202477  || Decoder Loss:  0.040297583 Validation Decoder Loss:  0.38415903
Encoder Loss:  0.053400323  || Decoder Loss:  0.042148486 Validation Decoder Loss:  0.37751067
Encoder Loss:  0.053578604  || Decoder Loss:  0.041638732 Validation Decoder Loss:  0.3787088
Encoder Loss:  0.052774537  || Decoder Loss:  0.039773006 Validation Decoder Loss:  0.37870717
Encoder Loss:  0.051103007  || Decoder Loss:  0.040170025 Validation Decoder Loss:  0.3755938
Encoder Loss:  0.05114406  || Decoder Loss:  0.039937567 Validation Decoder Loss:  0.37811399
Encoder Loss:  0.05346007  || Decoder Loss:  0.038978703 Validation Decoder Loss:  0.37559825
Encoder Loss:  0.050933357  || Decoder Loss:  0.039326325 Validation Decoder Loss:  0.37504703
Encoder Loss:  0.05165613  || Decoder Loss:  0.039422583 Validation Decoder Loss:  0.373182
Encoder Loss:  0.051551443  || Decoder Loss:  0.039095815 Validation Decoder Loss:  0.37387207
Encoder Loss:  0.05307964  || Decoder Loss:  0.038393598 Validation Decoder Loss:  0.37153548
Encoder Loss:  0.05210613  || Decoder Loss:  0.038090453 Validation Decoder Loss:  0.36793134
Encoder Loss:  0.05103742  || Decoder Loss:  0.03862284 Validation Decoder Loss:  0.3739668
Encoder Loss:  0.050860576  || Decoder Loss:  0.03835985 Validation Decoder Loss:  0.37231302
Encoder Loss:  0.052271172  || Decoder Loss:  0.038800746 Validation Decoder Loss:  0.37158757
Encoder Loss:  0.051141124  || Decoder Loss:  0.03804791 Validation Decoder Loss:  0.37475953
Encoder Loss:  0.050736543  || Decoder Loss:  0.03767065 Validation Decoder Loss:  0.37208602
Encoder Loss:  0.050837435  || Decoder Loss:  0.037887808 Validation Decoder Loss:  0.3715524
Encoder Loss:  0.051052712  || Decoder Loss:  0.037546337 Validation Decoder Loss:  0.37086397
Encoder Loss:  0.05083018  || Decoder Loss:  0.037227437 Validation Decoder Loss:  0.3727207
Encoder Loss:  0.05199799  || Decoder Loss:  0.037724018 Validation Decoder Loss:  0.37161875
Encoder Loss:  0.050856303  || Decoder Loss:  0.03731251 Validation Decoder Loss:  0.37047613
Encoder Loss:  0.051438533  || Decoder Loss:  0.03752049 Validation Decoder Loss:  0.371063
Encoder Loss:  0.050508905  || Decoder Loss:  0.036965646 Validation Decoder Loss:  0.3705206
Encoder Loss:  0.05095392  || Decoder Loss:  0.03703151 Validation Decoder Loss:  0.3712033
Encoder Loss:  0.050635546  || Decoder Loss:  0.03677582 Validation Decoder Loss:  0.37079063
Encoder Loss:  0.051626194  || Decoder Loss:  0.03690488 Validation Decoder Loss:  0.37045413
Encoder Loss:  0.05060473  || Decoder Loss:  0.03665543 Validation Decoder Loss:  0.37171084
Encoder Loss:  0.050771408  || Decoder Loss:  0.036652256 Validation Decoder Loss:  0.36993134
Encoder Loss:  0.050668456  || Decoder Loss:  0.036514312 Validation Decoder Loss:  0.37011978
Encoder Loss:  0.05080637  || Decoder Loss:  0.03645576 Validation Decoder Loss:  0.36906257
Encoder Loss:  0.050932255  || Decoder Loss:  0.036361374 Validation Decoder Loss:  0.36950317
Encoder Loss:  0.05055071  || Decoder Loss:  0.036276143 Validation Decoder Loss:  0.3687169
Encoder Loss:  0.0507609  || Decoder Loss:  0.036176298 Validation Decoder Loss:  0.36865658
Model: siamese_net_lr_0.36209223730267626 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36865658
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_56 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218043 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218032 Validation Decoder Loss:  0.33013794
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218043 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.330138
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218032 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218043 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218032 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218043 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218032 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013794
Encoder Loss:  0.21035427  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013794
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013794
Encoder Loss:  0.21035427  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035427  || Decoder Loss:  0.03621804 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Encoder Loss:  0.21035428  || Decoder Loss:  0.036218036 Validation Decoder Loss:  0.33013797
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33013797
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 257, 10, 20, 1)    263       
_________________________________________________________________
reshape_57 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03972306  || Decoder Loss:  0.03528858 Validation Decoder Loss:  0.33052993
Encoder Loss:  0.037136152  || Decoder Loss:  0.035221446 Validation Decoder Loss:  0.33019927
Encoder Loss:  0.037139736  || Decoder Loss:  0.035302427 Validation Decoder Loss:  0.33031255
Encoder Loss:  0.03704341  || Decoder Loss:  0.035348635 Validation Decoder Loss:  0.33049476
Encoder Loss:  0.036910597  || Decoder Loss:  0.035481866 Validation Decoder Loss:  0.33089507
Encoder Loss:  0.036968697  || Decoder Loss:  0.03548096 Validation Decoder Loss:  0.33133143
Encoder Loss:  0.037019297  || Decoder Loss:  0.0354825 Validation Decoder Loss:  0.33156148
Encoder Loss:  0.03686315  || Decoder Loss:  0.03541353 Validation Decoder Loss:  0.33217376
Encoder Loss:  0.03695332  || Decoder Loss:  0.03550085 Validation Decoder Loss:  0.33156955
Encoder Loss:  0.036819626  || Decoder Loss:  0.03542525 Validation Decoder Loss:  0.33146432
Encoder Loss:  0.037137978  || Decoder Loss:  0.035460994 Validation Decoder Loss:  0.33171824
Encoder Loss:  0.03691572  || Decoder Loss:  0.03545688 Validation Decoder Loss:  0.3317603
Encoder Loss:  0.037322503  || Decoder Loss:  0.035485886 Validation Decoder Loss:  0.33197945
Encoder Loss:  0.036788363  || Decoder Loss:  0.035427704 Validation Decoder Loss:  0.33177125
Encoder Loss:  0.036767963  || Decoder Loss:  0.035401154 Validation Decoder Loss:  0.3319431
Encoder Loss:  0.036809403  || Decoder Loss:  0.035416678 Validation Decoder Loss:  0.33194226
Encoder Loss:  0.036997497  || Decoder Loss:  0.03540601 Validation Decoder Loss:  0.33215198
Encoder Loss:  0.036826774  || Decoder Loss:  0.035413586 Validation Decoder Loss:  0.3320848
Encoder Loss:  0.036783233  || Decoder Loss:  0.035387643 Validation Decoder Loss:  0.33206797
Encoder Loss:  0.03680472  || Decoder Loss:  0.035408355 Validation Decoder Loss:  0.33201984
Encoder Loss:  0.03672321  || Decoder Loss:  0.035351887 Validation Decoder Loss:  0.33266428
Encoder Loss:  0.03674232  || Decoder Loss:  0.03535077 Validation Decoder Loss:  0.33254477
Encoder Loss:  0.036892615  || Decoder Loss:  0.035403296 Validation Decoder Loss:  0.33223066
Encoder Loss:  0.036728382  || Decoder Loss:  0.035363037 Validation Decoder Loss:  0.33224112
Encoder Loss:  0.03681398  || Decoder Loss:  0.035389975 Validation Decoder Loss:  0.33247095
Encoder Loss:  0.036713395  || Decoder Loss:  0.035348497 Validation Decoder Loss:  0.33261126
Encoder Loss:  0.03672153  || Decoder Loss:  0.03535451 Validation Decoder Loss:  0.33251634
Encoder Loss:  0.036857422  || Decoder Loss:  0.035352908 Validation Decoder Loss:  0.33281413
Encoder Loss:  0.036714874  || Decoder Loss:  0.03535904 Validation Decoder Loss:  0.33265853
Encoder Loss:  0.036723383  || Decoder Loss:  0.035353325 Validation Decoder Loss:  0.33241537
Encoder Loss:  0.036730926  || Decoder Loss:  0.035358775 Validation Decoder Loss:  0.33229107
Encoder Loss:  0.03675514  || Decoder Loss:  0.035366308 Validation Decoder Loss:  0.3324444
Encoder Loss:  0.03670411  || Decoder Loss:  0.035346102 Validation Decoder Loss:  0.33247977
Encoder Loss:  0.036714986  || Decoder Loss:  0.035344444 Validation Decoder Loss:  0.33244446
Encoder Loss:  0.03673602  || Decoder Loss:  0.035366666 Validation Decoder Loss:  0.33236396
Encoder Loss:  0.036727153  || Decoder Loss:  0.03535405 Validation Decoder Loss:  0.33235586
Encoder Loss:  0.03674773  || Decoder Loss:  0.035355087 Validation Decoder Loss:  0.33236313
Encoder Loss:  0.03677121  || Decoder Loss:  0.035368804 Validation Decoder Loss:  0.3323589
Encoder Loss:  0.03673508  || Decoder Loss:  0.03534749 Validation Decoder Loss:  0.33244967
Encoder Loss:  0.036691967  || Decoder Loss:  0.035329323 Validation Decoder Loss:  0.33293653
Model: siamese_net_lr_0.11066807894100995 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33293653
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_58 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.036681026 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222506  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.036681022 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222509  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Encoder Loss:  0.20222507  || Decoder Loss:  0.03668102 Validation Decoder Loss:  0.32673985
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32673985
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 257, 10, 20, 1)    31        
_________________________________________________________________
reshape_59 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867233  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867225  || Decoder Loss:  0.035867225 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586723  || Decoder Loss:  0.03586723 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.03586722  || Decoder Loss:  0.03586722 Validation Decoder Loss:  0.33169764
Encoder Loss:  0.035867233  || Decoder Loss:  0.035867233 Validation Decoder Loss:  0.33169764
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33169764
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 514, 5, 20, 1)     137       
_________________________________________________________________
reshape_60 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686504  || Decoder Loss:  0.035686504 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686515  || Decoder Loss:  0.035686515 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686515  || Decoder Loss:  0.035686515 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686523  || Decoder Loss:  0.035686523 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568651  || Decoder Loss:  0.03568651 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.03568652  || Decoder Loss:  0.03568652 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
Encoder Loss:  0.035686508  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33041954
2019-11-21 17:00:42.666970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33041954
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 257, 10, 20, 1)    787       
_________________________________________________________________
reshape_61 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [1.00000000e-14 1.00000000e+00 6.07441627e-01 5.47821315e-01
 4.51763363e-01 8.00000000e+00 2.57000000e+03]
Optimized Validation Decoder Loss: 0.3246876001358032











Optimizing at level  2
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 120, 10, 20, 1)    115       
_________________________________________________________________
dropout_186 (Dropout)        (None, 120, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_64 (Conv3DT (None, 257, 10, 20, 1)    139       
_________________________________________________________________
reshape_62 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 254
Trainable params: 254
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_188 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_63 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_190 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_63 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.046611458  || Decoder Loss:  0.03637573 Validation Decoder Loss:  0.32848155
Encoder Loss:  0.039095808  || Decoder Loss:  0.03484525 Validation Decoder Loss:  0.32841724
Encoder Loss:  0.039036255  || Decoder Loss:  0.034793627 Validation Decoder Loss:  0.32853186
Encoder Loss:  0.039011583  || Decoder Loss:  0.034772176 Validation Decoder Loss:  0.32862198
Encoder Loss:  0.039032105  || Decoder Loss:  0.03477883 Validation Decoder Loss:  0.32863104
Encoder Loss:  0.038998924  || Decoder Loss:  0.03476332 Validation Decoder Loss:  0.3287163
Encoder Loss:  0.040726412  || Decoder Loss:  0.034925565 Validation Decoder Loss:  0.32874522
Encoder Loss:  0.039043352  || Decoder Loss:  0.03482456 Validation Decoder Loss:  0.328757
Encoder Loss:  0.03902644  || Decoder Loss:  0.03479623 Validation Decoder Loss:  0.32878906
Encoder Loss:  0.039028097  || Decoder Loss:  0.03478885 Validation Decoder Loss:  0.328785
Encoder Loss:  0.03900921  || Decoder Loss:  0.034779824 Validation Decoder Loss:  0.3287577
Encoder Loss:  0.039008833  || Decoder Loss:  0.034773562 Validation Decoder Loss:  0.3287876
Encoder Loss:  0.039003946  || Decoder Loss:  0.03477005 Validation Decoder Loss:  0.32874194
Encoder Loss:  0.039000116  || Decoder Loss:  0.034766506 Validation Decoder Loss:  0.32876328
Encoder Loss:  0.038997915  || Decoder Loss:  0.03476173 Validation Decoder Loss:  0.32880992
Encoder Loss:  0.03900474  || Decoder Loss:  0.034767613 Validation Decoder Loss:  0.3288129
Encoder Loss:  0.0390144  || Decoder Loss:  0.034775287 Validation Decoder Loss:  0.32877
Encoder Loss:  0.039000716  || Decoder Loss:  0.034768894 Validation Decoder Loss:  0.32878202
Encoder Loss:  0.039023705  || Decoder Loss:  0.03477992 Validation Decoder Loss:  0.32880735
Encoder Loss:  0.03900502  || Decoder Loss:  0.03477452 Validation Decoder Loss:  0.32872885
Encoder Loss:  0.039025474  || Decoder Loss:  0.034781836 Validation Decoder Loss:  0.32885408
Encoder Loss:  0.039009012  || Decoder Loss:  0.03477914 Validation Decoder Loss:  0.3287655
Encoder Loss:  0.039003402  || Decoder Loss:  0.034773007 Validation Decoder Loss:  0.3288573
Encoder Loss:  0.039016657  || Decoder Loss:  0.0347799 Validation Decoder Loss:  0.32882005
Encoder Loss:  0.039006222  || Decoder Loss:  0.034777984 Validation Decoder Loss:  0.3287416
Encoder Loss:  0.039009735  || Decoder Loss:  0.03477818 Validation Decoder Loss:  0.32889062
Encoder Loss:  0.039005168  || Decoder Loss:  0.034775596 Validation Decoder Loss:  0.3288992
Encoder Loss:  0.039009415  || Decoder Loss:  0.03477799 Validation Decoder Loss:  0.3289572
Encoder Loss:  0.039014343  || Decoder Loss:  0.03478242 Validation Decoder Loss:  0.32881728
Encoder Loss:  0.0390102  || Decoder Loss:  0.034782596 Validation Decoder Loss:  0.32877952
Encoder Loss:  0.03900564  || Decoder Loss:  0.034778267 Validation Decoder Loss:  0.32908723
Encoder Loss:  0.039615814  || Decoder Loss:  0.03482297 Validation Decoder Loss:  0.32892898
Encoder Loss:  0.039022133  || Decoder Loss:  0.03480207 Validation Decoder Loss:  0.32890785
Encoder Loss:  0.039022323  || Decoder Loss:  0.034797017 Validation Decoder Loss:  0.32895505
Encoder Loss:  0.0390202  || Decoder Loss:  0.03479506 Validation Decoder Loss:  0.32898176
Encoder Loss:  0.03901721  || Decoder Loss:  0.034792036 Validation Decoder Loss:  0.32900947
Encoder Loss:  0.039021503  || Decoder Loss:  0.034794055 Validation Decoder Loss:  0.3289449
Encoder Loss:  0.039016455  || Decoder Loss:  0.034789957 Validation Decoder Loss:  0.32896477
Encoder Loss:  0.039014727  || Decoder Loss:  0.034788717 Validation Decoder Loss:  0.32889742
Encoder Loss:  0.039012175  || Decoder Loss:  0.034786135 Validation Decoder Loss:  0.3288953
Model: siamese_net_lr_0.013625137942066974 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3288953
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 235, 10, 20, 1)    219       
_________________________________________________________________
dropout_192 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_67 (Conv3DT (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_63 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 243
Trainable params: 243
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_194 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_65 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_196 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_65 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19060048  || Decoder Loss:  0.06707609 Validation Decoder Loss:  0.34953463
Encoder Loss:  0.051758956  || Decoder Loss:  0.070265405 Validation Decoder Loss:  0.34805998
Encoder Loss:  0.05142729  || Decoder Loss:  0.06835328 Validation Decoder Loss:  0.34653318
Encoder Loss:  0.05134579  || Decoder Loss:  0.06728129 Validation Decoder Loss:  0.34618372
Encoder Loss:  0.052290723  || Decoder Loss:  0.069212385 Validation Decoder Loss:  0.34607473
Encoder Loss:  0.05143998  || Decoder Loss:  0.06854653 Validation Decoder Loss:  0.34521633
Encoder Loss:  0.051246252  || Decoder Loss:  0.06755644 Validation Decoder Loss:  0.34585702
Encoder Loss:  0.0511692  || Decoder Loss:  0.06662185 Validation Decoder Loss:  0.34666258
Encoder Loss:  0.051119346  || Decoder Loss:  0.06588535 Validation Decoder Loss:  0.34817627
Encoder Loss:  0.052083116  || Decoder Loss:  0.06685504 Validation Decoder Loss:  0.3494658
Encoder Loss:  0.05288008  || Decoder Loss:  0.08165122 Validation Decoder Loss:  0.36043668
Encoder Loss:  0.07028924  || Decoder Loss:  0.3175624 Validation Decoder Loss:  0.68826205
Encoder Loss:  0.063115194  || Decoder Loss:  0.24282624 Validation Decoder Loss:  0.33122468
Encoder Loss:  0.049056478  || Decoder Loss:  0.035580616 Validation Decoder Loss:  0.33092582
Encoder Loss:  0.049043924  || Decoder Loss:  0.035515945 Validation Decoder Loss:  0.3306723
Encoder Loss:  0.04903804  || Decoder Loss:  0.035476457 Validation Decoder Loss:  0.33057836
Encoder Loss:  0.04903519  || Decoder Loss:  0.03543851 Validation Decoder Loss:  0.33063483
Encoder Loss:  0.04902998  || Decoder Loss:  0.035400428 Validation Decoder Loss:  0.33052272
Encoder Loss:  0.04902674  || Decoder Loss:  0.035363127 Validation Decoder Loss:  0.33044013
Encoder Loss:  0.049021386  || Decoder Loss:  0.035329722 Validation Decoder Loss:  0.33046156
Encoder Loss:  0.04902256  || Decoder Loss:  0.03538944 Validation Decoder Loss:  0.33052295
Encoder Loss:  0.049032915  || Decoder Loss:  0.035399567 Validation Decoder Loss:  0.32937592
Encoder Loss:  0.04902549  || Decoder Loss:  0.035431355 Validation Decoder Loss:  0.32995403
Encoder Loss:  0.049025796  || Decoder Loss:  0.035483275 Validation Decoder Loss:  0.32966834
Encoder Loss:  0.049033895  || Decoder Loss:  0.03557015 Validation Decoder Loss:  0.32712138
Encoder Loss:  0.04903271  || Decoder Loss:  0.035575915 Validation Decoder Loss:  0.327547
Encoder Loss:  0.049038425  || Decoder Loss:  0.035619628 Validation Decoder Loss:  0.32846612
Encoder Loss:  0.049048558  || Decoder Loss:  0.035632577 Validation Decoder Loss:  0.3284579
Encoder Loss:  0.049091134  || Decoder Loss:  0.03570393 Validation Decoder Loss:  0.32741815
Encoder Loss:  0.049048904  || Decoder Loss:  0.035680756 Validation Decoder Loss:  0.3282843
Encoder Loss:  0.049056754  || Decoder Loss:  0.035610463 Validation Decoder Loss:  0.3294459
Encoder Loss:  0.105092436  || Decoder Loss:  0.16395015 Validation Decoder Loss:  0.5445455
Encoder Loss:  0.057278603  || Decoder Loss:  0.15708867 Validation Decoder Loss:  0.5461714
Encoder Loss:  0.057268742  || Decoder Loss:  0.15707608 Validation Decoder Loss:  0.545631
Encoder Loss:  0.057255987  || Decoder Loss:  0.15692207 Validation Decoder Loss:  0.5452097
Encoder Loss:  0.057239477  || Decoder Loss:  0.15671054 Validation Decoder Loss:  0.54479736
Encoder Loss:  0.057230026  || Decoder Loss:  0.15659003 Validation Decoder Loss:  0.5445261
Encoder Loss:  0.057223316  || Decoder Loss:  0.15650526 Validation Decoder Loss:  0.5443587
Encoder Loss:  0.05721837  || Decoder Loss:  0.15644844 Validation Decoder Loss:  0.5442391
Encoder Loss:  0.05721627  || Decoder Loss:  0.15642732 Validation Decoder Loss:  0.54413533
Model: siamese_net_lr_0.8948574696342342 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.54413533
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 80, 7, 20, 1)      52        
_________________________________________________________________
dropout_198 (Dropout)        (None, 80, 7, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_70 (Conv3DT (None, 257, 10, 20, 1)    397       
_________________________________________________________________
reshape_64 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 449
Trainable params: 449
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_200 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_67 (Conv2D)           (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_202 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_67 (Conv2DT (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.420151  || Decoder Loss:  0.4818543 Validation Decoder Loss:  0.9755481
Encoder Loss:  0.42522085  || Decoder Loss:  0.48879027 Validation Decoder Loss:  1.0614235
Encoder Loss:  0.43387058  || Decoder Loss:  0.49932662 Validation Decoder Loss:  0.9987275
Encoder Loss:  0.4308978  || Decoder Loss:  0.4963863 Validation Decoder Loss:  0.98842263
Encoder Loss:  0.42756003  || Decoder Loss:  0.49243993 Validation Decoder Loss:  1.0918441
Encoder Loss:  0.43528095  || Decoder Loss:  0.5009828 Validation Decoder Loss:  1.008464
Encoder Loss:  0.4317811  || Decoder Loss:  0.49743012 Validation Decoder Loss:  1.0061412
Encoder Loss:  0.43169793  || Decoder Loss:  0.49732587 Validation Decoder Loss:  1.0014207
Encoder Loss:  0.4316696  || Decoder Loss:  0.49714306 Validation Decoder Loss:  1.0040445
Encoder Loss:  0.4320195  || Decoder Loss:  0.49767184 Validation Decoder Loss:  1.0086694
Encoder Loss:  0.4318671  || Decoder Loss:  0.4974694 Validation Decoder Loss:  1.0034891
Encoder Loss:  0.43191156  || Decoder Loss:  0.49757043 Validation Decoder Loss:  1.0075703
Encoder Loss:  0.43147996  || Decoder Loss:  0.4970553 Validation Decoder Loss:  0.98899066
Encoder Loss:  0.432868  || Decoder Loss:  0.4986 Validation Decoder Loss:  1.0053053
Encoder Loss:  0.43207398  || Decoder Loss:  0.49772912 Validation Decoder Loss:  1.0046765
Encoder Loss:  0.43214324  || Decoder Loss:  0.49763814 Validation Decoder Loss:  1.0065113
Encoder Loss:  0.4318472  || Decoder Loss:  0.49750397 Validation Decoder Loss:  1.0035377
Encoder Loss:  0.43176094  || Decoder Loss:  0.4974116 Validation Decoder Loss:  1.0073307
Encoder Loss:  0.42961326  || Decoder Loss:  0.49487537 Validation Decoder Loss:  0.98699087
Encoder Loss:  0.434814  || Decoder Loss:  0.50088006 Validation Decoder Loss:  0.9996611
Encoder Loss:  0.43214896  || Decoder Loss:  0.49782765 Validation Decoder Loss:  1.0095456
Encoder Loss:  0.43169343  || Decoder Loss:  0.4973211 Validation Decoder Loss:  1.0046775
Encoder Loss:  0.43246758  || Decoder Loss:  0.498229 Validation Decoder Loss:  1.0052711
Encoder Loss:  0.43209076  || Decoder Loss:  0.49777102 Validation Decoder Loss:  1.0029285
Encoder Loss:  0.43219203  || Decoder Loss:  0.49784482 Validation Decoder Loss:  1.0026289
Encoder Loss:  0.43187532  || Decoder Loss:  0.49754193 Validation Decoder Loss:  1.0017151
Encoder Loss:  0.4321255  || Decoder Loss:  0.49774104 Validation Decoder Loss:  1.003968
Encoder Loss:  0.43161416  || Decoder Loss:  0.4972324 Validation Decoder Loss:  1.0027715
Encoder Loss:  0.43177617  || Decoder Loss:  0.4974267 Validation Decoder Loss:  1.0091834
Encoder Loss:  0.43499196  || Decoder Loss:  0.5011065 Validation Decoder Loss:  1.0076623
Encoder Loss:  0.43286282  || Decoder Loss:  0.4986917 Validation Decoder Loss:  1.0004683
Encoder Loss:  0.43178046  || Decoder Loss:  0.4974061 Validation Decoder Loss:  1.020812
Encoder Loss:  0.43208855  || Decoder Loss:  0.4977068 Validation Decoder Loss:  1.0034695
Encoder Loss:  0.4327049  || Decoder Loss:  0.49849525 Validation Decoder Loss:  1.0050659
Encoder Loss:  0.43195626  || Decoder Loss:  0.49762484 Validation Decoder Loss:  0.9997488
Encoder Loss:  0.4321936  || Decoder Loss:  0.4978912 Validation Decoder Loss:  1.0045288
Encoder Loss:  0.43188953  || Decoder Loss:  0.4975431 Validation Decoder Loss:  1.0061798
Encoder Loss:  0.4318544  || Decoder Loss:  0.49751556 Validation Decoder Loss:  1.0050777
Encoder Loss:  0.42519778  || Decoder Loss:  0.48971096 Validation Decoder Loss:  0.9628782
Encoder Loss:  0.40680733  || Decoder Loss:  0.4681422 Validation Decoder Loss:  0.6091466
Model: siamese_net_lr_0.3175071921939762 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.6091466
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 151, 10, 20, 1)    529       
_________________________________________________________________
dropout_204 (Dropout)        (None, 151, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_73 (Conv3DT (None, 257, 10, 20, 1)    108       
_________________________________________________________________
reshape_65 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 637
Trainable params: 637
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_206 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_69 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_208 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_69 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.106395856  || Decoder Loss:  0.48593408 Validation Decoder Loss:  1.001042
Encoder Loss:  0.06631736  || Decoder Loss:  0.50238734 Validation Decoder Loss:  0.9886765
Encoder Loss:  0.06575217  || Decoder Loss:  0.49696144 Validation Decoder Loss:  0.97717965
Encoder Loss:  0.06564784  || Decoder Loss:  0.4943709 Validation Decoder Loss:  0.97878814
Encoder Loss:  0.065668195  || Decoder Loss:  0.49520788 Validation Decoder Loss:  0.97901535
Encoder Loss:  0.06566452  || Decoder Loss:  0.4951661 Validation Decoder Loss:  0.9787835
Encoder Loss:  0.065653354  || Decoder Loss:  0.4948906 Validation Decoder Loss:  0.9783613
Encoder Loss:  0.065636046  || Decoder Loss:  0.49436894 Validation Decoder Loss:  0.9773793
Encoder Loss:  0.06549538  || Decoder Loss:  0.49038762 Validation Decoder Loss:  0.9635339
Encoder Loss:  0.06551492  || Decoder Loss:  0.49096885 Validation Decoder Loss:  0.97901046
Encoder Loss:  0.065672055  || Decoder Loss:  0.4953714 Validation Decoder Loss:  0.9789278
Encoder Loss:  0.06566871  || Decoder Loss:  0.49532956 Validation Decoder Loss:  0.9788446
Encoder Loss:  0.065668896  || Decoder Loss:  0.4952879 Validation Decoder Loss:  0.97871184
Encoder Loss:  0.06566462  || Decoder Loss:  0.49521923 Validation Decoder Loss:  0.97857064
Encoder Loss:  0.0656653  || Decoder Loss:  0.4951457 Validation Decoder Loss:  0.97841954
Encoder Loss:  0.065658174  || Decoder Loss:  0.49506813 Validation Decoder Loss:  0.97829163
Encoder Loss:  0.06565507  || Decoder Loss:  0.49499077 Validation Decoder Loss:  0.9782022
Encoder Loss:  0.06564948  || Decoder Loss:  0.49489957 Validation Decoder Loss:  0.97818494
Encoder Loss:  0.06564897  || Decoder Loss:  0.49483204 Validation Decoder Loss:  0.9781587
Encoder Loss:  0.06564556  || Decoder Loss:  0.49474555 Validation Decoder Loss:  0.9781443
Encoder Loss:  0.06564243  || Decoder Loss:  0.4946518 Validation Decoder Loss:  0.9781644
Encoder Loss:  0.06564235  || Decoder Loss:  0.49456027 Validation Decoder Loss:  0.9782332
Encoder Loss:  0.0656369  || Decoder Loss:  0.4944357 Validation Decoder Loss:  0.9783137
Encoder Loss:  0.06562971  || Decoder Loss:  0.49432826 Validation Decoder Loss:  0.9785738
Encoder Loss:  0.06562278  || Decoder Loss:  0.4941887 Validation Decoder Loss:  0.9791081
Encoder Loss:  0.06561459  || Decoder Loss:  0.49398005 Validation Decoder Loss:  0.9803239
Encoder Loss:  0.06559648  || Decoder Loss:  0.49343812 Validation Decoder Loss:  0.9938834
Encoder Loss:  0.06549685  || Decoder Loss:  0.49063522 Validation Decoder Loss:  0.9867799
Encoder Loss:  0.06554539  || Decoder Loss:  0.49199185 Validation Decoder Loss:  0.9877479
Encoder Loss:  0.065529354  || Decoder Loss:  0.4915443 Validation Decoder Loss:  0.9985698
Encoder Loss:  0.06545843  || Decoder Loss:  0.48951492 Validation Decoder Loss:  1.0291636
Encoder Loss:  0.06544225  || Decoder Loss:  0.48900804 Validation Decoder Loss:  1.0577872
Encoder Loss:  0.06545887  || Decoder Loss:  0.48946363 Validation Decoder Loss:  1.0558581
Encoder Loss:  0.06548275  || Decoder Loss:  0.4902183 Validation Decoder Loss:  1.0302777
Encoder Loss:  0.06545459  || Decoder Loss:  0.4894313 Validation Decoder Loss:  1.0512699
Encoder Loss:  0.065453395  || Decoder Loss:  0.48938474 Validation Decoder Loss:  1.0462563
Encoder Loss:  0.06544249  || Decoder Loss:  0.48909855 Validation Decoder Loss:  1.053287
Encoder Loss:  0.065440446  || Decoder Loss:  0.48902407 Validation Decoder Loss:  1.0511099
Encoder Loss:  0.06543261  || Decoder Loss:  0.48880517 Validation Decoder Loss:  1.0501875
Encoder Loss:  0.06542303  || Decoder Loss:  0.48853287 Validation Decoder Loss:  1.048164
Model: siamese_net_lr_0.37264348372985584 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.048164
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_210 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_76 (Conv3DT (None, 257, 10, 20, 1)    138       
_________________________________________________________________
reshape_66 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 487
Trainable params: 487
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_212 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_71 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_214 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_71 (Conv2DT (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.436997  || Decoder Loss:  0.48513123 Validation Decoder Loss:  0.887056
Encoder Loss:  0.44533816  || Decoder Loss:  0.49601117 Validation Decoder Loss:  0.9289907
Encoder Loss:  0.42375755  || Decoder Loss:  0.4718161 Validation Decoder Loss:  1.0742315
Encoder Loss:  0.43317196  || Decoder Loss:  0.48246297 Validation Decoder Loss:  1.0374949
Encoder Loss:  0.42977944  || Decoder Loss:  0.47863692 Validation Decoder Loss:  0.8797355
Encoder Loss:  0.4338581  || Decoder Loss:  0.4832418 Validation Decoder Loss:  1.032176
Encoder Loss:  0.43367565  || Decoder Loss:  0.48305485 Validation Decoder Loss:  1.1840513
Encoder Loss:  0.4222326  || Decoder Loss:  0.47013882 Validation Decoder Loss:  1.0800855
Encoder Loss:  0.33047432  || Decoder Loss:  0.3665741 Validation Decoder Loss:  0.7492783
Encoder Loss:  0.17627087  || Decoder Loss:  0.19249564 Validation Decoder Loss:  0.5440913
Encoder Loss:  0.100454286  || Decoder Loss:  0.10692367 Validation Decoder Loss:  0.3832916
Encoder Loss:  0.111875236  || Decoder Loss:  0.11981239 Validation Decoder Loss:  0.32402328
Encoder Loss:  0.0993031  || Decoder Loss:  0.10562512 Validation Decoder Loss:  0.32792395
Encoder Loss:  0.2522473  || Decoder Loss:  0.27827102 Validation Decoder Loss:  0.70101273
Encoder Loss:  0.090007536  || Decoder Loss:  0.0951239 Validation Decoder Loss:  0.35259935
Encoder Loss:  0.07100584  || Decoder Loss:  0.07369511 Validation Decoder Loss:  0.36617243
Encoder Loss:  0.054986645  || Decoder Loss:  0.055607747 Validation Decoder Loss:  0.39878938
Encoder Loss:  0.08427893  || Decoder Loss:  0.088669516 Validation Decoder Loss:  0.35693523
Encoder Loss:  0.096482016  || Decoder Loss:  0.10244965 Validation Decoder Loss:  0.6391505
Encoder Loss:  0.14848922  || Decoder Loss:  0.16112272 Validation Decoder Loss:  0.34249786
Encoder Loss:  0.0471467  || Decoder Loss:  0.04676936 Validation Decoder Loss:  0.2748434
Encoder Loss:  0.05034739  || Decoder Loss:  0.050379414 Validation Decoder Loss:  0.3219843
Encoder Loss:  0.045293503  || Decoder Loss:  0.04468055 Validation Decoder Loss:  0.3288434
Encoder Loss:  0.0461048  || Decoder Loss:  0.04560031 Validation Decoder Loss:  0.41993225
Encoder Loss:  0.039278388  || Decoder Loss:  0.03789455 Validation Decoder Loss:  0.36255533
Encoder Loss:  0.06872754  || Decoder Loss:  0.071137555 Validation Decoder Loss:  0.34364098
Encoder Loss:  0.106877714  || Decoder Loss:  0.11419285 Validation Decoder Loss:  0.35397673
Encoder Loss:  0.03791669  || Decoder Loss:  0.036359455 Validation Decoder Loss:  0.33351693
Encoder Loss:  0.04095303  || Decoder Loss:  0.039786685 Validation Decoder Loss:  0.33145043
Encoder Loss:  0.038947877  || Decoder Loss:  0.03752324 Validation Decoder Loss:  0.33126634
Encoder Loss:  0.14019124  || Decoder Loss:  0.1517839 Validation Decoder Loss:  0.33877516
Encoder Loss:  0.070183225  || Decoder Loss:  0.07278289 Validation Decoder Loss:  0.34073445
Encoder Loss:  0.04241938  || Decoder Loss:  0.041442502 Validation Decoder Loss:  0.3385151
Encoder Loss:  0.04265653  || Decoder Loss:  0.041710213 Validation Decoder Loss:  0.3207263
Encoder Loss:  0.042131085  || Decoder Loss:  0.041116886 Validation Decoder Loss:  0.36682564
Encoder Loss:  0.03880673  || Decoder Loss:  0.037364174 Validation Decoder Loss:  0.2986866
Encoder Loss:  0.09287656  || Decoder Loss:  0.09839889 Validation Decoder Loss:  0.33459693
Encoder Loss:  0.04820739  || Decoder Loss:  0.04797571 Validation Decoder Loss:  0.33340013
Encoder Loss:  0.06659458  || Decoder Loss:  0.06873142 Validation Decoder Loss:  0.33443803
Encoder Loss:  0.05674665  || Decoder Loss:  0.057615414 Validation Decoder Loss:  0.34560502
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.4642202544622248 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34560502
Started Optimization Process
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 235, 10, 20, 1)    345       
_________________________________________________________________
dropout_216 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_79 (Conv3DT (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_67 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 369
Trainable params: 369
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_218 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_73 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_220 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_73 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2901584  || Decoder Loss:  0.498901 Validation Decoder Loss:  0.84789276
Encoder Loss:  0.26512071  || Decoder Loss:  0.48760906 Validation Decoder Loss:  0.85030496
Encoder Loss:  0.26180014  || Decoder Loss:  0.48141804 Validation Decoder Loss:  0.79373
Encoder Loss:  0.26358756  || Decoder Loss:  0.48512536 Validation Decoder Loss:  1.1878238
Encoder Loss:  0.10152938  || Decoder Loss:  0.15496807 Validation Decoder Loss:  0.31424052
Encoder Loss:  0.043783356  || Decoder Loss:  0.03732101 Validation Decoder Loss:  0.31528437
Encoder Loss:  0.043665253  || Decoder Loss:  0.037081726 Validation Decoder Loss:  0.31612682
Encoder Loss:  0.04358332  || Decoder Loss:  0.03691168 Validation Decoder Loss:  0.31654412
Encoder Loss:  0.043515176  || Decoder Loss:  0.036771394 Validation Decoder Loss:  0.31729943
Encoder Loss:  0.043441363  || Decoder Loss:  0.03662246 Validation Decoder Loss:  0.31772766
Encoder Loss:  0.04340029  || Decoder Loss:  0.036527585 Validation Decoder Loss:  0.31890708
Encoder Loss:  0.04337808  || Decoder Loss:  0.03648669 Validation Decoder Loss:  0.31936756
Encoder Loss:  0.043381874  || Decoder Loss:  0.036488935 Validation Decoder Loss:  0.31938905
Encoder Loss:  0.043315962  || Decoder Loss:  0.03636034 Validation Decoder Loss:  0.31975034
Encoder Loss:  0.05356812  || Decoder Loss:  0.055152416 Validation Decoder Loss:  0.3189061
Encoder Loss:  0.043443047  || Decoder Loss:  0.03663121 Validation Decoder Loss:  0.3180741
Encoder Loss:  0.043447047  || Decoder Loss:  0.03663969 Validation Decoder Loss:  0.3172778
Encoder Loss:  0.04350867  || Decoder Loss:  0.03676245 Validation Decoder Loss:  0.31794128
Encoder Loss:  0.04342997  || Decoder Loss:  0.03660606 Validation Decoder Loss:  0.31885588
Encoder Loss:  0.043461934  || Decoder Loss:  0.03666587 Validation Decoder Loss:  0.31912208
Encoder Loss:  0.043398023  || Decoder Loss:  0.036540084 Validation Decoder Loss:  0.31909516
Encoder Loss:  0.043389726  || Decoder Loss:  0.036519922 Validation Decoder Loss:  0.31962872
Encoder Loss:  0.043374192  || Decoder Loss:  0.036488786 Validation Decoder Loss:  0.3194072
Encoder Loss:  0.043306883  || Decoder Loss:  0.03635398 Validation Decoder Loss:  0.31991422
Encoder Loss:  0.043575305  || Decoder Loss:  0.036840446 Validation Decoder Loss:  0.3187819
Encoder Loss:  0.04340887  || Decoder Loss:  0.03654226 Validation Decoder Loss:  0.31983408
Encoder Loss:  0.043200526  || Decoder Loss:  0.036137953 Validation Decoder Loss:  0.32115856
Encoder Loss:  0.043332987  || Decoder Loss:  0.036396667 Validation Decoder Loss:  0.32081932
Encoder Loss:  0.04339971  || Decoder Loss:  0.036520373 Validation Decoder Loss:  0.3185605
Encoder Loss:  0.22618833  || Decoder Loss:  0.37849614 Validation Decoder Loss:  0.8165604
Encoder Loss:  0.04897453  || Decoder Loss:  0.045942686 Validation Decoder Loss:  0.3459381
Encoder Loss:  0.044500228  || Decoder Loss:  0.03792415 Validation Decoder Loss:  0.3486741
Encoder Loss:  0.04466848  || Decoder Loss:  0.03822404 Validation Decoder Loss:  0.34329468
Encoder Loss:  0.04449266  || Decoder Loss:  0.03796077 Validation Decoder Loss:  0.34646046
Encoder Loss:  0.044820935  || Decoder Loss:  0.038478993 Validation Decoder Loss:  0.3508609
Encoder Loss:  0.044403575  || Decoder Loss:  0.037902996 Validation Decoder Loss:  0.34772295
Encoder Loss:  0.04418303  || Decoder Loss:  0.037820686 Validation Decoder Loss:  0.31734064
Encoder Loss:  0.043749873  || Decoder Loss:  0.037182037 Validation Decoder Loss:  0.31897345
Encoder Loss:  0.04359045  || Decoder Loss:  0.036896855 Validation Decoder Loss:  0.3198318
Encoder Loss:  0.043532196  || Decoder Loss:  0.036794353 Validation Decoder Loss:  0.32001454
Model: siamese_net_lr_0.6073039083284718 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32001454
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 235, 10, 20, 1)    1033      
_________________________________________________________________
dropout_222 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_82 (Conv3DT (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_68 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_224 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_75 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_226 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_75 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28183118  || Decoder Loss:  0.47665024 Validation Decoder Loss:  1.0563533
Encoder Loss:  0.27507827  || Decoder Loss:  0.4834389 Validation Decoder Loss:  1.0726609
Encoder Loss:  0.2693434  || Decoder Loss:  0.47922367 Validation Decoder Loss:  0.9493537
Encoder Loss:  0.20703882  || Decoder Loss:  0.36304963 Validation Decoder Loss:  0.33697897
Encoder Loss:  0.04813623  || Decoder Loss:  0.045454055 Validation Decoder Loss:  0.3461607
Encoder Loss:  0.04676621  || Decoder Loss:  0.042650536 Validation Decoder Loss:  0.34639996
Encoder Loss:  0.04568705  || Decoder Loss:  0.040778503 Validation Decoder Loss:  0.34420413
Encoder Loss:  0.045213655  || Decoder Loss:  0.039931625 Validation Decoder Loss:  0.34308264
Encoder Loss:  0.04476052  || Decoder Loss:  0.039130796 Validation Decoder Loss:  0.3422871
Encoder Loss:  0.048227254  || Decoder Loss:  0.04512755 Validation Decoder Loss:  0.34590495
Encoder Loss:  0.045044076  || Decoder Loss:  0.039722424 Validation Decoder Loss:  0.3422364
Encoder Loss:  0.04537192  || Decoder Loss:  0.040182058 Validation Decoder Loss:  0.34407762
Encoder Loss:  0.04680504  || Decoder Loss:  0.042204365 Validation Decoder Loss:  0.34449676
Encoder Loss:  0.045288287  || Decoder Loss:  0.04002902 Validation Decoder Loss:  0.34323004
Encoder Loss:  0.04433027  || Decoder Loss:  0.03851218 Validation Decoder Loss:  0.34017834
Encoder Loss:  0.044020247  || Decoder Loss:  0.03792712 Validation Decoder Loss:  0.33890992
Encoder Loss:  0.043854326  || Decoder Loss:  0.037612192 Validation Decoder Loss:  0.33812237
Encoder Loss:  0.043740865  || Decoder Loss:  0.037376992 Validation Decoder Loss:  0.33768585
Encoder Loss:  0.043676343  || Decoder Loss:  0.037245166 Validation Decoder Loss:  0.33755884
Encoder Loss:  0.043595847  || Decoder Loss:  0.037091993 Validation Decoder Loss:  0.33765975
Encoder Loss:  0.043584757  || Decoder Loss:  0.037062462 Validation Decoder Loss:  0.32919934
Encoder Loss:  0.043850996  || Decoder Loss:  0.037561145 Validation Decoder Loss:  0.33780372
Encoder Loss:  0.04359799  || Decoder Loss:  0.037097346 Validation Decoder Loss:  0.3293171
Encoder Loss:  0.043486167  || Decoder Loss:  0.03688139 Validation Decoder Loss:  0.3288803
Encoder Loss:  0.04340529  || Decoder Loss:  0.036717217 Validation Decoder Loss:  0.3285506
Encoder Loss:  0.043392267  || Decoder Loss:  0.0366948 Validation Decoder Loss:  0.32744956
Encoder Loss:  0.043318905  || Decoder Loss:  0.036560073 Validation Decoder Loss:  0.32683265
Encoder Loss:  0.04325266  || Decoder Loss:  0.036426846 Validation Decoder Loss:  0.32777506
Encoder Loss:  0.043093204  || Decoder Loss:  0.036114212 Validation Decoder Loss:  0.3277033
Encoder Loss:  0.043134123  || Decoder Loss:  0.036200605 Validation Decoder Loss:  0.32731405
Encoder Loss:  0.043061994  || Decoder Loss:  0.036052126 Validation Decoder Loss:  0.32848275
Encoder Loss:  0.04306429  || Decoder Loss:  0.036062036 Validation Decoder Loss:  0.32739285
Encoder Loss:  0.043055706  || Decoder Loss:  0.036038317 Validation Decoder Loss:  0.32747364
Encoder Loss:  0.043525048  || Decoder Loss:  0.036972806 Validation Decoder Loss:  0.32674703
Encoder Loss:  0.043015756  || Decoder Loss:  0.03595683 Validation Decoder Loss:  0.3272853
Encoder Loss:  0.043069545  || Decoder Loss:  0.03607079 Validation Decoder Loss:  0.32728785
Encoder Loss:  0.042984113  || Decoder Loss:  0.03590385 Validation Decoder Loss:  0.32775152
Encoder Loss:  0.042967886  || Decoder Loss:  0.035872765 Validation Decoder Loss:  0.32782638
Encoder Loss:  0.0470976  || Decoder Loss:  0.041653037 Validation Decoder Loss:  0.3391061
Encoder Loss:  0.04433581  || Decoder Loss:  0.037954714 Validation Decoder Loss:  0.33805567
Model: siamese_net_lr_0.6056449279005478 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33805567
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 235, 10, 20, 1)    1033      
_________________________________________________________________
dropout_228 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_85 (Conv3DT (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_69 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_230 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_77 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_232 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_77 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.085512914  || Decoder Loss:  0.47134218 Validation Decoder Loss:  0.64139134
Encoder Loss:  0.06616283  || Decoder Loss:  0.48788536 Validation Decoder Loss:  0.6974528
Encoder Loss:  0.061548203  || Decoder Loss:  0.4951506 Validation Decoder Loss:  1.1357598
Encoder Loss:  0.053810578  || Decoder Loss:  0.499138 Validation Decoder Loss:  1.2381139
Encoder Loss:  0.05369816  || Decoder Loss:  0.4961586 Validation Decoder Loss:  1.0297225
Encoder Loss:  0.053586844  || Decoder Loss:  0.4938526 Validation Decoder Loss:  1.0659537
Encoder Loss:  0.052384034  || Decoder Loss:  0.49303994 Validation Decoder Loss:  1.044343
Encoder Loss:  0.051972665  || Decoder Loss:  0.49237102 Validation Decoder Loss:  1.0658963
Encoder Loss:  0.050994255  || Decoder Loss:  0.49221942 Validation Decoder Loss:  1.0617751
Encoder Loss:  0.050560523  || Decoder Loss:  0.4740859 Validation Decoder Loss:  1.0047572
Encoder Loss:  0.051439043  || Decoder Loss:  0.47085023 Validation Decoder Loss:  0.9966151
Encoder Loss:  0.050387856  || Decoder Loss:  0.48905572 Validation Decoder Loss:  0.8355088
Encoder Loss:  0.05058357  || Decoder Loss:  0.5013615 Validation Decoder Loss:  0.81060696
Encoder Loss:  0.05202043  || Decoder Loss:  0.5011306 Validation Decoder Loss:  0.8807234
Encoder Loss:  0.050571576  || Decoder Loss:  0.49677506 Validation Decoder Loss:  1.0371759
Encoder Loss:  0.05035697  || Decoder Loss:  0.49602246 Validation Decoder Loss:  1.0335817
Encoder Loss:  0.050330304  || Decoder Loss:  0.49559543 Validation Decoder Loss:  1.0318503
Encoder Loss:  0.050866768  || Decoder Loss:  0.49526963 Validation Decoder Loss:  1.0334501
Encoder Loss:  0.050360214  || Decoder Loss:  0.49478203 Validation Decoder Loss:  1.0287693
Encoder Loss:  0.05045175  || Decoder Loss:  0.49374753 Validation Decoder Loss:  1.0394372
Encoder Loss:  0.050297704  || Decoder Loss:  0.49147528 Validation Decoder Loss:  1.0367873
Encoder Loss:  0.05040244  || Decoder Loss:  0.479885 Validation Decoder Loss:  1.0195029
Encoder Loss:  0.050404698  || Decoder Loss:  0.47899467 Validation Decoder Loss:  1.0008779
Encoder Loss:  0.05035741  || Decoder Loss:  0.4938494 Validation Decoder Loss:  1.0023263
Encoder Loss:  0.05107301  || Decoder Loss:  0.48400384 Validation Decoder Loss:  0.86559916
Encoder Loss:  0.05016135  || Decoder Loss:  0.50134367 Validation Decoder Loss:  0.8569271
Encoder Loss:  0.050321173  || Decoder Loss:  0.50002235 Validation Decoder Loss:  0.8934393
Encoder Loss:  0.050173815  || Decoder Loss:  0.49701637 Validation Decoder Loss:  1.0023973
Encoder Loss:  0.051423136  || Decoder Loss:  0.49694553 Validation Decoder Loss:  1.0669937
Encoder Loss:  0.05003335  || Decoder Loss:  0.49650612 Validation Decoder Loss:  1.0659735
Encoder Loss:  0.05002534  || Decoder Loss:  0.49624103 Validation Decoder Loss:  1.0651087
Encoder Loss:  0.05002351  || Decoder Loss:  0.4957188 Validation Decoder Loss:  1.0675402
Encoder Loss:  0.050021697  || Decoder Loss:  0.49473998 Validation Decoder Loss:  1.0691135
Encoder Loss:  0.05002236  || Decoder Loss:  0.4937489 Validation Decoder Loss:  1.0623002
Encoder Loss:  0.050020672  || Decoder Loss:  0.49024403 Validation Decoder Loss:  1.0318346
Encoder Loss:  0.050021067  || Decoder Loss:  0.486525 Validation Decoder Loss:  1.0286294
Encoder Loss:  0.050017353  || Decoder Loss:  0.48677585 Validation Decoder Loss:  1.028051
Encoder Loss:  0.050015975  || Decoder Loss:  0.49650273 Validation Decoder Loss:  0.8793738
Encoder Loss:  0.050014067  || Decoder Loss:  0.49638736 Validation Decoder Loss:  1.0183183
Encoder Loss:  0.050010096  || Decoder Loss:  0.4892259 Validation Decoder Loss:  1.0151501
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0151501
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 235, 10, 20, 1)    219       
_________________________________________________________________
dropout_234 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_88 (Conv3DT (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_70 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 243
Trainable params: 243
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_236 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_79 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_238 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_79 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.071486  || Decoder Loss:  0.07197519 Validation Decoder Loss:  0.32337618
Encoder Loss:  0.043033544  || Decoder Loss:  0.037631847 Validation Decoder Loss:  0.32687265
Encoder Loss:  0.042674944  || Decoder Loss:  0.037030116 Validation Decoder Loss:  0.32747287
Encoder Loss:  0.042471908  || Decoder Loss:  0.036831062 Validation Decoder Loss:  0.33198977
Encoder Loss:  0.35994953  || Decoder Loss:  0.4837824 Validation Decoder Loss:  0.94029653
Encoder Loss:  0.31429875  || Decoder Loss:  0.47999576 Validation Decoder Loss:  0.9802972
Encoder Loss:  0.29668626  || Decoder Loss:  0.45815742 Validation Decoder Loss:  0.9816339
Encoder Loss:  0.31480247  || Decoder Loss:  0.49804255 Validation Decoder Loss:  1.0385038
Encoder Loss:  0.29979593  || Decoder Loss:  0.47250283 Validation Decoder Loss:  0.78175235
Encoder Loss:  0.06723373  || Decoder Loss:  0.06935223 Validation Decoder Loss:  0.32602113
Encoder Loss:  0.053576857  || Decoder Loss:  0.046727076 Validation Decoder Loss:  0.32021916
Encoder Loss:  0.046491183  || Decoder Loss:  0.03858324 Validation Decoder Loss:  0.32794094
Encoder Loss:  0.0473658  || Decoder Loss:  0.03810252 Validation Decoder Loss:  0.34729862
Encoder Loss:  0.047988616  || Decoder Loss:  0.03845557 Validation Decoder Loss:  0.3405772
Encoder Loss:  0.04674376  || Decoder Loss:  0.038201705 Validation Decoder Loss:  0.33914185
Encoder Loss:  0.045075517  || Decoder Loss:  0.03818039 Validation Decoder Loss:  0.33550578
Encoder Loss:  0.043219198  || Decoder Loss:  0.038025938 Validation Decoder Loss:  0.33701354
Encoder Loss:  0.04320935  || Decoder Loss:  0.03801433 Validation Decoder Loss:  0.33766758
Encoder Loss:  0.042920634  || Decoder Loss:  0.037505187 Validation Decoder Loss:  0.33732623
Encoder Loss:  0.04279798  || Decoder Loss:  0.037284832 Validation Decoder Loss:  0.3375477
Encoder Loss:  0.042680286  || Decoder Loss:  0.037084617 Validation Decoder Loss:  0.3369865
Encoder Loss:  0.04271467  || Decoder Loss:  0.037145577 Validation Decoder Loss:  0.3344167
Encoder Loss:  0.04245669  || Decoder Loss:  0.03668977 Validation Decoder Loss:  0.3342819
Encoder Loss:  0.042924486  || Decoder Loss:  0.03751607 Validation Decoder Loss:  0.3358903
Encoder Loss:  0.042269036  || Decoder Loss:  0.03636082 Validation Decoder Loss:  0.3358703
Encoder Loss:  0.042250887  || Decoder Loss:  0.036328692 Validation Decoder Loss:  0.3356905
Encoder Loss:  0.042235956  || Decoder Loss:  0.03630249 Validation Decoder Loss:  0.33584616
Encoder Loss:  0.042228505  || Decoder Loss:  0.036290515 Validation Decoder Loss:  0.33481422
Encoder Loss:  0.04222279  || Decoder Loss:  0.036280304 Validation Decoder Loss:  0.33648247
Encoder Loss:  0.04239054  || Decoder Loss:  0.036576644 Validation Decoder Loss:  0.3343427
Encoder Loss:  0.042045083  || Decoder Loss:  0.03596753 Validation Decoder Loss:  0.33468205
Encoder Loss:  0.04207582  || Decoder Loss:  0.036020905 Validation Decoder Loss:  0.33478588
Encoder Loss:  0.042069588  || Decoder Loss:  0.03601032 Validation Decoder Loss:  0.33471555
Encoder Loss:  0.042089086  || Decoder Loss:  0.036045037 Validation Decoder Loss:  0.33313313
Encoder Loss:  0.04220376  || Decoder Loss:  0.036246076 Validation Decoder Loss:  0.33414978
Encoder Loss:  0.042036783  || Decoder Loss:  0.035873238 Validation Decoder Loss:  0.33437812
Encoder Loss:  0.04211693  || Decoder Loss:  0.036094207 Validation Decoder Loss:  0.3340432
Encoder Loss:  0.0419544  || Decoder Loss:  0.03580746 Validation Decoder Loss:  0.33429706
Encoder Loss:  0.041969832  || Decoder Loss:  0.03583498 Validation Decoder Loss:  0.33430347
Encoder Loss:  0.042267818  || Decoder Loss:  0.03636076 Validation Decoder Loss:  0.33364925
Model: siamese_net_lr_0.4369775611604337 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33364922
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_240 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_91 (Conv3DT (None, 257, 10, 20, 1)    18        
_________________________________________________________________
reshape_71 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 135
Trainable params: 135
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_242 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_81 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_244 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_81 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21514547  || Decoder Loss:  0.49160948 Validation Decoder Loss:  0.9979902
Encoder Loss:  0.20236613  || Decoder Loss:  0.49693862 Validation Decoder Loss:  0.95436966
Encoder Loss:  0.06270543  || Decoder Loss:  0.08424756 Validation Decoder Loss:  0.3312402
Encoder Loss:  0.045847427  || Decoder Loss:  0.03533221 Validation Decoder Loss:  0.33278608
Encoder Loss:  0.04587774  || Decoder Loss:  0.03534292 Validation Decoder Loss:  0.33244216
Encoder Loss:  0.04551511  || Decoder Loss:  0.035301257 Validation Decoder Loss:  0.33096948
Encoder Loss:  0.045485225  || Decoder Loss:  0.035290334 Validation Decoder Loss:  0.32803565
Encoder Loss:  0.045577206  || Decoder Loss:  0.035367392 Validation Decoder Loss:  0.33021802
Encoder Loss:  0.04544509  || Decoder Loss:  0.035332613 Validation Decoder Loss:  0.33186865
Encoder Loss:  0.045374297  || Decoder Loss:  0.035265803 Validation Decoder Loss:  0.32968703
Encoder Loss:  0.045505233  || Decoder Loss:  0.035359766 Validation Decoder Loss:  0.33080554
Encoder Loss:  0.045346595  || Decoder Loss:  0.035285346 Validation Decoder Loss:  0.3310551
Encoder Loss:  0.045754056  || Decoder Loss:  0.035404876 Validation Decoder Loss:  0.33413136
Encoder Loss:  0.045612887  || Decoder Loss:  0.03564645 Validation Decoder Loss:  0.32840502
Encoder Loss:  0.045426287  || Decoder Loss:  0.03537584 Validation Decoder Loss:  0.3279513
Encoder Loss:  0.045454513  || Decoder Loss:  0.035443887 Validation Decoder Loss:  0.3289163
Encoder Loss:  0.046895932  || Decoder Loss:  0.03992085 Validation Decoder Loss:  0.32971883
Encoder Loss:  0.04535943  || Decoder Loss:  0.035337582 Validation Decoder Loss:  0.33330148
Encoder Loss:  0.048655003  || Decoder Loss:  0.044221006 Validation Decoder Loss:  0.3333228
Encoder Loss:  0.04532589  || Decoder Loss:  0.03531184 Validation Decoder Loss:  0.33419245
Encoder Loss:  0.045521855  || Decoder Loss:  0.035360392 Validation Decoder Loss:  0.32555142
Encoder Loss:  0.045387458  || Decoder Loss:  0.035413243 Validation Decoder Loss:  0.3303249
Encoder Loss:  0.045354657  || Decoder Loss:  0.035317358 Validation Decoder Loss:  0.33094683
Encoder Loss:  0.04535428  || Decoder Loss:  0.03530693 Validation Decoder Loss:  0.33135766
Encoder Loss:  0.04539086  || Decoder Loss:  0.035340928 Validation Decoder Loss:  0.33052814
Encoder Loss:  0.045440458  || Decoder Loss:  0.035400778 Validation Decoder Loss:  0.33221593
Encoder Loss:  0.04531556  || Decoder Loss:  0.035323404 Validation Decoder Loss:  0.33187655
Encoder Loss:  0.045266394  || Decoder Loss:  0.03539522 Validation Decoder Loss:  0.32962352
Encoder Loss:  0.045209628  || Decoder Loss:  0.03531224 Validation Decoder Loss:  0.3313273
Encoder Loss:  0.047320623  || Decoder Loss:  0.04133083 Validation Decoder Loss:  0.33069617
Encoder Loss:  0.045203034  || Decoder Loss:  0.03531111 Validation Decoder Loss:  0.33076438
Encoder Loss:  0.045207106  || Decoder Loss:  0.035316452 Validation Decoder Loss:  0.3320573
Encoder Loss:  0.04523563  || Decoder Loss:  0.035339538 Validation Decoder Loss:  0.33134717
Encoder Loss:  0.04515481  || Decoder Loss:  0.035299245 Validation Decoder Loss:  0.3327805
Encoder Loss:  0.04516869  || Decoder Loss:  0.035300717 Validation Decoder Loss:  0.33065295
Encoder Loss:  0.04526195  || Decoder Loss:  0.035346683 Validation Decoder Loss:  0.33126408
Encoder Loss:  0.045180954  || Decoder Loss:  0.03532024 Validation Decoder Loss:  0.33125493
Encoder Loss:  0.04514948  || Decoder Loss:  0.03531364 Validation Decoder Loss:  0.3311473
Encoder Loss:  0.04513734  || Decoder Loss:  0.035308264 Validation Decoder Loss:  0.33199215
Encoder Loss:  0.04516697  || Decoder Loss:  0.035354685 Validation Decoder Loss:  0.3319236
Model: siamese_net_lr_0.4623707955239413 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33192354
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_246 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_94 (Conv3DT (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_72 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_248 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_83 (Conv2D)           (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_250 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_83 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.041731607  || Decoder Loss:  0.035902712 Validation Decoder Loss:  0.32800004
Encoder Loss:  0.03961829  || Decoder Loss:  0.03579697 Validation Decoder Loss:  0.3249908
Encoder Loss:  0.039985504  || Decoder Loss:  0.03599718 Validation Decoder Loss:  0.3296116
Encoder Loss:  0.038626242  || Decoder Loss:  0.03562969 Validation Decoder Loss:  0.32958704
Encoder Loss:  0.038536668  || Decoder Loss:  0.035537265 Validation Decoder Loss:  0.32975623
Encoder Loss:  0.040380012  || Decoder Loss:  0.037885536 Validation Decoder Loss:  0.33010018
Encoder Loss:  0.039119903  || Decoder Loss:  0.03637049 Validation Decoder Loss:  0.33004653
Encoder Loss:  0.03900583  || Decoder Loss:  0.036187712 Validation Decoder Loss:  0.33007157
Encoder Loss:  0.039076254  || Decoder Loss:  0.03629096 Validation Decoder Loss:  0.3301543
Encoder Loss:  0.03918835  || Decoder Loss:  0.036386404 Validation Decoder Loss:  0.33023897
Encoder Loss:  0.03896595  || Decoder Loss:  0.03622936 Validation Decoder Loss:  0.3302362
Encoder Loss:  0.039046526  || Decoder Loss:  0.036267262 Validation Decoder Loss:  0.3302792
Encoder Loss:  0.039146256  || Decoder Loss:  0.036379904 Validation Decoder Loss:  0.3303942
Encoder Loss:  0.039651655  || Decoder Loss:  0.036868762 Validation Decoder Loss:  0.33046094
Encoder Loss:  0.039342307  || Decoder Loss:  0.036629792 Validation Decoder Loss:  0.33041042
Encoder Loss:  0.038955737  || Decoder Loss:  0.036266457 Validation Decoder Loss:  0.33037752
Encoder Loss:  0.038896676  || Decoder Loss:  0.036159772 Validation Decoder Loss:  0.33041567
Encoder Loss:  0.038785648  || Decoder Loss:  0.036062952 Validation Decoder Loss:  0.33041218
Encoder Loss:  0.038653694  || Decoder Loss:  0.035942107 Validation Decoder Loss:  0.3304098
Encoder Loss:  0.038582943  || Decoder Loss:  0.035855524 Validation Decoder Loss:  0.3304438
Encoder Loss:  0.0385401  || Decoder Loss:  0.03580278 Validation Decoder Loss:  0.3304354
Encoder Loss:  0.03854332  || Decoder Loss:  0.035800263 Validation Decoder Loss:  0.3304459
Encoder Loss:  0.038515516  || Decoder Loss:  0.035773173 Validation Decoder Loss:  0.33053514
Encoder Loss:  0.03886912  || Decoder Loss:  0.03613095 Validation Decoder Loss:  0.33057433
Encoder Loss:  0.038655683  || Decoder Loss:  0.035959758 Validation Decoder Loss:  0.33052108
Encoder Loss:  0.03851933  || Decoder Loss:  0.035793494 Validation Decoder Loss:  0.33052823
Encoder Loss:  0.038474165  || Decoder Loss:  0.035734013 Validation Decoder Loss:  0.33047697
Encoder Loss:  0.03971862  || Decoder Loss:  0.03702625 Validation Decoder Loss:  0.33074784
Encoder Loss:  0.039028503  || Decoder Loss:  0.036417328 Validation Decoder Loss:  0.33058715
Encoder Loss:  0.038773097  || Decoder Loss:  0.036106993 Validation Decoder Loss:  0.3306048
Encoder Loss:  0.03865451  || Decoder Loss:  0.0359613 Validation Decoder Loss:  0.33059803
Encoder Loss:  0.038587384  || Decoder Loss:  0.035879567 Validation Decoder Loss:  0.3305963
Encoder Loss:  0.03854116  || Decoder Loss:  0.035821382 Validation Decoder Loss:  0.33060512
Encoder Loss:  0.038530484  || Decoder Loss:  0.03580116 Validation Decoder Loss:  0.33063295
Encoder Loss:  0.038610004  || Decoder Loss:  0.035887133 Validation Decoder Loss:  0.3306076
Encoder Loss:  0.03871132  || Decoder Loss:  0.036002554 Validation Decoder Loss:  0.33057356
Encoder Loss:  0.039138254  || Decoder Loss:  0.03645524 Validation Decoder Loss:  0.33060592
Encoder Loss:  0.03879695  || Decoder Loss:  0.03613973 Validation Decoder Loss:  0.33066636
Encoder Loss:  0.038671125  || Decoder Loss:  0.035983454 Validation Decoder Loss:  0.3306597
Encoder Loss:  0.03859754  || Decoder Loss:  0.035893727 Validation Decoder Loss:  0.33065715
Model: siamese_net_lr_0.2279152774972429 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33065718
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 200, 6, 20, 1)     23        
_________________________________________________________________
dropout_252 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_97 (Conv3DT (None, 257, 10, 20, 1)    291       
_________________________________________________________________
reshape_73 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 314
Trainable params: 314
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_254 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_85 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_256 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_85 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2540344  || Decoder Loss:  0.34551612 Validation Decoder Loss:  1.0976523
Encoder Loss:  0.34707057  || Decoder Loss:  0.49613026 Validation Decoder Loss:  0.8978449
Encoder Loss:  0.32393047  || Decoder Loss:  0.4668364 Validation Decoder Loss:  0.7664403
Encoder Loss:  0.12081106  || Decoder Loss:  0.15647572 Validation Decoder Loss:  0.33070263
Encoder Loss:  0.04480841  || Decoder Loss:  0.040209077 Validation Decoder Loss:  0.33333862
Encoder Loss:  0.09351161  || Decoder Loss:  0.11464467 Validation Decoder Loss:  0.33142692
Encoder Loss:  0.045001145  || Decoder Loss:  0.040650267 Validation Decoder Loss:  0.32996935
Encoder Loss:  0.29469475  || Decoder Loss:  0.42298034 Validation Decoder Loss:  0.3335974
Encoder Loss:  0.04337132  || Decoder Loss:  0.038269993 Validation Decoder Loss:  0.3310665
Encoder Loss:  0.0438376  || Decoder Loss:  0.039519697 Validation Decoder Loss:  0.33109236
Encoder Loss:  0.04403847  || Decoder Loss:  0.040061425 Validation Decoder Loss:  0.34927532
Encoder Loss:  0.21456036  || Decoder Loss:  0.3006196 Validation Decoder Loss:  0.33213028
Encoder Loss:  0.041723605  || Decoder Loss:  0.036616836 Validation Decoder Loss:  0.33127785
Encoder Loss:  0.04209462  || Decoder Loss:  0.037315525 Validation Decoder Loss:  0.3307914
Encoder Loss:  0.23185739  || Decoder Loss:  0.32761618 Validation Decoder Loss:  0.3315633
Encoder Loss:  0.0408447  || Decoder Loss:  0.035896406 Validation Decoder Loss:  0.3315419
Encoder Loss:  0.040927563  || Decoder Loss:  0.03589182 Validation Decoder Loss:  0.3315286
Encoder Loss:  0.041048326  || Decoder Loss:  0.035973493 Validation Decoder Loss:  0.33177328
Encoder Loss:  0.04514958  || Decoder Loss:  0.04192001 Validation Decoder Loss:  0.33215427
Encoder Loss:  0.042662676  || Decoder Loss:  0.038732983 Validation Decoder Loss:  0.33152196
Encoder Loss:  0.0407583  || Decoder Loss:  0.035810858 Validation Decoder Loss:  0.3314403
Encoder Loss:  0.040781196  || Decoder Loss:  0.03584127 Validation Decoder Loss:  0.3312885
Encoder Loss:  0.04095552  || Decoder Loss:  0.03611857 Validation Decoder Loss:  0.33134645
Encoder Loss:  0.04109504  || Decoder Loss:  0.03633076 Validation Decoder Loss:  0.33136785
Encoder Loss:  0.04100091  || Decoder Loss:  0.036187254 Validation Decoder Loss:  0.3356856
Encoder Loss:  0.040862184  || Decoder Loss:  0.03597907 Validation Decoder Loss:  0.3371617
Encoder Loss:  0.04093822  || Decoder Loss:  0.03609973 Validation Decoder Loss:  0.33056188
Encoder Loss:  0.21013914  || Decoder Loss:  0.29539615 Validation Decoder Loss:  0.3265366
Encoder Loss:  0.0576753  || Decoder Loss:  0.06175651 Validation Decoder Loss:  0.325787
Encoder Loss:  0.055440977  || Decoder Loss:  0.05833225 Validation Decoder Loss:  0.3150494
Encoder Loss:  0.040663704  || Decoder Loss:  0.03568086 Validation Decoder Loss:  0.32940477
Encoder Loss:  0.040672563  || Decoder Loss:  0.03569413 Validation Decoder Loss:  0.33285135
Encoder Loss:  0.040688604  || Decoder Loss:  0.035718292 Validation Decoder Loss:  0.33087295
Encoder Loss:  0.040713027  || Decoder Loss:  0.035754457 Validation Decoder Loss:  0.3308722
Encoder Loss:  0.074136026  || Decoder Loss:  0.086980864 Validation Decoder Loss:  0.33224863
Encoder Loss:  0.040686935  || Decoder Loss:  0.035718217 Validation Decoder Loss:  0.33088297
Encoder Loss:  0.043320723  || Decoder Loss:  0.039741646 Validation Decoder Loss:  0.33577502
Encoder Loss:  0.040514488  || Decoder Loss:  0.03545445 Validation Decoder Loss:  0.3305492
Encoder Loss:  0.04063744  || Decoder Loss:  0.03564278 Validation Decoder Loss:  0.33134705
Encoder Loss:  0.36538306  || Decoder Loss:  0.5333073 Validation Decoder Loss:  1.0619693
Model: siamese_net_lr_0.30116462819137085 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0619693
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_258 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_100 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_74 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_260 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_87 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_262 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_87 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.066951826  || Decoder Loss:  0.04886031 Validation Decoder Loss:  0.34919745
Encoder Loss:  0.050395843  || Decoder Loss:  0.040991243 Validation Decoder Loss:  0.3491772
Encoder Loss:  0.04803491  || Decoder Loss:  0.041045018 Validation Decoder Loss:  0.3483867
Encoder Loss:  0.047975168  || Decoder Loss:  0.04107748 Validation Decoder Loss:  0.34850162
Encoder Loss:  0.047470856  || Decoder Loss:  0.041131224 Validation Decoder Loss:  0.34844375
Encoder Loss:  0.047027327  || Decoder Loss:  0.04109122 Validation Decoder Loss:  0.34761828
Encoder Loss:  0.04747158  || Decoder Loss:  0.041222524 Validation Decoder Loss:  0.35116693
Encoder Loss:  0.04716637  || Decoder Loss:  0.041339178 Validation Decoder Loss:  0.3514331
Encoder Loss:  0.047428876  || Decoder Loss:  0.041798253 Validation Decoder Loss:  0.35725707
Encoder Loss:  0.047412504  || Decoder Loss:  0.042050313 Validation Decoder Loss:  0.35791174
Encoder Loss:  0.047439627  || Decoder Loss:  0.04205644 Validation Decoder Loss:  0.35777944
Encoder Loss:  0.04738985  || Decoder Loss:  0.0419263 Validation Decoder Loss:  0.3555038
Encoder Loss:  0.063229784  || Decoder Loss:  0.08826247 Validation Decoder Loss:  0.69534993
Encoder Loss:  0.07328453  || Decoder Loss:  0.117502555 Validation Decoder Loss:  0.438325
Encoder Loss:  0.05622275  || Decoder Loss:  0.06774635 Validation Decoder Loss:  0.4705428
Encoder Loss:  0.05763814  || Decoder Loss:  0.07166799 Validation Decoder Loss:  0.33447105
Encoder Loss:  0.04514204  || Decoder Loss:  0.035227086 Validation Decoder Loss:  0.32995588
Encoder Loss:  0.045067944  || Decoder Loss:  0.03520847 Validation Decoder Loss:  0.33077067
Encoder Loss:  0.045082096  || Decoder Loss:  0.035224672 Validation Decoder Loss:  0.33462936
Encoder Loss:  0.04505603  || Decoder Loss:  0.03523271 Validation Decoder Loss:  0.33257324
Encoder Loss:  0.04503162  || Decoder Loss:  0.03521897 Validation Decoder Loss:  0.3327083
Encoder Loss:  0.045046285  || Decoder Loss:  0.035159364 Validation Decoder Loss:  0.3321404
Encoder Loss:  0.045041487  || Decoder Loss:  0.035166323 Validation Decoder Loss:  0.3314415
Encoder Loss:  0.045010604  || Decoder Loss:  0.035107147 Validation Decoder Loss:  0.33133116
Encoder Loss:  0.045013577  || Decoder Loss:  0.035062324 Validation Decoder Loss:  0.33502704
Encoder Loss:  0.044923037  || Decoder Loss:  0.03497119 Validation Decoder Loss:  0.32807148
Encoder Loss:  0.04635498  || Decoder Loss:  0.039183814 Validation Decoder Loss:  0.33421278
Encoder Loss:  0.04492099  || Decoder Loss:  0.035028774 Validation Decoder Loss:  0.33573765
Encoder Loss:  0.044949494  || Decoder Loss:  0.035137635 Validation Decoder Loss:  0.33068144
Encoder Loss:  0.044918098  || Decoder Loss:  0.035065673 Validation Decoder Loss:  0.33612734
Encoder Loss:  0.044961534  || Decoder Loss:  0.035214916 Validation Decoder Loss:  0.32904887
Encoder Loss:  0.04492945  || Decoder Loss:  0.035120297 Validation Decoder Loss:  0.33607596
Encoder Loss:  0.044871613  || Decoder Loss:  0.034962747 Validation Decoder Loss:  0.33365637
Encoder Loss:  0.044972192  || Decoder Loss:  0.035246562 Validation Decoder Loss:  0.33238962
Encoder Loss:  0.0449463  || Decoder Loss:  0.03519023 Validation Decoder Loss:  0.33009192
Encoder Loss:  0.044979908  || Decoder Loss:  0.035285134 Validation Decoder Loss:  0.3275382
Encoder Loss:  0.044991523  || Decoder Loss:  0.035318725 Validation Decoder Loss:  0.32675928
Encoder Loss:  0.044964164  || Decoder Loss:  0.03523983 Validation Decoder Loss:  0.32599765
Encoder Loss:  0.04496534  || Decoder Loss:  0.035240725 Validation Decoder Loss:  0.330356
Encoder Loss:  0.044930086  || Decoder Loss:  0.035143003 Validation Decoder Loss:  0.33002186
Model: siamese_net_lr_0.45960837934903537 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33002186
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_264 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_103 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_75 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_266 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_89 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_268 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_89 (Conv2DT (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35254106  || Decoder Loss:  0.43995723 Validation Decoder Loss:  0.41716266
Encoder Loss:  0.11363847  || Decoder Loss:  0.13229522 Validation Decoder Loss:  0.99385613
Encoder Loss:  0.3941317  || Decoder Loss:  0.49503288 Validation Decoder Loss:  0.9981587
Encoder Loss:  0.39384064  || Decoder Loss:  0.49465653 Validation Decoder Loss:  0.99476135
Encoder Loss:  0.24894448  || Decoder Loss:  0.307276 Validation Decoder Loss:  0.32620528
Encoder Loss:  0.038350806  || Decoder Loss:  0.034934536 Validation Decoder Loss:  0.32275927
Encoder Loss:  0.03824679  || Decoder Loss:  0.0347997 Validation Decoder Loss:  0.3304839
Encoder Loss:  0.36646992  || Decoder Loss:  0.4582021 Validation Decoder Loss:  0.65518683
Encoder Loss:  0.06053283  || Decoder Loss:  0.06361804 Validation Decoder Loss:  0.32238272
Encoder Loss:  0.041620612  || Decoder Loss:  0.039150976 Validation Decoder Loss:  0.33027765
Encoder Loss:  0.042076856  || Decoder Loss:  0.03974989 Validation Decoder Loss:  0.33653498
Encoder Loss:  0.041004486  || Decoder Loss:  0.038363453 Validation Decoder Loss:  0.33687207
Encoder Loss:  0.040249098  || Decoder Loss:  0.037387297 Validation Decoder Loss:  0.33303356
Encoder Loss:  0.040116314  || Decoder Loss:  0.037211444 Validation Decoder Loss:  0.3331424
Encoder Loss:  0.040564757  || Decoder Loss:  0.03779416 Validation Decoder Loss:  0.33111188
Encoder Loss:  0.040678132  || Decoder Loss:  0.03794305 Validation Decoder Loss:  0.33436945
Encoder Loss:  0.03948037  || Decoder Loss:  0.03639387 Validation Decoder Loss:  0.33633935
Encoder Loss:  0.3741194  || Decoder Loss:  0.4691403 Validation Decoder Loss:  0.97230005
Encoder Loss:  0.30061513  || Decoder Loss:  0.37409645 Validation Decoder Loss:  0.33996642
Encoder Loss:  0.039262157  || Decoder Loss:  0.036112916 Validation Decoder Loss:  0.3302881
Encoder Loss:  0.03909642  || Decoder Loss:  0.035898775 Validation Decoder Loss:  0.3295138
Encoder Loss:  0.039919507  || Decoder Loss:  0.03696321 Validation Decoder Loss:  0.3317563
Encoder Loss:  0.04692068  || Decoder Loss:  0.04601525 Validation Decoder Loss:  0.3208155
Encoder Loss:  0.40412873  || Decoder Loss:  0.50662875 Validation Decoder Loss:  1.0134869
Encoder Loss:  0.39565885  || Decoder Loss:  0.49697956 Validation Decoder Loss:  1.0231044
Encoder Loss:  0.38508058  || Decoder Loss:  0.4833172 Validation Decoder Loss:  1.0095333
Encoder Loss:  0.39426446  || Decoder Loss:  0.49517635 Validation Decoder Loss:  0.9604707
Encoder Loss:  0.15013325  || Decoder Loss:  0.17948578 Validation Decoder Loss:  0.3358171
Encoder Loss:  0.039280813  || Decoder Loss:  0.036137264 Validation Decoder Loss:  0.33171612
Encoder Loss:  0.03964047  || Decoder Loss:  0.036602303 Validation Decoder Loss:  0.33224386
Encoder Loss:  0.0397819  || Decoder Loss:  0.036785074 Validation Decoder Loss:  0.3338876
Encoder Loss:  0.039308924  || Decoder Loss:  0.03617321 Validation Decoder Loss:  0.33239794
Encoder Loss:  0.039253283  || Decoder Loss:  0.036101084 Validation Decoder Loss:  0.33220464
Encoder Loss:  0.03962126  || Decoder Loss:  0.036576897 Validation Decoder Loss:  0.33097097
Encoder Loss:  0.039492987  || Decoder Loss:  0.036413494 Validation Decoder Loss:  0.3587545
Encoder Loss:  0.1914137  || Decoder Loss:  0.2309194 Validation Decoder Loss:  0.3330174
Encoder Loss:  0.04285853  || Decoder Loss:  0.040680718 Validation Decoder Loss:  0.33868653
Encoder Loss:  0.044392057  || Decoder Loss:  0.042626966 Validation Decoder Loss:  0.3119768
Encoder Loss:  0.044340663  || Decoder Loss:  0.04256691 Validation Decoder Loss:  0.33013988
Encoder Loss:  0.046799153  || Decoder Loss:  0.045761224 Validation Decoder Loss:  0.32414007
Model: siamese_net_lr_0.5383088794231045 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32414007
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 242, 5, 20, 1)     180       
_________________________________________________________________
dropout_270 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_106 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_76 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 213
Trainable params: 213
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_272 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_91 (Conv2D)           (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_274 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_91 (Conv2DT (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22002324  || Decoder Loss:  0.46719465 Validation Decoder Loss:  1.0017481
Encoder Loss:  0.21468133  || Decoder Loss:  0.49661243 Validation Decoder Loss:  1.001951
Encoder Loss:  0.21463771  || Decoder Loss:  0.49659514 Validation Decoder Loss:  1.0018948
Encoder Loss:  0.2142028  || Decoder Loss:  0.4953165 Validation Decoder Loss:  0.99867064
Encoder Loss:  0.2160566  || Decoder Loss:  0.5004739 Validation Decoder Loss:  0.9939011
Encoder Loss:  0.12222957  || Decoder Loss:  0.24538226 Validation Decoder Loss:  0.34944493
Encoder Loss:  0.04747055  || Decoder Loss:  0.04239078 Validation Decoder Loss:  0.3417179
Encoder Loss:  0.067971386  || Decoder Loss:  0.09806462 Validation Decoder Loss:  0.3495268
Encoder Loss:  0.047953796  || Decoder Loss:  0.04387445 Validation Decoder Loss:  0.32711112
Encoder Loss:  0.06498862  || Decoder Loss:  0.08939828 Validation Decoder Loss:  0.34386164
Encoder Loss:  0.046692815  || Decoder Loss:  0.0407392 Validation Decoder Loss:  0.34241533
Encoder Loss:  0.05060761  || Decoder Loss:  0.05120737 Validation Decoder Loss:  0.33610928
Encoder Loss:  0.05780668  || Decoder Loss:  0.07056568 Validation Decoder Loss:  0.34507415
Encoder Loss:  0.049968634  || Decoder Loss:  0.049480774 Validation Decoder Loss:  0.3474362
Encoder Loss:  0.046811547  || Decoder Loss:  0.041009106 Validation Decoder Loss:  0.33328056
Encoder Loss:  0.084599346  || Decoder Loss:  0.14245607 Validation Decoder Loss:  0.33557194
Encoder Loss:  0.045949224  || Decoder Loss:  0.03888781 Validation Decoder Loss:  0.32170796
Encoder Loss:  0.048745874  || Decoder Loss:  0.046317495 Validation Decoder Loss:  0.3416336
Encoder Loss:  0.0457918  || Decoder Loss:  0.038422197 Validation Decoder Loss:  0.3215971
Encoder Loss:  0.046550296  || Decoder Loss:  0.04050155 Validation Decoder Loss:  0.3336874
Encoder Loss:  0.046238195  || Decoder Loss:  0.039609995 Validation Decoder Loss:  0.37474337
Encoder Loss:  0.056733  || Decoder Loss:  0.06800485 Validation Decoder Loss:  0.3428567
Encoder Loss:  0.046091314  || Decoder Loss:  0.03927516 Validation Decoder Loss:  0.2907875
Encoder Loss:  0.06842746  || Decoder Loss:  0.09926275 Validation Decoder Loss:  0.34219372
Encoder Loss:  0.04642619  || Decoder Loss:  0.040172096 Validation Decoder Loss:  0.34398666
Encoder Loss:  0.046588454  || Decoder Loss:  0.04062867 Validation Decoder Loss:  0.3329919
Encoder Loss:  0.04623794  || Decoder Loss:  0.03968616 Validation Decoder Loss:  0.34822822
Encoder Loss:  0.054831  || Decoder Loss:  0.06240623 Validation Decoder Loss:  0.33622116
Encoder Loss:  0.04638921  || Decoder Loss:  0.040126577 Validation Decoder Loss:  0.3760293
Encoder Loss:  0.047980357  || Decoder Loss:  0.044294745 Validation Decoder Loss:  0.3411035
Encoder Loss:  0.04678605  || Decoder Loss:  0.04116849 Validation Decoder Loss:  0.4113215
Encoder Loss:  0.046290126  || Decoder Loss:  0.039840862 Validation Decoder Loss:  0.3456582
Encoder Loss:  0.047999077  || Decoder Loss:  0.044409886 Validation Decoder Loss:  0.3233434
Encoder Loss:  0.05698258  || Decoder Loss:  0.068766296 Validation Decoder Loss:  0.33039558
Encoder Loss:  0.048513003  || Decoder Loss:  0.04583864 Validation Decoder Loss:  0.3428221
Encoder Loss:  0.045883164  || Decoder Loss:  0.038746342 Validation Decoder Loss:  0.3373815
Encoder Loss:  0.06349346  || Decoder Loss:  0.08622226 Validation Decoder Loss:  0.35294574
Encoder Loss:  0.046244312  || Decoder Loss:  0.03973656 Validation Decoder Loss:  0.30998355
Encoder Loss:  0.0702254  || Decoder Loss:  0.10461387 Validation Decoder Loss:  0.32968754
Encoder Loss:  0.045903083  || Decoder Loss:  0.03881148 Validation Decoder Loss:  0.3415794
Model: siamese_net_lr_0.42495605909761025 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3415794
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_108 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_276 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_109 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_77 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 214
Trainable params: 214
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_278 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_93 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_280 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_93 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21016161  || Decoder Loss:  0.3698931 Validation Decoder Loss:  0.37892678
Encoder Loss:  0.24895039  || Decoder Loss:  0.52737474 Validation Decoder Loss:  1.1958971
Encoder Loss:  0.22042888  || Decoder Loss:  0.472565 Validation Decoder Loss:  0.60393536
Encoder Loss:  0.23053528  || Decoder Loss:  0.5031209 Validation Decoder Loss:  0.9736557
Encoder Loss:  0.21838899  || Decoder Loss:  0.49561816 Validation Decoder Loss:  0.9951867
Encoder Loss:  0.2171049  || Decoder Loss:  0.4931499 Validation Decoder Loss:  0.9910308
Encoder Loss:  0.11424705  || Decoder Loss:  0.22006704 Validation Decoder Loss:  0.33106366
Encoder Loss:  0.044638604  || Decoder Loss:  0.03534636 Validation Decoder Loss:  0.32904395
Encoder Loss:  0.044817913  || Decoder Loss:  0.03539235 Validation Decoder Loss:  0.33316892
Encoder Loss:  0.045085356  || Decoder Loss:  0.036081634 Validation Decoder Loss:  0.33460146
Encoder Loss:  0.044755492  || Decoder Loss:  0.035300896 Validation Decoder Loss:  0.33046547
Encoder Loss:  0.044839352  || Decoder Loss:  0.03567104 Validation Decoder Loss:  0.330661
Encoder Loss:  0.044677094  || Decoder Loss:  0.035352718 Validation Decoder Loss:  0.33583862
Encoder Loss:  0.045055937  || Decoder Loss:  0.036113784 Validation Decoder Loss:  0.32806426
Encoder Loss:  0.047015  || Decoder Loss:  0.040885128 Validation Decoder Loss:  0.32412446
Encoder Loss:  0.04745855  || Decoder Loss:  0.04248304 Validation Decoder Loss:  0.31497765
Encoder Loss:  0.04522655  || Decoder Loss:  0.035958424 Validation Decoder Loss:  0.32170975
Encoder Loss:  0.044793997  || Decoder Loss:  0.03534125 Validation Decoder Loss:  0.3354259
Encoder Loss:  0.045202006  || Decoder Loss:  0.036275137 Validation Decoder Loss:  0.3276711
Encoder Loss:  0.045315236  || Decoder Loss:  0.036523733 Validation Decoder Loss:  0.33802742
Encoder Loss:  0.044928294  || Decoder Loss:  0.035511594 Validation Decoder Loss:  0.32275105
Encoder Loss:  0.077139996  || Decoder Loss:  0.11983564 Validation Decoder Loss:  0.30257377
Encoder Loss:  0.045277324  || Decoder Loss:  0.035999402 Validation Decoder Loss:  0.33633167
Encoder Loss:  0.046120297  || Decoder Loss:  0.03794728 Validation Decoder Loss:  0.31918538
Encoder Loss:  0.047410782  || Decoder Loss:  0.041794494 Validation Decoder Loss:  0.51413214
Encoder Loss:  0.047652196  || Decoder Loss:  0.04211972 Validation Decoder Loss:  0.3146732
Encoder Loss:  0.045174904  || Decoder Loss:  0.035725832 Validation Decoder Loss:  0.33043808
Encoder Loss:  0.045295652  || Decoder Loss:  0.036572207 Validation Decoder Loss:  0.3163282
Encoder Loss:  0.046433654  || Decoder Loss:  0.03917493 Validation Decoder Loss:  0.33395833
Encoder Loss:  0.04758224  || Decoder Loss:  0.042029366 Validation Decoder Loss:  0.33023405
Encoder Loss:  0.05853195  || Decoder Loss:  0.07117346 Validation Decoder Loss:  0.30815625
Encoder Loss:  0.044886354  || Decoder Loss:  0.03546883 Validation Decoder Loss:  0.34004536
Encoder Loss:  0.044865817  || Decoder Loss:  0.035608258 Validation Decoder Loss:  0.33444718
Encoder Loss:  0.048831325  || Decoder Loss:  0.045118514 Validation Decoder Loss:  0.3332973
Encoder Loss:  0.045599155  || Decoder Loss:  0.037440613 Validation Decoder Loss:  0.32874975
Encoder Loss:  0.045005884  || Decoder Loss:  0.035954084 Validation Decoder Loss:  0.3333332
Encoder Loss:  0.044887017  || Decoder Loss:  0.035366453 Validation Decoder Loss:  0.34439304
Encoder Loss:  0.045313336  || Decoder Loss:  0.03656213 Validation Decoder Loss:  0.3075831
Encoder Loss:  0.046326432  || Decoder Loss:  0.039498404 Validation Decoder Loss:  0.3278376
Encoder Loss:  0.04627524  || Decoder Loss:  0.039320953 Validation Decoder Loss:  0.33463824
Model: siamese_net_lr_0.46613249151939157 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33463824
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_111 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_282 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_112 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_78 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_284 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_95 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_286 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_95 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17559959  || Decoder Loss:  0.5358892 Validation Decoder Loss:  0.86445826
Encoder Loss:  0.15292281  || Decoder Loss:  0.48881423 Validation Decoder Loss:  1.0430679
Encoder Loss:  0.15507919  || Decoder Loss:  0.5021366 Validation Decoder Loss:  1.0180101
Encoder Loss:  0.14964701  || Decoder Loss:  0.49826896 Validation Decoder Loss:  1.00259
Encoder Loss:  0.14730641  || Decoder Loss:  0.49723104 Validation Decoder Loss:  1.0041959
Encoder Loss:  0.14732447  || Decoder Loss:  0.49723527 Validation Decoder Loss:  1.0036501
Encoder Loss:  0.14771713  || Decoder Loss:  0.4974676 Validation Decoder Loss:  1.0013503
Encoder Loss:  0.14744093  || Decoder Loss:  0.49721447 Validation Decoder Loss:  1.0033889
Encoder Loss:  0.14714146  || Decoder Loss:  0.49713337 Validation Decoder Loss:  1.0030632
Encoder Loss:  0.14711922  || Decoder Loss:  0.49709153 Validation Decoder Loss:  1.0030215
Encoder Loss:  0.14709027  || Decoder Loss:  0.49702454 Validation Decoder Loss:  1.0029467
Encoder Loss:  0.14709502  || Decoder Loss:  0.4970976 Validation Decoder Loss:  1.0031809
Encoder Loss:  0.14708929  || Decoder Loss:  0.49710238 Validation Decoder Loss:  1.0037042
Encoder Loss:  0.14706698  || Decoder Loss:  0.4970299 Validation Decoder Loss:  1.003391
Encoder Loss:  0.14706911  || Decoder Loss:  0.49704894 Validation Decoder Loss:  1.0032017
Encoder Loss:  0.14705484  || Decoder Loss:  0.4969925 Validation Decoder Loss:  1.0035975
Encoder Loss:  0.1470338  || Decoder Loss:  0.49690038 Validation Decoder Loss:  1.0030404
Encoder Loss:  0.1470047  || Decoder Loss:  0.49675652 Validation Decoder Loss:  1.0032612
Encoder Loss:  0.14693142  || Decoder Loss:  0.49644306 Validation Decoder Loss:  1.0022285
Encoder Loss:  0.14666149  || Decoder Loss:  0.4951878 Validation Decoder Loss:  1.0027717
Encoder Loss:  0.14686424  || Decoder Loss:  0.49613172 Validation Decoder Loss:  1.0013499
Encoder Loss:  0.1468818  || Decoder Loss:  0.49621856 Validation Decoder Loss:  1.0037193
Encoder Loss:  0.14703542  || Decoder Loss:  0.49691918 Validation Decoder Loss:  1.0037231
Encoder Loss:  0.1470402  || Decoder Loss:  0.4969106 Validation Decoder Loss:  1.0036707
Encoder Loss:  0.14703265  || Decoder Loss:  0.49691382 Validation Decoder Loss:  1.0037558
Encoder Loss:  0.14706078  || Decoder Loss:  0.4969136 Validation Decoder Loss:  1.003654
Encoder Loss:  0.14936955  || Decoder Loss:  0.49711555 Validation Decoder Loss:  1.0036192
Encoder Loss:  0.1470776  || Decoder Loss:  0.49710393 Validation Decoder Loss:  1.0036349
Encoder Loss:  0.14707458  || Decoder Loss:  0.49710408 Validation Decoder Loss:  1.0036317
Encoder Loss:  0.14707117  || Decoder Loss:  0.49709728 Validation Decoder Loss:  1.003636
Encoder Loss:  0.14707087  || Decoder Loss:  0.4970872 Validation Decoder Loss:  1.0036669
Encoder Loss:  0.14706631  || Decoder Loss:  0.49707428 Validation Decoder Loss:  1.0036705
Encoder Loss:  0.14706229  || Decoder Loss:  0.4970601 Validation Decoder Loss:  1.0036787
Encoder Loss:  0.14705905  || Decoder Loss:  0.49703723 Validation Decoder Loss:  1.0037138
Encoder Loss:  0.1470551  || Decoder Loss:  0.49701965 Validation Decoder Loss:  1.0037553
Encoder Loss:  0.14705062  || Decoder Loss:  0.4970004 Validation Decoder Loss:  1.0037674
Encoder Loss:  0.14705037  || Decoder Loss:  0.49699074 Validation Decoder Loss:  1.0037551
Encoder Loss:  0.14705049  || Decoder Loss:  0.49699718 Validation Decoder Loss:  1.0037929
Encoder Loss:  0.1470447  || Decoder Loss:  0.49697062 Validation Decoder Loss:  1.0038064
Encoder Loss:  0.14703998  || Decoder Loss:  0.49693406 Validation Decoder Loss:  1.0037248
Model: siamese_net_lr_0.47236180601296235 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0037248
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_114 (Conv3D (None, 234, 10, 20, 1)    271       
_________________________________________________________________
dropout_288 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_115 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_79 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 296
Trainable params: 296
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_290 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_97 (Conv2D)           (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_292 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_97 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24851088  || Decoder Loss:  0.2015592 Validation Decoder Loss:  0.7419996
Encoder Loss:  0.21296406  || Decoder Loss:  0.3707038 Validation Decoder Loss:  0.49993375
Encoder Loss:  0.09470946  || Decoder Loss:  0.14462024 Validation Decoder Loss:  0.4874641
Encoder Loss:  0.092262365  || Decoder Loss:  0.13944402 Validation Decoder Loss:  0.4891587
Encoder Loss:  0.0936127  || Decoder Loss:  0.14230198 Validation Decoder Loss:  0.4858662
Encoder Loss:  0.09261741  || Decoder Loss:  0.14019167 Validation Decoder Loss:  0.4799884
Encoder Loss:  0.086136  || Decoder Loss:  0.12648064 Validation Decoder Loss:  0.37674794
Encoder Loss:  0.0717897  || Decoder Loss:  0.09611125 Validation Decoder Loss:  0.47693253
Encoder Loss:  0.09018459  || Decoder Loss:  0.13505088 Validation Decoder Loss:  0.4682949
Encoder Loss:  0.079864934  || Decoder Loss:  0.113207385 Validation Decoder Loss:  0.33220145
Encoder Loss:  0.043360204  || Decoder Loss:  0.035938814 Validation Decoder Loss:  0.331702
Encoder Loss:  0.04337892  || Decoder Loss:  0.035843845 Validation Decoder Loss:  0.3314399
Encoder Loss:  0.043476887  || Decoder Loss:  0.03589043 Validation Decoder Loss:  0.33145753
Encoder Loss:  0.04655806  || Decoder Loss:  0.042690493 Validation Decoder Loss:  0.3315565
Encoder Loss:  0.044784293  || Decoder Loss:  0.03894786 Validation Decoder Loss:  0.3307169
Encoder Loss:  0.043364715  || Decoder Loss:  0.035939764 Validation Decoder Loss:  0.33143163
Encoder Loss:  0.043293163  || Decoder Loss:  0.035793696 Validation Decoder Loss:  0.33143055
Encoder Loss:  0.043295108  || Decoder Loss:  0.035797875 Validation Decoder Loss:  0.33116776
Encoder Loss:  0.045407467  || Decoder Loss:  0.040263172 Validation Decoder Loss:  0.33165848
Encoder Loss:  0.043351904  || Decoder Loss:  0.03590639 Validation Decoder Loss:  0.33119047
Encoder Loss:  0.04326607  || Decoder Loss:  0.035730094 Validation Decoder Loss:  0.3311277
Encoder Loss:  0.04326694  || Decoder Loss:  0.03573506 Validation Decoder Loss:  0.33070195
Encoder Loss:  0.045300942  || Decoder Loss:  0.040039763 Validation Decoder Loss:  0.33032537
Encoder Loss:  0.043300968  || Decoder Loss:  0.035795495 Validation Decoder Loss:  0.3309366
Encoder Loss:  0.043220162  || Decoder Loss:  0.035635054 Validation Decoder Loss:  0.33092424
Encoder Loss:  0.04325834  || Decoder Loss:  0.035632905 Validation Decoder Loss:  0.3306836
Encoder Loss:  0.14765806  || Decoder Loss:  0.18275498 Validation Decoder Loss:  1.1829156
Encoder Loss:  0.26194686  || Decoder Loss:  0.45172518 Validation Decoder Loss:  1.1990442
Encoder Loss:  0.25388336  || Decoder Loss:  0.44007164 Validation Decoder Loss:  1.0453277
Encoder Loss:  0.07630289  || Decoder Loss:  0.07133069 Validation Decoder Loss:  0.32912987
Encoder Loss:  0.057002805  || Decoder Loss:  0.03581043 Validation Decoder Loss:  0.3312938
Encoder Loss:  0.05577646  || Decoder Loss:  0.03561001 Validation Decoder Loss:  0.33108127
Encoder Loss:  0.049686432  || Decoder Loss:  0.03558886 Validation Decoder Loss:  0.33089846
Encoder Loss:  0.0509264  || Decoder Loss:  0.03559635 Validation Decoder Loss:  0.33133587
Encoder Loss:  0.04422659  || Decoder Loss:  0.03555742 Validation Decoder Loss:  0.3311256
Encoder Loss:  0.044030014  || Decoder Loss:  0.03552575 Validation Decoder Loss:  0.33095327
Encoder Loss:  0.04372588  || Decoder Loss:  0.03554185 Validation Decoder Loss:  0.33092222
Encoder Loss:  0.043483187  || Decoder Loss:  0.035599582 Validation Decoder Loss:  0.33088914
Encoder Loss:  0.04344824  || Decoder Loss:  0.035654247 Validation Decoder Loss:  0.33094698
Encoder Loss:  0.04350141  || Decoder Loss:  0.03574811 Validation Decoder Loss:  0.33100063
Model: siamese_net_lr_0.474116831133986 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33100063
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_117 (Conv3D (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_294 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_118 (Conv3D (None, 257, 10, 20, 1)    18        
_________________________________________________________________
reshape_80 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 367
Trainable params: 367
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_296 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_99 (Conv2D)           (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_298 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_99 (Conv2DT (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3766531  || Decoder Loss:  0.49752557 Validation Decoder Loss:  1.0021083
Encoder Loss:  0.15654153  || Decoder Loss:  0.19728881 Validation Decoder Loss:  0.34693336
Encoder Loss:  0.040181205  || Decoder Loss:  0.035681747 Validation Decoder Loss:  0.33131865
Encoder Loss:  0.039902914  || Decoder Loss:  0.03576271 Validation Decoder Loss:  0.33134553
Encoder Loss:  0.039708182  || Decoder Loss:  0.03550541 Validation Decoder Loss:  0.33059165
Encoder Loss:  0.039819464  || Decoder Loss:  0.035634104 Validation Decoder Loss:  0.3259856
Encoder Loss:  0.03966474  || Decoder Loss:  0.03545546 Validation Decoder Loss:  0.33295816
Encoder Loss:  0.039791524  || Decoder Loss:  0.03558595 Validation Decoder Loss:  0.32900327
Encoder Loss:  0.042893287  || Decoder Loss:  0.039890006 Validation Decoder Loss:  0.3319538
Encoder Loss:  0.03956436  || Decoder Loss:  0.03536626 Validation Decoder Loss:  0.32616845
Encoder Loss:  0.042567853  || Decoder Loss:  0.039285436 Validation Decoder Loss:  0.33608487
Encoder Loss:  0.039676  || Decoder Loss:  0.03548499 Validation Decoder Loss:  0.3306576
Encoder Loss:  0.039532635  || Decoder Loss:  0.03535865 Validation Decoder Loss:  0.33159137
Encoder Loss:  0.039616324  || Decoder Loss:  0.03545117 Validation Decoder Loss:  0.3349374
Encoder Loss:  0.039691202  || Decoder Loss:  0.035579797 Validation Decoder Loss:  0.33021897
Encoder Loss:  0.03956198  || Decoder Loss:  0.035379663 Validation Decoder Loss:  0.329263
Encoder Loss:  0.039717156  || Decoder Loss:  0.035595395 Validation Decoder Loss:  0.33154613
Encoder Loss:  0.039497916  || Decoder Loss:  0.035345055 Validation Decoder Loss:  0.32532436
Encoder Loss:  0.039620925  || Decoder Loss:  0.03544048 Validation Decoder Loss:  0.32920185
Encoder Loss:  0.039663244  || Decoder Loss:  0.03554294 Validation Decoder Loss:  0.32834625
Encoder Loss:  0.04542999  || Decoder Loss:  0.043522038 Validation Decoder Loss:  0.33337742
Encoder Loss:  0.041007467  || Decoder Loss:  0.037391435 Validation Decoder Loss:  0.32997817
Encoder Loss:  0.039557744  || Decoder Loss:  0.035366666 Validation Decoder Loss:  0.33207858
Encoder Loss:  0.041033067  || Decoder Loss:  0.037471667 Validation Decoder Loss:  0.33254504
Encoder Loss:  0.03991477  || Decoder Loss:  0.035808954 Validation Decoder Loss:  0.33096457
Encoder Loss:  0.039493397  || Decoder Loss:  0.035341814 Validation Decoder Loss:  0.33155048
Encoder Loss:  0.039508827  || Decoder Loss:  0.0353521 Validation Decoder Loss:  0.3326004
Encoder Loss:  0.039594766  || Decoder Loss:  0.035483673 Validation Decoder Loss:  0.33146298
Encoder Loss:  0.03949355  || Decoder Loss:  0.035347793 Validation Decoder Loss:  0.33054656
Encoder Loss:  0.03969415  || Decoder Loss:  0.03562397 Validation Decoder Loss:  0.33578426
Encoder Loss:  0.039774314  || Decoder Loss:  0.03571934 Validation Decoder Loss:  0.32570824
Encoder Loss:  0.04085698  || Decoder Loss:  0.037141863 Validation Decoder Loss:  0.33123463
Encoder Loss:  0.03949393  || Decoder Loss:  0.035343662 Validation Decoder Loss:  0.33175772
Encoder Loss:  0.039470777  || Decoder Loss:  0.035341673 Validation Decoder Loss:  0.3313368
Encoder Loss:  0.039601985  || Decoder Loss:  0.03551974 Validation Decoder Loss:  0.33809018
Encoder Loss:  0.040482435  || Decoder Loss:  0.036720507 Validation Decoder Loss:  0.33060318
Encoder Loss:  0.039469633  || Decoder Loss:  0.035341818 Validation Decoder Loss:  0.33172253
Encoder Loss:  0.04074023  || Decoder Loss:  0.037090536 Validation Decoder Loss:  0.33105153
Encoder Loss:  0.03947669  || Decoder Loss:  0.03535385 Validation Decoder Loss:  0.33456588
Encoder Loss:  0.039489485  || Decoder Loss:  0.035361703 Validation Decoder Loss:  0.33286875
Model: siamese_net_lr_0.43477578260507077 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33286875
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_120 (Conv3D (None, 242, 5, 20, 1)     180       
_________________________________________________________________
dropout_300 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_121 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_81 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_302 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_101 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_304 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_101 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4115008  || Decoder Loss:  0.4819055 Validation Decoder Loss:  0.9980962
Encoder Loss:  0.4126569  || Decoder Loss:  0.48584858 Validation Decoder Loss:  0.96984744
Encoder Loss:  0.08957308  || Decoder Loss:  0.09747327 Validation Decoder Loss:  0.33794588
Encoder Loss:  0.05663586  || Decoder Loss:  0.057873294 Validation Decoder Loss:  0.32869965
Encoder Loss:  0.10097531  || Decoder Loss:  0.11120143 Validation Decoder Loss:  0.3424014
Encoder Loss:  0.040553197  || Decoder Loss:  0.03862209 Validation Decoder Loss:  0.3385502
Encoder Loss:  0.040316567  || Decoder Loss:  0.03835474 Validation Decoder Loss:  0.33731434
Encoder Loss:  0.039362766  || Decoder Loss:  0.037210293 Validation Decoder Loss:  0.3539003
Encoder Loss:  0.4047987  || Decoder Loss:  0.47631413 Validation Decoder Loss:  0.9434601
Encoder Loss:  0.060879227  || Decoder Loss:  0.063076526 Validation Decoder Loss:  0.34355402
Encoder Loss:  0.045848574  || Decoder Loss:  0.045008622 Validation Decoder Loss:  0.34044957
Encoder Loss:  0.041260567  || Decoder Loss:  0.0394928 Validation Decoder Loss:  0.33998775
Encoder Loss:  0.04103847  || Decoder Loss:  0.039222218 Validation Decoder Loss:  0.33260933
Encoder Loss:  0.04076675  || Decoder Loss:  0.03889901 Validation Decoder Loss:  0.3341682
Encoder Loss:  0.0406069  || Decoder Loss:  0.038705744 Validation Decoder Loss:  0.3380241
Encoder Loss:  0.0400792  || Decoder Loss:  0.03807283 Validation Decoder Loss:  0.33357412
Encoder Loss:  0.0414652  || Decoder Loss:  0.039737597 Validation Decoder Loss:  0.33450294
Encoder Loss:  0.040263705  || Decoder Loss:  0.038294297 Validation Decoder Loss:  0.33477056
Encoder Loss:  0.040291004  || Decoder Loss:  0.038327187 Validation Decoder Loss:  0.3356763
Encoder Loss:  0.040021442  || Decoder Loss:  0.03800322 Validation Decoder Loss:  0.33589804
Encoder Loss:  0.34241143  || Decoder Loss:  0.4014368 Validation Decoder Loss:  1.1922982
Encoder Loss:  0.42397243  || Decoder Loss:  0.49956775 Validation Decoder Loss:  0.75869906
Encoder Loss:  0.43223724  || Decoder Loss:  0.5095032 Validation Decoder Loss:  1.2054875
Encoder Loss:  0.41705006  || Decoder Loss:  0.4912463 Validation Decoder Loss:  1.1728592
Encoder Loss:  0.42568374  || Decoder Loss:  0.50162584 Validation Decoder Loss:  1.1708388
Encoder Loss:  0.42048717  || Decoder Loss:  0.4953781 Validation Decoder Loss:  1.1634985
Encoder Loss:  0.4184576  || Decoder Loss:  0.4929406 Validation Decoder Loss:  0.76519036
Encoder Loss:  0.20808017  || Decoder Loss:  0.24003547 Validation Decoder Loss:  0.34214225
Encoder Loss:  0.041325856  || Decoder Loss:  0.039572086 Validation Decoder Loss:  0.3279602
Encoder Loss:  0.039981104  || Decoder Loss:  0.037955437 Validation Decoder Loss:  0.33689317
Encoder Loss:  0.039729685  || Decoder Loss:  0.037653036 Validation Decoder Loss:  0.33681107
Encoder Loss:  0.040354248  || Decoder Loss:  0.03840367 Validation Decoder Loss:  0.33752906
Encoder Loss:  0.03952403  || Decoder Loss:  0.037405588 Validation Decoder Loss:  0.3457247
Encoder Loss:  0.040858272  || Decoder Loss:  0.03900988 Validation Decoder Loss:  0.33207035
Encoder Loss:  0.039828785  || Decoder Loss:  0.03777212 Validation Decoder Loss:  0.33386606
Encoder Loss:  0.040373728  || Decoder Loss:  0.038427263 Validation Decoder Loss:  0.33069086
Encoder Loss:  0.039980426  || Decoder Loss:  0.0379533 Validation Decoder Loss:  0.3334221
Encoder Loss:  0.0395114  || Decoder Loss:  0.03739086 Validation Decoder Loss:  0.34873804
Encoder Loss:  0.03967471  || Decoder Loss:  0.037587125 Validation Decoder Loss:  0.3350708
Encoder Loss:  0.040311903  || Decoder Loss:  0.03835308 Validation Decoder Loss:  0.33339036
Model: siamese_net_lr_0.49884945609090214 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33339036
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_123 (Conv3D (None, 242, 5, 20, 1)     180       
_________________________________________________________________
dropout_306 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_124 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_82 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_308 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_103 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_310 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_103 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2940277  || Decoder Loss:  0.35259795 Validation Decoder Loss:  0.33395305
Encoder Loss:  0.04051467  || Decoder Loss:  0.038139425 Validation Decoder Loss:  0.32865226
Encoder Loss:  0.039498735  || Decoder Loss:  0.036864344 Validation Decoder Loss:  0.32459098
Encoder Loss:  0.38810918  || Decoder Loss:  0.46994144 Validation Decoder Loss:  1.1836739
Encoder Loss:  0.41808832  || Decoder Loss:  0.5100716 Validation Decoder Loss:  0.8009379
Encoder Loss:  0.41722736  || Decoder Loss:  0.50899434 Validation Decoder Loss:  0.78202915
Encoder Loss:  0.40055913  || Decoder Loss:  0.4881582 Validation Decoder Loss:  0.7487216
Encoder Loss:  0.40533447  || Decoder Loss:  0.4941265 Validation Decoder Loss:  0.77058065
Encoder Loss:  0.40467876  || Decoder Loss:  0.49330676 Validation Decoder Loss:  0.7723031
Encoder Loss:  0.41099504  || Decoder Loss:  0.5012047 Validation Decoder Loss:  0.97570384
Encoder Loss:  0.41744766  || Decoder Loss:  0.505854 Validation Decoder Loss:  0.99754834
Encoder Loss:  0.4072631  || Decoder Loss:  0.4948883 Validation Decoder Loss:  0.996001
Encoder Loss:  0.40696773  || Decoder Loss:  0.49485415 Validation Decoder Loss:  0.99656725
Encoder Loss:  0.40662488  || Decoder Loss:  0.49474755 Validation Decoder Loss:  1.0060409
Encoder Loss:  0.40740898  || Decoder Loss:  0.49671116 Validation Decoder Loss:  1.0037587
Encoder Loss:  0.40711766  || Decoder Loss:  0.49636087 Validation Decoder Loss:  1.0042067
Encoder Loss:  0.40405223  || Decoder Loss:  0.4925281 Validation Decoder Loss:  0.9883667
Encoder Loss:  0.40543187  || Decoder Loss:  0.4942511 Validation Decoder Loss:  0.9940719
Encoder Loss:  0.40108916  || Decoder Loss:  0.48879954 Validation Decoder Loss:  0.963253
Encoder Loss:  0.39453167  || Decoder Loss:  0.48060417 Validation Decoder Loss:  0.9885186
Encoder Loss:  0.38898084  || Decoder Loss:  0.47367668 Validation Decoder Loss:  0.9835414
Encoder Loss:  0.39191407  || Decoder Loss:  0.47728243 Validation Decoder Loss:  0.94766635
Encoder Loss:  0.389984  || Decoder Loss:  0.47493976 Validation Decoder Loss:  1.0005283
Encoder Loss:  0.3822178  || Decoder Loss:  0.46510902 Validation Decoder Loss:  0.95719194
Encoder Loss:  0.39801076  || Decoder Loss:  0.48497626 Validation Decoder Loss:  0.9912944
Encoder Loss:  0.40001878  || Decoder Loss:  0.48748496 Validation Decoder Loss:  0.9813585
Encoder Loss:  0.4017038  || Decoder Loss:  0.48959625 Validation Decoder Loss:  0.99640167
Encoder Loss:  0.4081  || Decoder Loss:  0.49759132 Validation Decoder Loss:  0.99272704
Encoder Loss:  0.39425564  || Decoder Loss:  0.48028678 Validation Decoder Loss:  0.98922086
Encoder Loss:  0.38387492  || Decoder Loss:  0.46731204 Validation Decoder Loss:  0.95964885
Encoder Loss:  0.29131874  || Decoder Loss:  0.35161704 Validation Decoder Loss:  0.46928394
Encoder Loss:  0.056365255  || Decoder Loss:  0.057955697 Validation Decoder Loss:  0.3462682
Encoder Loss:  0.05430564  || Decoder Loss:  0.055381294 Validation Decoder Loss:  0.36913675
Encoder Loss:  0.0556637  || Decoder Loss:  0.057078157 Validation Decoder Loss:  0.34694803
Encoder Loss:  0.05470092  || Decoder Loss:  0.055874392 Validation Decoder Loss:  0.41776127
Encoder Loss:  0.049446594  || Decoder Loss:  0.049307924 Validation Decoder Loss:  0.37467748
Encoder Loss:  0.046638638  || Decoder Loss:  0.045795675 Validation Decoder Loss:  0.3469115
Encoder Loss:  0.04713484  || Decoder Loss:  0.046418596 Validation Decoder Loss:  0.34958827
Encoder Loss:  0.04627028  || Decoder Loss:  0.04533756 Validation Decoder Loss:  0.35521314
Encoder Loss:  0.07377437  || Decoder Loss:  0.07971061 Validation Decoder Loss:  0.34727502
Model: siamese_net_lr_0.5202614217267006 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34727502
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_126 (Conv3D (None, 200, 6, 20, 1)     149       
_________________________________________________________________
dropout_312 (Dropout)        (None, 200, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_127 (Conv3D (None, 257, 10, 20, 1)    291       
_________________________________________________________________
reshape_83 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 440
Trainable params: 440
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_314 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_105 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_316 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_105 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27330875  || Decoder Loss:  0.4764162 Validation Decoder Loss:  0.90342885
Encoder Loss:  0.2738919  || Decoder Loss:  0.49249253 Validation Decoder Loss:  1.0408177
Encoder Loss:  0.27409318  || Decoder Loss:  0.493159 Validation Decoder Loss:  1.0446382
Encoder Loss:  0.27409354  || Decoder Loss:  0.49439964 Validation Decoder Loss:  1.0079341
Encoder Loss:  0.2752663  || Decoder Loss:  0.49583584 Validation Decoder Loss:  1.0062157
Encoder Loss:  0.27370203  || Decoder Loss:  0.4936846 Validation Decoder Loss:  1.0032914
Encoder Loss:  0.2736832  || Decoder Loss:  0.49360058 Validation Decoder Loss:  1.0064398
Encoder Loss:  0.27363873  || Decoder Loss:  0.4934935 Validation Decoder Loss:  1.0118402
Encoder Loss:  0.27340734  || Decoder Loss:  0.4867133 Validation Decoder Loss:  0.9702303
Encoder Loss:  0.27638564  || Decoder Loss:  0.49779782 Validation Decoder Loss:  1.0060043
Encoder Loss:  0.27399382  || Decoder Loss:  0.4943653 Validation Decoder Loss:  1.0127046
Encoder Loss:  0.27241156  || Decoder Loss:  0.49120522 Validation Decoder Loss:  1.0450928
Encoder Loss:  0.26623  || Decoder Loss:  0.47891825 Validation Decoder Loss:  0.79649115
Encoder Loss:  0.27381533  || Decoder Loss:  0.49397385 Validation Decoder Loss:  1.0103472
Encoder Loss:  0.26800457  || Decoder Loss:  0.48225638 Validation Decoder Loss:  0.9680635
Encoder Loss:  0.26754886  || Decoder Loss:  0.48155785 Validation Decoder Loss:  0.9105555
Encoder Loss:  0.2720185  || Decoder Loss:  0.49042085 Validation Decoder Loss:  0.9248715
Encoder Loss:  0.27055982  || Decoder Loss:  0.487512 Validation Decoder Loss:  0.90216184
Encoder Loss:  0.2691032  || Decoder Loss:  0.48439637 Validation Decoder Loss:  0.8013389
Encoder Loss:  0.26719144  || Decoder Loss:  0.48087537 Validation Decoder Loss:  0.8882004
Encoder Loss:  0.2689546  || Decoder Loss:  0.4843597 Validation Decoder Loss:  0.8396257
Encoder Loss:  0.26079693  || Decoder Loss:  0.4681455 Validation Decoder Loss:  0.6703656
Encoder Loss:  0.2637038  || Decoder Loss:  0.47390136 Validation Decoder Loss:  0.8800627
Encoder Loss:  0.2667527  || Decoder Loss:  0.47999656 Validation Decoder Loss:  0.8836009
Encoder Loss:  0.26993796  || Decoder Loss:  0.48630384 Validation Decoder Loss:  0.95892376
Encoder Loss:  0.274819  || Decoder Loss:  0.4959898 Validation Decoder Loss:  1.0017097
Encoder Loss:  0.27593154  || Decoder Loss:  0.4979867 Validation Decoder Loss:  0.9846065
Encoder Loss:  0.27329713  || Decoder Loss:  0.49300516 Validation Decoder Loss:  0.9666836
Encoder Loss:  0.27013528  || Decoder Loss:  0.4867217 Validation Decoder Loss:  0.8450068
Encoder Loss:  0.2669217  || Decoder Loss:  0.48034802 Validation Decoder Loss:  0.89515567
Encoder Loss:  0.26913035  || Decoder Loss:  0.48471886 Validation Decoder Loss:  0.87575376
Encoder Loss:  0.2671827  || Decoder Loss:  0.48068467 Validation Decoder Loss:  0.81062585
Encoder Loss:  0.26700795  || Decoder Loss:  0.48052144 Validation Decoder Loss:  0.8465613
Encoder Loss:  0.2697862  || Decoder Loss:  0.4860269 Validation Decoder Loss:  0.8143513
Encoder Loss:  0.26777512  || Decoder Loss:  0.48203865 Validation Decoder Loss:  0.8257723
Encoder Loss:  0.26619053  || Decoder Loss:  0.4788922 Validation Decoder Loss:  0.78292894
Encoder Loss:  0.2637191  || Decoder Loss:  0.4738975 Validation Decoder Loss:  1.0263388
Encoder Loss:  0.27467316  || Decoder Loss:  0.4957421 Validation Decoder Loss:  1.0135185
Encoder Loss:  0.27387175  || Decoder Loss:  0.49414426 Validation Decoder Loss:  1.0079811
Encoder Loss:  0.27226186  || Decoder Loss:  0.49094445 Validation Decoder Loss:  0.8504946
Model: siamese_net_lr_0.8423465553632883 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8504945
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_129 (Conv3D (None, 234, 10, 20, 1)    1027      
_________________________________________________________________
dropout_318 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_130 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_84 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,052
Trainable params: 1,052
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_320 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_322 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4381511  || Decoder Loss:  0.6342223 Validation Decoder Loss:  0.80810297
Encoder Loss:  0.3018389  || Decoder Loss:  0.49346015 Validation Decoder Loss:  0.79507077
Encoder Loss:  0.3030153  || Decoder Loss:  0.49447986 Validation Decoder Loss:  1.2354097
Encoder Loss:  0.30070022  || Decoder Loss:  0.49417755 Validation Decoder Loss:  1.2480413
Encoder Loss:  0.3011355  || Decoder Loss:  0.49543574 Validation Decoder Loss:  1.2499368
Encoder Loss:  0.29699045  || Decoder Loss:  0.48603302 Validation Decoder Loss:  1.1570193
Encoder Loss:  0.29259652  || Decoder Loss:  0.48178318 Validation Decoder Loss:  0.7664596
Encoder Loss:  0.29782856  || Decoder Loss:  0.49225736 Validation Decoder Loss:  0.72502565
Encoder Loss:  0.29165393  || Decoder Loss:  0.48038855 Validation Decoder Loss:  1.2008861
Encoder Loss:  0.2926974  || Decoder Loss:  0.48134214 Validation Decoder Loss:  0.70377403
Encoder Loss:  0.2968949  || Decoder Loss:  0.48974273 Validation Decoder Loss:  0.75124854
Encoder Loss:  0.29408744  || Decoder Loss:  0.4862093 Validation Decoder Loss:  0.745098
Encoder Loss:  0.27452648  || Decoder Loss:  0.45148972 Validation Decoder Loss:  0.6832795
Encoder Loss:  0.27474868  || Decoder Loss:  0.4500369 Validation Decoder Loss:  0.7387936
Encoder Loss:  0.291528  || Decoder Loss:  0.48076674 Validation Decoder Loss:  0.74056464
Encoder Loss:  0.19727777  || Decoder Loss:  0.31120563 Validation Decoder Loss:  0.3082881
Encoder Loss:  0.053708125  || Decoder Loss:  0.053486496 Validation Decoder Loss:  0.34378302
Encoder Loss:  0.049563896  || Decoder Loss:  0.045019817 Validation Decoder Loss:  0.34072965
Encoder Loss:  0.0479104  || Decoder Loss:  0.04253357 Validation Decoder Loss:  0.3409596
Encoder Loss:  0.047200676  || Decoder Loss:  0.041168895 Validation Decoder Loss:  0.33946085
Encoder Loss:  0.047316972  || Decoder Loss:  0.04066304 Validation Decoder Loss:  0.32944334
Encoder Loss:  0.046879277  || Decoder Loss:  0.04022026 Validation Decoder Loss:  0.33862847
Encoder Loss:  0.047026586  || Decoder Loss:  0.039808873 Validation Decoder Loss:  0.33754432
Encoder Loss:  0.04592023  || Decoder Loss:  0.039299715 Validation Decoder Loss:  0.3375783
Encoder Loss:  0.04539341  || Decoder Loss:  0.038674075 Validation Decoder Loss:  0.32963634
Encoder Loss:  0.04528464  || Decoder Loss:  0.038325183 Validation Decoder Loss:  0.336197
Encoder Loss:  0.045399565  || Decoder Loss:  0.037633456 Validation Decoder Loss:  0.33626437
Encoder Loss:  0.044575416  || Decoder Loss:  0.0367106 Validation Decoder Loss:  0.33613044
Encoder Loss:  0.043480948  || Decoder Loss:  0.03592226 Validation Decoder Loss:  0.33476102
Encoder Loss:  0.043221757  || Decoder Loss:  0.035312235 Validation Decoder Loss:  0.33193606
Encoder Loss:  0.043574534  || Decoder Loss:  0.03525105 Validation Decoder Loss:  0.33031973
Encoder Loss:  0.0422367  || Decoder Loss:  0.035241712 Validation Decoder Loss:  0.33059812
Encoder Loss:  0.041996293  || Decoder Loss:  0.035228048 Validation Decoder Loss:  0.33078954
Encoder Loss:  0.0419672  || Decoder Loss:  0.035224587 Validation Decoder Loss:  0.33082208
Encoder Loss:  0.041959234  || Decoder Loss:  0.035219423 Validation Decoder Loss:  0.33082497
Encoder Loss:  0.041962937  || Decoder Loss:  0.035214208 Validation Decoder Loss:  0.3307391
Encoder Loss:  0.042105228  || Decoder Loss:  0.035206422 Validation Decoder Loss:  0.33071285
Encoder Loss:  0.04203025  || Decoder Loss:  0.035390686 Validation Decoder Loss:  0.32999855
Encoder Loss:  0.042364445  || Decoder Loss:  0.035975605 Validation Decoder Loss:  0.3309359
Encoder Loss:  0.04339078  || Decoder Loss:  0.037591055 Validation Decoder Loss:  0.3321967
Model: siamese_net_lr_0.4096715216673248 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3321967
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_132 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_324 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_133 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_85 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 214
Trainable params: 214
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_326 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_328 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32512376  || Decoder Loss:  0.38839746 Validation Decoder Loss:  0.32352033
Encoder Loss:  0.04819376  || Decoder Loss:  0.04766912 Validation Decoder Loss:  0.32126385
Encoder Loss:  0.04873594  || Decoder Loss:  0.04834408 Validation Decoder Loss:  0.32260206
Encoder Loss:  0.053836726  || Decoder Loss:  0.05475295 Validation Decoder Loss:  0.30365503
Encoder Loss:  0.05739044  || Decoder Loss:  0.059225034 Validation Decoder Loss:  0.32517293
Encoder Loss:  0.038457595  || Decoder Loss:  0.03553896 Validation Decoder Loss:  0.32426652
Encoder Loss:  0.03815315  || Decoder Loss:  0.03516169 Validation Decoder Loss:  0.32385528
Encoder Loss:  0.03827565  || Decoder Loss:  0.035317637 Validation Decoder Loss:  0.33064294
Encoder Loss:  0.038497865  || Decoder Loss:  0.035596855 Validation Decoder Loss:  0.33564794
Encoder Loss:  0.54947096  || Decoder Loss:  0.6750038 Validation Decoder Loss:  1.565316
Encoder Loss:  0.38332027  || Decoder Loss:  0.4672822 Validation Decoder Loss:  0.7441002
Encoder Loss:  0.28516957  || Decoder Loss:  0.34440482 Validation Decoder Loss:  0.58128303
Encoder Loss:  0.13488407  || Decoder Loss:  0.15626891 Validation Decoder Loss:  0.3598583
Encoder Loss:  0.3790325  || Decoder Loss:  0.46194828 Validation Decoder Loss:  0.99756324
Encoder Loss:  0.40821466  || Decoder Loss:  0.4984853 Validation Decoder Loss:  0.96961695
Encoder Loss:  0.15941225  || Decoder Loss:  0.18698385 Validation Decoder Loss:  0.62960654
Encoder Loss:  0.21501416  || Decoder Loss:  0.2565993 Validation Decoder Loss:  0.8563414
Encoder Loss:  0.20025235  || Decoder Loss:  0.23811784 Validation Decoder Loss:  0.3292688
Encoder Loss:  0.04203304  || Decoder Loss:  0.040024742 Validation Decoder Loss:  0.33547485
Encoder Loss:  0.090943106  || Decoder Loss:  0.101230904 Validation Decoder Loss:  0.33562285
Encoder Loss:  0.04238505  || Decoder Loss:  0.04046514 Validation Decoder Loss:  0.33500654
Encoder Loss:  0.043401103  || Decoder Loss:  0.041737698 Validation Decoder Loss:  0.33248445
Encoder Loss:  0.040839385  || Decoder Loss:  0.0385306 Validation Decoder Loss:  0.3367411
Encoder Loss:  0.04055643  || Decoder Loss:  0.03817636 Validation Decoder Loss:  0.33445913
Encoder Loss:  0.31978494  || Decoder Loss:  0.38770747 Validation Decoder Loss:  1.1732197
Encoder Loss:  0.39480084  || Decoder Loss:  0.4816879 Validation Decoder Loss:  0.68621975
Encoder Loss:  0.31523854  || Decoder Loss:  0.38162437 Validation Decoder Loss:  0.3164964
Encoder Loss:  0.048878364  || Decoder Loss:  0.048590712 Validation Decoder Loss:  0.33943188
Encoder Loss:  0.044249404  || Decoder Loss:  0.042797543 Validation Decoder Loss:  0.3506793
Encoder Loss:  0.36266077  || Decoder Loss:  0.441353 Validation Decoder Loss:  0.9002357
Encoder Loss:  0.36874905  || Decoder Loss:  0.4490752 Validation Decoder Loss:  0.83664644
Encoder Loss:  0.35716033  || Decoder Loss:  0.43456578 Validation Decoder Loss:  0.751577
Encoder Loss:  0.12793675  || Decoder Loss:  0.14757642 Validation Decoder Loss:  0.3145712
Encoder Loss:  0.04174164  || Decoder Loss:  0.039659552 Validation Decoder Loss:  0.34409046
Encoder Loss:  0.04278403  || Decoder Loss:  0.040965 Validation Decoder Loss:  0.33221972
Encoder Loss:  0.044502884  || Decoder Loss:  0.043117154 Validation Decoder Loss:  0.33446735
Encoder Loss:  0.044001292  || Decoder Loss:  0.042489216 Validation Decoder Loss:  0.336429
Encoder Loss:  0.04365465  || Decoder Loss:  0.042055205 Validation Decoder Loss:  0.3382434
Encoder Loss:  0.041476987  || Decoder Loss:  0.039328605 Validation Decoder Loss:  0.3341739
Encoder Loss:  0.044228368  || Decoder Loss:  0.042773318 Validation Decoder Loss:  0.3030849
Model: siamese_net_lr_0.5218077936542972 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3030849
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_135 (Conv3D (None, 234, 10, 20, 1)    217       
_________________________________________________________________
dropout_330 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_136 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_86 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_332 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_334 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05084751  || Decoder Loss:  0.045737214 Validation Decoder Loss:  0.3275586
Encoder Loss:  0.043146536  || Decoder Loss:  0.03665974 Validation Decoder Loss:  0.328414
Encoder Loss:  0.042987127  || Decoder Loss:  0.036352094 Validation Decoder Loss:  0.32930335
Encoder Loss:  0.042908594  || Decoder Loss:  0.03620442 Validation Decoder Loss:  0.32946342
Encoder Loss:  0.04284276  || Decoder Loss:  0.03608785 Validation Decoder Loss:  0.3292693
Encoder Loss:  0.04292074  || Decoder Loss:  0.035950407 Validation Decoder Loss:  0.32936805
Encoder Loss:  0.08248994  || Decoder Loss:  0.110617 Validation Decoder Loss:  0.32773915
Encoder Loss:  0.042627744  || Decoder Loss:  0.035665218 Validation Decoder Loss:  0.33055884
Encoder Loss:  0.04259687  || Decoder Loss:  0.03561393 Validation Decoder Loss:  0.33040783
Encoder Loss:  0.042568497  || Decoder Loss:  0.03556263 Validation Decoder Loss:  0.3304376
Encoder Loss:  0.04253991  || Decoder Loss:  0.035508987 Validation Decoder Loss:  0.330335
Encoder Loss:  0.042516164  || Decoder Loss:  0.03546194 Validation Decoder Loss:  0.3301974
Encoder Loss:  0.042509913  || Decoder Loss:  0.03545073 Validation Decoder Loss:  0.32875133
Encoder Loss:  0.042673893  || Decoder Loss:  0.035768062 Validation Decoder Loss:  0.32691336
Encoder Loss:  0.042683125  || Decoder Loss:  0.03578807 Validation Decoder Loss:  0.3269817
Encoder Loss:  0.042672515  || Decoder Loss:  0.03576326 Validation Decoder Loss:  0.32759273
Encoder Loss:  0.042663623  || Decoder Loss:  0.035747048 Validation Decoder Loss:  0.32704213
Encoder Loss:  0.042689577  || Decoder Loss:  0.035779838 Validation Decoder Loss:  0.32763046
Encoder Loss:  0.04264067  || Decoder Loss:  0.035704993 Validation Decoder Loss:  0.3283882
Encoder Loss:  0.042727534  || Decoder Loss:  0.035808727 Validation Decoder Loss:  0.3281409
Encoder Loss:  0.0426361  || Decoder Loss:  0.03567563 Validation Decoder Loss:  0.3293421
Encoder Loss:  0.13506214  || Decoder Loss:  0.20134436 Validation Decoder Loss:  0.3405105
Encoder Loss:  0.042902816  || Decoder Loss:  0.036189914 Validation Decoder Loss:  0.32939124
Encoder Loss:  0.042751316  || Decoder Loss:  0.035909053 Validation Decoder Loss:  0.32956666
Encoder Loss:  0.0428216  || Decoder Loss:  0.0360464 Validation Decoder Loss:  0.3281076
Encoder Loss:  0.04304719  || Decoder Loss:  0.036490727 Validation Decoder Loss:  0.32798144
Encoder Loss:  0.043085165  || Decoder Loss:  0.03656037 Validation Decoder Loss:  0.32801116
Encoder Loss:  0.043073438  || Decoder Loss:  0.036539286 Validation Decoder Loss:  0.3280542
Encoder Loss:  0.04306877  || Decoder Loss:  0.036524225 Validation Decoder Loss:  0.32807028
Encoder Loss:  0.04305443  || Decoder Loss:  0.03650045 Validation Decoder Loss:  0.32812437
Encoder Loss:  0.043048687  || Decoder Loss:  0.036484897 Validation Decoder Loss:  0.32816347
Encoder Loss:  0.04302808  || Decoder Loss:  0.036451474 Validation Decoder Loss:  0.32818627
Encoder Loss:  0.0430314  || Decoder Loss:  0.0364498 Validation Decoder Loss:  0.32824504
Encoder Loss:  0.04300971  || Decoder Loss:  0.036415145 Validation Decoder Loss:  0.3283046
Encoder Loss:  0.04302496  || Decoder Loss:  0.036429778 Validation Decoder Loss:  0.32841393
Encoder Loss:  0.04300019  || Decoder Loss:  0.036386438 Validation Decoder Loss:  0.3284372
Encoder Loss:  0.043063056  || Decoder Loss:  0.036504477 Validation Decoder Loss:  0.32903355
Encoder Loss:  0.042952348  || Decoder Loss:  0.036275666 Validation Decoder Loss:  0.32857162
Encoder Loss:  0.042953923  || Decoder Loss:  0.036305252 Validation Decoder Loss:  0.3285852
Encoder Loss:  0.042947263  || Decoder Loss:  0.036292125 Validation Decoder Loss:  0.3286286
Model: siamese_net_lr_0.4377004557043699 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3286286
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_138 (Conv3D (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_336 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_139 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_87 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_338 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_340 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21178037  || Decoder Loss:  0.33370054 Validation Decoder Loss:  0.8733036
Encoder Loss:  0.19118853  || Decoder Loss:  0.30498818 Validation Decoder Loss:  0.3200311
Encoder Loss:  0.04227102  || Decoder Loss:  0.03602133 Validation Decoder Loss:  0.33051094
Encoder Loss:  0.042174414  || Decoder Loss:  0.035854816 Validation Decoder Loss:  0.33055386
Encoder Loss:  0.042162556  || Decoder Loss:  0.03583842 Validation Decoder Loss:  0.3306065
Encoder Loss:  0.04215211  || Decoder Loss:  0.03582039 Validation Decoder Loss:  0.3304436
Encoder Loss:  0.042142227  || Decoder Loss:  0.035801716 Validation Decoder Loss:  0.33062902
Encoder Loss:  0.042197734  || Decoder Loss:  0.035896193 Validation Decoder Loss:  0.3282252
Encoder Loss:  0.042371526  || Decoder Loss:  0.03620239 Validation Decoder Loss:  0.32681865
Encoder Loss:  0.042409822  || Decoder Loss:  0.036257204 Validation Decoder Loss:  0.32739767
Encoder Loss:  0.042516723  || Decoder Loss:  0.036420964 Validation Decoder Loss:  0.32595742
Encoder Loss:  0.042387523  || Decoder Loss:  0.03624545 Validation Decoder Loss:  0.3261558
Encoder Loss:  0.042296257  || Decoder Loss:  0.036028847 Validation Decoder Loss:  0.32696494
Encoder Loss:  0.043406714  || Decoder Loss:  0.037802767 Validation Decoder Loss:  0.3256947
Encoder Loss:  0.042309556  || Decoder Loss:  0.03606442 Validation Decoder Loss:  0.3275769
Encoder Loss:  0.047223005  || Decoder Loss:  0.043225303 Validation Decoder Loss:  0.4249574
Encoder Loss:  0.11602156  || Decoder Loss:  0.15315863 Validation Decoder Loss:  0.33878773
Encoder Loss:  0.04253274  || Decoder Loss:  0.03647571 Validation Decoder Loss:  0.3271258
Encoder Loss:  0.0423788  || Decoder Loss:  0.03622184 Validation Decoder Loss:  0.32317123
Encoder Loss:  0.042577907  || Decoder Loss:  0.036587022 Validation Decoder Loss:  0.32484293
Encoder Loss:  0.042596772  || Decoder Loss:  0.0366246 Validation Decoder Loss:  0.322129
Encoder Loss:  0.04261815  || Decoder Loss:  0.03666323 Validation Decoder Loss:  0.32474923
Encoder Loss:  0.042562414  || Decoder Loss:  0.036563136 Validation Decoder Loss:  0.32241648
Encoder Loss:  0.042559195  || Decoder Loss:  0.036556616 Validation Decoder Loss:  0.32514197
Encoder Loss:  0.042503905  || Decoder Loss:  0.036457013 Validation Decoder Loss:  0.32527998
Encoder Loss:  0.042475224  || Decoder Loss:  0.036405586 Validation Decoder Loss:  0.3254417
Encoder Loss:  0.042445507  || Decoder Loss:  0.03635163 Validation Decoder Loss:  0.32558316
Encoder Loss:  0.0424077  || Decoder Loss:  0.036284097 Validation Decoder Loss:  0.32566306
Encoder Loss:  0.042371985  || Decoder Loss:  0.036219142 Validation Decoder Loss:  0.32572344
Encoder Loss:  0.042361297  || Decoder Loss:  0.036200605 Validation Decoder Loss:  0.3259892
Encoder Loss:  0.04233757  || Decoder Loss:  0.03615798 Validation Decoder Loss:  0.32526284
Encoder Loss:  0.042323217  || Decoder Loss:  0.03613167 Validation Decoder Loss:  0.32633883
Encoder Loss:  0.042284813  || Decoder Loss:  0.03605778 Validation Decoder Loss:  0.32538283
Encoder Loss:  0.04231932  || Decoder Loss:  0.03612261 Validation Decoder Loss:  0.3204682
Encoder Loss:  0.042236887  || Decoder Loss:  0.035973072 Validation Decoder Loss:  0.3254242
Encoder Loss:  0.042255405  || Decoder Loss:  0.035999916 Validation Decoder Loss:  0.32944435
Encoder Loss:  0.044860654  || Decoder Loss:  0.040711608 Validation Decoder Loss:  0.31431952
Encoder Loss:  0.041916367  || Decoder Loss:  0.03539417 Validation Decoder Loss:  0.3303933
Encoder Loss:  0.041887056  || Decoder Loss:  0.035282794 Validation Decoder Loss:  0.33099437
Encoder Loss:  0.041926093  || Decoder Loss:  0.03532108 Validation Decoder Loss:  0.32703328
Model: siamese_net_lr_0.48867799774389215 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32703328
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_141 (Conv3D (None, 182, 5, 20, 1)     57        
_________________________________________________________________
dropout_342 (Dropout)        (None, 182, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_142 (Conv3D (None, 257, 10, 20, 1)    457       
_________________________________________________________________
reshape_88 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 514
Trainable params: 514
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_344 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_346 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22442329  || Decoder Loss:  0.4485401 Validation Decoder Loss:  0.5093987
Encoder Loss:  0.053209867  || Decoder Loss:  0.052958325 Validation Decoder Loss:  0.33444676
Encoder Loss:  0.04785942  || Decoder Loss:  0.04209981 Validation Decoder Loss:  0.34098917
Encoder Loss:  0.04687616  || Decoder Loss:  0.04001651 Validation Decoder Loss:  0.3324607
Encoder Loss:  0.05111885  || Decoder Loss:  0.047957756 Validation Decoder Loss:  0.34858453
Encoder Loss:  0.04908545  || Decoder Loss:  0.044957563 Validation Decoder Loss:  0.34555054
Encoder Loss:  0.047624774  || Decoder Loss:  0.04239656 Validation Decoder Loss:  0.33241403
Encoder Loss:  0.048604988  || Decoder Loss:  0.043994207 Validation Decoder Loss:  0.3375348
Encoder Loss:  0.049182996  || Decoder Loss:  0.04508369 Validation Decoder Loss:  0.33943844
Encoder Loss:  0.04800621  || Decoder Loss:  0.0435569 Validation Decoder Loss:  0.33703223
Encoder Loss:  0.047719378  || Decoder Loss:  0.04245065 Validation Decoder Loss:  0.3354154
Encoder Loss:  0.046954017  || Decoder Loss:  0.04120479 Validation Decoder Loss:  0.33241516
Encoder Loss:  0.046894673  || Decoder Loss:  0.040886927 Validation Decoder Loss:  0.33581713
Encoder Loss:  0.048012543  || Decoder Loss:  0.0433491 Validation Decoder Loss:  0.33620128
Encoder Loss:  0.046601973  || Decoder Loss:  0.040641345 Validation Decoder Loss:  0.33599657
Encoder Loss:  0.047079664  || Decoder Loss:  0.041284114 Validation Decoder Loss:  0.35806704
Encoder Loss:  0.050667554  || Decoder Loss:  0.048180867 Validation Decoder Loss:  0.3374985
Encoder Loss:  0.047147915  || Decoder Loss:  0.04127751 Validation Decoder Loss:  0.34555072
Encoder Loss:  0.04735925  || Decoder Loss:  0.04227626 Validation Decoder Loss:  0.34845692
Encoder Loss:  0.048406426  || Decoder Loss:  0.04385035 Validation Decoder Loss:  0.3357455
Encoder Loss:  0.047062792  || Decoder Loss:  0.041920368 Validation Decoder Loss:  0.335958
Encoder Loss:  0.046833202  || Decoder Loss:  0.041079357 Validation Decoder Loss:  0.3397405
Encoder Loss:  0.04835456  || Decoder Loss:  0.04323253 Validation Decoder Loss:  0.33671457
Encoder Loss:  0.047718156  || Decoder Loss:  0.042650353 Validation Decoder Loss:  0.34390157
Encoder Loss:  0.04727624  || Decoder Loss:  0.04204863 Validation Decoder Loss:  0.3360117
Encoder Loss:  0.046745867  || Decoder Loss:  0.040882584 Validation Decoder Loss:  0.33862633
Encoder Loss:  0.047441684  || Decoder Loss:  0.04196353 Validation Decoder Loss:  0.3360356
Encoder Loss:  0.047355853  || Decoder Loss:  0.04219338 Validation Decoder Loss:  0.33649555
Encoder Loss:  0.04763175  || Decoder Loss:  0.042569228 Validation Decoder Loss:  0.33807606
Encoder Loss:  0.046937227  || Decoder Loss:  0.041203685 Validation Decoder Loss:  0.33686477
Encoder Loss:  0.09004801  || Decoder Loss:  0.14595218 Validation Decoder Loss:  0.9629942
Encoder Loss:  0.09338642  || Decoder Loss:  0.15372147 Validation Decoder Loss:  0.3394583
Encoder Loss:  0.046847083  || Decoder Loss:  0.040746227 Validation Decoder Loss:  0.33625525
Encoder Loss:  0.046976242  || Decoder Loss:  0.041463677 Validation Decoder Loss:  0.33209127
Encoder Loss:  0.04782432  || Decoder Loss:  0.04315478 Validation Decoder Loss:  0.3348257
Encoder Loss:  0.047120623  || Decoder Loss:  0.041924372 Validation Decoder Loss:  0.33710986
Encoder Loss:  0.046837244  || Decoder Loss:  0.04097542 Validation Decoder Loss:  0.33774236
Encoder Loss:  0.048689485  || Decoder Loss:  0.04526637 Validation Decoder Loss:  0.33955434
Encoder Loss:  0.04655763  || Decoder Loss:  0.040598582 Validation Decoder Loss:  0.3371684
Encoder Loss:  0.046473607  || Decoder Loss:  0.040239386 Validation Decoder Loss:  0.337914
Model: siamese_net_lr_0.4734376764521318 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.337914
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_144 (Conv3D (None, 234, 10, 20, 1)    1027      
_________________________________________________________________
dropout_348 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_145 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_89 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,052
Trainable params: 1,052
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_350 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_352 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30830154  || Decoder Loss:  0.44517052 Validation Decoder Loss:  0.8306552
Encoder Loss:  0.31800252  || Decoder Loss:  0.48941642 Validation Decoder Loss:  0.88489527
Encoder Loss:  0.313923  || Decoder Loss:  0.48970002 Validation Decoder Loss:  0.89904714
Encoder Loss:  0.29400128  || Decoder Loss:  0.4577114 Validation Decoder Loss:  1.0434846
Encoder Loss:  0.13552648  || Decoder Loss:  0.19161122 Validation Decoder Loss:  0.32975465
Encoder Loss:  0.044911467  || Decoder Loss:  0.04141912 Validation Decoder Loss:  0.33004826
Encoder Loss:  0.04343806  || Decoder Loss:  0.03897863 Validation Decoder Loss:  0.33017266
Encoder Loss:  0.043046683  || Decoder Loss:  0.03831534 Validation Decoder Loss:  0.33016706
Encoder Loss:  0.042790823  || Decoder Loss:  0.037910115 Validation Decoder Loss:  0.33013114
Encoder Loss:  0.042631812  || Decoder Loss:  0.037649207 Validation Decoder Loss:  0.33000383
Encoder Loss:  0.042506587  || Decoder Loss:  0.0374472 Validation Decoder Loss:  0.32981166
Encoder Loss:  0.042409435  || Decoder Loss:  0.037289787 Validation Decoder Loss:  0.3297108
Encoder Loss:  0.042317685  || Decoder Loss:  0.03714056 Validation Decoder Loss:  0.32963637
Encoder Loss:  0.042232517  || Decoder Loss:  0.03699691 Validation Decoder Loss:  0.3295088
Encoder Loss:  0.04216647  || Decoder Loss:  0.036893714 Validation Decoder Loss:  0.3294425
Encoder Loss:  0.042107023  || Decoder Loss:  0.03679626 Validation Decoder Loss:  0.3293413
Encoder Loss:  0.04205533  || Decoder Loss:  0.03671 Validation Decoder Loss:  0.32927227
Encoder Loss:  0.04200639  || Decoder Loss:  0.036628496 Validation Decoder Loss:  0.32921082
Encoder Loss:  0.041962128  || Decoder Loss:  0.036552683 Validation Decoder Loss:  0.3291547
Encoder Loss:  0.04191441  || Decoder Loss:  0.03647376 Validation Decoder Loss:  0.32910192
Encoder Loss:  0.041862868  || Decoder Loss:  0.03638835 Validation Decoder Loss:  0.32905388
Encoder Loss:  0.04181264  || Decoder Loss:  0.036304872 Validation Decoder Loss:  0.32894123
Encoder Loss:  0.041781753  || Decoder Loss:  0.036252547 Validation Decoder Loss:  0.3288564
Encoder Loss:  0.04175401  || Decoder Loss:  0.036207497 Validation Decoder Loss:  0.32889026
Encoder Loss:  0.04172727  || Decoder Loss:  0.036162496 Validation Decoder Loss:  0.32895115
Encoder Loss:  0.04170054  || Decoder Loss:  0.036118552 Validation Decoder Loss:  0.32902062
Encoder Loss:  0.04167453  || Decoder Loss:  0.036075145 Validation Decoder Loss:  0.3290988
Encoder Loss:  0.041650567  || Decoder Loss:  0.03603452 Validation Decoder Loss:  0.32917827
Encoder Loss:  0.04162553  || Decoder Loss:  0.035993144 Validation Decoder Loss:  0.32926464
Encoder Loss:  0.041602712  || Decoder Loss:  0.035954896 Validation Decoder Loss:  0.32935256
Encoder Loss:  0.041580126  || Decoder Loss:  0.035917133 Validation Decoder Loss:  0.3294444
Encoder Loss:  0.041546427  || Decoder Loss:  0.03585962 Validation Decoder Loss:  0.32958642
Encoder Loss:  0.041528646  || Decoder Loss:  0.03583046 Validation Decoder Loss:  0.3296385
Encoder Loss:  0.041522466  || Decoder Loss:  0.035819672 Validation Decoder Loss:  0.32968882
Encoder Loss:  0.041523036  || Decoder Loss:  0.03582077 Validation Decoder Loss:  0.32970488
Encoder Loss:  0.04150312  || Decoder Loss:  0.035785962 Validation Decoder Loss:  0.3297636
Encoder Loss:  0.04147415  || Decoder Loss:  0.035739407 Validation Decoder Loss:  0.3298091
Encoder Loss:  0.041466933  || Decoder Loss:  0.03571924 Validation Decoder Loss:  0.32981333
Encoder Loss:  0.042489216  || Decoder Loss:  0.037101205 Validation Decoder Loss:  0.3298296
Encoder Loss:  0.045780696  || Decoder Loss:  0.038499765 Validation Decoder Loss:  0.3290596
Model: siamese_net_lr_0.4007472997386719 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3290596
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_147 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_354 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_148 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_90 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 214
Trainable params: 214
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_356 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_358 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25598872  || Decoder Loss:  0.2850998 Validation Decoder Loss:  1.0033886
Encoder Loss:  0.052650794  || Decoder Loss:  0.05304564 Validation Decoder Loss:  0.33074474
Encoder Loss:  0.038038466  || Decoder Loss:  0.03616497 Validation Decoder Loss:  0.33188713
Encoder Loss:  0.037558287  || Decoder Loss:  0.03561027 Validation Decoder Loss:  0.33181214
Encoder Loss:  0.0374344  || Decoder Loss:  0.035467222 Validation Decoder Loss:  0.32834384
Encoder Loss:  0.037377175  || Decoder Loss:  0.035400823 Validation Decoder Loss:  0.32787287
Encoder Loss:  0.03747265  || Decoder Loss:  0.03551042 Validation Decoder Loss:  0.32497054
Encoder Loss:  0.03772879  || Decoder Loss:  0.035797182 Validation Decoder Loss:  0.32845286
Encoder Loss:  0.037489325  || Decoder Loss:  0.03553035 Validation Decoder Loss:  0.3288145
Encoder Loss:  0.29668844  || Decoder Loss:  0.33519217 Validation Decoder Loss:  0.44712985
Encoder Loss:  0.037836146  || Decoder Loss:  0.03593004 Validation Decoder Loss:  0.33040845
Encoder Loss:  0.037823766  || Decoder Loss:  0.035917774 Validation Decoder Loss:  0.32841134
Encoder Loss:  0.03767403  || Decoder Loss:  0.03574466 Validation Decoder Loss:  0.3269788
Encoder Loss:  0.037657853  || Decoder Loss:  0.035725962 Validation Decoder Loss:  0.3319706
Encoder Loss:  0.03741022  || Decoder Loss:  0.035439562 Validation Decoder Loss:  0.3266681
Encoder Loss:  0.22080338  || Decoder Loss:  0.2474911 Validation Decoder Loss:  1.0023236
Encoder Loss:  0.3785799  || Decoder Loss:  0.4299846 Validation Decoder Loss:  0.98500764
Encoder Loss:  0.15260026  || Decoder Loss:  0.16865414 Validation Decoder Loss:  0.32478914
Encoder Loss:  0.037524614  || Decoder Loss:  0.035572123 Validation Decoder Loss:  0.32523775
Encoder Loss:  0.037493605  || Decoder Loss:  0.035536263 Validation Decoder Loss:  0.3243935
Encoder Loss:  0.037542135  || Decoder Loss:  0.0355923 Validation Decoder Loss:  0.33362463
Encoder Loss:  0.03750316  || Decoder Loss:  0.03554712 Validation Decoder Loss:  0.32796305
Encoder Loss:  0.14729674  || Decoder Loss:  0.16217127 Validation Decoder Loss:  1.0014249
Encoder Loss:  0.43544632  || Decoder Loss:  0.49575672 Validation Decoder Loss:  0.9892664
Encoder Loss:  0.43426934  || Decoder Loss:  0.49439633 Validation Decoder Loss:  0.9929715
Encoder Loss:  0.43314826  || Decoder Loss:  0.4931013 Validation Decoder Loss:  1.0377623
Encoder Loss:  0.43366322  || Decoder Loss:  0.4936964 Validation Decoder Loss:  0.9812015
Encoder Loss:  0.1763581  || Decoder Loss:  0.1961296 Validation Decoder Loss:  0.32147264
Encoder Loss:  0.03755559  || Decoder Loss:  0.035607927 Validation Decoder Loss:  0.32139814
Encoder Loss:  0.037511133  || Decoder Loss:  0.035556484 Validation Decoder Loss:  0.3317805
Encoder Loss:  0.037569314  || Decoder Loss:  0.035623576 Validation Decoder Loss:  0.32000053
Encoder Loss:  0.2226482  || Decoder Loss:  0.249662 Validation Decoder Loss:  0.32653993
Encoder Loss:  0.16907032  || Decoder Loss:  0.1876362 Validation Decoder Loss:  0.30289686
Encoder Loss:  0.44271696  || Decoder Loss:  0.50416493 Validation Decoder Loss:  0.6411146
Encoder Loss:  0.106059626  || Decoder Loss:  0.114830285 Validation Decoder Loss:  0.33000022
Encoder Loss:  0.038474232  || Decoder Loss:  0.0366703 Validation Decoder Loss:  0.32470042
Encoder Loss:  0.038346216  || Decoder Loss:  0.036522485 Validation Decoder Loss:  0.32883435
Encoder Loss:  0.03822224  || Decoder Loss:  0.036379077 Validation Decoder Loss:  0.32361847
Encoder Loss:  0.0378884  || Decoder Loss:  0.035992905 Validation Decoder Loss:  0.32037783
Encoder Loss:  0.03793269  || Decoder Loss:  0.0360441 Validation Decoder Loss:  0.31754643
Model: siamese_net_lr_0.4889389722792683 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31754643
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_150 (Conv3D (None, 234, 10, 20, 1)    217       
_________________________________________________________________
dropout_360 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_151 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_91 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_362 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_364 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31146288  || Decoder Loss:  0.41840488 Validation Decoder Loss:  1.0046545
Encoder Loss:  0.26995566  || Decoder Loss:  0.41174427 Validation Decoder Loss:  1.0022608
Encoder Loss:  0.25801194  || Decoder Loss:  0.39532897 Validation Decoder Loss:  0.966427
Encoder Loss:  0.20148584  || Decoder Loss:  0.2935584 Validation Decoder Loss:  0.32162094
Encoder Loss:  0.0670685  || Decoder Loss:  0.04028666 Validation Decoder Loss:  0.32580835
Encoder Loss:  0.05406334  || Decoder Loss:  0.03576903 Validation Decoder Loss:  0.33027783
Encoder Loss:  0.045445714  || Decoder Loss:  0.035608124 Validation Decoder Loss:  0.3303377
Encoder Loss:  0.04398199  || Decoder Loss:  0.035508566 Validation Decoder Loss:  0.33030176
Encoder Loss:  0.04397421  || Decoder Loss:  0.03550055 Validation Decoder Loss:  0.3302502
Encoder Loss:  0.044214197  || Decoder Loss:  0.036217283 Validation Decoder Loss:  0.32986063
Encoder Loss:  0.0442372  || Decoder Loss:  0.036901608 Validation Decoder Loss:  0.32982016
Encoder Loss:  0.044473168  || Decoder Loss:  0.037373316 Validation Decoder Loss:  0.329984
Encoder Loss:  0.04440625  || Decoder Loss:  0.03773823 Validation Decoder Loss:  0.32964617
Encoder Loss:  0.04459081  || Decoder Loss:  0.037717316 Validation Decoder Loss:  0.32952595
Encoder Loss:  0.043448  || Decoder Loss:  0.037443615 Validation Decoder Loss:  0.3297364
Encoder Loss:  0.043271165  || Decoder Loss:  0.03729202 Validation Decoder Loss:  0.3292453
Encoder Loss:  0.043140337  || Decoder Loss:  0.037075628 Validation Decoder Loss:  0.32930243
Encoder Loss:  0.043040432  || Decoder Loss:  0.03687617 Validation Decoder Loss:  0.32979518
Encoder Loss:  0.0429735  || Decoder Loss:  0.036786187 Validation Decoder Loss:  0.3298469
Encoder Loss:  0.042924337  || Decoder Loss:  0.03669816 Validation Decoder Loss:  0.32988435
Encoder Loss:  0.042881444  || Decoder Loss:  0.036618594 Validation Decoder Loss:  0.32992262
Encoder Loss:  0.042845983  || Decoder Loss:  0.036545634 Validation Decoder Loss:  0.32999927
Encoder Loss:  0.042832613  || Decoder Loss:  0.03652597 Validation Decoder Loss:  0.32964486
Encoder Loss:  0.04276737  || Decoder Loss:  0.036403608 Validation Decoder Loss:  0.33003855
Encoder Loss:  0.04277992  || Decoder Loss:  0.03641003 Validation Decoder Loss:  0.3297754
Encoder Loss:  0.04273566  || Decoder Loss:  0.036330696 Validation Decoder Loss:  0.3298496
Encoder Loss:  0.042705417  || Decoder Loss:  0.036280025 Validation Decoder Loss:  0.32986277
Encoder Loss:  0.042672418  || Decoder Loss:  0.03622478 Validation Decoder Loss:  0.32993206
Encoder Loss:  0.04265072  || Decoder Loss:  0.036181975 Validation Decoder Loss:  0.3299986
Encoder Loss:  0.0426415  || Decoder Loss:  0.03614806 Validation Decoder Loss:  0.32994467
Encoder Loss:  0.04260447  || Decoder Loss:  0.03609304 Validation Decoder Loss:  0.33003622
Encoder Loss:  0.042580012  || Decoder Loss:  0.036055222 Validation Decoder Loss:  0.3300355
Encoder Loss:  0.04257154  || Decoder Loss:  0.03602711 Validation Decoder Loss:  0.33007276
Encoder Loss:  0.042543627  || Decoder Loss:  0.03598262 Validation Decoder Loss:  0.33007833
Encoder Loss:  0.042537484  || Decoder Loss:  0.03595694 Validation Decoder Loss:  0.33009887
Encoder Loss:  0.04251708  || Decoder Loss:  0.03593337 Validation Decoder Loss:  0.33036235
Encoder Loss:  0.042494453  || Decoder Loss:  0.03589608 Validation Decoder Loss:  0.33044466
Encoder Loss:  0.042456865  || Decoder Loss:  0.035817493 Validation Decoder Loss:  0.3303614
Encoder Loss:  0.042447254  || Decoder Loss:  0.035802968 Validation Decoder Loss:  0.33029616
Encoder Loss:  0.04250445  || Decoder Loss:  0.03588474 Validation Decoder Loss:  0.33017424
Model: siamese_net_lr_0.44434446467133204 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33017424
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_153 (Conv3D (None, 234, 10, 20, 1)    217       
_________________________________________________________________
dropout_366 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_154 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_92 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_368 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_370 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294264 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.04229428 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294264 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.04229426 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.34258744
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.04229428 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294275 Validation Decoder Loss:  0.3425874
Encoder Loss:  0.40069005  || Decoder Loss:  0.042294268 Validation Decoder Loss:  0.3425874
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3425874
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_156 (Conv3D (None, 235, 10, 20, 1)    1033      
_________________________________________________________________
dropout_372 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_157 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_93 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_374 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_376 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23100124  || Decoder Loss:  0.42782006 Validation Decoder Loss:  1.1001889
Encoder Loss:  0.236782  || Decoder Loss:  0.46160832 Validation Decoder Loss:  0.8065404
Encoder Loss:  0.059727773  || Decoder Loss:  0.07141653 Validation Decoder Loss:  0.31568992
Encoder Loss:  0.044274207  || Decoder Loss:  0.037361424 Validation Decoder Loss:  0.31579173
Encoder Loss:  0.04411809  || Decoder Loss:  0.037015673 Validation Decoder Loss:  0.31629726
Encoder Loss:  0.043993555  || Decoder Loss:  0.03674344 Validation Decoder Loss:  0.31627086
Encoder Loss:  0.043921236  || Decoder Loss:  0.036584813 Validation Decoder Loss:  0.3164938
Encoder Loss:  0.043879714  || Decoder Loss:  0.036492728 Validation Decoder Loss:  0.31719673
Encoder Loss:  0.0438442  || Decoder Loss:  0.03641242 Validation Decoder Loss:  0.31862524
Encoder Loss:  0.043852787  || Decoder Loss:  0.03641964 Validation Decoder Loss:  0.31980756
Encoder Loss:  0.043934274  || Decoder Loss:  0.03657096 Validation Decoder Loss:  0.31931508
Encoder Loss:  0.043841194  || Decoder Loss:  0.036387447 Validation Decoder Loss:  0.32061088
Encoder Loss:  0.24191405  || Decoder Loss:  0.4465609 Validation Decoder Loss:  0.8827128
Encoder Loss:  0.25194782  || Decoder Loss:  0.49461076 Validation Decoder Loss:  1.0881128
Encoder Loss:  0.24690446  || Decoder Loss:  0.48391598 Validation Decoder Loss:  1.149791
Encoder Loss:  0.23938656  || Decoder Loss:  0.46735513 Validation Decoder Loss:  0.7858735
Encoder Loss:  0.21812062  || Decoder Loss:  0.42049724 Validation Decoder Loss:  0.35157457
Encoder Loss:  0.04702514  || Decoder Loss:  0.04343433 Validation Decoder Loss:  0.34890807
Encoder Loss:  0.044527076  || Decoder Loss:  0.037932944 Validation Decoder Loss:  0.34511173
Encoder Loss:  0.044337988  || Decoder Loss:  0.037513867 Validation Decoder Loss:  0.34416312
Encoder Loss:  0.044215545  || Decoder Loss:  0.03724286 Validation Decoder Loss:  0.3432082
Encoder Loss:  0.04413825  || Decoder Loss:  0.037073366 Validation Decoder Loss:  0.34254354
Encoder Loss:  0.04409853  || Decoder Loss:  0.036986075 Validation Decoder Loss:  0.34287366
Encoder Loss:  0.044028707  || Decoder Loss:  0.036834236 Validation Decoder Loss:  0.3418071
Encoder Loss:  0.043968365  || Decoder Loss:  0.0366979 Validation Decoder Loss:  0.34123504
Encoder Loss:  0.04406001  || Decoder Loss:  0.036897253 Validation Decoder Loss:  0.31527594
Encoder Loss:  0.04392242  || Decoder Loss:  0.036597177 Validation Decoder Loss:  0.31592384
Encoder Loss:  0.043920223  || Decoder Loss:  0.036577683 Validation Decoder Loss:  0.31788042
Encoder Loss:  0.044360105  || Decoder Loss:  0.03720073 Validation Decoder Loss:  0.34269404
Encoder Loss:  0.044074405  || Decoder Loss:  0.03693527 Validation Decoder Loss:  0.31690535
Encoder Loss:  0.04391615  || Decoder Loss:  0.036587074 Validation Decoder Loss:  0.31723797
Encoder Loss:  0.04383755  || Decoder Loss:  0.036413897 Validation Decoder Loss:  0.31746745
Encoder Loss:  0.043886896  || Decoder Loss:  0.036519278 Validation Decoder Loss:  0.31724477
Encoder Loss:  0.044058047  || Decoder Loss:  0.036847953 Validation Decoder Loss:  0.31765592
Encoder Loss:  0.04385163  || Decoder Loss:  0.036444366 Validation Decoder Loss:  0.31851447
Encoder Loss:  0.043845907  || Decoder Loss:  0.036430337 Validation Decoder Loss:  0.31717595
Encoder Loss:  0.043817118  || Decoder Loss:  0.03636575 Validation Decoder Loss:  0.3195541
Encoder Loss:  0.044063855  || Decoder Loss:  0.036884252 Validation Decoder Loss:  0.31766072
Encoder Loss:  0.043845512  || Decoder Loss:  0.03642935 Validation Decoder Loss:  0.31852987
Encoder Loss:  0.043943785  || Decoder Loss:  0.036638774 Validation Decoder Loss:  0.31510296
Model: siamese_net_lr_0.5806600823203183 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31510293
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_159 (Conv3D (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_378 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_160 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_94 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_380 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_382 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.346747  || Decoder Loss:  0.51483035 Validation Decoder Loss:  0.93278956
Encoder Loss:  0.30899614  || Decoder Loss:  0.48392692 Validation Decoder Loss:  0.9849256
Encoder Loss:  0.30584183  || Decoder Loss:  0.47803462 Validation Decoder Loss:  1.041657
Encoder Loss:  0.31706527  || Decoder Loss:  0.49905643 Validation Decoder Loss:  1.0515969
Encoder Loss:  0.31532142  || Decoder Loss:  0.49732167 Validation Decoder Loss:  1.0478216
Encoder Loss:  0.31435534  || Decoder Loss:  0.49616554 Validation Decoder Loss:  1.0391197
Encoder Loss:  0.31297597  || Decoder Loss:  0.49437538 Validation Decoder Loss:  1.0330803
Encoder Loss:  0.31123868  || Decoder Loss:  0.4915535 Validation Decoder Loss:  1.0317484
Encoder Loss:  0.3077018  || Decoder Loss:  0.48576477 Validation Decoder Loss:  0.9495908
Encoder Loss:  0.3122529  || Decoder Loss:  0.49366832 Validation Decoder Loss:  0.9395073
Encoder Loss:  0.3105542  || Decoder Loss:  0.49077883 Validation Decoder Loss:  0.9464308
Encoder Loss:  0.2818706  || Decoder Loss:  0.4422301 Validation Decoder Loss:  0.8672536
Encoder Loss:  0.06861508  || Decoder Loss:  0.08126811 Validation Decoder Loss:  0.3374208
Encoder Loss:  0.042744316  || Decoder Loss:  0.037283853 Validation Decoder Loss:  0.3392161
Encoder Loss:  0.043319024  || Decoder Loss:  0.037916303 Validation Decoder Loss:  0.3417382
Encoder Loss:  0.042951323  || Decoder Loss:  0.037728 Validation Decoder Loss:  0.33016145
Encoder Loss:  0.04304852  || Decoder Loss:  0.03771686 Validation Decoder Loss:  0.33196384
Encoder Loss:  0.042536803  || Decoder Loss:  0.03705651 Validation Decoder Loss:  0.33067325
Encoder Loss:  0.04285932  || Decoder Loss:  0.03756372 Validation Decoder Loss:  0.33261046
Encoder Loss:  0.042339336  || Decoder Loss:  0.03684227 Validation Decoder Loss:  0.33371723
Encoder Loss:  0.042459663  || Decoder Loss:  0.036943838 Validation Decoder Loss:  0.33483362
Encoder Loss:  0.04234299  || Decoder Loss:  0.036857408 Validation Decoder Loss:  0.3302179
Encoder Loss:  0.04316325  || Decoder Loss:  0.037924208 Validation Decoder Loss:  0.33210754
Encoder Loss:  0.042446125  || Decoder Loss:  0.037026625 Validation Decoder Loss:  0.3305651
Encoder Loss:  0.05277572  || Decoder Loss:  0.053466693 Validation Decoder Loss:  0.57910025
Encoder Loss:  0.052624043  || Decoder Loss:  0.054132704 Validation Decoder Loss:  0.33228707
Encoder Loss:  0.0473978  || Decoder Loss:  0.045254424 Validation Decoder Loss:  0.3308577
Encoder Loss:  0.045925334  || Decoder Loss:  0.04293244 Validation Decoder Loss:  0.33069628
Encoder Loss:  0.045473292  || Decoder Loss:  0.042111825 Validation Decoder Loss:  0.3308709
Encoder Loss:  0.04561826  || Decoder Loss:  0.04229135 Validation Decoder Loss:  0.33059493
Encoder Loss:  0.045618437  || Decoder Loss:  0.0422984 Validation Decoder Loss:  0.33127728
Encoder Loss:  0.044938583  || Decoder Loss:  0.04130791 Validation Decoder Loss:  0.33051598
Encoder Loss:  0.048777398  || Decoder Loss:  0.046676036 Validation Decoder Loss:  0.33232746
Encoder Loss:  0.047562066  || Decoder Loss:  0.045732684 Validation Decoder Loss:  0.33166036
Encoder Loss:  0.046074428  || Decoder Loss:  0.04320967 Validation Decoder Loss:  0.33136865
Encoder Loss:  0.045282193  || Decoder Loss:  0.041904125 Validation Decoder Loss:  0.3312063
Encoder Loss:  0.0448318  || Decoder Loss:  0.041154917 Validation Decoder Loss:  0.33067662
Encoder Loss:  0.044540733  || Decoder Loss:  0.04065815 Validation Decoder Loss:  0.33125183
Encoder Loss:  0.044901207  || Decoder Loss:  0.04108481 Validation Decoder Loss:  0.33070716
Encoder Loss:  0.0454977  || Decoder Loss:  0.04206199 Validation Decoder Loss:  0.3311916
Model: siamese_net_lr_0.5854760117690786 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3311916
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_162 (Conv3D (None, 236, 10, 20, 1)    221       
_________________________________________________________________
dropout_384 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_163 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_95 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 244
Trainable params: 244
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_386 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_388 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16869552  || Decoder Loss:  0.23819835 Validation Decoder Loss:  0.32304436
Encoder Loss:  0.046142563  || Decoder Loss:  0.039847776 Validation Decoder Loss:  0.3242234
Encoder Loss:  0.045342766  || Decoder Loss:  0.038055178 Validation Decoder Loss:  0.32479125
Encoder Loss:  0.045071624  || Decoder Loss:  0.037406217 Validation Decoder Loss:  0.3250153
Encoder Loss:  0.04491017  || Decoder Loss:  0.037015896 Validation Decoder Loss:  0.3253925
Encoder Loss:  0.044810317  || Decoder Loss:  0.03675418 Validation Decoder Loss:  0.32574973
Encoder Loss:  0.044734817  || Decoder Loss:  0.036559053 Validation Decoder Loss:  0.325755
Encoder Loss:  0.044725504  || Decoder Loss:  0.036515392 Validation Decoder Loss:  0.32553294
Encoder Loss:  0.045032386  || Decoder Loss:  0.036518294 Validation Decoder Loss:  0.32609576
Encoder Loss:  0.044681896  || Decoder Loss:  0.036420345 Validation Decoder Loss:  0.32612267
Encoder Loss:  0.04469512  || Decoder Loss:  0.036439825 Validation Decoder Loss:  0.32620525
Encoder Loss:  0.04466758  || Decoder Loss:  0.036294065 Validation Decoder Loss:  0.32678154
Encoder Loss:  0.045407563  || Decoder Loss:  0.03734084 Validation Decoder Loss:  0.32626373
Encoder Loss:  0.044745196  || Decoder Loss:  0.036579084 Validation Decoder Loss:  0.32634664
Encoder Loss:  0.04468421  || Decoder Loss:  0.036420085 Validation Decoder Loss:  0.32667172
Encoder Loss:  0.044667963  || Decoder Loss:  0.036375202 Validation Decoder Loss:  0.32686302
Encoder Loss:  0.044641525  || Decoder Loss:  0.036318187 Validation Decoder Loss:  0.32679942
Encoder Loss:  0.044713702  || Decoder Loss:  0.036312196 Validation Decoder Loss:  0.3275658
Encoder Loss:  0.08074695  || Decoder Loss:  0.061439265 Validation Decoder Loss:  0.36488238
Encoder Loss:  0.057427987  || Decoder Loss:  0.06878148 Validation Decoder Loss:  0.3648684
Encoder Loss:  0.0572215  || Decoder Loss:  0.06817392 Validation Decoder Loss:  0.36470756
Encoder Loss:  0.05618752  || Decoder Loss:  0.06573776 Validation Decoder Loss:  0.36583987
Encoder Loss:  0.05658157  || Decoder Loss:  0.066674024 Validation Decoder Loss:  0.36606032
Encoder Loss:  0.05542119  || Decoder Loss:  0.063808165 Validation Decoder Loss:  0.3568688
Encoder Loss:  0.048040133  || Decoder Loss:  0.040895592 Validation Decoder Loss:  0.33098486
Encoder Loss:  0.044654943  || Decoder Loss:  0.036344398 Validation Decoder Loss:  0.3307323
Encoder Loss:  0.044601817  || Decoder Loss:  0.036205962 Validation Decoder Loss:  0.33080834
Encoder Loss:  0.04459064  || Decoder Loss:  0.036136042 Validation Decoder Loss:  0.33112544
Encoder Loss:  0.044806417  || Decoder Loss:  0.036427442 Validation Decoder Loss:  0.33158788
Encoder Loss:  0.04497108  || Decoder Loss:  0.03682878 Validation Decoder Loss:  0.3259468
Encoder Loss:  0.0447322  || Decoder Loss:  0.036526855 Validation Decoder Loss:  0.32543108
Encoder Loss:  0.044597264  || Decoder Loss:  0.03620294 Validation Decoder Loss:  0.3249257
Encoder Loss:  0.04460823  || Decoder Loss:  0.036229752 Validation Decoder Loss:  0.3249165
Encoder Loss:  0.04465194  || Decoder Loss:  0.036341485 Validation Decoder Loss:  0.32519838
Encoder Loss:  0.044603445  || Decoder Loss:  0.036222905 Validation Decoder Loss:  0.32484543
Encoder Loss:  0.044660635  || Decoder Loss:  0.03635267 Validation Decoder Loss:  0.3255114
Encoder Loss:  0.04469012  || Decoder Loss:  0.036410857 Validation Decoder Loss:  0.3256122
Encoder Loss:  0.04460464  || Decoder Loss:  0.036218747 Validation Decoder Loss:  0.3250304
Encoder Loss:  0.044802375  || Decoder Loss:  0.036683563 Validation Decoder Loss:  0.3247751
Encoder Loss:  0.045086112  || Decoder Loss:  0.03718436 Validation Decoder Loss:  0.3248508
Model: siamese_net_lr_0.4505426900778487 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32485077
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_165 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_390 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_166 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_96 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_392 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_394 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43444782  || Decoder Loss:  0.496224 Validation Decoder Loss:  0.9971985
Encoder Loss:  0.4380575  || Decoder Loss:  0.50204396 Validation Decoder Loss:  0.99869764
Encoder Loss:  0.43722072  || Decoder Loss:  0.50109273 Validation Decoder Loss:  0.99872583
Encoder Loss:  0.4371965  || Decoder Loss:  0.50106436 Validation Decoder Loss:  0.9987979
Encoder Loss:  0.43717456  || Decoder Loss:  0.5010391 Validation Decoder Loss:  0.9988391
Encoder Loss:  0.4371454  || Decoder Loss:  0.5010053 Validation Decoder Loss:  0.99888575
Encoder Loss:  0.43712792  || Decoder Loss:  0.5009848 Validation Decoder Loss:  0.9989551
Encoder Loss:  0.43708816  || Decoder Loss:  0.5009385 Validation Decoder Loss:  0.99898946
Encoder Loss:  0.43698612  || Decoder Loss:  0.5008199 Validation Decoder Loss:  1.0029186
Encoder Loss:  0.4343324  || Decoder Loss:  0.4976615 Validation Decoder Loss:  1.0000501
Encoder Loss:  0.43590352  || Decoder Loss:  0.49955863 Validation Decoder Loss:  1.0006015
Encoder Loss:  0.43603596  || Decoder Loss:  0.49971265 Validation Decoder Loss:  1.000494
Encoder Loss:  0.43606842  || Decoder Loss:  0.49975023 Validation Decoder Loss:  1.0003308
Encoder Loss:  0.43601272  || Decoder Loss:  0.499685 Validation Decoder Loss:  1.0003669
Encoder Loss:  0.4359597  || Decoder Loss:  0.49962345 Validation Decoder Loss:  1.0004747
Encoder Loss:  0.4360037  || Decoder Loss:  0.49967396 Validation Decoder Loss:  1.0007287
Encoder Loss:  0.43634385  || Decoder Loss:  0.49979606 Validation Decoder Loss:  1.0003126
Encoder Loss:  0.43604088  || Decoder Loss:  0.49971944 Validation Decoder Loss:  1.0004997
Encoder Loss:  0.4352687  || Decoder Loss:  0.49881977 Validation Decoder Loss:  1.0143559
Encoder Loss:  0.4364516  || Decoder Loss:  0.5001969 Validation Decoder Loss:  1.000237
Encoder Loss:  0.43640515  || Decoder Loss:  0.5001438 Validation Decoder Loss:  1.0000379
Encoder Loss:  0.43427342  || Decoder Loss:  0.49766004 Validation Decoder Loss:  0.9975587
Encoder Loss:  0.43556744  || Decoder Loss:  0.49916774 Validation Decoder Loss:  0.9901102
Encoder Loss:  0.42450345  || Decoder Loss:  0.48627815 Validation Decoder Loss:  1.0039306
Encoder Loss:  0.4167276  || Decoder Loss:  0.47721988 Validation Decoder Loss:  0.97816926
Encoder Loss:  0.14940867  || Decoder Loss:  0.16572374 Validation Decoder Loss:  0.4059245
Encoder Loss:  0.053505883  || Decoder Loss:  0.054081403 Validation Decoder Loss:  0.40634948
Encoder Loss:  0.43091384  || Decoder Loss:  0.49373996 Validation Decoder Loss:  0.9958161
Encoder Loss:  0.43650317  || Decoder Loss:  0.5002573 Validation Decoder Loss:  0.9967556
Encoder Loss:  0.4355248  || Decoder Loss:  0.49911702 Validation Decoder Loss:  1.0575335
Encoder Loss:  0.4279416  || Decoder Loss:  0.4902831 Validation Decoder Loss:  0.99158555
Encoder Loss:  0.42594662  || Decoder Loss:  0.48795933 Validation Decoder Loss:  1.1992366
Encoder Loss:  0.16029292  || Decoder Loss:  0.17848551 Validation Decoder Loss:  1.3654203
Encoder Loss:  0.3854369  || Decoder Loss:  0.44076788 Validation Decoder Loss:  0.9928696
Encoder Loss:  0.41636464  || Decoder Loss:  0.47679675 Validation Decoder Loss:  1.0015697
Encoder Loss:  0.43619046  || Decoder Loss:  0.49989304 Validation Decoder Loss:  0.995429
Encoder Loss:  0.43672934  || Decoder Loss:  0.5005209 Validation Decoder Loss:  1.0059794
Encoder Loss:  0.43562478  || Decoder Loss:  0.49923366 Validation Decoder Loss:  1.009431
Encoder Loss:  0.43549114  || Decoder Loss:  0.4990763 Validation Decoder Loss:  0.9952073
Encoder Loss:  0.437234  || Decoder Loss:  0.501109 Validation Decoder Loss:  1.0035844
Model: siamese_net_lr_0.532064905329755 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0035844
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_168 (Conv3D (None, 120, 10, 20, 1)    115       
_________________________________________________________________
dropout_396 (Dropout)        (None, 120, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_169 (Conv3D (None, 257, 10, 20, 1)    20        
_________________________________________________________________
reshape_97 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 135
Trainable params: 135
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_328"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_398 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_400 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007496  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826408 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.037826408 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826408 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826408 Validation Decoder Loss:  0.335519
Encoder Loss:  0.130075  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.130075  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007496  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.335519
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.037826415 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.13007498  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Encoder Loss:  0.130075  || Decoder Loss:  0.03782641 Validation Decoder Loss:  0.33551896
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33551896
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_171 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_402 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_172 (Conv3D (None, 257, 10, 20, 1)    346       
_________________________________________________________________
reshape_98 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 411
Trainable params: 411
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_404 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_406 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18411942  || Decoder Loss:  0.33137378 Validation Decoder Loss:  0.8768343
Encoder Loss:  0.18491344  || Decoder Loss:  0.49135655 Validation Decoder Loss:  0.69001806
Encoder Loss:  0.12472476  || Decoder Loss:  0.29682207 Validation Decoder Loss:  0.37883863
Encoder Loss:  0.0531365  || Decoder Loss:  0.059538938 Validation Decoder Loss:  0.33668372
Encoder Loss:  0.04676339  || Decoder Loss:  0.037445836 Validation Decoder Loss:  0.33423287
Encoder Loss:  0.047844123  || Decoder Loss:  0.035789628 Validation Decoder Loss:  0.33202463
Encoder Loss:  0.045996305  || Decoder Loss:  0.035680395 Validation Decoder Loss:  0.33265668
Encoder Loss:  0.045961075  || Decoder Loss:  0.03566963 Validation Decoder Loss:  0.33267242
Encoder Loss:  0.045954324  || Decoder Loss:  0.035664205 Validation Decoder Loss:  0.3327723
Encoder Loss:  0.045856744  || Decoder Loss:  0.035662673 Validation Decoder Loss:  0.33258688
Encoder Loss:  0.04579312  || Decoder Loss:  0.035646513 Validation Decoder Loss:  0.3325867
Encoder Loss:  0.04578318  || Decoder Loss:  0.035638645 Validation Decoder Loss:  0.3326745
Encoder Loss:  0.045764312  || Decoder Loss:  0.03562158 Validation Decoder Loss:  0.33276194
Encoder Loss:  0.04575555  || Decoder Loss:  0.03561669 Validation Decoder Loss:  0.33276814
Encoder Loss:  0.04578924  || Decoder Loss:  0.035607833 Validation Decoder Loss:  0.33291364
Encoder Loss:  0.045785353  || Decoder Loss:  0.035603296 Validation Decoder Loss:  0.3329981
Encoder Loss:  0.045765184  || Decoder Loss:  0.03559231 Validation Decoder Loss:  0.33308512
Encoder Loss:  0.04577198  || Decoder Loss:  0.035587944 Validation Decoder Loss:  0.332993
Encoder Loss:  0.045792695  || Decoder Loss:  0.035584807 Validation Decoder Loss:  0.33298427
Encoder Loss:  0.045801636  || Decoder Loss:  0.035586905 Validation Decoder Loss:  0.3330229
Encoder Loss:  0.045948297  || Decoder Loss:  0.035568275 Validation Decoder Loss:  0.33231947
Encoder Loss:  0.046062957  || Decoder Loss:  0.03554948 Validation Decoder Loss:  0.3319125
Encoder Loss:  0.045900963  || Decoder Loss:  0.035556834 Validation Decoder Loss:  0.33256072
Encoder Loss:  0.04579141  || Decoder Loss:  0.03555536 Validation Decoder Loss:  0.33273885
Encoder Loss:  0.045763623  || Decoder Loss:  0.03555757 Validation Decoder Loss:  0.3327847
Encoder Loss:  0.045753457  || Decoder Loss:  0.035553623 Validation Decoder Loss:  0.33297616
Encoder Loss:  0.045746945  || Decoder Loss:  0.035551503 Validation Decoder Loss:  0.33311892
Encoder Loss:  0.045705903  || Decoder Loss:  0.03554718 Validation Decoder Loss:  0.3331032
Encoder Loss:  0.045706306  || Decoder Loss:  0.035550937 Validation Decoder Loss:  0.33319485
Encoder Loss:  0.04570607  || Decoder Loss:  0.0355619 Validation Decoder Loss:  0.3332235
Encoder Loss:  0.045704573  || Decoder Loss:  0.03555857 Validation Decoder Loss:  0.33322006
Encoder Loss:  0.045702204  || Decoder Loss:  0.0355542 Validation Decoder Loss:  0.33315063
Encoder Loss:  0.045702837  || Decoder Loss:  0.035549287 Validation Decoder Loss:  0.33302236
Encoder Loss:  0.045704495  || Decoder Loss:  0.035557725 Validation Decoder Loss:  0.3329214
Encoder Loss:  0.045738444  || Decoder Loss:  0.0355606 Validation Decoder Loss:  0.33299875
Encoder Loss:  0.04579387  || Decoder Loss:  0.035573147 Validation Decoder Loss:  0.3330298
Encoder Loss:  0.045831528  || Decoder Loss:  0.03558352 Validation Decoder Loss:  0.33263284
Encoder Loss:  0.045736052  || Decoder Loss:  0.035534583 Validation Decoder Loss:  0.33300546
Encoder Loss:  0.045768563  || Decoder Loss:  0.03554425 Validation Decoder Loss:  0.3329956
Encoder Loss:  0.045748647  || Decoder Loss:  0.03553455 Validation Decoder Loss:  0.33330995
Model: siamese_net_lr_0.21804026708198204 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33330995
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_174 (Conv3D (None, 130, 7, 20, 1)     202       
_________________________________________________________________
dropout_408 (Dropout)        (None, 130, 7, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_175 (Conv3D (None, 257, 10, 20, 1)    513       
_________________________________________________________________
reshape_99 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 715
Trainable params: 715
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_410 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_412 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18398334  || Decoder Loss:  0.49480748 Validation Decoder Loss:  1.0659945
Encoder Loss:  0.18253489  || Decoder Loss:  0.49438873 Validation Decoder Loss:  1.0609244
Encoder Loss:  0.18067543  || Decoder Loss:  0.49245918 Validation Decoder Loss:  1.0737158
Encoder Loss:  0.18007721  || Decoder Loss:  0.49151602 Validation Decoder Loss:  1.1037133
Encoder Loss:  0.18014869  || Decoder Loss:  0.49459475 Validation Decoder Loss:  1.0947247
Encoder Loss:  0.17988981  || Decoder Loss:  0.49503186 Validation Decoder Loss:  1.0885155
Encoder Loss:  0.1798758  || Decoder Loss:  0.494936 Validation Decoder Loss:  1.0248041
Encoder Loss:  0.17930536  || Decoder Loss:  0.49308822 Validation Decoder Loss:  1.031932
Encoder Loss:  0.1789729  || Decoder Loss:  0.492146 Validation Decoder Loss:  1.0511382
Encoder Loss:  0.17810936  || Decoder Loss:  0.48895302 Validation Decoder Loss:  0.9729909
Encoder Loss:  0.17964861  || Decoder Loss:  0.49403808 Validation Decoder Loss:  0.9821959
Encoder Loss:  0.17906018  || Decoder Loss:  0.49242637 Validation Decoder Loss:  1.1006393
Encoder Loss:  0.17996797  || Decoder Loss:  0.49527675 Validation Decoder Loss:  1.0646708
Encoder Loss:  0.18011722  || Decoder Loss:  0.49601042 Validation Decoder Loss:  0.96381795
Encoder Loss:  0.18095799  || Decoder Loss:  0.4986229 Validation Decoder Loss:  0.9431305
Encoder Loss:  0.17919926  || Decoder Loss:  0.492546 Validation Decoder Loss:  0.95115644
Encoder Loss:  0.1804507  || Decoder Loss:  0.49721488 Validation Decoder Loss:  1.11082
Encoder Loss:  0.17917073  || Decoder Loss:  0.492719 Validation Decoder Loss:  1.0260739
Encoder Loss:  0.18051162  || Decoder Loss:  0.49731502 Validation Decoder Loss:  0.9316468
Encoder Loss:  0.17974882  || Decoder Loss:  0.49464703 Validation Decoder Loss:  0.9803373
Encoder Loss:  0.17784965  || Decoder Loss:  0.48810637 Validation Decoder Loss:  1.0554001
Encoder Loss:  0.1786912  || Decoder Loss:  0.49114308 Validation Decoder Loss:  1.0765252
Encoder Loss:  0.18020925  || Decoder Loss:  0.4963993 Validation Decoder Loss:  0.9194001
Encoder Loss:  0.18002184  || Decoder Loss:  0.49551225 Validation Decoder Loss:  1.0468476
Encoder Loss:  0.17768069  || Decoder Loss:  0.48781037 Validation Decoder Loss:  1.0522773
Encoder Loss:  0.18084894  || Decoder Loss:  0.49851114 Validation Decoder Loss:  0.882659
Encoder Loss:  0.17952354  || Decoder Loss:  0.49301356 Validation Decoder Loss:  1.1515564
Encoder Loss:  0.17958483  || Decoder Loss:  0.49432895 Validation Decoder Loss:  1.0791105
Encoder Loss:  0.18072744  || Decoder Loss:  0.49833784 Validation Decoder Loss:  0.9217346
Encoder Loss:  0.18062408  || Decoder Loss:  0.49793267 Validation Decoder Loss:  0.93974364
Encoder Loss:  0.17918548  || Decoder Loss:  0.49283418 Validation Decoder Loss:  1.135308
Encoder Loss:  0.18079147  || Decoder Loss:  0.49846885 Validation Decoder Loss:  0.90917045
Encoder Loss:  0.1810257  || Decoder Loss:  0.49926624 Validation Decoder Loss:  0.9202862
Encoder Loss:  0.18020487  || Decoder Loss:  0.49629706 Validation Decoder Loss:  1.0278018
Encoder Loss:  0.17882635  || Decoder Loss:  0.49174416 Validation Decoder Loss:  1.0884424
Encoder Loss:  0.18044896  || Decoder Loss:  0.49729112 Validation Decoder Loss:  0.876274
Encoder Loss:  0.18052122  || Decoder Loss:  0.4945132 Validation Decoder Loss:  1.1250883
Encoder Loss:  0.1800121  || Decoder Loss:  0.4958754 Validation Decoder Loss:  1.1047561
Encoder Loss:  0.18017185  || Decoder Loss:  0.49635434 Validation Decoder Loss:  1.080621
Encoder Loss:  0.18065947  || Decoder Loss:  0.49811113 Validation Decoder Loss:  0.9126091
Model: siamese_net_lr_0.5216549928597015 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9126091
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_177 (Conv3D (None, 210, 10, 20, 1)    295       
_________________________________________________________________
dropout_414 (Dropout)        (None, 210, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_178 (Conv3D (None, 257, 10, 20, 1)    49        
_________________________________________________________________
reshape_100 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 344
Trainable params: 344
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_340"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_416 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_418 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07960826  || Decoder Loss:  0.060262974 Validation Decoder Loss:  0.32556373
Encoder Loss:  0.037815645  || Decoder Loss:  0.03621967 Validation Decoder Loss:  0.3343086
Encoder Loss:  0.037413213  || Decoder Loss:  0.03586194 Validation Decoder Loss:  0.33420712
Encoder Loss:  0.03733793  || Decoder Loss:  0.035779104 Validation Decoder Loss:  0.33423603
Encoder Loss:  0.037268758  || Decoder Loss:  0.035702657 Validation Decoder Loss:  0.3342685
Encoder Loss:  0.037205707  || Decoder Loss:  0.03563194 Validation Decoder Loss:  0.33438158
Encoder Loss:  0.03715054  || Decoder Loss:  0.035569962 Validation Decoder Loss:  0.33460647
Encoder Loss:  0.037104193  || Decoder Loss:  0.035517942 Validation Decoder Loss:  0.3350822
Encoder Loss:  0.037087455  || Decoder Loss:  0.03549914 Validation Decoder Loss:  0.3352511
Encoder Loss:  0.037025284  || Decoder Loss:  0.035429303 Validation Decoder Loss:  0.33433717
Encoder Loss:  0.036981415  || Decoder Loss:  0.035380017 Validation Decoder Loss:  0.33452362
Encoder Loss:  0.03690853  || Decoder Loss:  0.035298288 Validation Decoder Loss:  0.3346814
Encoder Loss:  0.03686569  || Decoder Loss:  0.035250217 Validation Decoder Loss:  0.33494896
Encoder Loss:  0.03682211  || Decoder Loss:  0.035201333 Validation Decoder Loss:  0.33529714
Encoder Loss:  0.036788274  || Decoder Loss:  0.03516333 Validation Decoder Loss:  0.3361041
Encoder Loss:  0.036884144  || Decoder Loss:  0.03527102 Validation Decoder Loss:  0.33490092
Encoder Loss:  0.03683625  || Decoder Loss:  0.03521725 Validation Decoder Loss:  0.33556443
Encoder Loss:  0.0368298  || Decoder Loss:  0.03520995 Validation Decoder Loss:  0.33407193
Encoder Loss:  0.036817983  || Decoder Loss:  0.03519669 Validation Decoder Loss:  0.33533588
Encoder Loss:  0.036797833  || Decoder Loss:  0.03517412 Validation Decoder Loss:  0.33391133
Encoder Loss:  0.036779642  || Decoder Loss:  0.035153747 Validation Decoder Loss:  0.33569068
Encoder Loss:  0.03677728  || Decoder Loss:  0.035151094 Validation Decoder Loss:  0.33418173
Encoder Loss:  0.036723007  || Decoder Loss:  0.03509016 Validation Decoder Loss:  0.33605617
Encoder Loss:  0.036741927  || Decoder Loss:  0.03511137 Validation Decoder Loss:  0.33558312
Encoder Loss:  0.036683418  || Decoder Loss:  0.035045613 Validation Decoder Loss:  0.33591667
Encoder Loss:  0.036699004  || Decoder Loss:  0.035063162 Validation Decoder Loss:  0.3359468
Encoder Loss:  0.03665121  || Decoder Loss:  0.035009485 Validation Decoder Loss:  0.3356498
Encoder Loss:  0.036664456  || Decoder Loss:  0.035024367 Validation Decoder Loss:  0.3359685
Encoder Loss:  0.03662913  || Decoder Loss:  0.03498471 Validation Decoder Loss:  0.33549166
Encoder Loss:  0.036632124  || Decoder Loss:  0.034988128 Validation Decoder Loss:  0.3357876
Encoder Loss:  0.036615245  || Decoder Loss:  0.034969144 Validation Decoder Loss:  0.33544332
Encoder Loss:  0.036607943  || Decoder Loss:  0.03496103 Validation Decoder Loss:  0.33546034
Encoder Loss:  0.036603145  || Decoder Loss:  0.03495556 Validation Decoder Loss:  0.33539468
Encoder Loss:  0.03659816  || Decoder Loss:  0.03495008 Validation Decoder Loss:  0.33538026
Encoder Loss:  0.03659627  || Decoder Loss:  0.034947928 Validation Decoder Loss:  0.33540457
Encoder Loss:  0.036597196  || Decoder Loss:  0.03494871 Validation Decoder Loss:  0.33536604
Encoder Loss:  0.03659563  || Decoder Loss:  0.0349471 Validation Decoder Loss:  0.33495498
Encoder Loss:  0.036584705  || Decoder Loss:  0.034934543 Validation Decoder Loss:  0.334588
Encoder Loss:  0.036577467  || Decoder Loss:  0.034926612 Validation Decoder Loss:  0.3346539
Encoder Loss:  0.036576513  || Decoder Loss:  0.034925643 Validation Decoder Loss:  0.33460948
Model: siamese_net_lr_0.02569720449422261 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33460945
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_180 (Conv3D (None, 150, 8, 20, 1)     97        
_________________________________________________________________
dropout_420 (Dropout)        (None, 150, 8, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_181 (Conv3D (None, 257, 10, 20, 1)    325       
_________________________________________________________________
reshape_101 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 422
Trainable params: 422
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_344"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_422 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_424 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36585248  || Decoder Loss:  0.43137443 Validation Decoder Loss:  1.4465423
Encoder Loss:  0.42591953  || Decoder Loss:  0.5078773 Validation Decoder Loss:  0.34064406
Encoder Loss:  0.038704026  || Decoder Loss:  0.036229428 Validation Decoder Loss:  0.3477378
Encoder Loss:  0.03906616  || Decoder Loss:  0.036670394 Validation Decoder Loss:  0.34894025
Encoder Loss:  0.038837843  || Decoder Loss:  0.036393274 Validation Decoder Loss:  0.34949607
Encoder Loss:  0.038712848  || Decoder Loss:  0.03623976 Validation Decoder Loss:  0.3491856
Encoder Loss:  0.038353  || Decoder Loss:  0.03580064 Validation Decoder Loss:  0.33579764
Encoder Loss:  0.038094115  || Decoder Loss:  0.035486974 Validation Decoder Loss:  0.3459339
Encoder Loss:  0.03915462  || Decoder Loss:  0.03677309 Validation Decoder Loss:  0.36032498
Encoder Loss:  0.037889246  || Decoder Loss:  0.03524025 Validation Decoder Loss:  0.34594822
Encoder Loss:  0.0378739  || Decoder Loss:  0.035220865 Validation Decoder Loss:  0.34116265
Encoder Loss:  0.037885405  || Decoder Loss:  0.035236537 Validation Decoder Loss:  0.32090467
Encoder Loss:  0.04686725  || Decoder Loss:  0.04590613 Validation Decoder Loss:  0.33511305
Encoder Loss:  0.040488873  || Decoder Loss:  0.038399536 Validation Decoder Loss:  0.33072275
Encoder Loss:  0.040218934  || Decoder Loss:  0.038057484 Validation Decoder Loss:  0.33146125
Encoder Loss:  0.039488856  || Decoder Loss:  0.037184797 Validation Decoder Loss:  0.33144224
Encoder Loss:  0.03943347  || Decoder Loss:  0.037117854 Validation Decoder Loss:  0.3318464
Encoder Loss:  0.03866259  || Decoder Loss:  0.036166962 Validation Decoder Loss:  0.33305308
Encoder Loss:  0.03851598  || Decoder Loss:  0.03599705 Validation Decoder Loss:  0.34479618
Encoder Loss:  0.039196316  || Decoder Loss:  0.0368279 Validation Decoder Loss:  0.38716817
Encoder Loss:  0.0379481  || Decoder Loss:  0.0353091 Validation Decoder Loss:  0.3450615
Encoder Loss:  0.038002864  || Decoder Loss:  0.03537865 Validation Decoder Loss:  0.36114597
Encoder Loss:  0.038349725  || Decoder Loss:  0.035800822 Validation Decoder Loss:  0.36828524
Encoder Loss:  0.038685292  || Decoder Loss:  0.036135603 Validation Decoder Loss:  0.3707248
Encoder Loss:  0.038343754  || Decoder Loss:  0.03579815 Validation Decoder Loss:  0.36292732
Encoder Loss:  0.03831463  || Decoder Loss:  0.035761427 Validation Decoder Loss:  0.36281866
Encoder Loss:  0.038334236  || Decoder Loss:  0.03578486 Validation Decoder Loss:  0.3634597
Encoder Loss:  0.038306933  || Decoder Loss:  0.035753038 Validation Decoder Loss:  0.36170042
Encoder Loss:  0.038276184  || Decoder Loss:  0.03571441 Validation Decoder Loss:  0.36143458
Encoder Loss:  0.038282428  || Decoder Loss:  0.035721313 Validation Decoder Loss:  0.3608687
Encoder Loss:  0.03837638  || Decoder Loss:  0.035825957 Validation Decoder Loss:  0.36134833
Encoder Loss:  0.038241036  || Decoder Loss:  0.035671793 Validation Decoder Loss:  0.36102393
Encoder Loss:  0.03840077  || Decoder Loss:  0.035836548 Validation Decoder Loss:  0.3611263
Encoder Loss:  0.03820796  || Decoder Loss:  0.035633124 Validation Decoder Loss:  0.36046505
Encoder Loss:  0.038167812  || Decoder Loss:  0.0355841 Validation Decoder Loss:  0.35839382
Encoder Loss:  0.038119454  || Decoder Loss:  0.035523817 Validation Decoder Loss:  0.35789824
Encoder Loss:  0.038067874  || Decoder Loss:  0.035460416 Validation Decoder Loss:  0.35787275
Encoder Loss:  0.0380514  || Decoder Loss:  0.035440493 Validation Decoder Loss:  0.35532427
Encoder Loss:  0.038801596  || Decoder Loss:  0.036272384 Validation Decoder Loss:  0.37538952
Encoder Loss:  0.038476612  || Decoder Loss:  0.03596177 Validation Decoder Loss:  0.36649096
Model: siamese_net_lr_0.1158306748728953 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36649096
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_183 (Conv3D (None, 114, 5, 20, 1)     52        
_________________________________________________________________
dropout_426 (Dropout)        (None, 114, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_184 (Conv3D (None, 257, 10, 20, 1)    63        
_________________________________________________________________
reshape_102 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 115
Trainable params: 115
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_428 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_430 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3204042  || Decoder Loss:  0.32279748 Validation Decoder Loss:  0.95199156
Encoder Loss:  0.48058757  || Decoder Loss:  0.48632717 Validation Decoder Loss:  0.9926325
Encoder Loss:  0.48858237  || Decoder Loss:  0.49448514 Validation Decoder Loss:  1.0047607
Encoder Loss:  0.4873143  || Decoder Loss:  0.4932156 Validation Decoder Loss:  0.9971256
Encoder Loss:  0.48635387  || Decoder Loss:  0.49222434 Validation Decoder Loss:  0.9915341
Encoder Loss:  0.4865926  || Decoder Loss:  0.49244037 Validation Decoder Loss:  0.992136
Encoder Loss:  0.486175  || Decoder Loss:  0.4919987 Validation Decoder Loss:  0.984842
Encoder Loss:  0.483957  || Decoder Loss:  0.4897898 Validation Decoder Loss:  1.0077505
Encoder Loss:  0.4880792  || Decoder Loss:  0.4939654 Validation Decoder Loss:  0.99291277
Encoder Loss:  0.48378482  || Decoder Loss:  0.48958617 Validation Decoder Loss:  0.9876081
Encoder Loss:  0.4809149  || Decoder Loss:  0.4866991 Validation Decoder Loss:  1.0783396
Encoder Loss:  0.48917377  || Decoder Loss:  0.4950398 Validation Decoder Loss:  1.0192553
Encoder Loss:  0.4837286  || Decoder Loss:  0.4895612 Validation Decoder Loss:  0.9832151
Encoder Loss:  0.4993418  || Decoder Loss:  0.50540745 Validation Decoder Loss:  0.9870919
Encoder Loss:  0.4736017  || Decoder Loss:  0.47930077 Validation Decoder Loss:  0.97041136
Encoder Loss:  0.42039394  || Decoder Loss:  0.4253709 Validation Decoder Loss:  0.85471725
Encoder Loss:  0.47367093  || Decoder Loss:  0.4793829 Validation Decoder Loss:  1.0373173
Encoder Loss:  0.46233425  || Decoder Loss:  0.46785286 Validation Decoder Loss:  1.0468113
Encoder Loss:  0.47754288  || Decoder Loss:  0.48329806 Validation Decoder Loss:  0.98983514
Encoder Loss:  0.4808239  || Decoder Loss:  0.48659766 Validation Decoder Loss:  1.0988903
Encoder Loss:  0.4616548  || Decoder Loss:  0.46718982 Validation Decoder Loss:  0.9245306
Encoder Loss:  0.44867545  || Decoder Loss:  0.45404214 Validation Decoder Loss:  1.0001622
Encoder Loss:  0.48279083  || Decoder Loss:  0.48862034 Validation Decoder Loss:  1.001797
Encoder Loss:  0.48010686  || Decoder Loss:  0.48587298 Validation Decoder Loss:  0.9792274
Encoder Loss:  0.48287103  || Decoder Loss:  0.48867705 Validation Decoder Loss:  0.9970002
Encoder Loss:  0.47915947  || Decoder Loss:  0.48495105 Validation Decoder Loss:  0.99734664
Encoder Loss:  0.47553173  || Decoder Loss:  0.48126873 Validation Decoder Loss:  0.9864158
Encoder Loss:  0.45742607  || Decoder Loss:  0.46292332 Validation Decoder Loss:  0.88883054
Encoder Loss:  0.43152332  || Decoder Loss:  0.4366333 Validation Decoder Loss:  1.2080331
Encoder Loss:  0.48221484  || Decoder Loss:  0.48802474 Validation Decoder Loss:  0.9551647
Encoder Loss:  0.41156155  || Decoder Loss:  0.41643038 Validation Decoder Loss:  0.9721581
Encoder Loss:  0.42046273  || Decoder Loss:  0.42545223 Validation Decoder Loss:  0.99233055
Encoder Loss:  0.48099473  || Decoder Loss:  0.4868046 Validation Decoder Loss:  0.9996852
Encoder Loss:  0.48199353  || Decoder Loss:  0.48781747 Validation Decoder Loss:  0.99984825
Encoder Loss:  0.48177823  || Decoder Loss:  0.4876001 Validation Decoder Loss:  0.9955506
Encoder Loss:  0.4774764  || Decoder Loss:  0.48325115 Validation Decoder Loss:  0.99018395
Encoder Loss:  0.47078988  || Decoder Loss:  0.47645962 Validation Decoder Loss:  1.0438011
Encoder Loss:  0.4574067  || Decoder Loss:  0.4628702 Validation Decoder Loss:  0.78602684
Encoder Loss:  0.49442863  || Decoder Loss:  0.50040555 Validation Decoder Loss:  0.9824265
Encoder Loss:  0.49335313  || Decoder Loss:  0.49934185 Validation Decoder Loss:  0.98020846
Model: siamese_net_lr_0.29159718005710455 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.98020846
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_186 (Conv3D (None, 187, 10, 20, 1)    249       
_________________________________________________________________
dropout_432 (Dropout)        (None, 187, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_187 (Conv3D (None, 257, 10, 20, 1)    72        
_________________________________________________________________
reshape_103 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 321
Trainable params: 321
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_352"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_434 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_436 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18315765  || Decoder Loss:  0.49513808 Validation Decoder Loss:  1.1244435
Encoder Loss:  0.18395934  || Decoder Loss:  0.4969886 Validation Decoder Loss:  0.877977
Encoder Loss:  0.18537924  || Decoder Loss:  0.49954513 Validation Decoder Loss:  1.1131344
Encoder Loss:  0.18316251  || Decoder Loss:  0.49932563 Validation Decoder Loss:  0.91618407
Encoder Loss:  0.17985857  || Decoder Loss:  0.48818934 Validation Decoder Loss:  0.87865764
Encoder Loss:  0.18209194  || Decoder Loss:  0.49561927 Validation Decoder Loss:  0.9292063
Encoder Loss:  0.18342663  || Decoder Loss:  0.50023866 Validation Decoder Loss:  1.0494277
Encoder Loss:  0.18324737  || Decoder Loss:  0.49936986 Validation Decoder Loss:  1.1181152
Encoder Loss:  0.18044181  || Decoder Loss:  0.49019396 Validation Decoder Loss:  1.1176578
Encoder Loss:  0.18236901  || Decoder Loss:  0.49669227 Validation Decoder Loss:  0.8764973
Encoder Loss:  0.18154544  || Decoder Loss:  0.49390042 Validation Decoder Loss:  0.89967775
Encoder Loss:  0.18349805  || Decoder Loss:  0.5004865 Validation Decoder Loss:  0.88957345
Encoder Loss:  0.10800927  || Decoder Loss:  0.21733296 Validation Decoder Loss:  0.7472154
Encoder Loss:  0.11329753  || Decoder Loss:  0.2635875 Validation Decoder Loss:  0.7414829
Encoder Loss:  0.10331996  || Decoder Loss:  0.2298892 Validation Decoder Loss:  0.7527485
Encoder Loss:  0.10656974  || Decoder Loss:  0.24089098 Validation Decoder Loss:  0.7406839
Encoder Loss:  0.18240854  || Decoder Loss:  0.4868814 Validation Decoder Loss:  1.1909411
Encoder Loss:  0.1787992  || Decoder Loss:  0.48464334 Validation Decoder Loss:  1.1984255
Encoder Loss:  0.17769158  || Decoder Loss:  0.48091263 Validation Decoder Loss:  1.1935868
Encoder Loss:  0.1769424  || Decoder Loss:  0.47838143 Validation Decoder Loss:  1.1872046
Encoder Loss:  0.17644289  || Decoder Loss:  0.47668865 Validation Decoder Loss:  1.1704823
Encoder Loss:  0.17703548  || Decoder Loss:  0.4786833 Validation Decoder Loss:  1.1533818
Encoder Loss:  0.17839812  || Decoder Loss:  0.48329008 Validation Decoder Loss:  1.118496
Encoder Loss:  0.17905374  || Decoder Loss:  0.48551342 Validation Decoder Loss:  1.0922656
Encoder Loss:  0.17934418  || Decoder Loss:  0.48648563 Validation Decoder Loss:  1.0924726
Encoder Loss:  0.17949045  || Decoder Loss:  0.4869791 Validation Decoder Loss:  1.0042694
Encoder Loss:  0.17908663  || Decoder Loss:  0.4851617 Validation Decoder Loss:  1.1194346
Encoder Loss:  0.17829697  || Decoder Loss:  0.48297387 Validation Decoder Loss:  1.0789254
Encoder Loss:  0.17944032  || Decoder Loss:  0.4868293 Validation Decoder Loss:  1.1013627
Encoder Loss:  0.18000242  || Decoder Loss:  0.48872748 Validation Decoder Loss:  1.089623
Encoder Loss:  0.18042429  || Decoder Loss:  0.4901487 Validation Decoder Loss:  1.0596704
Encoder Loss:  0.18055867  || Decoder Loss:  0.49053136 Validation Decoder Loss:  0.8713111
Encoder Loss:  0.18078288  || Decoder Loss:  0.49131066 Validation Decoder Loss:  0.9509243
Encoder Loss:  0.18179534  || Decoder Loss:  0.49477276 Validation Decoder Loss:  1.0883467
Encoder Loss:  0.18224752  || Decoder Loss:  0.4962981 Validation Decoder Loss:  1.0956117
Encoder Loss:  0.1810248  || Decoder Loss:  0.49217102 Validation Decoder Loss:  1.087529
Encoder Loss:  0.18148002  || Decoder Loss:  0.49369174 Validation Decoder Loss:  0.9242636
Encoder Loss:  0.18260568  || Decoder Loss:  0.49750277 Validation Decoder Loss:  0.93247986
Encoder Loss:  0.18266982  || Decoder Loss:  0.49771267 Validation Decoder Loss:  1.1092405
Encoder Loss:  0.18253165  || Decoder Loss:  0.49724174 Validation Decoder Loss:  0.9229137
Model: siamese_net_lr_0.4622546761281377 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9229137
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_189 (Conv3D (None, 167, 10, 20, 1)    209       
_________________________________________________________________
dropout_438 (Dropout)        (None, 167, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_190 (Conv3D (None, 257, 10, 20, 1)    92        
_________________________________________________________________
reshape_104 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_440 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_442 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18574062  || Decoder Loss:  0.16055605 Validation Decoder Loss:  0.36455774
Encoder Loss:  0.10417392  || Decoder Loss:  0.105237074 Validation Decoder Loss:  0.3616119
Encoder Loss:  0.099591844  || Decoder Loss:  0.10707025 Validation Decoder Loss:  0.36120093
Encoder Loss:  0.09956546  || Decoder Loss:  0.107483074 Validation Decoder Loss:  0.3610869
Encoder Loss:  0.09940717  || Decoder Loss:  0.107596666 Validation Decoder Loss:  0.36106455
Encoder Loss:  0.099403724  || Decoder Loss:  0.10760168 Validation Decoder Loss:  0.3610525
Encoder Loss:  0.099385835  || Decoder Loss:  0.107581474 Validation Decoder Loss:  0.36104634
Encoder Loss:  0.09936397  || Decoder Loss:  0.10755667 Validation Decoder Loss:  0.3610383
Encoder Loss:  0.099342436  || Decoder Loss:  0.107531756 Validation Decoder Loss:  0.36102304
Encoder Loss:  0.09931974  || Decoder Loss:  0.107506454 Validation Decoder Loss:  0.36101493
Encoder Loss:  0.09929926  || Decoder Loss:  0.10748309 Validation Decoder Loss:  0.36101
Encoder Loss:  0.0992803  || Decoder Loss:  0.10746134 Validation Decoder Loss:  0.3610093
Encoder Loss:  0.09926279  || Decoder Loss:  0.10744118 Validation Decoder Loss:  0.36101145
Encoder Loss:  0.09924583  || Decoder Loss:  0.10742156 Validation Decoder Loss:  0.36101562
Encoder Loss:  0.09922903  || Decoder Loss:  0.107402116 Validation Decoder Loss:  0.36101633
Encoder Loss:  0.099212125  || Decoder Loss:  0.10738244 Validation Decoder Loss:  0.3610186
Encoder Loss:  0.099195175  || Decoder Loss:  0.10736277 Validation Decoder Loss:  0.36102024
Encoder Loss:  0.09917804  || Decoder Loss:  0.107342824 Validation Decoder Loss:  0.3610217
Encoder Loss:  0.09916074  || Decoder Loss:  0.107322715 Validation Decoder Loss:  0.3610232
Encoder Loss:  0.09914329  || Decoder Loss:  0.1073024 Validation Decoder Loss:  0.36102462
Encoder Loss:  0.0991256  || Decoder Loss:  0.10728185 Validation Decoder Loss:  0.3610264
Encoder Loss:  0.09910774  || Decoder Loss:  0.10726107 Validation Decoder Loss:  0.36102852
Encoder Loss:  0.09908973  || Decoder Loss:  0.10724011 Validation Decoder Loss:  0.36103168
Encoder Loss:  0.09907178  || Decoder Loss:  0.10721922 Validation Decoder Loss:  0.36103797
Encoder Loss:  0.09905438  || Decoder Loss:  0.107199 Validation Decoder Loss:  0.36104807
Encoder Loss:  0.09903758  || Decoder Loss:  0.10717943 Validation Decoder Loss:  0.36105868
Encoder Loss:  0.09901956  || Decoder Loss:  0.10715839 Validation Decoder Loss:  0.36106193
Encoder Loss:  0.09900339  || Decoder Loss:  0.107139215 Validation Decoder Loss:  0.36107084
Encoder Loss:  0.09898552  || Decoder Loss:  0.107118845 Validation Decoder Loss:  0.36105973
Encoder Loss:  0.09896579  || Decoder Loss:  0.10709602 Validation Decoder Loss:  0.361062
Encoder Loss:  0.09894742  || Decoder Loss:  0.107074626 Validation Decoder Loss:  0.36107048
Encoder Loss:  0.09892889  || Decoder Loss:  0.10705304 Validation Decoder Loss:  0.3610782
Encoder Loss:  0.09891022  || Decoder Loss:  0.10703137 Validation Decoder Loss:  0.36107695
Encoder Loss:  0.09888977  || Decoder Loss:  0.107007615 Validation Decoder Loss:  0.3610751
Encoder Loss:  0.09887049  || Decoder Loss:  0.1069852 Validation Decoder Loss:  0.3610807
Encoder Loss:  0.09885096  || Decoder Loss:  0.1069625 Validation Decoder Loss:  0.36108047
Encoder Loss:  0.098831356  || Decoder Loss:  0.10693968 Validation Decoder Loss:  0.3610819
Encoder Loss:  0.098811366  || Decoder Loss:  0.106916435 Validation Decoder Loss:  0.36107534
Encoder Loss:  0.09878991  || Decoder Loss:  0.10689152 Validation Decoder Loss:  0.36106747
Encoder Loss:  0.098770104  || Decoder Loss:  0.106868446 Validation Decoder Loss:  0.3610696
Model: siamese_net_lr_0.8290832038652803 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3610696
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_192 (Conv3D (None, 236, 10, 20, 1)    661       
_________________________________________________________________
dropout_444 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_193 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_105 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 684
Trainable params: 684
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_446 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_448 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06285952  || Decoder Loss:  0.06440211 Validation Decoder Loss:  0.34593076
Encoder Loss:  0.32928902  || Decoder Loss:  0.47625187 Validation Decoder Loss:  0.8812295
Encoder Loss:  0.29192528  || Decoder Loss:  0.44214028 Validation Decoder Loss:  0.88313043
Encoder Loss:  0.29358825  || Decoder Loss:  0.44485247 Validation Decoder Loss:  0.8891026
Encoder Loss:  0.31592044  || Decoder Loss:  0.48106098 Validation Decoder Loss:  0.9275842
Encoder Loss:  0.3261618  || Decoder Loss:  0.49766156 Validation Decoder Loss:  0.9586395
Encoder Loss:  0.32435825  || Decoder Loss:  0.49430427 Validation Decoder Loss:  1.0270401
Encoder Loss:  0.30706522  || Decoder Loss:  0.46671632 Validation Decoder Loss:  0.95070034
Encoder Loss:  0.32205755  || Decoder Loss:  0.49101126 Validation Decoder Loss:  0.96994287
Encoder Loss:  0.32497016  || Decoder Loss:  0.49564114 Validation Decoder Loss:  1.0421228
Encoder Loss:  0.31334805  || Decoder Loss:  0.47655416 Validation Decoder Loss:  0.9308425
Encoder Loss:  0.32394135  || Decoder Loss:  0.49353966 Validation Decoder Loss:  0.9330649
Encoder Loss:  0.30922619  || Decoder Loss:  0.47022414 Validation Decoder Loss:  0.8981756
Encoder Loss:  0.29655826  || Decoder Loss:  0.44968766 Validation Decoder Loss:  0.87241477
Encoder Loss:  0.31508192  || Decoder Loss:  0.4794384 Validation Decoder Loss:  0.92210406
Encoder Loss:  0.3184716  || Decoder Loss:  0.48510376 Validation Decoder Loss:  1.0179898
Encoder Loss:  0.31395966  || Decoder Loss:  0.47788766 Validation Decoder Loss:  1.0961087
Encoder Loss:  0.2994006  || Decoder Loss:  0.4542824 Validation Decoder Loss:  0.94006616
Encoder Loss:  0.2829963  || Decoder Loss:  0.4258171 Validation Decoder Loss:  0.62213504
Encoder Loss:  0.19600339  || Decoder Loss:  0.28667948 Validation Decoder Loss:  0.58912385
Encoder Loss:  0.19235204  || Decoder Loss:  0.28075862 Validation Decoder Loss:  0.6406622
Encoder Loss:  0.24738558  || Decoder Loss:  0.36997005 Validation Decoder Loss:  0.9530915
Encoder Loss:  0.31313306  || Decoder Loss:  0.47655892 Validation Decoder Loss:  0.9138756
Encoder Loss:  0.3183533  || Decoder Loss:  0.48502204 Validation Decoder Loss:  0.97240525
Encoder Loss:  0.32242888  || Decoder Loss:  0.49160212 Validation Decoder Loss:  1.0323708
Encoder Loss:  0.32516375  || Decoder Loss:  0.49602777 Validation Decoder Loss:  1.0032158
Encoder Loss:  0.3071849  || Decoder Loss:  0.46688548 Validation Decoder Loss:  1.0144811
Encoder Loss:  0.31136933  || Decoder Loss:  0.4737012 Validation Decoder Loss:  1.0908709
Encoder Loss:  0.32613397  || Decoder Loss:  0.49762475 Validation Decoder Loss:  1.0454125
Encoder Loss:  0.2899885  || Decoder Loss:  0.43844602 Validation Decoder Loss:  0.83995765
Encoder Loss:  0.28026864  || Decoder Loss:  0.42328736 Validation Decoder Loss:  0.8194243
Encoder Loss:  0.27324  || Decoder Loss:  0.41189307 Validation Decoder Loss:  0.7996118
Encoder Loss:  0.26911193  || Decoder Loss:  0.40520093 Validation Decoder Loss:  0.7861206
Encoder Loss:  0.29517218  || Decoder Loss:  0.44741845 Validation Decoder Loss:  0.9784931
Encoder Loss:  0.3124298  || Decoder Loss:  0.47541928 Validation Decoder Loss:  0.97018063
Encoder Loss:  0.32591018  || Decoder Loss:  0.4972427 Validation Decoder Loss:  0.99199176
Encoder Loss:  0.31419823  || Decoder Loss:  0.4782768 Validation Decoder Loss:  1.0345433
Encoder Loss:  0.30964336  || Decoder Loss:  0.47035968 Validation Decoder Loss:  0.90805566
Encoder Loss:  0.3089779  || Decoder Loss:  0.4698287 Validation Decoder Loss:  0.9020258
Encoder Loss:  0.30629894  || Decoder Loss:  0.4654856 Validation Decoder Loss:  0.886739
Model: siamese_net_lr_0.8178086183188128 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.886739
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_195 (Conv3D (None, 242, 5, 20, 1)     180       
_________________________________________________________________
dropout_450 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_196 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_106 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 213
Trainable params: 213
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_364"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_452 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_454 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21709032  || Decoder Loss:  0.47817993 Validation Decoder Loss:  0.9921806
Encoder Loss:  0.21942693  || Decoder Loss:  0.4951471 Validation Decoder Loss:  0.9994986
Encoder Loss:  0.2190869  || Decoder Loss:  0.49451295 Validation Decoder Loss:  0.995337
Encoder Loss:  0.10357447  || Decoder Loss:  0.19021034 Validation Decoder Loss:  0.33282977
Encoder Loss:  0.09840642  || Decoder Loss:  0.17510995 Validation Decoder Loss:  0.33608016
Encoder Loss:  0.044786368  || Decoder Loss:  0.03595388 Validation Decoder Loss:  0.33721823
Encoder Loss:  0.044964094  || Decoder Loss:  0.036377102 Validation Decoder Loss:  0.33650085
Encoder Loss:  0.04531639  || Decoder Loss:  0.037417155 Validation Decoder Loss:  0.3146231
Encoder Loss:  0.044803295  || Decoder Loss:  0.036121834 Validation Decoder Loss:  0.34123284
Encoder Loss:  0.10387332  || Decoder Loss:  0.19115163 Validation Decoder Loss:  0.33418724
Encoder Loss:  0.044733316  || Decoder Loss:  0.036046017 Validation Decoder Loss:  0.33748317
Encoder Loss:  0.19095585  || Decoder Loss:  0.4188152 Validation Decoder Loss:  1.0198436
Encoder Loss:  0.22048682  || Decoder Loss:  0.4982954 Validation Decoder Loss:  0.99569666
Encoder Loss:  0.21814647  || Decoder Loss:  0.49250537 Validation Decoder Loss:  1.0013857
Encoder Loss:  0.14834557  || Decoder Loss:  0.30830204 Validation Decoder Loss:  0.33618382
Encoder Loss:  0.046992775  || Decoder Loss:  0.04198575 Validation Decoder Loss:  0.33418286
Encoder Loss:  0.04495686  || Decoder Loss:  0.036672987 Validation Decoder Loss:  0.33401734
Encoder Loss:  0.045054987  || Decoder Loss:  0.036914717 Validation Decoder Loss:  0.33581465
Encoder Loss:  0.04531382  || Decoder Loss:  0.037589587 Validation Decoder Loss:  0.3324759
Encoder Loss:  0.0460156  || Decoder Loss:  0.039439496 Validation Decoder Loss:  0.49394011
Encoder Loss:  0.063238405  || Decoder Loss:  0.080036 Validation Decoder Loss:  0.333838
Encoder Loss:  0.045977708  || Decoder Loss:  0.039363585 Validation Decoder Loss:  0.3374498
Encoder Loss:  0.046009496  || Decoder Loss:  0.039404236 Validation Decoder Loss:  0.34217525
Encoder Loss:  0.06192039  || Decoder Loss:  0.0811097 Validation Decoder Loss:  0.33310005
Encoder Loss:  0.046025343  || Decoder Loss:  0.03944497 Validation Decoder Loss:  0.33544087
Encoder Loss:  0.04642222  || Decoder Loss:  0.040450417 Validation Decoder Loss:  0.33905277
Encoder Loss:  0.049492218  || Decoder Loss:  0.048407406 Validation Decoder Loss:  0.3345183
Encoder Loss:  0.04567373  || Decoder Loss:  0.038539983 Validation Decoder Loss:  0.34045422
Encoder Loss:  0.048954964  || Decoder Loss:  0.04697296 Validation Decoder Loss:  0.3379393
Encoder Loss:  0.045736626  || Decoder Loss:  0.038707484 Validation Decoder Loss:  0.35914165
Encoder Loss:  0.049217276  || Decoder Loss:  0.04775124 Validation Decoder Loss:  0.33672246
Encoder Loss:  0.054229617  || Decoder Loss:  0.06085794 Validation Decoder Loss:  0.3423589
Encoder Loss:  0.045898773  || Decoder Loss:  0.039138112 Validation Decoder Loss:  0.3471318
Encoder Loss:  0.05372104  || Decoder Loss:  0.05960435 Validation Decoder Loss:  0.35037807
Encoder Loss:  0.04624009  || Decoder Loss:  0.039984334 Validation Decoder Loss:  0.33839044
Encoder Loss:  0.0456389  || Decoder Loss:  0.038463384 Validation Decoder Loss:  0.33457944
Encoder Loss:  0.06421175  || Decoder Loss:  0.087065876 Validation Decoder Loss:  0.3350086
Encoder Loss:  0.046177153  || Decoder Loss:  0.039879892 Validation Decoder Loss:  0.3407031
Encoder Loss:  0.05683674  || Decoder Loss:  0.06789989 Validation Decoder Loss:  0.3406073
Encoder Loss:  0.045511257  || Decoder Loss:  0.038099762 Validation Decoder Loss:  0.3363316
Model: siamese_net_lr_0.36721343857602945 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3363316
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_198 (Conv3D (None, 167, 10, 20, 1)    83        
_________________________________________________________________
dropout_456 (Dropout)        (None, 167, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_199 (Conv3D (None, 257, 10, 20, 1)    92        
_________________________________________________________________
reshape_107 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_458 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_460 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36273885  || Decoder Loss:  0.430801 Validation Decoder Loss:  1.0767844
Encoder Loss:  0.36610258  || Decoder Loss:  0.48305932 Validation Decoder Loss:  1.0508583
Encoder Loss:  0.3647947  || Decoder Loss:  0.4879533 Validation Decoder Loss:  0.98110765
Encoder Loss:  0.3625383  || Decoder Loss:  0.48521343 Validation Decoder Loss:  0.92684567
Encoder Loss:  0.3393097  || Decoder Loss:  0.4528792 Validation Decoder Loss:  0.9532131
Encoder Loss:  0.3684699  || Decoder Loss:  0.49363622 Validation Decoder Loss:  0.97524124
Encoder Loss:  0.3695034  || Decoder Loss:  0.49509838 Validation Decoder Loss:  0.95165175
Encoder Loss:  0.36933637  || Decoder Loss:  0.49483302 Validation Decoder Loss:  0.9621887
Encoder Loss:  0.3692431  || Decoder Loss:  0.49468657 Validation Decoder Loss:  0.97525954
Encoder Loss:  0.3689415  || Decoder Loss:  0.49429727 Validation Decoder Loss:  0.96968925
Encoder Loss:  0.3687243  || Decoder Loss:  0.49399558 Validation Decoder Loss:  0.9973042
Encoder Loss:  0.36888093  || Decoder Loss:  0.4941213 Validation Decoder Loss:  1.003444
Encoder Loss:  0.3690722  || Decoder Loss:  0.49428654 Validation Decoder Loss:  1.0198061
Encoder Loss:  0.36832377  || Decoder Loss:  0.49331245 Validation Decoder Loss:  1.0225445
Encoder Loss:  0.36806643  || Decoder Loss:  0.49299613 Validation Decoder Loss:  0.9642476
Encoder Loss:  0.36798856  || Decoder Loss:  0.49297637 Validation Decoder Loss:  1.019492
Encoder Loss:  0.36813432  || Decoder Loss:  0.4930077 Validation Decoder Loss:  0.98747224
Encoder Loss:  0.367514  || Decoder Loss:  0.49218446 Validation Decoder Loss:  1.0191258
Encoder Loss:  0.36727974  || Decoder Loss:  0.4919401 Validation Decoder Loss:  0.9917337
Encoder Loss:  0.36712727  || Decoder Loss:  0.4916939 Validation Decoder Loss:  0.95442045
Encoder Loss:  0.36666682  || Decoder Loss:  0.49111068 Validation Decoder Loss:  1.0062957
Encoder Loss:  0.36630332  || Decoder Loss:  0.4906002 Validation Decoder Loss:  0.9700049
Encoder Loss:  0.36582005  || Decoder Loss:  0.48994035 Validation Decoder Loss:  1.0221633
Encoder Loss:  0.36560607  || Decoder Loss:  0.4895545 Validation Decoder Loss:  0.9708985
Encoder Loss:  0.36514416  || Decoder Loss:  0.48903394 Validation Decoder Loss:  1.0142025
Encoder Loss:  0.36512983  || Decoder Loss:  0.48874635 Validation Decoder Loss:  1.1497732
Encoder Loss:  0.3655703  || Decoder Loss:  0.4886465 Validation Decoder Loss:  0.99302566
Encoder Loss:  0.36377254  || Decoder Loss:  0.48695523 Validation Decoder Loss:  1.0238452
Encoder Loss:  0.36323366  || Decoder Loss:  0.48622945 Validation Decoder Loss:  0.9839213
Encoder Loss:  0.3619806  || Decoder Loss:  0.48453948 Validation Decoder Loss:  1.0138632
Encoder Loss:  0.35987777  || Decoder Loss:  0.48166448 Validation Decoder Loss:  0.9653923
Encoder Loss:  0.35470134  || Decoder Loss:  0.47449493 Validation Decoder Loss:  0.9797631
Encoder Loss:  0.28122532  || Decoder Loss:  0.37201604 Validation Decoder Loss:  0.79866165
Encoder Loss:  0.3427183  || Decoder Loss:  0.45772016 Validation Decoder Loss:  0.99380493
Encoder Loss:  0.36433455  || Decoder Loss:  0.48790374 Validation Decoder Loss:  0.9444071
Encoder Loss:  0.3638414  || Decoder Loss:  0.48721945 Validation Decoder Loss:  0.94428825
Encoder Loss:  0.36329895  || Decoder Loss:  0.48642147 Validation Decoder Loss:  0.97095495
Encoder Loss:  0.3623873  || Decoder Loss:  0.48523852 Validation Decoder Loss:  0.92860836
Encoder Loss:  0.36168516  || Decoder Loss:  0.4841701 Validation Decoder Loss:  0.97017676
Encoder Loss:  0.36035892  || Decoder Loss:  0.4823518 Validation Decoder Loss:  0.9330071
Model: siamese_net_lr_0.7380122649150258 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9330071
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_201 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_462 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_202 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_108 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 214
Trainable params: 214
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_464 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_466 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43168908  || Decoder Loss:  0.48915225 Validation Decoder Loss:  0.99693644
Encoder Loss:  0.12411149  || Decoder Loss:  0.1359816 Validation Decoder Loss:  0.33279505
Encoder Loss:  0.056900196  || Decoder Loss:  0.0579545 Validation Decoder Loss:  0.3315318
Encoder Loss:  0.060463395  || Decoder Loss:  0.061954085 Validation Decoder Loss:  0.33285272
Encoder Loss:  0.04002918  || Decoder Loss:  0.03841887 Validation Decoder Loss:  0.31028187
Encoder Loss:  0.359584  || Decoder Loss:  0.40811467 Validation Decoder Loss:  0.3118252
Encoder Loss:  0.06868461  || Decoder Loss:  0.0716207 Validation Decoder Loss:  0.33033097
Encoder Loss:  0.037382808  || Decoder Loss:  0.035355646 Validation Decoder Loss:  0.33653995
Encoder Loss:  0.038654562  || Decoder Loss:  0.03682517 Validation Decoder Loss:  0.3330443
Encoder Loss:  0.13826852  || Decoder Loss:  0.15229702 Validation Decoder Loss:  0.33146006
Encoder Loss:  0.037485167  || Decoder Loss:  0.035474293 Validation Decoder Loss:  0.3323223
Encoder Loss:  0.03747904  || Decoder Loss:  0.035468105 Validation Decoder Loss:  0.3327806
Encoder Loss:  0.03746916  || Decoder Loss:  0.035456054 Validation Decoder Loss:  0.33092678
Encoder Loss:  0.041303426  || Decoder Loss:  0.03990453 Validation Decoder Loss:  0.33373
Encoder Loss:  0.037492856  || Decoder Loss:  0.035485096 Validation Decoder Loss:  0.3330806
Encoder Loss:  0.03751613  || Decoder Loss:  0.035512075 Validation Decoder Loss:  0.33472154
Encoder Loss:  0.11243749  || Decoder Loss:  0.12243399 Validation Decoder Loss:  0.9985687
Encoder Loss:  0.15348697  || Decoder Loss:  0.17009565 Validation Decoder Loss:  0.33437294
Encoder Loss:  0.037596416  || Decoder Loss:  0.035605326 Validation Decoder Loss:  0.33344698
Encoder Loss:  0.03757225  || Decoder Loss:  0.03557746 Validation Decoder Loss:  0.33488408
Encoder Loss:  0.03791777  || Decoder Loss:  0.035978477 Validation Decoder Loss:  0.33940387
Encoder Loss:  0.038526684  || Decoder Loss:  0.036685064 Validation Decoder Loss:  0.3409865
Encoder Loss:  0.03867629  || Decoder Loss:  0.03685868 Validation Decoder Loss:  0.33483607
Encoder Loss:  0.097842515  || Decoder Loss:  0.10551355 Validation Decoder Loss:  0.3277923
Encoder Loss:  0.037802834  || Decoder Loss:  0.03584137 Validation Decoder Loss:  0.32625175
Encoder Loss:  0.037599336  || Decoder Loss:  0.035607144 Validation Decoder Loss:  0.33860677
Encoder Loss:  0.037640262  || Decoder Loss:  0.035656244 Validation Decoder Loss:  0.33130765
Encoder Loss:  0.040006105  || Decoder Loss:  0.03840176 Validation Decoder Loss:  0.33421332
Encoder Loss:  0.03755392  || Decoder Loss:  0.03555605 Validation Decoder Loss:  0.33296984
Encoder Loss:  0.0677436  || Decoder Loss:  0.070590265 Validation Decoder Loss:  0.33188546
Encoder Loss:  0.037573382  || Decoder Loss:  0.03557869 Validation Decoder Loss:  0.33174267
Encoder Loss:  0.03818774  || Decoder Loss:  0.036290444 Validation Decoder Loss:  0.3324223
Encoder Loss:  0.0375545  || Decoder Loss:  0.035556898 Validation Decoder Loss:  0.3340612
Encoder Loss:  0.13189936  || Decoder Loss:  0.14504154 Validation Decoder Loss:  0.33404467
Encoder Loss:  0.03752207  || Decoder Loss:  0.035519257 Validation Decoder Loss:  0.3307404
Encoder Loss:  0.03752377  || Decoder Loss:  0.03552122 Validation Decoder Loss:  0.3341324
Encoder Loss:  0.037558608  || Decoder Loss:  0.035561606 Validation Decoder Loss:  0.33395773
Encoder Loss:  0.037536874  || Decoder Loss:  0.035536308 Validation Decoder Loss:  0.3347324
Encoder Loss:  0.30922335  || Decoder Loss:  0.35081676 Validation Decoder Loss:  0.9199693
Encoder Loss:  0.19597647  || Decoder Loss:  0.2194051 Validation Decoder Loss:  0.33301434
Model: siamese_net_lr_0.5442121910533804 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33301434
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_204 (Conv3D (None, 236, 10, 20, 1)    1039      
_________________________________________________________________
dropout_468 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_205 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_109 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,062
Trainable params: 1,062
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_376"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_470 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_472 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05089078  || Decoder Loss:  0.036043655 Validation Decoder Loss:  0.33086008
Encoder Loss:  0.047057856  || Decoder Loss:  0.035113722 Validation Decoder Loss:  0.3286111
Encoder Loss:  0.04699045  || Decoder Loss:  0.0348022 Validation Decoder Loss:  0.32859898
Encoder Loss:  0.046993837  || Decoder Loss:  0.034827568 Validation Decoder Loss:  0.32947934
Encoder Loss:  0.046977997  || Decoder Loss:  0.03475432 Validation Decoder Loss:  0.32849553
Encoder Loss:  0.11295083  || Decoder Loss:  0.09057764 Validation Decoder Loss:  0.3218932
Encoder Loss:  0.054885324  || Decoder Loss:  0.039425302 Validation Decoder Loss:  0.37217113
Encoder Loss:  0.054161772  || Decoder Loss:  0.03703039 Validation Decoder Loss:  0.3760983
Encoder Loss:  0.05299716  || Decoder Loss:  0.03650892 Validation Decoder Loss:  0.3615198
Encoder Loss:  0.05277787  || Decoder Loss:  0.036306407 Validation Decoder Loss:  0.3264433
Encoder Loss:  0.052752223  || Decoder Loss:  0.0352881 Validation Decoder Loss:  0.32851064
Encoder Loss:  0.052152924  || Decoder Loss:  0.035130803 Validation Decoder Loss:  0.3307958
Encoder Loss:  0.052648984  || Decoder Loss:  0.03554702 Validation Decoder Loss:  0.33166713
Encoder Loss:  0.052524038  || Decoder Loss:  0.036119867 Validation Decoder Loss:  0.3549565
Encoder Loss:  0.052215066  || Decoder Loss:  0.03737918 Validation Decoder Loss:  0.32620698
Encoder Loss:  0.050989673  || Decoder Loss:  0.035091575 Validation Decoder Loss:  0.3327925
Encoder Loss:  0.047070667  || Decoder Loss:  0.03501353 Validation Decoder Loss:  0.33240074
Encoder Loss:  0.047023077  || Decoder Loss:  0.03491914 Validation Decoder Loss:  0.35006618
Encoder Loss:  0.04704063  || Decoder Loss:  0.03506144 Validation Decoder Loss:  0.33032066
Encoder Loss:  0.047591556  || Decoder Loss:  0.037839208 Validation Decoder Loss:  0.3260092
Encoder Loss:  0.04734385  || Decoder Loss:  0.0366203 Validation Decoder Loss:  0.3273111
Encoder Loss:  0.047323804  || Decoder Loss:  0.036528338 Validation Decoder Loss:  0.32629168
Encoder Loss:  0.047314998  || Decoder Loss:  0.036470257 Validation Decoder Loss:  0.32810718
Encoder Loss:  0.04738995  || Decoder Loss:  0.03631471 Validation Decoder Loss:  0.36265284
Encoder Loss:  0.047338486  || Decoder Loss:  0.03643399 Validation Decoder Loss:  0.3280095
Encoder Loss:  0.04724686  || Decoder Loss:  0.03615607 Validation Decoder Loss:  0.32365504
Encoder Loss:  0.047179922  || Decoder Loss:  0.035817616 Validation Decoder Loss:  0.335143
Encoder Loss:  0.04709908  || Decoder Loss:  0.03539445 Validation Decoder Loss:  0.329902
Encoder Loss:  0.047297817  || Decoder Loss:  0.03641089 Validation Decoder Loss:  0.3292308
Encoder Loss:  0.047060803  || Decoder Loss:  0.035147276 Validation Decoder Loss:  0.33787566
Encoder Loss:  0.047519393  || Decoder Loss:  0.037464228 Validation Decoder Loss:  0.32546598
Encoder Loss:  0.047110025  || Decoder Loss:  0.03546609 Validation Decoder Loss:  0.32998523
Encoder Loss:  0.0470486  || Decoder Loss:  0.035154317 Validation Decoder Loss:  0.33972728
Encoder Loss:  0.048105374  || Decoder Loss:  0.0387226 Validation Decoder Loss:  0.36232063
Encoder Loss:  0.0476056  || Decoder Loss:  0.03721321 Validation Decoder Loss:  0.37071505
Encoder Loss:  0.047290307  || Decoder Loss:  0.03638473 Validation Decoder Loss:  0.36879194
Encoder Loss:  0.04717452  || Decoder Loss:  0.03580333 Validation Decoder Loss:  0.32454482
Encoder Loss:  0.047068175  || Decoder Loss:  0.035269756 Validation Decoder Loss:  0.34116644
Encoder Loss:  0.047036763  || Decoder Loss:  0.035111755 Validation Decoder Loss:  0.35692185
Encoder Loss:  0.04768206  || Decoder Loss:  0.038350854 Validation Decoder Loss:  0.36901933
Model: siamese_net_lr_0.06665622028884112 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36901933
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_207 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_474 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_208 (Conv3D (None, 257, 10, 20, 1)    125       
_________________________________________________________________
reshape_110 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_476 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_478 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36889094  || Decoder Loss:  0.48610824 Validation Decoder Loss:  0.75687313
Encoder Loss:  0.27981633  || Decoder Loss:  0.3843314 Validation Decoder Loss:  0.2879181
Encoder Loss:  0.045900255  || Decoder Loss:  0.041855875 Validation Decoder Loss:  0.32814762
Encoder Loss:  0.043444525  || Decoder Loss:  0.03569592 Validation Decoder Loss:  0.3427772
Encoder Loss:  0.043003216  || Decoder Loss:  0.035507265 Validation Decoder Loss:  0.33513495
Encoder Loss:  0.043074034  || Decoder Loss:  0.035486083 Validation Decoder Loss:  0.3350609
Encoder Loss:  0.041105196  || Decoder Loss:  0.03550369 Validation Decoder Loss:  0.3398735
Encoder Loss:  0.040797595  || Decoder Loss:  0.035529383 Validation Decoder Loss:  0.34346443
Encoder Loss:  0.04125656  || Decoder Loss:  0.03551665 Validation Decoder Loss:  0.35034418
Encoder Loss:  0.041239653  || Decoder Loss:  0.035701968 Validation Decoder Loss:  0.34916323
Encoder Loss:  0.041481398  || Decoder Loss:  0.035848606 Validation Decoder Loss:  0.35016924
Encoder Loss:  0.04129216  || Decoder Loss:  0.03568374 Validation Decoder Loss:  0.336437
Encoder Loss:  0.041133203  || Decoder Loss:  0.03554766 Validation Decoder Loss:  0.3358588
Encoder Loss:  0.04182632  || Decoder Loss:  0.035461754 Validation Decoder Loss:  0.33523202
Encoder Loss:  0.04063717  || Decoder Loss:  0.03544919 Validation Decoder Loss:  0.33487186
Encoder Loss:  0.042116676  || Decoder Loss:  0.035441108 Validation Decoder Loss:  0.3388442
Encoder Loss:  0.040908918  || Decoder Loss:  0.03542009 Validation Decoder Loss:  0.33884305
Encoder Loss:  0.04113024  || Decoder Loss:  0.035412252 Validation Decoder Loss:  0.3407806
Encoder Loss:  0.040711686  || Decoder Loss:  0.035413243 Validation Decoder Loss:  0.34126747
Encoder Loss:  0.040785454  || Decoder Loss:  0.03542323 Validation Decoder Loss:  0.33903688
Encoder Loss:  0.04142982  || Decoder Loss:  0.035414923 Validation Decoder Loss:  0.3408565
Encoder Loss:  0.040717017  || Decoder Loss:  0.035421398 Validation Decoder Loss:  0.3435799
Encoder Loss:  0.040917415  || Decoder Loss:  0.03544622 Validation Decoder Loss:  0.34438452
Encoder Loss:  0.040882055  || Decoder Loss:  0.035450984 Validation Decoder Loss:  0.3452187
Encoder Loss:  0.04088953  || Decoder Loss:  0.035496354 Validation Decoder Loss:  0.3414173
Encoder Loss:  0.041301027  || Decoder Loss:  0.035765402 Validation Decoder Loss:  0.33287433
Encoder Loss:  0.04141486  || Decoder Loss:  0.0355906 Validation Decoder Loss:  0.3502995
Encoder Loss:  0.04086912  || Decoder Loss:  0.035586312 Validation Decoder Loss:  0.35642886
Encoder Loss:  0.04152095  || Decoder Loss:  0.035640996 Validation Decoder Loss:  0.35298687
Encoder Loss:  0.041558575  || Decoder Loss:  0.035710264 Validation Decoder Loss:  0.34782362
Encoder Loss:  0.04116148  || Decoder Loss:  0.03567941 Validation Decoder Loss:  0.35006392
Encoder Loss:  0.04109761  || Decoder Loss:  0.03566775 Validation Decoder Loss:  0.35241112
Encoder Loss:  0.040611252  || Decoder Loss:  0.035554525 Validation Decoder Loss:  0.34925503
Encoder Loss:  0.041002817  || Decoder Loss:  0.035662647 Validation Decoder Loss:  0.35217452
Encoder Loss:  0.04130064  || Decoder Loss:  0.035663716 Validation Decoder Loss:  0.3510035
Encoder Loss:  0.041131783  || Decoder Loss:  0.035653282 Validation Decoder Loss:  0.34197664
Encoder Loss:  0.0410351  || Decoder Loss:  0.03563386 Validation Decoder Loss:  0.353443
Encoder Loss:  0.041283056  || Decoder Loss:  0.03564165 Validation Decoder Loss:  0.34363008
Encoder Loss:  0.04106642  || Decoder Loss:  0.0355905 Validation Decoder Loss:  0.34634733
Encoder Loss:  0.041178703  || Decoder Loss:  0.035765156 Validation Decoder Loss:  0.34552103
Model: siamese_net_lr_0.20178845903214357 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34552103
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_210 (Conv3D (None, 236, 10, 20, 1)    283       
_________________________________________________________________
dropout_480 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_211 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_111 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 306
Trainable params: 306
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_482 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_484 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07971561  || Decoder Loss:  0.12147932 Validation Decoder Loss:  0.3314292
Encoder Loss:  0.048191804  || Decoder Loss:  0.037766244 Validation Decoder Loss:  0.33040208
Encoder Loss:  0.048084587  || Decoder Loss:  0.03724372 Validation Decoder Loss:  0.32973036
Encoder Loss:  0.047978383  || Decoder Loss:  0.036576018 Validation Decoder Loss:  0.32949042
Encoder Loss:  0.04795052  || Decoder Loss:  0.036516365 Validation Decoder Loss:  0.3296431
Encoder Loss:  0.048191156  || Decoder Loss:  0.037325975 Validation Decoder Loss:  0.321154
Encoder Loss:  0.048614927  || Decoder Loss:  0.03919509 Validation Decoder Loss:  0.3299455
Encoder Loss:  0.047979955  || Decoder Loss:  0.03692296 Validation Decoder Loss:  0.32957852
Encoder Loss:  0.047926337  || Decoder Loss:  0.03652443 Validation Decoder Loss:  0.3309467
Encoder Loss:  0.04795339  || Decoder Loss:  0.036633454 Validation Decoder Loss:  0.32870945
Encoder Loss:  0.17225641  || Decoder Loss:  0.422537 Validation Decoder Loss:  0.9909175
Encoder Loss:  0.12468726  || Decoder Loss:  0.50168407 Validation Decoder Loss:  0.9207069
Encoder Loss:  0.123895556  || Decoder Loss:  0.49754283 Validation Decoder Loss:  1.0236803
Encoder Loss:  0.12424608  || Decoder Loss:  0.49886686 Validation Decoder Loss:  0.998981
Encoder Loss:  0.122076884  || Decoder Loss:  0.49612015 Validation Decoder Loss:  1.0120616
Encoder Loss:  0.12119706  || Decoder Loss:  0.4937799 Validation Decoder Loss:  0.98043436
Encoder Loss:  0.11850476  || Decoder Loss:  0.48822325 Validation Decoder Loss:  0.9860921
Encoder Loss:  0.11776921  || Decoder Loss:  0.4836626 Validation Decoder Loss:  0.98514426
Encoder Loss:  0.11688518  || Decoder Loss:  0.4780297 Validation Decoder Loss:  0.9941914
Encoder Loss:  0.059022024  || Decoder Loss:  0.10751572 Validation Decoder Loss:  0.339957
Encoder Loss:  0.049807172  || Decoder Loss:  0.04854689 Validation Decoder Loss:  0.33013755
Encoder Loss:  0.052048825  || Decoder Loss:  0.04979971 Validation Decoder Loss:  0.35981375
Encoder Loss:  0.048854936  || Decoder Loss:  0.04245883 Validation Decoder Loss:  0.33234128
Encoder Loss:  0.04858252  || Decoder Loss:  0.04078199 Validation Decoder Loss:  0.3318303
Encoder Loss:  0.048540797  || Decoder Loss:  0.04045982 Validation Decoder Loss:  0.34240636
Encoder Loss:  0.048621874  || Decoder Loss:  0.04099659 Validation Decoder Loss:  0.33970666
Encoder Loss:  0.048409916  || Decoder Loss:  0.0397155 Validation Decoder Loss:  0.3390463
Encoder Loss:  0.048335716  || Decoder Loss:  0.0392091 Validation Decoder Loss:  0.33733022
Encoder Loss:  0.04829429  || Decoder Loss:  0.03895129 Validation Decoder Loss:  0.33569705
Encoder Loss:  0.04915844  || Decoder Loss:  0.04074183 Validation Decoder Loss:  0.33422226
Encoder Loss:  0.048501156  || Decoder Loss:  0.040364534 Validation Decoder Loss:  0.33214238
Encoder Loss:  0.048322536  || Decoder Loss:  0.03875286 Validation Decoder Loss:  0.33468807
Encoder Loss:  0.048202883  || Decoder Loss:  0.038442403 Validation Decoder Loss:  0.3345054
Encoder Loss:  0.048179932  || Decoder Loss:  0.038281225 Validation Decoder Loss:  0.33380526
Encoder Loss:  0.0480804  || Decoder Loss:  0.03763266 Validation Decoder Loss:  0.3300025
Encoder Loss:  0.04802961  || Decoder Loss:  0.037295505 Validation Decoder Loss:  0.33119398
Encoder Loss:  0.04800493  || Decoder Loss:  0.03714607 Validation Decoder Loss:  0.33105856
Encoder Loss:  0.048012428  || Decoder Loss:  0.037178196 Validation Decoder Loss:  0.33205593
Encoder Loss:  0.048029445  || Decoder Loss:  0.03728174 Validation Decoder Loss:  0.3328054
Encoder Loss:  0.048025943  || Decoder Loss:  0.03720342 Validation Decoder Loss:  0.33552963
Model: siamese_net_lr_0.35469598781732786 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33552963
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_213 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_486 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_214 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_112 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 214
Trainable params: 214
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_488 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_490 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.048434243  || Decoder Loss:  0.04622047 Validation Decoder Loss:  0.34126195
Encoder Loss:  0.044420972  || Decoder Loss:  0.042812295 Validation Decoder Loss:  0.34116727
Encoder Loss:  0.04389008  || Decoder Loss:  0.042829286 Validation Decoder Loss:  0.33671165
Encoder Loss:  0.044013444  || Decoder Loss:  0.042897157 Validation Decoder Loss:  0.34007612
Encoder Loss:  0.3813936  || Decoder Loss:  0.43606701 Validation Decoder Loss:  0.9969355
Encoder Loss:  0.43050793  || Decoder Loss:  0.49334863 Validation Decoder Loss:  1.0036504
Encoder Loss:  0.4350999  || Decoder Loss:  0.4986958 Validation Decoder Loss:  0.99241173
Encoder Loss:  0.43439317  || Decoder Loss:  0.49789467 Validation Decoder Loss:  0.9939437
Encoder Loss:  0.43463418  || Decoder Loss:  0.49818245 Validation Decoder Loss:  0.99421364
Encoder Loss:  0.41590396  || Decoder Loss:  0.47635528 Validation Decoder Loss:  0.35647845
Encoder Loss:  0.39398164  || Decoder Loss:  0.45081088 Validation Decoder Loss:  1.0050236
Encoder Loss:  0.43740693  || Decoder Loss:  0.5009328 Validation Decoder Loss:  0.98981625
Encoder Loss:  0.12130986  || Decoder Loss:  0.13302797 Validation Decoder Loss:  0.4358154
Encoder Loss:  0.05876916  || Decoder Loss:  0.06019293 Validation Decoder Loss:  0.42510158
Encoder Loss:  0.056202512  || Decoder Loss:  0.057211246 Validation Decoder Loss:  0.42763758
Encoder Loss:  0.054756507  || Decoder Loss:  0.05553893 Validation Decoder Loss:  0.43135348
Encoder Loss:  0.057992727  || Decoder Loss:  0.059312083 Validation Decoder Loss:  0.4395967
Encoder Loss:  0.058312684  || Decoder Loss:  0.05968494 Validation Decoder Loss:  0.43305343
Encoder Loss:  0.3166013  || Decoder Loss:  0.3606522 Validation Decoder Loss:  0.7429962
Encoder Loss:  0.3730168  || Decoder Loss:  0.42638978 Validation Decoder Loss:  1.1183217
Encoder Loss:  0.43226075  || Decoder Loss:  0.4954229 Validation Decoder Loss:  1.0371088
Encoder Loss:  0.41896302  || Decoder Loss:  0.4799239 Validation Decoder Loss:  1.2405171
Encoder Loss:  0.3444018  || Decoder Loss:  0.39304706 Validation Decoder Loss:  0.98126996
Encoder Loss:  0.42920792  || Decoder Loss:  0.49186227 Validation Decoder Loss:  1.0053725
Encoder Loss:  0.43348747  || Decoder Loss:  0.49685338 Validation Decoder Loss:  0.9809563
Encoder Loss:  0.43050796  || Decoder Loss:  0.49337724 Validation Decoder Loss:  0.9723635
Encoder Loss:  0.43060407  || Decoder Loss:  0.49349335 Validation Decoder Loss:  1.0174353
Encoder Loss:  0.43132287  || Decoder Loss:  0.49433064 Validation Decoder Loss:  0.98569554
Encoder Loss:  0.23164338  || Decoder Loss:  0.2615396 Validation Decoder Loss:  0.38565642
Encoder Loss:  0.26629922  || Decoder Loss:  0.30203664 Validation Decoder Loss:  0.4058861
Encoder Loss:  0.23413415  || Decoder Loss:  0.26455697 Validation Decoder Loss:  0.3583007
Encoder Loss:  0.16397436  || Decoder Loss:  0.18280624 Validation Decoder Loss:  0.35088402
Encoder Loss:  0.07024773  || Decoder Loss:  0.07359238 Validation Decoder Loss:  0.33225772
Encoder Loss:  0.04218807  || Decoder Loss:  0.040896524 Validation Decoder Loss:  0.3283617
Encoder Loss:  0.040692702  || Decoder Loss:  0.039154153 Validation Decoder Loss:  0.33406776
Encoder Loss:  0.039808817  || Decoder Loss:  0.038124334 Validation Decoder Loss:  0.33115155
Encoder Loss:  0.0391688  || Decoder Loss:  0.03737858 Validation Decoder Loss:  0.33348987
Encoder Loss:  0.12091138  || Decoder Loss:  0.13257201 Validation Decoder Loss:  1.3224003
Encoder Loss:  0.51168954  || Decoder Loss:  0.58797526 Validation Decoder Loss:  1.3652103
Encoder Loss:  0.4570135  || Decoder Loss:  0.52426463 Validation Decoder Loss:  0.83194184
Model: siamese_net_lr_0.41490094289685037 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8319419
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_216 (Conv3D (None, 250, 9, 20, 1)     621       
_________________________________________________________________
dropout_492 (Dropout)        (None, 250, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_217 (Conv3D (None, 257, 10, 20, 1)    17        
_________________________________________________________________
reshape_113 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 638
Trainable params: 638
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_392"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_494 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_496 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07077851  || Decoder Loss:  0.061973855 Validation Decoder Loss:  0.30945703
Encoder Loss:  0.041646782  || Decoder Loss:  0.0392386 Validation Decoder Loss:  0.32219768
Encoder Loss:  0.04033834  || Decoder Loss:  0.037626803 Validation Decoder Loss:  0.31538355
Encoder Loss:  0.03998624  || Decoder Loss:  0.03721705 Validation Decoder Loss:  0.31735015
Encoder Loss:  0.039750643  || Decoder Loss:  0.036923777 Validation Decoder Loss:  0.3180536
Encoder Loss:  0.039536454  || Decoder Loss:  0.03664472 Validation Decoder Loss:  0.32000226
Encoder Loss:  0.03951794  || Decoder Loss:  0.036623932 Validation Decoder Loss:  0.31946427
Encoder Loss:  0.039237037  || Decoder Loss:  0.036236476 Validation Decoder Loss:  0.31860602
Encoder Loss:  0.039520033  || Decoder Loss:  0.036591567 Validation Decoder Loss:  0.32154867
Encoder Loss:  0.039525293  || Decoder Loss:  0.036601752 Validation Decoder Loss:  0.32801485
Encoder Loss:  0.039418116  || Decoder Loss:  0.036475398 Validation Decoder Loss:  0.32797015
Encoder Loss:  0.039328642  || Decoder Loss:  0.036355365 Validation Decoder Loss:  0.32979298
Encoder Loss:  0.0396265  || Decoder Loss:  0.03670007 Validation Decoder Loss:  0.32977715
Encoder Loss:  0.040955078  || Decoder Loss:  0.03812057 Validation Decoder Loss:  0.32199576
Encoder Loss:  0.04042436  || Decoder Loss:  0.037784897 Validation Decoder Loss:  0.32936665
Encoder Loss:  0.039440986  || Decoder Loss:  0.036531657 Validation Decoder Loss:  0.33165216
Encoder Loss:  0.03934027  || Decoder Loss:  0.03640019 Validation Decoder Loss:  0.33097935
Encoder Loss:  0.039280683  || Decoder Loss:  0.036316574 Validation Decoder Loss:  0.33027545
Encoder Loss:  0.039259158  || Decoder Loss:  0.036291245 Validation Decoder Loss:  0.33233625
Encoder Loss:  0.039266784  || Decoder Loss:  0.036300056 Validation Decoder Loss:  0.33250847
Encoder Loss:  0.04099247  || Decoder Loss:  0.038274568 Validation Decoder Loss:  0.33000565
Encoder Loss:  0.039453894  || Decoder Loss:  0.036548503 Validation Decoder Loss:  0.3317342
Encoder Loss:  0.039303087  || Decoder Loss:  0.03635742 Validation Decoder Loss:  0.332162
Encoder Loss:  0.039354153  || Decoder Loss:  0.036416594 Validation Decoder Loss:  0.3320847
Encoder Loss:  0.039361447  || Decoder Loss:  0.036426127 Validation Decoder Loss:  0.33224928
Encoder Loss:  0.03935239  || Decoder Loss:  0.036412638 Validation Decoder Loss:  0.3319836
Encoder Loss:  0.039228044  || Decoder Loss:  0.036242567 Validation Decoder Loss:  0.3337694
Encoder Loss:  0.039537802  || Decoder Loss:  0.03664886 Validation Decoder Loss:  0.33358604
Encoder Loss:  0.039545804  || Decoder Loss:  0.036655426 Validation Decoder Loss:  0.3345554
Encoder Loss:  0.039659854  || Decoder Loss:  0.03679472 Validation Decoder Loss:  0.33412367
Encoder Loss:  0.0393447  || Decoder Loss:  0.036403205 Validation Decoder Loss:  0.3343074
Encoder Loss:  0.03983865  || Decoder Loss:  0.035298705 Validation Decoder Loss:  0.33045968
Encoder Loss:  0.038418557  || Decoder Loss:  0.035237003 Validation Decoder Loss:  0.33036336
Encoder Loss:  0.038423765  || Decoder Loss:  0.03524201 Validation Decoder Loss:  0.33041418
Encoder Loss:  0.03842597  || Decoder Loss:  0.03524613 Validation Decoder Loss:  0.33040482
Encoder Loss:  0.03843204  || Decoder Loss:  0.03525047 Validation Decoder Loss:  0.330382
Encoder Loss:  0.03843622  || Decoder Loss:  0.03525361 Validation Decoder Loss:  0.33045918
Encoder Loss:  0.03843525  || Decoder Loss:  0.03525669 Validation Decoder Loss:  0.33049333
Encoder Loss:  0.03843675  || Decoder Loss:  0.035258707 Validation Decoder Loss:  0.33058113
Encoder Loss:  0.038439814  || Decoder Loss:  0.03526028 Validation Decoder Loss:  0.3306537
Model: siamese_net_lr_0.43811103056152295 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306537
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_219 (Conv3D (None, 242, 5, 20, 1)     180       
_________________________________________________________________
dropout_498 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_220 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_114 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_500 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_502 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2750278  || Decoder Loss:  0.43953952 Validation Decoder Loss:  1.0052409
Encoder Loss:  0.28877228  || Decoder Loss:  0.49706146 Validation Decoder Loss:  0.9779159
Encoder Loss:  0.13251065  || Decoder Loss:  0.20429577 Validation Decoder Loss:  0.33290026
Encoder Loss:  0.049829725  || Decoder Loss:  0.049082328 Validation Decoder Loss:  0.32871732
Encoder Loss:  0.0535902  || Decoder Loss:  0.056088958 Validation Decoder Loss:  0.33493704
Encoder Loss:  0.043578286  || Decoder Loss:  0.03786235 Validation Decoder Loss:  0.33802944
Encoder Loss:  0.049733106  || Decoder Loss:  0.04913372 Validation Decoder Loss:  0.32863685
Encoder Loss:  0.09946182  || Decoder Loss:  0.14179157 Validation Decoder Loss:  0.3367898
Encoder Loss:  0.06495078  || Decoder Loss:  0.07768733 Validation Decoder Loss:  0.3330392
Encoder Loss:  0.04524411  || Decoder Loss:  0.040948786 Validation Decoder Loss:  0.3381074
Encoder Loss:  0.059891697  || Decoder Loss:  0.06690933 Validation Decoder Loss:  0.33375263
Encoder Loss:  0.044305958  || Decoder Loss:  0.039236985 Validation Decoder Loss:  0.3347928
Encoder Loss:  0.04528233  || Decoder Loss:  0.04100602 Validation Decoder Loss:  0.3395943
Encoder Loss:  0.056872778  || Decoder Loss:  0.062548004 Validation Decoder Loss:  0.33666837
Encoder Loss:  0.04938751  || Decoder Loss:  0.04866871 Validation Decoder Loss:  0.33860546
Encoder Loss:  0.04480663  || Decoder Loss:  0.040147863 Validation Decoder Loss:  0.33867532
Encoder Loss:  0.05943433  || Decoder Loss:  0.06734445 Validation Decoder Loss:  0.33630514
Encoder Loss:  0.045131702  || Decoder Loss:  0.04080869 Validation Decoder Loss:  0.3325576
Encoder Loss:  0.058899987  || Decoder Loss:  0.06636861 Validation Decoder Loss:  0.337193
Encoder Loss:  0.050860472  || Decoder Loss:  0.05135083 Validation Decoder Loss:  0.33928826
Encoder Loss:  0.05459458  || Decoder Loss:  0.058532048 Validation Decoder Loss:  0.36833346
Encoder Loss:  0.08092594  || Decoder Loss:  0.10770658 Validation Decoder Loss:  0.33810747
Encoder Loss:  0.04826697  || Decoder Loss:  0.046659112 Validation Decoder Loss:  0.3353227
Encoder Loss:  0.04964381  || Decoder Loss:  0.04924154 Validation Decoder Loss:  0.32673544
Encoder Loss:  0.069576524  || Decoder Loss:  0.08574069 Validation Decoder Loss:  0.34162167
Encoder Loss:  0.045322467  || Decoder Loss:  0.041180868 Validation Decoder Loss:  0.33329096
Encoder Loss:  0.0489973  || Decoder Loss:  0.048000928 Validation Decoder Loss:  0.3462559
Encoder Loss:  0.047112633  || Decoder Loss:  0.044503164 Validation Decoder Loss:  0.34111232
Encoder Loss:  0.050057337  || Decoder Loss:  0.05000149 Validation Decoder Loss:  0.33663052
Encoder Loss:  0.045434326  || Decoder Loss:  0.041337375 Validation Decoder Loss:  0.4982788
Encoder Loss:  0.08141752  || Decoder Loss:  0.108561665 Validation Decoder Loss:  0.36150092
Encoder Loss:  0.04580308  || Decoder Loss:  0.042087056 Validation Decoder Loss:  0.34075212
Encoder Loss:  0.049428586  || Decoder Loss:  0.048814427 Validation Decoder Loss:  0.33577013
Encoder Loss:  0.045677114  || Decoder Loss:  0.041833386 Validation Decoder Loss:  0.33908924
Encoder Loss:  0.0456041  || Decoder Loss:  0.041708186 Validation Decoder Loss:  0.3356202
Encoder Loss:  0.04531487  || Decoder Loss:  0.041176945 Validation Decoder Loss:  0.3426882
Encoder Loss:  0.04692428  || Decoder Loss:  0.044149563 Validation Decoder Loss:  0.3401906
Encoder Loss:  0.05129456  || Decoder Loss:  0.05230447 Validation Decoder Loss:  0.34067357
Encoder Loss:  0.045552846  || Decoder Loss:  0.041614585 Validation Decoder Loss:  0.33838153
Encoder Loss:  0.064289525  || Decoder Loss:  0.07663193 Validation Decoder Loss:  0.33390456
Model: siamese_net_lr_0.3323753534382414 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33390456
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_222 (Conv3D (None, 235, 10, 20, 1)    219       
_________________________________________________________________
dropout_504 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_223 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_115 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 243
Trainable params: 243
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_506 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_508 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.068451576  || Decoder Loss:  0.06481067 Validation Decoder Loss:  0.32761347
Encoder Loss:  0.045350943  || Decoder Loss:  0.040557656 Validation Decoder Loss:  0.32479173
Encoder Loss:  0.043739308  || Decoder Loss:  0.037811417 Validation Decoder Loss:  0.32477173
Encoder Loss:  0.043480564  || Decoder Loss:  0.037329197 Validation Decoder Loss:  0.3253802
Encoder Loss:  0.043339826  || Decoder Loss:  0.037058063 Validation Decoder Loss:  0.3227644
Encoder Loss:  0.043347936  || Decoder Loss:  0.03707545 Validation Decoder Loss:  0.32572412
Encoder Loss:  0.043643747  || Decoder Loss:  0.037549496 Validation Decoder Loss:  0.3220944
Encoder Loss:  0.043334264  || Decoder Loss:  0.037041523 Validation Decoder Loss:  0.32604057
Encoder Loss:  0.09824561  || Decoder Loss:  0.10702526 Validation Decoder Loss:  1.0130346
Encoder Loss:  0.104394026  || Decoder Loss:  0.12889186 Validation Decoder Loss:  0.3317005
Encoder Loss:  0.047264744  || Decoder Loss:  0.03669018 Validation Decoder Loss:  0.3282496
Encoder Loss:  0.04625084  || Decoder Loss:  0.03770968 Validation Decoder Loss:  0.33538306
Encoder Loss:  0.0457219  || Decoder Loss:  0.037908684 Validation Decoder Loss:  0.3311201
Encoder Loss:  0.04557604  || Decoder Loss:  0.037771057 Validation Decoder Loss:  0.33140853
Encoder Loss:  0.045466155  || Decoder Loss:  0.037981443 Validation Decoder Loss:  0.33477408
Encoder Loss:  0.044557076  || Decoder Loss:  0.037341982 Validation Decoder Loss:  0.33755916
Encoder Loss:  0.04326131  || Decoder Loss:  0.03675476 Validation Decoder Loss:  0.3347019
Encoder Loss:  0.043074265  || Decoder Loss:  0.036501497 Validation Decoder Loss:  0.33378464
Encoder Loss:  0.04295999  || Decoder Loss:  0.03630316 Validation Decoder Loss:  0.33308756
Encoder Loss:  0.042950287  || Decoder Loss:  0.03628847 Validation Decoder Loss:  0.33174735
Encoder Loss:  0.04289317  || Decoder Loss:  0.036182646 Validation Decoder Loss:  0.33099738
Encoder Loss:  0.042846154  || Decoder Loss:  0.036099374 Validation Decoder Loss:  0.330656
Encoder Loss:  0.042840656  || Decoder Loss:  0.03607494 Validation Decoder Loss:  0.3306856
Encoder Loss:  0.042791918  || Decoder Loss:  0.035996184 Validation Decoder Loss:  0.33001184
Encoder Loss:  0.042765245  || Decoder Loss:  0.035944816 Validation Decoder Loss:  0.3300447
Encoder Loss:  0.042745754  || Decoder Loss:  0.035905186 Validation Decoder Loss:  0.32974824
Encoder Loss:  0.04272628  || Decoder Loss:  0.035865627 Validation Decoder Loss:  0.32967466
Encoder Loss:  0.04270909  || Decoder Loss:  0.035837665 Validation Decoder Loss:  0.33006686
Encoder Loss:  0.042699367  || Decoder Loss:  0.03581791 Validation Decoder Loss:  0.32987452
Encoder Loss:  0.042710997  || Decoder Loss:  0.035796355 Validation Decoder Loss:  0.33000547
Encoder Loss:  0.042655565  || Decoder Loss:  0.035741888 Validation Decoder Loss:  0.32972318
Encoder Loss:  0.04271656  || Decoder Loss:  0.035806697 Validation Decoder Loss:  0.33083135
Encoder Loss:  0.04260809  || Decoder Loss:  0.03564722 Validation Decoder Loss:  0.3300475
Encoder Loss:  0.042607956  || Decoder Loss:  0.03566227 Validation Decoder Loss:  0.33043748
Encoder Loss:  0.05028817  || Decoder Loss:  0.049784325 Validation Decoder Loss:  0.33204252
Encoder Loss:  0.045023754  || Decoder Loss:  0.04033642 Validation Decoder Loss:  0.3298871
Encoder Loss:  0.04443428  || Decoder Loss:  0.039198056 Validation Decoder Loss:  0.33027515
Encoder Loss:  0.044330172  || Decoder Loss:  0.03899887 Validation Decoder Loss:  0.33042735
Encoder Loss:  0.0442516  || Decoder Loss:  0.03884996 Validation Decoder Loss:  0.33044323
Encoder Loss:  0.04405701  || Decoder Loss:  0.038477715 Validation Decoder Loss:  0.32975626
Model: siamese_net_lr_0.4922738268517409 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3297563
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_225 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_510 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_226 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_116 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_404"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_512 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_514 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2575182  || Decoder Loss:  0.42428222 Validation Decoder Loss:  0.97380424
Encoder Loss:  0.25349802  || Decoder Loss:  0.49352002 Validation Decoder Loss:  0.98112905
Encoder Loss:  0.2522805  || Decoder Loss:  0.49708307 Validation Decoder Loss:  1.0517383
Encoder Loss:  0.25356224  || Decoder Loss:  0.5076346 Validation Decoder Loss:  0.96448606
Encoder Loss:  0.25207606  || Decoder Loss:  0.49905327 Validation Decoder Loss:  0.91818786
Encoder Loss:  0.2519652  || Decoder Loss:  0.50020677 Validation Decoder Loss:  0.95594954
Encoder Loss:  0.24429095  || Decoder Loss:  0.4867733 Validation Decoder Loss:  0.8560746
Encoder Loss:  0.25166962  || Decoder Loss:  0.5082267 Validation Decoder Loss:  1.6043695
Encoder Loss:  0.25176883  || Decoder Loss:  0.5101124 Validation Decoder Loss:  1.6266035
Encoder Loss:  0.2586529  || Decoder Loss:  0.5225348 Validation Decoder Loss:  1.6101387
Encoder Loss:  0.27530015  || Decoder Loss:  0.56163126 Validation Decoder Loss:  1.6025684
Encoder Loss:  0.23610988  || Decoder Loss:  0.47017556 Validation Decoder Loss:  1.5528965
Encoder Loss:  0.22339189  || Decoder Loss:  0.4484501 Validation Decoder Loss:  0.3582704
Encoder Loss:  0.06481514  || Decoder Loss:  0.08256592 Validation Decoder Loss:  0.3310792
Encoder Loss:  0.043944433  || Decoder Loss:  0.03541844 Validation Decoder Loss:  0.3304243
Encoder Loss:  0.04404935  || Decoder Loss:  0.035270546 Validation Decoder Loss:  0.33083987
Encoder Loss:  0.04384913  || Decoder Loss:  0.035349656 Validation Decoder Loss:  0.33123603
Encoder Loss:  0.0439098  || Decoder Loss:  0.03541389 Validation Decoder Loss:  0.33094108
Encoder Loss:  0.04403325  || Decoder Loss:  0.035570506 Validation Decoder Loss:  0.3298373
Encoder Loss:  0.043940343  || Decoder Loss:  0.035463013 Validation Decoder Loss:  0.32867062
Encoder Loss:  0.044592377  || Decoder Loss:  0.036366504 Validation Decoder Loss:  0.3317169
Encoder Loss:  0.044025473  || Decoder Loss:  0.03555791 Validation Decoder Loss:  0.33063683
Encoder Loss:  0.04436506  || Decoder Loss:  0.035802864 Validation Decoder Loss:  0.32983494
Encoder Loss:  0.045337494  || Decoder Loss:  0.03847766 Validation Decoder Loss:  0.3280897
Encoder Loss:  0.049992558  || Decoder Loss:  0.04923111 Validation Decoder Loss:  0.3317982
Encoder Loss:  0.044156212  || Decoder Loss:  0.03563684 Validation Decoder Loss:  0.3313526
Encoder Loss:  0.044746634  || Decoder Loss:  0.036935445 Validation Decoder Loss:  0.33079883
Encoder Loss:  0.04793731  || Decoder Loss:  0.044245902 Validation Decoder Loss:  0.3298223
Encoder Loss:  0.055891853  || Decoder Loss:  0.06286748 Validation Decoder Loss:  0.3719883
Encoder Loss:  0.0444755  || Decoder Loss:  0.03646929 Validation Decoder Loss:  0.3312
Encoder Loss:  0.04627423  || Decoder Loss:  0.040166702 Validation Decoder Loss:  0.36654824
Encoder Loss:  0.05857639  || Decoder Loss:  0.06867325 Validation Decoder Loss:  0.32854286
Encoder Loss:  0.044450533  || Decoder Loss:  0.036313884 Validation Decoder Loss:  0.33111593
Encoder Loss:  0.044561315  || Decoder Loss:  0.036541115 Validation Decoder Loss:  0.3325393
Encoder Loss:  0.045669194  || Decoder Loss:  0.038779043 Validation Decoder Loss:  0.33860213
Encoder Loss:  0.045242116  || Decoder Loss:  0.038242593 Validation Decoder Loss:  0.33328876
Encoder Loss:  0.044741746  || Decoder Loss:  0.036977857 Validation Decoder Loss:  0.32787865
Encoder Loss:  0.049687553  || Decoder Loss:  0.04778434 Validation Decoder Loss:  0.3314646
Encoder Loss:  0.04674333  || Decoder Loss:  0.041306376 Validation Decoder Loss:  0.33260047
Encoder Loss:  0.04563293  || Decoder Loss:  0.038447194 Validation Decoder Loss:  0.3332995
Model: siamese_net_lr_0.43858710105421844 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33329952
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_228 (Conv3D (None, 236, 10, 20, 1)    347       
_________________________________________________________________
dropout_516 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_229 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_117 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_518 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_520 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.119103774  || Decoder Loss:  0.3272077 Validation Decoder Loss:  0.32813388
Encoder Loss:  0.053191412  || Decoder Loss:  0.05122273 Validation Decoder Loss:  0.3363596
Encoder Loss:  0.050283514  || Decoder Loss:  0.044325713 Validation Decoder Loss:  0.33631855
Encoder Loss:  0.052294955  || Decoder Loss:  0.051026214 Validation Decoder Loss:  0.33750635
Encoder Loss:  0.04976363  || Decoder Loss:  0.045029964 Validation Decoder Loss:  0.33363593
Encoder Loss:  0.05076126  || Decoder Loss:  0.046121377 Validation Decoder Loss:  0.3242901
Encoder Loss:  0.05041199  || Decoder Loss:  0.0468413 Validation Decoder Loss:  0.3460957
Encoder Loss:  0.048859287  || Decoder Loss:  0.043160688 Validation Decoder Loss:  0.3316944
Encoder Loss:  0.048352867  || Decoder Loss:  0.040335264 Validation Decoder Loss:  0.33056194
Encoder Loss:  0.048192877  || Decoder Loss:  0.039559387 Validation Decoder Loss:  0.33050776
Encoder Loss:  0.048272885  || Decoder Loss:  0.03996897 Validation Decoder Loss:  0.32741588
Encoder Loss:  0.047891773  || Decoder Loss:  0.03795461 Validation Decoder Loss:  0.33042496
Encoder Loss:  0.047995634  || Decoder Loss:  0.038579784 Validation Decoder Loss:  0.3418932
Encoder Loss:  0.059157748  || Decoder Loss:  0.081420854 Validation Decoder Loss:  0.32628417
Encoder Loss:  0.049529005  || Decoder Loss:  0.0448813 Validation Decoder Loss:  0.33241248
Encoder Loss:  0.04861479  || Decoder Loss:  0.041845173 Validation Decoder Loss:  0.33172208
Encoder Loss:  0.048459753  || Decoder Loss:  0.040977813 Validation Decoder Loss:  0.33094648
Encoder Loss:  0.04819794  || Decoder Loss:  0.03983665 Validation Decoder Loss:  0.33075404
Encoder Loss:  0.048068933  || Decoder Loss:  0.039113704 Validation Decoder Loss:  0.3309015
Encoder Loss:  0.048007168  || Decoder Loss:  0.03874953 Validation Decoder Loss:  0.33105156
Encoder Loss:  0.04795004  || Decoder Loss:  0.038459215 Validation Decoder Loss:  0.32947966
Encoder Loss:  0.047835182  || Decoder Loss:  0.038039118 Validation Decoder Loss:  0.33456832
Encoder Loss:  0.15839246  || Decoder Loss:  0.4599508 Validation Decoder Loss:  0.82423574
Encoder Loss:  0.12984604  || Decoder Loss:  0.4935878 Validation Decoder Loss:  1.1141953
Encoder Loss:  0.12897211  || Decoder Loss:  0.49058002 Validation Decoder Loss:  1.1287823
Encoder Loss:  0.12622581  || Decoder Loss:  0.4754658 Validation Decoder Loss:  0.82417494
Encoder Loss:  0.1248568  || Decoder Loss:  0.4678563 Validation Decoder Loss:  0.795487
Encoder Loss:  0.116092436  || Decoder Loss:  0.41895244 Validation Decoder Loss:  0.906523
Encoder Loss:  0.056535266  || Decoder Loss:  0.0864577 Validation Decoder Loss:  0.3413768
Encoder Loss:  0.049346652  || Decoder Loss:  0.046326105 Validation Decoder Loss:  0.32286024
Encoder Loss:  0.04888013  || Decoder Loss:  0.043725543 Validation Decoder Loss:  0.35328573
Encoder Loss:  0.048128787  || Decoder Loss:  0.039490297 Validation Decoder Loss:  0.3348184
Encoder Loss:  0.048865527  || Decoder Loss:  0.043634195 Validation Decoder Loss:  0.34031928
Encoder Loss:  0.048442677  || Decoder Loss:  0.04126496 Validation Decoder Loss:  0.34098238
Encoder Loss:  0.0481332  || Decoder Loss:  0.038784288 Validation Decoder Loss:  0.3314869
Encoder Loss:  0.048171196  || Decoder Loss:  0.03976323 Validation Decoder Loss:  0.33158487
Encoder Loss:  0.04815546  || Decoder Loss:  0.039676987 Validation Decoder Loss:  0.33168086
Encoder Loss:  0.048107103  || Decoder Loss:  0.03940157 Validation Decoder Loss:  0.3318891
Encoder Loss:  0.04806101  || Decoder Loss:  0.039147608 Validation Decoder Loss:  0.33202544
Encoder Loss:  0.048209816  || Decoder Loss:  0.039972726 Validation Decoder Loss:  0.326923
Model: siamese_net_lr_0.7298981158117119 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.326923
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_231 (Conv3D (None, 182, 5, 20, 1)     120       
_________________________________________________________________
dropout_522 (Dropout)        (None, 182, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_232 (Conv3D (None, 257, 10, 20, 1)    153       
_________________________________________________________________
reshape_118 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 273
Trainable params: 273
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_412"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_524 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_526 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31219915  || Decoder Loss:  0.5102501 Validation Decoder Loss:  1.0026551
Encoder Loss:  0.2973761  || Decoder Loss:  0.49852496 Validation Decoder Loss:  1.002683
Encoder Loss:  0.2955315  || Decoder Loss:  0.498514 Validation Decoder Loss:  1.00265
Encoder Loss:  0.29559383  || Decoder Loss:  0.4985376 Validation Decoder Loss:  1.0027176
Encoder Loss:  0.29618192  || Decoder Loss:  0.4985376 Validation Decoder Loss:  1.0028136
Encoder Loss:  0.29574844  || Decoder Loss:  0.49851954 Validation Decoder Loss:  1.0027443
Encoder Loss:  0.2964963  || Decoder Loss:  0.49843732 Validation Decoder Loss:  1.0030103
Encoder Loss:  0.2954999  || Decoder Loss:  0.49841645 Validation Decoder Loss:  1.00313
Encoder Loss:  0.2954861  || Decoder Loss:  0.49846187 Validation Decoder Loss:  1.0029488
Encoder Loss:  0.29559085  || Decoder Loss:  0.49850494 Validation Decoder Loss:  1.002895
Encoder Loss:  0.2958187  || Decoder Loss:  0.49850425 Validation Decoder Loss:  1.0033855
Encoder Loss:  0.2955926  || Decoder Loss:  0.49853396 Validation Decoder Loss:  1.0035489
Encoder Loss:  0.29615146  || Decoder Loss:  0.49856213 Validation Decoder Loss:  1.0026886
Encoder Loss:  0.29551727  || Decoder Loss:  0.4984725 Validation Decoder Loss:  1.0027093
Encoder Loss:  0.29573566  || Decoder Loss:  0.49851584 Validation Decoder Loss:  1.0025821
Encoder Loss:  0.29552764  || Decoder Loss:  0.49851924 Validation Decoder Loss:  1.0025773
Encoder Loss:  0.29565027  || Decoder Loss:  0.49855557 Validation Decoder Loss:  1.0024643
Encoder Loss:  0.29581428  || Decoder Loss:  0.4985962 Validation Decoder Loss:  1.00242
Encoder Loss:  0.29568794  || Decoder Loss:  0.4986379 Validation Decoder Loss:  1.0021806
Encoder Loss:  0.2956108  || Decoder Loss:  0.49870092 Validation Decoder Loss:  1.0021927
Encoder Loss:  0.29565385  || Decoder Loss:  0.49872026 Validation Decoder Loss:  1.0021441
Encoder Loss:  0.29720575  || Decoder Loss:  0.500824 Validation Decoder Loss:  0.9950592
Encoder Loss:  0.29706258  || Decoder Loss:  0.50133723 Validation Decoder Loss:  0.9975378
Encoder Loss:  0.29537728  || Decoder Loss:  0.4982651 Validation Decoder Loss:  0.98651874
Encoder Loss:  0.2924738  || Decoder Loss:  0.492982 Validation Decoder Loss:  1.0159123
Encoder Loss:  0.29587924  || Decoder Loss:  0.49919784 Validation Decoder Loss:  1.0331097
Encoder Loss:  0.2912283  || Decoder Loss:  0.49071002 Validation Decoder Loss:  1.1796491
Encoder Loss:  0.29603758  || Decoder Loss:  0.4994539 Validation Decoder Loss:  1.0370162
Encoder Loss:  0.2934522  || Decoder Loss:  0.4947733 Validation Decoder Loss:  1.1896007
Encoder Loss:  0.2896767  || Decoder Loss:  0.487893 Validation Decoder Loss:  1.003149
Encoder Loss:  0.29403362  || Decoder Loss:  0.4958533 Validation Decoder Loss:  0.9934869
Encoder Loss:  0.2955674  || Decoder Loss:  0.49863544 Validation Decoder Loss:  0.9930121
Encoder Loss:  0.29527438  || Decoder Loss:  0.49812058 Validation Decoder Loss:  0.99251485
Encoder Loss:  0.29412872  || Decoder Loss:  0.4960204 Validation Decoder Loss:  0.98204416
Encoder Loss:  0.090500295  || Decoder Loss:  0.12396727 Validation Decoder Loss:  0.33467525
Encoder Loss:  0.043271728  || Decoder Loss:  0.037646934 Validation Decoder Loss:  0.33038986
Encoder Loss:  0.042312816  || Decoder Loss:  0.035931695 Validation Decoder Loss:  0.3325212
Encoder Loss:  0.042175308  || Decoder Loss:  0.03568031 Validation Decoder Loss:  0.33165622
Encoder Loss:  0.04215923  || Decoder Loss:  0.0356553 Validation Decoder Loss:  0.33132982
Encoder Loss:  0.042749647  || Decoder Loss:  0.036678866 Validation Decoder Loss:  0.33090472
Model: siamese_net_lr_0.31323661056011853 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33090472
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_234 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_528 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_235 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_119 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_416"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_530 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_532 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.048805844  || Decoder Loss:  0.048805844 Validation Decoder Loss:  0.34432
Encoder Loss:  0.046905257  || Decoder Loss:  0.046905257 Validation Decoder Loss:  0.3320317
Encoder Loss:  0.034620155  || Decoder Loss:  0.034620155 Validation Decoder Loss:  0.33221844
Encoder Loss:  0.034585975  || Decoder Loss:  0.034585975 Validation Decoder Loss:  0.33207864
Encoder Loss:  0.03455352  || Decoder Loss:  0.03455352 Validation Decoder Loss:  0.33184093
Encoder Loss:  0.03451492  || Decoder Loss:  0.03451492 Validation Decoder Loss:  0.3318179
Encoder Loss:  0.034471717  || Decoder Loss:  0.034471717 Validation Decoder Loss:  0.3315093
Encoder Loss:  0.0344329  || Decoder Loss:  0.0344329 Validation Decoder Loss:  0.3316864
Encoder Loss:  0.034411017  || Decoder Loss:  0.034411017 Validation Decoder Loss:  0.3315557
Encoder Loss:  0.037344277  || Decoder Loss:  0.037344277 Validation Decoder Loss:  0.3445403
Encoder Loss:  0.03959407  || Decoder Loss:  0.03959407 Validation Decoder Loss:  0.34435934
Encoder Loss:  0.039395723  || Decoder Loss:  0.039395723 Validation Decoder Loss:  0.3439304
Encoder Loss:  0.039107174  || Decoder Loss:  0.039107174 Validation Decoder Loss:  0.34300053
Encoder Loss:  0.038356226  || Decoder Loss:  0.038356226 Validation Decoder Loss:  0.3384413
Encoder Loss:  0.03470193  || Decoder Loss:  0.03470193 Validation Decoder Loss:  0.33150595
Encoder Loss:  0.03445963  || Decoder Loss:  0.03445963 Validation Decoder Loss:  0.3315373
Encoder Loss:  0.034452703  || Decoder Loss:  0.034452703 Validation Decoder Loss:  0.3315925
Encoder Loss:  0.034445062  || Decoder Loss:  0.034445062 Validation Decoder Loss:  0.33164388
Encoder Loss:  0.03443621  || Decoder Loss:  0.03443621 Validation Decoder Loss:  0.33169878
Encoder Loss:  0.034424867  || Decoder Loss:  0.034424867 Validation Decoder Loss:  0.3316791
Encoder Loss:  0.034414176  || Decoder Loss:  0.034414176 Validation Decoder Loss:  0.33166003
Encoder Loss:  0.034397602  || Decoder Loss:  0.034397602 Validation Decoder Loss:  0.3316285
Encoder Loss:  0.034383405  || Decoder Loss:  0.034383405 Validation Decoder Loss:  0.3315386
Encoder Loss:  0.03437414  || Decoder Loss:  0.03437414 Validation Decoder Loss:  0.33148354
Encoder Loss:  0.03436114  || Decoder Loss:  0.03436114 Validation Decoder Loss:  0.33136457
Encoder Loss:  0.034347992  || Decoder Loss:  0.034347992 Validation Decoder Loss:  0.3311834
Encoder Loss:  0.034331214  || Decoder Loss:  0.034331214 Validation Decoder Loss:  0.33099395
Encoder Loss:  0.034307353  || Decoder Loss:  0.034307353 Validation Decoder Loss:  0.33068717
Encoder Loss:  0.03427688  || Decoder Loss:  0.03427688 Validation Decoder Loss:  0.3305145
Encoder Loss:  0.03423476  || Decoder Loss:  0.03423476 Validation Decoder Loss:  0.32986414
Encoder Loss:  0.034183964  || Decoder Loss:  0.034183964 Validation Decoder Loss:  0.33061624
Encoder Loss:  0.034139775  || Decoder Loss:  0.034139775 Validation Decoder Loss:  0.33083016
Encoder Loss:  0.0341141  || Decoder Loss:  0.0341141 Validation Decoder Loss:  0.33091927
Encoder Loss:  0.03409454  || Decoder Loss:  0.03409454 Validation Decoder Loss:  0.33110708
Encoder Loss:  0.034080554  || Decoder Loss:  0.034080554 Validation Decoder Loss:  0.3312617
Encoder Loss:  0.034071058  || Decoder Loss:  0.034071058 Validation Decoder Loss:  0.33128792
Encoder Loss:  0.034060165  || Decoder Loss:  0.034060165 Validation Decoder Loss:  0.3313018
Encoder Loss:  0.03404976  || Decoder Loss:  0.03404976 Validation Decoder Loss:  0.33131504
Encoder Loss:  0.03404052  || Decoder Loss:  0.03404052 Validation Decoder Loss:  0.33132204
Encoder Loss:  0.034032825  || Decoder Loss:  0.034032825 Validation Decoder Loss:  0.33133477
Model: siamese_net_lr_0.29860839706013037 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33133477
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_237 (Conv3D (None, 199, 10, 20, 1)    817       
_________________________________________________________________
dropout_534 (Dropout)        (None, 199, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_238 (Conv3D (None, 257, 10, 20, 1)    60        
_________________________________________________________________
reshape_120 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 877
Trainable params: 877
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_536 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_538 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35301524  || Decoder Loss:  0.48923847 Validation Decoder Loss:  1.1121641
Encoder Loss:  0.35008064  || Decoder Loss:  0.48825982 Validation Decoder Loss:  1.0929017
Encoder Loss:  0.35469663  || Decoder Loss:  0.49545753 Validation Decoder Loss:  1.0863233
Encoder Loss:  0.3543344  || Decoder Loss:  0.49486914 Validation Decoder Loss:  1.0809402
Encoder Loss:  0.35275033  || Decoder Loss:  0.4927153 Validation Decoder Loss:  1.1046712
Encoder Loss:  0.35018244  || Decoder Loss:  0.48886788 Validation Decoder Loss:  1.1125699
Encoder Loss:  0.34923375  || Decoder Loss:  0.48704156 Validation Decoder Loss:  0.9082811
Encoder Loss:  0.3568307  || Decoder Loss:  0.49869493 Validation Decoder Loss:  0.9149692
Encoder Loss:  0.35659733  || Decoder Loss:  0.49833503 Validation Decoder Loss:  0.91635394
Encoder Loss:  0.3564919  || Decoder Loss:  0.4982399 Validation Decoder Loss:  0.9124353
Encoder Loss:  0.35633293  || Decoder Loss:  0.49802434 Validation Decoder Loss:  0.9290874
Encoder Loss:  0.3562845  || Decoder Loss:  0.4977022 Validation Decoder Loss:  0.9242947
Encoder Loss:  0.35638145  || Decoder Loss:  0.4979015 Validation Decoder Loss:  0.92115754
Encoder Loss:  0.35618737  || Decoder Loss:  0.49778107 Validation Decoder Loss:  0.9379822
Encoder Loss:  0.3556968  || Decoder Loss:  0.49706474 Validation Decoder Loss:  0.9802376
Encoder Loss:  0.35225198  || Decoder Loss:  0.49196348 Validation Decoder Loss:  1.014466
Encoder Loss:  0.35112774  || Decoder Loss:  0.49041677 Validation Decoder Loss:  1.0521454
Encoder Loss:  0.35032737  || Decoder Loss:  0.48922238 Validation Decoder Loss:  1.003747
Encoder Loss:  0.3521892  || Decoder Loss:  0.49194843 Validation Decoder Loss:  0.9515947
Encoder Loss:  0.3520787  || Decoder Loss:  0.49178535 Validation Decoder Loss:  0.95236975
Encoder Loss:  0.35123038  || Decoder Loss:  0.4905356 Validation Decoder Loss:  1.0715284
Encoder Loss:  0.3509302  || Decoder Loss:  0.490022 Validation Decoder Loss:  1.0688863
Encoder Loss:  0.3504964  || Decoder Loss:  0.48940614 Validation Decoder Loss:  0.9478178
Encoder Loss:  0.35165164  || Decoder Loss:  0.49112874 Validation Decoder Loss:  1.0004964
Encoder Loss:  0.34997213  || Decoder Loss:  0.48864675 Validation Decoder Loss:  1.002855
Encoder Loss:  0.35084477  || Decoder Loss:  0.48990074 Validation Decoder Loss:  1.0421548
Encoder Loss:  0.3522566  || Decoder Loss:  0.49194205 Validation Decoder Loss:  1.0396159
Encoder Loss:  0.3488475  || Decoder Loss:  0.48699355 Validation Decoder Loss:  0.99650246
Encoder Loss:  0.34769908  || Decoder Loss:  0.48536366 Validation Decoder Loss:  1.0349822
Encoder Loss:  0.34658626  || Decoder Loss:  0.48377967 Validation Decoder Loss:  0.968061
Encoder Loss:  0.34382713  || Decoder Loss:  0.47967356 Validation Decoder Loss:  0.95585084
Encoder Loss:  0.3483151  || Decoder Loss:  0.48621532 Validation Decoder Loss:  0.96511626
Encoder Loss:  0.34826982  || Decoder Loss:  0.48611927 Validation Decoder Loss:  1.0265474
Encoder Loss:  0.34222373  || Decoder Loss:  0.47739166 Validation Decoder Loss:  1.0317891
Encoder Loss:  0.33503094  || Decoder Loss:  0.46686623 Validation Decoder Loss:  0.9661928
Encoder Loss:  0.33759135  || Decoder Loss:  0.47050998 Validation Decoder Loss:  0.99823564
Encoder Loss:  0.32460776  || Decoder Loss:  0.45142382 Validation Decoder Loss:  0.995076
Encoder Loss:  0.32038116  || Decoder Loss:  0.4454385 Validation Decoder Loss:  0.9956492
Encoder Loss:  0.3206813  || Decoder Loss:  0.44587517 Validation Decoder Loss:  0.99545664
Encoder Loss:  0.32039115  || Decoder Loss:  0.44543597 Validation Decoder Loss:  0.99360317
Model: siamese_net_lr_0.619437470419973 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9936032
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_240 (Conv3D (None, 218, 10, 20, 1)    59        
_________________________________________________________________
dropout_540 (Dropout)        (None, 218, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_241 (Conv3D (None, 257, 10, 20, 1)    41        
_________________________________________________________________
reshape_121 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 100
Trainable params: 100
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_542 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_544 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3790815  || Decoder Loss:  0.11933074 Validation Decoder Loss:  0.35046285
Encoder Loss:  0.41303912  || Decoder Loss:  0.058818653 Validation Decoder Loss:  0.35013458
Encoder Loss:  0.39020145  || Decoder Loss:  0.08648064 Validation Decoder Loss:  1.5784727
Encoder Loss:  0.15522298  || Decoder Loss:  0.5209694 Validation Decoder Loss:  1.4539957
Encoder Loss:  0.15087599  || Decoder Loss:  0.48628914 Validation Decoder Loss:  1.1693193
Encoder Loss:  0.10714324  || Decoder Loss:  0.49389634 Validation Decoder Loss:  1.1446422
Encoder Loss:  0.07061191  || Decoder Loss:  0.50663733 Validation Decoder Loss:  1.0347102
Encoder Loss:  0.061264817  || Decoder Loss:  0.4979993 Validation Decoder Loss:  1.0216503
Encoder Loss:  0.058922015  || Decoder Loss:  0.4956059 Validation Decoder Loss:  1.0180941
Encoder Loss:  0.05822779  || Decoder Loss:  0.49367675 Validation Decoder Loss:  1.0087245
Encoder Loss:  0.058224373  || Decoder Loss:  0.49124706 Validation Decoder Loss:  0.99002296
Encoder Loss:  0.058149263  || Decoder Loss:  0.48983964 Validation Decoder Loss:  1.0002699
Encoder Loss:  0.058188733  || Decoder Loss:  0.4893845 Validation Decoder Loss:  1.0013092
Encoder Loss:  0.05838692  || Decoder Loss:  0.48833954 Validation Decoder Loss:  1.0113358
Encoder Loss:  0.058204547  || Decoder Loss:  0.49291635 Validation Decoder Loss:  1.0178034
Encoder Loss:  0.05818113  || Decoder Loss:  0.4983634 Validation Decoder Loss:  1.0248957
Encoder Loss:  0.058454264  || Decoder Loss:  0.4979808 Validation Decoder Loss:  1.0249631
Encoder Loss:  0.058170337  || Decoder Loss:  0.49535385 Validation Decoder Loss:  1.0157092
Encoder Loss:  0.05825022  || Decoder Loss:  0.49166825 Validation Decoder Loss:  1.0052993
Encoder Loss:  0.05797068  || Decoder Loss:  0.4911468 Validation Decoder Loss:  1.0006773
Encoder Loss:  0.058231503  || Decoder Loss:  0.4911013 Validation Decoder Loss:  1.0061074
Encoder Loss:  0.057933025  || Decoder Loss:  0.49110436 Validation Decoder Loss:  1.00349
Encoder Loss:  0.057889927  || Decoder Loss:  0.49059105 Validation Decoder Loss:  1.0053104
Encoder Loss:  0.058740962  || Decoder Loss:  0.4910255 Validation Decoder Loss:  0.99100167
Encoder Loss:  0.058239702  || Decoder Loss:  0.4913242 Validation Decoder Loss:  1.0053971
Encoder Loss:  0.058186326  || Decoder Loss:  0.49075833 Validation Decoder Loss:  1.007067
Encoder Loss:  0.058571454  || Decoder Loss:  0.4906041 Validation Decoder Loss:  1.003506
Encoder Loss:  0.058098555  || Decoder Loss:  0.48730764 Validation Decoder Loss:  0.9589436
Encoder Loss:  0.057674676  || Decoder Loss:  0.47334784 Validation Decoder Loss:  0.9695366
Encoder Loss:  0.058500763  || Decoder Loss:  0.4979375 Validation Decoder Loss:  0.9673269
Encoder Loss:  0.05812207  || Decoder Loss:  0.49760765 Validation Decoder Loss:  0.9628486
Encoder Loss:  0.059025064  || Decoder Loss:  0.497192 Validation Decoder Loss:  0.9764479
Encoder Loss:  0.058034603  || Decoder Loss:  0.49584025 Validation Decoder Loss:  0.9700635
Encoder Loss:  0.057897564  || Decoder Loss:  0.48424652 Validation Decoder Loss:  0.9822719
Encoder Loss:  0.05845748  || Decoder Loss:  0.49886516 Validation Decoder Loss:  0.98263264
Encoder Loss:  0.058023497  || Decoder Loss:  0.4992075 Validation Decoder Loss:  0.96817726
Encoder Loss:  0.059032146  || Decoder Loss:  0.49953336 Validation Decoder Loss:  0.98791826
Encoder Loss:  0.058813773  || Decoder Loss:  0.49898362 Validation Decoder Loss:  0.98048264
Encoder Loss:  0.057988066  || Decoder Loss:  0.49925274 Validation Decoder Loss:  0.97130203
Encoder Loss:  0.058405872  || Decoder Loss:  0.49926338 Validation Decoder Loss:  0.96397674
Model: siamese_net_lr_0.9307290070463631 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.96397674
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_243 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_546 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_244 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_122 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_428"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_548 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_550 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4097205  || Decoder Loss:  0.42254457 Validation Decoder Loss:  0.44175065
Encoder Loss:  0.0653433  || Decoder Loss:  0.065894626 Validation Decoder Loss:  0.3338406
Encoder Loss:  0.036032584  || Decoder Loss:  0.03553045 Validation Decoder Loss:  0.33342558
Encoder Loss:  0.035988633  || Decoder Loss:  0.03548495 Validation Decoder Loss:  0.33265167
Encoder Loss:  0.03587329  || Decoder Loss:  0.035365425 Validation Decoder Loss:  0.33239
Encoder Loss:  0.035910577  || Decoder Loss:  0.035404023 Validation Decoder Loss:  0.33197886
Encoder Loss:  0.097100236  || Decoder Loss:  0.09880745 Validation Decoder Loss:  1.604867
Encoder Loss:  0.51102436  || Decoder Loss:  0.52674127 Validation Decoder Loss:  0.99640286
Encoder Loss:  0.48680642  || Decoder Loss:  0.50248605 Validation Decoder Loss:  0.9962691
Encoder Loss:  0.4866359  || Decoder Loss:  0.50230426 Validation Decoder Loss:  0.99480176
Encoder Loss:  0.40942723  || Decoder Loss:  0.42232877 Validation Decoder Loss:  0.36839902
Encoder Loss:  0.07291936  || Decoder Loss:  0.0737152 Validation Decoder Loss:  0.3326998
Encoder Loss:  0.039310023  || Decoder Loss:  0.038901765 Validation Decoder Loss:  0.36162663
Encoder Loss:  0.043018866  || Decoder Loss:  0.042747494 Validation Decoder Loss:  0.33001363
Encoder Loss:  0.04387095  || Decoder Loss:  0.043631773 Validation Decoder Loss:  0.3080842
Encoder Loss:  0.06562132  || Decoder Loss:  0.0661603 Validation Decoder Loss:  0.34016553
Encoder Loss:  0.036727834  || Decoder Loss:  0.036227647 Validation Decoder Loss:  0.326226
Encoder Loss:  0.039230015  || Decoder Loss:  0.038829688 Validation Decoder Loss:  0.31954992
Encoder Loss:  0.03680558  || Decoder Loss:  0.036315307 Validation Decoder Loss:  0.33602846
Encoder Loss:  0.042850994  || Decoder Loss:  0.042587575 Validation Decoder Loss:  0.3305312
Encoder Loss:  0.03833652  || Decoder Loss:  0.037916247 Validation Decoder Loss:  0.33427465
Encoder Loss:  0.036214113  || Decoder Loss:  0.035717506 Validation Decoder Loss:  0.33392838
Encoder Loss:  0.036056325  || Decoder Loss:  0.03555306 Validation Decoder Loss:  0.32998544
Encoder Loss:  0.036016062  || Decoder Loss:  0.035512947 Validation Decoder Loss:  0.3323954
Encoder Loss:  0.03595501  || Decoder Loss:  0.035449833 Validation Decoder Loss:  0.33088243
Encoder Loss:  0.24537282  || Decoder Loss:  0.25239474 Validation Decoder Loss:  0.98702884
Encoder Loss:  0.091831036  || Decoder Loss:  0.093333855 Validation Decoder Loss:  0.33048654
Encoder Loss:  0.036016054  || Decoder Loss:  0.03551322 Validation Decoder Loss:  0.33069763
Encoder Loss:  0.036078215  || Decoder Loss:  0.03557754 Validation Decoder Loss:  0.3305246
Encoder Loss:  0.036141347  || Decoder Loss:  0.035643175 Validation Decoder Loss:  0.32964903
Encoder Loss:  0.03615106  || Decoder Loss:  0.03565321 Validation Decoder Loss:  0.32983536
Encoder Loss:  0.036183264  || Decoder Loss:  0.035686556 Validation Decoder Loss:  0.33107492
Encoder Loss:  0.03621023  || Decoder Loss:  0.035714503 Validation Decoder Loss:  0.3311356
Encoder Loss:  0.036176488  || Decoder Loss:  0.035679556 Validation Decoder Loss:  0.33123222
Encoder Loss:  0.0360651  || Decoder Loss:  0.035564095 Validation Decoder Loss:  0.33132094
Encoder Loss:  0.19797605  || Decoder Loss:  0.20329453 Validation Decoder Loss:  0.9997257
Encoder Loss:  0.48042107  || Decoder Loss:  0.49589077 Validation Decoder Loss:  0.997363
Encoder Loss:  0.25098172  || Decoder Loss:  0.25820518 Validation Decoder Loss:  0.33114725
Encoder Loss:  0.036068663  || Decoder Loss:  0.035567872 Validation Decoder Loss:  0.33164105
Encoder Loss:  0.03607539  || Decoder Loss:  0.035574887 Validation Decoder Loss:  0.33164728
Model: siamese_net_lr_0.38446260373663643 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33164728
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_246 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_552 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_247 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_123 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 87
Trainable params: 87
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_554 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_556 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42866626  || Decoder Loss:  0.49374458 Validation Decoder Loss:  1.0006009
Encoder Loss:  0.4333978  || Decoder Loss:  0.49943858 Validation Decoder Loss:  1.0006185
Encoder Loss:  0.43335706  || Decoder Loss:  0.49939147 Validation Decoder Loss:  1.0007181
Encoder Loss:  0.43315202  || Decoder Loss:  0.49915066 Validation Decoder Loss:  0.99269176
Encoder Loss:  0.43431157  || Decoder Loss:  0.4992572 Validation Decoder Loss:  1.0008738
Encoder Loss:  0.43336704  || Decoder Loss:  0.4994025 Validation Decoder Loss:  1.000696
Encoder Loss:  0.4333413  || Decoder Loss:  0.49937332 Validation Decoder Loss:  1.0006511
Encoder Loss:  0.43335244  || Decoder Loss:  0.49938664 Validation Decoder Loss:  1.0006402
Encoder Loss:  0.433432  || Decoder Loss:  0.4994796 Validation Decoder Loss:  1.0006319
Encoder Loss:  0.43333355  || Decoder Loss:  0.4993645 Validation Decoder Loss:  1.0005369
Encoder Loss:  0.43329728  || Decoder Loss:  0.49932116 Validation Decoder Loss:  1.0003766
Encoder Loss:  0.42027  || Decoder Loss:  0.4840442 Validation Decoder Loss:  0.992957
Encoder Loss:  0.4340953  || Decoder Loss:  0.50025636 Validation Decoder Loss:  0.99870956
Encoder Loss:  0.4336322  || Decoder Loss:  0.49971375 Validation Decoder Loss:  0.99852216
Encoder Loss:  0.43006194  || Decoder Loss:  0.4955293 Validation Decoder Loss:  1.0142796
Encoder Loss:  0.17229691  || Decoder Loss:  0.19336237 Validation Decoder Loss:  0.33201975
Encoder Loss:  0.07209996  || Decoder Loss:  0.07590012 Validation Decoder Loss:  0.33017996
Encoder Loss:  0.03749305  || Decoder Loss:  0.035338387 Validation Decoder Loss:  0.33452445
Encoder Loss:  0.037462912  || Decoder Loss:  0.035302926 Validation Decoder Loss:  0.33367127
Encoder Loss:  0.03744852  || Decoder Loss:  0.035285965 Validation Decoder Loss:  0.33377713
Encoder Loss:  0.13757756  || Decoder Loss:  0.15265796 Validation Decoder Loss:  0.3338658
Encoder Loss:  0.0374266  || Decoder Loss:  0.035260424 Validation Decoder Loss:  0.32900167
Encoder Loss:  0.037484054  || Decoder Loss:  0.03532765 Validation Decoder Loss:  0.3394923
Encoder Loss:  0.038279437  || Decoder Loss:  0.0362599 Validation Decoder Loss:  0.33101922
Encoder Loss:  0.43133944  || Decoder Loss:  0.49514118 Validation Decoder Loss:  1.0553572
Encoder Loss:  0.43621227  || Decoder Loss:  0.50207996 Validation Decoder Loss:  1.0363228
Encoder Loss:  0.4361965  || Decoder Loss:  0.5024415 Validation Decoder Loss:  0.9988829
Encoder Loss:  0.43441483  || Decoder Loss:  0.5006246 Validation Decoder Loss:  0.9996066
Encoder Loss:  0.43427247  || Decoder Loss:  0.5004647 Validation Decoder Loss:  1.0001787
Encoder Loss:  0.43431103  || Decoder Loss:  0.50050086 Validation Decoder Loss:  0.997578
Encoder Loss:  0.43418103  || Decoder Loss:  0.5003257 Validation Decoder Loss:  1.0002553
Encoder Loss:  0.43312445  || Decoder Loss:  0.49911755 Validation Decoder Loss:  0.48564938
Encoder Loss:  0.42745736  || Decoder Loss:  0.4924732 Validation Decoder Loss:  0.99968106
Encoder Loss:  0.43307889  || Decoder Loss:  0.49906623 Validation Decoder Loss:  1.0003033
Encoder Loss:  0.43302  || Decoder Loss:  0.49899718 Validation Decoder Loss:  1.0003338
Encoder Loss:  0.43394434  || Decoder Loss:  0.5000799 Validation Decoder Loss:  0.9996841
Encoder Loss:  0.434392  || Decoder Loss:  0.5006044 Validation Decoder Loss:  0.9998467
Encoder Loss:  0.43418297  || Decoder Loss:  0.5003599 Validation Decoder Loss:  0.9993128
Encoder Loss:  0.4294969  || Decoder Loss:  0.49486613 Validation Decoder Loss:  0.9905257
Encoder Loss:  0.43363371  || Decoder Loss:  0.49971563 Validation Decoder Loss:  0.99776614
Model: siamese_net_lr_0.5438452184833341 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99776614
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_249 (Conv3D (None, 163, 10, 20, 1)    201       
_________________________________________________________________
dropout_558 (Dropout)        (None, 163, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_250 (Conv3D (None, 257, 10, 20, 1)    96        
_________________________________________________________________
reshape_124 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 297
Trainable params: 297
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_560 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_562 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23610397  || Decoder Loss:  0.50728106 Validation Decoder Loss:  1.040595
Encoder Loss:  0.22784767  || Decoder Loss:  0.49812728 Validation Decoder Loss:  1.0603161
Encoder Loss:  0.22724913  || Decoder Loss:  0.49874792 Validation Decoder Loss:  1.04628
Encoder Loss:  0.22883312  || Decoder Loss:  0.50173795 Validation Decoder Loss:  0.9894304
Encoder Loss:  0.22776884  || Decoder Loss:  0.49993268 Validation Decoder Loss:  0.9835321
Encoder Loss:  0.22732748  || Decoder Loss:  0.49959525 Validation Decoder Loss:  0.9766489
Encoder Loss:  0.22656767  || Decoder Loss:  0.4967657 Validation Decoder Loss:  1.0190514
Encoder Loss:  0.22704883  || Decoder Loss:  0.498411 Validation Decoder Loss:  1.0222319
Encoder Loss:  0.22503316  || Decoder Loss:  0.49397168 Validation Decoder Loss:  1.0594735
Encoder Loss:  0.22333954  || Decoder Loss:  0.49024373 Validation Decoder Loss:  1.0403363
Encoder Loss:  0.22291408  || Decoder Loss:  0.48983735 Validation Decoder Loss:  1.0451788
Encoder Loss:  0.22288379  || Decoder Loss:  0.4898238 Validation Decoder Loss:  1.0452329
Encoder Loss:  0.22294629  || Decoder Loss:  0.48999435 Validation Decoder Loss:  1.0082716
Encoder Loss:  0.22304945  || Decoder Loss:  0.49026105 Validation Decoder Loss:  1.0393362
Encoder Loss:  0.2228547  || Decoder Loss:  0.4897697 Validation Decoder Loss:  1.0388281
Encoder Loss:  0.22282742  || Decoder Loss:  0.48969877 Validation Decoder Loss:  1.0365721
Encoder Loss:  0.22276203  || Decoder Loss:  0.48953488 Validation Decoder Loss:  0.9949366
Encoder Loss:  0.22270072  || Decoder Loss:  0.48938122 Validation Decoder Loss:  1.0071535
Encoder Loss:  0.22254127  || Decoder Loss:  0.48889214 Validation Decoder Loss:  1.0122977
Encoder Loss:  0.22192451  || Decoder Loss:  0.48740834 Validation Decoder Loss:  1.042014
Encoder Loss:  0.22165784  || Decoder Loss:  0.48673093 Validation Decoder Loss:  1.0268667
Encoder Loss:  0.22140525  || Decoder Loss:  0.48608765 Validation Decoder Loss:  1.0216475
Encoder Loss:  0.22109188  || Decoder Loss:  0.4852905 Validation Decoder Loss:  1.0364621
Encoder Loss:  0.21843255  || Decoder Loss:  0.47812533 Validation Decoder Loss:  1.0609317
Encoder Loss:  0.22098063  || Decoder Loss:  0.48500794 Validation Decoder Loss:  1.071614
Encoder Loss:  0.21944082  || Decoder Loss:  0.4810895 Validation Decoder Loss:  0.85891247
Encoder Loss:  0.22663446  || Decoder Loss:  0.4993918 Validation Decoder Loss:  1.1234267
Encoder Loss:  0.22472599  || Decoder Loss:  0.49453452 Validation Decoder Loss:  1.1109657
Encoder Loss:  0.22221987  || Decoder Loss:  0.48815796 Validation Decoder Loss:  0.92749643
Encoder Loss:  0.22433273  || Decoder Loss:  0.49353448 Validation Decoder Loss:  1.0437963
Encoder Loss:  0.22573452  || Decoder Loss:  0.4970853 Validation Decoder Loss:  0.9128625
Encoder Loss:  0.22602701  || Decoder Loss:  0.49784514 Validation Decoder Loss:  0.9648588
Encoder Loss:  0.2257051  || Decoder Loss:  0.49702778 Validation Decoder Loss:  0.997627
Encoder Loss:  0.22523376  || Decoder Loss:  0.49582916 Validation Decoder Loss:  1.0185752
Encoder Loss:  0.22646707  || Decoder Loss:  0.4989668 Validation Decoder Loss:  1.0276964
Encoder Loss:  0.2255913  || Decoder Loss:  0.49547997 Validation Decoder Loss:  1.0616035
Encoder Loss:  0.22509281  || Decoder Loss:  0.49547115 Validation Decoder Loss:  0.9406293
Encoder Loss:  0.22426708  || Decoder Loss:  0.49337015 Validation Decoder Loss:  1.0489035
Encoder Loss:  0.22477485  || Decoder Loss:  0.49463764 Validation Decoder Loss:  0.9973229
Encoder Loss:  0.22404815  || Decoder Loss:  0.4928127 Validation Decoder Loss:  1.0357243
Model: siamese_net_lr_0.2856367295517955 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0357242
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_252 (Conv3D (None, 105, 6, 20, 1)     85        
_________________________________________________________________
dropout_564 (Dropout)        (None, 105, 6, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_253 (Conv3D (None, 257, 10, 20, 1)    766       
_________________________________________________________________
reshape_125 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 851
Trainable params: 851
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_566 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_568 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18311274  || Decoder Loss:  0.44705608 Validation Decoder Loss:  0.7373334
Encoder Loss:  0.14141235  || Decoder Loss:  0.4927895 Validation Decoder Loss:  0.8487354
Encoder Loss:  0.14326827  || Decoder Loss:  0.5097172 Validation Decoder Loss:  0.83317983
Encoder Loss:  0.1413846  || Decoder Loss:  0.50200915 Validation Decoder Loss:  0.8305854
Encoder Loss:  0.14093645  || Decoder Loss:  0.500078 Validation Decoder Loss:  0.82811195
Encoder Loss:  0.14061521  || Decoder Loss:  0.49855432 Validation Decoder Loss:  0.82720625
Encoder Loss:  0.1403072  || Decoder Loss:  0.49705014 Validation Decoder Loss:  0.8256737
Encoder Loss:  0.13989557  || Decoder Loss:  0.4945853 Validation Decoder Loss:  0.82197475
Encoder Loss:  0.13917516  || Decoder Loss:  0.4912363 Validation Decoder Loss:  0.8185028
Encoder Loss:  0.13856243  || Decoder Loss:  0.48826692 Validation Decoder Loss:  0.815503
Encoder Loss:  0.13790034  || Decoder Loss:  0.48499978 Validation Decoder Loss:  0.8117537
Encoder Loss:  0.137415  || Decoder Loss:  0.48239982 Validation Decoder Loss:  0.8089583
Encoder Loss:  0.13683845  || Decoder Loss:  0.47884 Validation Decoder Loss:  0.8043915
Encoder Loss:  0.13581055  || Decoder Loss:  0.4736701 Validation Decoder Loss:  0.7950452
Encoder Loss:  0.1343319  || Decoder Loss:  0.4670845 Validation Decoder Loss:  0.7860042
Encoder Loss:  0.13344736  || Decoder Loss:  0.462936 Validation Decoder Loss:  0.78043914
Encoder Loss:  0.13280009  || Decoder Loss:  0.45899934 Validation Decoder Loss:  0.77156967
Encoder Loss:  0.13129444  || Decoder Loss:  0.4515757 Validation Decoder Loss:  0.760242
Encoder Loss:  0.12953061  || Decoder Loss:  0.44314086 Validation Decoder Loss:  0.74886394
Encoder Loss:  0.12831227  || Decoder Loss:  0.4374165 Validation Decoder Loss:  0.7421514
Encoder Loss:  0.12735906  || Decoder Loss:  0.43270504 Validation Decoder Loss:  0.73552835
Encoder Loss:  0.12644866  || Decoder Loss:  0.42828292 Validation Decoder Loss:  0.72989357
Encoder Loss:  0.12573305  || Decoder Loss:  0.42471316 Validation Decoder Loss:  0.72520065
Encoder Loss:  0.12500338  || Decoder Loss:  0.4211254 Validation Decoder Loss:  0.72044855
Encoder Loss:  0.12425417  || Decoder Loss:  0.41677895 Validation Decoder Loss:  0.71226597
Encoder Loss:  0.1226021  || Decoder Loss:  0.4088917 Validation Decoder Loss:  0.7023435
Encoder Loss:  0.12142594  || Decoder Loss:  0.40336013 Validation Decoder Loss:  0.6967982
Encoder Loss:  0.120571174  || Decoder Loss:  0.39919612 Validation Decoder Loss:  0.6914549
Encoder Loss:  0.11983449  || Decoder Loss:  0.39564118 Validation Decoder Loss:  0.68738294
Encoder Loss:  0.11922829  || Decoder Loss:  0.3926303 Validation Decoder Loss:  0.68366927
Encoder Loss:  0.11858817  || Decoder Loss:  0.38957012 Validation Decoder Loss:  0.68011886
Encoder Loss:  0.11803569  || Decoder Loss:  0.38625798 Validation Decoder Loss:  0.67733294
Encoder Loss:  0.12078784  || Decoder Loss:  0.3996373 Validation Decoder Loss:  0.71389365
Encoder Loss:  0.12518711  || Decoder Loss:  0.42151752 Validation Decoder Loss:  0.74554574
Encoder Loss:  0.1381153  || Decoder Loss:  0.4843651 Validation Decoder Loss:  0.8845165
Encoder Loss:  0.14130722  || Decoder Loss:  0.501275 Validation Decoder Loss:  0.80227584
Encoder Loss:  0.13600975  || Decoder Loss:  0.4756046 Validation Decoder Loss:  0.8038708
Encoder Loss:  0.13568935  || Decoder Loss:  0.47416222 Validation Decoder Loss:  0.8005444
Encoder Loss:  0.13490011  || Decoder Loss:  0.4700712 Validation Decoder Loss:  0.79356813
Encoder Loss:  0.1338265  || Decoder Loss:  0.4649474 Validation Decoder Loss:  0.78686106
Model: siamese_net_lr_0.7149499057575085 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.78686106
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_255 (Conv3D (None, 121, 10, 20, 1)    349       
_________________________________________________________________
dropout_570 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_256 (Conv3D (None, 257, 10, 20, 1)    138       
_________________________________________________________________
reshape_126 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 487
Trainable params: 487
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_444"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_572 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_574 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4444538  || Decoder Loss:  0.47866887 Validation Decoder Loss:  1.1555374
Encoder Loss:  0.4521721  || Decoder Loss:  0.4877104 Validation Decoder Loss:  1.0883806
Encoder Loss:  0.44816497  || Decoder Loss:  0.48352185 Validation Decoder Loss:  1.1034461
Encoder Loss:  0.44829097  || Decoder Loss:  0.48363575 Validation Decoder Loss:  1.0969058
Encoder Loss:  0.44799644  || Decoder Loss:  0.4833465 Validation Decoder Loss:  1.0906501
Encoder Loss:  0.44781357  || Decoder Loss:  0.48316252 Validation Decoder Loss:  1.096904
Encoder Loss:  0.4480031  || Decoder Loss:  0.4833869 Validation Decoder Loss:  1.1416225
Encoder Loss:  0.397944  || Decoder Loss:  0.42885098 Validation Decoder Loss:  0.9436363
Encoder Loss:  0.25074595  || Decoder Loss:  0.26858667 Validation Decoder Loss:  0.52665603
Encoder Loss:  0.4074076  || Decoder Loss:  0.439171 Validation Decoder Loss:  0.44944018
Encoder Loss:  0.29599655  || Decoder Loss:  0.31785345 Validation Decoder Loss:  0.29674667
Encoder Loss:  0.36710265  || Decoder Loss:  0.39528808 Validation Decoder Loss:  0.46794367
Encoder Loss:  0.32507518  || Decoder Loss:  0.34951866 Validation Decoder Loss:  0.29974177
Encoder Loss:  0.14371021  || Decoder Loss:  0.1520279 Validation Decoder Loss:  0.6885823
Encoder Loss:  0.13973162  || Decoder Loss:  0.14769225 Validation Decoder Loss:  0.36414045
Encoder Loss:  0.08355549  || Decoder Loss:  0.08651814 Validation Decoder Loss:  0.3797038
Encoder Loss:  0.07702792  || Decoder Loss:  0.07941966 Validation Decoder Loss:  0.34235457
Encoder Loss:  0.102725856  || Decoder Loss:  0.10740447 Validation Decoder Loss:  0.33280915
Encoder Loss:  0.08595337  || Decoder Loss:  0.08913697 Validation Decoder Loss:  0.3107823
Encoder Loss:  0.09228833  || Decoder Loss:  0.09603644 Validation Decoder Loss:  1.1969111
Encoder Loss:  0.45215625  || Decoder Loss:  0.4878614 Validation Decoder Loss:  1.175528
Encoder Loss:  0.4452985  || Decoder Loss:  0.480456 Validation Decoder Loss:  0.5869279
Encoder Loss:  0.44358283  || Decoder Loss:  0.47859132 Validation Decoder Loss:  0.9837669
Encoder Loss:  0.36321658  || Decoder Loss:  0.39107665 Validation Decoder Loss:  0.54508173
Encoder Loss:  0.15871568  || Decoder Loss:  0.16837545 Validation Decoder Loss:  0.34278512
Encoder Loss:  0.03788459  || Decoder Loss:  0.036806196 Validation Decoder Loss:  0.32868207
Encoder Loss:  0.065062925  || Decoder Loss:  0.06639942 Validation Decoder Loss:  0.34586903
Encoder Loss:  0.04264544  || Decoder Loss:  0.041990504 Validation Decoder Loss:  0.32800734
Encoder Loss:  0.0554699  || Decoder Loss:  0.05595507 Validation Decoder Loss:  0.28602317
Encoder Loss:  0.07602582  || Decoder Loss:  0.078338854 Validation Decoder Loss:  0.34836677
Encoder Loss:  0.04482787  || Decoder Loss:  0.04436694 Validation Decoder Loss:  0.3308144
Encoder Loss:  0.045905422  || Decoder Loss:  0.045540825 Validation Decoder Loss:  0.58169174
Encoder Loss:  0.046682175  || Decoder Loss:  0.046386022 Validation Decoder Loss:  0.33650285
Encoder Loss:  0.03982884  || Decoder Loss:  0.038923625 Validation Decoder Loss:  0.33084345
Encoder Loss:  0.098591916  || Decoder Loss:  0.10291325 Validation Decoder Loss:  0.33934012
Encoder Loss:  0.043364592  || Decoder Loss:  0.042774 Validation Decoder Loss:  0.36548883
Encoder Loss:  0.07386984  || Decoder Loss:  0.07599137 Validation Decoder Loss:  0.3470286
Encoder Loss:  0.040131915  || Decoder Loss:  0.03925383 Validation Decoder Loss:  0.3542631
Encoder Loss:  0.14412446  || Decoder Loss:  0.15249464 Validation Decoder Loss:  0.31952426
Encoder Loss:  0.03935956  || Decoder Loss:  0.038412906 Validation Decoder Loss:  0.35880363
Model: siamese_net_lr_0.4585698329566734 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35880363
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_258 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_576 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_259 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_127 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 87
Trainable params: 87
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_578 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_580 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3752457  || Decoder Loss:  0.44855177 Validation Decoder Loss:  0.33421457
Encoder Loss:  0.037879646  || Decoder Loss:  0.035137665 Validation Decoder Loss:  0.33293098
Encoder Loss:  0.03780603  || Decoder Loss:  0.03504757 Validation Decoder Loss:  0.33190978
Encoder Loss:  0.03774949  || Decoder Loss:  0.034978095 Validation Decoder Loss:  0.33059657
Encoder Loss:  0.037701502  || Decoder Loss:  0.03491953 Validation Decoder Loss:  0.33332527
Encoder Loss:  0.43434033  || Decoder Loss:  0.5130767 Validation Decoder Loss:  1.0282755
Encoder Loss:  0.4193397  || Decoder Loss:  0.50202596 Validation Decoder Loss:  0.9998771
Encoder Loss:  0.4175194  || Decoder Loss:  0.5005949 Validation Decoder Loss:  1.0010247
Encoder Loss:  0.41768324  || Decoder Loss:  0.5006671 Validation Decoder Loss:  0.99982375
Encoder Loss:  0.41772294  || Decoder Loss:  0.50086874 Validation Decoder Loss:  0.99934787
Encoder Loss:  0.41742095  || Decoder Loss:  0.50051254 Validation Decoder Loss:  0.99896735
Encoder Loss:  0.38444492  || Decoder Loss:  0.4600786 Validation Decoder Loss:  0.33014917
Encoder Loss:  0.079917215  || Decoder Loss:  0.086682595 Validation Decoder Loss:  0.32232273
Encoder Loss:  0.056653693  || Decoder Loss:  0.05815806 Validation Decoder Loss:  0.32339966
Encoder Loss:  0.037959315  || Decoder Loss:  0.035235845 Validation Decoder Loss:  0.32145056
Encoder Loss:  0.03792665  || Decoder Loss:  0.03519564 Validation Decoder Loss:  0.32093573
Encoder Loss:  0.12822536  || Decoder Loss:  0.14581898 Validation Decoder Loss:  1.0231245
Encoder Loss:  0.41637784  || Decoder Loss:  0.49923268 Validation Decoder Loss:  0.9982151
Encoder Loss:  0.4163516  || Decoder Loss:  0.49920124 Validation Decoder Loss:  0.9970456
Encoder Loss:  0.4140703  || Decoder Loss:  0.49640414 Validation Decoder Loss:  0.9980093
Encoder Loss:  0.39697903  || Decoder Loss:  0.47544697 Validation Decoder Loss:  0.31472877
Encoder Loss:  0.057885114  || Decoder Loss:  0.05966771 Validation Decoder Loss:  0.3240955
Encoder Loss:  0.038080774  || Decoder Loss:  0.035384562 Validation Decoder Loss:  0.32271308
Encoder Loss:  0.038089737  || Decoder Loss:  0.03539534 Validation Decoder Loss:  0.3232438
Encoder Loss:  0.038133994  || Decoder Loss:  0.03544964 Validation Decoder Loss:  0.32039952
Encoder Loss:  0.03850314  || Decoder Loss:  0.03590154 Validation Decoder Loss:  0.32590675
Encoder Loss:  0.038210522  || Decoder Loss:  0.035543535 Validation Decoder Loss:  0.3226797
Encoder Loss:  0.039017774  || Decoder Loss:  0.03649236 Validation Decoder Loss:  0.33002114
Encoder Loss:  0.03823112  || Decoder Loss:  0.035569347 Validation Decoder Loss:  0.3290808
Encoder Loss:  0.038213596  || Decoder Loss:  0.035547737 Validation Decoder Loss:  0.33357555
Encoder Loss:  0.03819076  || Decoder Loss:  0.03551972 Validation Decoder Loss:  0.32841578
Encoder Loss:  0.03818445  || Decoder Loss:  0.03551187 Validation Decoder Loss:  0.3284545
Encoder Loss:  0.038575593  || Decoder Loss:  0.035991434 Validation Decoder Loss:  0.32815623
Encoder Loss:  0.038119115  || Decoder Loss:  0.03543156 Validation Decoder Loss:  0.3258183
Encoder Loss:  0.062392745  || Decoder Loss:  0.06517173 Validation Decoder Loss:  0.33251852
Encoder Loss:  0.4527796  || Decoder Loss:  0.54377943 Validation Decoder Loss:  0.3622411
Encoder Loss:  0.042347573  || Decoder Loss:  0.04061653 Validation Decoder Loss:  0.36027905
Encoder Loss:  0.042154893  || Decoder Loss:  0.0403801 Validation Decoder Loss:  0.36104643
Encoder Loss:  0.042222925  || Decoder Loss:  0.040463373 Validation Decoder Loss:  0.36479798
Encoder Loss:  0.042521607  || Decoder Loss:  0.040829264 Validation Decoder Loss:  0.36556274
Model: siamese_net_lr_0.47055739731112073 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3655627
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_261 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_582 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_262 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_128 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 87
Trainable params: 87
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_584 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 2590, 20, 1)       22        
_________________________________________________________________
dropout_586 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.252872  || Decoder Loss:  0.4906363 Validation Decoder Loss:  0.99973756
Encoder Loss:  0.2564499  || Decoder Loss:  0.49949822 Validation Decoder Loss:  1.0007894
Encoder Loss:  0.25628048  || Decoder Loss:  0.49917465 Validation Decoder Loss:  0.998785
Encoder Loss:  0.25624982  || Decoder Loss:  0.4991254 Validation Decoder Loss:  0.99946094
Encoder Loss:  0.2544095  || Decoder Loss:  0.49512684 Validation Decoder Loss:  0.9994587
Encoder Loss:  0.25600585  || Decoder Loss:  0.49860543 Validation Decoder Loss:  0.9992396
Encoder Loss:  0.25591227  || Decoder Loss:  0.49840316 Validation Decoder Loss:  0.9989042
Encoder Loss:  0.2558083  || Decoder Loss:  0.4981766 Validation Decoder Loss:  0.99858415
Encoder Loss:  0.25568545  || Decoder Loss:  0.49790904 Validation Decoder Loss:  0.9981915
Encoder Loss:  0.25543475  || Decoder Loss:  0.49736318 Validation Decoder Loss:  0.996868
Encoder Loss:  0.25440976  || Decoder Loss:  0.4951318 Validation Decoder Loss:  0.987696
Encoder Loss:  0.251386  || Decoder Loss:  0.4885442 Validation Decoder Loss:  0.9969876
Encoder Loss:  0.2559066  || Decoder Loss:  0.498391 Validation Decoder Loss:  0.9958952
Encoder Loss:  0.2553185  || Decoder Loss:  0.49710932 Validation Decoder Loss:  0.9925133
Encoder Loss:  0.13211216  || Decoder Loss:  0.22880886 Validation Decoder Loss:  0.33144188
Encoder Loss:  0.04325147  || Decoder Loss:  0.0353006 Validation Decoder Loss:  0.33104277
Encoder Loss:  0.043211903  || Decoder Loss:  0.035213903 Validation Decoder Loss:  0.3309791
Encoder Loss:  0.043200005  || Decoder Loss:  0.03518809 Validation Decoder Loss:  0.33058095
Encoder Loss:  0.043197613  || Decoder Loss:  0.035178915 Validation Decoder Loss:  0.33053312
Encoder Loss:  0.04318873  || Decoder Loss:  0.035163295 Validation Decoder Loss:  0.3303713
Encoder Loss:  0.04316916  || Decoder Loss:  0.035119556 Validation Decoder Loss:  0.3304208
Encoder Loss:  0.043190338  || Decoder Loss:  0.03516464 Validation Decoder Loss:  0.3304845
Encoder Loss:  0.04319939  || Decoder Loss:  0.035185546 Validation Decoder Loss:  0.33058012
Encoder Loss:  0.043199774  || Decoder Loss:  0.035185143 Validation Decoder Loss:  0.33085498
Encoder Loss:  0.14123598  || Decoder Loss:  0.2353171 Validation Decoder Loss:  1.0404584
Encoder Loss:  0.26238355  || Decoder Loss:  0.5018274 Validation Decoder Loss:  1.0070963
Encoder Loss:  0.2601239  || Decoder Loss:  0.49949726 Validation Decoder Loss:  0.99160135
Encoder Loss:  0.2586684  || Decoder Loss:  0.4985052 Validation Decoder Loss:  1.00401
Encoder Loss:  0.25741944  || Decoder Loss:  0.49879155 Validation Decoder Loss:  1.0025352
Encoder Loss:  0.25582147  || Decoder Loss:  0.4977709 Validation Decoder Loss:  1.0084677
Encoder Loss:  0.25635794  || Decoder Loss:  0.49823642 Validation Decoder Loss:  1.0041068
Encoder Loss:  0.25565934  || Decoder Loss:  0.49752918 Validation Decoder Loss:  1.0032427
Encoder Loss:  0.25288752  || Decoder Loss:  0.49148682 Validation Decoder Loss:  0.9895023
Encoder Loss:  0.25556225  || Decoder Loss:  0.4973864 Validation Decoder Loss:  1.0046031
Encoder Loss:  0.25606477  || Decoder Loss:  0.49813157 Validation Decoder Loss:  1.0047753
Encoder Loss:  0.25611314  || Decoder Loss:  0.49820033 Validation Decoder Loss:  1.0040318
Encoder Loss:  0.25602397  || Decoder Loss:  0.49815056 Validation Decoder Loss:  1.0051174
Encoder Loss:  0.25587124  || Decoder Loss:  0.49792966 Validation Decoder Loss:  1.0048
Encoder Loss:  0.25584957  || Decoder Loss:  0.49785247 Validation Decoder Loss:  1.0043161
Encoder Loss:  0.25559396  || Decoder Loss:  0.49747983 Validation Decoder Loss:  1.0031415
Model: siamese_net_lr_0.439897655736024 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0031415
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_264 (Conv3D (None, 234, 10, 20, 1)    1027      
_________________________________________________________________
dropout_588 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_265 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_129 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,052
Trainable params: 1,052
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_590 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_457"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_592 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07360565  || Decoder Loss:  0.06676335 Validation Decoder Loss:  0.3227651
Encoder Loss:  0.06185993  || Decoder Loss:  0.05562078 Validation Decoder Loss:  0.32562417
Encoder Loss:  0.05614463  || Decoder Loss:  0.052247744 Validation Decoder Loss:  0.32244632
Encoder Loss:  0.054923743  || Decoder Loss:  0.048989996 Validation Decoder Loss:  0.34529114
Encoder Loss:  0.052294664  || Decoder Loss:  0.047762558 Validation Decoder Loss:  0.3410747
Encoder Loss:  0.05075498  || Decoder Loss:  0.045814756 Validation Decoder Loss:  0.34533504
Encoder Loss:  0.05194972  || Decoder Loss:  0.0458293 Validation Decoder Loss:  0.34123006
Encoder Loss:  0.05032202  || Decoder Loss:  0.04440927 Validation Decoder Loss:  0.32535326
Encoder Loss:  0.05053037  || Decoder Loss:  0.04363337 Validation Decoder Loss:  0.34103593
Encoder Loss:  0.048555516  || Decoder Loss:  0.042336434 Validation Decoder Loss:  0.32330167
Encoder Loss:  0.050629154  || Decoder Loss:  0.039889142 Validation Decoder Loss:  0.3288071
Encoder Loss:  0.04528091  || Decoder Loss:  0.035652377 Validation Decoder Loss:  0.3314886
Encoder Loss:  0.043984532  || Decoder Loss:  0.035238646 Validation Decoder Loss:  0.33164087
Encoder Loss:  0.04193968  || Decoder Loss:  0.03522099 Validation Decoder Loss:  0.33140177
Encoder Loss:  0.0420347  || Decoder Loss:  0.035215244 Validation Decoder Loss:  0.33131778
Encoder Loss:  0.041902497  || Decoder Loss:  0.03520756 Validation Decoder Loss:  0.33152816
Encoder Loss:  0.041993093  || Decoder Loss:  0.035207693 Validation Decoder Loss:  0.33130574
Encoder Loss:  0.042146277  || Decoder Loss:  0.03551124 Validation Decoder Loss:  0.32953298
Encoder Loss:  0.04260902  || Decoder Loss:  0.03652315 Validation Decoder Loss:  0.3322178
Encoder Loss:  0.04424269  || Decoder Loss:  0.039174307 Validation Decoder Loss:  0.3318066
Encoder Loss:  0.043746863  || Decoder Loss:  0.03853128 Validation Decoder Loss:  0.3294491
Encoder Loss:  0.043180194  || Decoder Loss:  0.03762054 Validation Decoder Loss:  0.33345023
Encoder Loss:  0.04310967  || Decoder Loss:  0.03750902 Validation Decoder Loss:  0.3334268
Encoder Loss:  0.0432353  || Decoder Loss:  0.03766839 Validation Decoder Loss:  0.33364636
Encoder Loss:  0.0447558  || Decoder Loss:  0.040106285 Validation Decoder Loss:  0.33600408
Encoder Loss:  0.044504747  || Decoder Loss:  0.039816067 Validation Decoder Loss:  0.32981813
Encoder Loss:  0.04435371  || Decoder Loss:  0.039522313 Validation Decoder Loss:  0.32929772
Encoder Loss:  0.04349257  || Decoder Loss:  0.038229253 Validation Decoder Loss:  0.32997793
Encoder Loss:  0.043853685  || Decoder Loss:  0.038689606 Validation Decoder Loss:  0.33246672
Encoder Loss:  0.04458453  || Decoder Loss:  0.03987278 Validation Decoder Loss:  0.3288991
Encoder Loss:  0.044757567  || Decoder Loss:  0.04012059 Validation Decoder Loss:  0.33712396
Encoder Loss:  0.04528841  || Decoder Loss:  0.04122977 Validation Decoder Loss:  0.32975918
Encoder Loss:  0.043751717  || Decoder Loss:  0.038838588 Validation Decoder Loss:  0.33098012
Encoder Loss:  0.043383535  || Decoder Loss:  0.03819005 Validation Decoder Loss:  0.3307892
Encoder Loss:  0.04329239  || Decoder Loss:  0.03802752 Validation Decoder Loss:  0.33062726
Encoder Loss:  0.043017007  || Decoder Loss:  0.037533853 Validation Decoder Loss:  0.33040702
Encoder Loss:  0.042939693  || Decoder Loss:  0.037402753 Validation Decoder Loss:  0.33062845
Encoder Loss:  0.04291201  || Decoder Loss:  0.037354294 Validation Decoder Loss:  0.3305794
Encoder Loss:  0.042842273  || Decoder Loss:  0.037231144 Validation Decoder Loss:  0.33054197
Encoder Loss:  0.042591475  || Decoder Loss:  0.036772918 Validation Decoder Loss:  0.33069664
Model: siamese_net_lr_0.5077672236458496 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33069664
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_267 (Conv3D (None, 234, 10, 20, 1)    91        
_________________________________________________________________
dropout_594 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_268 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_130 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_596 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_598 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36097392  || Decoder Loss:  0.41181642 Validation Decoder Loss:  0.8330637
Encoder Loss:  0.066413864  || Decoder Loss:  0.07416861 Validation Decoder Loss:  0.330492
Encoder Loss:  0.04846903  || Decoder Loss:  0.039774884 Validation Decoder Loss:  0.330023
Encoder Loss:  0.047351636  || Decoder Loss:  0.039749354 Validation Decoder Loss:  0.32977948
Encoder Loss:  0.047354013  || Decoder Loss:  0.03952752 Validation Decoder Loss:  0.32894385
Encoder Loss:  0.047339406  || Decoder Loss:  0.039656762 Validation Decoder Loss:  0.3291068
Encoder Loss:  0.046135303  || Decoder Loss:  0.039109506 Validation Decoder Loss:  0.3287803
Encoder Loss:  0.0466928  || Decoder Loss:  0.039627764 Validation Decoder Loss:  0.328745
Encoder Loss:  0.047024995  || Decoder Loss:  0.039546236 Validation Decoder Loss:  0.32839173
Encoder Loss:  0.04664484  || Decoder Loss:  0.039496914 Validation Decoder Loss:  0.3291493
Encoder Loss:  0.04655668  || Decoder Loss:  0.040122744 Validation Decoder Loss:  0.32998896
Encoder Loss:  0.04633321  || Decoder Loss:  0.039532498 Validation Decoder Loss:  0.32930157
Encoder Loss:  0.04649395  || Decoder Loss:  0.03992213 Validation Decoder Loss:  0.32765058
Encoder Loss:  0.045854155  || Decoder Loss:  0.039657332 Validation Decoder Loss:  0.3273455
Encoder Loss:  0.04638582  || Decoder Loss:  0.04000487 Validation Decoder Loss:  0.32826906
Encoder Loss:  0.0456605  || Decoder Loss:  0.03982864 Validation Decoder Loss:  0.3279646
Encoder Loss:  0.04524967  || Decoder Loss:  0.039473176 Validation Decoder Loss:  0.32861975
Encoder Loss:  0.04549472  || Decoder Loss:  0.039427925 Validation Decoder Loss:  0.32773042
Encoder Loss:  0.045168757  || Decoder Loss:  0.039641462 Validation Decoder Loss:  0.3282591
Encoder Loss:  0.044808574  || Decoder Loss:  0.039229874 Validation Decoder Loss:  0.32824495
Encoder Loss:  0.044687673  || Decoder Loss:  0.03900503 Validation Decoder Loss:  0.3283709
Encoder Loss:  0.044818595  || Decoder Loss:  0.0392054 Validation Decoder Loss:  0.32892847
Encoder Loss:  0.04465132  || Decoder Loss:  0.03896834 Validation Decoder Loss:  0.32857895
Encoder Loss:  0.044799834  || Decoder Loss:  0.039225694 Validation Decoder Loss:  0.32914987
Encoder Loss:  0.044625953  || Decoder Loss:  0.03881941 Validation Decoder Loss:  0.3292923
Encoder Loss:  0.044532526  || Decoder Loss:  0.038869407 Validation Decoder Loss:  0.3291132
Encoder Loss:  0.044911314  || Decoder Loss:  0.039187547 Validation Decoder Loss:  0.32940495
Encoder Loss:  0.044624027  || Decoder Loss:  0.03897406 Validation Decoder Loss:  0.3293842
Encoder Loss:  0.0443401  || Decoder Loss:  0.038767044 Validation Decoder Loss:  0.3291759
Encoder Loss:  0.044328995  || Decoder Loss:  0.038703486 Validation Decoder Loss:  0.32941848
Encoder Loss:  0.044444397  || Decoder Loss:  0.038665343 Validation Decoder Loss:  0.32954264
Encoder Loss:  0.044260874  || Decoder Loss:  0.038559556 Validation Decoder Loss:  0.32969415
Encoder Loss:  0.045175087  || Decoder Loss:  0.04027461 Validation Decoder Loss:  0.33437783
Encoder Loss:  0.04538677  || Decoder Loss:  0.03939501 Validation Decoder Loss:  0.32969588
Encoder Loss:  0.044295758  || Decoder Loss:  0.03872836 Validation Decoder Loss:  0.32966465
Encoder Loss:  0.044394374  || Decoder Loss:  0.03888318 Validation Decoder Loss:  0.32999262
Encoder Loss:  0.04460962  || Decoder Loss:  0.03863336 Validation Decoder Loss:  0.3297497
Encoder Loss:  0.044093233  || Decoder Loss:  0.03834314 Validation Decoder Loss:  0.32995567
Encoder Loss:  0.04404092  || Decoder Loss:  0.038233496 Validation Decoder Loss:  0.3298335
Encoder Loss:  0.044113513  || Decoder Loss:  0.03835542 Validation Decoder Loss:  0.3300091
Model: siamese_net_lr_0.45337076753484373 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3300091
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_270 (Conv3D (None, 205, 10, 20, 1)    97        
_________________________________________________________________
dropout_600 (Dropout)        (None, 205, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_271 (Conv3D (None, 257, 10, 20, 1)    54        
_________________________________________________________________
reshape_131 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_602 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_604 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3313518  || Decoder Loss:  0.65416074 Validation Decoder Loss:  1.1458042
Encoder Loss:  0.25037646  || Decoder Loss:  0.5818286 Validation Decoder Loss:  0.8032223
Encoder Loss:  0.22207588  || Decoder Loss:  0.50735444 Validation Decoder Loss:  0.78735554
Encoder Loss:  0.21979244  || Decoder Loss:  0.5014808 Validation Decoder Loss:  0.74443364
Encoder Loss:  0.2136557  || Decoder Loss:  0.48531017 Validation Decoder Loss:  0.78221816
Encoder Loss:  0.21874972  || Decoder Loss:  0.49889973 Validation Decoder Loss:  0.75534904
Encoder Loss:  0.20358911  || Decoder Loss:  0.45858964 Validation Decoder Loss:  0.7733979
Encoder Loss:  0.21075536  || Decoder Loss:  0.47773704 Validation Decoder Loss:  0.8542166
Encoder Loss:  0.11163348  || Decoder Loss:  0.21391024 Validation Decoder Loss:  0.29846936
Encoder Loss:  0.048027147  || Decoder Loss:  0.044591155 Validation Decoder Loss:  0.3282761
Encoder Loss:  0.04487677  || Decoder Loss:  0.036221653 Validation Decoder Loss:  0.3432898
Encoder Loss:  0.04464893  || Decoder Loss:  0.035655994 Validation Decoder Loss:  0.33629608
Encoder Loss:  0.04461379  || Decoder Loss:  0.03556095 Validation Decoder Loss:  0.33605573
Encoder Loss:  0.04459006  || Decoder Loss:  0.035520855 Validation Decoder Loss:  0.33566955
Encoder Loss:  0.04457118  || Decoder Loss:  0.03547966 Validation Decoder Loss:  0.33572498
Encoder Loss:  0.04454988  || Decoder Loss:  0.035428554 Validation Decoder Loss:  0.33579856
Encoder Loss:  0.04453123  || Decoder Loss:  0.035385545 Validation Decoder Loss:  0.33592388
Encoder Loss:  0.044513587  || Decoder Loss:  0.035347365 Validation Decoder Loss:  0.3362609
Encoder Loss:  0.044503197  || Decoder Loss:  0.03531827 Validation Decoder Loss:  0.33632612
Encoder Loss:  0.044499487  || Decoder Loss:  0.03530194 Validation Decoder Loss:  0.3364691
Encoder Loss:  0.0444864  || Decoder Loss:  0.03527695 Validation Decoder Loss:  0.33661246
Encoder Loss:  0.044474393  || Decoder Loss:  0.03525364 Validation Decoder Loss:  0.3366758
Encoder Loss:  0.044459887  || Decoder Loss:  0.035223506 Validation Decoder Loss:  0.33675414
Encoder Loss:  0.044446297  || Decoder Loss:  0.035192024 Validation Decoder Loss:  0.33670026
Encoder Loss:  0.04443234  || Decoder Loss:  0.03515788 Validation Decoder Loss:  0.33662426
Encoder Loss:  0.044416968  || Decoder Loss:  0.035114117 Validation Decoder Loss:  0.33643687
Encoder Loss:  0.044405125  || Decoder Loss:  0.035048973 Validation Decoder Loss:  0.33610588
Encoder Loss:  0.044362795  || Decoder Loss:  0.03493414 Validation Decoder Loss:  0.33521783
Encoder Loss:  0.044310983  || Decoder Loss:  0.03479383 Validation Decoder Loss:  0.33473718
Encoder Loss:  0.044269834  || Decoder Loss:  0.03470935 Validation Decoder Loss:  0.33589637
Encoder Loss:  0.044258717  || Decoder Loss:  0.03468343 Validation Decoder Loss:  0.334745
Encoder Loss:  0.044256255  || Decoder Loss:  0.03468359 Validation Decoder Loss:  0.33524042
Encoder Loss:  0.044319715  || Decoder Loss:  0.034849063 Validation Decoder Loss:  0.33134237
Encoder Loss:  0.044732094  || Decoder Loss:  0.035904482 Validation Decoder Loss:  0.33252394
Encoder Loss:  0.044433996  || Decoder Loss:  0.03510497 Validation Decoder Loss:  0.33880344
Encoder Loss:  0.044510484  || Decoder Loss:  0.035316244 Validation Decoder Loss:  0.3378247
Encoder Loss:  0.044395577  || Decoder Loss:  0.034884192 Validation Decoder Loss:  0.33838996
Encoder Loss:  0.04437001  || Decoder Loss:  0.0348881 Validation Decoder Loss:  0.34352544
Encoder Loss:  0.045293923  || Decoder Loss:  0.035180725 Validation Decoder Loss:  0.32720762
Encoder Loss:  0.28543866  || Decoder Loss:  0.39019948 Validation Decoder Loss:  0.81403846
Model: siamese_net_lr_0.39573673480358934 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.81403846
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_273 (Conv3D (None, 234, 10, 20, 1)    271       
_________________________________________________________________
dropout_606 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_274 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_132 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 296
Trainable params: 296
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_608 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_469"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_610 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05556532  || Decoder Loss:  0.055422287 Validation Decoder Loss:  0.32872194
Encoder Loss:  0.035720717  || Decoder Loss:  0.035672415 Validation Decoder Loss:  0.32880467
Encoder Loss:  0.035624176  || Decoder Loss:  0.03557558 Validation Decoder Loss:  0.32872576
Encoder Loss:  0.035553865  || Decoder Loss:  0.0355049 Validation Decoder Loss:  0.3229227
Encoder Loss:  0.035782177  || Decoder Loss:  0.03573409 Validation Decoder Loss:  0.32437372
Encoder Loss:  0.035590596  || Decoder Loss:  0.035541456 Validation Decoder Loss:  0.3254769
Encoder Loss:  0.035475418  || Decoder Loss:  0.03542605 Validation Decoder Loss:  0.3261106
Encoder Loss:  0.03671376  || Decoder Loss:  0.036652673 Validation Decoder Loss:  0.30577204
Encoder Loss:  0.0361724  || Decoder Loss:  0.036125317 Validation Decoder Loss:  0.33100948
Encoder Loss:  0.036072344  || Decoder Loss:  0.03602535 Validation Decoder Loss:  0.3336562
Encoder Loss:  0.036057673  || Decoder Loss:  0.036010638 Validation Decoder Loss:  0.33384502
Encoder Loss:  0.036039006  || Decoder Loss:  0.035991944 Validation Decoder Loss:  0.33345976
Encoder Loss:  0.036021575  || Decoder Loss:  0.035974413 Validation Decoder Loss:  0.3329171
Encoder Loss:  0.03600295  || Decoder Loss:  0.035955735 Validation Decoder Loss:  0.33222306
Encoder Loss:  0.035981763  || Decoder Loss:  0.0359344 Validation Decoder Loss:  0.3268385
Encoder Loss:  0.035967458  || Decoder Loss:  0.035920076 Validation Decoder Loss:  0.32688552
Encoder Loss:  0.03594174  || Decoder Loss:  0.03589407 Validation Decoder Loss:  0.32696402
Encoder Loss:  0.036600586  || Decoder Loss:  0.036554843 Validation Decoder Loss:  0.32924014
Encoder Loss:  0.03626208  || Decoder Loss:  0.036215592 Validation Decoder Loss:  0.32927608
Encoder Loss:  0.035984647  || Decoder Loss:  0.03593731 Validation Decoder Loss:  0.32967496
Encoder Loss:  0.035928164  || Decoder Loss:  0.035880603 Validation Decoder Loss:  0.33011925
Encoder Loss:  0.03588302  || Decoder Loss:  0.03583519 Validation Decoder Loss:  0.3298753
Encoder Loss:  0.03581695  || Decoder Loss:  0.035769045 Validation Decoder Loss:  0.3309717
Encoder Loss:  0.035734992  || Decoder Loss:  0.035686843 Validation Decoder Loss:  0.33197576
Encoder Loss:  0.035663523  || Decoder Loss:  0.03561515 Validation Decoder Loss:  0.3318216
Encoder Loss:  0.035591304  || Decoder Loss:  0.03554274 Validation Decoder Loss:  0.33161008
Encoder Loss:  0.035536252  || Decoder Loss:  0.035487495 Validation Decoder Loss:  0.33151078
Encoder Loss:  0.035495386  || Decoder Loss:  0.03544646 Validation Decoder Loss:  0.33177516
Encoder Loss:  0.036440957  || Decoder Loss:  0.036392614 Validation Decoder Loss:  0.32829145
Encoder Loss:  0.035597987  || Decoder Loss:  0.035549346 Validation Decoder Loss:  0.3286707
Encoder Loss:  0.03549299  || Decoder Loss:  0.035443973 Validation Decoder Loss:  0.3291995
Encoder Loss:  0.035461493  || Decoder Loss:  0.03541245 Validation Decoder Loss:  0.32920787
Encoder Loss:  0.035417028  || Decoder Loss:  0.035367835 Validation Decoder Loss:  0.32952783
Encoder Loss:  0.035408065  || Decoder Loss:  0.035358876 Validation Decoder Loss:  0.3296718
Encoder Loss:  0.03538663  || Decoder Loss:  0.035337333 Validation Decoder Loss:  0.33003104
Encoder Loss:  0.035389192  || Decoder Loss:  0.035339877 Validation Decoder Loss:  0.33016258
Encoder Loss:  0.035342876  || Decoder Loss:  0.035293493 Validation Decoder Loss:  0.33035934
Encoder Loss:  0.035345744  || Decoder Loss:  0.0352964 Validation Decoder Loss:  0.33045703
Encoder Loss:  0.03532836  || Decoder Loss:  0.035278913 Validation Decoder Loss:  0.33042404
Encoder Loss:  0.03531665  || Decoder Loss:  0.035267193 Validation Decoder Loss:  0.33044702
Model: siamese_net_lr_0.22002764111106202 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33044702
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_276 (Conv3D (None, 235, 10, 20, 1)    277       
_________________________________________________________________
dropout_612 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_277 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_133 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_614 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_473"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_616 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10444971  || Decoder Loss:  0.110862345 Validation Decoder Loss:  0.33512485
Encoder Loss:  0.04552911  || Decoder Loss:  0.040987886 Validation Decoder Loss:  0.3359502
Encoder Loss:  0.043514818  || Decoder Loss:  0.04042178 Validation Decoder Loss:  0.3401504
Encoder Loss:  0.041186895  || Decoder Loss:  0.03768282 Validation Decoder Loss:  0.33566412
Encoder Loss:  0.04065296  || Decoder Loss:  0.03697179 Validation Decoder Loss:  0.3345047
Encoder Loss:  0.040635232  || Decoder Loss:  0.036966376 Validation Decoder Loss:  0.33467156
Encoder Loss:  0.04051479  || Decoder Loss:  0.03681135 Validation Decoder Loss:  0.33476672
Encoder Loss:  0.04049392  || Decoder Loss:  0.036754604 Validation Decoder Loss:  0.33444774
Encoder Loss:  0.040308822  || Decoder Loss:  0.036558654 Validation Decoder Loss:  0.3336875
Encoder Loss:  0.04025594  || Decoder Loss:  0.03647201 Validation Decoder Loss:  0.33342263
Encoder Loss:  0.040149525  || Decoder Loss:  0.03632395 Validation Decoder Loss:  0.33350545
Encoder Loss:  0.040200725  || Decoder Loss:  0.036400307 Validation Decoder Loss:  0.33372092
Encoder Loss:  0.040097557  || Decoder Loss:  0.036248263 Validation Decoder Loss:  0.3323365
Encoder Loss:  0.040144395  || Decoder Loss:  0.03630993 Validation Decoder Loss:  0.33308223
Encoder Loss:  0.04015245  || Decoder Loss:  0.036333717 Validation Decoder Loss:  0.332046
Encoder Loss:  0.04473432  || Decoder Loss:  0.042661265 Validation Decoder Loss:  0.3290543
Encoder Loss:  0.042147182  || Decoder Loss:  0.039100096 Validation Decoder Loss:  0.3288109
Encoder Loss:  0.0420153  || Decoder Loss:  0.038897563 Validation Decoder Loss:  0.3302916
Encoder Loss:  0.041979555  || Decoder Loss:  0.03884891 Validation Decoder Loss:  0.32887885
Encoder Loss:  0.04169879  || Decoder Loss:  0.038482275 Validation Decoder Loss:  0.3294044
Encoder Loss:  0.041555654  || Decoder Loss:  0.038285255 Validation Decoder Loss:  0.32947004
Encoder Loss:  0.041538533  || Decoder Loss:  0.038240302 Validation Decoder Loss:  0.3300259
Encoder Loss:  0.043407504  || Decoder Loss:  0.040806368 Validation Decoder Loss:  0.3286416
Encoder Loss:  0.041991442  || Decoder Loss:  0.038902704 Validation Decoder Loss:  0.32923454
Encoder Loss:  0.041594908  || Decoder Loss:  0.038356155 Validation Decoder Loss:  0.32914484
Encoder Loss:  0.041393112  || Decoder Loss:  0.038072802 Validation Decoder Loss:  0.3297051
Encoder Loss:  0.041258536  || Decoder Loss:  0.037889723 Validation Decoder Loss:  0.32959995
Encoder Loss:  0.041105933  || Decoder Loss:  0.037678555 Validation Decoder Loss:  0.32982707
Encoder Loss:  0.041055355  || Decoder Loss:  0.03761408 Validation Decoder Loss:  0.32992402
Encoder Loss:  0.04093503  || Decoder Loss:  0.037449352 Validation Decoder Loss:  0.3298918
Encoder Loss:  0.040972017  || Decoder Loss:  0.037502166 Validation Decoder Loss:  0.3299124
Encoder Loss:  0.040948156  || Decoder Loss:  0.03746928 Validation Decoder Loss:  0.32981968
Encoder Loss:  0.041705415  || Decoder Loss:  0.038485907 Validation Decoder Loss:  0.33008736
Encoder Loss:  0.041739006  || Decoder Loss:  0.038569104 Validation Decoder Loss:  0.32985863
Encoder Loss:  0.041287042  || Decoder Loss:  0.037946485 Validation Decoder Loss:  0.32986543
Encoder Loss:  0.041107215  || Decoder Loss:  0.037695337 Validation Decoder Loss:  0.32988358
Encoder Loss:  0.041042197  || Decoder Loss:  0.03760719 Validation Decoder Loss:  0.33019066
Encoder Loss:  0.04093146  || Decoder Loss:  0.03745334 Validation Decoder Loss:  0.33004433
Encoder Loss:  0.041061692  || Decoder Loss:  0.037630152 Validation Decoder Loss:  0.32972348
Encoder Loss:  0.04111963  || Decoder Loss:  0.03773216 Validation Decoder Loss:  0.3328892
Model: siamese_net_lr_0.6057787736155096 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3328892
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_279 (Conv3D (None, 235, 10, 20, 1)    277       
_________________________________________________________________
dropout_618 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_280 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_134 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_476"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_620 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_622 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13284159  || Decoder Loss:  0.16482435 Validation Decoder Loss:  0.3316887
Encoder Loss:  0.043834172  || Decoder Loss:  0.04024812 Validation Decoder Loss:  0.33084208
Encoder Loss:  0.042546347  || Decoder Loss:  0.038389463 Validation Decoder Loss:  0.33934572
Encoder Loss:  0.04294694  || Decoder Loss:  0.039014712 Validation Decoder Loss:  0.33251303
Encoder Loss:  0.04195639  || Decoder Loss:  0.037459865 Validation Decoder Loss:  0.3308499
Encoder Loss:  0.04156429  || Decoder Loss:  0.03682913 Validation Decoder Loss:  0.330545
Encoder Loss:  0.043098982  || Decoder Loss:  0.0390463 Validation Decoder Loss:  0.33065948
Encoder Loss:  0.0497591  || Decoder Loss:  0.045818094 Validation Decoder Loss:  0.330495
Encoder Loss:  0.04284327  || Decoder Loss:  0.03886156 Validation Decoder Loss:  0.32789576
Encoder Loss:  0.042706426  || Decoder Loss:  0.038665194 Validation Decoder Loss:  0.3271408
Encoder Loss:  0.041547183  || Decoder Loss:  0.03680331 Validation Decoder Loss:  0.33275503
Encoder Loss:  0.04170557  || Decoder Loss:  0.037106834 Validation Decoder Loss:  0.33375317
Encoder Loss:  0.04153499  || Decoder Loss:  0.036829893 Validation Decoder Loss:  0.33493367
Encoder Loss:  0.041493785  || Decoder Loss:  0.03680997 Validation Decoder Loss:  0.33345333
Encoder Loss:  0.041360904  || Decoder Loss:  0.03659288 Validation Decoder Loss:  0.33242092
Encoder Loss:  0.041292917  || Decoder Loss:  0.036489014 Validation Decoder Loss:  0.3312387
Encoder Loss:  0.041286554  || Decoder Loss:  0.036440134 Validation Decoder Loss:  0.3329618
Encoder Loss:  0.041231953  || Decoder Loss:  0.036381915 Validation Decoder Loss:  0.33025956
Encoder Loss:  0.041556392  || Decoder Loss:  0.03685264 Validation Decoder Loss:  0.33329034
Encoder Loss:  0.04150189  || Decoder Loss:  0.03676724 Validation Decoder Loss:  0.33397582
Encoder Loss:  0.041305427  || Decoder Loss:  0.036507316 Validation Decoder Loss:  0.33296275
Encoder Loss:  0.04143192  || Decoder Loss:  0.036686443 Validation Decoder Loss:  0.33234262
Encoder Loss:  0.041373383  || Decoder Loss:  0.0365885 Validation Decoder Loss:  0.33314928
Encoder Loss:  0.041472483  || Decoder Loss:  0.03675742 Validation Decoder Loss:  0.33218998
Encoder Loss:  0.045834556  || Decoder Loss:  0.043494288 Validation Decoder Loss:  0.3295126
Encoder Loss:  0.04272863  || Decoder Loss:  0.038304307 Validation Decoder Loss:  0.33071026
Encoder Loss:  0.041577414  || Decoder Loss:  0.03695989 Validation Decoder Loss:  0.33213437
Encoder Loss:  0.041424688  || Decoder Loss:  0.03672974 Validation Decoder Loss:  0.33213764
Encoder Loss:  0.047856376  || Decoder Loss:  0.046651326 Validation Decoder Loss:  0.33026442
Encoder Loss:  0.04453362  || Decoder Loss:  0.041522555 Validation Decoder Loss:  0.33031392
Encoder Loss:  0.043941442  || Decoder Loss:  0.040604405 Validation Decoder Loss:  0.3302816
Encoder Loss:  0.04516174  || Decoder Loss:  0.042392083 Validation Decoder Loss:  0.3300095
Encoder Loss:  0.04398872  || Decoder Loss:  0.040680695 Validation Decoder Loss:  0.33023483
Encoder Loss:  0.04361259  || Decoder Loss:  0.040110722 Validation Decoder Loss:  0.3302077
Encoder Loss:  0.043419395  || Decoder Loss:  0.039792843 Validation Decoder Loss:  0.3303846
Encoder Loss:  0.043331742  || Decoder Loss:  0.039660074 Validation Decoder Loss:  0.3303694
Encoder Loss:  0.043182924  || Decoder Loss:  0.039433457 Validation Decoder Loss:  0.33034718
Encoder Loss:  0.043110445  || Decoder Loss:  0.03932989 Validation Decoder Loss:  0.3305517
Encoder Loss:  0.043142978  || Decoder Loss:  0.039369047 Validation Decoder Loss:  0.3299384
Encoder Loss:  0.043322142  || Decoder Loss:  0.039637525 Validation Decoder Loss:  0.32989427
Model: siamese_net_lr_0.6241892664231533 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3298943
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_282 (Conv3D (None, 236, 10, 20, 1)    283       
_________________________________________________________________
dropout_624 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_283 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_135 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 306
Trainable params: 306
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_626 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_628 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0871585  || Decoder Loss:  0.051606122 Validation Decoder Loss:  0.33519697
Encoder Loss:  0.04979993  || Decoder Loss:  0.046674386 Validation Decoder Loss:  0.33734775
Encoder Loss:  0.05070892  || Decoder Loss:  0.04660823 Validation Decoder Loss:  0.34205675
Encoder Loss:  0.052929252  || Decoder Loss:  0.046824645 Validation Decoder Loss:  0.34461293
Encoder Loss:  0.049773287  || Decoder Loss:  0.046269637 Validation Decoder Loss:  0.33903068
Encoder Loss:  0.0500958  || Decoder Loss:  0.046098363 Validation Decoder Loss:  0.33954823
Encoder Loss:  0.051324382  || Decoder Loss:  0.046665758 Validation Decoder Loss:  0.33755603
Encoder Loss:  0.050247006  || Decoder Loss:  0.04675663 Validation Decoder Loss:  0.33554652
Encoder Loss:  0.049807042  || Decoder Loss:  0.04662497 Validation Decoder Loss:  0.33738297
Encoder Loss:  0.049787685  || Decoder Loss:  0.046466675 Validation Decoder Loss:  0.3364712
Encoder Loss:  0.053587697  || Decoder Loss:  0.051420838 Validation Decoder Loss:  0.33549565
Encoder Loss:  0.049986653  || Decoder Loss:  0.0496169 Validation Decoder Loss:  0.3371874
Encoder Loss:  0.050015844  || Decoder Loss:  0.049356733 Validation Decoder Loss:  0.3388126
Encoder Loss:  0.050353084  || Decoder Loss:  0.049542304 Validation Decoder Loss:  0.33985224
Encoder Loss:  0.050240744  || Decoder Loss:  0.049907632 Validation Decoder Loss:  0.3392617
Encoder Loss:  0.050616384  || Decoder Loss:  0.05166704 Validation Decoder Loss:  0.341493
Encoder Loss:  0.050605908  || Decoder Loss:  0.052984852 Validation Decoder Loss:  0.34203586
Encoder Loss:  0.050333586  || Decoder Loss:  0.053350016 Validation Decoder Loss:  0.3429279
Encoder Loss:  0.050238095  || Decoder Loss:  0.05291431 Validation Decoder Loss:  0.34552968
Encoder Loss:  0.05023295  || Decoder Loss:  0.05252552 Validation Decoder Loss:  0.3456528
Encoder Loss:  0.07445169  || Decoder Loss:  0.3834243 Validation Decoder Loss:  0.5513979
Encoder Loss:  0.05837783  || Decoder Loss:  0.17071062 Validation Decoder Loss:  0.43451622
Encoder Loss:  0.063442126  || Decoder Loss:  0.2438785 Validation Decoder Loss:  0.7117087
Encoder Loss:  0.061389774  || Decoder Loss:  0.21442953 Validation Decoder Loss:  0.49704927
Encoder Loss:  0.05715825  || Decoder Loss:  0.15318733 Validation Decoder Loss:  0.32579976
Encoder Loss:  0.049475692  || Decoder Loss:  0.042107053 Validation Decoder Loss:  0.3777576
Encoder Loss:  0.05022883  || Decoder Loss:  0.053042106 Validation Decoder Loss:  0.34794497
Encoder Loss:  0.050388664  || Decoder Loss:  0.055262566 Validation Decoder Loss:  0.3257358
Encoder Loss:  0.05186266  || Decoder Loss:  0.06982781 Validation Decoder Loss:  0.32896215
Encoder Loss:  0.049600888  || Decoder Loss:  0.04405526 Validation Decoder Loss:  0.3344706
Encoder Loss:  0.05127314  || Decoder Loss:  0.06829394 Validation Decoder Loss:  0.33539563
Encoder Loss:  0.050162196  || Decoder Loss:  0.052190956 Validation Decoder Loss:  0.37061396
Encoder Loss:  0.050485853  || Decoder Loss:  0.056832008 Validation Decoder Loss:  0.32633364
Encoder Loss:  0.050252665  || Decoder Loss:  0.05338155 Validation Decoder Loss:  0.32606173
Encoder Loss:  0.049863596  || Decoder Loss:  0.04365386 Validation Decoder Loss:  0.32741675
Encoder Loss:  0.049542412  || Decoder Loss:  0.04322681 Validation Decoder Loss:  0.33339232
Encoder Loss:  0.049536098  || Decoder Loss:  0.043170933 Validation Decoder Loss:  0.33470362
Encoder Loss:  0.05167205  || Decoder Loss:  0.07408664 Validation Decoder Loss:  0.37607443
Encoder Loss:  0.049920015  || Decoder Loss:  0.0487166 Validation Decoder Loss:  0.3623309
Encoder Loss:  0.049359657  || Decoder Loss:  0.04051759 Validation Decoder Loss:  0.32587233
Model: siamese_net_lr_0.8129695532687576 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32587233
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_285 (Conv3D (None, 242, 5, 20, 1)     54        
_________________________________________________________________
dropout_630 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_286 (Conv3D (None, 257, 10, 20, 1)    97        
_________________________________________________________________
reshape_136 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 151
Trainable params: 151
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_632 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_634 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10796051  || Decoder Loss:  0.10861884 Validation Decoder Loss:  0.35669094
Encoder Loss:  0.047415018  || Decoder Loss:  0.047288124 Validation Decoder Loss:  0.37769297
Encoder Loss:  0.04025075  || Decoder Loss:  0.039876055 Validation Decoder Loss:  0.3341729
Encoder Loss:  0.035687443  || Decoder Loss:  0.035140313 Validation Decoder Loss:  0.33428237
Encoder Loss:  0.035686176  || Decoder Loss:  0.035138376 Validation Decoder Loss:  0.33453688
Encoder Loss:  0.035702255  || Decoder Loss:  0.0351538 Validation Decoder Loss:  0.33500466
Encoder Loss:  0.03572159  || Decoder Loss:  0.035173774 Validation Decoder Loss:  0.33517003
Encoder Loss:  0.035766903  || Decoder Loss:  0.0352198 Validation Decoder Loss:  0.33495915
Encoder Loss:  0.035743013  || Decoder Loss:  0.0351963 Validation Decoder Loss:  0.33488214
Encoder Loss:  0.03572995  || Decoder Loss:  0.035183635 Validation Decoder Loss:  0.3350527
Encoder Loss:  0.03573246  || Decoder Loss:  0.035187315 Validation Decoder Loss:  0.33499426
Encoder Loss:  0.03564466  || Decoder Loss:  0.035095982 Validation Decoder Loss:  0.33513406
Encoder Loss:  0.035596322  || Decoder Loss:  0.03504862 Validation Decoder Loss:  0.33433667
Encoder Loss:  0.035565473  || Decoder Loss:  0.035017673 Validation Decoder Loss:  0.3344164
Encoder Loss:  0.037807547  || Decoder Loss:  0.037345666 Validation Decoder Loss:  0.33565456
Encoder Loss:  0.035741407  || Decoder Loss:  0.035202444 Validation Decoder Loss:  0.3348474
Encoder Loss:  0.03575032  || Decoder Loss:  0.035211764 Validation Decoder Loss:  0.3352182
Encoder Loss:  0.035673685  || Decoder Loss:  0.035132166 Validation Decoder Loss:  0.33462083
Encoder Loss:  0.03566955  || Decoder Loss:  0.03512782 Validation Decoder Loss:  0.33338732
Encoder Loss:  0.164856  || Decoder Loss:  0.16913489 Validation Decoder Loss:  0.36030772
Encoder Loss:  0.05651402  || Decoder Loss:  0.05675835 Validation Decoder Loss:  0.3312429
Encoder Loss:  0.035970148  || Decoder Loss:  0.03543876 Validation Decoder Loss:  0.3305893
Encoder Loss:  0.035982214  || Decoder Loss:  0.03545157 Validation Decoder Loss:  0.33064157
Encoder Loss:  0.035979357  || Decoder Loss:  0.035448983 Validation Decoder Loss:  0.33067197
Encoder Loss:  0.036007665  || Decoder Loss:  0.035477974 Validation Decoder Loss:  0.3309021
Encoder Loss:  0.03602967  || Decoder Loss:  0.035500888 Validation Decoder Loss:  0.3312562
Encoder Loss:  0.036045756  || Decoder Loss:  0.035517827 Validation Decoder Loss:  0.3315171
Encoder Loss:  0.036047213  || Decoder Loss:  0.035519443 Validation Decoder Loss:  0.33185968
Encoder Loss:  0.036044605  || Decoder Loss:  0.03551679 Validation Decoder Loss:  0.3319226
Encoder Loss:  0.036027752  || Decoder Loss:  0.03549941 Validation Decoder Loss:  0.3318898
Encoder Loss:  0.036004946  || Decoder Loss:  0.035475966 Validation Decoder Loss:  0.33168724
Encoder Loss:  0.035981916  || Decoder Loss:  0.03545226 Validation Decoder Loss:  0.33139575
Encoder Loss:  0.03596559  || Decoder Loss:  0.035435434 Validation Decoder Loss:  0.33108062
Encoder Loss:  0.03594354  || Decoder Loss:  0.035412543 Validation Decoder Loss:  0.33093333
Encoder Loss:  0.03594545  || Decoder Loss:  0.03541443 Validation Decoder Loss:  0.3308335
Encoder Loss:  0.037170045  || Decoder Loss:  0.036682628 Validation Decoder Loss:  0.33088583
Encoder Loss:  0.035878234  || Decoder Loss:  0.035344895 Validation Decoder Loss:  0.33065754
Encoder Loss:  0.03584961  || Decoder Loss:  0.03531528 Validation Decoder Loss:  0.3304627
Encoder Loss:  0.03585738  || Decoder Loss:  0.035323307 Validation Decoder Loss:  0.3302849
Encoder Loss:  0.03587032  || Decoder Loss:  0.035336766 Validation Decoder Loss:  0.33073017
Model: siamese_net_lr_0.1759403282362854 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33073017
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_288 (Conv3D (None, 250, 9, 20, 1)     621       
_________________________________________________________________
dropout_636 (Dropout)        (None, 250, 9, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_289 (Conv3D (None, 257, 10, 20, 1)    17        
_________________________________________________________________
reshape_137 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 638
Trainable params: 638
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_488"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_638 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_640 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.072894454  || Decoder Loss:  0.07264382 Validation Decoder Loss:  0.32747895
Encoder Loss:  0.035734788  || Decoder Loss:  0.035502482 Validation Decoder Loss:  0.3304726
Encoder Loss:  0.035603102  || Decoder Loss:  0.035391327 Validation Decoder Loss:  0.32979894
Encoder Loss:  0.03557489  || Decoder Loss:  0.035364367 Validation Decoder Loss:  0.32929558
Encoder Loss:  0.035553724  || Decoder Loss:  0.035343584 Validation Decoder Loss:  0.32922825
Encoder Loss:  0.03554245  || Decoder Loss:  0.03533245 Validation Decoder Loss:  0.32926226
Encoder Loss:  0.10867525  || Decoder Loss:  0.10950167 Validation Decoder Loss:  0.32976735
Encoder Loss:  0.035552062  || Decoder Loss:  0.03534273 Validation Decoder Loss:  0.33009243
Encoder Loss:  0.035510227  || Decoder Loss:  0.03530043 Validation Decoder Loss:  0.32979628
Encoder Loss:  0.035509497  || Decoder Loss:  0.035299763 Validation Decoder Loss:  0.32948077
Encoder Loss:  0.03551888  || Decoder Loss:  0.035309285 Validation Decoder Loss:  0.329364
Encoder Loss:  0.035529356  || Decoder Loss:  0.03531998 Validation Decoder Loss:  0.3294278
Encoder Loss:  0.06297705  || Decoder Loss:  0.063130066 Validation Decoder Loss:  0.33091122
Encoder Loss:  0.035782617  || Decoder Loss:  0.03557676 Validation Decoder Loss:  0.33165222
Encoder Loss:  0.035653483  || Decoder Loss:  0.035445943 Validation Decoder Loss:  0.3298217
Encoder Loss:  0.036309358  || Decoder Loss:  0.036111247 Validation Decoder Loss:  0.33133155
Encoder Loss:  0.03562078  || Decoder Loss:  0.035412844 Validation Decoder Loss:  0.33098745
Encoder Loss:  0.03557296  || Decoder Loss:  0.03536441 Validation Decoder Loss:  0.33056095
Encoder Loss:  0.03565708  || Decoder Loss:  0.03544967 Validation Decoder Loss:  0.33207235
Encoder Loss:  0.0356627  || Decoder Loss:  0.03545543 Validation Decoder Loss:  0.33129698
Encoder Loss:  0.035640586  || Decoder Loss:  0.03543307 Validation Decoder Loss:  0.33047682
Encoder Loss:  0.0356392  || Decoder Loss:  0.03543173 Validation Decoder Loss:  0.33175915
Encoder Loss:  0.22441283  || Decoder Loss:  0.22623384 Validation Decoder Loss:  0.331069
Encoder Loss:  0.035751823  || Decoder Loss:  0.035544317 Validation Decoder Loss:  0.33096427
Encoder Loss:  0.035740875  || Decoder Loss:  0.0355303 Validation Decoder Loss:  0.33099183
Encoder Loss:  0.03569617  || Decoder Loss:  0.035488103 Validation Decoder Loss:  0.33087796
Encoder Loss:  0.035680734  || Decoder Loss:  0.035461307 Validation Decoder Loss:  0.3308051
Encoder Loss:  0.03562616  || Decoder Loss:  0.03541764 Validation Decoder Loss:  0.33072016
Encoder Loss:  0.035601106  || Decoder Loss:  0.03538884 Validation Decoder Loss:  0.33062956
Encoder Loss:  0.03565568  || Decoder Loss:  0.035447154 Validation Decoder Loss:  0.33075953
Encoder Loss:  0.03570117  || Decoder Loss:  0.035494126 Validation Decoder Loss:  0.330666
Encoder Loss:  0.035618555  || Decoder Loss:  0.035398852 Validation Decoder Loss:  0.33067462
Encoder Loss:  0.035756003  || Decoder Loss:  0.035550315 Validation Decoder Loss:  0.33084202
Encoder Loss:  0.035648912  || Decoder Loss:  0.035441145 Validation Decoder Loss:  0.33073092
Encoder Loss:  0.035594665  || Decoder Loss:  0.03538615 Validation Decoder Loss:  0.33065522
Encoder Loss:  0.035714332  || Decoder Loss:  0.03550659 Validation Decoder Loss:  0.33077013
Encoder Loss:  0.035619516  || Decoder Loss:  0.03540931 Validation Decoder Loss:  0.3306821
Encoder Loss:  0.035600286  || Decoder Loss:  0.035392143 Validation Decoder Loss:  0.3306372
Encoder Loss:  0.035619188  || Decoder Loss:  0.035410594 Validation Decoder Loss:  0.3306518
Encoder Loss:  0.03567262  || Decoder Loss:  0.035464317 Validation Decoder Loss:  0.33094388
Model: siamese_net_lr_0.5228416493374876 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3309439
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_291 (Conv3D (None, 234, 10, 20, 1)    91        
_________________________________________________________________
dropout_642 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_292 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_138 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_644 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_646 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05368415  || Decoder Loss:  0.04725069 Validation Decoder Loss:  0.37070823
Encoder Loss:  0.045376286  || Decoder Loss:  0.04501452 Validation Decoder Loss:  0.36876413
Encoder Loss:  0.044628862  || Decoder Loss:  0.044219896 Validation Decoder Loss:  0.36811903
Encoder Loss:  0.043996047  || Decoder Loss:  0.04354153 Validation Decoder Loss:  0.36697483
Encoder Loss:  0.043283496  || Decoder Loss:  0.042776037 Validation Decoder Loss:  0.36446393
Encoder Loss:  0.039819527  || Decoder Loss:  0.039049823 Validation Decoder Loss:  0.33540356
Encoder Loss:  0.03634081  || Decoder Loss:  0.035309736 Validation Decoder Loss:  0.33486372
Encoder Loss:  0.03631678  || Decoder Loss:  0.035284378 Validation Decoder Loss:  0.33469236
Encoder Loss:  0.036939483  || Decoder Loss:  0.03525428 Validation Decoder Loss:  0.33525908
Encoder Loss:  0.036292937  || Decoder Loss:  0.035231724 Validation Decoder Loss:  0.33489206
Encoder Loss:  0.03623869  || Decoder Loss:  0.035198342 Validation Decoder Loss:  0.33495218
Encoder Loss:  0.036184482  || Decoder Loss:  0.035142023 Validation Decoder Loss:  0.33489776
Encoder Loss:  0.03613411  || Decoder Loss:  0.035082303 Validation Decoder Loss:  0.33458865
Encoder Loss:  0.036091927  || Decoder Loss:  0.035010844 Validation Decoder Loss:  0.33445996
Encoder Loss:  0.0360056  || Decoder Loss:  0.034947496 Validation Decoder Loss:  0.33435178
Encoder Loss:  0.03599334  || Decoder Loss:  0.03488709 Validation Decoder Loss:  0.33410466
Encoder Loss:  0.03584577  || Decoder Loss:  0.03477075 Validation Decoder Loss:  0.33382547
Encoder Loss:  0.035707515  || Decoder Loss:  0.034514718 Validation Decoder Loss:  0.33252767
Encoder Loss:  0.035598125  || Decoder Loss:  0.034355238 Validation Decoder Loss:  0.33130574
Encoder Loss:  0.0354362  || Decoder Loss:  0.034327243 Validation Decoder Loss:  0.33171612
Encoder Loss:  0.035541195  || Decoder Loss:  0.03431969 Validation Decoder Loss:  0.3338579
Encoder Loss:  0.036206104  || Decoder Loss:  0.034919802 Validation Decoder Loss:  0.32966086
Encoder Loss:  0.03591004  || Decoder Loss:  0.034840826 Validation Decoder Loss:  0.3296771
Encoder Loss:  0.035916988  || Decoder Loss:  0.034850024 Validation Decoder Loss:  0.3296426
Encoder Loss:  0.03592107  || Decoder Loss:  0.03485408 Validation Decoder Loss:  0.3298137
Encoder Loss:  0.03592585  || Decoder Loss:  0.034859225 Validation Decoder Loss:  0.32984853
Encoder Loss:  0.035943486  || Decoder Loss:  0.03487901 Validation Decoder Loss:  0.3296525
Encoder Loss:  0.039284036  || Decoder Loss:  0.038471922 Validation Decoder Loss:  0.33161134
Encoder Loss:  0.036850072  || Decoder Loss:  0.035854783 Validation Decoder Loss:  0.33157125
Encoder Loss:  0.03683847  || Decoder Loss:  0.035842653 Validation Decoder Loss:  0.33154157
Encoder Loss:  0.0368261  || Decoder Loss:  0.035829473 Validation Decoder Loss:  0.331506
Encoder Loss:  0.036814116  || Decoder Loss:  0.035816733 Validation Decoder Loss:  0.3314553
Encoder Loss:  0.036800694  || Decoder Loss:  0.03580263 Validation Decoder Loss:  0.33139968
Encoder Loss:  0.036785405  || Decoder Loss:  0.035786405 Validation Decoder Loss:  0.3313559
Encoder Loss:  0.03676789  || Decoder Loss:  0.03576775 Validation Decoder Loss:  0.331286
Encoder Loss:  0.036755186  || Decoder Loss:  0.035754405 Validation Decoder Loss:  0.3312459
Encoder Loss:  0.036737993  || Decoder Loss:  0.035736106 Validation Decoder Loss:  0.33121806
Encoder Loss:  0.036719684  || Decoder Loss:  0.035716616 Validation Decoder Loss:  0.33116716
Encoder Loss:  0.03669762  || Decoder Loss:  0.035693143 Validation Decoder Loss:  0.33125585
Encoder Loss:  0.036676224  || Decoder Loss:  0.0356702 Validation Decoder Loss:  0.33128995
Model: siamese_net_lr_0.30350698950918237 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33128995
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_294 (Conv3D (None, 234, 10, 20, 1)    91        
_________________________________________________________________
dropout_648 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_295 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_139 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_650 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_652 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054108173  || Decoder Loss:  0.048241474 Validation Decoder Loss:  0.3721608
Encoder Loss:  0.04530559  || Decoder Loss:  0.044546887 Validation Decoder Loss:  0.3728598
Encoder Loss:  0.04489052  || Decoder Loss:  0.04410154 Validation Decoder Loss:  0.37308457
Encoder Loss:  0.044678938  || Decoder Loss:  0.043861777 Validation Decoder Loss:  0.37303287
Encoder Loss:  0.044518296  || Decoder Loss:  0.04367559 Validation Decoder Loss:  0.3725271
Encoder Loss:  0.044304103  || Decoder Loss:  0.043427248 Validation Decoder Loss:  0.3709809
Encoder Loss:  0.044466823  || Decoder Loss:  0.042901497 Validation Decoder Loss:  0.36877087
Encoder Loss:  0.038248565  || Decoder Loss:  0.036031183 Validation Decoder Loss:  0.33604527
Encoder Loss:  0.03731001  || Decoder Loss:  0.035362933 Validation Decoder Loss:  0.33621818
Encoder Loss:  0.03728941  || Decoder Loss:  0.035338655 Validation Decoder Loss:  0.336102
Encoder Loss:  0.037269138  || Decoder Loss:  0.03531525 Validation Decoder Loss:  0.33591464
Encoder Loss:  0.03729401  || Decoder Loss:  0.03528863 Validation Decoder Loss:  0.33524436
Encoder Loss:  0.037228208  || Decoder Loss:  0.03526543 Validation Decoder Loss:  0.33481988
Encoder Loss:  0.039426763  || Decoder Loss:  0.03525438 Validation Decoder Loss:  0.32695693
Encoder Loss:  0.049781658  || Decoder Loss:  0.048556942 Validation Decoder Loss:  0.33727312
Encoder Loss:  0.045169972  || Decoder Loss:  0.04441651 Validation Decoder Loss:  0.33977836
Encoder Loss:  0.045088917  || Decoder Loss:  0.044329472 Validation Decoder Loss:  0.34177834
Encoder Loss:  0.044970382  || Decoder Loss:  0.044196043 Validation Decoder Loss:  0.34578097
Encoder Loss:  0.044732127  || Decoder Loss:  0.043922883 Validation Decoder Loss:  0.34532595
Encoder Loss:  0.044158563  || Decoder Loss:  0.043261442 Validation Decoder Loss:  0.34592152
Encoder Loss:  0.044131443  || Decoder Loss:  0.043229904 Validation Decoder Loss:  0.34529072
Encoder Loss:  0.04408952  || Decoder Loss:  0.043181077 Validation Decoder Loss:  0.34505934
Encoder Loss:  0.044195104  || Decoder Loss:  0.043303944 Validation Decoder Loss:  0.34357765
Encoder Loss:  0.044049367  || Decoder Loss:  0.04313561 Validation Decoder Loss:  0.34524608
Encoder Loss:  0.044593815  || Decoder Loss:  0.04376369 Validation Decoder Loss:  0.3434652
Encoder Loss:  0.044252597  || Decoder Loss:  0.0433698 Validation Decoder Loss:  0.34543562
Encoder Loss:  0.044002496  || Decoder Loss:  0.043081407 Validation Decoder Loss:  0.34415054
Encoder Loss:  0.0441537  || Decoder Loss:  0.043256357 Validation Decoder Loss:  0.34174484
Encoder Loss:  0.04502257  || Decoder Loss:  0.044256344 Validation Decoder Loss:  0.34175992
Encoder Loss:  0.044932827  || Decoder Loss:  0.044046167 Validation Decoder Loss:  0.3525451
Encoder Loss:  0.04453104  || Decoder Loss:  0.043107543 Validation Decoder Loss:  0.34536904
Encoder Loss:  0.044028014  || Decoder Loss:  0.043111034 Validation Decoder Loss:  0.34540853
Encoder Loss:  0.044023562  || Decoder Loss:  0.043106236 Validation Decoder Loss:  0.34575635
Encoder Loss:  0.04493497  || Decoder Loss:  0.044149738 Validation Decoder Loss:  0.33976272
Encoder Loss:  0.045183677  || Decoder Loss:  0.044439983 Validation Decoder Loss:  0.34116942
Encoder Loss:  0.04579839  || Decoder Loss:  0.044389635 Validation Decoder Loss:  0.34195006
Encoder Loss:  0.045546424  || Decoder Loss:  0.04461489 Validation Decoder Loss:  0.3502484
Encoder Loss:  0.044420153  || Decoder Loss:  0.04356211 Validation Decoder Loss:  0.34445924
Encoder Loss:  0.044214148  || Decoder Loss:  0.043326214 Validation Decoder Loss:  0.34466246
Encoder Loss:  0.04416631  || Decoder Loss:  0.043271035 Validation Decoder Loss:  0.34328705
Model: siamese_net_lr_0.31262420872632085 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34328705
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_297 (Conv3D (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_654 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_298 (Conv3D (None, 257, 10, 20, 1)    18        
_________________________________________________________________
reshape_140 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 135
Trainable params: 135
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_500"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_656 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_658 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23424025  || Decoder Loss:  0.4969827 Validation Decoder Loss:  1.0070632
Encoder Loss:  0.23055397  || Decoder Loss:  0.4972822 Validation Decoder Loss:  1.0122571
Encoder Loss:  0.23060657  || Decoder Loss:  0.49601448 Validation Decoder Loss:  1.0051389
Encoder Loss:  0.22835696  || Decoder Loss:  0.4953402 Validation Decoder Loss:  1.0824893
Encoder Loss:  0.22737342  || Decoder Loss:  0.49142066 Validation Decoder Loss:  0.982718
Encoder Loss:  0.2209934  || Decoder Loss:  0.47691247 Validation Decoder Loss:  0.88361347
Encoder Loss:  0.084943645  || Decoder Loss:  0.13445273 Validation Decoder Loss:  0.3615061
Encoder Loss:  0.05312526  || Decoder Loss:  0.05608932 Validation Decoder Loss:  0.340383
Encoder Loss:  0.05329432  || Decoder Loss:  0.058014166 Validation Decoder Loss:  0.34069252
Encoder Loss:  0.047060866  || Decoder Loss:  0.042298827 Validation Decoder Loss:  0.3479633
Encoder Loss:  0.048318747  || Decoder Loss:  0.04535804 Validation Decoder Loss:  0.33636877
Encoder Loss:  0.047181714  || Decoder Loss:  0.042717684 Validation Decoder Loss:  0.33801547
Encoder Loss:  0.046716448  || Decoder Loss:  0.04150553 Validation Decoder Loss:  0.3377477
Encoder Loss:  0.046353307  || Decoder Loss:  0.040498886 Validation Decoder Loss:  0.33332634
Encoder Loss:  0.046972945  || Decoder Loss:  0.042271696 Validation Decoder Loss:  0.33195767
Encoder Loss:  0.04624179  || Decoder Loss:  0.04039529 Validation Decoder Loss:  0.33476353
Encoder Loss:  0.045259982  || Decoder Loss:  0.03801912 Validation Decoder Loss:  0.3329558
Encoder Loss:  0.04526137  || Decoder Loss:  0.03804524 Validation Decoder Loss:  0.33130276
Encoder Loss:  0.045065604  || Decoder Loss:  0.037545815 Validation Decoder Loss:  0.3336197
Encoder Loss:  0.0460427  || Decoder Loss:  0.039750785 Validation Decoder Loss:  0.34700495
Encoder Loss:  0.055655524  || Decoder Loss:  0.0634436 Validation Decoder Loss:  0.33624634
Encoder Loss:  0.045929402  || Decoder Loss:  0.039752055 Validation Decoder Loss:  0.33144838
Encoder Loss:  0.045680776  || Decoder Loss:  0.03910939 Validation Decoder Loss:  0.33346236
Encoder Loss:  0.04558587  || Decoder Loss:  0.03887432 Validation Decoder Loss:  0.33178198
Encoder Loss:  0.04563998  || Decoder Loss:  0.039003685 Validation Decoder Loss:  0.33340913
Encoder Loss:  0.045356847  || Decoder Loss:  0.03828355 Validation Decoder Loss:  0.33433762
Encoder Loss:  0.045376875  || Decoder Loss:  0.03836825 Validation Decoder Loss:  0.3320263
Encoder Loss:  0.04552198  || Decoder Loss:  0.038708463 Validation Decoder Loss:  0.33212897
Encoder Loss:  0.04468937  || Decoder Loss:  0.036647826 Validation Decoder Loss:  0.33120897
Encoder Loss:  0.067318924  || Decoder Loss:  0.09253942 Validation Decoder Loss:  0.3364937
Encoder Loss:  0.045856323  || Decoder Loss:  0.039582834 Validation Decoder Loss:  0.33725697
Encoder Loss:  0.04705502  || Decoder Loss:  0.0425669 Validation Decoder Loss:  0.33658904
Encoder Loss:  0.046320472  || Decoder Loss:  0.04071316 Validation Decoder Loss:  0.33652273
Encoder Loss:  0.045845427  || Decoder Loss:  0.039537426 Validation Decoder Loss:  0.33564913
Encoder Loss:  0.046159305  || Decoder Loss:  0.04032901 Validation Decoder Loss:  0.3371117
Encoder Loss:  0.046037782  || Decoder Loss:  0.040027153 Validation Decoder Loss:  0.33664846
Encoder Loss:  0.045611717  || Decoder Loss:  0.038962625 Validation Decoder Loss:  0.3370232
Encoder Loss:  0.045342084  || Decoder Loss:  0.038284637 Validation Decoder Loss:  0.33416283
Encoder Loss:  0.04562443  || Decoder Loss:  0.03899618 Validation Decoder Loss:  0.33868432
Encoder Loss:  0.045776464  || Decoder Loss:  0.039386228 Validation Decoder Loss:  0.3350528
Model: siamese_net_lr_0.3854107964610956 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33505276
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_300 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_660 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_301 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_141 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_662 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 2600, 20, 1)       32        
_________________________________________________________________
dropout_664 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 2607, 20, 1)       9         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23172306  || Decoder Loss:  0.48393905 Validation Decoder Loss:  0.99845195
Encoder Loss:  0.2335733  || Decoder Loss:  0.5004439 Validation Decoder Loss:  0.99989945
Encoder Loss:  0.23125306  || Decoder Loss:  0.4998146 Validation Decoder Loss:  1.0004134
Encoder Loss:  0.23088787  || Decoder Loss:  0.4971245 Validation Decoder Loss:  0.99665767
Encoder Loss:  0.23047572  || Decoder Loss:  0.4974639 Validation Decoder Loss:  0.9985306
Encoder Loss:  0.22775753  || Decoder Loss:  0.49054337 Validation Decoder Loss:  0.97572243
Encoder Loss:  0.05685958  || Decoder Loss:  0.06688111 Validation Decoder Loss:  0.33325744
Encoder Loss:  0.04447671  || Decoder Loss:  0.036177523 Validation Decoder Loss:  0.3403672
Encoder Loss:  0.102072135  || Decoder Loss:  0.17806515 Validation Decoder Loss:  0.33401105
Encoder Loss:  0.045302227  || Decoder Loss:  0.03770059 Validation Decoder Loss:  0.33273983
Encoder Loss:  0.044425182  || Decoder Loss:  0.0360608 Validation Decoder Loss:  0.33286917
Encoder Loss:  0.044457242  || Decoder Loss:  0.036178593 Validation Decoder Loss:  0.33155382
Encoder Loss:  0.044753928  || Decoder Loss:  0.03686331 Validation Decoder Loss:  0.33995798
Encoder Loss:  0.099024504  || Decoder Loss:  0.16180736 Validation Decoder Loss:  0.37146965
Encoder Loss:  0.047544938  || Decoder Loss:  0.04336536 Validation Decoder Loss:  0.3451032
Encoder Loss:  0.04587056  || Decoder Loss:  0.039157867 Validation Decoder Loss:  0.3332994
Encoder Loss:  0.04639704  || Decoder Loss:  0.040719185 Validation Decoder Loss:  0.33342707
Encoder Loss:  0.045701403  || Decoder Loss:  0.039209254 Validation Decoder Loss:  0.33393437
Encoder Loss:  0.045456  || Decoder Loss:  0.038632616 Validation Decoder Loss:  0.33740184
Encoder Loss:  0.045388047  || Decoder Loss:  0.038468234 Validation Decoder Loss:  0.3326345
Encoder Loss:  0.044820756  || Decoder Loss:  0.03706933 Validation Decoder Loss:  0.3367699
Encoder Loss:  0.045495223  || Decoder Loss:  0.038734455 Validation Decoder Loss:  0.34580588
Encoder Loss:  0.06575604  || Decoder Loss:  0.08884925 Validation Decoder Loss:  0.33943477
Encoder Loss:  0.044894915  || Decoder Loss:  0.037288643 Validation Decoder Loss:  0.34105045
Encoder Loss:  0.045083646  || Decoder Loss:  0.037742473 Validation Decoder Loss:  0.33055735
Encoder Loss:  0.047941715  || Decoder Loss:  0.04481142 Validation Decoder Loss:  0.33547634
Encoder Loss:  0.04508934  || Decoder Loss:  0.037740503 Validation Decoder Loss:  0.34324148
Encoder Loss:  0.04475619  || Decoder Loss:  0.03691567 Validation Decoder Loss:  0.35505456
Encoder Loss:  0.045710973  || Decoder Loss:  0.039261755 Validation Decoder Loss:  0.3393716
Encoder Loss:  0.044900075  || Decoder Loss:  0.037291065 Validation Decoder Loss:  0.36014047
Encoder Loss:  0.06685619  || Decoder Loss:  0.0910744 Validation Decoder Loss:  0.33474374
Encoder Loss:  0.045036875  || Decoder Loss:  0.037664223 Validation Decoder Loss:  0.33857313
Encoder Loss:  0.0449983  || Decoder Loss:  0.037562024 Validation Decoder Loss:  0.33416793
Encoder Loss:  0.045178037  || Decoder Loss:  0.038002636 Validation Decoder Loss:  0.33631927
Encoder Loss:  0.057685018  || Decoder Loss:  0.068990946 Validation Decoder Loss:  0.33445004
Encoder Loss:  0.044923663  || Decoder Loss:  0.037366003 Validation Decoder Loss:  0.33624128
Encoder Loss:  0.04457177  || Decoder Loss:  0.036489177 Validation Decoder Loss:  0.33730197
Encoder Loss:  0.04540745  || Decoder Loss:  0.03855338 Validation Decoder Loss:  0.3424315
Encoder Loss:  0.06939118  || Decoder Loss:  0.096876204 Validation Decoder Loss:  0.33360437
Encoder Loss:  0.045225415  || Decoder Loss:  0.038127333 Validation Decoder Loss:  0.33287394
Model: siamese_net_lr_0.3637702443172197 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33287394
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_303 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_666 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_304 (Conv3D (None, 257, 10, 20, 1)    346       
_________________________________________________________________
reshape_142 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 411
Trainable params: 411
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_668 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_670 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14027165  || Decoder Loss:  0.17474268 Validation Decoder Loss:  1.2956231
Encoder Loss:  0.20934707  || Decoder Loss:  0.5231784 Validation Decoder Loss:  1.0057237
Encoder Loss:  0.19898567  || Decoder Loss:  0.4988091 Validation Decoder Loss:  1.0057274
Encoder Loss:  0.19884552  || Decoder Loss:  0.4983191 Validation Decoder Loss:  1.0057695
Encoder Loss:  0.19786312  || Decoder Loss:  0.49784485 Validation Decoder Loss:  1.0030067
Encoder Loss:  0.1976672  || Decoder Loss:  0.49787334 Validation Decoder Loss:  1.0030743
Encoder Loss:  0.19734623  || Decoder Loss:  0.49743828 Validation Decoder Loss:  1.0021746
Encoder Loss:  0.19701105  || Decoder Loss:  0.4967721 Validation Decoder Loss:  1.0021633
Encoder Loss:  0.1967894  || Decoder Loss:  0.49621928 Validation Decoder Loss:  1.0006217
Encoder Loss:  0.19651252  || Decoder Loss:  0.4953523 Validation Decoder Loss:  0.99979186
Encoder Loss:  0.19604301  || Decoder Loss:  0.49392343 Validation Decoder Loss:  0.99765503
Encoder Loss:  0.19504303  || Decoder Loss:  0.4909443 Validation Decoder Loss:  0.99128604
Encoder Loss:  0.19223313  || Decoder Loss:  0.482285 Validation Decoder Loss:  0.9597765
Encoder Loss:  0.11419058  || Decoder Loss:  0.24459976 Validation Decoder Loss:  0.3083229
Encoder Loss:  0.048504304  || Decoder Loss:  0.044649124 Validation Decoder Loss:  0.33752465
Encoder Loss:  0.046302255  || Decoder Loss:  0.0360899 Validation Decoder Loss:  0.32975256
Encoder Loss:  0.04719027  || Decoder Loss:  0.036000423 Validation Decoder Loss:  0.32873374
Encoder Loss:  0.04798026  || Decoder Loss:  0.035857398 Validation Decoder Loss:  0.33792666
Encoder Loss:  0.045599107  || Decoder Loss:  0.03577721 Validation Decoder Loss:  0.3371156
Encoder Loss:  0.0454344  || Decoder Loss:  0.035765275 Validation Decoder Loss:  0.33220923
Encoder Loss:  0.045375437  || Decoder Loss:  0.035673548 Validation Decoder Loss:  0.33558318
Encoder Loss:  0.045338277  || Decoder Loss:  0.035663825 Validation Decoder Loss:  0.33443418
Encoder Loss:  0.045326363  || Decoder Loss:  0.03567441 Validation Decoder Loss:  0.33514607
Encoder Loss:  0.04532882  || Decoder Loss:  0.035686508 Validation Decoder Loss:  0.33549833
Encoder Loss:  0.045322303  || Decoder Loss:  0.035670385 Validation Decoder Loss:  0.33571607
Encoder Loss:  0.045332596  || Decoder Loss:  0.035659667 Validation Decoder Loss:  0.3362993
Encoder Loss:  0.045351952  || Decoder Loss:  0.035696078 Validation Decoder Loss:  0.33705026
Encoder Loss:  0.04532371  || Decoder Loss:  0.0356532 Validation Decoder Loss:  0.33604002
Encoder Loss:  0.045329798  || Decoder Loss:  0.035668958 Validation Decoder Loss:  0.33529633
Encoder Loss:  0.045326732  || Decoder Loss:  0.035656966 Validation Decoder Loss:  0.3360446
Encoder Loss:  0.04534407  || Decoder Loss:  0.03567718 Validation Decoder Loss:  0.3354379
Encoder Loss:  0.045326374  || Decoder Loss:  0.035654534 Validation Decoder Loss:  0.33520085
Encoder Loss:  0.04532984  || Decoder Loss:  0.03566613 Validation Decoder Loss:  0.33563673
Encoder Loss:  0.04541211  || Decoder Loss:  0.03570008 Validation Decoder Loss:  0.33376396
Encoder Loss:  0.045445886  || Decoder Loss:  0.03567225 Validation Decoder Loss:  0.3362558
Encoder Loss:  0.04532509  || Decoder Loss:  0.035700228 Validation Decoder Loss:  0.33411926
Encoder Loss:  0.045314003  || Decoder Loss:  0.035662707 Validation Decoder Loss:  0.33492038
Encoder Loss:  0.04533834  || Decoder Loss:  0.035659768 Validation Decoder Loss:  0.33395624
Encoder Loss:  0.045364905  || Decoder Loss:  0.035677396 Validation Decoder Loss:  0.33709222
Encoder Loss:  0.04532475  || Decoder Loss:  0.035664424 Validation Decoder Loss:  0.33444196
Model: siamese_net_lr_0.26737507620992756 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33444196
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_306 (Conv3D (None, 156, 10, 20, 1)    61        
_________________________________________________________________
dropout_672 (Dropout)        (None, 156, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_307 (Conv3D (None, 257, 10, 20, 1)    103       
_________________________________________________________________
reshape_143 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 164
Trainable params: 164
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_512"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_674 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_676 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30033857  || Decoder Loss:  0.26665747 Validation Decoder Loss:  1.5851338
Encoder Loss:  0.34109107  || Decoder Loss:  0.54987407 Validation Decoder Loss:  0.9924331
Encoder Loss:  0.27756348  || Decoder Loss:  0.501959 Validation Decoder Loss:  0.995974
Encoder Loss:  0.2799527  || Decoder Loss:  0.5017905 Validation Decoder Loss:  1.0026796
Encoder Loss:  0.27658784  || Decoder Loss:  0.5025494 Validation Decoder Loss:  0.9982468
Encoder Loss:  0.27229905  || Decoder Loss:  0.5009961 Validation Decoder Loss:  1.0034549
Encoder Loss:  0.26996887  || Decoder Loss:  0.5007443 Validation Decoder Loss:  1.0036
Encoder Loss:  0.26977944  || Decoder Loss:  0.50067425 Validation Decoder Loss:  1.0032754
Encoder Loss:  0.26975197  || Decoder Loss:  0.5006119 Validation Decoder Loss:  1.002868
Encoder Loss:  0.26970404  || Decoder Loss:  0.5005265 Validation Decoder Loss:  1.002651
Encoder Loss:  0.26965165  || Decoder Loss:  0.50044596 Validation Decoder Loss:  1.0022985
Encoder Loss:  0.26960778  || Decoder Loss:  0.5003313 Validation Decoder Loss:  1.0019879
Encoder Loss:  0.2695136  || Decoder Loss:  0.5001607 Validation Decoder Loss:  1.001609
Encoder Loss:  0.26928794  || Decoder Loss:  0.4996773 Validation Decoder Loss:  0.998388
Encoder Loss:  0.26859888  || Decoder Loss:  0.49820223 Validation Decoder Loss:  0.9984573
Encoder Loss:  0.2687811  || Decoder Loss:  0.49846685 Validation Decoder Loss:  0.99966836
Encoder Loss:  0.26498246  || Decoder Loss:  0.4907771 Validation Decoder Loss:  0.9840549
Encoder Loss:  0.22761458  || Decoder Loss:  0.4141689 Validation Decoder Loss:  0.50406915
Encoder Loss:  0.107991606  || Decoder Loss:  0.16887291 Validation Decoder Loss:  0.35226387
Encoder Loss:  0.05015252  || Decoder Loss:  0.050150562 Validation Decoder Loss:  0.33113694
Encoder Loss:  0.043266125  || Decoder Loss:  0.03592609 Validation Decoder Loss:  0.33212686
Encoder Loss:  0.04316773  || Decoder Loss:  0.035898704 Validation Decoder Loss:  0.3323785
Encoder Loss:  0.04316839  || Decoder Loss:  0.03590073 Validation Decoder Loss:  0.33211058
Encoder Loss:  0.043180298  || Decoder Loss:  0.035902157 Validation Decoder Loss:  0.330683
Encoder Loss:  0.04321804  || Decoder Loss:  0.035929337 Validation Decoder Loss:  0.33151618
Encoder Loss:  0.043187  || Decoder Loss:  0.035908457 Validation Decoder Loss:  0.33229092
Encoder Loss:  0.04321108  || Decoder Loss:  0.035907242 Validation Decoder Loss:  0.33226788
Encoder Loss:  0.043149658  || Decoder Loss:  0.035880934 Validation Decoder Loss:  0.33097723
Encoder Loss:  0.043150954  || Decoder Loss:  0.03589095 Validation Decoder Loss:  0.3302285
Encoder Loss:  0.043212753  || Decoder Loss:  0.035889894 Validation Decoder Loss:  0.33114493
Encoder Loss:  0.04369944  || Decoder Loss:  0.036021322 Validation Decoder Loss:  0.33357266
Encoder Loss:  0.043562382  || Decoder Loss:  0.03593443 Validation Decoder Loss:  0.33896586
Encoder Loss:  0.04320872  || Decoder Loss:  0.035912637 Validation Decoder Loss:  0.33186287
Encoder Loss:  0.043126035  || Decoder Loss:  0.035869304 Validation Decoder Loss:  0.33202094
Encoder Loss:  0.043139864  || Decoder Loss:  0.035884727 Validation Decoder Loss:  0.33206803
Encoder Loss:  0.043244172  || Decoder Loss:  0.036019366 Validation Decoder Loss:  0.3345803
Encoder Loss:  0.043141957  || Decoder Loss:  0.035879847 Validation Decoder Loss:  0.33226293
Encoder Loss:  0.043224744  || Decoder Loss:  0.03594092 Validation Decoder Loss:  0.33135128
Encoder Loss:  0.044368815  || Decoder Loss:  0.037942115 Validation Decoder Loss:  0.32941073
Encoder Loss:  0.043889366  || Decoder Loss:  0.036601596 Validation Decoder Loss:  0.33497417
Model: siamese_net_lr_0.8335495435856535 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33497417
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_309 (Conv3D (None, 104, 5, 20, 1)     42        
_________________________________________________________________
dropout_678 (Dropout)        (None, 104, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_310 (Conv3D (None, 257, 10, 20, 1)    925       
_________________________________________________________________
reshape_144 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 967
Trainable params: 967
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_680 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_682 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41957656  || Decoder Loss:  0.48720807 Validation Decoder Loss:  0.9967811
Encoder Loss:  0.41875106  || Decoder Loss:  0.49945346 Validation Decoder Loss:  1.1260073
Encoder Loss:  0.41832742  || Decoder Loss:  0.49919757 Validation Decoder Loss:  1.1176302
Encoder Loss:  0.41901463  || Decoder Loss:  0.50020736 Validation Decoder Loss:  1.1130775
Encoder Loss:  0.41837612  || Decoder Loss:  0.49950203 Validation Decoder Loss:  1.1311996
Encoder Loss:  0.41905677  || Decoder Loss:  0.5004082 Validation Decoder Loss:  1.0019768
Encoder Loss:  0.41916993  || Decoder Loss:  0.5006228 Validation Decoder Loss:  1.0922822
Encoder Loss:  0.41842583  || Decoder Loss:  0.4996895 Validation Decoder Loss:  1.1181974
Encoder Loss:  0.41849923  || Decoder Loss:  0.4996511 Validation Decoder Loss:  0.9665134
Encoder Loss:  0.41854706  || Decoder Loss:  0.49997312 Validation Decoder Loss:  1.0596725
Encoder Loss:  0.41796094  || Decoder Loss:  0.49912265 Validation Decoder Loss:  1.0176063
Encoder Loss:  0.41820726  || Decoder Loss:  0.49946985 Validation Decoder Loss:  0.9259508
Encoder Loss:  0.4160112  || Decoder Loss:  0.4965867 Validation Decoder Loss:  1.0219052
Encoder Loss:  0.41757083  || Decoder Loss:  0.49868244 Validation Decoder Loss:  1.088388
Encoder Loss:  0.41335434  || Decoder Loss:  0.49361867 Validation Decoder Loss:  1.0142503
Encoder Loss:  0.41765648  || Decoder Loss:  0.49895576 Validation Decoder Loss:  0.9454019
Encoder Loss:  0.4179098  || Decoder Loss:  0.49921647 Validation Decoder Loss:  1.039706
Encoder Loss:  0.41801617  || Decoder Loss:  0.49931476 Validation Decoder Loss:  0.9391944
Encoder Loss:  0.41798317  || Decoder Loss:  0.49936345 Validation Decoder Loss:  0.9872747
Encoder Loss:  0.4175659  || Decoder Loss:  0.49891552 Validation Decoder Loss:  0.97543675
Encoder Loss:  0.41743374  || Decoder Loss:  0.4987586 Validation Decoder Loss:  0.9582697
Encoder Loss:  0.41738302  || Decoder Loss:  0.4986636 Validation Decoder Loss:  0.98010004
Encoder Loss:  0.41682544  || Decoder Loss:  0.49790505 Validation Decoder Loss:  1.0370455
Encoder Loss:  0.41724345  || Decoder Loss:  0.4983497 Validation Decoder Loss:  1.0031004
Encoder Loss:  0.41673577  || Decoder Loss:  0.4978207 Validation Decoder Loss:  0.9674411
Encoder Loss:  0.41619602  || Decoder Loss:  0.49722525 Validation Decoder Loss:  0.9517927
Encoder Loss:  0.4155162  || Decoder Loss:  0.49640626 Validation Decoder Loss:  0.96732765
Encoder Loss:  0.40899253  || Decoder Loss:  0.48835263 Validation Decoder Loss:  1.0492837
Encoder Loss:  0.3969688  || Decoder Loss:  0.47374013 Validation Decoder Loss:  1.0787938
Encoder Loss:  0.39584258  || Decoder Loss:  0.47240683 Validation Decoder Loss:  1.0842966
Encoder Loss:  0.39566094  || Decoder Loss:  0.47217774 Validation Decoder Loss:  1.0825065
Encoder Loss:  0.39571202  || Decoder Loss:  0.4721986 Validation Decoder Loss:  1.0819006
Encoder Loss:  0.39532644  || Decoder Loss:  0.4717031 Validation Decoder Loss:  1.1090322
Encoder Loss:  0.39602172  || Decoder Loss:  0.4724418 Validation Decoder Loss:  1.0834618
Encoder Loss:  0.39583945  || Decoder Loss:  0.47223666 Validation Decoder Loss:  1.0771275
Encoder Loss:  0.39574552  || Decoder Loss:  0.4722166 Validation Decoder Loss:  1.0781274
Encoder Loss:  0.39542553  || Decoder Loss:  0.47172794 Validation Decoder Loss:  1.0386238
Encoder Loss:  0.39603642  || Decoder Loss:  0.47235286 Validation Decoder Loss:  1.0580434
Encoder Loss:  0.39571077  || Decoder Loss:  0.47190085 Validation Decoder Loss:  1.0910836
Encoder Loss:  0.3950499  || Decoder Loss:  0.47136974 Validation Decoder Loss:  1.0775723
Model: siamese_net_lr_0.7977417044907305 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0775723
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_312 (Conv3D (None, 121, 10, 20, 1)    117       
_________________________________________________________________
dropout_684 (Dropout)        (None, 121, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_313 (Conv3D (None, 257, 10, 20, 1)    18        
_________________________________________________________________
reshape_145 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 135
Trainable params: 135
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_686 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_688 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45233607  || Decoder Loss:  0.49360222 Validation Decoder Loss:  1.0097399
Encoder Loss:  0.44853893  || Decoder Loss:  0.4904172 Validation Decoder Loss:  1.0064521
Encoder Loss:  0.14167811  || Decoder Loss:  0.15130201 Validation Decoder Loss:  0.33188093
Encoder Loss:  0.15605223  || Decoder Loss:  0.16706449 Validation Decoder Loss:  0.33226213
Encoder Loss:  0.03705794  || Decoder Loss:  0.03566076 Validation Decoder Loss:  0.33161396
Encoder Loss:  0.037049536  || Decoder Loss:  0.03566051 Validation Decoder Loss:  0.33199656
Encoder Loss:  0.037090708  || Decoder Loss:  0.03571186 Validation Decoder Loss:  0.3318757
Encoder Loss:  0.036989428  || Decoder Loss:  0.035606824 Validation Decoder Loss:  0.33339524
Encoder Loss:  0.037008945  || Decoder Loss:  0.03563123 Validation Decoder Loss:  0.3316684
Encoder Loss:  0.036880903  || Decoder Loss:  0.03549367 Validation Decoder Loss:  0.33248544
Encoder Loss:  0.03688059  || Decoder Loss:  0.035492074 Validation Decoder Loss:  0.33290458
Encoder Loss:  0.037011355  || Decoder Loss:  0.035637595 Validation Decoder Loss:  0.33366832
Encoder Loss:  0.036926396  || Decoder Loss:  0.035544943 Validation Decoder Loss:  0.33183408
Encoder Loss:  0.036964078  || Decoder Loss:  0.03558558 Validation Decoder Loss:  0.33139944
Encoder Loss:  0.03704321  || Decoder Loss:  0.03567432 Validation Decoder Loss:  0.33200592
Encoder Loss:  0.037070084  || Decoder Loss:  0.035705067 Validation Decoder Loss:  0.33238435
Encoder Loss:  0.03694108  || Decoder Loss:  0.035561156 Validation Decoder Loss:  0.33187652
Encoder Loss:  0.03688229  || Decoder Loss:  0.035496905 Validation Decoder Loss:  0.33080018
Encoder Loss:  0.037322126  || Decoder Loss:  0.035983503 Validation Decoder Loss:  0.33262575
Encoder Loss:  0.03684147  || Decoder Loss:  0.03545269 Validation Decoder Loss:  0.33238125
Encoder Loss:  0.036834326  || Decoder Loss:  0.035445888 Validation Decoder Loss:  0.33099964
Encoder Loss:  0.036994945  || Decoder Loss:  0.035621516 Validation Decoder Loss:  0.33091003
Encoder Loss:  0.036856666  || Decoder Loss:  0.03547038 Validation Decoder Loss:  0.33083838
Encoder Loss:  0.03694264  || Decoder Loss:  0.03555603 Validation Decoder Loss:  0.33077425
Encoder Loss:  0.03687762  || Decoder Loss:  0.03549496 Validation Decoder Loss:  0.33073986
Encoder Loss:  0.037497833  || Decoder Loss:  0.036179963 Validation Decoder Loss:  0.33063304
Encoder Loss:  0.036829296  || Decoder Loss:  0.035440605 Validation Decoder Loss:  0.3312505
Encoder Loss:  0.03686242  || Decoder Loss:  0.03547615 Validation Decoder Loss:  0.33139205
Encoder Loss:  0.036826707  || Decoder Loss:  0.03543698 Validation Decoder Loss:  0.33075762
Encoder Loss:  0.0368355  || Decoder Loss:  0.03544759 Validation Decoder Loss:  0.3307681
Encoder Loss:  0.036898144  || Decoder Loss:  0.03551622 Validation Decoder Loss:  0.33065075
Encoder Loss:  0.03738237  || Decoder Loss:  0.036050964 Validation Decoder Loss:  0.33064836
Encoder Loss:  0.03685216  || Decoder Loss:  0.035465654 Validation Decoder Loss:  0.33066198
Encoder Loss:  0.03697372  || Decoder Loss:  0.03560042 Validation Decoder Loss:  0.33085424
Encoder Loss:  0.03682235  || Decoder Loss:  0.03543284 Validation Decoder Loss:  0.3306386
Encoder Loss:  0.03686282  || Decoder Loss:  0.035477992 Validation Decoder Loss:  0.33054423
Encoder Loss:  0.03691792  || Decoder Loss:  0.035538968 Validation Decoder Loss:  0.3307347
Encoder Loss:  0.03688734  || Decoder Loss:  0.035504837 Validation Decoder Loss:  0.33056343
Encoder Loss:  0.036949478  || Decoder Loss:  0.035573184 Validation Decoder Loss:  0.33080113
Encoder Loss:  0.03743051  || Decoder Loss:  0.036105815 Validation Decoder Loss:  0.33083177
Model: siamese_net_lr_0.350970109441083 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33083177
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_315 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_690 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_316 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_146 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 150
Trainable params: 150
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_692 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_694 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4804474  || Decoder Loss:  0.51717544 Validation Decoder Loss:  0.99749887
Encoder Loss:  0.46472016  || Decoder Loss:  0.50127405 Validation Decoder Loss:  0.99855566
Encoder Loss:  0.4645221  || Decoder Loss:  0.5011971 Validation Decoder Loss:  0.9985937
Encoder Loss:  0.46448717  || Decoder Loss:  0.5011595 Validation Decoder Loss:  0.9986456
Encoder Loss:  0.46445176  || Decoder Loss:  0.5011209 Validation Decoder Loss:  0.9987006
Encoder Loss:  0.4644127  || Decoder Loss:  0.50107855 Validation Decoder Loss:  0.9987331
Encoder Loss:  0.46432006  || Decoder Loss:  0.5009781 Validation Decoder Loss:  0.9979688
Encoder Loss:  0.46203694  || Decoder Loss:  0.49849337 Validation Decoder Loss:  1.001042
Encoder Loss:  0.46242213  || Decoder Loss:  0.49891195 Validation Decoder Loss:  1.0008757
Encoder Loss:  0.46247262  || Decoder Loss:  0.49897143 Validation Decoder Loss:  0.9834728
Encoder Loss:  0.45773372  || Decoder Loss:  0.4917115 Validation Decoder Loss:  1.003339
Encoder Loss:  0.4608989  || Decoder Loss:  0.49722713 Validation Decoder Loss:  1.0032465
Encoder Loss:  0.46091133  || Decoder Loss:  0.4972346 Validation Decoder Loss:  1.0036438
Encoder Loss:  0.46081826  || Decoder Loss:  0.49712893 Validation Decoder Loss:  1.0031645
Encoder Loss:  0.46077287  || Decoder Loss:  0.49707398 Validation Decoder Loss:  1.0031211
Encoder Loss:  0.46058738  || Decoder Loss:  0.4968707 Validation Decoder Loss:  1.0014024
Encoder Loss:  0.45472223  || Decoder Loss:  0.49049217 Validation Decoder Loss:  0.8581667
Encoder Loss:  0.089565426  || Decoder Loss:  0.0930111 Validation Decoder Loss:  0.3438903
Encoder Loss:  0.06718361  || Decoder Loss:  0.06868043 Validation Decoder Loss:  0.3265745
Encoder Loss:  0.040157393  || Decoder Loss:  0.039280448 Validation Decoder Loss:  0.3203454
Encoder Loss:  0.04176482  || Decoder Loss:  0.041027866 Validation Decoder Loss:  0.3261147
Encoder Loss:  0.04077152  || Decoder Loss:  0.03994828 Validation Decoder Loss:  0.3298689
Encoder Loss:  0.036747254  || Decoder Loss:  0.035572883 Validation Decoder Loss:  0.3299091
Encoder Loss:  0.04150175  || Decoder Loss:  0.04074168 Validation Decoder Loss:  0.330957
Encoder Loss:  0.036790602  || Decoder Loss:  0.035619546 Validation Decoder Loss:  0.33120516
Encoder Loss:  0.036722366  || Decoder Loss:  0.03554679 Validation Decoder Loss:  0.3304549
Encoder Loss:  0.03670985  || Decoder Loss:  0.035533186 Validation Decoder Loss:  0.33011684
Encoder Loss:  0.03900213  || Decoder Loss:  0.03802854 Validation Decoder Loss:  0.33149505
Encoder Loss:  0.036757544  || Decoder Loss:  0.0355855 Validation Decoder Loss:  0.33221325
Encoder Loss:  0.036921438  || Decoder Loss:  0.035763163 Validation Decoder Loss:  0.33180088
Encoder Loss:  0.036852457  || Decoder Loss:  0.035688993 Validation Decoder Loss:  0.3307557
Encoder Loss:  0.036761962  || Decoder Loss:  0.035590507 Validation Decoder Loss:  0.33087718
Encoder Loss:  0.036667712  || Decoder Loss:  0.03548793 Validation Decoder Loss:  0.32950565
Encoder Loss:  0.036575664  || Decoder Loss:  0.03538758 Validation Decoder Loss:  0.32856303
Encoder Loss:  0.070464134  || Decoder Loss:  0.07227459 Validation Decoder Loss:  0.99983346
Encoder Loss:  0.46008876  || Decoder Loss:  0.49637222 Validation Decoder Loss:  0.9988124
Encoder Loss:  0.45914498  || Decoder Loss:  0.4953455 Validation Decoder Loss:  1.0000614
Encoder Loss:  0.4604743  || Decoder Loss:  0.49679202 Validation Decoder Loss:  0.9990325
Encoder Loss:  0.45753384  || Decoder Loss:  0.49359185 Validation Decoder Loss:  0.9948392
Encoder Loss:  0.4632933  || Decoder Loss:  0.49986088 Validation Decoder Loss:  0.9939028
Model: siamese_net_lr_0.41243340595401445 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9939028
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_318 (Conv3D (None, 234, 10, 20, 1)    1027      
_________________________________________________________________
dropout_696 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_319 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_147 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,052
Trainable params: 1,052
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_698 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_700 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2669849  || Decoder Loss:  0.4421607 Validation Decoder Loss:  1.1226981
Encoder Loss:  0.29270622  || Decoder Loss:  0.49601048 Validation Decoder Loss:  0.9044943
Encoder Loss:  0.2819986  || Decoder Loss:  0.4763374 Validation Decoder Loss:  0.70066524
Encoder Loss:  0.06599393  || Decoder Loss:  0.07938567 Validation Decoder Loss:  0.32381016
Encoder Loss:  0.043491725  || Decoder Loss:  0.03803505 Validation Decoder Loss:  0.32543382
Encoder Loss:  0.043159887  || Decoder Loss:  0.037427265 Validation Decoder Loss:  0.3257076
Encoder Loss:  0.043010063  || Decoder Loss:  0.03715144 Validation Decoder Loss:  0.32562327
Encoder Loss:  0.042920876  || Decoder Loss:  0.036985926 Validation Decoder Loss:  0.32588333
Encoder Loss:  0.042823516  || Decoder Loss:  0.036807682 Validation Decoder Loss:  0.32532865
Encoder Loss:  0.04274781  || Decoder Loss:  0.036669787 Validation Decoder Loss:  0.3283952
Encoder Loss:  0.04279012  || Decoder Loss:  0.03674507 Validation Decoder Loss:  0.32601652
Encoder Loss:  0.042669214  || Decoder Loss:  0.03652362 Validation Decoder Loss:  0.32949674
Encoder Loss:  0.042631235  || Decoder Loss:  0.036454782 Validation Decoder Loss:  0.32580703
Encoder Loss:  0.042565197  || Decoder Loss:  0.036330167 Validation Decoder Loss:  0.3266984
Encoder Loss:  0.0425404  || Decoder Loss:  0.03628728 Validation Decoder Loss:  0.32665646
Encoder Loss:  0.042508483  || Decoder Loss:  0.036228046 Validation Decoder Loss:  0.32714263
Encoder Loss:  0.042496268  || Decoder Loss:  0.036198497 Validation Decoder Loss:  0.32736164
Encoder Loss:  0.042473875  || Decoder Loss:  0.036162347 Validation Decoder Loss:  0.32791013
Encoder Loss:  0.042481545  || Decoder Loss:  0.036172938 Validation Decoder Loss:  0.33046472
Encoder Loss:  0.04241877  || Decoder Loss:  0.036060087 Validation Decoder Loss:  0.32803762
Encoder Loss:  0.043148313  || Decoder Loss:  0.03732215 Validation Decoder Loss:  0.32822233
Encoder Loss:  0.042822383  || Decoder Loss:  0.03676312 Validation Decoder Loss:  0.3284638
Encoder Loss:  0.042426396  || Decoder Loss:  0.036076874 Validation Decoder Loss:  0.33216676
Encoder Loss:  0.04236514  || Decoder Loss:  0.035966776 Validation Decoder Loss:  0.3320101
Encoder Loss:  0.04233463  || Decoder Loss:  0.03591141 Validation Decoder Loss:  0.33171576
Encoder Loss:  0.04231797  || Decoder Loss:  0.03587456 Validation Decoder Loss:  0.33228797
Encoder Loss:  0.13049647  || Decoder Loss:  0.19114801 Validation Decoder Loss:  0.7439213
Encoder Loss:  0.13792728  || Decoder Loss:  0.21154436 Validation Decoder Loss:  0.3389386
Encoder Loss:  0.044882786  || Decoder Loss:  0.04057944 Validation Decoder Loss:  0.33653945
Encoder Loss:  0.043510646  || Decoder Loss:  0.038065054 Validation Decoder Loss:  0.32986626
Encoder Loss:  0.04321159  || Decoder Loss:  0.037509717 Validation Decoder Loss:  0.33579907
Encoder Loss:  0.04307314  || Decoder Loss:  0.03725906 Validation Decoder Loss:  0.33590397
Encoder Loss:  0.042977065  || Decoder Loss:  0.03708826 Validation Decoder Loss:  0.3360897
Encoder Loss:  0.042890105  || Decoder Loss:  0.036926378 Validation Decoder Loss:  0.33625257
Encoder Loss:  0.042852815  || Decoder Loss:  0.03686061 Validation Decoder Loss:  0.33619374
Encoder Loss:  0.04285497  || Decoder Loss:  0.03684546 Validation Decoder Loss:  0.33621982
Encoder Loss:  0.042793047  || Decoder Loss:  0.03674783 Validation Decoder Loss:  0.3364603
Encoder Loss:  0.042791296  || Decoder Loss:  0.036734287 Validation Decoder Loss:  0.33641645
Encoder Loss:  0.04272332  || Decoder Loss:  0.03661864 Validation Decoder Loss:  0.33631682
Encoder Loss:  0.042705335  || Decoder Loss:  0.036587004 Validation Decoder Loss:  0.33654684
Model: siamese_net_lr_0.46800572295107745 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33654684
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_321 (Conv3D (None, 226, 10, 20, 1)    201       
_________________________________________________________________
dropout_702 (Dropout)        (None, 226, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_322 (Conv3D (None, 257, 10, 20, 1)    33        
_________________________________________________________________
reshape_148 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 234
Trainable params: 234
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_704 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_706 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18923846  || Decoder Loss:  0.38393146 Validation Decoder Loss:  0.9302388
Encoder Loss:  0.19523151  || Decoder Loss:  0.4745716 Validation Decoder Loss:  1.0058023
Encoder Loss:  0.20819294  || Decoder Loss:  0.5132768 Validation Decoder Loss:  1.0367382
Encoder Loss:  0.19619  || Decoder Loss:  0.47816753 Validation Decoder Loss:  1.0146775
Encoder Loss:  0.19697359  || Decoder Loss:  0.48057878 Validation Decoder Loss:  0.95168394
Encoder Loss:  0.17897652  || Decoder Loss:  0.42741907 Validation Decoder Loss:  1.0394617
Encoder Loss:  0.19424413  || Decoder Loss:  0.46970955 Validation Decoder Loss:  0.9466753
Encoder Loss:  0.177357  || Decoder Loss:  0.42306542 Validation Decoder Loss:  0.86216414
Encoder Loss:  0.18019377  || Decoder Loss:  0.43135434 Validation Decoder Loss:  1.0554692
Encoder Loss:  0.18361989  || Decoder Loss:  0.44105706 Validation Decoder Loss:  0.9917895
Encoder Loss:  0.20614265  || Decoder Loss:  0.5074608 Validation Decoder Loss:  0.96797967
Encoder Loss:  0.19684266  || Decoder Loss:  0.47981793 Validation Decoder Loss:  0.90980864
Encoder Loss:  0.19180039  || Decoder Loss:  0.4653838 Validation Decoder Loss:  0.97508633
Encoder Loss:  0.19312724  || Decoder Loss:  0.46907356 Validation Decoder Loss:  1.0019083
Encoder Loss:  0.20407215  || Decoder Loss:  0.5013996 Validation Decoder Loss:  0.9630332
Encoder Loss:  0.2060342  || Decoder Loss:  0.50595176 Validation Decoder Loss:  0.9902326
Encoder Loss:  0.19540554  || Decoder Loss:  0.47517312 Validation Decoder Loss:  0.84154147
Encoder Loss:  0.16987582  || Decoder Loss:  0.40122712 Validation Decoder Loss:  0.7535389
Encoder Loss:  0.19641408  || Decoder Loss:  0.47896484 Validation Decoder Loss:  0.87692034
Encoder Loss:  0.20758729  || Decoder Loss:  0.5117541 Validation Decoder Loss:  1.0416003
Encoder Loss:  0.19033846  || Decoder Loss:  0.46108776 Validation Decoder Loss:  1.147404
Encoder Loss:  0.19799043  || Decoder Loss:  0.4836521 Validation Decoder Loss:  0.92156196
Encoder Loss:  0.18319169  || Decoder Loss:  0.44022834 Validation Decoder Loss:  0.91804343
Encoder Loss:  0.2092905  || Decoder Loss:  0.51613325 Validation Decoder Loss:  0.9937381
Encoder Loss:  0.19211659  || Decoder Loss:  0.4664769 Validation Decoder Loss:  0.73943913
Encoder Loss:  0.18583395  || Decoder Loss:  0.44807038 Validation Decoder Loss:  0.8630794
Encoder Loss:  0.17434599  || Decoder Loss:  0.41438824 Validation Decoder Loss:  0.817734
Encoder Loss:  0.048656072  || Decoder Loss:  0.046019744 Validation Decoder Loss:  0.31204957
Encoder Loss:  0.045889635  || Decoder Loss:  0.03790232 Validation Decoder Loss:  0.3147043
Encoder Loss:  0.045601826  || Decoder Loss:  0.037000608 Validation Decoder Loss:  0.32464296
Encoder Loss:  0.047037445  || Decoder Loss:  0.03883647 Validation Decoder Loss:  0.33257934
Encoder Loss:  0.047469713  || Decoder Loss:  0.042565722 Validation Decoder Loss:  0.33013546
Encoder Loss:  0.047594093  || Decoder Loss:  0.042929444 Validation Decoder Loss:  0.32865465
Encoder Loss:  0.04725572  || Decoder Loss:  0.041940533 Validation Decoder Loss:  0.32764485
Encoder Loss:  0.04721046  || Decoder Loss:  0.041800838 Validation Decoder Loss:  0.32703686
Encoder Loss:  0.046968132  || Decoder Loss:  0.041092146 Validation Decoder Loss:  0.3267169
Encoder Loss:  0.046809774  || Decoder Loss:  0.040630236 Validation Decoder Loss:  0.32643634
Encoder Loss:  0.0465054  || Decoder Loss:  0.039733905 Validation Decoder Loss:  0.32483256
Encoder Loss:  0.04636456  || Decoder Loss:  0.039317954 Validation Decoder Loss:  0.32539022
Encoder Loss:  0.04612696  || Decoder Loss:  0.038619377 Validation Decoder Loss:  0.3245145
Model: siamese_net_lr_0.9783478398962578 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3245145
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_324 (Conv3D (None, 95, 6, 20, 1)      65        
_________________________________________________________________
dropout_708 (Dropout)        (None, 95, 6, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_325 (Conv3D (None, 257, 10, 20, 1)    816       
_________________________________________________________________
reshape_149 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 881
Trainable params: 881
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_710 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 2570, 20, 1)       2         
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_712 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24104355  || Decoder Loss:  0.47886407 Validation Decoder Loss:  0.87532437
Encoder Loss:  0.19495282  || Decoder Loss:  0.49618465 Validation Decoder Loss:  0.8250766
Encoder Loss:  0.19354601  || Decoder Loss:  0.50124556 Validation Decoder Loss:  0.85926
Encoder Loss:  0.19100769  || Decoder Loss:  0.49087006 Validation Decoder Loss:  0.84465927
Encoder Loss:  0.19422714  || Decoder Loss:  0.5016242 Validation Decoder Loss:  0.856726
Encoder Loss:  0.19383392  || Decoder Loss:  0.5013818 Validation Decoder Loss:  0.8454468
Encoder Loss:  0.1932803  || Decoder Loss:  0.49997312 Validation Decoder Loss:  0.86024666
Encoder Loss:  0.19501933  || Decoder Loss:  0.5020457 Validation Decoder Loss:  0.82192427
Encoder Loss:  0.19689164  || Decoder Loss:  0.5030462 Validation Decoder Loss:  0.83196336
Encoder Loss:  0.19351941  || Decoder Loss:  0.5014592 Validation Decoder Loss:  0.82667065
Encoder Loss:  0.19299278  || Decoder Loss:  0.50056845 Validation Decoder Loss:  0.8269171
Encoder Loss:  0.19218329  || Decoder Loss:  0.4986177 Validation Decoder Loss:  0.8233788
Encoder Loss:  0.19228937  || Decoder Loss:  0.4989579 Validation Decoder Loss:  0.8218386
Encoder Loss:  0.19329144  || Decoder Loss:  0.5019708 Validation Decoder Loss:  0.8350343
Encoder Loss:  0.19249126  || Decoder Loss:  0.49951783 Validation Decoder Loss:  0.83393574
Encoder Loss:  0.19239357  || Decoder Loss:  0.49908638 Validation Decoder Loss:  0.83167124
Encoder Loss:  0.1935298  || Decoder Loss:  0.50277257 Validation Decoder Loss:  0.8303971
Encoder Loss:  0.19240263  || Decoder Loss:  0.49922547 Validation Decoder Loss:  0.826043
Encoder Loss:  0.1921846  || Decoder Loss:  0.49855298 Validation Decoder Loss:  0.8092147
Encoder Loss:  0.19153716  || Decoder Loss:  0.4962281 Validation Decoder Loss:  0.82761204
Encoder Loss:  0.19376811  || Decoder Loss:  0.50320613 Validation Decoder Loss:  0.8175121
Encoder Loss:  0.19160475  || Decoder Loss:  0.49618042 Validation Decoder Loss:  0.84380674
Encoder Loss:  0.19351251  || Decoder Loss:  0.50087243 Validation Decoder Loss:  0.81949544
Encoder Loss:  0.19374795  || Decoder Loss:  0.5026841 Validation Decoder Loss:  0.80695367
Encoder Loss:  0.19280304  || Decoder Loss:  0.49976596 Validation Decoder Loss:  0.83086073
Encoder Loss:  0.19325632  || Decoder Loss:  0.49990302 Validation Decoder Loss:  0.81888235
Encoder Loss:  0.19342485  || Decoder Loss:  0.50090116 Validation Decoder Loss:  0.8243356
Encoder Loss:  0.19262911  || Decoder Loss:  0.49982026 Validation Decoder Loss:  0.81676126
Encoder Loss:  0.19280134  || Decoder Loss:  0.5003919 Validation Decoder Loss:  0.81211495
Encoder Loss:  0.19230548  || Decoder Loss:  0.498903 Validation Decoder Loss:  0.8126182
Encoder Loss:  0.19230732  || Decoder Loss:  0.49833158 Validation Decoder Loss:  0.8259342
Encoder Loss:  0.19395222  || Decoder Loss:  0.5034494 Validation Decoder Loss:  0.814739
Encoder Loss:  0.19278258  || Decoder Loss:  0.5002939 Validation Decoder Loss:  0.8163918
Encoder Loss:  0.19251102  || Decoder Loss:  0.49950957 Validation Decoder Loss:  0.81419307
Encoder Loss:  0.19211903  || Decoder Loss:  0.4980744 Validation Decoder Loss:  0.8297107
Encoder Loss:  0.19081476  || Decoder Loss:  0.4942022 Validation Decoder Loss:  0.9970136
Encoder Loss:  0.1900962  || Decoder Loss:  0.49193928 Validation Decoder Loss:  0.981563
Encoder Loss:  0.1899833  || Decoder Loss:  0.49152076 Validation Decoder Loss:  0.9728564
Encoder Loss:  0.18937072  || Decoder Loss:  0.48890504 Validation Decoder Loss:  1.14119
Encoder Loss:  0.19170849  || Decoder Loss:  0.49453494 Validation Decoder Loss:  1.201014
Model: siamese_net_lr_0.2578752103820224 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.201014
Model: "sequential_538"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_327 (Conv3D (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_714 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_328 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_150 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_716 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_718 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2391817  || Decoder Loss:  0.38963866 Validation Decoder Loss:  0.95047927
Encoder Loss:  0.27640736  || Decoder Loss:  0.4685565 Validation Decoder Loss:  0.9928989
Encoder Loss:  0.2922376  || Decoder Loss:  0.49782962 Validation Decoder Loss:  0.9787742
Encoder Loss:  0.2862752  || Decoder Loss:  0.4868129 Validation Decoder Loss:  0.9443526
Encoder Loss:  0.092792965  || Decoder Loss:  0.12910861 Validation Decoder Loss:  0.32172972
Encoder Loss:  0.043915767  || Decoder Loss:  0.038746413 Validation Decoder Loss:  0.32284814
Encoder Loss:  0.04346837  || Decoder Loss:  0.037920572 Validation Decoder Loss:  0.32336593
Encoder Loss:  0.043304868  || Decoder Loss:  0.037619133 Validation Decoder Loss:  0.32360315
Encoder Loss:  0.043211512  || Decoder Loss:  0.037446663 Validation Decoder Loss:  0.32380015
Encoder Loss:  0.043145157  || Decoder Loss:  0.037324045 Validation Decoder Loss:  0.3240254
Encoder Loss:  0.043092955  || Decoder Loss:  0.037226986 Validation Decoder Loss:  0.3242141
Encoder Loss:  0.043060984  || Decoder Loss:  0.03716476 Validation Decoder Loss:  0.32436204
Encoder Loss:  0.043035015  || Decoder Loss:  0.03711498 Validation Decoder Loss:  0.32465786
Encoder Loss:  0.04321999  || Decoder Loss:  0.03738198 Validation Decoder Loss:  0.32436228
Encoder Loss:  0.04327517  || Decoder Loss:  0.037501175 Validation Decoder Loss:  0.32398826
Encoder Loss:  0.04302869  || Decoder Loss:  0.03710743 Validation Decoder Loss:  0.32439688
Encoder Loss:  0.042938877  || Decoder Loss:  0.03692975 Validation Decoder Loss:  0.32478136
Encoder Loss:  0.042838246  || Decoder Loss:  0.036754016 Validation Decoder Loss:  0.3248214
Encoder Loss:  0.04283137  || Decoder Loss:  0.036730304 Validation Decoder Loss:  0.32531124
Encoder Loss:  0.054394916  || Decoder Loss:  0.057571582 Validation Decoder Loss:  0.3257948
Encoder Loss:  0.0425173  || Decoder Loss:  0.036159333 Validation Decoder Loss:  0.3305211
Encoder Loss:  0.042242184  || Decoder Loss:  0.035650596 Validation Decoder Loss:  0.33067316
Encoder Loss:  0.042270016  || Decoder Loss:  0.03565465 Validation Decoder Loss:  0.33034828
Encoder Loss:  0.043775797  || Decoder Loss:  0.038085498 Validation Decoder Loss:  0.32299376
Encoder Loss:  0.04341606  || Decoder Loss:  0.0374039 Validation Decoder Loss:  0.32264817
Encoder Loss:  0.04299905  || Decoder Loss:  0.037036084 Validation Decoder Loss:  0.32321662
Encoder Loss:  0.0428001  || Decoder Loss:  0.036684126 Validation Decoder Loss:  0.32381675
Encoder Loss:  0.042734776  || Decoder Loss:  0.036563314 Validation Decoder Loss:  0.32411376
Encoder Loss:  0.04268723  || Decoder Loss:  0.036474764 Validation Decoder Loss:  0.324306
Encoder Loss:  0.042645406  || Decoder Loss:  0.036398154 Validation Decoder Loss:  0.32471555
Encoder Loss:  0.042593732  || Decoder Loss:  0.036278088 Validation Decoder Loss:  0.32603544
Encoder Loss:  0.042800363  || Decoder Loss:  0.03611022 Validation Decoder Loss:  0.32677794
Encoder Loss:  0.042814  || Decoder Loss:  0.03651701 Validation Decoder Loss:  0.3255286
Encoder Loss:  0.042618085  || Decoder Loss:  0.0363418 Validation Decoder Loss:  0.32692435
Encoder Loss:  0.042522036  || Decoder Loss:  0.036169704 Validation Decoder Loss:  0.3269335
Encoder Loss:  0.042483874  || Decoder Loss:  0.036092672 Validation Decoder Loss:  0.32761073
Encoder Loss:  0.042485915  || Decoder Loss:  0.036095846 Validation Decoder Loss:  0.3276977
Encoder Loss:  0.042491693  || Decoder Loss:  0.03610614 Validation Decoder Loss:  0.32695737
Encoder Loss:  0.042406626  || Decoder Loss:  0.03595427 Validation Decoder Loss:  0.32736
Encoder Loss:  0.042378455  || Decoder Loss:  0.035895098 Validation Decoder Loss:  0.3284517
Model: siamese_net_lr_0.4688892799920011 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3284517
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_330 (Conv3D (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_720 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_331 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_151 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_722 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_724 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04631639  || Decoder Loss:  0.038432043 Validation Decoder Loss:  0.32990548
Encoder Loss:  0.041715026  || Decoder Loss:  0.036725406 Validation Decoder Loss:  0.32986224
Encoder Loss:  0.03952396  || Decoder Loss:  0.03549462 Validation Decoder Loss:  0.3317626
Encoder Loss:  0.036844876  || Decoder Loss:  0.035289768 Validation Decoder Loss:  0.32983568
Encoder Loss:  0.036824673  || Decoder Loss:  0.035308223 Validation Decoder Loss:  0.33017412
Encoder Loss:  0.037165  || Decoder Loss:  0.035705537 Validation Decoder Loss:  0.330113
Encoder Loss:  0.036779433  || Decoder Loss:  0.035284434 Validation Decoder Loss:  0.3296414
Encoder Loss:  0.0367606  || Decoder Loss:  0.035271008 Validation Decoder Loss:  0.33064032
Encoder Loss:  0.03724288  || Decoder Loss:  0.035805862 Validation Decoder Loss:  0.3307985
Encoder Loss:  0.03672018  || Decoder Loss:  0.03522485 Validation Decoder Loss:  0.3284616
Encoder Loss:  0.0367882  || Decoder Loss:  0.035299927 Validation Decoder Loss:  0.3331179
Encoder Loss:  0.03680663  || Decoder Loss:  0.03532061 Validation Decoder Loss:  0.33100313
Encoder Loss:  0.036734518  || Decoder Loss:  0.0352419 Validation Decoder Loss:  0.32990158
Encoder Loss:  0.03675077  || Decoder Loss:  0.035257336 Validation Decoder Loss:  0.33160567
Encoder Loss:  0.03683013  || Decoder Loss:  0.035344873 Validation Decoder Loss:  0.3298124
Encoder Loss:  0.03685527  || Decoder Loss:  0.035373684 Validation Decoder Loss:  0.33038718
Encoder Loss:  0.03675679  || Decoder Loss:  0.03526288 Validation Decoder Loss:  0.32863283
Encoder Loss:  0.036777694  || Decoder Loss:  0.035289165 Validation Decoder Loss:  0.33130497
Encoder Loss:  0.036733717  || Decoder Loss:  0.0352369 Validation Decoder Loss:  0.33026573
Encoder Loss:  0.03673799  || Decoder Loss:  0.035241444 Validation Decoder Loss:  0.33057508
Encoder Loss:  0.03683085  || Decoder Loss:  0.035346154 Validation Decoder Loss:  0.32675976
Encoder Loss:  0.036700293  || Decoder Loss:  0.035196617 Validation Decoder Loss:  0.33067703
Encoder Loss:  0.037706073  || Decoder Loss:  0.0363193 Validation Decoder Loss:  0.33436003
Encoder Loss:  0.036885012  || Decoder Loss:  0.035401177 Validation Decoder Loss:  0.33151162
Encoder Loss:  0.036647275  || Decoder Loss:  0.035126593 Validation Decoder Loss:  0.3319769
Encoder Loss:  0.036621734  || Decoder Loss:  0.035115194 Validation Decoder Loss:  0.33096766
Encoder Loss:  0.03666904  || Decoder Loss:  0.035164796 Validation Decoder Loss:  0.33047482
Encoder Loss:  0.03680942  || Decoder Loss:  0.03532437 Validation Decoder Loss:  0.33069575
Encoder Loss:  0.036663353  || Decoder Loss:  0.035133194 Validation Decoder Loss:  0.32966352
Encoder Loss:  0.03665154  || Decoder Loss:  0.035137627 Validation Decoder Loss:  0.33135974
Encoder Loss:  0.036663547  || Decoder Loss:  0.035150412 Validation Decoder Loss:  0.33089602
Encoder Loss:  0.036674593  || Decoder Loss:  0.035166997 Validation Decoder Loss:  0.33107367
Encoder Loss:  0.036680795  || Decoder Loss:  0.03518259 Validation Decoder Loss:  0.33033156
Encoder Loss:  0.03676284  || Decoder Loss:  0.035272956 Validation Decoder Loss:  0.32310474
Encoder Loss:  0.036678232  || Decoder Loss:  0.03518065 Validation Decoder Loss:  0.3323613
Encoder Loss:  0.0366009  || Decoder Loss:  0.035085414 Validation Decoder Loss:  0.3307907
Encoder Loss:  0.037258536  || Decoder Loss:  0.03526402 Validation Decoder Loss:  0.32909846
Encoder Loss:  0.03655382  || Decoder Loss:  0.035041135 Validation Decoder Loss:  0.32923645
Encoder Loss:  0.036580812  || Decoder Loss:  0.035070878 Validation Decoder Loss:  0.32862365
Encoder Loss:  0.036597323  || Decoder Loss:  0.035090655 Validation Decoder Loss:  0.32847267
Model: siamese_net_lr_0.30937283557708395 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32847267
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_333 (Conv3D (None, 234, 10, 20, 1)    343       
_________________________________________________________________
dropout_726 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_334 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_152 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 368
Trainable params: 368
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_728 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_730 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.098791875  || Decoder Loss:  0.10705369 Validation Decoder Loss:  0.35151273
Encoder Loss:  0.039216913  || Decoder Loss:  0.036107022 Validation Decoder Loss:  0.33178344
Encoder Loss:  0.03892281  || Decoder Loss:  0.03582312 Validation Decoder Loss:  0.33178726
Encoder Loss:  0.038873326  || Decoder Loss:  0.0358214 Validation Decoder Loss:  0.3316856
Encoder Loss:  0.038840335  || Decoder Loss:  0.0358189 Validation Decoder Loss:  0.33175075
Encoder Loss:  0.038823567  || Decoder Loss:  0.035816006 Validation Decoder Loss:  0.33168656
Encoder Loss:  0.03881662  || Decoder Loss:  0.03581605 Validation Decoder Loss:  0.33086434
Encoder Loss:  0.038999926  || Decoder Loss:  0.036054336 Validation Decoder Loss:  0.32925585
Encoder Loss:  0.038989335  || Decoder Loss:  0.036045797 Validation Decoder Loss:  0.33006725
Encoder Loss:  0.038978904  || Decoder Loss:  0.03603671 Validation Decoder Loss:  0.32987887
Encoder Loss:  0.038922943  || Decoder Loss:  0.035969373 Validation Decoder Loss:  0.3304435
Encoder Loss:  0.038915265  || Decoder Loss:  0.035962537 Validation Decoder Loss:  0.33066028
Encoder Loss:  0.038908027  || Decoder Loss:  0.035955578 Validation Decoder Loss:  0.33086115
Encoder Loss:  0.038937256  || Decoder Loss:  0.035991967 Validation Decoder Loss:  0.32993394
Encoder Loss:  0.03889426  || Decoder Loss:  0.035937563 Validation Decoder Loss:  0.33081043
Encoder Loss:  0.03889444  || Decoder Loss:  0.035939194 Validation Decoder Loss:  0.33077753
Encoder Loss:  0.03886855  || Decoder Loss:  0.035906054 Validation Decoder Loss:  0.33120498
Encoder Loss:  0.038887322  || Decoder Loss:  0.035924014 Validation Decoder Loss:  0.32992834
Encoder Loss:  0.03877454  || Decoder Loss:  0.03578789 Validation Decoder Loss:  0.3272441
Encoder Loss:  0.03890867  || Decoder Loss:  0.035957266 Validation Decoder Loss:  0.3306995
Encoder Loss:  0.038795814  || Decoder Loss:  0.03581462 Validation Decoder Loss:  0.32828662
Encoder Loss:  0.03876866  || Decoder Loss:  0.0357799 Validation Decoder Loss:  0.3317166
Encoder Loss:  0.038836814  || Decoder Loss:  0.03586619 Validation Decoder Loss:  0.3312074
Encoder Loss:  0.038715467  || Decoder Loss:  0.035710696 Validation Decoder Loss:  0.33144957
Encoder Loss:  0.04113329  || Decoder Loss:  0.03839352 Validation Decoder Loss:  0.33141977
Encoder Loss:  0.038713332  || Decoder Loss:  0.035637494 Validation Decoder Loss:  0.3318473
Encoder Loss:  0.0386388  || Decoder Loss:  0.035616588 Validation Decoder Loss:  0.33147067
Encoder Loss:  0.03862658  || Decoder Loss:  0.035601716 Validation Decoder Loss:  0.33200017
Encoder Loss:  0.038716957  || Decoder Loss:  0.035716485 Validation Decoder Loss:  0.331657
Encoder Loss:  0.038685  || Decoder Loss:  0.03567608 Validation Decoder Loss:  0.33139083
Encoder Loss:  0.03866093  || Decoder Loss:  0.03564562 Validation Decoder Loss:  0.33141124
Encoder Loss:  0.038634773  || Decoder Loss:  0.035612468 Validation Decoder Loss:  0.3313409
Encoder Loss:  0.03861282  || Decoder Loss:  0.035584643 Validation Decoder Loss:  0.33121
Encoder Loss:  0.038593024  || Decoder Loss:  0.035559725 Validation Decoder Loss:  0.33117062
Encoder Loss:  0.0385788  || Decoder Loss:  0.035541352 Validation Decoder Loss:  0.3310702
Encoder Loss:  0.03855694  || Decoder Loss:  0.035513636 Validation Decoder Loss:  0.33068937
Encoder Loss:  0.038542777  || Decoder Loss:  0.03549567 Validation Decoder Loss:  0.330507
Encoder Loss:  0.03852582  || Decoder Loss:  0.035474643 Validation Decoder Loss:  0.33051878
Encoder Loss:  0.038512513  || Decoder Loss:  0.03545778 Validation Decoder Loss:  0.33054405
Encoder Loss:  0.03850018  || Decoder Loss:  0.035442065 Validation Decoder Loss:  0.33051702
Model: siamese_net_lr_0.34133280753628126 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.330517
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_336 (Conv3D (None, 234, 10, 20, 1)    217       
_________________________________________________________________
dropout_732 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_337 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_153 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_734 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_736 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26743537  || Decoder Loss:  0.31503654 Validation Decoder Loss:  0.31759834
Encoder Loss:  0.040851988  || Decoder Loss:  0.0381862 Validation Decoder Loss:  0.33091754
Encoder Loss:  0.03871785  || Decoder Loss:  0.03556091 Validation Decoder Loss:  0.33054572
Encoder Loss:  0.038581178  || Decoder Loss:  0.03542744 Validation Decoder Loss:  0.33084556
Encoder Loss:  0.03846627  || Decoder Loss:  0.035340436 Validation Decoder Loss:  0.33061814
Encoder Loss:  0.03837017  || Decoder Loss:  0.035258785 Validation Decoder Loss:  0.33023903
Encoder Loss:  0.03831621  || Decoder Loss:  0.03521436 Validation Decoder Loss:  0.32981294
Encoder Loss:  0.038295798  || Decoder Loss:  0.03520632 Validation Decoder Loss:  0.32979023
Encoder Loss:  0.03827705  || Decoder Loss:  0.03519009 Validation Decoder Loss:  0.3298808
Encoder Loss:  0.03826427  || Decoder Loss:  0.03517696 Validation Decoder Loss:  0.3298906
Encoder Loss:  0.038253307  || Decoder Loss:  0.03516526 Validation Decoder Loss:  0.32984692
Encoder Loss:  0.038242813  || Decoder Loss:  0.03515397 Validation Decoder Loss:  0.32981724
Encoder Loss:  0.03823331  || Decoder Loss:  0.035143662 Validation Decoder Loss:  0.32981712
Encoder Loss:  0.038224593  || Decoder Loss:  0.035134066 Validation Decoder Loss:  0.32989308
Encoder Loss:  0.0382165  || Decoder Loss:  0.03512515 Validation Decoder Loss:  0.33005726
Encoder Loss:  0.03820911  || Decoder Loss:  0.03511649 Validation Decoder Loss:  0.3299256
Encoder Loss:  0.038200654  || Decoder Loss:  0.035106614 Validation Decoder Loss:  0.3296684
Encoder Loss:  0.038191754  || Decoder Loss:  0.03509572 Validation Decoder Loss:  0.32964596
Encoder Loss:  0.038183108  || Decoder Loss:  0.035085384 Validation Decoder Loss:  0.32983813
Encoder Loss:  0.0381758  || Decoder Loss:  0.035075393 Validation Decoder Loss:  0.32985175
Encoder Loss:  0.038165063  || Decoder Loss:  0.035061922 Validation Decoder Loss:  0.3295079
Encoder Loss:  0.03815786  || Decoder Loss:  0.035052914 Validation Decoder Loss:  0.32974845
Encoder Loss:  0.0381502  || Decoder Loss:  0.035044838 Validation Decoder Loss:  0.3303119
Encoder Loss:  0.038128674  || Decoder Loss:  0.03501637 Validation Decoder Loss:  0.32980418
Encoder Loss:  0.038121007  || Decoder Loss:  0.03500933 Validation Decoder Loss:  0.32969463
Encoder Loss:  0.038100667  || Decoder Loss:  0.03498285 Validation Decoder Loss:  0.3295493
Encoder Loss:  0.043637395  || Decoder Loss:  0.03880264 Validation Decoder Loss:  0.65675247
Encoder Loss:  0.110197164  || Decoder Loss:  0.11966483 Validation Decoder Loss:  0.33565763
Encoder Loss:  0.041272532  || Decoder Loss:  0.035844177 Validation Decoder Loss:  0.33553723
Encoder Loss:  0.04060354  || Decoder Loss:  0.035866413 Validation Decoder Loss:  0.33362272
Encoder Loss:  0.040523548  || Decoder Loss:  0.03579189 Validation Decoder Loss:  0.33559346
Encoder Loss:  0.040205073  || Decoder Loss:  0.035764802 Validation Decoder Loss:  0.336398
Encoder Loss:  0.040236726  || Decoder Loss:  0.0357361 Validation Decoder Loss:  0.33509967
Encoder Loss:  0.04040919  || Decoder Loss:  0.035728693 Validation Decoder Loss:  0.33797988
Encoder Loss:  0.040129934  || Decoder Loss:  0.03571376 Validation Decoder Loss:  0.3337145
Encoder Loss:  0.04074396  || Decoder Loss:  0.03568808 Validation Decoder Loss:  0.3343226
Encoder Loss:  0.039830185  || Decoder Loss:  0.035653774 Validation Decoder Loss:  0.33700398
Encoder Loss:  0.03977834  || Decoder Loss:  0.035669 Validation Decoder Loss:  0.33566335
Encoder Loss:  0.039747808  || Decoder Loss:  0.035644695 Validation Decoder Loss:  0.33241194
Encoder Loss:  0.03979108  || Decoder Loss:  0.035628118 Validation Decoder Loss:  0.33423835
Model: siamese_net_lr_0.3404546863670107 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33423835
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_339 (Conv3D (None, 236, 10, 20, 1)    221       
_________________________________________________________________
dropout_738 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_340 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_154 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 244
Trainable params: 244
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_740 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_742 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24438204  || Decoder Loss:  0.45004237 Validation Decoder Loss:  1.0582845
Encoder Loss:  0.08496791  || Decoder Loss:  0.15904617 Validation Decoder Loss:  0.33276436
Encoder Loss:  0.05328851  || Decoder Loss:  0.04003559 Validation Decoder Loss:  0.33478072
Encoder Loss:  0.051713172  || Decoder Loss:  0.039295793 Validation Decoder Loss:  0.3410036
Encoder Loss:  0.050682813  || Decoder Loss:  0.03909335 Validation Decoder Loss:  0.34379688
Encoder Loss:  0.05033105  || Decoder Loss:  0.039085124 Validation Decoder Loss:  0.3390898
Encoder Loss:  0.048887182  || Decoder Loss:  0.038715135 Validation Decoder Loss:  0.3402909
Encoder Loss:  0.048761778  || Decoder Loss:  0.039637685 Validation Decoder Loss:  0.33866438
Encoder Loss:  0.048403334  || Decoder Loss:  0.038857475 Validation Decoder Loss:  0.339396
Encoder Loss:  0.048246402  || Decoder Loss:  0.038794097 Validation Decoder Loss:  0.337114
Encoder Loss:  0.047873423  || Decoder Loss:  0.03828659 Validation Decoder Loss:  0.32773197
Encoder Loss:  0.04792013  || Decoder Loss:  0.03860071 Validation Decoder Loss:  0.34065706
Encoder Loss:  0.048351422  || Decoder Loss:  0.03906837 Validation Decoder Loss:  0.3387038
Encoder Loss:  0.04743089  || Decoder Loss:  0.037885413 Validation Decoder Loss:  0.3392477
Encoder Loss:  0.047747657  || Decoder Loss:  0.038251873 Validation Decoder Loss:  0.33797935
Encoder Loss:  0.04789397  || Decoder Loss:  0.038463898 Validation Decoder Loss:  0.3365929
Encoder Loss:  0.048305012  || Decoder Loss:  0.039134696 Validation Decoder Loss:  0.32920086
Encoder Loss:  0.047607377  || Decoder Loss:  0.038098503 Validation Decoder Loss:  0.32870638
Encoder Loss:  0.048892207  || Decoder Loss:  0.04030013 Validation Decoder Loss:  0.33611047
Encoder Loss:  0.047570996  || Decoder Loss:  0.03822146 Validation Decoder Loss:  0.3380516
Encoder Loss:  0.04752903  || Decoder Loss:  0.03800321 Validation Decoder Loss:  0.33072954
Encoder Loss:  0.04775454  || Decoder Loss:  0.03826609 Validation Decoder Loss:  0.327982
Encoder Loss:  0.04845807  || Decoder Loss:  0.03853391 Validation Decoder Loss:  0.33145705
Encoder Loss:  0.04780073  || Decoder Loss:  0.03878996 Validation Decoder Loss:  0.33758265
Encoder Loss:  0.047230445  || Decoder Loss:  0.03731081 Validation Decoder Loss:  0.33585244
Encoder Loss:  0.047453944  || Decoder Loss:  0.037922014 Validation Decoder Loss:  0.33060092
Encoder Loss:  0.047995165  || Decoder Loss:  0.03846812 Validation Decoder Loss:  0.33168995
Encoder Loss:  0.047363475  || Decoder Loss:  0.037719812 Validation Decoder Loss:  0.3361823
Encoder Loss:  0.047344316  || Decoder Loss:  0.0374686 Validation Decoder Loss:  0.3361182
Encoder Loss:  0.047107734  || Decoder Loss:  0.037289694 Validation Decoder Loss:  0.33425504
Encoder Loss:  0.048438773  || Decoder Loss:  0.038853742 Validation Decoder Loss:  0.33020282
Encoder Loss:  0.047726613  || Decoder Loss:  0.038107466 Validation Decoder Loss:  0.33595
Encoder Loss:  0.047150496  || Decoder Loss:  0.037336532 Validation Decoder Loss:  0.33595806
Encoder Loss:  0.047196813  || Decoder Loss:  0.037293617 Validation Decoder Loss:  0.33486074
Encoder Loss:  0.047280733  || Decoder Loss:  0.037118517 Validation Decoder Loss:  0.33204025
Encoder Loss:  0.047332868  || Decoder Loss:  0.037348043 Validation Decoder Loss:  0.3317577
Encoder Loss:  0.047410864  || Decoder Loss:  0.037558936 Validation Decoder Loss:  0.33532354
Encoder Loss:  0.047116097  || Decoder Loss:  0.037166674 Validation Decoder Loss:  0.33516356
Encoder Loss:  0.046952844  || Decoder Loss:  0.036761995 Validation Decoder Loss:  0.3316391
Encoder Loss:  0.047244154  || Decoder Loss:  0.03725479 Validation Decoder Loss:  0.33421642
Model: siamese_net_lr_0.617228429492455 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33421642
Model: "sequential_558"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_342 (Conv3D (None, 236, 10, 20, 1)    221       
_________________________________________________________________
dropout_744 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_343 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_155 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 244
Trainable params: 244
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_746 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_748 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20154992  || Decoder Loss:  0.2951699 Validation Decoder Loss:  0.338033
Encoder Loss:  0.054660916  || Decoder Loss:  0.03667773 Validation Decoder Loss:  0.33309102
Encoder Loss:  0.053258795  || Decoder Loss:  0.039070815 Validation Decoder Loss:  0.32869977
Encoder Loss:  0.0512501  || Decoder Loss:  0.03879169 Validation Decoder Loss:  0.32955456
Encoder Loss:  0.04978577  || Decoder Loss:  0.03864552 Validation Decoder Loss:  0.3444256
Encoder Loss:  0.049162094  || Decoder Loss:  0.039481483 Validation Decoder Loss:  0.3463787
Encoder Loss:  0.04886988  || Decoder Loss:  0.038513042 Validation Decoder Loss:  0.34729466
Encoder Loss:  0.049341697  || Decoder Loss:  0.039514225 Validation Decoder Loss:  0.33853048
Encoder Loss:  0.048364107  || Decoder Loss:  0.038430143 Validation Decoder Loss:  0.33999968
Encoder Loss:  0.048246585  || Decoder Loss:  0.038335726 Validation Decoder Loss:  0.33689064
Encoder Loss:  0.047654554  || Decoder Loss:  0.03772771 Validation Decoder Loss:  0.34015962
Encoder Loss:  0.048693605  || Decoder Loss:  0.03899189 Validation Decoder Loss:  0.33956212
Encoder Loss:  0.048018746  || Decoder Loss:  0.03832127 Validation Decoder Loss:  0.32740107
Encoder Loss:  0.048119884  || Decoder Loss:  0.038516745 Validation Decoder Loss:  0.3408788
Encoder Loss:  0.047944017  || Decoder Loss:  0.038217224 Validation Decoder Loss:  0.33916742
Encoder Loss:  0.04848622  || Decoder Loss:  0.038743183 Validation Decoder Loss:  0.36764377
Encoder Loss:  0.047776304  || Decoder Loss:  0.038495902 Validation Decoder Loss:  0.32804346
Encoder Loss:  0.04906264  || Decoder Loss:  0.039663337 Validation Decoder Loss:  0.33114648
Encoder Loss:  0.047728464  || Decoder Loss:  0.038406104 Validation Decoder Loss:  0.32707578
Encoder Loss:  0.04930966  || Decoder Loss:  0.040138863 Validation Decoder Loss:  0.3396655
Encoder Loss:  0.047674708  || Decoder Loss:  0.03822232 Validation Decoder Loss:  0.32719606
Encoder Loss:  0.049087215  || Decoder Loss:  0.039804325 Validation Decoder Loss:  0.34161848
Encoder Loss:  0.048006944  || Decoder Loss:  0.038671013 Validation Decoder Loss:  0.33102503
Encoder Loss:  0.049007244  || Decoder Loss:  0.044063635 Validation Decoder Loss:  0.33228427
Encoder Loss:  0.047403324  || Decoder Loss:  0.036847625 Validation Decoder Loss:  0.32988152
Encoder Loss:  0.04719325  || Decoder Loss:  0.037059333 Validation Decoder Loss:  0.33134747
Encoder Loss:  0.047849808  || Decoder Loss:  0.03844388 Validation Decoder Loss:  0.3307505
Encoder Loss:  0.04749113  || Decoder Loss:  0.037958432 Validation Decoder Loss:  0.33053365
Encoder Loss:  0.047277395  || Decoder Loss:  0.03759116 Validation Decoder Loss:  0.3407779
Encoder Loss:  0.049454007  || Decoder Loss:  0.039938413 Validation Decoder Loss:  0.33215272
Encoder Loss:  0.0473008  || Decoder Loss:  0.037984893 Validation Decoder Loss:  0.33725947
Encoder Loss:  0.04722348  || Decoder Loss:  0.03727786 Validation Decoder Loss:  0.33695328
Encoder Loss:  0.047369715  || Decoder Loss:  0.03767122 Validation Decoder Loss:  0.33717248
Encoder Loss:  0.047153655  || Decoder Loss:  0.03705509 Validation Decoder Loss:  0.3345643
Encoder Loss:  0.0478874  || Decoder Loss:  0.0382394 Validation Decoder Loss:  0.33128825
Encoder Loss:  0.047236748  || Decoder Loss:  0.037599806 Validation Decoder Loss:  0.3319386
Encoder Loss:  0.04712095  || Decoder Loss:  0.03700735 Validation Decoder Loss:  0.3358987
Encoder Loss:  0.047249194  || Decoder Loss:  0.037164547 Validation Decoder Loss:  0.33549446
Encoder Loss:  0.047102813  || Decoder Loss:  0.036937773 Validation Decoder Loss:  0.3361739
Encoder Loss:  0.04823135  || Decoder Loss:  0.03856039 Validation Decoder Loss:  0.33716378
Model: siamese_net_lr_0.6147952071919658 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33716378
Model: "sequential_562"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_345 (Conv3D (None, 234, 10, 20, 1)    217       
_________________________________________________________________
dropout_750 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_346 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_156 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_752 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_754 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2584229  || Decoder Loss:  0.27642548 Validation Decoder Loss:  0.3328304
Encoder Loss:  0.041982464  || Decoder Loss:  0.035833318 Validation Decoder Loss:  0.33139062
Encoder Loss:  0.04077581  || Decoder Loss:  0.03565813 Validation Decoder Loss:  0.33148253
Encoder Loss:  0.04014691  || Decoder Loss:  0.03554327 Validation Decoder Loss:  0.33123168
Encoder Loss:  0.040459815  || Decoder Loss:  0.035437766 Validation Decoder Loss:  0.3312763
Encoder Loss:  0.03973138  || Decoder Loss:  0.03537095 Validation Decoder Loss:  0.33087698
Encoder Loss:  0.040246777  || Decoder Loss:  0.035322092 Validation Decoder Loss:  0.33062494
Encoder Loss:  0.038838867  || Decoder Loss:  0.035263356 Validation Decoder Loss:  0.33039242
Encoder Loss:  0.038702987  || Decoder Loss:  0.035215255 Validation Decoder Loss:  0.33082873
Encoder Loss:  0.037804063  || Decoder Loss:  0.035194267 Validation Decoder Loss:  0.32977152
Encoder Loss:  0.037740868  || Decoder Loss:  0.035183743 Validation Decoder Loss:  0.32925656
Encoder Loss:  0.037713002  || Decoder Loss:  0.03517341 Validation Decoder Loss:  0.32936633
Encoder Loss:  0.0376978  || Decoder Loss:  0.035160422 Validation Decoder Loss:  0.3301177
Encoder Loss:  0.03767274  || Decoder Loss:  0.03513206 Validation Decoder Loss:  0.32937127
Encoder Loss:  0.03766457  || Decoder Loss:  0.03512378 Validation Decoder Loss:  0.3288104
Encoder Loss:  0.04194653  || Decoder Loss:  0.040287565 Validation Decoder Loss:  0.32952416
Encoder Loss:  0.038263254  || Decoder Loss:  0.03584737 Validation Decoder Loss:  0.33209074
Encoder Loss:  0.038246166  || Decoder Loss:  0.035827275 Validation Decoder Loss:  0.33219427
Encoder Loss:  0.038234983  || Decoder Loss:  0.035814174 Validation Decoder Loss:  0.3323725
Encoder Loss:  0.03822295  || Decoder Loss:  0.035799786 Validation Decoder Loss:  0.33255804
Encoder Loss:  0.038211837  || Decoder Loss:  0.035786018 Validation Decoder Loss:  0.33260444
Encoder Loss:  0.038200643  || Decoder Loss:  0.035771817 Validation Decoder Loss:  0.33250654
Encoder Loss:  0.038186457  || Decoder Loss:  0.035755545 Validation Decoder Loss:  0.3323561
Encoder Loss:  0.038171876  || Decoder Loss:  0.035737924 Validation Decoder Loss:  0.33222958
Encoder Loss:  0.038155913  || Decoder Loss:  0.035718493 Validation Decoder Loss:  0.3321279
Encoder Loss:  0.03813801  || Decoder Loss:  0.03569698 Validation Decoder Loss:  0.33204806
Encoder Loss:  0.038118433  || Decoder Loss:  0.035673417 Validation Decoder Loss:  0.33197576
Encoder Loss:  0.03809806  || Decoder Loss:  0.035647944 Validation Decoder Loss:  0.33192575
Encoder Loss:  0.03807438  || Decoder Loss:  0.03561949 Validation Decoder Loss:  0.33190465
Encoder Loss:  0.038047943  || Decoder Loss:  0.035588376 Validation Decoder Loss:  0.33196115
Encoder Loss:  0.038019992  || Decoder Loss:  0.035553742 Validation Decoder Loss:  0.33201155
Encoder Loss:  0.03798609  || Decoder Loss:  0.035513848 Validation Decoder Loss:  0.3316464
Encoder Loss:  0.037951082  || Decoder Loss:  0.03547137 Validation Decoder Loss:  0.33143985
Encoder Loss:  0.037915897  || Decoder Loss:  0.03542921 Validation Decoder Loss:  0.33140597
Encoder Loss:  0.03789016  || Decoder Loss:  0.03539754 Validation Decoder Loss:  0.33133745
Encoder Loss:  0.037870318  || Decoder Loss:  0.035373554 Validation Decoder Loss:  0.33116388
Encoder Loss:  0.03785362  || Decoder Loss:  0.03535421 Validation Decoder Loss:  0.33118755
Encoder Loss:  0.037841808  || Decoder Loss:  0.035340134 Validation Decoder Loss:  0.33104903
Encoder Loss:  0.037835687  || Decoder Loss:  0.03533259 Validation Decoder Loss:  0.33138558
Encoder Loss:  0.037809785  || Decoder Loss:  0.035301298 Validation Decoder Loss:  0.33106175
Model: siamese_net_lr_0.3487160422962109 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33106175
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_348 (Conv3D (None, 234, 10, 20, 1)    91        
_________________________________________________________________
dropout_756 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_349 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_157 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_758 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_569"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_760 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4227443  || Decoder Loss:  0.04408234 Validation Decoder Loss:  0.35465863
Encoder Loss:  0.4210341  || Decoder Loss:  0.20660006 Validation Decoder Loss:  1.6286142
Encoder Loss:  0.43697944  || Decoder Loss:  0.8965955 Validation Decoder Loss:  0.38129422
Encoder Loss:  0.38688374  || Decoder Loss:  0.7784053 Validation Decoder Loss:  0.59311914
Encoder Loss:  0.14592214  || Decoder Loss:  0.43032798 Validation Decoder Loss:  1.0495479
Encoder Loss:  0.108344555  || Decoder Loss:  0.46269095 Validation Decoder Loss:  1.0724901
Encoder Loss:  0.08948662  || Decoder Loss:  0.1482282 Validation Decoder Loss:  0.33152622
Encoder Loss:  0.054438833  || Decoder Loss:  0.035924282 Validation Decoder Loss:  0.33122543
Encoder Loss:  0.053146347  || Decoder Loss:  0.036033712 Validation Decoder Loss:  0.3312071
Encoder Loss:  0.05235403  || Decoder Loss:  0.036244716 Validation Decoder Loss:  0.33116153
Encoder Loss:  0.05286613  || Decoder Loss:  0.037309095 Validation Decoder Loss:  0.3317544
Encoder Loss:  0.05255354  || Decoder Loss:  0.036986433 Validation Decoder Loss:  0.33058387
Encoder Loss:  0.052685  || Decoder Loss:  0.03654127 Validation Decoder Loss:  0.33101633
Encoder Loss:  0.05269975  || Decoder Loss:  0.037666198 Validation Decoder Loss:  0.3318973
Encoder Loss:  0.052300483  || Decoder Loss:  0.037288256 Validation Decoder Loss:  0.3288942
Encoder Loss:  0.053422898  || Decoder Loss:  0.037526138 Validation Decoder Loss:  0.33177203
Encoder Loss:  0.05237536  || Decoder Loss:  0.03738902 Validation Decoder Loss:  0.33186218
Encoder Loss:  0.05270616  || Decoder Loss:  0.03718008 Validation Decoder Loss:  0.33206445
Encoder Loss:  0.052803006  || Decoder Loss:  0.037334498 Validation Decoder Loss:  0.3315466
Encoder Loss:  0.051922217  || Decoder Loss:  0.036174785 Validation Decoder Loss:  0.33109716
Encoder Loss:  0.05187379  || Decoder Loss:  0.037019648 Validation Decoder Loss:  0.33201623
Encoder Loss:  0.051951498  || Decoder Loss:  0.03626219 Validation Decoder Loss:  0.3339172
Encoder Loss:  0.051816482  || Decoder Loss:  0.03710032 Validation Decoder Loss:  0.3319812
Encoder Loss:  0.05131163  || Decoder Loss:  0.03734286 Validation Decoder Loss:  0.33326444
Encoder Loss:  0.051600758  || Decoder Loss:  0.03723788 Validation Decoder Loss:  0.33114105
Encoder Loss:  0.050628934  || Decoder Loss:  0.03697767 Validation Decoder Loss:  0.33123374
Encoder Loss:  0.05141692  || Decoder Loss:  0.036966186 Validation Decoder Loss:  0.33156812
Encoder Loss:  0.051158622  || Decoder Loss:  0.03658091 Validation Decoder Loss:  0.33000898
Encoder Loss:  0.050254468  || Decoder Loss:  0.036992718 Validation Decoder Loss:  0.33093354
Encoder Loss:  0.050318364  || Decoder Loss:  0.0367463 Validation Decoder Loss:  0.33091274
Encoder Loss:  0.050446354  || Decoder Loss:  0.036591098 Validation Decoder Loss:  0.3310957
Encoder Loss:  0.05054479  || Decoder Loss:  0.03659358 Validation Decoder Loss:  0.33200052
Encoder Loss:  0.050924763  || Decoder Loss:  0.036738515 Validation Decoder Loss:  0.33095396
Encoder Loss:  0.050034773  || Decoder Loss:  0.036484182 Validation Decoder Loss:  0.33035973
Encoder Loss:  0.05033879  || Decoder Loss:  0.03636784 Validation Decoder Loss:  0.33156645
Encoder Loss:  0.050377943  || Decoder Loss:  0.03656672 Validation Decoder Loss:  0.3308933
Encoder Loss:  0.050088968  || Decoder Loss:  0.036294833 Validation Decoder Loss:  0.3295256
Encoder Loss:  0.050476488  || Decoder Loss:  0.036488354 Validation Decoder Loss:  0.33056098
Encoder Loss:  0.05206869  || Decoder Loss:  0.037033472 Validation Decoder Loss:  0.3340636
Encoder Loss:  0.050317667  || Decoder Loss:  0.039474774 Validation Decoder Loss:  0.33404082
Model: siamese_net_lr_0.9574127276331587 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3340408
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_351 (Conv3D (None, 234, 10, 20, 1)    91        
_________________________________________________________________
dropout_762 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_352 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_158 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_764 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_766 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4785202  || Decoder Loss:  0.9233323 Validation Decoder Loss:  1.6313213
Encoder Loss:  0.48201665  || Decoder Loss:  0.9545887 Validation Decoder Loss:  1.6311606
Encoder Loss:  0.48129678  || Decoder Loss:  0.95454097 Validation Decoder Loss:  1.6310384
Encoder Loss:  0.22117159  || Decoder Loss:  0.40899077 Validation Decoder Loss:  0.36818767
Encoder Loss:  0.0476683  || Decoder Loss:  0.04510809 Validation Decoder Loss:  0.36796355
Encoder Loss:  0.12778492  || Decoder Loss:  0.21313441 Validation Decoder Loss:  1.6314576
Encoder Loss:  0.4813871  || Decoder Loss:  0.9547336 Validation Decoder Loss:  1.6315145
Encoder Loss:  0.48139495  || Decoder Loss:  0.95474946 Validation Decoder Loss:  1.6315475
Encoder Loss:  0.4817303  || Decoder Loss:  0.9546643 Validation Decoder Loss:  1.6312444
Encoder Loss:  0.4844773  || Decoder Loss:  0.9451709 Validation Decoder Loss:  1.6255645
Encoder Loss:  0.33530575  || Decoder Loss:  0.64835066 Validation Decoder Loss:  0.3753499
Encoder Loss:  0.05015018  || Decoder Loss:  0.050312757 Validation Decoder Loss:  0.3747729
Encoder Loss:  0.049974762  || Decoder Loss:  0.04994525 Validation Decoder Loss:  0.37444395
Encoder Loss:  0.04986948  || Decoder Loss:  0.049721025 Validation Decoder Loss:  0.37418824
Encoder Loss:  0.049806487  || Decoder Loss:  0.04958663 Validation Decoder Loss:  0.37402058
Encoder Loss:  0.04977494  || Decoder Loss:  0.049514398 Validation Decoder Loss:  0.3738402
Encoder Loss:  0.049742654  || Decoder Loss:  0.04945833 Validation Decoder Loss:  0.37377548
Encoder Loss:  0.04972584  || Decoder Loss:  0.049421076 Validation Decoder Loss:  0.37363142
Encoder Loss:  0.050421167  || Decoder Loss:  0.04990386 Validation Decoder Loss:  0.37475953
Encoder Loss:  0.24055254  || Decoder Loss:  0.4475009 Validation Decoder Loss:  0.9426476
Encoder Loss:  0.052411333  || Decoder Loss:  0.055049643 Validation Decoder Loss:  0.32958227
Encoder Loss:  0.04326657  || Decoder Loss:  0.03587301 Validation Decoder Loss:  0.33117843
Encoder Loss:  0.043254804  || Decoder Loss:  0.03584898 Validation Decoder Loss:  0.33113524
Encoder Loss:  0.04325122  || Decoder Loss:  0.03584182 Validation Decoder Loss:  0.33120823
Encoder Loss:  0.043247417  || Decoder Loss:  0.0358338 Validation Decoder Loss:  0.3311847
Encoder Loss:  0.043243643  || Decoder Loss:  0.035826072 Validation Decoder Loss:  0.33113933
Encoder Loss:  0.04324305  || Decoder Loss:  0.035824917 Validation Decoder Loss:  0.33104327
Encoder Loss:  0.04403034  || Decoder Loss:  0.037476238 Validation Decoder Loss:  0.33175504
Encoder Loss:  0.043264013  || Decoder Loss:  0.035868905 Validation Decoder Loss:  0.33106852
Encoder Loss:  0.04322547  || Decoder Loss:  0.0357879 Validation Decoder Loss:  0.33106506
Encoder Loss:  0.04321845  || Decoder Loss:  0.035773024 Validation Decoder Loss:  0.33101845
Encoder Loss:  0.04321337  || Decoder Loss:  0.0357626 Validation Decoder Loss:  0.33093795
Encoder Loss:  0.043953408  || Decoder Loss:  0.037314977 Validation Decoder Loss:  0.33106706
Encoder Loss:  0.04326333  || Decoder Loss:  0.035868127 Validation Decoder Loss:  0.3309128
Encoder Loss:  0.04318861  || Decoder Loss:  0.035710856 Validation Decoder Loss:  0.33093292
Encoder Loss:  0.043181144  || Decoder Loss:  0.035693042 Validation Decoder Loss:  0.33086967
Encoder Loss:  0.04317358  || Decoder Loss:  0.035679676 Validation Decoder Loss:  0.33078915
Encoder Loss:  0.04379393  || Decoder Loss:  0.03698004 Validation Decoder Loss:  0.3315004
Encoder Loss:  0.043170027  || Decoder Loss:  0.035670165 Validation Decoder Loss:  0.33066392
Encoder Loss:  0.043146882  || Decoder Loss:  0.03562283 Validation Decoder Loss:  0.33071005
Model: siamese_net_lr_0.46177606766989376 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33071005
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_354 (Conv3D (None, 236, 10, 20, 1)    347       
_________________________________________________________________
dropout_768 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_355 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_159 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_770 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_772 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13704723  || Decoder Loss:  0.3617503 Validation Decoder Loss:  0.3108146
Encoder Loss:  0.046897054  || Decoder Loss:  0.037878856 Validation Decoder Loss:  0.31246966
Encoder Loss:  0.04673283  || Decoder Loss:  0.037237555 Validation Decoder Loss:  0.31311643
Encoder Loss:  0.0466886  || Decoder Loss:  0.037071522 Validation Decoder Loss:  0.31686443
Encoder Loss:  0.04659164  || Decoder Loss:  0.036695942 Validation Decoder Loss:  0.31594878
Encoder Loss:  0.046627015  || Decoder Loss:  0.036775537 Validation Decoder Loss:  0.31545407
Encoder Loss:  0.046592485  || Decoder Loss:  0.03664901 Validation Decoder Loss:  0.32527402
Encoder Loss:  0.047630195  || Decoder Loss:  0.037978712 Validation Decoder Loss:  0.31351757
Encoder Loss:  0.04673139  || Decoder Loss:  0.03726749 Validation Decoder Loss:  0.3116091
Encoder Loss:  0.046706896  || Decoder Loss:  0.037172187 Validation Decoder Loss:  0.31322813
Encoder Loss:  0.04668801  || Decoder Loss:  0.037090477 Validation Decoder Loss:  0.31351405
Encoder Loss:  0.04659245  || Decoder Loss:  0.036728755 Validation Decoder Loss:  0.31072992
Encoder Loss:  0.04659264  || Decoder Loss:  0.036718782 Validation Decoder Loss:  0.31490678
Encoder Loss:  0.04659617  || Decoder Loss:  0.0367425 Validation Decoder Loss:  0.31692284
Encoder Loss:  0.048560902  || Decoder Loss:  0.040593885 Validation Decoder Loss:  0.29977357
Encoder Loss:  0.04715083  || Decoder Loss:  0.038906932 Validation Decoder Loss:  0.3094097
Encoder Loss:  0.046931874  || Decoder Loss:  0.03805621 Validation Decoder Loss:  0.303836
Encoder Loss:  0.046846002  || Decoder Loss:  0.037728723 Validation Decoder Loss:  0.30583608
Encoder Loss:  0.04681741  || Decoder Loss:  0.037617728 Validation Decoder Loss:  0.3128725
Encoder Loss:  0.046700075  || Decoder Loss:  0.037165344 Validation Decoder Loss:  0.31230852
Encoder Loss:  0.046682492  || Decoder Loss:  0.03708441 Validation Decoder Loss:  0.31066927
Encoder Loss:  0.04672972  || Decoder Loss:  0.03727861 Validation Decoder Loss:  0.31264037
Encoder Loss:  0.046703476  || Decoder Loss:  0.037142795 Validation Decoder Loss:  0.3125351
Encoder Loss:  0.052324943  || Decoder Loss:  0.05131757 Validation Decoder Loss:  0.29355305
Encoder Loss:  0.04713529  || Decoder Loss:  0.03882817 Validation Decoder Loss:  0.36179277
Encoder Loss:  0.046985697  || Decoder Loss:  0.038259294 Validation Decoder Loss:  0.36121625
Encoder Loss:  0.04698816  || Decoder Loss:  0.038265955 Validation Decoder Loss:  0.36046097
Encoder Loss:  0.046945468  || Decoder Loss:  0.0381072 Validation Decoder Loss:  0.359751
Encoder Loss:  0.046867423  || Decoder Loss:  0.037811507 Validation Decoder Loss:  0.3594129
Encoder Loss:  0.04683796  || Decoder Loss:  0.03770127 Validation Decoder Loss:  0.35880965
Encoder Loss:  0.046872918  || Decoder Loss:  0.037823807 Validation Decoder Loss:  0.36152184
Encoder Loss:  0.04706729  || Decoder Loss:  0.03857572 Validation Decoder Loss:  0.30600864
Encoder Loss:  0.046858516  || Decoder Loss:  0.03778312 Validation Decoder Loss:  0.3092185
Encoder Loss:  0.0468439  || Decoder Loss:  0.037722953 Validation Decoder Loss:  0.3099475
Encoder Loss:  0.046797942  || Decoder Loss:  0.037544575 Validation Decoder Loss:  0.31012738
Encoder Loss:  0.046795517  || Decoder Loss:  0.037539862 Validation Decoder Loss:  0.31076595
Encoder Loss:  0.046789993  || Decoder Loss:  0.037473094 Validation Decoder Loss:  0.3084145
Encoder Loss:  0.046902798  || Decoder Loss:  0.03761496 Validation Decoder Loss:  0.36444005
Encoder Loss:  0.046946593  || Decoder Loss:  0.038129736 Validation Decoder Loss:  0.3102458
Encoder Loss:  0.04676417  || Decoder Loss:  0.037421264 Validation Decoder Loss:  0.3101051
Model: siamese_net_lr_0.5904620894457504 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3101051
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_357 (Conv3D (None, 236, 10, 20, 1)    661       
_________________________________________________________________
dropout_774 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_358 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_160 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 684
Trainable params: 684
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_776 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_778 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06445603  || Decoder Loss:  0.076065205 Validation Decoder Loss:  0.36407095
Encoder Loss:  0.057589144  || Decoder Loss:  0.07787862 Validation Decoder Loss:  0.3685584
Encoder Loss:  0.061678577  || Decoder Loss:  0.10061159 Validation Decoder Loss:  0.37444913
Encoder Loss:  0.06288728  || Decoder Loss:  0.106110595 Validation Decoder Loss:  0.31750572
Encoder Loss:  0.046966944  || Decoder Loss:  0.035873 Validation Decoder Loss:  0.33043557
Encoder Loss:  0.04707811  || Decoder Loss:  0.036394525 Validation Decoder Loss:  0.32499066
Encoder Loss:  0.047260027  || Decoder Loss:  0.037202176 Validation Decoder Loss:  0.3240754
Encoder Loss:  0.04731138  || Decoder Loss:  0.037462518 Validation Decoder Loss:  0.32415748
Encoder Loss:  0.04724875  || Decoder Loss:  0.0371236 Validation Decoder Loss:  0.32502717
Encoder Loss:  0.0472471  || Decoder Loss:  0.03714571 Validation Decoder Loss:  0.32549638
Encoder Loss:  0.04729087  || Decoder Loss:  0.037245244 Validation Decoder Loss:  0.32584417
Encoder Loss:  0.04729148  || Decoder Loss:  0.03731383 Validation Decoder Loss:  0.32514143
Encoder Loss:  0.04721388  || Decoder Loss:  0.03696955 Validation Decoder Loss:  0.32706016
Encoder Loss:  0.058332704  || Decoder Loss:  0.07515656 Validation Decoder Loss:  0.31609005
Encoder Loss:  0.04839109  || Decoder Loss:  0.042489246 Validation Decoder Loss:  0.32218838
Encoder Loss:  0.047658786  || Decoder Loss:  0.03912124 Validation Decoder Loss:  0.31838638
Encoder Loss:  0.047564507  || Decoder Loss:  0.038690463 Validation Decoder Loss:  0.31889248
Encoder Loss:  0.047468558  || Decoder Loss:  0.038252708 Validation Decoder Loss:  0.32316047
Encoder Loss:  0.04743225  || Decoder Loss:  0.038079537 Validation Decoder Loss:  0.31959933
Encoder Loss:  0.047380928  || Decoder Loss:  0.037842438 Validation Decoder Loss:  0.32362944
Encoder Loss:  0.047341112  || Decoder Loss:  0.03764683 Validation Decoder Loss:  0.32053083
Encoder Loss:  0.047307216  || Decoder Loss:  0.037400905 Validation Decoder Loss:  0.32477748
Encoder Loss:  0.04731278  || Decoder Loss:  0.037389062 Validation Decoder Loss:  0.32181835
Encoder Loss:  0.047519162  || Decoder Loss:  0.03719135 Validation Decoder Loss:  0.33056676
Encoder Loss:  0.047667965  || Decoder Loss:  0.03899199 Validation Decoder Loss:  0.3201729
Encoder Loss:  0.047312178  || Decoder Loss:  0.037504822 Validation Decoder Loss:  0.3244087
Encoder Loss:  0.047277942  || Decoder Loss:  0.037346218 Validation Decoder Loss:  0.32151708
Encoder Loss:  0.047252156  || Decoder Loss:  0.037213635 Validation Decoder Loss:  0.32199723
Encoder Loss:  0.047728624  || Decoder Loss:  0.03786363 Validation Decoder Loss:  0.31744066
Encoder Loss:  0.04975796  || Decoder Loss:  0.043539416 Validation Decoder Loss:  0.3171768
Encoder Loss:  0.047829747  || Decoder Loss:  0.039902866 Validation Decoder Loss:  0.32233536
Encoder Loss:  0.047658846  || Decoder Loss:  0.03911855 Validation Decoder Loss:  0.32181326
Encoder Loss:  0.04766401  || Decoder Loss:  0.03914714 Validation Decoder Loss:  0.31736553
Encoder Loss:  0.047583763  || Decoder Loss:  0.038787235 Validation Decoder Loss:  0.31791055
Encoder Loss:  0.047581736  || Decoder Loss:  0.0387503 Validation Decoder Loss:  0.31796926
Encoder Loss:  0.04760493  || Decoder Loss:  0.03885341 Validation Decoder Loss:  0.31849623
Encoder Loss:  0.047741383  || Decoder Loss:  0.03948818 Validation Decoder Loss:  0.32301345
Encoder Loss:  0.047779158  || Decoder Loss:  0.039653383 Validation Decoder Loss:  0.3237967
Encoder Loss:  0.04783508  || Decoder Loss:  0.039896186 Validation Decoder Loss:  0.3173019
Encoder Loss:  0.04789186  || Decoder Loss:  0.04006178 Validation Decoder Loss:  0.32364064
Model: siamese_net_lr_0.6035274029635301 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32364064
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_360 (Conv3D (None, 234, 10, 20, 1)    1027      
_________________________________________________________________
dropout_780 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_361 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_161 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,052
Trainable params: 1,052
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_782 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_585"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_784 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37714636  || Decoder Loss:  0.44342405 Validation Decoder Loss:  1.0220594
Encoder Loss:  0.16750811  || Decoder Loss:  0.19213255 Validation Decoder Loss:  0.31925008
Encoder Loss:  0.038497664  || Decoder Loss:  0.03604582 Validation Decoder Loss:  0.3310225
Encoder Loss:  0.03839563  || Decoder Loss:  0.035939563 Validation Decoder Loss:  0.32955778
Encoder Loss:  0.038910273  || Decoder Loss:  0.03657327 Validation Decoder Loss:  0.32845238
Encoder Loss:  0.038942996  || Decoder Loss:  0.036615282 Validation Decoder Loss:  0.32852718
Encoder Loss:  0.03883505  || Decoder Loss:  0.036485206 Validation Decoder Loss:  0.32917923
Encoder Loss:  0.038743176  || Decoder Loss:  0.036374554 Validation Decoder Loss:  0.3293373
Encoder Loss:  0.038694732  || Decoder Loss:  0.03631521 Validation Decoder Loss:  0.3294162
Encoder Loss:  0.038624715  || Decoder Loss:  0.036226124 Validation Decoder Loss:  0.32962564
Encoder Loss:  0.038620085  || Decoder Loss:  0.036220457 Validation Decoder Loss:  0.32973224
Encoder Loss:  0.03861743  || Decoder Loss:  0.036219377 Validation Decoder Loss:  0.3297633
Encoder Loss:  0.038387872  || Decoder Loss:  0.035939477 Validation Decoder Loss:  0.3297337
Encoder Loss:  0.038675636  || Decoder Loss:  0.036273126 Validation Decoder Loss:  0.33014947
Encoder Loss:  0.038438  || Decoder Loss:  0.035998028 Validation Decoder Loss:  0.329876
Encoder Loss:  0.03832056  || Decoder Loss:  0.035860933 Validation Decoder Loss:  0.33018002
Encoder Loss:  0.038245972  || Decoder Loss:  0.035764385 Validation Decoder Loss:  0.33028463
Encoder Loss:  0.03823204  || Decoder Loss:  0.03574821 Validation Decoder Loss:  0.32985452
Encoder Loss:  0.03816814  || Decoder Loss:  0.03567625 Validation Decoder Loss:  0.33137196
Encoder Loss:  0.042480275  || Decoder Loss:  0.040541705 Validation Decoder Loss:  0.32821384
Encoder Loss:  0.038345646  || Decoder Loss:  0.03589346 Validation Decoder Loss:  0.32932115
Encoder Loss:  0.038233683  || Decoder Loss:  0.035756685 Validation Decoder Loss:  0.3293497
Encoder Loss:  0.038193915  || Decoder Loss:  0.035709802 Validation Decoder Loss:  0.32924688
Encoder Loss:  0.038170468  || Decoder Loss:  0.03568297 Validation Decoder Loss:  0.32883796
Encoder Loss:  0.038127877  || Decoder Loss:  0.035630256 Validation Decoder Loss:  0.32950172
Encoder Loss:  0.038109347  || Decoder Loss:  0.035607003 Validation Decoder Loss:  0.33060822
Encoder Loss:  0.038104005  || Decoder Loss:  0.03560116 Validation Decoder Loss:  0.33055598
Encoder Loss:  0.038086835  || Decoder Loss:  0.03558095 Validation Decoder Loss:  0.3305746
Encoder Loss:  0.038054135  || Decoder Loss:  0.035541363 Validation Decoder Loss:  0.3308805
Encoder Loss:  0.03806488  || Decoder Loss:  0.035555348 Validation Decoder Loss:  0.33042186
Encoder Loss:  0.038034912  || Decoder Loss:  0.0355186 Validation Decoder Loss:  0.33091944
Encoder Loss:  0.03797898  || Decoder Loss:  0.03544853 Validation Decoder Loss:  0.3308405
Encoder Loss:  0.038026173  || Decoder Loss:  0.035507523 Validation Decoder Loss:  0.32974282
Encoder Loss:  0.03799474  || Decoder Loss:  0.03546763 Validation Decoder Loss:  0.3307413
Encoder Loss:  0.038189713  || Decoder Loss:  0.035681628 Validation Decoder Loss:  0.33139375
Encoder Loss:  0.038001135  || Decoder Loss:  0.03547782 Validation Decoder Loss:  0.3300245
Encoder Loss:  0.038015734  || Decoder Loss:  0.03549508 Validation Decoder Loss:  0.33114874
Encoder Loss:  0.038020473  || Decoder Loss:  0.03549665 Validation Decoder Loss:  0.33021873
Encoder Loss:  0.03985087  || Decoder Loss:  0.03734924 Validation Decoder Loss:  0.3302713
Encoder Loss:  0.0382907  || Decoder Loss:  0.035827626 Validation Decoder Loss:  0.32989278
Model: siamese_net_lr_0.32532061731473033 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32989278
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_363 (Conv3D (None, 235, 10, 20, 1)    345       
_________________________________________________________________
dropout_786 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_364 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_162 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 369
Trainable params: 369
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_788 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_790 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17601526  || Decoder Loss:  0.21834989 Validation Decoder Loss:  0.3589853
Encoder Loss:  0.046079837  || Decoder Loss:  0.044150148 Validation Decoder Loss:  0.2972537
Encoder Loss:  0.04357954  || Decoder Loss:  0.040529784 Validation Decoder Loss:  0.30039844
Encoder Loss:  0.04288277  || Decoder Loss:  0.039516244 Validation Decoder Loss:  0.30102193
Encoder Loss:  0.042736817  || Decoder Loss:  0.039313916 Validation Decoder Loss:  0.3018463
Encoder Loss:  0.042419013  || Decoder Loss:  0.038850285 Validation Decoder Loss:  0.30272496
Encoder Loss:  0.042423345  || Decoder Loss:  0.038847715 Validation Decoder Loss:  0.3030014
Encoder Loss:  0.04222723  || Decoder Loss:  0.038542297 Validation Decoder Loss:  0.30332673
Encoder Loss:  0.041840263  || Decoder Loss:  0.03802788 Validation Decoder Loss:  0.30559397
Encoder Loss:  0.04259155  || Decoder Loss:  0.038967498 Validation Decoder Loss:  0.3060078
Encoder Loss:  0.04151756  || Decoder Loss:  0.03758609 Validation Decoder Loss:  0.30863488
Encoder Loss:  0.041489262  || Decoder Loss:  0.037535157 Validation Decoder Loss:  0.31018984
Encoder Loss:  0.04136488  || Decoder Loss:  0.037329685 Validation Decoder Loss:  0.30922157
Encoder Loss:  0.041462228  || Decoder Loss:  0.037478678 Validation Decoder Loss:  0.31335863
Encoder Loss:  0.043901455  || Decoder Loss:  0.04064279 Validation Decoder Loss:  0.3066272
Encoder Loss:  0.041783098  || Decoder Loss:  0.03798366 Validation Decoder Loss:  0.3070898
Encoder Loss:  0.04147657  || Decoder Loss:  0.037544366 Validation Decoder Loss:  0.3109416
Encoder Loss:  0.04134199  || Decoder Loss:  0.03734187 Validation Decoder Loss:  0.3106627
Encoder Loss:  0.041169878  || Decoder Loss:  0.0370979 Validation Decoder Loss:  0.31375444
Encoder Loss:  0.041059624  || Decoder Loss:  0.03692847 Validation Decoder Loss:  0.3142633
Encoder Loss:  0.041043695  || Decoder Loss:  0.036917575 Validation Decoder Loss:  0.31865105
Encoder Loss:  0.041705944  || Decoder Loss:  0.03783149 Validation Decoder Loss:  0.31249624
Encoder Loss:  0.04152094  || Decoder Loss:  0.03759484 Validation Decoder Loss:  0.31851164
Encoder Loss:  0.04084614  || Decoder Loss:  0.036637038 Validation Decoder Loss:  0.31927368
Encoder Loss:  0.0752718  || Decoder Loss:  0.08638451 Validation Decoder Loss:  0.32746926
Encoder Loss:  0.04066963  || Decoder Loss:  0.036388624 Validation Decoder Loss:  0.3297696
Encoder Loss:  0.040969215  || Decoder Loss:  0.03682515 Validation Decoder Loss:  0.3164099
Encoder Loss:  0.041622184  || Decoder Loss:  0.03777746 Validation Decoder Loss:  0.31370065
Encoder Loss:  0.041662373  || Decoder Loss:  0.03783339 Validation Decoder Loss:  0.31669146
Encoder Loss:  0.041503392  || Decoder Loss:  0.037604723 Validation Decoder Loss:  0.31671208
Encoder Loss:  0.041614227  || Decoder Loss:  0.037764035 Validation Decoder Loss:  0.31613907
Encoder Loss:  0.04143767  || Decoder Loss:  0.037508532 Validation Decoder Loss:  0.317653
Encoder Loss:  0.0418262  || Decoder Loss:  0.03806535 Validation Decoder Loss:  0.31982332
Encoder Loss:  0.04320667  || Decoder Loss:  0.040077582 Validation Decoder Loss:  0.3163048
Encoder Loss:  0.041595116  || Decoder Loss:  0.03773229 Validation Decoder Loss:  0.31445974
Encoder Loss:  0.041987006  || Decoder Loss:  0.038300384 Validation Decoder Loss:  0.3148675
Encoder Loss:  0.044977948  || Decoder Loss:  0.041947536 Validation Decoder Loss:  0.3086215
Encoder Loss:  0.04422029  || Decoder Loss:  0.041568145 Validation Decoder Loss:  0.31124052
Encoder Loss:  0.0433367  || Decoder Loss:  0.04028019 Validation Decoder Loss:  0.31184578
Encoder Loss:  0.042635098  || Decoder Loss:  0.039257806 Validation Decoder Loss:  0.31221876
Model: siamese_net_lr_0.615854292817577 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31221876
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_366 (Conv3D (None, 234, 10, 20, 1)    649       
_________________________________________________________________
dropout_792 (Dropout)        (None, 234, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_367 (Conv3D (None, 257, 10, 20, 1)    25        
_________________________________________________________________
reshape_163 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 674
Trainable params: 674
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_794 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 2570, 20, 1)       12        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_796 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07233624  || Decoder Loss:  0.06485565 Validation Decoder Loss:  0.3466656
Encoder Loss:  0.067053325  || Decoder Loss:  0.06960406 Validation Decoder Loss:  0.3304205
Encoder Loss:  0.06375829  || Decoder Loss:  0.06583826 Validation Decoder Loss:  0.32865924
Encoder Loss:  0.06042465  || Decoder Loss:  0.062000852 Validation Decoder Loss:  0.32819155
Encoder Loss:  0.05765407  || Decoder Loss:  0.058808316 Validation Decoder Loss:  0.33034664
Encoder Loss:  0.055664152  || Decoder Loss:  0.056494113 Validation Decoder Loss:  0.33375636
Encoder Loss:  0.054446336  || Decoder Loss:  0.055109266 Validation Decoder Loss:  0.33734554
Encoder Loss:  0.054000016  || Decoder Loss:  0.05448324 Validation Decoder Loss:  0.32859308
Encoder Loss:  0.063098244  || Decoder Loss:  0.06427756 Validation Decoder Loss:  0.32529104
Encoder Loss:  0.060107864  || Decoder Loss:  0.0616576 Validation Decoder Loss:  0.32577524
Encoder Loss:  0.05714642  || Decoder Loss:  0.058239534 Validation Decoder Loss:  0.32847768
Encoder Loss:  0.05512514  || Decoder Loss:  0.055836726 Validation Decoder Loss:  0.32599252
Encoder Loss:  0.04022851  || Decoder Loss:  0.03841489 Validation Decoder Loss:  0.3302164
Encoder Loss:  0.03809536  || Decoder Loss:  0.03551424 Validation Decoder Loss:  0.3324626
Encoder Loss:  0.03745849  || Decoder Loss:  0.03547759 Validation Decoder Loss:  0.33175886
Encoder Loss:  0.03741274  || Decoder Loss:  0.035435427 Validation Decoder Loss:  0.3318004
Encoder Loss:  0.037370563  || Decoder Loss:  0.035391334 Validation Decoder Loss:  0.33179426
Encoder Loss:  0.037334483  || Decoder Loss:  0.03534486 Validation Decoder Loss:  0.33205462
Encoder Loss:  0.03728707  || Decoder Loss:  0.035299376 Validation Decoder Loss:  0.33208308
Encoder Loss:  0.037271272  || Decoder Loss:  0.035256375 Validation Decoder Loss:  0.33205128
Encoder Loss:  0.03740185  || Decoder Loss:  0.03538935 Validation Decoder Loss:  0.3307084
Encoder Loss:  0.037281916  || Decoder Loss:  0.035289355 Validation Decoder Loss:  0.33163366
Encoder Loss:  0.037379652  || Decoder Loss:  0.03539356 Validation Decoder Loss:  0.32985133
Encoder Loss:  0.037488416  || Decoder Loss:  0.03552341 Validation Decoder Loss:  0.33126837
Encoder Loss:  0.03745904  || Decoder Loss:  0.03549339 Validation Decoder Loss:  0.3304879
Encoder Loss:  0.037619203  || Decoder Loss:  0.03567084 Validation Decoder Loss:  0.32744908
Encoder Loss:  0.03736261  || Decoder Loss:  0.03538796 Validation Decoder Loss:  0.32912326
Encoder Loss:  0.037352506  || Decoder Loss:  0.035374876 Validation Decoder Loss:  0.32787
Encoder Loss:  0.03742229  || Decoder Loss:  0.035459064 Validation Decoder Loss:  0.32969517
Encoder Loss:  0.037391435  || Decoder Loss:  0.0354179 Validation Decoder Loss:  0.33008438
Encoder Loss:  0.037424125  || Decoder Loss:  0.035461035 Validation Decoder Loss:  0.32920176
Encoder Loss:  0.037342437  || Decoder Loss:  0.035364512 Validation Decoder Loss:  0.33051166
Encoder Loss:  0.037399217  || Decoder Loss:  0.035423752 Validation Decoder Loss:  0.3291669
Encoder Loss:  0.037417673  || Decoder Loss:  0.035451055 Validation Decoder Loss:  0.32919016
Encoder Loss:  0.037323963  || Decoder Loss:  0.035344496 Validation Decoder Loss:  0.32942402
Encoder Loss:  0.037328944  || Decoder Loss:  0.035350613 Validation Decoder Loss:  0.33016714
Encoder Loss:  0.037296977  || Decoder Loss:  0.03531511 Validation Decoder Loss:  0.32173404
Encoder Loss:  0.037389725  || Decoder Loss:  0.035422448 Validation Decoder Loss:  0.32868153
Encoder Loss:  0.037313983  || Decoder Loss:  0.035336535 Validation Decoder Loss:  0.32973444
Encoder Loss:  0.03727977  || Decoder Loss:  0.03529516 Validation Decoder Loss:  0.3306362
Model: siamese_net_lr_0.3368034626355867 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306362
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_369 (Conv3D (None, 88, 10, 20, 1)     51        
_________________________________________________________________
dropout_798 (Dropout)        (None, 88, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_370 (Conv3D (None, 257, 10, 20, 1)    171       
_________________________________________________________________
reshape_164 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 222
Trainable params: 222
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_800 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_597"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 2580, 20, 1)       12        
_________________________________________________________________
dropout_802 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.065326884  || Decoder Loss:  0.49979427 Validation Decoder Loss:  0.8570664
Encoder Loss:  0.057568673  || Decoder Loss:  0.50186944 Validation Decoder Loss:  0.85368246
Encoder Loss:  0.057530995  || Decoder Loss:  0.4999815 Validation Decoder Loss:  1.146996
Encoder Loss:  0.05742821  || Decoder Loss:  0.49369925 Validation Decoder Loss:  1.1461254
Encoder Loss:  0.057515845  || Decoder Loss:  0.49907804 Validation Decoder Loss:  1.1512934
Encoder Loss:  0.057473026  || Decoder Loss:  0.49690086 Validation Decoder Loss:  1.1551275
Encoder Loss:  0.05744439  || Decoder Loss:  0.49491733 Validation Decoder Loss:  1.1561978
Encoder Loss:  0.057527374  || Decoder Loss:  0.49931008 Validation Decoder Loss:  0.8486117
Encoder Loss:  0.057626713  || Decoder Loss:  0.5023949 Validation Decoder Loss:  0.85589874
Encoder Loss:  0.057557486  || Decoder Loss:  0.50124574 Validation Decoder Loss:  0.86574996
Encoder Loss:  0.057512283  || Decoder Loss:  0.49880973 Validation Decoder Loss:  0.8550758
Encoder Loss:  0.057558812  || Decoder Loss:  0.50060445 Validation Decoder Loss:  0.85142064
Encoder Loss:  0.05753985  || Decoder Loss:  0.49982175 Validation Decoder Loss:  0.853194
Encoder Loss:  0.057516523  || Decoder Loss:  0.4983373 Validation Decoder Loss:  0.8524194
Encoder Loss:  0.057553764  || Decoder Loss:  0.50096357 Validation Decoder Loss:  0.8568414
Encoder Loss:  0.057542905  || Decoder Loss:  0.49703583 Validation Decoder Loss:  0.8682436
Encoder Loss:  0.057558373  || Decoder Loss:  0.5013426 Validation Decoder Loss:  0.8443482
Encoder Loss:  0.057562176  || Decoder Loss:  0.5002256 Validation Decoder Loss:  0.84674525
Encoder Loss:  0.057614706  || Decoder Loss:  0.5006245 Validation Decoder Loss:  1.1943704
Encoder Loss:  0.05921689  || Decoder Loss:  0.49836457 Validation Decoder Loss:  1.1626179
Encoder Loss:  0.05746829  || Decoder Loss:  0.49661458 Validation Decoder Loss:  1.165592
Encoder Loss:  0.05745184  || Decoder Loss:  0.49526525 Validation Decoder Loss:  1.1628385
Encoder Loss:  0.05741063  || Decoder Loss:  0.4928773 Validation Decoder Loss:  1.0891378
Encoder Loss:  0.05739949  || Decoder Loss:  0.49234843 Validation Decoder Loss:  1.078181
Encoder Loss:  0.05739891  || Decoder Loss:  0.49216104 Validation Decoder Loss:  1.013575
Encoder Loss:  0.05743039  || Decoder Loss:  0.49375755 Validation Decoder Loss:  1.0448527
Encoder Loss:  0.05742909  || Decoder Loss:  0.4932435 Validation Decoder Loss:  1.1625067
Encoder Loss:  0.057418715  || Decoder Loss:  0.4934789 Validation Decoder Loss:  1.1631491
Encoder Loss:  0.05744142  || Decoder Loss:  0.49395168 Validation Decoder Loss:  1.1611567
Encoder Loss:  0.05750873  || Decoder Loss:  0.49779642 Validation Decoder Loss:  0.9042952
Encoder Loss:  0.057422314  || Decoder Loss:  0.49279135 Validation Decoder Loss:  1.1602811
Encoder Loss:  0.057441797  || Decoder Loss:  0.49384364 Validation Decoder Loss:  1.1637949
Encoder Loss:  0.057431534  || Decoder Loss:  0.4936153 Validation Decoder Loss:  1.1616151
Encoder Loss:  0.057527307  || Decoder Loss:  0.49932706 Validation Decoder Loss:  1.1630245
Encoder Loss:  0.057507835  || Decoder Loss:  0.49823865 Validation Decoder Loss:  1.1669375
Encoder Loss:  0.0575617  || Decoder Loss:  0.5003828 Validation Decoder Loss:  0.8434154
Encoder Loss:  0.05744607  || Decoder Loss:  0.49361163 Validation Decoder Loss:  0.8291447
Encoder Loss:  0.05742006  || Decoder Loss:  0.49251133 Validation Decoder Loss:  1.117625
Encoder Loss:  0.05741004  || Decoder Loss:  0.49163663 Validation Decoder Loss:  1.1692897
Encoder Loss:  0.057443716  || Decoder Loss:  0.49387628 Validation Decoder Loss:  1.1658906
Model: siamese_net_lr_0.6951082171330285 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1658906
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_372 (Conv3D (None, 235, 10, 20, 1)    1033      
_________________________________________________________________
dropout_804 (Dropout)        (None, 235, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_373 (Conv3D (None, 257, 10, 20, 1)    24        
_________________________________________________________________
reshape_165 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_806 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 2570, 20, 1)       32        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_808 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31269273  || Decoder Loss:  0.4384681 Validation Decoder Loss:  1.0474286
Encoder Loss:  0.3270588  || Decoder Loss:  0.4712556 Validation Decoder Loss:  0.9967166
Encoder Loss:  0.06205347  || Decoder Loss:  0.06827581 Validation Decoder Loss:  0.316678
Encoder Loss:  0.04142036  || Decoder Loss:  0.036886953 Validation Decoder Loss:  0.318627
Encoder Loss:  0.041364074  || Decoder Loss:  0.036804613 Validation Decoder Loss:  0.3182037
Encoder Loss:  0.04204173  || Decoder Loss:  0.0377467 Validation Decoder Loss:  0.31740212
Encoder Loss:  0.04136888  || Decoder Loss:  0.0367472 Validation Decoder Loss:  0.31174135
Encoder Loss:  0.24489003  || Decoder Loss:  0.34385446 Validation Decoder Loss:  0.6648108
Encoder Loss:  0.07042012  || Decoder Loss:  0.08101933 Validation Decoder Loss:  0.31233478
Encoder Loss:  0.041407272  || Decoder Loss:  0.036898915 Validation Decoder Loss:  0.33599123
Encoder Loss:  0.041549988  || Decoder Loss:  0.037101474 Validation Decoder Loss:  0.33646327
Encoder Loss:  0.04146302  || Decoder Loss:  0.03698329 Validation Decoder Loss:  0.33716595
Encoder Loss:  0.04121597  || Decoder Loss:  0.03660479 Validation Decoder Loss:  0.33631554
Encoder Loss:  0.04176613  || Decoder Loss:  0.03744632 Validation Decoder Loss:  0.31467253
Encoder Loss:  0.041044336  || Decoder Loss:  0.036345154 Validation Decoder Loss:  0.3161015
Encoder Loss:  0.041204244  || Decoder Loss:  0.036589317 Validation Decoder Loss:  0.31728524
Encoder Loss:  0.040972102  || Decoder Loss:  0.0362385 Validation Decoder Loss:  0.31804216
Encoder Loss:  0.04113789  || Decoder Loss:  0.036483686 Validation Decoder Loss:  0.31832355
Encoder Loss:  0.0410444  || Decoder Loss:  0.036335394 Validation Decoder Loss:  0.31806725
Encoder Loss:  0.041002955  || Decoder Loss:  0.036266126 Validation Decoder Loss:  0.3180399
Encoder Loss:  0.042649046  || Decoder Loss:  0.038489513 Validation Decoder Loss:  0.31457818
Encoder Loss:  0.040976707  || Decoder Loss:  0.036256384 Validation Decoder Loss:  0.3197924
Encoder Loss:  0.040760536  || Decoder Loss:  0.035936777 Validation Decoder Loss:  0.32101932
Encoder Loss:  0.04075211  || Decoder Loss:  0.035921738 Validation Decoder Loss:  0.32152563
Encoder Loss:  0.04363866  || Decoder Loss:  0.03969019 Validation Decoder Loss:  0.3182826
Encoder Loss:  0.041041788  || Decoder Loss:  0.03636702 Validation Decoder Loss:  0.3193068
Encoder Loss:  0.040926162  || Decoder Loss:  0.036193315 Validation Decoder Loss:  0.31945166
Encoder Loss:  0.04082499  || Decoder Loss:  0.036038805 Validation Decoder Loss:  0.32038358
Encoder Loss:  0.040805653  || Decoder Loss:  0.03601112 Validation Decoder Loss:  0.32069844
Encoder Loss:  0.040795445  || Decoder Loss:  0.035994936 Validation Decoder Loss:  0.3207218
Encoder Loss:  0.040743977  || Decoder Loss:  0.03591587 Validation Decoder Loss:  0.3207081
Encoder Loss:  0.040685426  || Decoder Loss:  0.035822123 Validation Decoder Loss:  0.3206634
Encoder Loss:  0.0406728  || Decoder Loss:  0.035805453 Validation Decoder Loss:  0.32171974
Encoder Loss:  0.04076694  || Decoder Loss:  0.035941973 Validation Decoder Loss:  0.32213745
Encoder Loss:  0.04077189  || Decoder Loss:  0.035954807 Validation Decoder Loss:  0.31977123
Encoder Loss:  0.04117582  || Decoder Loss:  0.03652758 Validation Decoder Loss:  0.3203898
Encoder Loss:  0.040907454  || Decoder Loss:  0.03616126 Validation Decoder Loss:  0.32077456
Encoder Loss:  0.040869758  || Decoder Loss:  0.03610586 Validation Decoder Loss:  0.32460338
Encoder Loss:  0.15403943  || Decoder Loss:  0.2079196 Validation Decoder Loss:  0.7845424
Encoder Loss:  0.3354447  || Decoder Loss:  0.48403987 Validation Decoder Loss:  1.1605794
Model: siamese_net_lr_0.5731919381171274 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1605794
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_375 (Conv3D (None, 236, 10, 20, 1)    283       
_________________________________________________________________
dropout_810 (Dropout)        (None, 236, 10, 20, 1)    0         
_________________________________________________________________
conv3d_transpose_376 (Conv3D (None, 257, 10, 20, 1)    23        
_________________________________________________________________
reshape_166 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 306
Trainable params: 306
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_812 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 2570, 20, 1)       22        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 2570, 20, 1)       2         
_________________________________________________________________
dropout_814 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.103808835  || Decoder Loss:  0.050602876 Validation Decoder Loss:  0.3283596
Encoder Loss:  0.056853212  || Decoder Loss:  0.039243165 Validation Decoder Loss:  0.33083585
Encoder Loss:  0.050848417  || Decoder Loss:  0.03945566 Validation Decoder Loss:  0.33060682
Encoder Loss:  0.047794417  || Decoder Loss:  0.03692136 Validation Decoder Loss:  0.33065635
Encoder Loss:  0.047718953  || Decoder Loss:  0.03658117 Validation Decoder Loss:  0.33059004
Encoder Loss:  0.047674794  || Decoder Loss:  0.036331866 Validation Decoder Loss:  0.33062977
Encoder Loss:  0.047651533  || Decoder Loss:  0.036097694 Validation Decoder Loss:  0.33022565
Encoder Loss:  0.047610298  || Decoder Loss:  0.035970062 Validation Decoder Loss:  0.3293404
Encoder Loss:  0.16269284  || Decoder Loss:  0.41856956 Validation Decoder Loss:  0.96925086
Encoder Loss:  0.06406698  || Decoder Loss:  0.10340097 Validation Decoder Loss:  0.3321458
Encoder Loss:  0.05215673  || Decoder Loss:  0.040761013 Validation Decoder Loss:  0.34349763
Encoder Loss:  0.05065381  || Decoder Loss:  0.040832147 Validation Decoder Loss:  0.3395213
Encoder Loss:  0.048146166  || Decoder Loss:  0.039015647 Validation Decoder Loss:  0.3369817
Encoder Loss:  0.048023865  || Decoder Loss:  0.03837744 Validation Decoder Loss:  0.33554608
Encoder Loss:  0.047951687  || Decoder Loss:  0.03792746 Validation Decoder Loss:  0.33445027
Encoder Loss:  0.047879208  || Decoder Loss:  0.037539616 Validation Decoder Loss:  0.33331382
Encoder Loss:  0.04786212  || Decoder Loss:  0.03730663 Validation Decoder Loss:  0.33299142
Encoder Loss:  0.04779874  || Decoder Loss:  0.037061278 Validation Decoder Loss:  0.33250588
Encoder Loss:  0.04773321  || Decoder Loss:  0.036751077 Validation Decoder Loss:  0.33189693
Encoder Loss:  0.04773325  || Decoder Loss:  0.036597613 Validation Decoder Loss:  0.33268636
Encoder Loss:  0.054471456  || Decoder Loss:  0.0389939 Validation Decoder Loss:  0.33417833
Encoder Loss:  0.049700238  || Decoder Loss:  0.03805506 Validation Decoder Loss:  0.3344054
Encoder Loss:  0.0491187  || Decoder Loss:  0.037957665 Validation Decoder Loss:  0.33254436
Encoder Loss:  0.04783971  || Decoder Loss:  0.03734684 Validation Decoder Loss:  0.33222812
Encoder Loss:  0.04779797  || Decoder Loss:  0.037163388 Validation Decoder Loss:  0.33180428
Encoder Loss:  0.04774931  || Decoder Loss:  0.03686804 Validation Decoder Loss:  0.33161205
Encoder Loss:  0.04772255  || Decoder Loss:  0.0367085 Validation Decoder Loss:  0.33134773
Encoder Loss:  0.047698192  || Decoder Loss:  0.036568277 Validation Decoder Loss:  0.33130443
Encoder Loss:  0.047672443  || Decoder Loss:  0.036420535 Validation Decoder Loss:  0.33125067
Encoder Loss:  0.047608875  || Decoder Loss:  0.036065746 Validation Decoder Loss:  0.32874426
Encoder Loss:  0.047604375  || Decoder Loss:  0.036044333 Validation Decoder Loss:  0.32881692
Encoder Loss:  0.047632065  || Decoder Loss:  0.03620807 Validation Decoder Loss:  0.33162412
Encoder Loss:  0.047605034  || Decoder Loss:  0.03607272 Validation Decoder Loss:  0.3292595
Encoder Loss:  0.04926118  || Decoder Loss:  0.045629445 Validation Decoder Loss:  0.3312801
Encoder Loss:  0.04887084  || Decoder Loss:  0.0433778 Validation Decoder Loss:  0.32931125
Encoder Loss:  0.04918334  || Decoder Loss:  0.04480539 Validation Decoder Loss:  0.32871908
Encoder Loss:  0.048790537  || Decoder Loss:  0.042972326 Validation Decoder Loss:  0.32903916
Encoder Loss:  0.04869692  || Decoder Loss:  0.04242803 Validation Decoder Loss:  0.32943523
Encoder Loss:  0.04865198  || Decoder Loss:  0.042169873 Validation Decoder Loss:  0.32946855
Encoder Loss:  0.04861018  || Decoder Loss:  0.041922234 Validation Decoder Loss:  0.32990247
Model: siamese_net_lr_0.3017989068272755 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32990247
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.3246876001358032 2
[(257, 10, 20, 1)] [(2570, 20, 1)]
[(2570, 20, 1)] [(2570, 20, 1)]
[(2607, 20, 1)] [(2570, 20, 1)]
