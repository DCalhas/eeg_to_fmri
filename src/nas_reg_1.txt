Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 3245, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-19 11:46:33.922576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-19 11:46:33.939660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-19 11:46:33.939831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 11:46:33.940898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-19 11:46:33.941974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-19 11:46:33.942188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-19 11:46:33.943125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-19 11:46:33.943643: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-19 11:46:33.945663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-19 11:46:33.946798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-19 11:46:33.947018: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-19 11:46:33.975912: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-19 11:46:33.977546: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc567bc550 executing computations on platform Host. Devices:
2019-11-19 11:46:33.977601: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-19 11:46:33.979607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-19 11:46:33.979692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 11:46:33.979720: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-19 11:46:33.979743: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-19 11:46:33.979766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-19 11:46:33.979788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-19 11:46:33.979811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-19 11:46:33.979834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-19 11:46:33.983472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-19 11:46:33.983528: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 11:46:34.210990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-19 11:46:34.211026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-19 11:46:34.211031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-19 11:46:34.213661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-19 11:46:34.215793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc57502fb0 executing computations on platform CUDA. Devices:
2019-11-19 11:46:34.215823: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-19 11:46:34.596620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 3245, 20)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 70, 6, 20, 1)      15        
_________________________________________________________________
reshape (Reshape)            (None, 420, 20, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 420, 20, 1)        732       
=================================================================
Total params: 732
Trainable params: 732
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 3245, 20, 1)       1570      
=================================================================
Total params: 1,570
Trainable params: 1,570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30642375  || Decoder Loss:  0.31078765 Validation Decoder Loss:  0.43576157
Encoder Loss:  0.08465335  || Decoder Loss:  0.0779613 Validation Decoder Loss:  0.3709789
Encoder Loss:  0.051917735  || Decoder Loss:  0.045238934 Validation Decoder Loss:  0.3444808
Encoder Loss:  0.04415536  || Decoder Loss:  0.038008418 Validation Decoder Loss:  0.34513098
Encoder Loss:  0.04124958  || Decoder Loss:  0.035150267 Validation Decoder Loss:  0.37287116
Encoder Loss:  0.03945925  || Decoder Loss:  0.033914868 Validation Decoder Loss:  0.35799628
Encoder Loss:  0.03802951  || Decoder Loss:  0.033076573 Validation Decoder Loss:  0.35874736
Encoder Loss:  0.037519336  || Decoder Loss:  0.032486748 Validation Decoder Loss:  0.3550666
Encoder Loss:  0.036938842  || Decoder Loss:  0.0321977 Validation Decoder Loss:  0.35534135
Encoder Loss:  0.036535755  || Decoder Loss:  0.032049015 Validation Decoder Loss:  0.3528697
Encoder Loss:  0.035700332  || Decoder Loss:  0.03188384 Validation Decoder Loss:  0.3636805
Encoder Loss:  0.036734942  || Decoder Loss:  0.0317655 Validation Decoder Loss:  0.3521666
Encoder Loss:  0.03635626  || Decoder Loss:  0.03166874 Validation Decoder Loss:  0.34539032
Encoder Loss:  0.03624178  || Decoder Loss:  0.031560473 Validation Decoder Loss:  0.3529955
Encoder Loss:  0.034962367  || Decoder Loss:  0.031387553 Validation Decoder Loss:  0.3538963
Encoder Loss:  0.035515107  || Decoder Loss:  0.031364784 Validation Decoder Loss:  0.34651005
Encoder Loss:  0.034179974  || Decoder Loss:  0.03122386 Validation Decoder Loss:  0.35685158
Encoder Loss:  0.034348484  || Decoder Loss:  0.031256348 Validation Decoder Loss:  0.3506766
Encoder Loss:  0.03564941  || Decoder Loss:  0.031469617 Validation Decoder Loss:  0.3438318
Encoder Loss:  0.0349964  || Decoder Loss:  0.03138599 Validation Decoder Loss:  0.3432502
Encoder Loss:  0.035920188  || Decoder Loss:  0.03134488 Validation Decoder Loss:  0.344903
Encoder Loss:  0.037275013  || Decoder Loss:  0.031403687 Validation Decoder Loss:  0.35495666
Encoder Loss:  0.036337066  || Decoder Loss:  0.031404007 Validation Decoder Loss:  0.3573813
Encoder Loss:  0.039312087  || Decoder Loss:  0.031416073 Validation Decoder Loss:  0.35200673
Encoder Loss:  0.03536525  || Decoder Loss:  0.031183738 Validation Decoder Loss:  0.3520701
Encoder Loss:  0.033946995  || Decoder Loss:  0.031046009 Validation Decoder Loss:  0.35231858
Encoder Loss:  0.03380763  || Decoder Loss:  0.031026749 Validation Decoder Loss:  0.34791815
Encoder Loss:  0.032908835  || Decoder Loss:  0.030949915 Validation Decoder Loss:  0.34651077
Encoder Loss:  0.03350862  || Decoder Loss:  0.030905144 Validation Decoder Loss:  0.3427304
Encoder Loss:  0.03430225  || Decoder Loss:  0.031164698 Validation Decoder Loss:  0.35044876
Encoder Loss:  0.03378061  || Decoder Loss:  0.030899508 Validation Decoder Loss:  0.34841868
Encoder Loss:  0.03472999  || Decoder Loss:  0.030926779 Validation Decoder Loss:  0.3513071
Encoder Loss:  0.036080763  || Decoder Loss:  0.031117909 Validation Decoder Loss:  0.35069358
Encoder Loss:  0.03359352  || Decoder Loss:  0.030901305 Validation Decoder Loss:  0.34972176
Encoder Loss:  0.033916377  || Decoder Loss:  0.030862028 Validation Decoder Loss:  0.34950083
Encoder Loss:  0.032766987  || Decoder Loss:  0.030795021 Validation Decoder Loss:  0.34892723
Encoder Loss:  0.033138588  || Decoder Loss:  0.03074867 Validation Decoder Loss:  0.34854257
Encoder Loss:  0.03389075  || Decoder Loss:  0.030833228 Validation Decoder Loss:  0.34729692
Encoder Loss:  0.036928914  || Decoder Loss:  0.0311472 Validation Decoder Loss:  0.35259035
Encoder Loss:  0.035365272  || Decoder Loss:  0.030934988 Validation Decoder Loss:  0.35211515
Model: siamese_net_lr_0.02158124350988271 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35211518
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 151, 20, 20, 1)    353       
_________________________________________________________________
reshape_1 (Reshape)          (None, 3020, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24986766  || Decoder Loss:  0.17255524 Validation Decoder Loss:  0.32496673
Encoder Loss:  0.110968344  || Decoder Loss:  0.08192721 Validation Decoder Loss:  0.35764626
Encoder Loss:  0.05315785  || Decoder Loss:  0.037735865 Validation Decoder Loss:  0.36346343
Encoder Loss:  0.056501254  || Decoder Loss:  0.03674803 Validation Decoder Loss:  0.35808063
Encoder Loss:  0.055751447  || Decoder Loss:  0.036132477 Validation Decoder Loss:  0.35658693
Encoder Loss:  0.051294185  || Decoder Loss:  0.035677172 Validation Decoder Loss:  0.35516137
Encoder Loss:  0.05026634  || Decoder Loss:  0.035351183 Validation Decoder Loss:  0.3543352
Encoder Loss:  0.056511678  || Decoder Loss:  0.035148997 Validation Decoder Loss:  0.35194695
Encoder Loss:  0.053706747  || Decoder Loss:  0.035126787 Validation Decoder Loss:  0.35224336
Encoder Loss:  0.053669747  || Decoder Loss:  0.03495191 Validation Decoder Loss:  0.35134864
Encoder Loss:  0.05319109  || Decoder Loss:  0.03495256 Validation Decoder Loss:  0.35101107
Encoder Loss:  0.048578992  || Decoder Loss:  0.0348068 Validation Decoder Loss:  0.3504792
Encoder Loss:  0.049775805  || Decoder Loss:  0.034775443 Validation Decoder Loss:  0.34998977
Encoder Loss:  0.052025262  || Decoder Loss:  0.034727313 Validation Decoder Loss:  0.3496184
Encoder Loss:  0.051564865  || Decoder Loss:  0.034713067 Validation Decoder Loss:  0.34895825
Encoder Loss:  0.053678025  || Decoder Loss:  0.034636807 Validation Decoder Loss:  0.34905714
Encoder Loss:  0.049707886  || Decoder Loss:  0.034622144 Validation Decoder Loss:  0.34918767
Encoder Loss:  0.050385445  || Decoder Loss:  0.03460672 Validation Decoder Loss:  0.34875268
Encoder Loss:  0.057671424  || Decoder Loss:  0.034577318 Validation Decoder Loss:  0.34876874
Encoder Loss:  0.05087963  || Decoder Loss:  0.034550976 Validation Decoder Loss:  0.34882072
Encoder Loss:  0.047580358  || Decoder Loss:  0.034531 Validation Decoder Loss:  0.34881872
Encoder Loss:  0.047930174  || Decoder Loss:  0.034502875 Validation Decoder Loss:  0.34884447
Encoder Loss:  0.05037808  || Decoder Loss:  0.034478758 Validation Decoder Loss:  0.34873614
Encoder Loss:  0.048180804  || Decoder Loss:  0.034463122 Validation Decoder Loss:  0.34862322
Encoder Loss:  0.053328503  || Decoder Loss:  0.03444052 Validation Decoder Loss:  0.348345
Encoder Loss:  0.049390573  || Decoder Loss:  0.034402434 Validation Decoder Loss:  0.3483476
Encoder Loss:  0.04821916  || Decoder Loss:  0.03438944 Validation Decoder Loss:  0.34815216
Encoder Loss:  0.053119507  || Decoder Loss:  0.034359384 Validation Decoder Loss:  0.34821898
Encoder Loss:  0.056156583  || Decoder Loss:  0.034338232 Validation Decoder Loss:  0.34834448
Encoder Loss:  0.050581437  || Decoder Loss:  0.03432841 Validation Decoder Loss:  0.34811586
Encoder Loss:  0.04750572  || Decoder Loss:  0.03430035 Validation Decoder Loss:  0.3479283
Encoder Loss:  0.047539778  || Decoder Loss:  0.03428113 Validation Decoder Loss:  0.34793904
Encoder Loss:  0.048553385  || Decoder Loss:  0.03426186 Validation Decoder Loss:  0.34795702
Encoder Loss:  0.0530566  || Decoder Loss:  0.034246348 Validation Decoder Loss:  0.34791976
Encoder Loss:  0.049739458  || Decoder Loss:  0.03422638 Validation Decoder Loss:  0.34790015
Encoder Loss:  0.046658974  || Decoder Loss:  0.034210633 Validation Decoder Loss:  0.34789383
Encoder Loss:  0.051356975  || Decoder Loss:  0.034194574 Validation Decoder Loss:  0.34793907
Encoder Loss:  0.04831817  || Decoder Loss:  0.034181476 Validation Decoder Loss:  0.34795573
Encoder Loss:  0.04951513  || Decoder Loss:  0.034165863 Validation Decoder Loss:  0.34790623
Encoder Loss:  0.047807824  || Decoder Loss:  0.034152508 Validation Decoder Loss:  0.34781703
Model: siamese_net_lr_0.005206479021859143 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.347817
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 564, 5, 20, 1)     502       
_________________________________________________________________
reshape_2 (Reshape)          (None, 2820, 20, 1)       0         
=================================================================
Total params: 502
Trainable params: 502
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 2820, 20, 1)       427       
=================================================================
Total params: 427
Trainable params: 427
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 3245, 20, 1)       427       
=================================================================
Total params: 427
Trainable params: 427
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.60137796  || Decoder Loss:  0.93762517 Validation Decoder Loss:  1.6433058
Encoder Loss:  0.6111639  || Decoder Loss:  0.95483917 Validation Decoder Loss:  1.6428497
Encoder Loss:  0.61089796  || Decoder Loss:  0.95453155 Validation Decoder Loss:  1.6422389
Encoder Loss:  0.61052084  || Decoder Loss:  0.9540967 Validation Decoder Loss:  1.6414411
Encoder Loss:  0.6099921  || Decoder Loss:  0.9534962 Validation Decoder Loss:  1.6404176
Encoder Loss:  0.60924375  || Decoder Loss:  0.95266175 Validation Decoder Loss:  1.6391072
Encoder Loss:  0.60816187  || Decoder Loss:  0.95148057 Validation Decoder Loss:  1.6374105
Encoder Loss:  0.6065489  || Decoder Loss:  0.949758 Validation Decoder Loss:  1.6351545
Encoder Loss:  0.60404426  || Decoder Loss:  0.9471431 Validation Decoder Loss:  1.6320055
Encoder Loss:  0.59993494  || Decoder Loss:  0.94294685 Validation Decoder Loss:  1.627228
Encoder Loss:  0.59261817  || Decoder Loss:  0.93562186 Validation Decoder Loss:  1.6188484
Encoder Loss:  0.5776008  || Decoder Loss:  0.9207979 Validation Decoder Loss:  1.5995795
Encoder Loss:  0.53537226  || Decoder Loss:  0.8788202 Validation Decoder Loss:  1.5158435
Encoder Loss:  0.3229559  || Decoder Loss:  0.62211967 Validation Decoder Loss:  0.9765045
Encoder Loss:  0.20612007  || Decoder Loss:  0.49606192 Validation Decoder Loss:  1.0639503
Encoder Loss:  0.20023762  || Decoder Loss:  0.4968982 Validation Decoder Loss:  1.0713573
Encoder Loss:  0.19930023  || Decoder Loss:  0.49905562 Validation Decoder Loss:  1.0792863
Encoder Loss:  0.19855022  || Decoder Loss:  0.49818245 Validation Decoder Loss:  1.082158
Encoder Loss:  0.19772702  || Decoder Loss:  0.4962132 Validation Decoder Loss:  1.0981256
Encoder Loss:  0.19848233  || Decoder Loss:  0.50009775 Validation Decoder Loss:  1.081223
Encoder Loss:  0.19792126  || Decoder Loss:  0.49696895 Validation Decoder Loss:  1.0863972
Encoder Loss:  0.19972514  || Decoder Loss:  0.49543735 Validation Decoder Loss:  1.0510495
Encoder Loss:  0.19814947  || Decoder Loss:  0.49739373 Validation Decoder Loss:  1.0818064
Encoder Loss:  0.1981116  || Decoder Loss:  0.49691245 Validation Decoder Loss:  1.072434
Encoder Loss:  0.19654289  || Decoder Loss:  0.4958613 Validation Decoder Loss:  1.0710154
Encoder Loss:  0.19700246  || Decoder Loss:  0.49668533 Validation Decoder Loss:  1.074918
Encoder Loss:  0.19703606  || Decoder Loss:  0.4955269 Validation Decoder Loss:  1.0627657
Encoder Loss:  0.19654436  || Decoder Loss:  0.4956796 Validation Decoder Loss:  1.0576422
Encoder Loss:  0.19658455  || Decoder Loss:  0.4949444 Validation Decoder Loss:  1.0687621
Encoder Loss:  0.1990513  || Decoder Loss:  0.49344772 Validation Decoder Loss:  1.0429144
Encoder Loss:  0.19653666  || Decoder Loss:  0.49521264 Validation Decoder Loss:  1.0428977
Encoder Loss:  0.19621564  || Decoder Loss:  0.4936432 Validation Decoder Loss:  1.0498126
Encoder Loss:  0.19651304  || Decoder Loss:  0.49339134 Validation Decoder Loss:  1.050494
Encoder Loss:  0.19642344  || Decoder Loss:  0.49276313 Validation Decoder Loss:  1.0370532
Encoder Loss:  0.19569887  || Decoder Loss:  0.4927326 Validation Decoder Loss:  1.0187972
Encoder Loss:  0.195358  || Decoder Loss:  0.49112105 Validation Decoder Loss:  1.0199403
Encoder Loss:  0.19726503  || Decoder Loss:  0.4876122 Validation Decoder Loss:  0.9911519
Encoder Loss:  0.19453712  || Decoder Loss:  0.4844758 Validation Decoder Loss:  0.97136927
Encoder Loss:  0.18806055  || Decoder Loss:  0.46705315 Validation Decoder Loss:  0.80116296
Encoder Loss:  0.16926028  || Decoder Loss:  0.40905607 Validation Decoder Loss:  0.9686082
Model: siamese_net_lr_0.08482990356808423 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.96860826
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 294, 5, 20, 1)     232       
_________________________________________________________________
reshape_3 (Reshape)          (None, 1470, 20, 1)       0         
=================================================================
Total params: 232
Trainable params: 232
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 1470, 20, 1)       308       
=================================================================
Total params: 308
Trainable params: 308
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 3245, 20, 1)       308       
=================================================================
Total params: 308
Trainable params: 308
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40931052  || Decoder Loss:  0.4024607 Validation Decoder Loss:  0.37734511
Encoder Loss:  0.13783208  || Decoder Loss:  0.043445677 Validation Decoder Loss:  0.36317396
Encoder Loss:  0.13712108  || Decoder Loss:  0.04307687 Validation Decoder Loss:  0.37062365
Encoder Loss:  0.13897564  || Decoder Loss:  0.046718348 Validation Decoder Loss:  0.38578472
Encoder Loss:  0.14405529  || Decoder Loss:  0.05650931 Validation Decoder Loss:  0.42523137
Encoder Loss:  0.16789408  || Decoder Loss:  0.10159839 Validation Decoder Loss:  0.688612
Encoder Loss:  0.37464306  || Decoder Loss:  0.45403355 Validation Decoder Loss:  1.2346177
Encoder Loss:  0.38656643  || Decoder Loss:  0.48449612 Validation Decoder Loss:  1.1875701
Encoder Loss:  0.38628507  || Decoder Loss:  0.4859994 Validation Decoder Loss:  1.1826246
Encoder Loss:  0.38325587  || Decoder Loss:  0.48335865 Validation Decoder Loss:  1.1772852
Encoder Loss:  0.3825829  || Decoder Loss:  0.48315048 Validation Decoder Loss:  1.1686232
Encoder Loss:  0.38056287  || Decoder Loss:  0.4790514 Validation Decoder Loss:  1.2069865
Encoder Loss:  0.37384164  || Decoder Loss:  0.47037262 Validation Decoder Loss:  1.1204048
Encoder Loss:  0.3486449  || Decoder Loss:  0.43819112 Validation Decoder Loss:  0.7635936
Encoder Loss:  0.346294  || Decoder Loss:  0.43540367 Validation Decoder Loss:  0.8583126
Encoder Loss:  0.33040646  || Decoder Loss:  0.41394794 Validation Decoder Loss:  0.7883061
Encoder Loss:  0.32113078  || Decoder Loss:  0.4022041 Validation Decoder Loss:  1.0528768
Encoder Loss:  0.22136046  || Decoder Loss:  0.27147806 Validation Decoder Loss:  0.4654708
Encoder Loss:  0.05490571  || Decoder Loss:  0.05414528 Validation Decoder Loss:  0.38232738
Encoder Loss:  0.042284284  || Decoder Loss:  0.037885323 Validation Decoder Loss:  0.36331356
Encoder Loss:  0.040382612  || Decoder Loss:  0.034892824 Validation Decoder Loss:  0.3701633
Encoder Loss:  0.04132297  || Decoder Loss:  0.03517996 Validation Decoder Loss:  0.3424206
Encoder Loss:  0.040799018  || Decoder Loss:  0.034929577 Validation Decoder Loss:  0.33334425
Encoder Loss:  0.041400213  || Decoder Loss:  0.036457416 Validation Decoder Loss:  0.34108117
Encoder Loss:  0.03876865  || Decoder Loss:  0.03404458 Validation Decoder Loss:  0.34302688
Encoder Loss:  0.0391322  || Decoder Loss:  0.03362546 Validation Decoder Loss:  0.34765047
Encoder Loss:  0.040299635  || Decoder Loss:  0.034934424 Validation Decoder Loss:  0.37369752
Encoder Loss:  0.04461985  || Decoder Loss:  0.03926451 Validation Decoder Loss:  0.35714376
Encoder Loss:  0.040942825  || Decoder Loss:  0.03579986 Validation Decoder Loss:  0.37827086
Encoder Loss:  0.041307315  || Decoder Loss:  0.03703393 Validation Decoder Loss:  0.3537496
Encoder Loss:  0.039317273  || Decoder Loss:  0.034517787 Validation Decoder Loss:  0.37728208
Encoder Loss:  0.041495346  || Decoder Loss:  0.0361622 Validation Decoder Loss:  0.33775732
Encoder Loss:  0.04124917  || Decoder Loss:  0.03718706 Validation Decoder Loss:  0.33486864
Encoder Loss:  0.038793553  || Decoder Loss:  0.034247912 Validation Decoder Loss:  0.35615927
Encoder Loss:  0.03870418  || Decoder Loss:  0.03415199 Validation Decoder Loss:  0.35099548
Encoder Loss:  0.04055138  || Decoder Loss:  0.03666392 Validation Decoder Loss:  0.3291218
Encoder Loss:  0.040510744  || Decoder Loss:  0.035696544 Validation Decoder Loss:  0.33660132
Encoder Loss:  0.040322766  || Decoder Loss:  0.03558315 Validation Decoder Loss:  0.3297946
Encoder Loss:  0.03957505  || Decoder Loss:  0.034916244 Validation Decoder Loss:  0.33886173
Encoder Loss:  0.040202715  || Decoder Loss:  0.03577531 Validation Decoder Loss:  0.3768259
Model: siamese_net_lr_0.024521309000290644 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3768259
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 495, 6, 20, 1)     235       
_________________________________________________________________
reshape_4 (Reshape)          (None, 2970, 20, 1)       0         
=================================================================
Total params: 235
Trainable params: 235
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2970, 20, 1)       277       
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 3245, 20, 1)       277       
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5048376  || Decoder Loss:  0.9457382 Validation Decoder Loss:  1.6514513
Encoder Loss:  0.5236232  || Decoder Loss:  0.96169335 Validation Decoder Loss:  1.6516067
Encoder Loss:  0.52359766  || Decoder Loss:  0.9616526 Validation Decoder Loss:  1.6517632
Encoder Loss:  0.52356416  || Decoder Loss:  0.9615961 Validation Decoder Loss:  1.6519526
Encoder Loss:  0.52352434  || Decoder Loss:  0.9615286 Validation Decoder Loss:  1.6521785
Encoder Loss:  0.5234784  || Decoder Loss:  0.9614505 Validation Decoder Loss:  1.652444
Encoder Loss:  0.52342623  || Decoder Loss:  0.961362 Validation Decoder Loss:  1.6527524
Encoder Loss:  0.52336764  || Decoder Loss:  0.9612621 Validation Decoder Loss:  1.6531094
Encoder Loss:  0.52330214  || Decoder Loss:  0.9611497 Validation Decoder Loss:  1.6535217
Encoder Loss:  0.5232291  || Decoder Loss:  0.9610236 Validation Decoder Loss:  1.6539981
Encoder Loss:  0.52314794  || Decoder Loss:  0.96088195 Validation Decoder Loss:  1.6545503
Encoder Loss:  0.52305734  || Decoder Loss:  0.9607217 Validation Decoder Loss:  1.6551933
Encoder Loss:  0.522956  || Decoder Loss:  0.9605386 Validation Decoder Loss:  1.6559472
Encoder Loss:  0.5228421  || Decoder Loss:  0.96032685 Validation Decoder Loss:  1.6568404
Encoder Loss:  0.5227127  || Decoder Loss:  0.96007735 Validation Decoder Loss:  1.6579132
Encoder Loss:  0.52256405  || Decoder Loss:  0.9597751 Validation Decoder Loss:  1.6592281
Encoder Loss:  0.5223899  || Decoder Loss:  0.9593944 Validation Decoder Loss:  1.6608872
Encoder Loss:  0.5221794  || Decoder Loss:  0.95888406 Validation Decoder Loss:  1.6630789
Encoder Loss:  0.5219108  || Decoder Loss:  0.95812434 Validation Decoder Loss:  1.6662114
Encoder Loss:  0.52152175  || Decoder Loss:  0.95673555 Validation Decoder Loss:  1.6714717
Encoder Loss:  0.52058196  || Decoder Loss:  0.95185626 Validation Decoder Loss:  1.6852462
Encoder Loss:  0.4207437  || Decoder Loss:  0.2755661 Validation Decoder Loss:  0.3586897
Encoder Loss:  0.38569766  || Decoder Loss:  0.03983698 Validation Decoder Loss:  0.35710952
Encoder Loss:  0.38528526  || Decoder Loss:  0.040030364 Validation Decoder Loss:  0.35682946
Encoder Loss:  0.38472927  || Decoder Loss:  0.04025985 Validation Decoder Loss:  0.35662636
Encoder Loss:  0.38394776  || Decoder Loss:  0.040524878 Validation Decoder Loss:  0.35642284
Encoder Loss:  0.3827976  || Decoder Loss:  0.040839028 Validation Decoder Loss:  0.35621095
Encoder Loss:  0.38100246  || Decoder Loss:  0.04122852 Validation Decoder Loss:  0.35598558
Encoder Loss:  0.37795562  || Decoder Loss:  0.041750044 Validation Decoder Loss:  0.35573816
Encoder Loss:  0.3720086  || Decoder Loss:  0.04255789 Validation Decoder Loss:  0.35545656
Encoder Loss:  0.35625538  || Decoder Loss:  0.04433148 Validation Decoder Loss:  0.35528803
Encoder Loss:  0.25889865  || Decoder Loss:  0.21240593 Validation Decoder Loss:  1.5628556
Encoder Loss:  0.16944689  || Decoder Loss:  0.53186435 Validation Decoder Loss:  0.87166154
Encoder Loss:  0.1226294  || Decoder Loss:  0.46056977 Validation Decoder Loss:  1.1913314
Encoder Loss:  0.12400793  || Decoder Loss:  0.46411526 Validation Decoder Loss:  0.98156965
Encoder Loss:  0.121159725  || Decoder Loss:  0.46627423 Validation Decoder Loss:  1.1441144
Encoder Loss:  0.119580224  || Decoder Loss:  0.45834783 Validation Decoder Loss:  1.0734228
Encoder Loss:  0.115961276  || Decoder Loss:  0.44212446 Validation Decoder Loss:  1.0192673
Encoder Loss:  0.117601216  || Decoder Loss:  0.45778874 Validation Decoder Loss:  0.83792084
Encoder Loss:  0.10726517  || Decoder Loss:  0.40890417 Validation Decoder Loss:  1.0422629
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.08706859101474777 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0422628
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 302, 10, 20, 1)    1057      
_________________________________________________________________
reshape_5 (Reshape)          (None, 3020, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29015025  || Decoder Loss:  0.123856075 Validation Decoder Loss:  0.3391121
Encoder Loss:  0.22378176  || Decoder Loss:  0.1949417 Validation Decoder Loss:  0.6814507
Encoder Loss:  0.07779904  || Decoder Loss:  0.08487502 Validation Decoder Loss:  0.35135207
Encoder Loss:  0.05677713  || Decoder Loss:  0.039142262 Validation Decoder Loss:  0.34888458
Encoder Loss:  0.052860774  || Decoder Loss:  0.035594393 Validation Decoder Loss:  0.34658408
Encoder Loss:  0.048965555  || Decoder Loss:  0.034839164 Validation Decoder Loss:  0.34617478
Encoder Loss:  0.046589386  || Decoder Loss:  0.0346042 Validation Decoder Loss:  0.3461461
Encoder Loss:  0.047472548  || Decoder Loss:  0.03444538 Validation Decoder Loss:  0.34591728
Encoder Loss:  0.047572408  || Decoder Loss:  0.03433518 Validation Decoder Loss:  0.3459497
Encoder Loss:  0.04853577  || Decoder Loss:  0.034255326 Validation Decoder Loss:  0.34593683
Encoder Loss:  0.050141964  || Decoder Loss:  0.03418711 Validation Decoder Loss:  0.3464093
Encoder Loss:  0.05370966  || Decoder Loss:  0.034155842 Validation Decoder Loss:  0.34661773
Encoder Loss:  0.04761979  || Decoder Loss:  0.03409246 Validation Decoder Loss:  0.34598455
Encoder Loss:  0.049956795  || Decoder Loss:  0.034060467 Validation Decoder Loss:  0.34622496
Encoder Loss:  0.047083687  || Decoder Loss:  0.034006618 Validation Decoder Loss:  0.3461187
Encoder Loss:  0.047077037  || Decoder Loss:  0.03396337 Validation Decoder Loss:  0.3459686
Encoder Loss:  0.046297375  || Decoder Loss:  0.033922896 Validation Decoder Loss:  0.345927
Encoder Loss:  0.04681673  || Decoder Loss:  0.033905137 Validation Decoder Loss:  0.3459701
Encoder Loss:  0.046444584  || Decoder Loss:  0.03385507 Validation Decoder Loss:  0.3457694
Encoder Loss:  0.048798993  || Decoder Loss:  0.033827163 Validation Decoder Loss:  0.34579605
Encoder Loss:  0.047616016  || Decoder Loss:  0.03381854 Validation Decoder Loss:  0.34616894
Encoder Loss:  0.050763074  || Decoder Loss:  0.033792906 Validation Decoder Loss:  0.34609175
Encoder Loss:  0.046413247  || Decoder Loss:  0.033793177 Validation Decoder Loss:  0.3453359
Encoder Loss:  0.04692742  || Decoder Loss:  0.033773407 Validation Decoder Loss:  0.3460989
Encoder Loss:  0.04530442  || Decoder Loss:  0.033844005 Validation Decoder Loss:  0.3457013
Encoder Loss:  0.04470638  || Decoder Loss:  0.0337914 Validation Decoder Loss:  0.34584767
Encoder Loss:  0.04470207  || Decoder Loss:  0.03379538 Validation Decoder Loss:  0.34577313
Encoder Loss:  0.044653974  || Decoder Loss:  0.033799313 Validation Decoder Loss:  0.3458364
Encoder Loss:  0.044636317  || Decoder Loss:  0.03380759 Validation Decoder Loss:  0.3458358
Encoder Loss:  0.04466244  || Decoder Loss:  0.033814415 Validation Decoder Loss:  0.3458361
Encoder Loss:  0.044617247  || Decoder Loss:  0.033822425 Validation Decoder Loss:  0.3458461
Encoder Loss:  0.044615913  || Decoder Loss:  0.03384182 Validation Decoder Loss:  0.34589013
Encoder Loss:  0.044625584  || Decoder Loss:  0.033864044 Validation Decoder Loss:  0.34593278
Encoder Loss:  0.04468407  || Decoder Loss:  0.033881847 Validation Decoder Loss:  0.34601134
Encoder Loss:  0.044679835  || Decoder Loss:  0.03389441 Validation Decoder Loss:  0.3460581
Encoder Loss:  0.044680882  || Decoder Loss:  0.033911932 Validation Decoder Loss:  0.34613
Encoder Loss:  0.04469557  || Decoder Loss:  0.033935443 Validation Decoder Loss:  0.34621167
Encoder Loss:  0.044696707  || Decoder Loss:  0.033950113 Validation Decoder Loss:  0.34626144
Encoder Loss:  0.04468874  || Decoder Loss:  0.03395684 Validation Decoder Loss:  0.34625894
Encoder Loss:  0.044714212  || Decoder Loss:  0.033950493 Validation Decoder Loss:  0.34627268
Model: siamese_net_lr_0.005206475632601458 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34627268
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 307, 10, 20, 1)    709       
_________________________________________________________________
reshape_6 (Reshape)          (None, 3070, 20, 1)       0         
=================================================================
Total params: 709
Trainable params: 709
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 3070, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 3245, 20, 1)       177       
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12244759  || Decoder Loss:  0.088192046 Validation Decoder Loss:  0.343372
Encoder Loss:  0.074439794  || Decoder Loss:  0.05793633 Validation Decoder Loss:  0.35415694
Encoder Loss:  0.050572407  || Decoder Loss:  0.048981275 Validation Decoder Loss:  0.35338473
Encoder Loss:  0.04219235  || Decoder Loss:  0.037728347 Validation Decoder Loss:  0.34716913
Encoder Loss:  0.04088677  || Decoder Loss:  0.036741175 Validation Decoder Loss:  0.34756976
Encoder Loss:  0.04014376  || Decoder Loss:  0.03639884 Validation Decoder Loss:  0.34793663
Encoder Loss:  0.039858375  || Decoder Loss:  0.036085 Validation Decoder Loss:  0.3480441
Encoder Loss:  0.03961932  || Decoder Loss:  0.03579531 Validation Decoder Loss:  0.34807035
Encoder Loss:  0.03953207  || Decoder Loss:  0.035626724 Validation Decoder Loss:  0.34811294
Encoder Loss:  0.039371077  || Decoder Loss:  0.03546965 Validation Decoder Loss:  0.34802756
Encoder Loss:  0.03929065  || Decoder Loss:  0.03532662 Validation Decoder Loss:  0.34804994
Encoder Loss:  0.0391653  || Decoder Loss:  0.035175607 Validation Decoder Loss:  0.3480683
Encoder Loss:  0.039077178  || Decoder Loss:  0.035039727 Validation Decoder Loss:  0.3480939
Encoder Loss:  0.03898779  || Decoder Loss:  0.034920298 Validation Decoder Loss:  0.34812245
Encoder Loss:  0.038905155  || Decoder Loss:  0.03486998 Validation Decoder Loss:  0.34806216
Encoder Loss:  0.038847037  || Decoder Loss:  0.034791075 Validation Decoder Loss:  0.3481948
Encoder Loss:  0.038781602  || Decoder Loss:  0.034719307 Validation Decoder Loss:  0.3481456
Encoder Loss:  0.038760733  || Decoder Loss:  0.034632288 Validation Decoder Loss:  0.3481315
Encoder Loss:  0.038681313  || Decoder Loss:  0.03456491 Validation Decoder Loss:  0.34800237
Encoder Loss:  0.03865143  || Decoder Loss:  0.034539558 Validation Decoder Loss:  0.34833395
Encoder Loss:  0.03861255  || Decoder Loss:  0.03449225 Validation Decoder Loss:  0.34815562
Encoder Loss:  0.03858455  || Decoder Loss:  0.03444719 Validation Decoder Loss:  0.34822756
Encoder Loss:  0.038527954  || Decoder Loss:  0.034395557 Validation Decoder Loss:  0.34805095
Encoder Loss:  0.03849486  || Decoder Loss:  0.034361057 Validation Decoder Loss:  0.34811383
Encoder Loss:  0.038480066  || Decoder Loss:  0.03433588 Validation Decoder Loss:  0.3481903
Encoder Loss:  0.038479306  || Decoder Loss:  0.03430047 Validation Decoder Loss:  0.3481935
Encoder Loss:  0.038438026  || Decoder Loss:  0.03427965 Validation Decoder Loss:  0.34823704
Encoder Loss:  0.038400095  || Decoder Loss:  0.034247823 Validation Decoder Loss:  0.34804824
Encoder Loss:  0.03839313  || Decoder Loss:  0.034228314 Validation Decoder Loss:  0.34822986
Encoder Loss:  0.038390625  || Decoder Loss:  0.034217954 Validation Decoder Loss:  0.34820616
Encoder Loss:  0.038389083  || Decoder Loss:  0.034192696 Validation Decoder Loss:  0.34834465
Encoder Loss:  0.038374856  || Decoder Loss:  0.034170546 Validation Decoder Loss:  0.34823602
Encoder Loss:  0.038333  || Decoder Loss:  0.03416416 Validation Decoder Loss:  0.34829897
Encoder Loss:  0.03832796  || Decoder Loss:  0.034153815 Validation Decoder Loss:  0.34850672
Encoder Loss:  0.0383634  || Decoder Loss:  0.034152027 Validation Decoder Loss:  0.3486303
Encoder Loss:  0.038347524  || Decoder Loss:  0.03413122 Validation Decoder Loss:  0.34831026
Encoder Loss:  0.03831376  || Decoder Loss:  0.034124643 Validation Decoder Loss:  0.34840763
Encoder Loss:  0.038281344  || Decoder Loss:  0.034105703 Validation Decoder Loss:  0.34860653
Encoder Loss:  0.03829386  || Decoder Loss:  0.034090854 Validation Decoder Loss:  0.34836948
Encoder Loss:  0.03826718  || Decoder Loss:  0.03407678 Validation Decoder Loss:  0.34864974
Model: siamese_net_lr_0.0035718438138898703 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34864974
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 151, 20, 20, 1)    353       
_________________________________________________________________
reshape_7 (Reshape)          (None, 3020, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.052587703  || Decoder Loss:  0.052587703 Validation Decoder Loss:  0.34521705
Encoder Loss:  0.038273577  || Decoder Loss:  0.038273577 Validation Decoder Loss:  0.3451451
Encoder Loss:  0.03793839  || Decoder Loss:  0.03793839 Validation Decoder Loss:  0.3450774
Encoder Loss:  0.037561312  || Decoder Loss:  0.037561312 Validation Decoder Loss:  0.34502023
Encoder Loss:  0.037159175  || Decoder Loss:  0.037159175 Validation Decoder Loss:  0.34498194
Encoder Loss:  0.03674872  || Decoder Loss:  0.03674872 Validation Decoder Loss:  0.34496894
Encoder Loss:  0.036343623  || Decoder Loss:  0.036343623 Validation Decoder Loss:  0.34498543
Encoder Loss:  0.035954844  || Decoder Loss:  0.035954844 Validation Decoder Loss:  0.34503332
Encoder Loss:  0.035590995  || Decoder Loss:  0.035590995 Validation Decoder Loss:  0.3451126
Encoder Loss:  0.035258647  || Decoder Loss:  0.035258647 Validation Decoder Loss:  0.3452213
Encoder Loss:  0.034962382  || Decoder Loss:  0.034962382 Validation Decoder Loss:  0.3453559
Encoder Loss:  0.03470492  || Decoder Loss:  0.03470492 Validation Decoder Loss:  0.34551117
Encoder Loss:  0.034487084  || Decoder Loss:  0.034487084 Validation Decoder Loss:  0.345681
Encoder Loss:  0.034307886  || Decoder Loss:  0.034307886 Validation Decoder Loss:  0.34585845
Encoder Loss:  0.03416475  || Decoder Loss:  0.03416475 Validation Decoder Loss:  0.34603676
Encoder Loss:  0.03405373  || Decoder Loss:  0.03405373 Validation Decoder Loss:  0.34620944
Encoder Loss:  0.033970036  || Decoder Loss:  0.033970036 Validation Decoder Loss:  0.3463713
Encoder Loss:  0.03390855  || Decoder Loss:  0.03390855 Validation Decoder Loss:  0.34651843
Encoder Loss:  0.03386434  || Decoder Loss:  0.03386434 Validation Decoder Loss:  0.34664857
Encoder Loss:  0.03383303  || Decoder Loss:  0.03383303 Validation Decoder Loss:  0.346761
Encoder Loss:  0.033811003  || Decoder Loss:  0.033811003 Validation Decoder Loss:  0.34685594
Encoder Loss:  0.033795465  || Decoder Loss:  0.033795465 Validation Decoder Loss:  0.34693468
Encoder Loss:  0.033784337  || Decoder Loss:  0.033784337 Validation Decoder Loss:  0.346999
Encoder Loss:  0.033776164  || Decoder Loss:  0.033776164 Validation Decoder Loss:  0.3470508
Encoder Loss:  0.033769958  || Decoder Loss:  0.033769958 Validation Decoder Loss:  0.3470921
Encoder Loss:  0.03376505  || Decoder Loss:  0.03376505 Validation Decoder Loss:  0.34712476
Encoder Loss:  0.03376101  || Decoder Loss:  0.03376101 Validation Decoder Loss:  0.3471504
Encoder Loss:  0.033757553  || Decoder Loss:  0.033757553 Validation Decoder Loss:  0.34717047
Encoder Loss:  0.03375451  || Decoder Loss:  0.03375451 Validation Decoder Loss:  0.34718615
Encoder Loss:  0.033751756  || Decoder Loss:  0.033751756 Validation Decoder Loss:  0.34719843
Encoder Loss:  0.03374921  || Decoder Loss:  0.03374921 Validation Decoder Loss:  0.34720796
Encoder Loss:  0.033746835  || Decoder Loss:  0.033746835 Validation Decoder Loss:  0.34721553
Encoder Loss:  0.03374459  || Decoder Loss:  0.03374459 Validation Decoder Loss:  0.3472215
Encoder Loss:  0.033742443  || Decoder Loss:  0.033742443 Validation Decoder Loss:  0.34722626
Encoder Loss:  0.03374039  || Decoder Loss:  0.03374039 Validation Decoder Loss:  0.34723008
Encoder Loss:  0.033738405  || Decoder Loss:  0.033738405 Validation Decoder Loss:  0.3472332
Encoder Loss:  0.033736486  || Decoder Loss:  0.033736486 Validation Decoder Loss:  0.34723586
Encoder Loss:  0.033734623  || Decoder Loss:  0.033734623 Validation Decoder Loss:  0.3472381
Encoder Loss:  0.03373282  || Decoder Loss:  0.03373282 Validation Decoder Loss:  0.34724003
Encoder Loss:  0.03373106  || Decoder Loss:  0.03373106 Validation Decoder Loss:  0.34724176
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34724173
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 302, 10, 20, 1)    353       
_________________________________________________________________
reshape_8 (Reshape)          (None, 3020, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21128367  || Decoder Loss:  0.5105235 Validation Decoder Loss:  0.9313039
Encoder Loss:  0.16580042  || Decoder Loss:  0.42016742 Validation Decoder Loss:  0.7922008
Encoder Loss:  0.10555556  || Decoder Loss:  0.3431232 Validation Decoder Loss:  0.6944962
Encoder Loss:  0.06671958  || Decoder Loss:  0.28890553 Validation Decoder Loss:  0.6283827
Encoder Loss:  0.06763793  || Decoder Loss:  0.2500669 Validation Decoder Loss:  0.58116484
Encoder Loss:  0.067556575  || Decoder Loss:  0.2209679 Validation Decoder Loss:  0.5466992
Encoder Loss:  0.06717023  || Decoder Loss:  0.19880657 Validation Decoder Loss:  0.52083385
Encoder Loss:  0.06716099  || Decoder Loss:  0.18151037 Validation Decoder Loss:  0.50086474
Encoder Loss:  0.06712531  || Decoder Loss:  0.16769275 Validation Decoder Loss:  0.48504105
Encoder Loss:  0.066924356  || Decoder Loss:  0.15641622 Validation Decoder Loss:  0.47222254
Encoder Loss:  0.06681502  || Decoder Loss:  0.14704242 Validation Decoder Loss:  0.46163177
Encoder Loss:  0.06663014  || Decoder Loss:  0.13912342 Validation Decoder Loss:  0.4527407
Encoder Loss:  0.06639804  || Decoder Loss:  0.13234359 Validation Decoder Loss:  0.44517222
Encoder Loss:  0.06613957  || Decoder Loss:  0.12646964 Validation Decoder Loss:  0.43865
Encoder Loss:  0.0658135  || Decoder Loss:  0.1213279 Validation Decoder Loss:  0.43297
Encoder Loss:  0.06531087  || Decoder Loss:  0.1167871 Validation Decoder Loss:  0.42798337
Encoder Loss:  0.064615674  || Decoder Loss:  0.11274771 Validation Decoder Loss:  0.42356893
Encoder Loss:  0.06317982  || Decoder Loss:  0.10913201 Validation Decoder Loss:  0.41964507
Encoder Loss:  0.059770364  || Decoder Loss:  0.1058895 Validation Decoder Loss:  0.41616297
Encoder Loss:  0.05448471  || Decoder Loss:  0.10303559 Validation Decoder Loss:  0.41319978
Encoder Loss:  0.05327914  || Decoder Loss:  0.10042875 Validation Decoder Loss:  0.41038814
Encoder Loss:  0.052801486  || Decoder Loss:  0.09798109 Validation Decoder Loss:  0.40776336
Encoder Loss:  0.052555338  || Decoder Loss:  0.09570204 Validation Decoder Loss:  0.4053303
Encoder Loss:  0.052465998  || Decoder Loss:  0.093582116 Validation Decoder Loss:  0.40307292
Encoder Loss:  0.052302226  || Decoder Loss:  0.09160846 Validation Decoder Loss:  0.4009804
Encoder Loss:  0.05218462  || Decoder Loss:  0.089768305 Validation Decoder Loss:  0.39903656
Encoder Loss:  0.05214832  || Decoder Loss:  0.08804861 Validation Decoder Loss:  0.39722496
Encoder Loss:  0.051966168  || Decoder Loss:  0.08643821 Validation Decoder Loss:  0.3955364
Encoder Loss:  0.051981382  || Decoder Loss:  0.08492646 Validation Decoder Loss:  0.39395505
Encoder Loss:  0.051888395  || Decoder Loss:  0.08350461 Validation Decoder Loss:  0.39247337
Encoder Loss:  0.051842794  || Decoder Loss:  0.082164615 Validation Decoder Loss:  0.39108145
Encoder Loss:  0.051802497  || Decoder Loss:  0.080899306 Validation Decoder Loss:  0.38977134
Encoder Loss:  0.05175728  || Decoder Loss:  0.079702474 Validation Decoder Loss:  0.38853619
Encoder Loss:  0.051728368  || Decoder Loss:  0.07856864 Validation Decoder Loss:  0.38736963
Encoder Loss:  0.051719643  || Decoder Loss:  0.077492855 Validation Decoder Loss:  0.3862661
Encoder Loss:  0.051650047  || Decoder Loss:  0.07647054 Validation Decoder Loss:  0.3852207
Encoder Loss:  0.05163785  || Decoder Loss:  0.07549769 Validation Decoder Loss:  0.38422894
Encoder Loss:  0.051631898  || Decoder Loss:  0.07457115 Validation Decoder Loss:  0.38328716
Encoder Loss:  0.051547404  || Decoder Loss:  0.073686875 Validation Decoder Loss:  0.38239086
Encoder Loss:  0.051542457  || Decoder Loss:  0.07284196 Validation Decoder Loss:  0.38153726
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38153726
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 120, 26, 20, 1)    1255      
_________________________________________________________________
reshape_9 (Reshape)          (None, 3120, 20, 1)       0         
=================================================================
Total params: 1,255
Trainable params: 1,255
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 3120, 20, 1)       127       
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 3245, 20, 1)       127       
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23994704  || Decoder Loss:  0.10529819 Validation Decoder Loss:  0.3422225
Encoder Loss:  0.20651084  || Decoder Loss:  0.059067797 Validation Decoder Loss:  0.37183475
Encoder Loss:  0.26230168  || Decoder Loss:  0.33408725 Validation Decoder Loss:  0.74661946
Encoder Loss:  0.16564484  || Decoder Loss:  0.24072197 Validation Decoder Loss:  0.39346272
Encoder Loss:  0.05387749  || Decoder Loss:  0.045377985 Validation Decoder Loss:  0.3525557
Encoder Loss:  0.04738135  || Decoder Loss:  0.03638737 Validation Decoder Loss:  0.34897238
Encoder Loss:  0.045226097  || Decoder Loss:  0.035129245 Validation Decoder Loss:  0.34897104
Encoder Loss:  0.04424027  || Decoder Loss:  0.034796614 Validation Decoder Loss:  0.34746298
Encoder Loss:  0.044364844  || Decoder Loss:  0.03460047 Validation Decoder Loss:  0.34688938
Encoder Loss:  0.043269854  || Decoder Loss:  0.03444241 Validation Decoder Loss:  0.34645194
Encoder Loss:  0.044267062  || Decoder Loss:  0.034363568 Validation Decoder Loss:  0.3472597
Encoder Loss:  0.043651935  || Decoder Loss:  0.034492146 Validation Decoder Loss:  0.34842977
Encoder Loss:  0.044306178  || Decoder Loss:  0.035016853 Validation Decoder Loss:  0.34752297
Encoder Loss:  0.044496354  || Decoder Loss:  0.034856927 Validation Decoder Loss:  0.34537065
Encoder Loss:  0.047967367  || Decoder Loss:  0.036255594 Validation Decoder Loss:  0.3490107
Encoder Loss:  0.045463067  || Decoder Loss:  0.037190214 Validation Decoder Loss:  0.35395014
Encoder Loss:  0.045959897  || Decoder Loss:  0.03858663 Validation Decoder Loss:  0.34859252
Encoder Loss:  0.0451793  || Decoder Loss:  0.035483368 Validation Decoder Loss:  0.35184178
Encoder Loss:  0.0446751  || Decoder Loss:  0.03600502 Validation Decoder Loss:  0.34826794
Encoder Loss:  0.043955985  || Decoder Loss:  0.035918325 Validation Decoder Loss:  0.3492
Encoder Loss:  0.043740824  || Decoder Loss:  0.035909045 Validation Decoder Loss:  0.3475313
Encoder Loss:  0.043753937  || Decoder Loss:  0.035647348 Validation Decoder Loss:  0.34732768
Encoder Loss:  0.042933293  || Decoder Loss:  0.035605457 Validation Decoder Loss:  0.35023022
Encoder Loss:  0.043946788  || Decoder Loss:  0.035770368 Validation Decoder Loss:  0.34669876
Encoder Loss:  0.043839697  || Decoder Loss:  0.035351932 Validation Decoder Loss:  0.3525127
Encoder Loss:  0.044326916  || Decoder Loss:  0.036279988 Validation Decoder Loss:  0.3494603
Encoder Loss:  0.044295207  || Decoder Loss:  0.036292404 Validation Decoder Loss:  0.3537053
Encoder Loss:  0.044049807  || Decoder Loss:  0.03627553 Validation Decoder Loss:  0.34704372
Encoder Loss:  0.043435793  || Decoder Loss:  0.035548743 Validation Decoder Loss:  0.34632003
Encoder Loss:  0.04373976  || Decoder Loss:  0.03541759 Validation Decoder Loss:  0.3479108
Encoder Loss:  0.043572202  || Decoder Loss:  0.035171922 Validation Decoder Loss:  0.35020438
Encoder Loss:  0.043909997  || Decoder Loss:  0.035893057 Validation Decoder Loss:  0.3503037
Encoder Loss:  0.04520566  || Decoder Loss:  0.036801018 Validation Decoder Loss:  0.34709173
Encoder Loss:  0.04399243  || Decoder Loss:  0.03670069 Validation Decoder Loss:  0.35140157
Encoder Loss:  0.044624127  || Decoder Loss:  0.036141265 Validation Decoder Loss:  0.3474152
Encoder Loss:  0.04293963  || Decoder Loss:  0.0351622 Validation Decoder Loss:  0.34892228
Encoder Loss:  0.044348273  || Decoder Loss:  0.035559528 Validation Decoder Loss:  0.3466252
Encoder Loss:  0.044112217  || Decoder Loss:  0.03571848 Validation Decoder Loss:  0.34955215
Encoder Loss:  0.04350703  || Decoder Loss:  0.035804305 Validation Decoder Loss:  0.34590575
Encoder Loss:  0.04316946  || Decoder Loss:  0.035436098 Validation Decoder Loss:  0.3484764
Model: siamese_net_lr_0.01756475537359646 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3484764
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 317, 10, 20, 1)    383       
_________________________________________________________________
reshape_10 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 383
Trainable params: 383
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8000562  || Decoder Loss:  0.9423452 Validation Decoder Loss:  1.6628556
Encoder Loss:  0.8016598  || Decoder Loss:  0.9657187 Validation Decoder Loss:  1.6627319
Encoder Loss:  0.7376308  || Decoder Loss:  0.96558875 Validation Decoder Loss:  1.6626363
Encoder Loss:  0.7357815  || Decoder Loss:  0.96552 Validation Decoder Loss:  1.6625752
Encoder Loss:  0.7269509  || Decoder Loss:  0.9654543 Validation Decoder Loss:  1.66254
Encoder Loss:  0.73204756  || Decoder Loss:  0.9653928 Validation Decoder Loss:  1.6624689
Encoder Loss:  0.73697436  || Decoder Loss:  0.9653208 Validation Decoder Loss:  1.6623658
Encoder Loss:  0.7271786  || Decoder Loss:  0.9652375 Validation Decoder Loss:  1.66226
Encoder Loss:  0.72571266  || Decoder Loss:  0.9651715 Validation Decoder Loss:  1.6621175
Encoder Loss:  0.7274942  || Decoder Loss:  0.96510506 Validation Decoder Loss:  1.6620028
Encoder Loss:  0.7269813  || Decoder Loss:  0.96502334 Validation Decoder Loss:  1.6618488
Encoder Loss:  0.728328  || Decoder Loss:  0.9649274 Validation Decoder Loss:  1.6616678
Encoder Loss:  0.7273007  || Decoder Loss:  0.9648082 Validation Decoder Loss:  1.6615202
Encoder Loss:  0.7391817  || Decoder Loss:  0.9646424 Validation Decoder Loss:  1.6611866
Encoder Loss:  0.7333416  || Decoder Loss:  0.96442574 Validation Decoder Loss:  1.6607455
Encoder Loss:  0.7276205  || Decoder Loss:  0.964178 Validation Decoder Loss:  1.660197
Encoder Loss:  0.7255657  || Decoder Loss:  0.96387863 Validation Decoder Loss:  1.6593516
Encoder Loss:  0.72285765  || Decoder Loss:  0.9633666 Validation Decoder Loss:  1.6574821
Encoder Loss:  0.7189585  || Decoder Loss:  0.9604882 Validation Decoder Loss:  1.5730476
Encoder Loss:  0.07020249  || Decoder Loss:  0.07122067 Validation Decoder Loss:  0.33598483
Encoder Loss:  0.04558466  || Decoder Loss:  0.035120964 Validation Decoder Loss:  0.33603942
Encoder Loss:  0.04492467  || Decoder Loss:  0.035203043 Validation Decoder Loss:  0.33597124
Encoder Loss:  0.04445219  || Decoder Loss:  0.035287272 Validation Decoder Loss:  0.33596146
Encoder Loss:  0.043699037  || Decoder Loss:  0.035358626 Validation Decoder Loss:  0.33590782
Encoder Loss:  0.046003122  || Decoder Loss:  0.035433687 Validation Decoder Loss:  0.33586597
Encoder Loss:  0.045433152  || Decoder Loss:  0.035522662 Validation Decoder Loss:  0.33587068
Encoder Loss:  0.048687838  || Decoder Loss:  0.03561222 Validation Decoder Loss:  0.33581954
Encoder Loss:  0.054411348  || Decoder Loss:  0.035779767 Validation Decoder Loss:  0.33594853
Encoder Loss:  0.043399338  || Decoder Loss:  0.035930403 Validation Decoder Loss:  0.33589312
Encoder Loss:  0.043917406  || Decoder Loss:  0.03603246 Validation Decoder Loss:  0.33584666
Encoder Loss:  0.04390225  || Decoder Loss:  0.036137003 Validation Decoder Loss:  0.3356914
Encoder Loss:  0.042527303  || Decoder Loss:  0.036260888 Validation Decoder Loss:  0.3354807
Encoder Loss:  0.044199266  || Decoder Loss:  0.036387753 Validation Decoder Loss:  0.335327
Encoder Loss:  0.044967588  || Decoder Loss:  0.036511496 Validation Decoder Loss:  0.33524817
Encoder Loss:  0.04411788  || Decoder Loss:  0.03663382 Validation Decoder Loss:  0.33517128
Encoder Loss:  0.04492517  || Decoder Loss:  0.036769804 Validation Decoder Loss:  0.33499157
Encoder Loss:  0.04562787  || Decoder Loss:  0.036916707 Validation Decoder Loss:  0.33498442
Encoder Loss:  0.04438238  || Decoder Loss:  0.03704476 Validation Decoder Loss:  0.33493343
Encoder Loss:  0.046638966  || Decoder Loss:  0.03715296 Validation Decoder Loss:  0.33497196
Encoder Loss:  0.051503744  || Decoder Loss:  0.03733216 Validation Decoder Loss:  0.33508778
Model: siamese_net_lr_0.05894852287710721 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3350878
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 230, 14, 20, 1)    247       
_________________________________________________________________
reshape_11 (Reshape)         (None, 3220, 20, 1)       0         
=================================================================
Total params: 247
Trainable params: 247
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 3220, 20, 1)       27        
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 3245, 20, 1)       27        
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13000245  || Decoder Loss:  0.06854077 Validation Decoder Loss:  0.34341758
Encoder Loss:  0.112869084  || Decoder Loss:  0.03288102 Validation Decoder Loss:  0.34332156
Encoder Loss:  0.11284797  || Decoder Loss:  0.03289534 Validation Decoder Loss:  0.34329104
Encoder Loss:  0.11274834  || Decoder Loss:  0.032912437 Validation Decoder Loss:  0.34326267
Encoder Loss:  0.11256371  || Decoder Loss:  0.032933317 Validation Decoder Loss:  0.34323248
Encoder Loss:  0.11214657  || Decoder Loss:  0.032958493 Validation Decoder Loss:  0.34320167
Encoder Loss:  0.1094049  || Decoder Loss:  0.03298856 Validation Decoder Loss:  0.3431744
Encoder Loss:  0.103407755  || Decoder Loss:  0.033023257 Validation Decoder Loss:  0.34313768
Encoder Loss:  0.088977374  || Decoder Loss:  0.0330591 Validation Decoder Loss:  0.3431068
Encoder Loss:  0.09174731  || Decoder Loss:  0.033096824 Validation Decoder Loss:  0.3430755
Encoder Loss:  0.06437385  || Decoder Loss:  0.03313566 Validation Decoder Loss:  0.34306085
Encoder Loss:  0.056803994  || Decoder Loss:  0.033158015 Validation Decoder Loss:  0.34304965
Encoder Loss:  0.043998584  || Decoder Loss:  0.03317301 Validation Decoder Loss:  0.3430394
Encoder Loss:  0.045538556  || Decoder Loss:  0.03317943 Validation Decoder Loss:  0.34303424
Encoder Loss:  0.045426015  || Decoder Loss:  0.033187013 Validation Decoder Loss:  0.3430279
Encoder Loss:  0.040506408  || Decoder Loss:  0.033193678 Validation Decoder Loss:  0.34302315
Encoder Loss:  0.04213551  || Decoder Loss:  0.03319786 Validation Decoder Loss:  0.34301978
Encoder Loss:  0.041721154  || Decoder Loss:  0.033203956 Validation Decoder Loss:  0.3430165
Encoder Loss:  0.040399633  || Decoder Loss:  0.033209626 Validation Decoder Loss:  0.34301522
Encoder Loss:  0.039685763  || Decoder Loss:  0.033214062 Validation Decoder Loss:  0.34301364
Encoder Loss:  0.041220352  || Decoder Loss:  0.03321904 Validation Decoder Loss:  0.34301135
Encoder Loss:  0.043319635  || Decoder Loss:  0.033225216 Validation Decoder Loss:  0.3430058
Encoder Loss:  0.039216023  || Decoder Loss:  0.033231597 Validation Decoder Loss:  0.34300238
Encoder Loss:  0.041465286  || Decoder Loss:  0.033235826 Validation Decoder Loss:  0.342998
Encoder Loss:  0.04301614  || Decoder Loss:  0.03324262 Validation Decoder Loss:  0.3429947
Encoder Loss:  0.03899764  || Decoder Loss:  0.033248596 Validation Decoder Loss:  0.34299397
Encoder Loss:  0.039917506  || Decoder Loss:  0.033253804 Validation Decoder Loss:  0.34299335
Encoder Loss:  0.04030388  || Decoder Loss:  0.033259824 Validation Decoder Loss:  0.34299177
Encoder Loss:  0.039982367  || Decoder Loss:  0.03326596 Validation Decoder Loss:  0.3429897
Encoder Loss:  0.042086683  || Decoder Loss:  0.03327282 Validation Decoder Loss:  0.34298968
Encoder Loss:  0.042837027  || Decoder Loss:  0.033284217 Validation Decoder Loss:  0.34298742
Encoder Loss:  0.04119045  || Decoder Loss:  0.03329713 Validation Decoder Loss:  0.34298894
Encoder Loss:  0.0402606  || Decoder Loss:  0.0333074 Validation Decoder Loss:  0.3429876
Encoder Loss:  0.040707927  || Decoder Loss:  0.033312645 Validation Decoder Loss:  0.3429863
Encoder Loss:  0.046468697  || Decoder Loss:  0.03332705 Validation Decoder Loss:  0.34299082
Encoder Loss:  0.0463485  || Decoder Loss:  0.033354323 Validation Decoder Loss:  0.34299856
Encoder Loss:  0.041639373  || Decoder Loss:  0.033383746 Validation Decoder Loss:  0.3430044
Encoder Loss:  0.041721363  || Decoder Loss:  0.03339712 Validation Decoder Loss:  0.34300387
Encoder Loss:  0.04020148  || Decoder Loss:  0.03341209 Validation Decoder Loss:  0.34300828
Encoder Loss:  0.038801625  || Decoder Loss:  0.03342276 Validation Decoder Loss:  0.34301433
Model: siamese_net_lr_0.05502740135231668 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34301433
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 94, 5, 20, 1)      32        
_________________________________________________________________
reshape_12 (Reshape)         (None, 470, 20, 1)        0         
=================================================================
Total params: 32
Trainable params: 32
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 470, 20, 1)        1370      
=================================================================
Total params: 1,370
Trainable params: 1,370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 3245, 20, 1)       2777      
=================================================================
Total params: 2,777
Trainable params: 2,777
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.92635506  || Decoder Loss:  0.9362784 Validation Decoder Loss:  1.6423228
Encoder Loss:  0.94302565  || Decoder Loss:  0.9531359 Validation Decoder Loss:  1.638875
Encoder Loss:  0.9392787  || Decoder Loss:  0.94931495 Validation Decoder Loss:  1.632454
Encoder Loss:  0.93242776  || Decoder Loss:  0.9423272 Validation Decoder Loss:  1.6199996
Encoder Loss:  0.9194769  || Decoder Loss:  0.92911553 Validation Decoder Loss:  1.595185
Encoder Loss:  0.89422524  || Decoder Loss:  0.9033527 Validation Decoder Loss:  1.5448923
Encoder Loss:  0.8440401  || Decoder Loss:  0.852148 Validation Decoder Loss:  1.4428225
Encoder Loss:  0.74456686  || Decoder Loss:  0.750649 Validation Decoder Loss:  1.2415586
Encoder Loss:  0.560889  || Decoder Loss:  0.56322575 Validation Decoder Loss:  0.90165216
Encoder Loss:  0.31295827  || Decoder Loss:  0.31023866 Validation Decoder Loss:  0.5657051
Encoder Loss:  0.13952768  || Decoder Loss:  0.13327919 Validation Decoder Loss:  0.41513926
Encoder Loss:  0.07452024  || Decoder Loss:  0.06696603 Validation Decoder Loss:  0.3704908
Encoder Loss:  0.054804884  || Decoder Loss:  0.04688121 Validation Decoder Loss:  0.3574996
Encoder Loss:  0.048590217  || Decoder Loss:  0.04059255 Validation Decoder Loss:  0.35345152
Encoder Loss:  0.046557087  || Decoder Loss:  0.038619027 Validation Decoder Loss:  0.35245353
Encoder Loss:  0.04634164  || Decoder Loss:  0.038754668 Validation Decoder Loss:  0.35732365
Encoder Loss:  0.35661468  || Decoder Loss:  0.3602413 Validation Decoder Loss:  1.3167317
Encoder Loss:  0.48516244  || Decoder Loss:  0.49270886 Validation Decoder Loss:  1.4652016
Encoder Loss:  0.45154774  || Decoder Loss:  0.45828053 Validation Decoder Loss:  1.1370234
Encoder Loss:  0.4253513  || Decoder Loss:  0.43195456 Validation Decoder Loss:  1.3342372
Encoder Loss:  0.41405895  || Decoder Loss:  0.42018357 Validation Decoder Loss:  1.1574465
Encoder Loss:  0.40708682  || Decoder Loss:  0.41328168 Validation Decoder Loss:  1.2856232
Encoder Loss:  0.4032882  || Decoder Loss:  0.409375 Validation Decoder Loss:  1.2278905
Encoder Loss:  0.40150926  || Decoder Loss:  0.4076068 Validation Decoder Loss:  1.2792059
Encoder Loss:  0.40086827  || Decoder Loss:  0.40691563 Validation Decoder Loss:  1.199239
Encoder Loss:  0.38315034  || Decoder Loss:  0.38884917 Validation Decoder Loss:  1.2655145
Encoder Loss:  0.38681006  || Decoder Loss:  0.39256692 Validation Decoder Loss:  1.1640458
Encoder Loss:  0.37192237  || Decoder Loss:  0.3774673 Validation Decoder Loss:  1.2406718
Encoder Loss:  0.35842803  || Decoder Loss:  0.36361152 Validation Decoder Loss:  1.2154825
Encoder Loss:  0.32470262  || Decoder Loss:  0.32924706 Validation Decoder Loss:  1.1839995
Encoder Loss:  0.26897013  || Decoder Loss:  0.27232698 Validation Decoder Loss:  0.7994581
Encoder Loss:  0.090815604  || Decoder Loss:  0.090621375 Validation Decoder Loss:  0.44633484
Encoder Loss:  0.029483456  || Decoder Loss:  0.028010271 Validation Decoder Loss:  0.37954628
Encoder Loss:  0.02438391  || Decoder Loss:  0.022768568 Validation Decoder Loss:  0.37537843
Encoder Loss:  0.022917634  || Decoder Loss:  0.021365752 Validation Decoder Loss:  0.37540817
Encoder Loss:  0.022815159  || Decoder Loss:  0.021236947 Validation Decoder Loss:  0.37457088
Encoder Loss:  0.022736806  || Decoder Loss:  0.021016775 Validation Decoder Loss:  0.38560396
Encoder Loss:  0.214783  || Decoder Loss:  0.21657364 Validation Decoder Loss:  0.5007237
Encoder Loss:  0.33060318  || Decoder Loss:  0.3349902 Validation Decoder Loss:  0.9181642
Encoder Loss:  0.23883373  || Decoder Loss:  0.24139556 Validation Decoder Loss:  0.45981386
Model: siamese_net_lr_0.062165899322632195 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.45981386
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 74, 5, 20, 1)      12        
_________________________________________________________________
reshape_13 (Reshape)         (None, 370, 20, 1)        0         
=================================================================
Total params: 12
Trainable params: 12
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 370, 20, 1)        294       
=================================================================
Total params: 294
Trainable params: 294
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 3245, 20, 1)       1770      
=================================================================
Total params: 1,770
Trainable params: 1,770
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.72886825  || Decoder Loss:  0.88198197 Validation Decoder Loss:  1.625265
Encoder Loss:  0.730627  || Decoder Loss:  0.8898827 Validation Decoder Loss:  1.4122759
Encoder Loss:  0.2577045  || Decoder Loss:  0.24823809 Validation Decoder Loss:  1.04894
Encoder Loss:  0.18067886  || Decoder Loss:  0.19737926 Validation Decoder Loss:  0.39768583
Encoder Loss:  0.07056321  || Decoder Loss:  0.038417257 Validation Decoder Loss:  0.35060072
Encoder Loss:  0.05736513  || Decoder Loss:  0.032145016 Validation Decoder Loss:  0.34965917
Encoder Loss:  0.05401783  || Decoder Loss:  0.031528234 Validation Decoder Loss:  0.3543968
Encoder Loss:  0.06365806  || Decoder Loss:  0.031354714 Validation Decoder Loss:  0.35037524
Encoder Loss:  0.05349208  || Decoder Loss:  0.031007513 Validation Decoder Loss:  0.352589
Encoder Loss:  0.06006517  || Decoder Loss:  0.030852074 Validation Decoder Loss:  0.34847844
Encoder Loss:  0.050461773  || Decoder Loss:  0.030537203 Validation Decoder Loss:  0.34818438
Encoder Loss:  0.050670166  || Decoder Loss:  0.03038688 Validation Decoder Loss:  0.349664
Encoder Loss:  0.049145754  || Decoder Loss:  0.030301169 Validation Decoder Loss:  0.34868944
Encoder Loss:  0.044573244  || Decoder Loss:  0.030460147 Validation Decoder Loss:  0.359946
Encoder Loss:  0.048615523  || Decoder Loss:  0.030683542 Validation Decoder Loss:  0.3557634
Encoder Loss:  0.043942995  || Decoder Loss:  0.030066192 Validation Decoder Loss:  0.35132644
Encoder Loss:  0.04254145  || Decoder Loss:  0.029731972 Validation Decoder Loss:  0.35168785
Encoder Loss:  0.040355276  || Decoder Loss:  0.029570637 Validation Decoder Loss:  0.35375947
Encoder Loss:  0.039986663  || Decoder Loss:  0.02946366 Validation Decoder Loss:  0.35794544
Encoder Loss:  0.039255466  || Decoder Loss:  0.02937722 Validation Decoder Loss:  0.3530041
Encoder Loss:  0.03803602  || Decoder Loss:  0.029205715 Validation Decoder Loss:  0.35543475
Encoder Loss:  0.038431793  || Decoder Loss:  0.029098071 Validation Decoder Loss:  0.35503882
Encoder Loss:  0.037678313  || Decoder Loss:  0.028962117 Validation Decoder Loss:  0.35527664
Encoder Loss:  0.037344433  || Decoder Loss:  0.028888838 Validation Decoder Loss:  0.35409218
Encoder Loss:  0.036908753  || Decoder Loss:  0.02874557 Validation Decoder Loss:  0.35457695
Encoder Loss:  0.036574222  || Decoder Loss:  0.028636215 Validation Decoder Loss:  0.35244682
Encoder Loss:  0.036395416  || Decoder Loss:  0.028511655 Validation Decoder Loss:  0.35313588
Encoder Loss:  0.03721458  || Decoder Loss:  0.028419854 Validation Decoder Loss:  0.35327345
Encoder Loss:  0.03736642  || Decoder Loss:  0.028348079 Validation Decoder Loss:  0.35777542
Encoder Loss:  0.03843066  || Decoder Loss:  0.028425207 Validation Decoder Loss:  0.3624455
Encoder Loss:  0.040377837  || Decoder Loss:  0.028404184 Validation Decoder Loss:  0.35063443
Encoder Loss:  0.036995098  || Decoder Loss:  0.028130794 Validation Decoder Loss:  0.35994357
Encoder Loss:  0.037393354  || Decoder Loss:  0.028170919 Validation Decoder Loss:  0.36028966
Encoder Loss:  0.03979417  || Decoder Loss:  0.028308798 Validation Decoder Loss:  0.3598807
Encoder Loss:  0.04155574  || Decoder Loss:  0.028025791 Validation Decoder Loss:  0.3563587
Encoder Loss:  0.039278504  || Decoder Loss:  0.028110564 Validation Decoder Loss:  0.35586828
Encoder Loss:  0.036270365  || Decoder Loss:  0.027745772 Validation Decoder Loss:  0.35365552
Encoder Loss:  0.036205456  || Decoder Loss:  0.027701551 Validation Decoder Loss:  0.35787475
Encoder Loss:  0.037004314  || Decoder Loss:  0.027629549 Validation Decoder Loss:  0.357301
Encoder Loss:  0.03666728  || Decoder Loss:  0.027635317 Validation Decoder Loss:  0.3622171
2019-11-19 12:24:35.035097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_0.021134587939597247 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3622171
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 64, 5, 20, 1)      2         
_________________________________________________________________
reshape_14 (Reshape)         (None, 320, 20, 1)        0         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 320, 20, 1)        694       
=================================================================
Total params: 694
Trainable params: 694
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 3245, 20, 1)       2927      
=================================================================
Total params: 2,927
Trainable params: 2,927
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07795689  || Decoder Loss:  0.06161123 Validation Decoder Loss:  0.3694926
Encoder Loss:  0.0683827  || Decoder Loss:  0.03550694 Validation Decoder Loss:  0.35888708
Encoder Loss:  0.0597746  || Decoder Loss:  0.03304478 Validation Decoder Loss:  0.35715133
Encoder Loss:  0.059670225  || Decoder Loss:  0.031598393 Validation Decoder Loss:  0.354601
Encoder Loss:  0.056259975  || Decoder Loss:  0.030048799 Validation Decoder Loss:  0.35932347
Encoder Loss:  0.058091525  || Decoder Loss:  0.028879259 Validation Decoder Loss:  0.35713577
Encoder Loss:  0.05386983  || Decoder Loss:  0.027488718 Validation Decoder Loss:  0.3715004
Encoder Loss:  0.057133228  || Decoder Loss:  0.026508126 Validation Decoder Loss:  0.36577785
Encoder Loss:  0.055897426  || Decoder Loss:  0.02541326 Validation Decoder Loss:  0.3688201
Encoder Loss:  0.055108618  || Decoder Loss:  0.024500206 Validation Decoder Loss:  0.3689427
Encoder Loss:  0.056178395  || Decoder Loss:  0.024039432 Validation Decoder Loss:  0.3711617
Encoder Loss:  0.058523417  || Decoder Loss:  0.023643173 Validation Decoder Loss:  0.39578944
Encoder Loss:  0.054524545  || Decoder Loss:  0.022898182 Validation Decoder Loss:  0.37214983
Encoder Loss:  0.054132387  || Decoder Loss:  0.022419868 Validation Decoder Loss:  0.37571013
Encoder Loss:  0.05213387  || Decoder Loss:  0.022137763 Validation Decoder Loss:  0.39495352
Encoder Loss:  0.055929054  || Decoder Loss:  0.02166422 Validation Decoder Loss:  0.38032785
Encoder Loss:  0.054820396  || Decoder Loss:  0.021418251 Validation Decoder Loss:  0.38511896
Encoder Loss:  0.053986106  || Decoder Loss:  0.02076412 Validation Decoder Loss:  0.37981653
Encoder Loss:  0.05464074  || Decoder Loss:  0.020812169 Validation Decoder Loss:  0.39810503
Encoder Loss:  0.05346631  || Decoder Loss:  0.020455124 Validation Decoder Loss:  0.3791191
Encoder Loss:  0.053137206  || Decoder Loss:  0.0207415 Validation Decoder Loss:  0.39169025
Encoder Loss:  0.05403612  || Decoder Loss:  0.020337902 Validation Decoder Loss:  0.3916726
Encoder Loss:  0.054075196  || Decoder Loss:  0.020126332 Validation Decoder Loss:  0.38544282
Encoder Loss:  0.05461066  || Decoder Loss:  0.020352472 Validation Decoder Loss:  0.41819838
Encoder Loss:  0.059321914  || Decoder Loss:  0.020980416 Validation Decoder Loss:  0.3664676
Encoder Loss:  0.04916103  || Decoder Loss:  0.019796997 Validation Decoder Loss:  0.39085248
Encoder Loss:  0.05243862  || Decoder Loss:  0.019776694 Validation Decoder Loss:  0.38324597
Encoder Loss:  0.05338994  || Decoder Loss:  0.019997042 Validation Decoder Loss:  0.40423238
Encoder Loss:  0.05339483  || Decoder Loss:  0.02016226 Validation Decoder Loss:  0.39117998
Encoder Loss:  0.053011958  || Decoder Loss:  0.019756183 Validation Decoder Loss:  0.39130694
Encoder Loss:  0.05264575  || Decoder Loss:  0.019639844 Validation Decoder Loss:  0.39220208
Encoder Loss:  0.052680835  || Decoder Loss:  0.019705663 Validation Decoder Loss:  0.3990447
Encoder Loss:  0.05332538  || Decoder Loss:  0.01972655 Validation Decoder Loss:  0.4030108
Encoder Loss:  0.05222625  || Decoder Loss:  0.019629596 Validation Decoder Loss:  0.3823198
Encoder Loss:  0.052819826  || Decoder Loss:  0.01998891 Validation Decoder Loss:  0.3955096
Encoder Loss:  0.054388598  || Decoder Loss:  0.019810397 Validation Decoder Loss:  0.39569193
Encoder Loss:  0.052276563  || Decoder Loss:  0.019734742 Validation Decoder Loss:  0.39466864
Encoder Loss:  0.05261683  || Decoder Loss:  0.019534577 Validation Decoder Loss:  0.40129334
Encoder Loss:  0.05236713  || Decoder Loss:  0.019736685 Validation Decoder Loss:  0.39858142
Encoder Loss:  0.052756153  || Decoder Loss:  0.019531092 Validation Decoder Loss:  0.3915002
Model: siamese_net_lr_0.001673467568838189 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3915002
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 71, 20, 20, 1)     97        
_________________________________________________________________
reshape_15 (Reshape)         (None, 1420, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 1420, 20, 1)       408       
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 3245, 20, 1)       1827      
=================================================================
Total params: 1,827
Trainable params: 1,827
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28682575  || Decoder Loss:  0.22605549 Validation Decoder Loss:  0.33425444
Encoder Loss:  0.17155696  || Decoder Loss:  0.05537595 Validation Decoder Loss:  0.32871804
Encoder Loss:  0.1656719  || Decoder Loss:  0.047067955 Validation Decoder Loss:  0.33607858
Encoder Loss:  0.1609822  || Decoder Loss:  0.040476795 Validation Decoder Loss:  0.3520205
Encoder Loss:  0.15973549  || Decoder Loss:  0.038795687 Validation Decoder Loss:  0.3585284
Encoder Loss:  0.15946743  || Decoder Loss:  0.038528096 Validation Decoder Loss:  0.35704678
Encoder Loss:  0.15923467  || Decoder Loss:  0.038340364 Validation Decoder Loss:  0.35747075
Encoder Loss:  0.15901999  || Decoder Loss:  0.03821839 Validation Decoder Loss:  0.35815287
Encoder Loss:  0.15879987  || Decoder Loss:  0.038146395 Validation Decoder Loss:  0.3585829
Encoder Loss:  0.1585481  || Decoder Loss:  0.038118564 Validation Decoder Loss:  0.35908207
Encoder Loss:  0.15822126  || Decoder Loss:  0.038135193 Validation Decoder Loss:  0.35961205
Encoder Loss:  0.15773186  || Decoder Loss:  0.038209185 Validation Decoder Loss:  0.3602426
Encoder Loss:  0.15685213  || Decoder Loss:  0.038382832 Validation Decoder Loss:  0.3611399
Encoder Loss:  0.15471037  || Decoder Loss:  0.038813435 Validation Decoder Loss:  0.3630544
Encoder Loss:  0.14009082  || Decoder Loss:  0.04363699 Validation Decoder Loss:  1.2159306
Encoder Loss:  0.41113293  || Decoder Loss:  0.54553676 Validation Decoder Loss:  1.0381792
Encoder Loss:  0.36583713  || Decoder Loss:  0.49044013 Validation Decoder Loss:  1.0207287
Encoder Loss:  0.36691335  || Decoder Loss:  0.4928581 Validation Decoder Loss:  1.0019681
Encoder Loss:  0.3658079  || Decoder Loss:  0.4924135 Validation Decoder Loss:  1.0430663
Encoder Loss:  0.36489102  || Decoder Loss:  0.49166983 Validation Decoder Loss:  1.0216482
Encoder Loss:  0.36637536  || Decoder Loss:  0.493295 Validation Decoder Loss:  0.9785055
Encoder Loss:  0.36203966  || Decoder Loss:  0.4891718 Validation Decoder Loss:  1.0260438
Encoder Loss:  0.3624714  || Decoder Loss:  0.4886824 Validation Decoder Loss:  1.01859
Encoder Loss:  0.3510464  || Decoder Loss:  0.47381198 Validation Decoder Loss:  0.9572574
Encoder Loss:  0.3625769  || Decoder Loss:  0.49058667 Validation Decoder Loss:  0.99773484
Encoder Loss:  0.36687896  || Decoder Loss:  0.49684784 Validation Decoder Loss:  0.9483192
Encoder Loss:  0.36458337  || Decoder Loss:  0.49157745 Validation Decoder Loss:  1.0052761
Encoder Loss:  0.37029445  || Decoder Loss:  0.4997541 Validation Decoder Loss:  0.95614064
Encoder Loss:  0.36496928  || Decoder Loss:  0.48916042 Validation Decoder Loss:  1.0271679
Encoder Loss:  0.37030998  || Decoder Loss:  0.50048304 Validation Decoder Loss:  0.9780939
Encoder Loss:  0.3659496  || Decoder Loss:  0.49556857 Validation Decoder Loss:  1.0206225
Encoder Loss:  0.36769032  || Decoder Loss:  0.49553487 Validation Decoder Loss:  0.99296725
Encoder Loss:  0.36972582  || Decoder Loss:  0.49903542 Validation Decoder Loss:  1.0105857
Encoder Loss:  0.36497974  || Decoder Loss:  0.49448186 Validation Decoder Loss:  1.0030824
Encoder Loss:  0.3649217  || Decoder Loss:  0.49178046 Validation Decoder Loss:  1.0467829
Encoder Loss:  0.36829627  || Decoder Loss:  0.4990906 Validation Decoder Loss:  1.011932
Encoder Loss:  0.36601436  || Decoder Loss:  0.49571624 Validation Decoder Loss:  0.9683957
Encoder Loss:  0.36477292  || Decoder Loss:  0.49241027 Validation Decoder Loss:  0.97186786
Encoder Loss:  0.35962924  || Decoder Loss:  0.48719403 Validation Decoder Loss:  0.9773294
Encoder Loss:  0.3654139  || Decoder Loss:  0.49548474 Validation Decoder Loss:  1.0003226
Model: siamese_net_lr_0.04221659715160738 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0003226
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 95, 16, 20, 1)     257       
_________________________________________________________________
reshape_16 (Reshape)         (None, 1520, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 1520, 20, 1)       1727      
=================================================================
Total params: 1,727
Trainable params: 1,727
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 3245, 20, 1)       1727      
=================================================================
Total params: 1,727
Trainable params: 1,727
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5837772  || Decoder Loss:  0.6758936 Validation Decoder Loss:  1.2203541
Encoder Loss:  0.3726239  || Decoder Loss:  0.46739975 Validation Decoder Loss:  1.0233699
Encoder Loss:  0.3745868  || Decoder Loss:  0.47997376 Validation Decoder Loss:  1.0050137
Encoder Loss:  0.37443084  || Decoder Loss:  0.47933522 Validation Decoder Loss:  0.9940035
Encoder Loss:  0.3173376  || Decoder Loss:  0.40379992 Validation Decoder Loss:  0.73931426
Encoder Loss:  0.33648005  || Decoder Loss:  0.42626053 Validation Decoder Loss:  1.268469
Encoder Loss:  0.36934352  || Decoder Loss:  0.4677101 Validation Decoder Loss:  0.61952496
Encoder Loss:  0.22757782  || Decoder Loss:  0.2839038 Validation Decoder Loss:  0.40818816
Encoder Loss:  0.20974308  || Decoder Loss:  0.26023042 Validation Decoder Loss:  0.42160442
Encoder Loss:  0.1315048  || Decoder Loss:  0.15624924 Validation Decoder Loss:  0.93492705
Encoder Loss:  0.1367266  || Decoder Loss:  0.16106823 Validation Decoder Loss:  0.42878985
Encoder Loss:  0.06601265  || Decoder Loss:  0.06836226 Validation Decoder Loss:  0.35945302
Encoder Loss:  0.048392437  || Decoder Loss:  0.04514809 Validation Decoder Loss:  0.37904847
Encoder Loss:  0.048989013  || Decoder Loss:  0.042719606 Validation Decoder Loss:  0.38022932
Encoder Loss:  0.04107753  || Decoder Loss:  0.03641384 Validation Decoder Loss:  0.3605435
Encoder Loss:  0.041359674  || Decoder Loss:  0.03619959 Validation Decoder Loss:  0.35691583
Encoder Loss:  0.040887736  || Decoder Loss:  0.03605603 Validation Decoder Loss:  0.35650617
Encoder Loss:  0.04175833  || Decoder Loss:  0.03607695 Validation Decoder Loss:  0.36709246
Encoder Loss:  0.044496857  || Decoder Loss:  0.040847316 Validation Decoder Loss:  0.37052596
Encoder Loss:  0.042314373  || Decoder Loss:  0.038407747 Validation Decoder Loss:  0.36164874
Encoder Loss:  0.039290704  || Decoder Loss:  0.034239635 Validation Decoder Loss:  0.35654354
Encoder Loss:  0.043572564  || Decoder Loss:  0.038426615 Validation Decoder Loss:  0.3644144
Encoder Loss:  0.04165692  || Decoder Loss:  0.0365493 Validation Decoder Loss:  0.35300285
Encoder Loss:  0.04003104  || Decoder Loss:  0.035000667 Validation Decoder Loss:  0.3635512
Encoder Loss:  0.04432596  || Decoder Loss:  0.040466473 Validation Decoder Loss:  0.35940373
Encoder Loss:  0.043042846  || Decoder Loss:  0.03664298 Validation Decoder Loss:  0.35895705
Encoder Loss:  0.040427893  || Decoder Loss:  0.035805658 Validation Decoder Loss:  0.353872
Encoder Loss:  0.040073257  || Decoder Loss:  0.035341196 Validation Decoder Loss:  0.35418418
Encoder Loss:  0.041301895  || Decoder Loss:  0.0368736 Validation Decoder Loss:  0.35275856
Encoder Loss:  0.040541023  || Decoder Loss:  0.036641844 Validation Decoder Loss:  0.3608743
Encoder Loss:  0.04179237  || Decoder Loss:  0.036980644 Validation Decoder Loss:  0.35250753
Encoder Loss:  0.040397927  || Decoder Loss:  0.03561411 Validation Decoder Loss:  0.35201982
Encoder Loss:  0.039957155  || Decoder Loss:  0.034589227 Validation Decoder Loss:  0.37837905
Encoder Loss:  0.046653423  || Decoder Loss:  0.04454176 Validation Decoder Loss:  0.35051274
Encoder Loss:  0.03970501  || Decoder Loss:  0.03474231 Validation Decoder Loss:  0.35410982
Encoder Loss:  0.0402708  || Decoder Loss:  0.035784695 Validation Decoder Loss:  0.35539836
Encoder Loss:  0.042316113  || Decoder Loss:  0.036843825 Validation Decoder Loss:  0.3584798
Encoder Loss:  0.045431897  || Decoder Loss:  0.040907856 Validation Decoder Loss:  0.35787958
Encoder Loss:  0.04051144  || Decoder Loss:  0.035759367 Validation Decoder Loss:  0.3571324
Encoder Loss:  0.042313088  || Decoder Loss:  0.037567556 Validation Decoder Loss:  0.3638572
Model: siamese_net_lr_0.008145485509039634 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36385715
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 314, 5, 20, 1)     63        
_________________________________________________________________
reshape_17 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 1570, 20, 1)       1677      
=================================================================
Total params: 1,677
Trainable params: 1,677
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 3245, 20, 1)       108       
=================================================================
Total params: 108
Trainable params: 108
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5876323  || Decoder Loss:  0.671153 Validation Decoder Loss:  0.6624211
Encoder Loss:  0.22908778  || Decoder Loss:  0.104005665 Validation Decoder Loss:  0.35134992
Encoder Loss:  0.18463624  || Decoder Loss:  0.034331743 Validation Decoder Loss:  0.3429175
Encoder Loss:  0.18364134  || Decoder Loss:  0.03278504 Validation Decoder Loss:  0.3429933
Encoder Loss:  0.18363376  || Decoder Loss:  0.03278874 Validation Decoder Loss:  0.34289062
Encoder Loss:  0.18362015  || Decoder Loss:  0.032785658 Validation Decoder Loss:  0.3428323
Encoder Loss:  0.18361345  || Decoder Loss:  0.03279611 Validation Decoder Loss:  0.34279
Encoder Loss:  0.1836063  || Decoder Loss:  0.03280885 Validation Decoder Loss:  0.34274596
Encoder Loss:  0.1835983  || Decoder Loss:  0.0328235 Validation Decoder Loss:  0.34269726
Encoder Loss:  0.1835894  || Decoder Loss:  0.03284029 Validation Decoder Loss:  0.34264457
Encoder Loss:  0.1835795  || Decoder Loss:  0.03285945 Validation Decoder Loss:  0.34258822
Encoder Loss:  0.18356843  || Decoder Loss:  0.032881264 Validation Decoder Loss:  0.3425282
Encoder Loss:  0.18355606  || Decoder Loss:  0.032906074 Validation Decoder Loss:  0.34246427
Encoder Loss:  0.1835421  || Decoder Loss:  0.032934267 Validation Decoder Loss:  0.3423964
Encoder Loss:  0.18352622  || Decoder Loss:  0.032966305 Validation Decoder Loss:  0.34232444
Encoder Loss:  0.18350804  || Decoder Loss:  0.033002738 Validation Decoder Loss:  0.3422482
Encoder Loss:  0.1834868  || Decoder Loss:  0.03304423 Validation Decoder Loss:  0.3421674
Encoder Loss:  0.18346168  || Decoder Loss:  0.03309159 Validation Decoder Loss:  0.3420817
Encoder Loss:  0.18343136  || Decoder Loss:  0.03314585 Validation Decoder Loss:  0.34199074
Encoder Loss:  0.18339384  || Decoder Loss:  0.033208314 Validation Decoder Loss:  0.3418938
Encoder Loss:  0.18334605  || Decoder Loss:  0.033280745 Validation Decoder Loss:  0.34179017
Encoder Loss:  0.1832831  || Decoder Loss:  0.033365544 Validation Decoder Loss:  0.34167862
Encoder Loss:  0.18319704  || Decoder Loss:  0.03346621 Validation Decoder Loss:  0.3415574
Encoder Loss:  0.18307394  || Decoder Loss:  0.03358812 Validation Decoder Loss:  0.34142393
Encoder Loss:  0.18288831  || Decoder Loss:  0.033740237 Validation Decoder Loss:  0.34127364
Encoder Loss:  0.18258862  || Decoder Loss:  0.03393929 Validation Decoder Loss:  0.3410989
Encoder Loss:  0.18205562  || Decoder Loss:  0.03422182 Validation Decoder Loss:  0.34088516
Encoder Loss:  0.18093872  || Decoder Loss:  0.034691915 Validation Decoder Loss:  0.34060553
Encoder Loss:  0.17746095  || Decoder Loss:  0.035887063 Validation Decoder Loss:  0.34043717
Encoder Loss:  0.23946427  || Decoder Loss:  0.2342506 Validation Decoder Loss:  1.1127077
Encoder Loss:  0.28719774  || Decoder Loss:  0.3973029 Validation Decoder Loss:  0.67197984
Encoder Loss:  0.08793282  || Decoder Loss:  0.09413457 Validation Decoder Loss:  0.36239976
Encoder Loss:  0.052119885  || Decoder Loss:  0.039099656 Validation Decoder Loss:  0.34429586
Encoder Loss:  0.046697184  || Decoder Loss:  0.034049578 Validation Decoder Loss:  0.3456951
Encoder Loss:  0.04596141  || Decoder Loss:  0.03360209 Validation Decoder Loss:  0.3463222
Encoder Loss:  0.047788277  || Decoder Loss:  0.034331862 Validation Decoder Loss:  0.34709495
Encoder Loss:  0.046759352  || Decoder Loss:  0.03466478 Validation Decoder Loss:  0.34687844
Encoder Loss:  0.04242121  || Decoder Loss:  0.03384621 Validation Decoder Loss:  0.34665412
Encoder Loss:  0.04501666  || Decoder Loss:  0.033777285 Validation Decoder Loss:  0.3469717
Encoder Loss:  0.045043077  || Decoder Loss:  0.03434266 Validation Decoder Loss:  0.34711754
Model: siamese_net_lr_0.07908045816565337 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34711754
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 108, 15, 20, 1)    136       
_________________________________________________________________
reshape_18 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 136
Trainable params: 136
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 1620, 20, 1)       8         
=================================================================
Total params: 8
Trainable params: 8
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 3245, 20, 1)       8         
=================================================================
Total params: 8
Trainable params: 8
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.062913105  || Decoder Loss:  0.053408194 Validation Decoder Loss:  0.34616643
Encoder Loss:  0.049981814  || Decoder Loss:  0.033655554 Validation Decoder Loss:  0.34518668
Encoder Loss:  0.067696586  || Decoder Loss:  0.033595353 Validation Decoder Loss:  0.34501272
Encoder Loss:  0.066267006  || Decoder Loss:  0.03360094 Validation Decoder Loss:  0.34495515
Encoder Loss:  0.049782623  || Decoder Loss:  0.033611633 Validation Decoder Loss:  0.34496552
Encoder Loss:  0.04465096  || Decoder Loss:  0.033609692 Validation Decoder Loss:  0.34501827
Encoder Loss:  0.04345516  || Decoder Loss:  0.033604797 Validation Decoder Loss:  0.3450936
Encoder Loss:  0.038204562  || Decoder Loss:  0.03360036 Validation Decoder Loss:  0.34517902
Encoder Loss:  0.042233538  || Decoder Loss:  0.033596586 Validation Decoder Loss:  0.3452456
Encoder Loss:  0.038195405  || Decoder Loss:  0.03359516 Validation Decoder Loss:  0.3452985
Encoder Loss:  0.037726983  || Decoder Loss:  0.033595078 Validation Decoder Loss:  0.3453315
Encoder Loss:  0.038321994  || Decoder Loss:  0.033595704 Validation Decoder Loss:  0.3453501
Encoder Loss:  0.039212137  || Decoder Loss:  0.033597518 Validation Decoder Loss:  0.3453652
Encoder Loss:  0.03739164  || Decoder Loss:  0.03360007 Validation Decoder Loss:  0.34538484
Encoder Loss:  0.03762487  || Decoder Loss:  0.033601794 Validation Decoder Loss:  0.34540063
Encoder Loss:  0.038937114  || Decoder Loss:  0.03360466 Validation Decoder Loss:  0.34541562
Encoder Loss:  0.038259353  || Decoder Loss:  0.03360777 Validation Decoder Loss:  0.34543717
Encoder Loss:  0.04019086  || Decoder Loss:  0.03361151 Validation Decoder Loss:  0.34546566
Encoder Loss:  0.0359892  || Decoder Loss:  0.03361418 Validation Decoder Loss:  0.3454998
Encoder Loss:  0.03847547  || Decoder Loss:  0.033615574 Validation Decoder Loss:  0.34552065
Encoder Loss:  0.036710408  || Decoder Loss:  0.03361691 Validation Decoder Loss:  0.34554297
Encoder Loss:  0.0368048  || Decoder Loss:  0.03361875 Validation Decoder Loss:  0.3455583
Encoder Loss:  0.037096962  || Decoder Loss:  0.033620507 Validation Decoder Loss:  0.34557557
Encoder Loss:  0.036334258  || Decoder Loss:  0.03362228 Validation Decoder Loss:  0.34559107
Encoder Loss:  0.037124313  || Decoder Loss:  0.03362377 Validation Decoder Loss:  0.3456045
Encoder Loss:  0.037027117  || Decoder Loss:  0.03362547 Validation Decoder Loss:  0.3456197
Encoder Loss:  0.037351653  || Decoder Loss:  0.033627376 Validation Decoder Loss:  0.3456346
Encoder Loss:  0.036398593  || Decoder Loss:  0.033629533 Validation Decoder Loss:  0.34564853
Encoder Loss:  0.037596043  || Decoder Loss:  0.033631302 Validation Decoder Loss:  0.34566516
Encoder Loss:  0.0405889  || Decoder Loss:  0.033634283 Validation Decoder Loss:  0.3456915
Encoder Loss:  0.03916564  || Decoder Loss:  0.03363869 Validation Decoder Loss:  0.34573716
Encoder Loss:  0.037871033  || Decoder Loss:  0.033641886 Validation Decoder Loss:  0.34575975
Encoder Loss:  0.037265133  || Decoder Loss:  0.0336444 Validation Decoder Loss:  0.3457821
Encoder Loss:  0.037317246  || Decoder Loss:  0.033646297 Validation Decoder Loss:  0.34579733
Encoder Loss:  0.039969258  || Decoder Loss:  0.033648916 Validation Decoder Loss:  0.3458235
Encoder Loss:  0.037815858  || Decoder Loss:  0.03365242 Validation Decoder Loss:  0.34586015
Encoder Loss:  0.03941808  || Decoder Loss:  0.03365582 Validation Decoder Loss:  0.34588775
Encoder Loss:  0.0383924  || Decoder Loss:  0.033659622 Validation Decoder Loss:  0.3459254
Encoder Loss:  0.03640783  || Decoder Loss:  0.033662714 Validation Decoder Loss:  0.34594575
Encoder Loss:  0.03865295  || Decoder Loss:  0.03366492 Validation Decoder Loss:  0.34596288
Model: siamese_net_lr_0.06616972652332863 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34596288
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 167, 10, 20, 1)    625       
_________________________________________________________________
reshape_19 (Reshape)         (None, 1670, 20, 1)       0         
=================================================================
Total params: 625
Trainable params: 625
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 1670, 20, 1)       1577      
=================================================================
Total params: 1,577
Trainable params: 1,577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 3245, 20, 1)       1577      
=================================================================
Total params: 1,577
Trainable params: 1,577
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.75003123  || Decoder Loss:  0.88770217 Validation Decoder Loss:  1.6352088
Encoder Loss:  0.7612954  || Decoder Loss:  0.90196794 Validation Decoder Loss:  1.6331909
Encoder Loss:  0.7592945  || Decoder Loss:  0.9001121 Validation Decoder Loss:  1.6305549
Encoder Loss:  0.7566601  || Decoder Loss:  0.8977135 Validation Decoder Loss:  1.6272281
Encoder Loss:  0.753276  || Decoder Loss:  0.8947078 Validation Decoder Loss:  1.6230955
Encoder Loss:  0.7489349  || Decoder Loss:  0.8909648 Validation Decoder Loss:  1.617924
Encoder Loss:  0.743243  || Decoder Loss:  0.88622576 Validation Decoder Loss:  1.6112366
Encoder Loss:  0.73537284  || Decoder Loss:  0.8799393 Validation Decoder Loss:  1.6019244
Encoder Loss:  0.7232014  || Decoder Loss:  0.87067485 Validation Decoder Loss:  1.5865635
Encoder Loss:  0.6984487  || Decoder Loss:  0.85254365 Validation Decoder Loss:  1.5436685
Encoder Loss:  0.52  || Decoder Loss:  0.6640578 Validation Decoder Loss:  0.55064845
Encoder Loss:  0.35263157  || Decoder Loss:  0.45902997 Validation Decoder Loss:  0.6379477
Encoder Loss:  0.3576993  || Decoder Loss:  0.47117814 Validation Decoder Loss:  0.6741471
Encoder Loss:  0.36021113  || Decoder Loss:  0.47840157 Validation Decoder Loss:  0.7399924
Encoder Loss:  0.3755879  || Decoder Loss:  0.5029256 Validation Decoder Loss:  0.84461963
Encoder Loss:  0.3820789  || Decoder Loss:  0.51436174 Validation Decoder Loss:  0.81123674
Encoder Loss:  0.38127768  || Decoder Loss:  0.51319796 Validation Decoder Loss:  0.8010253
Encoder Loss:  0.37796187  || Decoder Loss:  0.50873065 Validation Decoder Loss:  0.8231937
Encoder Loss:  0.3783805  || Decoder Loss:  0.5103153 Validation Decoder Loss:  0.7971981
Encoder Loss:  0.37735498  || Decoder Loss:  0.5087791 Validation Decoder Loss:  0.7833648
Encoder Loss:  0.37343675  || Decoder Loss:  0.50367033 Validation Decoder Loss:  0.77694815
Encoder Loss:  0.37190613  || Decoder Loss:  0.50198334 Validation Decoder Loss:  0.7806101
Encoder Loss:  0.36880952  || Decoder Loss:  0.49833462 Validation Decoder Loss:  0.7508815
Encoder Loss:  0.36580327  || Decoder Loss:  0.49373105 Validation Decoder Loss:  0.7582566
Encoder Loss:  0.36427993  || Decoder Loss:  0.49212125 Validation Decoder Loss:  0.76306665
Encoder Loss:  0.36128524  || Decoder Loss:  0.489389 Validation Decoder Loss:  0.79631996
Encoder Loss:  0.36506313  || Decoder Loss:  0.49649966 Validation Decoder Loss:  0.8102864
Encoder Loss:  0.36026108  || Decoder Loss:  0.4901475 Validation Decoder Loss:  0.84411025
Encoder Loss:  0.360177  || Decoder Loss:  0.49156785 Validation Decoder Loss:  0.8090435
Encoder Loss:  0.3565709  || Decoder Loss:  0.48470697 Validation Decoder Loss:  0.88611966
Encoder Loss:  0.3581694  || Decoder Loss:  0.48259732 Validation Decoder Loss:  0.8749763
Encoder Loss:  0.36557674  || Decoder Loss:  0.4949654 Validation Decoder Loss:  0.85446
Encoder Loss:  0.35622856  || Decoder Loss:  0.4855456 Validation Decoder Loss:  0.81390643
Encoder Loss:  0.35955933  || Decoder Loss:  0.48840824 Validation Decoder Loss:  0.7999903
Encoder Loss:  0.35855606  || Decoder Loss:  0.48836285 Validation Decoder Loss:  0.8121265
Encoder Loss:  0.35539466  || Decoder Loss:  0.48316178 Validation Decoder Loss:  0.8250783
Encoder Loss:  0.35605267  || Decoder Loss:  0.48544186 Validation Decoder Loss:  0.82957435
Encoder Loss:  0.35975045  || Decoder Loss:  0.48991004 Validation Decoder Loss:  0.7821126
Encoder Loss:  0.35968742  || Decoder Loss:  0.4860997 Validation Decoder Loss:  0.7819327
Encoder Loss:  0.35532805  || Decoder Loss:  0.48221833 Validation Decoder Loss:  0.8284023
Model: siamese_net_lr_0.08911490163739204 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8284023
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 104, 5, 20, 1)     42        
_________________________________________________________________
reshape_20 (Reshape)         (None, 520, 20, 1)        0         
=================================================================
Total params: 42
Trainable params: 42
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 520, 20, 1)        2727      
=================================================================
Total params: 2,727
Trainable params: 2,727
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 3245, 20, 1)       1689      
=================================================================
Total params: 1,689
Trainable params: 1,689
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8069572  || Decoder Loss:  0.8743281 Validation Decoder Loss:  1.5860783
Encoder Loss:  0.7370945  || Decoder Loss:  0.79097116 Validation Decoder Loss:  1.0813041
Encoder Loss:  0.3903281  || Decoder Loss:  0.4216629 Validation Decoder Loss:  1.1685054
Encoder Loss:  0.3789736  || Decoder Loss:  0.42938945 Validation Decoder Loss:  1.453257
Encoder Loss:  0.39586213  || Decoder Loss:  0.44400683 Validation Decoder Loss:  1.174808
Encoder Loss:  0.3617529  || Decoder Loss:  0.4097049 Validation Decoder Loss:  1.2592111
Encoder Loss:  0.24559046  || Decoder Loss:  0.27149257 Validation Decoder Loss:  0.469913
Encoder Loss:  0.06203193  || Decoder Loss:  0.054925423 Validation Decoder Loss:  0.36858693
Encoder Loss:  0.044126496  || Decoder Loss:  0.03240594 Validation Decoder Loss:  0.35884172
Encoder Loss:  0.03990401  || Decoder Loss:  0.029209053 Validation Decoder Loss:  0.36273745
Encoder Loss:  0.040515967  || Decoder Loss:  0.028704345 Validation Decoder Loss:  0.36040395
Encoder Loss:  0.038973644  || Decoder Loss:  0.028440282 Validation Decoder Loss:  0.3644339
Encoder Loss:  0.039206926  || Decoder Loss:  0.02832686 Validation Decoder Loss:  0.36848086
Encoder Loss:  0.040247455  || Decoder Loss:  0.028348142 Validation Decoder Loss:  0.36681405
Encoder Loss:  0.039073378  || Decoder Loss:  0.028275752 Validation Decoder Loss:  0.36593175
Encoder Loss:  0.039893348  || Decoder Loss:  0.028381307 Validation Decoder Loss:  0.36191183
Encoder Loss:  0.038999204  || Decoder Loss:  0.028528608 Validation Decoder Loss:  0.35863292
Encoder Loss:  0.038792208  || Decoder Loss:  0.028681323 Validation Decoder Loss:  0.35865286
Encoder Loss:  0.0384718  || Decoder Loss:  0.028593114 Validation Decoder Loss:  0.3587016
Encoder Loss:  0.03872548  || Decoder Loss:  0.028746903 Validation Decoder Loss:  0.35823208
Encoder Loss:  0.03990913  || Decoder Loss:  0.029911594 Validation Decoder Loss:  0.3456059
Encoder Loss:  0.039334737  || Decoder Loss:  0.030055601 Validation Decoder Loss:  0.36271372
Encoder Loss:  0.038446873  || Decoder Loss:  0.029027972 Validation Decoder Loss:  0.35076723
Encoder Loss:  0.038557347  || Decoder Loss:  0.029142678 Validation Decoder Loss:  0.3584262
Encoder Loss:  0.0383809  || Decoder Loss:  0.029193234 Validation Decoder Loss:  0.3553041
Encoder Loss:  0.03852701  || Decoder Loss:  0.029344533 Validation Decoder Loss:  0.35831213
Encoder Loss:  0.038455285  || Decoder Loss:  0.029533613 Validation Decoder Loss:  0.35891125
Encoder Loss:  0.039072204  || Decoder Loss:  0.029868161 Validation Decoder Loss:  0.36075228
Encoder Loss:  0.038343713  || Decoder Loss:  0.030011253 Validation Decoder Loss:  0.36400372
Encoder Loss:  0.038476557  || Decoder Loss:  0.030031195 Validation Decoder Loss:  0.3653944
Encoder Loss:  0.038688138  || Decoder Loss:  0.030378386 Validation Decoder Loss:  0.36175954
Encoder Loss:  0.039726287  || Decoder Loss:  0.030986814 Validation Decoder Loss:  0.36439353
Encoder Loss:  0.039287426  || Decoder Loss:  0.031260386 Validation Decoder Loss:  0.36810315
Encoder Loss:  0.038028304  || Decoder Loss:  0.030937884 Validation Decoder Loss:  0.37090364
Encoder Loss:  0.03811612  || Decoder Loss:  0.030990638 Validation Decoder Loss:  0.37698823
Encoder Loss:  0.037360415  || Decoder Loss:  0.03130611 Validation Decoder Loss:  0.35829842
Encoder Loss:  0.039090987  || Decoder Loss:  0.031231811 Validation Decoder Loss:  0.36832494
Encoder Loss:  0.039494622  || Decoder Loss:  0.031787805 Validation Decoder Loss:  0.36326343
Encoder Loss:  0.037660975  || Decoder Loss:  0.03199741 Validation Decoder Loss:  0.35953525
Encoder Loss:  0.03933177  || Decoder Loss:  0.032923482 Validation Decoder Loss:  0.35020602
Model: siamese_net_lr_0.021931877004638726 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35020602
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 634, 5, 20, 1)     446       
_________________________________________________________________
reshape_21 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 446
Trainable params: 446
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.082824275  || Decoder Loss:  0.45645428 Validation Decoder Loss:  0.86837167
Encoder Loss:  0.056118306  || Decoder Loss:  0.39291608 Validation Decoder Loss:  0.7497269
Encoder Loss:  0.054632932  || Decoder Loss:  0.3195463 Validation Decoder Loss:  0.6539298
Encoder Loss:  0.054529447  || Decoder Loss:  0.26532868 Validation Decoder Loss:  0.58860964
Encoder Loss:  0.05433781  || Decoder Loss:  0.22667828 Validation Decoder Loss:  0.5441744
Encoder Loss:  0.05412751  || Decoder Loss:  0.19892713 Validation Decoder Loss:  0.51301616
Encoder Loss:  0.0539736  || Decoder Loss:  0.17837195 Validation Decoder Loss:  0.49024817
Encoder Loss:  0.053835716  || Decoder Loss:  0.16264677 Validation Decoder Loss:  0.4729439
Encoder Loss:  0.053685423  || Decoder Loss:  0.15023349 Validation Decoder Loss:  0.45938754
Encoder Loss:  0.05346756  || Decoder Loss:  0.14018811 Validation Decoder Loss:  0.4484821
Encoder Loss:  0.053208984  || Decoder Loss:  0.13187759 Validation Decoder Loss:  0.43949056
Encoder Loss:  0.05292741  || Decoder Loss:  0.1248871 Validation Decoder Loss:  0.43200344
Encoder Loss:  0.052671444  || Decoder Loss:  0.11892449 Validation Decoder Loss:  0.4257036
Encoder Loss:  0.052470937  || Decoder Loss:  0.113787964 Validation Decoder Loss:  0.42032918
Encoder Loss:  0.052325383  || Decoder Loss:  0.10930197 Validation Decoder Loss:  0.41564804
Encoder Loss:  0.052143767  || Decoder Loss:  0.10534092 Validation Decoder Loss:  0.41157416
Encoder Loss:  0.052009087  || Decoder Loss:  0.10182111 Validation Decoder Loss:  0.407967
Encoder Loss:  0.051882364  || Decoder Loss:  0.0986671 Validation Decoder Loss:  0.40475485
Encoder Loss:  0.051768728  || Decoder Loss:  0.09581968 Validation Decoder Loss:  0.4018793
Encoder Loss:  0.051667232  || Decoder Loss:  0.09324011 Validation Decoder Loss:  0.3992977
Encoder Loss:  0.05159225  || Decoder Loss:  0.09088941 Validation Decoder Loss:  0.39695972
Encoder Loss:  0.051530212  || Decoder Loss:  0.08873751 Validation Decoder Loss:  0.394836
Encoder Loss:  0.051478993  || Decoder Loss:  0.086759545 Validation Decoder Loss:  0.39288634
Encoder Loss:  0.051416058  || Decoder Loss:  0.084933825 Validation Decoder Loss:  0.39111358
Encoder Loss:  0.051388606  || Decoder Loss:  0.0832434 Validation Decoder Loss:  0.38947392
Encoder Loss:  0.05134944  || Decoder Loss:  0.08167116 Validation Decoder Loss:  0.3879578
Encoder Loss:  0.05131504  || Decoder Loss:  0.08020572 Validation Decoder Loss:  0.38655597
Encoder Loss:  0.05129384  || Decoder Loss:  0.0788374 Validation Decoder Loss:  0.38525242
Encoder Loss:  0.051276397  || Decoder Loss:  0.07755442 Validation Decoder Loss:  0.3840375
Encoder Loss:  0.051264163  || Decoder Loss:  0.076349765 Validation Decoder Loss:  0.38290238
Encoder Loss:  0.051255994  || Decoder Loss:  0.07521686 Validation Decoder Loss:  0.38184112
Encoder Loss:  0.051249333  || Decoder Loss:  0.07414861 Validation Decoder Loss:  0.3808434
Encoder Loss:  0.05124453  || Decoder Loss:  0.07313905 Validation Decoder Loss:  0.37990484
Encoder Loss:  0.051240444  || Decoder Loss:  0.07218346 Validation Decoder Loss:  0.37901863
Encoder Loss:  0.051237  || Decoder Loss:  0.071277186 Validation Decoder Loss:  0.3781817
Encoder Loss:  0.051234454  || Decoder Loss:  0.07041654 Validation Decoder Loss:  0.37738883
Encoder Loss:  0.05123035  || Decoder Loss:  0.069597416 Validation Decoder Loss:  0.37663656
Encoder Loss:  0.051227313  || Decoder Loss:  0.06881734 Validation Decoder Loss:  0.3759223
Encoder Loss:  0.051225368  || Decoder Loss:  0.06807323 Validation Decoder Loss:  0.37524313
Encoder Loss:  0.05122146  || Decoder Loss:  0.06736262 Validation Decoder Loss:  0.37459603
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37459606
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 114, 5, 20, 1)     52        
_________________________________________________________________
reshape_22 (Reshape)         (None, 570, 20, 1)        0         
=================================================================
Total params: 52
Trainable params: 52
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 570, 20, 1)        401       
=================================================================
Total params: 401
Trainable params: 401
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 3245, 20, 1)       2677      
=================================================================
Total params: 2,677
Trainable params: 2,677
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.812707  || Decoder Loss:  0.93069077 Validation Decoder Loss:  1.6376588
Encoder Loss:  0.8274456  || Decoder Loss:  0.94658935 Validation Decoder Loss:  1.6316763
Encoder Loss:  0.82233983  || Decoder Loss:  0.93997514 Validation Decoder Loss:  1.6199555
Encoder Loss:  0.81264883  || Decoder Loss:  0.92737395 Validation Decoder Loss:  1.596034
Encoder Loss:  0.79342604  || Decoder Loss:  0.90229636 Validation Decoder Loss:  1.5456021
Encoder Loss:  0.7535315  || Decoder Loss:  0.85012555 Validation Decoder Loss:  1.4362154
Encoder Loss:  0.66782725  || Decoder Loss:  0.7378717 Validation Decoder Loss:  1.1985779
Encoder Loss:  0.49615386  || Decoder Loss:  0.512831 Validation Decoder Loss:  0.7851208
Encoder Loss:  0.28482404  || Decoder Loss:  0.23585549 Validation Decoder Loss:  0.47413784
Encoder Loss:  0.17694494  || Decoder Loss:  0.094928406 Validation Decoder Loss:  0.38121247
Encoder Loss:  0.14596234  || Decoder Loss:  0.055375557 Validation Decoder Loss:  0.3600083
Encoder Loss:  0.13652343  || Decoder Loss:  0.045099333 Validation Decoder Loss:  0.35610914
Encoder Loss:  0.13018395  || Decoder Loss:  0.04359251 Validation Decoder Loss:  0.3652278
Encoder Loss:  0.39594012  || Decoder Loss:  0.45098087 Validation Decoder Loss:  1.1093696
Encoder Loss:  0.3636723  || Decoder Loss:  0.44661197 Validation Decoder Loss:  1.2217424
Encoder Loss:  0.35499218  || Decoder Loss:  0.43584076 Validation Decoder Loss:  1.2695518
Encoder Loss:  0.35137993  || Decoder Loss:  0.43042922 Validation Decoder Loss:  1.314083
Encoder Loss:  0.3680667  || Decoder Loss:  0.45131612 Validation Decoder Loss:  1.2004776
Encoder Loss:  0.34314442  || Decoder Loss:  0.41999942 Validation Decoder Loss:  1.2950529
Encoder Loss:  0.35708633  || Decoder Loss:  0.43724486 Validation Decoder Loss:  1.1770104
Encoder Loss:  0.3398876  || Decoder Loss:  0.41662207 Validation Decoder Loss:  1.2701182
Encoder Loss:  0.34311932  || Decoder Loss:  0.42042178 Validation Decoder Loss:  1.2101153
Encoder Loss:  0.3299804  || Decoder Loss:  0.40303615 Validation Decoder Loss:  1.2043822
Encoder Loss:  0.32420513  || Decoder Loss:  0.3964195 Validation Decoder Loss:  1.2540028
Encoder Loss:  0.32412273  || Decoder Loss:  0.3961419 Validation Decoder Loss:  1.2887948
Encoder Loss:  0.32624328  || Decoder Loss:  0.39877868 Validation Decoder Loss:  1.2579963
Encoder Loss:  0.31647712  || Decoder Loss:  0.38617927 Validation Decoder Loss:  1.2694877
Encoder Loss:  0.30652717  || Decoder Loss:  0.3727777 Validation Decoder Loss:  1.2064933
Encoder Loss:  0.27339503  || Decoder Loss:  0.33038303 Validation Decoder Loss:  1.1163894
Encoder Loss:  0.2275662  || Decoder Loss:  0.26947936 Validation Decoder Loss:  0.83683395
Encoder Loss:  0.12344293  || Decoder Loss:  0.13345805 Validation Decoder Loss:  0.5318574
Encoder Loss:  0.13533872  || Decoder Loss:  0.14935006 Validation Decoder Loss:  0.648469
Encoder Loss:  0.12065114  || Decoder Loss:  0.12993634 Validation Decoder Loss:  0.6792887
Encoder Loss:  0.07580851  || Decoder Loss:  0.07161759 Validation Decoder Loss:  0.47493693
Encoder Loss:  0.04941588  || Decoder Loss:  0.03683116 Validation Decoder Loss:  0.41892007
Encoder Loss:  0.042275026  || Decoder Loss:  0.028234351 Validation Decoder Loss:  0.38565293
Encoder Loss:  0.040054917  || Decoder Loss:  0.025235705 Validation Decoder Loss:  0.42024004
Encoder Loss:  0.04068143  || Decoder Loss:  0.026484983 Validation Decoder Loss:  0.3993478
Encoder Loss:  0.043665115  || Decoder Loss:  0.030799227 Validation Decoder Loss:  0.40536416
Encoder Loss:  0.040479854  || Decoder Loss:  0.027257454 Validation Decoder Loss:  0.40449327
Model: siamese_net_lr_0.06343878223030512 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.40449327
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 124, 5, 20, 1)     62        
_________________________________________________________________
reshape_23 (Reshape)         (None, 620, 20, 1)        0         
=================================================================
Total params: 62
Trainable params: 62
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 620, 20, 1)        2008      
=================================================================
Total params: 2,008
Trainable params: 2,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 3245, 20, 1)       2627      
=================================================================
Total params: 2,627
Trainable params: 2,627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7571904  || Decoder Loss:  0.9259163 Validation Decoder Loss:  1.6154411
Encoder Loss:  0.7614132  || Decoder Loss:  0.9274858 Validation Decoder Loss:  1.5647918
Encoder Loss:  0.72895736  || Decoder Loss:  0.87808084 Validation Decoder Loss:  1.4153464
Encoder Loss:  0.6239351  || Decoder Loss:  0.71783125 Validation Decoder Loss:  0.9958452
Encoder Loss:  0.3906408  || Decoder Loss:  0.36160907 Validation Decoder Loss:  0.4877444
Encoder Loss:  0.22879116  || Decoder Loss:  0.114741 Validation Decoder Loss:  0.36118627
Encoder Loss:  0.19037682  || Decoder Loss:  0.056764744 Validation Decoder Loss:  0.34459502
Encoder Loss:  0.18184823  || Decoder Loss:  0.04479899 Validation Decoder Loss:  0.34231266
Encoder Loss:  0.17876154  || Decoder Loss:  0.041731354 Validation Decoder Loss:  0.3422266
Encoder Loss:  0.17630494  || Decoder Loss:  0.040885907 Validation Decoder Loss:  0.34339175
Encoder Loss:  0.1718877  || Decoder Loss:  0.041313652 Validation Decoder Loss:  0.34833434
Encoder Loss:  0.2891214  || Decoder Loss:  0.29353964 Validation Decoder Loss:  1.4598527
Encoder Loss:  0.3301005  || Decoder Loss:  0.4382583 Validation Decoder Loss:  1.4673529
Encoder Loss:  0.3501516  || Decoder Loss:  0.47485173 Validation Decoder Loss:  1.3986009
Encoder Loss:  0.35199893  || Decoder Loss:  0.47810394 Validation Decoder Loss:  1.2869053
Encoder Loss:  0.33600166  || Decoder Loss:  0.45982802 Validation Decoder Loss:  1.2971184
Encoder Loss:  0.3360631  || Decoder Loss:  0.46046627 Validation Decoder Loss:  1.2890285
Encoder Loss:  0.3376756  || Decoder Loss:  0.46272096 Validation Decoder Loss:  1.3214846
Encoder Loss:  0.33657315  || Decoder Loss:  0.45935613 Validation Decoder Loss:  1.2469486
Encoder Loss:  0.33013687  || Decoder Loss:  0.45208725 Validation Decoder Loss:  1.2595879
Encoder Loss:  0.33003944  || Decoder Loss:  0.45194522 Validation Decoder Loss:  1.264413
Encoder Loss:  0.32813418  || Decoder Loss:  0.4478177 Validation Decoder Loss:  1.2886734
Encoder Loss:  0.33483502  || Decoder Loss:  0.45595425 Validation Decoder Loss:  1.1827928
Encoder Loss:  0.32361484  || Decoder Loss:  0.44260484 Validation Decoder Loss:  1.2766652
Encoder Loss:  0.33102176  || Decoder Loss:  0.45107797 Validation Decoder Loss:  1.1672108
Encoder Loss:  0.3182345  || Decoder Loss:  0.43706474 Validation Decoder Loss:  1.2045428
Encoder Loss:  0.31473517  || Decoder Loss:  0.4310259 Validation Decoder Loss:  1.2181137
Encoder Loss:  0.3129208  || Decoder Loss:  0.42834213 Validation Decoder Loss:  1.2639053
Encoder Loss:  0.31414518  || Decoder Loss:  0.42961416 Validation Decoder Loss:  1.2544041
Encoder Loss:  0.30736944  || Decoder Loss:  0.41926047 Validation Decoder Loss:  1.2643478
Encoder Loss:  0.30210376  || Decoder Loss:  0.41037107 Validation Decoder Loss:  1.2416072
Encoder Loss:  0.29644153  || Decoder Loss:  0.4018997 Validation Decoder Loss:  1.2365909
Encoder Loss:  0.2947942  || Decoder Loss:  0.39683834 Validation Decoder Loss:  1.1000156
Encoder Loss:  0.27283782  || Decoder Loss:  0.36748025 Validation Decoder Loss:  1.1452844
Encoder Loss:  0.2922568  || Decoder Loss:  0.39569148 Validation Decoder Loss:  1.2774279
Encoder Loss:  0.28712445  || Decoder Loss:  0.38722095 Validation Decoder Loss:  1.1136156
Encoder Loss:  0.27943262  || Decoder Loss:  0.37776467 Validation Decoder Loss:  1.2568656
Encoder Loss:  0.2718124  || Decoder Loss:  0.36582306 Validation Decoder Loss:  1.1346296
Encoder Loss:  0.33147216  || Decoder Loss:  0.4544954 Validation Decoder Loss:  0.6825631
Encoder Loss:  0.29082906  || Decoder Loss:  0.39628875 Validation Decoder Loss:  1.0212803
Model: siamese_net_lr_0.06759486466032205 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0212803
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 101, 20, 20, 1)    305       
_________________________________________________________________
reshape_24 (Reshape)         (None, 2020, 20, 1)       0         
=================================================================
Total params: 305
Trainable params: 305
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 2020, 20, 1)       1227      
=================================================================
Total params: 1,227
Trainable params: 1,227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 3245, 20, 1)       1227      
=================================================================
Total params: 1,227
Trainable params: 1,227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5051142  || Decoder Loss:  0.8934562 Validation Decoder Loss:  1.6366047
Encoder Loss:  0.5135481  || Decoder Loss:  0.9101736 Validation Decoder Loss:  1.631638
Encoder Loss:  0.51084656  || Decoder Loss:  0.90625554 Validation Decoder Loss:  1.6246552
Encoder Loss:  0.505304  || Decoder Loss:  0.9004429 Validation Decoder Loss:  1.6142168
Encoder Loss:  0.48942402  || Decoder Loss:  0.89056087 Validation Decoder Loss:  1.5953102
Encoder Loss:  0.32887244  || Decoder Loss:  0.6881548 Validation Decoder Loss:  0.5255599
Encoder Loss:  0.15982921  || Decoder Loss:  0.47301415 Validation Decoder Loss:  1.0103296
Encoder Loss:  0.1284808  || Decoder Loss:  0.48480728 Validation Decoder Loss:  0.8112516
Encoder Loss:  0.11607968  || Decoder Loss:  0.40269473 Validation Decoder Loss:  0.9196392
Encoder Loss:  0.11276276  || Decoder Loss:  0.40283307 Validation Decoder Loss:  1.0454907
Encoder Loss:  0.093752325  || Decoder Loss:  0.28132805 Validation Decoder Loss:  0.82316875
Encoder Loss:  0.1051776  || Decoder Loss:  0.3683853 Validation Decoder Loss:  0.78628707
Encoder Loss:  0.07103469  || Decoder Loss:  0.16499874 Validation Decoder Loss:  0.6252552
Encoder Loss:  0.083035834  || Decoder Loss:  0.22518225 Validation Decoder Loss:  0.6145487
Encoder Loss:  0.07596553  || Decoder Loss:  0.18195145 Validation Decoder Loss:  0.46568796
Encoder Loss:  0.07035176  || Decoder Loss:  0.14975157 Validation Decoder Loss:  0.4875073
Encoder Loss:  0.06523746  || Decoder Loss:  0.13124236 Validation Decoder Loss:  0.49397367
Encoder Loss:  0.059784144  || Decoder Loss:  0.06961604 Validation Decoder Loss:  0.33899248
Encoder Loss:  0.055252843  || Decoder Loss:  0.03822739 Validation Decoder Loss:  0.34465805
Encoder Loss:  0.05754801  || Decoder Loss:  0.040208437 Validation Decoder Loss:  0.34889746
Encoder Loss:  0.05627127  || Decoder Loss:  0.038970795 Validation Decoder Loss:  0.3645964
Encoder Loss:  0.05250963  || Decoder Loss:  0.039260354 Validation Decoder Loss:  0.36826706
Encoder Loss:  0.05667095  || Decoder Loss:  0.04105549 Validation Decoder Loss:  0.34756377
Encoder Loss:  0.06092133  || Decoder Loss:  0.03789773 Validation Decoder Loss:  0.35835108
Encoder Loss:  0.053847283  || Decoder Loss:  0.039836388 Validation Decoder Loss:  0.36010635
Encoder Loss:  0.05340789  || Decoder Loss:  0.04406347 Validation Decoder Loss:  0.3651922
Encoder Loss:  0.056242514  || Decoder Loss:  0.04181911 Validation Decoder Loss:  0.3625993
Encoder Loss:  0.05253433  || Decoder Loss:  0.039657857 Validation Decoder Loss:  0.3614607
Encoder Loss:  0.054818157  || Decoder Loss:  0.039234217 Validation Decoder Loss:  0.37239158
Encoder Loss:  0.052565884  || Decoder Loss:  0.041628685 Validation Decoder Loss:  0.34950703
Encoder Loss:  0.052557897  || Decoder Loss:  0.039866477 Validation Decoder Loss:  0.35406345
Encoder Loss:  0.05137948  || Decoder Loss:  0.039456636 Validation Decoder Loss:  0.3673373
Encoder Loss:  0.05550879  || Decoder Loss:  0.042430386 Validation Decoder Loss:  0.358415
Encoder Loss:  0.054759372  || Decoder Loss:  0.03788026 Validation Decoder Loss:  0.365157
Encoder Loss:  0.055202045  || Decoder Loss:  0.0406958 Validation Decoder Loss:  0.37139452
Encoder Loss:  0.052125245  || Decoder Loss:  0.041605238 Validation Decoder Loss:  0.36231005
Encoder Loss:  0.053212527  || Decoder Loss:  0.039591253 Validation Decoder Loss:  0.35596204
Encoder Loss:  0.05842969  || Decoder Loss:  0.040760897 Validation Decoder Loss:  0.36898273
Encoder Loss:  0.05193949  || Decoder Loss:  0.04125701 Validation Decoder Loss:  0.36151135
Encoder Loss:  0.051571574  || Decoder Loss:  0.039383795 Validation Decoder Loss:  0.3558344
Model: siamese_net_lr_0.019991253134955096 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3558344
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 138, 15, 20, 1)    85        
_________________________________________________________________
reshape_25 (Reshape)         (None, 2070, 20, 1)       0         
=================================================================
Total params: 85
Trainable params: 85
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 2070, 20, 1)       1177      
=================================================================
Total params: 1,177
Trainable params: 1,177
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 3245, 20, 1)       1177      
=================================================================
Total params: 1,177
Trainable params: 1,177
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5339521  || Decoder Loss:  0.9050127 Validation Decoder Loss:  1.6338131
Encoder Loss:  0.5552268  || Decoder Loss:  0.92065805 Validation Decoder Loss:  1.6293166
Encoder Loss:  0.55456764  || Decoder Loss:  0.918379 Validation Decoder Loss:  1.6224046
Encoder Loss:  0.5533377  || Decoder Loss:  0.91488403 Validation Decoder Loss:  1.6112452
Encoder Loss:  0.5511711  || Decoder Loss:  0.90890473 Validation Decoder Loss:  1.5894125
Encoder Loss:  0.5459527  || Decoder Loss:  0.8932128 Validation Decoder Loss:  1.5031576
Encoder Loss:  0.42738804  || Decoder Loss:  0.3893174 Validation Decoder Loss:  0.3177147
Encoder Loss:  0.33059993  || Decoder Loss:  0.067102015 Validation Decoder Loss:  0.32606387
Encoder Loss:  0.26067927  || Decoder Loss:  0.5735831 Validation Decoder Loss:  0.32313508
Encoder Loss:  0.14320165  || Decoder Loss:  0.4043546 Validation Decoder Loss:  1.414303
Encoder Loss:  0.16360663  || Decoder Loss:  0.49514976 Validation Decoder Loss:  1.5920945
Encoder Loss:  0.16102327  || Decoder Loss:  0.48056352 Validation Decoder Loss:  1.384394
Encoder Loss:  0.14662781  || Decoder Loss:  0.42855617 Validation Decoder Loss:  1.288795
Encoder Loss:  0.16128226  || Decoder Loss:  0.4948431 Validation Decoder Loss:  1.1248168
Encoder Loss:  0.15012309  || Decoder Loss:  0.44699243 Validation Decoder Loss:  1.307695
Encoder Loss:  0.13516633  || Decoder Loss:  0.38248783 Validation Decoder Loss:  0.93488777
Encoder Loss:  0.1542254  || Decoder Loss:  0.44404724 Validation Decoder Loss:  0.7270514
Encoder Loss:  0.094809875  || Decoder Loss:  0.20533134 Validation Decoder Loss:  0.41312814
Encoder Loss:  0.069966905  || Decoder Loss:  0.09336939 Validation Decoder Loss:  0.5819415
Encoder Loss:  0.0605019  || Decoder Loss:  0.0554801 Validation Decoder Loss:  0.36883837
Encoder Loss:  0.056704525  || Decoder Loss:  0.043870673 Validation Decoder Loss:  0.36070964
Encoder Loss:  0.05749105  || Decoder Loss:  0.039679825 Validation Decoder Loss:  0.3752362
Encoder Loss:  0.05499739  || Decoder Loss:  0.037336547 Validation Decoder Loss:  0.34971592
Encoder Loss:  0.052734222  || Decoder Loss:  0.034487337 Validation Decoder Loss:  0.35092545
Encoder Loss:  0.059168816  || Decoder Loss:  0.035852633 Validation Decoder Loss:  0.35998142
Encoder Loss:  0.06348488  || Decoder Loss:  0.03959173 Validation Decoder Loss:  0.37820554
Encoder Loss:  0.06455496  || Decoder Loss:  0.043548312 Validation Decoder Loss:  0.3561859
Encoder Loss:  0.05524652  || Decoder Loss:  0.036084384 Validation Decoder Loss:  0.3541798
Encoder Loss:  0.05064188  || Decoder Loss:  0.033745505 Validation Decoder Loss:  0.3501926
Encoder Loss:  0.052707173  || Decoder Loss:  0.033677295 Validation Decoder Loss:  0.3485115
Encoder Loss:  0.04996108  || Decoder Loss:  0.033083238 Validation Decoder Loss:  0.35530436
Encoder Loss:  0.056316648  || Decoder Loss:  0.03617765 Validation Decoder Loss:  0.37083393
Encoder Loss:  0.05895164  || Decoder Loss:  0.037759572 Validation Decoder Loss:  0.36263824
Encoder Loss:  0.06358187  || Decoder Loss:  0.038680013 Validation Decoder Loss:  0.35243484
Encoder Loss:  0.054038536  || Decoder Loss:  0.037170276 Validation Decoder Loss:  0.3559323
Encoder Loss:  0.05450267  || Decoder Loss:  0.03922264 Validation Decoder Loss:  0.35445148
Encoder Loss:  0.052240923  || Decoder Loss:  0.03555369 Validation Decoder Loss:  0.35517186
Encoder Loss:  0.0533674  || Decoder Loss:  0.033959605 Validation Decoder Loss:  0.35576195
Encoder Loss:  0.053048257  || Decoder Loss:  0.034905203 Validation Decoder Loss:  0.3522333
Encoder Loss:  0.053358465  || Decoder Loss:  0.033335716 Validation Decoder Loss:  0.34446687
Model: siamese_net_lr_0.024393594589038625 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34446687
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 212, 10, 20, 1)    299       
_________________________________________________________________
reshape_26 (Reshape)         (None, 2120, 20, 1)       0         
=================================================================
Total params: 299
Trainable params: 299
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 2120, 20, 1)       1127      
=================================================================
Total params: 1,127
Trainable params: 1,127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 3245, 20, 1)       1127      
=================================================================
Total params: 1,127
Trainable params: 1,127
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.64502454  || Decoder Loss:  0.9028116 Validation Decoder Loss:  1.6367438
Encoder Loss:  0.656362  || Decoder Loss:  0.91815084 Validation Decoder Loss:  1.6351111
Encoder Loss:  0.6554995  || Decoder Loss:  0.9169382 Validation Decoder Loss:  1.6330392
Encoder Loss:  0.6543319  || Decoder Loss:  0.9153502 Validation Decoder Loss:  1.6303928
Encoder Loss:  0.6527783  || Decoder Loss:  0.91333 Validation Decoder Loss:  1.6270607
Encoder Loss:  0.6507058  || Decoder Loss:  0.9107762 Validation Decoder Loss:  1.6228573
Encoder Loss:  0.6478816  || Decoder Loss:  0.90750945 Validation Decoder Loss:  1.6174531
Encoder Loss:  0.6438702  || Decoder Loss:  0.90319234 Validation Decoder Loss:  1.6102113
Encoder Loss:  0.6377401  || Decoder Loss:  0.89710516 Validation Decoder Loss:  1.5996798
Encoder Loss:  0.6269896  || Decoder Loss:  0.88730866 Validation Decoder Loss:  1.5813497
Encoder Loss:  0.6008292  || Decoder Loss:  0.86518174 Validation Decoder Loss:  1.5257021
Encoder Loss:  0.40714827  || Decoder Loss:  0.6440212 Validation Decoder Loss:  0.78792727
Encoder Loss:  0.27539405  || Decoder Loss:  0.49880764 Validation Decoder Loss:  0.98118186
Encoder Loss:  0.26582897  || Decoder Loss:  0.5087442 Validation Decoder Loss:  0.9681342
Encoder Loss:  0.26347268  || Decoder Loss:  0.5058213 Validation Decoder Loss:  0.9781363
Encoder Loss:  0.26174372  || Decoder Loss:  0.5046025 Validation Decoder Loss:  0.9760355
Encoder Loss:  0.25894037  || Decoder Loss:  0.49995762 Validation Decoder Loss:  0.9818611
Encoder Loss:  0.25656423  || Decoder Loss:  0.49714983 Validation Decoder Loss:  0.97026193
Encoder Loss:  0.25457194  || Decoder Loss:  0.4910612 Validation Decoder Loss:  0.9901897
Encoder Loss:  0.25172263  || Decoder Loss:  0.48955375 Validation Decoder Loss:  0.9862752
Encoder Loss:  0.25075486  || Decoder Loss:  0.48764402 Validation Decoder Loss:  0.9958117
Encoder Loss:  0.24799281  || Decoder Loss:  0.48493022 Validation Decoder Loss:  1.0095137
Encoder Loss:  0.24638903  || Decoder Loss:  0.48252782 Validation Decoder Loss:  1.0291576
Encoder Loss:  0.24539879  || Decoder Loss:  0.4806636 Validation Decoder Loss:  1.0524616
Encoder Loss:  0.2439918  || Decoder Loss:  0.47789288 Validation Decoder Loss:  1.1011703
Encoder Loss:  0.24359654  || Decoder Loss:  0.4765203 Validation Decoder Loss:  1.1434646
Encoder Loss:  0.24017014  || Decoder Loss:  0.47177982 Validation Decoder Loss:  1.1589533
Encoder Loss:  0.24423403  || Decoder Loss:  0.47506976 Validation Decoder Loss:  1.0627041
Encoder Loss:  0.24401295  || Decoder Loss:  0.46345302 Validation Decoder Loss:  1.0744829
Encoder Loss:  0.21562468  || Decoder Loss:  0.4150343 Validation Decoder Loss:  0.8475653
Encoder Loss:  0.21770921  || Decoder Loss:  0.41960102 Validation Decoder Loss:  1.0472705
Encoder Loss:  0.23741046  || Decoder Loss:  0.45817074 Validation Decoder Loss:  1.1362628
Encoder Loss:  0.21668607  || Decoder Loss:  0.41862172 Validation Decoder Loss:  0.82740486
Encoder Loss:  0.24609981  || Decoder Loss:  0.48134136 Validation Decoder Loss:  0.8958502
Encoder Loss:  0.24692683  || Decoder Loss:  0.4856061 Validation Decoder Loss:  0.9203169
Encoder Loss:  0.24226081  || Decoder Loss:  0.47353536 Validation Decoder Loss:  1.0321848
Encoder Loss:  0.21948813  || Decoder Loss:  0.42245185 Validation Decoder Loss:  0.9280538
Encoder Loss:  0.21102637  || Decoder Loss:  0.40107417 Validation Decoder Loss:  0.89178276
Encoder Loss:  0.23243998  || Decoder Loss:  0.44222164 Validation Decoder Loss:  0.80194783
Encoder Loss:  0.22090603  || Decoder Loss:  0.422715 Validation Decoder Loss:  1.0618453
Model: siamese_net_lr_0.0661881586913471 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0618453
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 394, 5, 20, 1)     206       
_________________________________________________________________
reshape_27 (Reshape)         (None, 1970, 20, 1)       0         
=================================================================
Total params: 206
Trainable params: 206
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 1970, 20, 1)       1277      
=================================================================
Total params: 1,277
Trainable params: 1,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 3245, 20, 1)       1277      
=================================================================
Total params: 1,277
Trainable params: 1,277
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43300053  || Decoder Loss:  0.89669764 Validation Decoder Loss:  1.6362822
Encoder Loss:  0.44834313  || Decoder Loss:  0.91014826 Validation Decoder Loss:  1.6294932
Encoder Loss:  0.44797343  || Decoder Loss:  0.9060946 Validation Decoder Loss:  1.6192305
Encoder Loss:  0.4474716  || Decoder Loss:  0.8999629 Validation Decoder Loss:  1.6018505
Encoder Loss:  0.44680434  || Decoder Loss:  0.8889767 Validation Decoder Loss:  1.561721
Encoder Loss:  0.44574836  || Decoder Loss:  0.82142675 Validation Decoder Loss:  0.35054958
Encoder Loss:  0.44201428  || Decoder Loss:  0.07708443 Validation Decoder Loss:  0.31745687
Encoder Loss:  0.44060743  || Decoder Loss:  0.07245322 Validation Decoder Loss:  0.32296944
Encoder Loss:  0.43872523  || Decoder Loss:  0.071881145 Validation Decoder Loss:  0.32482886
Encoder Loss:  0.43605998  || Decoder Loss:  0.0707279 Validation Decoder Loss:  0.326617
Encoder Loss:  0.43197793  || Decoder Loss:  0.06902136 Validation Decoder Loss:  0.32917005
Encoder Loss:  0.42469886  || Decoder Loss:  0.06639721 Validation Decoder Loss:  0.3351298
Encoder Loss:  0.4055067  || Decoder Loss:  0.06368604 Validation Decoder Loss:  0.37795025
Encoder Loss:  0.22904521  || Decoder Loss:  0.31908095 Validation Decoder Loss:  1.1053891
Encoder Loss:  0.0927479  || Decoder Loss:  0.43919632 Validation Decoder Loss:  1.2449759
Encoder Loss:  0.09517042  || Decoder Loss:  0.44541776 Validation Decoder Loss:  1.2116365
Encoder Loss:  0.09146299  || Decoder Loss:  0.43747643 Validation Decoder Loss:  1.2452102
Encoder Loss:  0.089543365  || Decoder Loss:  0.44029778 Validation Decoder Loss:  1.2452289
Encoder Loss:  0.086994216  || Decoder Loss:  0.43984348 Validation Decoder Loss:  1.2516083
Encoder Loss:  0.084927194  || Decoder Loss:  0.44088495 Validation Decoder Loss:  1.2565589
Encoder Loss:  0.082985915  || Decoder Loss:  0.44002837 Validation Decoder Loss:  1.2709556
Encoder Loss:  0.08142975  || Decoder Loss:  0.4412924 Validation Decoder Loss:  1.2229362
Encoder Loss:  0.07703826  || Decoder Loss:  0.4387542 Validation Decoder Loss:  1.3180175
Encoder Loss:  0.075205475  || Decoder Loss:  0.4436286 Validation Decoder Loss:  1.2830975
Encoder Loss:  0.07278462  || Decoder Loss:  0.4377169 Validation Decoder Loss:  1.3262653
Encoder Loss:  0.069753535  || Decoder Loss:  0.44155213 Validation Decoder Loss:  1.3175123
Encoder Loss:  0.06786004  || Decoder Loss:  0.4410561 Validation Decoder Loss:  1.3642988
Encoder Loss:  0.065126926  || Decoder Loss:  0.44389194 Validation Decoder Loss:  1.2792375
Encoder Loss:  0.06328252  || Decoder Loss:  0.43798125 Validation Decoder Loss:  1.1999027
Encoder Loss:  0.057418313  || Decoder Loss:  0.41271564 Validation Decoder Loss:  1.0874264
Encoder Loss:  0.059438378  || Decoder Loss:  0.36903626 Validation Decoder Loss:  0.93752044
Encoder Loss:  0.056621496  || Decoder Loss:  0.4286609 Validation Decoder Loss:  0.9676397
Encoder Loss:  0.05870931  || Decoder Loss:  0.49420872 Validation Decoder Loss:  0.97797537
Encoder Loss:  0.06376589  || Decoder Loss:  0.49434718 Validation Decoder Loss:  0.97584426
Encoder Loss:  0.060716692  || Decoder Loss:  0.49408227 Validation Decoder Loss:  0.9780108
Encoder Loss:  0.06252181  || Decoder Loss:  0.4928774 Validation Decoder Loss:  0.98520625
Encoder Loss:  0.057212457  || Decoder Loss:  0.489452 Validation Decoder Loss:  0.99016446
Encoder Loss:  0.05814806  || Decoder Loss:  0.48254412 Validation Decoder Loss:  0.99618495
Encoder Loss:  0.056858074  || Decoder Loss:  0.408952 Validation Decoder Loss:  0.8921522
Encoder Loss:  0.05700825  || Decoder Loss:  0.37354288 Validation Decoder Loss:  0.8669262
Model: siamese_net_lr_0.043941505511170986 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8669262
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 70, 16, 20, 1)     57        
_________________________________________________________________
reshape_28 (Reshape)         (None, 1120, 20, 1)       0         
=================================================================
Total params: 57
Trainable params: 57
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 1120, 20, 1)       1008      
=================================================================
Total params: 1,008
Trainable params: 1,008
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 3245, 20, 1)       2127      
=================================================================
Total params: 2,127
Trainable params: 2,127
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5185189  || Decoder Loss:  0.9008685 Validation Decoder Loss:  1.6280339
Encoder Loss:  0.52657026  || Decoder Loss:  0.9042846 Validation Decoder Loss:  1.6085937
Encoder Loss:  0.5216523  || Decoder Loss:  0.8765862 Validation Decoder Loss:  1.5615498
Encoder Loss:  0.5098789  || Decoder Loss:  0.81251955 Validation Decoder Loss:  1.4094806
Encoder Loss:  0.44880593  || Decoder Loss:  0.51889336 Validation Decoder Loss:  0.53725374
Encoder Loss:  0.38400853  || Decoder Loss:  0.07624194 Validation Decoder Loss:  0.37626088
Encoder Loss:  0.3792926  || Decoder Loss:  0.050111637 Validation Decoder Loss:  0.37769818
Encoder Loss:  0.37876225  || Decoder Loss:  0.04899693 Validation Decoder Loss:  0.37891382
Encoder Loss:  0.37821233  || Decoder Loss:  0.048511423 Validation Decoder Loss:  0.37893116
Encoder Loss:  0.37745312  || Decoder Loss:  0.048075136 Validation Decoder Loss:  0.37850696
Encoder Loss:  0.37626934  || Decoder Loss:  0.047645874 Validation Decoder Loss:  0.37798536
Encoder Loss:  0.37409824  || Decoder Loss:  0.04722858 Validation Decoder Loss:  0.37751782
Encoder Loss:  0.36877197  || Decoder Loss:  0.046870492 Validation Decoder Loss:  0.37733513
Encoder Loss:  0.32559574  || Decoder Loss:  0.0483267 Validation Decoder Loss:  1.3124636
Encoder Loss:  0.1681225  || Decoder Loss:  0.51882005 Validation Decoder Loss:  1.1615266
Encoder Loss:  0.15085767  || Decoder Loss:  0.49137115 Validation Decoder Loss:  1.2572134
Encoder Loss:  0.13843992  || Decoder Loss:  0.4977981 Validation Decoder Loss:  1.0587273
Encoder Loss:  0.11865534  || Decoder Loss:  0.41303307 Validation Decoder Loss:  1.4965758
Encoder Loss:  0.13494687  || Decoder Loss:  0.4801324 Validation Decoder Loss:  1.185961
Encoder Loss:  0.114297055  || Decoder Loss:  0.39633095 Validation Decoder Loss:  1.1838145
Encoder Loss:  0.13743974  || Decoder Loss:  0.49106053 Validation Decoder Loss:  1.0371513
Encoder Loss:  0.14014518  || Decoder Loss:  0.4944688 Validation Decoder Loss:  0.8391247
Encoder Loss:  0.1340729  || Decoder Loss:  0.47623435 Validation Decoder Loss:  0.77536654
Encoder Loss:  0.1374544  || Decoder Loss:  0.49600628 Validation Decoder Loss:  0.85053146
Encoder Loss:  0.14325425  || Decoder Loss:  0.50039846 Validation Decoder Loss:  0.9110915
Encoder Loss:  0.14706248  || Decoder Loss:  0.49027088 Validation Decoder Loss:  1.0146791
Encoder Loss:  0.13508572  || Decoder Loss:  0.48876816 Validation Decoder Loss:  1.0357572
Encoder Loss:  0.1449005  || Decoder Loss:  0.49157524 Validation Decoder Loss:  0.9259032
Encoder Loss:  0.13271195  || Decoder Loss:  0.47882 Validation Decoder Loss:  1.0217948
Encoder Loss:  0.13124076  || Decoder Loss:  0.4850437 Validation Decoder Loss:  0.8335213
Encoder Loss:  0.13647966  || Decoder Loss:  0.48308152 Validation Decoder Loss:  0.9900367
Encoder Loss:  0.12796825  || Decoder Loss:  0.44156602 Validation Decoder Loss:  0.6500299
Encoder Loss:  0.1334334  || Decoder Loss:  0.49187228 Validation Decoder Loss:  0.9850799
Encoder Loss:  0.13200366  || Decoder Loss:  0.49501583 Validation Decoder Loss:  1.0372627
Encoder Loss:  0.12968673  || Decoder Loss:  0.4870206 Validation Decoder Loss:  0.9248723
Encoder Loss:  0.13376889  || Decoder Loss:  0.47654784 Validation Decoder Loss:  0.7067123
Encoder Loss:  0.13916764  || Decoder Loss:  0.5027572 Validation Decoder Loss:  0.9580176
Encoder Loss:  0.13022074  || Decoder Loss:  0.48880628 Validation Decoder Loss:  0.99277395
Encoder Loss:  0.13224903  || Decoder Loss:  0.49647027 Validation Decoder Loss:  0.9842211
Encoder Loss:  0.13279657  || Decoder Loss:  0.49310502 Validation Decoder Loss:  0.97279286
Model: siamese_net_lr_0.043858662563794955 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.97279286
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 80, 9, 20, 1)      86        
_________________________________________________________________
reshape_29 (Reshape)         (None, 720, 20, 1)        0         
=================================================================
Total params: 86
Trainable params: 86
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 720, 20, 1)        1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 3245, 20, 1)       2527      
=================================================================
Total params: 2,527
Trainable params: 2,527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.82174706  || Decoder Loss:  0.92152184 Validation Decoder Loss:  1.6322633
Encoder Loss:  0.8354146  || Decoder Loss:  0.9371671 Validation Decoder Loss:  1.6257818
Encoder Loss:  0.82837385  || Decoder Loss:  0.928553 Validation Decoder Loss:  1.6132636
Encoder Loss:  0.815894  || Decoder Loss:  0.9132321 Validation Decoder Loss:  1.5889004
Encoder Loss:  0.79323465  || Decoder Loss:  0.88534814 Validation Decoder Loss:  1.5408342
Encoder Loss:  0.7502502  || Decoder Loss:  0.8324849 Validation Decoder Loss:  1.4423149
Encoder Loss:  0.66025496  || Decoder Loss:  0.7236529 Validation Decoder Loss:  1.217459
Encoder Loss:  0.4087112  || Decoder Loss:  0.4702073 Validation Decoder Loss:  0.8732628
Encoder Loss:  0.35394046  || Decoder Loss:  0.41962162 Validation Decoder Loss:  0.83604825
Encoder Loss:  0.3423969  || Decoder Loss:  0.40619662 Validation Decoder Loss:  0.7816866
Encoder Loss:  0.32025623  || Decoder Loss:  0.3792522 Validation Decoder Loss:  0.7358937
Encoder Loss:  0.2904692  || Decoder Loss:  0.3425193 Validation Decoder Loss:  0.7017529
Encoder Loss:  0.18808798  || Decoder Loss:  0.21438278 Validation Decoder Loss:  0.4797887
Encoder Loss:  0.056435138  || Decoder Loss:  0.049193762 Validation Decoder Loss:  0.34145683
Encoder Loss:  0.0418234  || Decoder Loss:  0.031366806 Validation Decoder Loss:  0.41138563
Encoder Loss:  0.036875445  || Decoder Loss:  0.026492799 Validation Decoder Loss:  0.3669964
Encoder Loss:  0.036426585  || Decoder Loss:  0.026301883 Validation Decoder Loss:  0.3574615
Encoder Loss:  0.03426269  || Decoder Loss:  0.026895508 Validation Decoder Loss:  0.3610798
Encoder Loss:  0.0359264  || Decoder Loss:  0.028774004 Validation Decoder Loss:  0.36999154
Encoder Loss:  0.051992774  || Decoder Loss:  0.04684576 Validation Decoder Loss:  0.4387104
Encoder Loss:  0.06794077  || Decoder Loss:  0.06615687 Validation Decoder Loss:  0.36643603
Encoder Loss:  0.042348117  || Decoder Loss:  0.03680799 Validation Decoder Loss:  0.37247378
Encoder Loss:  0.04015051  || Decoder Loss:  0.031201834 Validation Decoder Loss:  0.35590592
Encoder Loss:  0.041821685  || Decoder Loss:  0.03404866 Validation Decoder Loss:  0.37010157
Encoder Loss:  0.03872549  || Decoder Loss:  0.033157848 Validation Decoder Loss:  0.36365843
Encoder Loss:  0.03808598  || Decoder Loss:  0.031786278 Validation Decoder Loss:  0.36439282
Encoder Loss:  0.037849132  || Decoder Loss:  0.031380605 Validation Decoder Loss:  0.37729913
Encoder Loss:  0.039206773  || Decoder Loss:  0.03364843 Validation Decoder Loss:  0.35316366
Encoder Loss:  0.03710183  || Decoder Loss:  0.030410852 Validation Decoder Loss:  0.35256937
Encoder Loss:  0.03949561  || Decoder Loss:  0.03406347 Validation Decoder Loss:  0.3604385
Encoder Loss:  0.040458053  || Decoder Loss:  0.035038512 Validation Decoder Loss:  0.38023156
Encoder Loss:  0.0413951  || Decoder Loss:  0.03468926 Validation Decoder Loss:  0.36285925
Encoder Loss:  0.04076971  || Decoder Loss:  0.03324397 Validation Decoder Loss:  0.40234616
Encoder Loss:  0.041586094  || Decoder Loss:  0.037105836 Validation Decoder Loss:  0.36726514
Encoder Loss:  0.036229964  || Decoder Loss:  0.030841297 Validation Decoder Loss:  0.3551062
Encoder Loss:  0.037942484  || Decoder Loss:  0.032275118 Validation Decoder Loss:  0.3860788
Encoder Loss:  0.04371885  || Decoder Loss:  0.038595714 Validation Decoder Loss:  0.40103498
Encoder Loss:  0.03901903  || Decoder Loss:  0.032875672 Validation Decoder Loss:  0.35751718
Encoder Loss:  0.0371034  || Decoder Loss:  0.031028867 Validation Decoder Loss:  0.37703156
Encoder Loss:  0.044903293  || Decoder Loss:  0.03657106 Validation Decoder Loss:  0.36586085
Model: siamese_net_lr_0.036381524334762105 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36586082
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 70, 11, 20, 1)     50        
_________________________________________________________________
reshape_30 (Reshape)         (None, 770, 20, 1)        0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 770, 20, 1)        2477      
=================================================================
Total params: 2,477
Trainable params: 2,477
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 3245, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50407624  || Decoder Loss:  0.5046014 Validation Decoder Loss:  0.41797376
Encoder Loss:  0.042926125  || Decoder Loss:  0.042729802 Validation Decoder Loss:  0.34748542
Encoder Loss:  0.054317802  || Decoder Loss:  0.05401668 Validation Decoder Loss:  0.35777736
Encoder Loss:  0.044219404  || Decoder Loss:  0.043898333 Validation Decoder Loss:  0.34829485
Encoder Loss:  0.034449708  || Decoder Loss:  0.03417672 Validation Decoder Loss:  0.34761465
Encoder Loss:  0.03370567  || Decoder Loss:  0.03355732 Validation Decoder Loss:  0.34789628
Encoder Loss:  0.03354524  || Decoder Loss:  0.033430625 Validation Decoder Loss:  0.34784633
Encoder Loss:  0.033546463  || Decoder Loss:  0.033373393 Validation Decoder Loss:  0.3477613
Encoder Loss:  0.03345101  || Decoder Loss:  0.03330288 Validation Decoder Loss:  0.34818172
Encoder Loss:  0.033370864  || Decoder Loss:  0.033248387 Validation Decoder Loss:  0.34790474
Encoder Loss:  0.033368755  || Decoder Loss:  0.033202957 Validation Decoder Loss:  0.34821218
Encoder Loss:  0.03325551  || Decoder Loss:  0.03314958 Validation Decoder Loss:  0.348076
Encoder Loss:  0.033234127  || Decoder Loss:  0.033117916 Validation Decoder Loss:  0.34809563
Encoder Loss:  0.033229604  || Decoder Loss:  0.03308685 Validation Decoder Loss:  0.34806252
Encoder Loss:  0.033151116  || Decoder Loss:  0.0330451 Validation Decoder Loss:  0.34804085
Encoder Loss:  0.033117674  || Decoder Loss:  0.03302183 Validation Decoder Loss:  0.34818518
Encoder Loss:  0.033085067  || Decoder Loss:  0.032987293 Validation Decoder Loss:  0.34820515
Encoder Loss:  0.033161663  || Decoder Loss:  0.032975577 Validation Decoder Loss:  0.34913006
Encoder Loss:  0.033071183  || Decoder Loss:  0.032939862 Validation Decoder Loss:  0.34813428
Encoder Loss:  0.033032734  || Decoder Loss:  0.032908466 Validation Decoder Loss:  0.34777725
Encoder Loss:  0.03298161  || Decoder Loss:  0.032869264 Validation Decoder Loss:  0.3479865
Encoder Loss:  0.032955173  || Decoder Loss:  0.032850273 Validation Decoder Loss:  0.34766173
Encoder Loss:  0.03293941  || Decoder Loss:  0.032835796 Validation Decoder Loss:  0.3484131
Encoder Loss:  0.0329038  || Decoder Loss:  0.032812275 Validation Decoder Loss:  0.34867716
Encoder Loss:  0.03290886  || Decoder Loss:  0.03280141 Validation Decoder Loss:  0.3484274
Encoder Loss:  0.03289229  || Decoder Loss:  0.032786086 Validation Decoder Loss:  0.34843147
Encoder Loss:  0.03290462  || Decoder Loss:  0.032779083 Validation Decoder Loss:  0.3484741
Encoder Loss:  0.032857124  || Decoder Loss:  0.0327369 Validation Decoder Loss:  0.34846473
Encoder Loss:  0.032894112  || Decoder Loss:  0.032749027 Validation Decoder Loss:  0.34869924
Encoder Loss:  0.03294765  || Decoder Loss:  0.03276138 Validation Decoder Loss:  0.3478053
Encoder Loss:  0.032929435  || Decoder Loss:  0.032747578 Validation Decoder Loss:  0.3479341
Encoder Loss:  0.032802075  || Decoder Loss:  0.03268287 Validation Decoder Loss:  0.34981796
Encoder Loss:  0.032858867  || Decoder Loss:  0.032696854 Validation Decoder Loss:  0.34849548
Encoder Loss:  0.0327884  || Decoder Loss:  0.032681827 Validation Decoder Loss:  0.34862113
Encoder Loss:  0.032756973  || Decoder Loss:  0.032657865 Validation Decoder Loss:  0.34824526
Encoder Loss:  0.03282652  || Decoder Loss:  0.032672122 Validation Decoder Loss:  0.34830227
Encoder Loss:  0.032745257  || Decoder Loss:  0.032628022 Validation Decoder Loss:  0.3504117
Encoder Loss:  0.0327975  || Decoder Loss:  0.032667395 Validation Decoder Loss:  0.34804836
Encoder Loss:  0.032766595  || Decoder Loss:  0.03263256 Validation Decoder Loss:  0.34979576
Encoder Loss:  0.032825597  || Decoder Loss:  0.0326606 Validation Decoder Loss:  0.3487087
Model: siamese_net_lr_0.010698719964636345 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3487087
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 164, 5, 20, 1)     102       
_________________________________________________________________
reshape_31 (Reshape)         (None, 820, 20, 1)        0         
=================================================================
Total params: 102
Trainable params: 102
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 820, 20, 1)        2427      
=================================================================
Total params: 2,427
Trainable params: 2,427
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 3245, 20, 1)       2427      
=================================================================
Total params: 2,427
Trainable params: 2,427
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8634838  || Decoder Loss:  0.9255997 Validation Decoder Loss:  1.6346939
Encoder Loss:  0.8746311  || Decoder Loss:  0.93816996 Validation Decoder Loss:  1.6342242
Encoder Loss:  0.8731954  || Decoder Loss:  0.9369531 Validation Decoder Loss:  1.6336241
Encoder Loss:  0.8710975  || Decoder Loss:  0.935333 Validation Decoder Loss:  1.632951
Encoder Loss:  0.86797935  || Decoder Loss:  0.93320984 Validation Decoder Loss:  1.632226
Encoder Loss:  0.8627143  || Decoder Loss:  0.93024087 Validation Decoder Loss:  1.6313924
Encoder Loss:  0.82897764  || Decoder Loss:  0.90582514 Validation Decoder Loss:  0.62564325
Encoder Loss:  0.38273427  || Decoder Loss:  0.42194816 Validation Decoder Loss:  0.62951285
Encoder Loss:  0.45187414  || Decoder Loss:  0.50554407 Validation Decoder Loss:  0.73699284
Encoder Loss:  0.44616282  || Decoder Loss:  0.49947762 Validation Decoder Loss:  0.7535942
Encoder Loss:  0.43984035  || Decoder Loss:  0.49255246 Validation Decoder Loss:  0.71123344
Encoder Loss:  0.43999034  || Decoder Loss:  0.49246815 Validation Decoder Loss:  0.7669008
Encoder Loss:  0.4325022  || Decoder Loss:  0.48433927 Validation Decoder Loss:  0.7461099
Encoder Loss:  0.43773362  || Decoder Loss:  0.4902697 Validation Decoder Loss:  0.76756096
Encoder Loss:  0.4308232  || Decoder Loss:  0.48256642 Validation Decoder Loss:  0.7669649
Encoder Loss:  0.4335867  || Decoder Loss:  0.48545942 Validation Decoder Loss:  0.823612
Encoder Loss:  0.43115315  || Decoder Loss:  0.483035 Validation Decoder Loss:  0.812538
Encoder Loss:  0.4243516  || Decoder Loss:  0.4753918 Validation Decoder Loss:  0.8455596
Encoder Loss:  0.42420882  || Decoder Loss:  0.47576082 Validation Decoder Loss:  0.8358727
Encoder Loss:  0.4259896  || Decoder Loss:  0.47805908 Validation Decoder Loss:  0.8941729
Encoder Loss:  0.4252938  || Decoder Loss:  0.4778081 Validation Decoder Loss:  1.1222005
Encoder Loss:  0.4429702  || Decoder Loss:  0.49870396 Validation Decoder Loss:  0.9731202
Encoder Loss:  0.43362677  || Decoder Loss:  0.4881507 Validation Decoder Loss:  1.0028629
Encoder Loss:  0.43378758  || Decoder Loss:  0.48815522 Validation Decoder Loss:  1.0105793
Encoder Loss:  0.43588117  || Decoder Loss:  0.49129146 Validation Decoder Loss:  1.113657
Encoder Loss:  0.44891062  || Decoder Loss:  0.5063571 Validation Decoder Loss:  1.1161964
Encoder Loss:  0.43860158  || Decoder Loss:  0.49459648 Validation Decoder Loss:  1.1321814
Encoder Loss:  0.44478235  || Decoder Loss:  0.5005303 Validation Decoder Loss:  1.1422675
Encoder Loss:  0.4329214  || Decoder Loss:  0.48782936 Validation Decoder Loss:  1.340708
Encoder Loss:  0.4560942  || Decoder Loss:  0.5144492 Validation Decoder Loss:  1.1140392
Encoder Loss:  0.43717164  || Decoder Loss:  0.49334294 Validation Decoder Loss:  1.2329519
Encoder Loss:  0.43583584  || Decoder Loss:  0.49168694 Validation Decoder Loss:  1.1936212
Encoder Loss:  0.43029007  || Decoder Loss:  0.48406625 Validation Decoder Loss:  1.0003228
Encoder Loss:  0.43180966  || Decoder Loss:  0.4868156 Validation Decoder Loss:  1.1580037
Encoder Loss:  0.4367462  || Decoder Loss:  0.49285498 Validation Decoder Loss:  1.1322405
Encoder Loss:  0.43480203  || Decoder Loss:  0.49058837 Validation Decoder Loss:  1.1283461
Encoder Loss:  0.43741715  || Decoder Loss:  0.49374253 Validation Decoder Loss:  1.1351054
Encoder Loss:  0.43499887  || Decoder Loss:  0.4914739 Validation Decoder Loss:  1.1059946
Encoder Loss:  0.43372062  || Decoder Loss:  0.48865113 Validation Decoder Loss:  1.1106386
Encoder Loss:  0.43416524  || Decoder Loss:  0.48996717 Validation Decoder Loss:  1.1270392
Model: siamese_net_lr_0.0975495587663433 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1270392
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 194, 5, 20, 1)     69        
_________________________________________________________________
reshape_32 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 69
Trainable params: 69
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 970, 20, 1)        2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 3245, 20, 1)       2277      
=================================================================
Total params: 2,277
Trainable params: 2,277
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.76881427  || Decoder Loss:  0.9081585 Validation Decoder Loss:  1.6329687
Encoder Loss:  0.785007  || Decoder Loss:  0.9282668 Validation Decoder Loss:  1.6290964
Encoder Loss:  0.78213227  || Decoder Loss:  0.9242351 Validation Decoder Loss:  1.6230423
Encoder Loss:  0.7780505  || Decoder Loss:  0.91850555 Validation Decoder Loss:  1.6137513
Encoder Loss:  0.77233976  || Decoder Loss:  0.9104843 Validation Decoder Loss:  1.5997183
Encoder Loss:  0.764333  || Decoder Loss:  0.89922714 Validation Decoder Loss:  1.5786138
Encoder Loss:  0.75290734  || Decoder Loss:  0.8831457 Validation Decoder Loss:  1.5466051
Encoder Loss:  0.7360376  || Decoder Loss:  0.85937047 Validation Decoder Loss:  1.4968033
Encoder Loss:  0.709671  || Decoder Loss:  0.8221515 Validation Decoder Loss:  1.415237
Encoder Loss:  0.6645268  || Decoder Loss:  0.75830543 Validation Decoder Loss:  1.2694011
Encoder Loss:  0.57694584  || Decoder Loss:  0.6341933 Validation Decoder Loss:  0.98416114
Encoder Loss:  0.41053393  || Decoder Loss:  0.39815453 Validation Decoder Loss:  0.57468665
Encoder Loss:  0.24915929  || Decoder Loss:  0.17059094 Validation Decoder Loss:  0.40371415
Encoder Loss:  0.18933496  || Decoder Loss:  0.09712213 Validation Decoder Loss:  0.46466762
Encoder Loss:  0.3723646  || Decoder Loss:  0.46583393 Validation Decoder Loss:  1.4333801
Encoder Loss:  0.3844754  || Decoder Loss:  0.49876195 Validation Decoder Loss:  1.2496008
Encoder Loss:  0.3540528  || Decoder Loss:  0.46059036 Validation Decoder Loss:  1.3597444
Encoder Loss:  0.35874993  || Decoder Loss:  0.4659997 Validation Decoder Loss:  1.2042718
Encoder Loss:  0.34727582  || Decoder Loss:  0.45221856 Validation Decoder Loss:  1.302794
Encoder Loss:  0.3456099  || Decoder Loss:  0.4487442 Validation Decoder Loss:  1.1860652
Encoder Loss:  0.33862174  || Decoder Loss:  0.44137082 Validation Decoder Loss:  1.2499838
Encoder Loss:  0.34256577  || Decoder Loss:  0.44681156 Validation Decoder Loss:  1.1981494
Encoder Loss:  0.3355744  || Decoder Loss:  0.43826118 Validation Decoder Loss:  1.2296035
Encoder Loss:  0.33962935  || Decoder Loss:  0.44449136 Validation Decoder Loss:  1.1770079
Encoder Loss:  0.33701983  || Decoder Loss:  0.4427784 Validation Decoder Loss:  1.1814027
Encoder Loss:  0.3297501  || Decoder Loss:  0.43333107 Validation Decoder Loss:  1.1694038
Encoder Loss:  0.33635753  || Decoder Loss:  0.44374606 Validation Decoder Loss:  1.1243583
Encoder Loss:  0.32908413  || Decoder Loss:  0.43516335 Validation Decoder Loss:  1.1852221
Encoder Loss:  0.3308165  || Decoder Loss:  0.4381984 Validation Decoder Loss:  1.1057576
Encoder Loss:  0.32405877  || Decoder Loss:  0.43033513 Validation Decoder Loss:  1.1792789
Encoder Loss:  0.32810065  || Decoder Loss:  0.43642166 Validation Decoder Loss:  1.0784056
Encoder Loss:  0.3209427  || Decoder Loss:  0.4275849 Validation Decoder Loss:  1.1973526
Encoder Loss:  0.3214863  || Decoder Loss:  0.4290572 Validation Decoder Loss:  1.1736336
Encoder Loss:  0.32168773  || Decoder Loss:  0.43045804 Validation Decoder Loss:  1.162012
Encoder Loss:  0.31481332  || Decoder Loss:  0.4209471 Validation Decoder Loss:  1.275312
Encoder Loss:  0.3178744  || Decoder Loss:  0.426256 Validation Decoder Loss:  1.1310761
Encoder Loss:  0.30554798  || Decoder Loss:  0.4093275 Validation Decoder Loss:  1.0964253
Encoder Loss:  0.29546726  || Decoder Loss:  0.3950975 Validation Decoder Loss:  1.207793
Encoder Loss:  0.24127434  || Decoder Loss:  0.31883976 Validation Decoder Loss:  0.95045644
Encoder Loss:  0.3043107  || Decoder Loss:  0.40921652 Validation Decoder Loss:  0.84750605
Model: siamese_net_lr_0.06787733337207122 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.84750605
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 322, 10, 20, 1)    267       
_________________________________________________________________
reshape_33 (Reshape)         (None, 3220, 20, 1)       0         
=================================================================
Total params: 267
Trainable params: 267
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 3220, 20, 1)       27        
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 3245, 20, 1)       27        
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13656586  || Decoder Loss:  0.3739747 Validation Decoder Loss:  0.87750375
Encoder Loss:  0.09438301  || Decoder Loss:  0.36808228 Validation Decoder Loss:  0.86911964
Encoder Loss:  0.061130628  || Decoder Loss:  0.35252118 Validation Decoder Loss:  0.8030064
Encoder Loss:  0.06121308  || Decoder Loss:  0.30029568 Validation Decoder Loss:  0.727159
Encoder Loss:  0.061161894  || Decoder Loss:  0.26229954 Validation Decoder Loss:  0.671243
Encoder Loss:  0.060805794  || Decoder Loss:  0.23245852 Validation Decoder Loss:  0.63077056
Encoder Loss:  0.060934965  || Decoder Loss:  0.20962471 Validation Decoder Loss:  0.598909
Encoder Loss:  0.060853776  || Decoder Loss:  0.19165243 Validation Decoder Loss:  0.5740085
Encoder Loss:  0.06080231  || Decoder Loss:  0.1772369 Validation Decoder Loss:  0.5539328
Encoder Loss:  0.060723707  || Decoder Loss:  0.16541094 Validation Decoder Loss:  0.5374708
Encoder Loss:  0.060646445  || Decoder Loss:  0.15554886 Validation Decoder Loss:  0.5237312
Encoder Loss:  0.06056178  || Decoder Loss:  0.14719881 Validation Decoder Loss:  0.5120834
Encoder Loss:  0.060461637  || Decoder Loss:  0.14004816 Validation Decoder Loss:  0.5021016
Encoder Loss:  0.0603918  || Decoder Loss:  0.13384493 Validation Decoder Loss:  0.49340147
Encoder Loss:  0.060280185  || Decoder Loss:  0.12841202 Validation Decoder Loss:  0.48578495
Encoder Loss:  0.060163092  || Decoder Loss:  0.123613164 Validation Decoder Loss:  0.47909588
Encoder Loss:  0.06009541  || Decoder Loss:  0.11933833 Validation Decoder Loss:  0.47311747
Encoder Loss:  0.060015608  || Decoder Loss:  0.11551586 Validation Decoder Loss:  0.46768686
Encoder Loss:  0.05987172  || Decoder Loss:  0.11204345 Validation Decoder Loss:  0.46287143
Encoder Loss:  0.059799828  || Decoder Loss:  0.10892186 Validation Decoder Loss:  0.45841938
Encoder Loss:  0.05964665  || Decoder Loss:  0.10604583 Validation Decoder Loss:  0.45440614
Encoder Loss:  0.05954176  || Decoder Loss:  0.10342665 Validation Decoder Loss:  0.4507146
Encoder Loss:  0.05943513  || Decoder Loss:  0.10101209 Validation Decoder Loss:  0.44730777
Encoder Loss:  0.059321098  || Decoder Loss:  0.09878085 Validation Decoder Loss:  0.44416004
Encoder Loss:  0.059204873  || Decoder Loss:  0.09671387 Validation Decoder Loss:  0.44124225
Encoder Loss:  0.05907813  || Decoder Loss:  0.094795465 Validation Decoder Loss:  0.43853626
Encoder Loss:  0.05896347  || Decoder Loss:  0.09300651 Validation Decoder Loss:  0.4360049
Encoder Loss:  0.058850072  || Decoder Loss:  0.09133039 Validation Decoder Loss:  0.4336298
Encoder Loss:  0.058720775  || Decoder Loss:  0.089760944 Validation Decoder Loss:  0.43140635
Encoder Loss:  0.05859019  || Decoder Loss:  0.08829004 Validation Decoder Loss:  0.4293112
Encoder Loss:  0.058460604  || Decoder Loss:  0.0869024 Validation Decoder Loss:  0.42734015
Encoder Loss:  0.058320694  || Decoder Loss:  0.08559223 Validation Decoder Loss:  0.42546836
Encoder Loss:  0.058161117  || Decoder Loss:  0.08434997 Validation Decoder Loss:  0.42371216
Encoder Loss:  0.058033675  || Decoder Loss:  0.0831754 Validation Decoder Loss:  0.4220379
Encoder Loss:  0.057874516  || Decoder Loss:  0.08206113 Validation Decoder Loss:  0.4204629
Encoder Loss:  0.057769947  || Decoder Loss:  0.080998614 Validation Decoder Loss:  0.41893837
Encoder Loss:  0.057630286  || Decoder Loss:  0.07998705 Validation Decoder Loss:  0.41750953
Encoder Loss:  0.05751341  || Decoder Loss:  0.079031594 Validation Decoder Loss:  0.4161224
Encoder Loss:  0.05732874  || Decoder Loss:  0.07811017 Validation Decoder Loss:  0.41481736
Encoder Loss:  0.05719268  || Decoder Loss:  0.07722973 Validation Decoder Loss:  0.41354936
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.41354936
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 65, 38, 20, 1)     69        
_________________________________________________________________
reshape_34 (Reshape)         (None, 2470, 20, 1)       0         
=================================================================
Total params: 69
Trainable params: 69
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 2470, 20, 1)       777       
=================================================================
Total params: 777
Trainable params: 777
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 3245, 20, 1)       777       
=================================================================
Total params: 777
Trainable params: 777
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.62388575  || Decoder Loss:  0.92432976 Validation Decoder Loss:  1.6378365
Encoder Loss:  0.6356583  || Decoder Loss:  0.94226176 Validation Decoder Loss:  1.6378827
Encoder Loss:  0.6355988  || Decoder Loss:  0.9421866 Validation Decoder Loss:  1.6379094
Encoder Loss:  0.63552153  || Decoder Loss:  0.9420849 Validation Decoder Loss:  1.6379435
Encoder Loss:  0.63542855  || Decoder Loss:  0.9419629 Validation Decoder Loss:  1.6379898
Encoder Loss:  0.6353195  || Decoder Loss:  0.9418217 Validation Decoder Loss:  1.6380513
Encoder Loss:  0.6351937  || Decoder Loss:  0.94166046 Validation Decoder Loss:  1.6381314
Encoder Loss:  0.6350496  || Decoder Loss:  0.94147795 Validation Decoder Loss:  1.6382345
Encoder Loss:  0.6348851  || Decoder Loss:  0.94127244 Validation Decoder Loss:  1.6383655
Encoder Loss:  0.6346973  || Decoder Loss:  0.94104135 Validation Decoder Loss:  1.6385306
Encoder Loss:  0.63448244  || Decoder Loss:  0.94078094 Validation Decoder Loss:  1.6387371
Encoder Loss:  0.6342352  || Decoder Loss:  0.94048715 Validation Decoder Loss:  1.6389945
Encoder Loss:  0.63394827  || Decoder Loss:  0.9401536 Validation Decoder Loss:  1.6393142
Encoder Loss:  0.6336116  || Decoder Loss:  0.9397721 Validation Decoder Loss:  1.6397111
Encoder Loss:  0.63321066  || Decoder Loss:  0.93933123 Validation Decoder Loss:  1.6402048
Encoder Loss:  0.632724  || Decoder Loss:  0.9388142 Validation Decoder Loss:  1.640821
Encoder Loss:  0.63211894  || Decoder Loss:  0.9381971 Validation Decoder Loss:  1.6415939
Encoder Loss:  0.6313436  || Decoder Loss:  0.9374419 Validation Decoder Loss:  1.6425724
Encoder Loss:  0.6303086  || Decoder Loss:  0.93648607 Validation Decoder Loss:  1.6438253
Encoder Loss:  0.62884694  || Decoder Loss:  0.93521726 Validation Decoder Loss:  1.6454529
Encoder Loss:  0.62660015  || Decoder Loss:  0.93340755 Validation Decoder Loss:  1.6475976
Encoder Loss:  0.62259626  || Decoder Loss:  0.9304943 Validation Decoder Loss:  1.6503763
Encoder Loss:  0.61251026  || Decoder Loss:  0.9244088 Validation Decoder Loss:  1.6520317
Encoder Loss:  0.42383084  || Decoder Loss:  0.63071805 Validation Decoder Loss:  0.4200188
Encoder Loss:  0.25772378  || Decoder Loss:  0.5064574 Validation Decoder Loss:  0.80563927
Encoder Loss:  0.23433277  || Decoder Loss:  0.4879853 Validation Decoder Loss:  0.6474204
Encoder Loss:  0.2253353  || Decoder Loss:  0.4679252 Validation Decoder Loss:  0.7957786
Encoder Loss:  0.20600188  || Decoder Loss:  0.42483538 Validation Decoder Loss:  0.9312202
Encoder Loss:  0.1679885  || Decoder Loss:  0.3257814 Validation Decoder Loss:  0.9137502
Encoder Loss:  0.22629882  || Decoder Loss:  0.4804132 Validation Decoder Loss:  0.9318432
Encoder Loss:  0.2245247  || Decoder Loss:  0.48534358 Validation Decoder Loss:  0.92051744
Encoder Loss:  0.21956451  || Decoder Loss:  0.4678147 Validation Decoder Loss:  0.94348
Encoder Loss:  0.1920238  || Decoder Loss:  0.39464736 Validation Decoder Loss:  0.8515738
Encoder Loss:  0.21496648  || Decoder Loss:  0.45528793 Validation Decoder Loss:  0.9927287
Encoder Loss:  0.22386408  || Decoder Loss:  0.49008518 Validation Decoder Loss:  0.9986356
Encoder Loss:  0.225766  || Decoder Loss:  0.48742354 Validation Decoder Loss:  0.99206567
Encoder Loss:  0.22011904  || Decoder Loss:  0.48121607 Validation Decoder Loss:  0.99396515
Encoder Loss:  0.1986545  || Decoder Loss:  0.4267751 Validation Decoder Loss:  1.0418694
Encoder Loss:  0.17362675  || Decoder Loss:  0.35020408 Validation Decoder Loss:  0.9616797
Encoder Loss:  0.21860035  || Decoder Loss:  0.48286563 Validation Decoder Loss:  0.9681218
Model: siamese_net_lr_0.0757243359552565 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9681218
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 267, 10, 20, 1)    847       
_________________________________________________________________
reshape_35 (Reshape)         (None, 2670, 20, 1)       0         
=================================================================
Total params: 847
Trainable params: 847
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 2670, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 3245, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.104402065  || Decoder Loss:  0.088590756 Validation Decoder Loss:  0.32453233
Encoder Loss:  0.06884309  || Decoder Loss:  0.04337409 Validation Decoder Loss:  0.33050025
Encoder Loss:  0.054081574  || Decoder Loss:  0.038010847 Validation Decoder Loss:  0.3467564
Encoder Loss:  0.049857527  || Decoder Loss:  0.037054785 Validation Decoder Loss:  0.34329367
Encoder Loss:  0.047383614  || Decoder Loss:  0.036441695 Validation Decoder Loss:  0.34218782
Encoder Loss:  0.047497414  || Decoder Loss:  0.036003597 Validation Decoder Loss:  0.34299886
Encoder Loss:  0.05017318  || Decoder Loss:  0.03571747 Validation Decoder Loss:  0.34355494
Encoder Loss:  0.051240876  || Decoder Loss:  0.035458073 Validation Decoder Loss:  0.34374768
Encoder Loss:  0.0460425  || Decoder Loss:  0.03519782 Validation Decoder Loss:  0.34425065
Encoder Loss:  0.052447863  || Decoder Loss:  0.034998022 Validation Decoder Loss:  0.34438965
Encoder Loss:  0.05260344  || Decoder Loss:  0.034798004 Validation Decoder Loss:  0.34404722
Encoder Loss:  0.044889588  || Decoder Loss:  0.03455977 Validation Decoder Loss:  0.34465063
Encoder Loss:  0.044349205  || Decoder Loss:  0.034408852 Validation Decoder Loss:  0.34451342
Encoder Loss:  0.046917047  || Decoder Loss:  0.034266036 Validation Decoder Loss:  0.34427518
Encoder Loss:  0.043859668  || Decoder Loss:  0.034145232 Validation Decoder Loss:  0.34374958
Encoder Loss:  0.04481173  || Decoder Loss:  0.034025326 Validation Decoder Loss:  0.34388775
Encoder Loss:  0.046176866  || Decoder Loss:  0.03392303 Validation Decoder Loss:  0.3437601
Encoder Loss:  0.044856586  || Decoder Loss:  0.033835974 Validation Decoder Loss:  0.34513992
Encoder Loss:  0.043736607  || Decoder Loss:  0.033764854 Validation Decoder Loss:  0.3443544
Encoder Loss:  0.04551535  || Decoder Loss:  0.03369096 Validation Decoder Loss:  0.34509826
Encoder Loss:  0.043501854  || Decoder Loss:  0.033645004 Validation Decoder Loss:  0.34590536
Encoder Loss:  0.04797988  || Decoder Loss:  0.033610374 Validation Decoder Loss:  0.34679475
Encoder Loss:  0.04661052  || Decoder Loss:  0.03352755 Validation Decoder Loss:  0.34330222
Encoder Loss:  0.045178033  || Decoder Loss:  0.033466887 Validation Decoder Loss:  0.34459844
Encoder Loss:  0.04281369  || Decoder Loss:  0.033430856 Validation Decoder Loss:  0.3450958
Encoder Loss:  0.042648472  || Decoder Loss:  0.0333962 Validation Decoder Loss:  0.34556156
Encoder Loss:  0.043147627  || Decoder Loss:  0.03336744 Validation Decoder Loss:  0.34568796
Encoder Loss:  0.04456685  || Decoder Loss:  0.033344615 Validation Decoder Loss:  0.34539062
Encoder Loss:  0.04271145  || Decoder Loss:  0.03330498 Validation Decoder Loss:  0.34533384
Encoder Loss:  0.0433776  || Decoder Loss:  0.033274904 Validation Decoder Loss:  0.34560448
Encoder Loss:  0.042945642  || Decoder Loss:  0.03326393 Validation Decoder Loss:  0.3454606
Encoder Loss:  0.042469762  || Decoder Loss:  0.03323641 Validation Decoder Loss:  0.34539053
Encoder Loss:  0.044024378  || Decoder Loss:  0.03322171 Validation Decoder Loss:  0.3457005
Encoder Loss:  0.042754877  || Decoder Loss:  0.03317848 Validation Decoder Loss:  0.3454576
Encoder Loss:  0.04316425  || Decoder Loss:  0.033165537 Validation Decoder Loss:  0.34521478
Encoder Loss:  0.042701412  || Decoder Loss:  0.03314728 Validation Decoder Loss:  0.34529352
Encoder Loss:  0.042029418  || Decoder Loss:  0.033131722 Validation Decoder Loss:  0.34490207
Encoder Loss:  0.04252573  || Decoder Loss:  0.033119768 Validation Decoder Loss:  0.34492806
Encoder Loss:  0.042431258  || Decoder Loss:  0.033108555 Validation Decoder Loss:  0.34482583
Encoder Loss:  0.043541852  || Decoder Loss:  0.03310685 Validation Decoder Loss:  0.34462878
Model: siamese_net_lr_0.0025871784559553654 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34462878
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 524, 5, 20, 1)     210       
_________________________________________________________________
reshape_36 (Reshape)         (None, 2620, 20, 1)       0         
=================================================================
Total params: 210
Trainable params: 210
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 2620, 20, 1)       627       
=================================================================
Total params: 627
Trainable params: 627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 3245, 20, 1)       627       
=================================================================
Total params: 627
Trainable params: 627
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.80377406  || Decoder Loss:  0.9324643 Validation Decoder Loss:  1.6409853
Encoder Loss:  0.81500727  || Decoder Loss:  0.94474036 Validation Decoder Loss:  1.6408045
Encoder Loss:  0.81340647  || Decoder Loss:  0.9433989 Validation Decoder Loss:  1.6406913
Encoder Loss:  0.810383  || Decoder Loss:  0.9417498 Validation Decoder Loss:  1.6404421
Encoder Loss:  0.79651564  || Decoder Loss:  0.9383683 Validation Decoder Loss:  1.6329491
Encoder Loss:  0.38144764  || Decoder Loss:  0.4609146 Validation Decoder Loss:  0.775434
Encoder Loss:  0.33509335  || Decoder Loss:  0.428778 Validation Decoder Loss:  0.7748718
Encoder Loss:  0.3468367  || Decoder Loss:  0.44765723 Validation Decoder Loss:  1.0724956
Encoder Loss:  0.37056786  || Decoder Loss:  0.48011258 Validation Decoder Loss:  0.91640174
Encoder Loss:  0.3716258  || Decoder Loss:  0.48354325 Validation Decoder Loss:  0.6196648
Encoder Loss:  0.3787275  || Decoder Loss:  0.49197036 Validation Decoder Loss:  1.0068376
Encoder Loss:  0.38526776  || Decoder Loss:  0.5012394 Validation Decoder Loss:  0.975262
Encoder Loss:  0.38726857  || Decoder Loss:  0.5021509 Validation Decoder Loss:  1.038902
Encoder Loss:  0.3901001  || Decoder Loss:  0.5074432 Validation Decoder Loss:  0.998824
Encoder Loss:  0.3840372  || Decoder Loss:  0.5001548 Validation Decoder Loss:  1.0120728
Encoder Loss:  0.3885403  || Decoder Loss:  0.5043822 Validation Decoder Loss:  0.90347433
Encoder Loss:  0.38904777  || Decoder Loss:  0.50097066 Validation Decoder Loss:  0.8965012
Encoder Loss:  0.38218182  || Decoder Loss:  0.49633157 Validation Decoder Loss:  0.9440929
Encoder Loss:  0.38328284  || Decoder Loss:  0.49687484 Validation Decoder Loss:  0.957492
Encoder Loss:  0.37939614  || Decoder Loss:  0.49330026 Validation Decoder Loss:  0.985734
Encoder Loss:  0.38439667  || Decoder Loss:  0.50022525 Validation Decoder Loss:  0.95498157
Encoder Loss:  0.3777251  || Decoder Loss:  0.49023107 Validation Decoder Loss:  1.1227669
Encoder Loss:  0.3890192  || Decoder Loss:  0.5018415 Validation Decoder Loss:  1.1705897
Encoder Loss:  0.38700536  || Decoder Loss:  0.5026465 Validation Decoder Loss:  0.8770225
Encoder Loss:  0.37910014  || Decoder Loss:  0.48879117 Validation Decoder Loss:  0.8345148
Encoder Loss:  0.381241  || Decoder Loss:  0.49300766 Validation Decoder Loss:  1.1084826
Encoder Loss:  0.37930816  || Decoder Loss:  0.4895551 Validation Decoder Loss:  1.2164395
Encoder Loss:  0.3779955  || Decoder Loss:  0.49091834 Validation Decoder Loss:  0.9710144
Encoder Loss:  0.3670664  || Decoder Loss:  0.47797245 Validation Decoder Loss:  1.0104179
Encoder Loss:  0.36949843  || Decoder Loss:  0.4808963 Validation Decoder Loss:  1.0593871
Encoder Loss:  0.33996668  || Decoder Loss:  0.4403001 Validation Decoder Loss:  1.0223198
Encoder Loss:  0.3752163  || Decoder Loss:  0.48791945 Validation Decoder Loss:  1.0030849
Encoder Loss:  0.37845665  || Decoder Loss:  0.492332 Validation Decoder Loss:  0.98090667
Encoder Loss:  0.37935483  || Decoder Loss:  0.4920596 Validation Decoder Loss:  0.9464854
Encoder Loss:  0.37574595  || Decoder Loss:  0.48724478 Validation Decoder Loss:  0.9638192
Encoder Loss:  0.3736005  || Decoder Loss:  0.48542255 Validation Decoder Loss:  1.0180032
Encoder Loss:  0.3764842  || Decoder Loss:  0.48981854 Validation Decoder Loss:  0.97078687
Encoder Loss:  0.37432635  || Decoder Loss:  0.48644057 Validation Decoder Loss:  0.9873348
Encoder Loss:  0.37347355  || Decoder Loss:  0.4857497 Validation Decoder Loss:  1.008516
Encoder Loss:  0.3732157  || Decoder Loss:  0.48556954 Validation Decoder Loss:  1.0105408
Model: siamese_net_lr_0.09592373579781982 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0105408
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 272, 10, 20, 1)    419       
_________________________________________________________________
reshape_37 (Reshape)         (None, 2720, 20, 1)       0         
=================================================================
Total params: 419
Trainable params: 419
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 2720, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 3245, 20, 1)       527       
=================================================================
Total params: 527
Trainable params: 527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.559168  || Decoder Loss:  0.929251 Validation Decoder Loss:  1.6415615
Encoder Loss:  0.5696911  || Decoder Loss:  0.94839203 Validation Decoder Loss:  1.6412402
Encoder Loss:  0.5692858  || Decoder Loss:  0.9479207 Validation Decoder Loss:  1.6407526
Encoder Loss:  0.5687326  || Decoder Loss:  0.9472859 Validation Decoder Loss:  1.6400769
Encoder Loss:  0.5679901  || Decoder Loss:  0.9464545 Validation Decoder Loss:  1.6391528
Encoder Loss:  0.56699723  || Decoder Loss:  0.9453725 Validation Decoder Loss:  1.6378851
Encoder Loss:  0.56565976  || Decoder Loss:  0.9439545 Validation Decoder Loss:  1.6361257
Encoder Loss:  0.56382966  || Decoder Loss:  0.94206667 Validation Decoder Loss:  1.6336364
Encoder Loss:  0.56126356  || Decoder Loss:  0.93948776 Validation Decoder Loss:  1.6300133
Encoder Loss:  0.55753255  || Decoder Loss:  0.9358271 Validation Decoder Loss:  1.6245086
Encoder Loss:  0.5517948  || Decoder Loss:  0.9303161 Validation Decoder Loss:  1.6155386
Encoder Loss:  0.5420948  || Decoder Loss:  0.92115015 Validation Decoder Loss:  1.5989282
Encoder Loss:  0.52233386  || Decoder Loss:  0.90257806 Validation Decoder Loss:  1.5580912
Encoder Loss:  0.4551839  || Decoder Loss:  0.83630896 Validation Decoder Loss:  1.2918398
Encoder Loss:  0.20712493  || Decoder Loss:  0.5165835 Validation Decoder Loss:  0.9545738
Encoder Loss:  0.1740013  || Decoder Loss:  0.5040812 Validation Decoder Loss:  0.9157293
Encoder Loss:  0.17313635  || Decoder Loss:  0.501929 Validation Decoder Loss:  0.91686416
Encoder Loss:  0.17175797  || Decoder Loss:  0.5010296 Validation Decoder Loss:  0.9187689
Encoder Loss:  0.16994435  || Decoder Loss:  0.5015896 Validation Decoder Loss:  0.9345712
Encoder Loss:  0.1677857  || Decoder Loss:  0.5015469 Validation Decoder Loss:  0.9167271
Encoder Loss:  0.16655436  || Decoder Loss:  0.4987695 Validation Decoder Loss:  0.91988206
Encoder Loss:  0.16491544  || Decoder Loss:  0.49615642 Validation Decoder Loss:  0.92947406
Encoder Loss:  0.16308068  || Decoder Loss:  0.49603778 Validation Decoder Loss:  0.92496145
Encoder Loss:  0.16194214  || Decoder Loss:  0.49442577 Validation Decoder Loss:  0.9039545
Encoder Loss:  0.16197887  || Decoder Loss:  0.49210986 Validation Decoder Loss:  0.9131241
Encoder Loss:  0.16188085  || Decoder Loss:  0.49293637 Validation Decoder Loss:  0.91762036
Encoder Loss:  0.1611492  || Decoder Loss:  0.49079555 Validation Decoder Loss:  0.9053715
Encoder Loss:  0.16460991  || Decoder Loss:  0.49249333 Validation Decoder Loss:  0.8801782
Encoder Loss:  0.15875652  || Decoder Loss:  0.48410693 Validation Decoder Loss:  0.83427227
Encoder Loss:  0.15021694  || Decoder Loss:  0.44614246 Validation Decoder Loss:  1.0680654
Encoder Loss:  0.14404787  || Decoder Loss:  0.4089632 Validation Decoder Loss:  1.0074114
Encoder Loss:  0.16882406  || Decoder Loss:  0.48784068 Validation Decoder Loss:  1.022975
Encoder Loss:  0.15800197  || Decoder Loss:  0.48043716 Validation Decoder Loss:  1.0753788
Encoder Loss:  0.14111589  || Decoder Loss:  0.40994775 Validation Decoder Loss:  1.0897284
Encoder Loss:  0.14633125  || Decoder Loss:  0.4343773 Validation Decoder Loss:  0.8558165
Encoder Loss:  0.14146462  || Decoder Loss:  0.40410155 Validation Decoder Loss:  0.84926355
Encoder Loss:  0.163395  || Decoder Loss:  0.49084008 Validation Decoder Loss:  0.8728219
Encoder Loss:  0.1620768  || Decoder Loss:  0.49227643 Validation Decoder Loss:  0.8934946
Encoder Loss:  0.16332485  || Decoder Loss:  0.49183407 Validation Decoder Loss:  0.8635925
Encoder Loss:  0.16035217  || Decoder Loss:  0.49123794 Validation Decoder Loss:  0.85376716
Model: siamese_net_lr_0.07916423644857958 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.85376716
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 127, 10, 20, 1)    385       
_________________________________________________________________
reshape_38 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 1270, 20, 1)       708       
=================================================================
Total params: 708
Trainable params: 708
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 3245, 20, 1)       708       
=================================================================
Total params: 708
Trainable params: 708
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.46131957  || Decoder Loss:  0.9086413 Validation Decoder Loss:  1.6408626
Encoder Loss:  0.46727234  || Decoder Loss:  0.9273619 Validation Decoder Loss:  1.6401
Encoder Loss:  0.4646289  || Decoder Loss:  0.9252609 Validation Decoder Loss:  1.6388613
Encoder Loss:  0.461026  || Decoder Loss:  0.9224268 Validation Decoder Loss:  1.6369209
Encoder Loss:  0.45615345  || Decoder Loss:  0.91850924 Validation Decoder Loss:  1.633468
Encoder Loss:  0.4494256  || Decoder Loss:  0.91229117 Validation Decoder Loss:  1.6252575
Encoder Loss:  0.4394489  || Decoder Loss:  0.89876145 Validation Decoder Loss:  1.5976322
Encoder Loss:  0.42212903  || Decoder Loss:  0.8570017 Validation Decoder Loss:  1.4910798
Encoder Loss:  0.38358483  || Decoder Loss:  0.7281911 Validation Decoder Loss:  1.1903982
Encoder Loss:  0.23794283  || Decoder Loss:  0.5251083 Validation Decoder Loss:  1.0441964
Encoder Loss:  0.1500529  || Decoder Loss:  0.49583316 Validation Decoder Loss:  1.0264845
Encoder Loss:  0.13270737  || Decoder Loss:  0.49191064 Validation Decoder Loss:  1.0159137
Encoder Loss:  0.12404702  || Decoder Loss:  0.489243 Validation Decoder Loss:  1.0053618
Encoder Loss:  0.11776423  || Decoder Loss:  0.48578286 Validation Decoder Loss:  0.9810142
Encoder Loss:  0.11133831  || Decoder Loss:  0.47998637 Validation Decoder Loss:  0.9784583
Encoder Loss:  0.11022302  || Decoder Loss:  0.47820687 Validation Decoder Loss:  0.9875748
Encoder Loss:  0.11107594  || Decoder Loss:  0.47597146 Validation Decoder Loss:  0.9801152
Encoder Loss:  0.10928601  || Decoder Loss:  0.4721824 Validation Decoder Loss:  0.9795556
Encoder Loss:  0.10842341  || Decoder Loss:  0.47030094 Validation Decoder Loss:  0.9865216
Encoder Loss:  0.10825277  || Decoder Loss:  0.46900794 Validation Decoder Loss:  0.9928051
Encoder Loss:  0.10732737  || Decoder Loss:  0.46718216 Validation Decoder Loss:  1.0103513
Encoder Loss:  0.10769943  || Decoder Loss:  0.46583226 Validation Decoder Loss:  1.0138263
Encoder Loss:  0.106438465  || Decoder Loss:  0.46410164 Validation Decoder Loss:  1.0216715
Encoder Loss:  0.10557761  || Decoder Loss:  0.46211612 Validation Decoder Loss:  1.0273151
Encoder Loss:  0.10451328  || Decoder Loss:  0.4594425 Validation Decoder Loss:  1.0391569
Encoder Loss:  0.104107946  || Decoder Loss:  0.45733374 Validation Decoder Loss:  1.0451288
Encoder Loss:  0.102877654  || Decoder Loss:  0.45363754 Validation Decoder Loss:  1.037972
Encoder Loss:  0.101787955  || Decoder Loss:  0.44576293 Validation Decoder Loss:  1.0102085
Encoder Loss:  0.098680496  || Decoder Loss:  0.42097127 Validation Decoder Loss:  1.0992738
Encoder Loss:  0.09382833  || Decoder Loss:  0.3881204 Validation Decoder Loss:  0.9340966
Encoder Loss:  0.088163584  || Decoder Loss:  0.32879102 Validation Decoder Loss:  0.83510643
Encoder Loss:  0.093554094  || Decoder Loss:  0.46102738 Validation Decoder Loss:  0.8288897
Encoder Loss:  0.08376202  || Decoder Loss:  0.36466703 Validation Decoder Loss:  0.63113165
Encoder Loss:  0.07848868  || Decoder Loss:  0.30237922 Validation Decoder Loss:  0.8337271
Encoder Loss:  0.07261868  || Decoder Loss:  0.21840481 Validation Decoder Loss:  0.4335634
Encoder Loss:  0.06321689  || Decoder Loss:  0.14921564 Validation Decoder Loss:  0.40480307
Encoder Loss:  0.06934429  || Decoder Loss:  0.13535236 Validation Decoder Loss:  0.55121297
Encoder Loss:  0.062060285  || Decoder Loss:  0.114081666 Validation Decoder Loss:  0.39436647
Encoder Loss:  0.066823  || Decoder Loss:  0.085221834 Validation Decoder Loss:  0.42414755
Encoder Loss:  0.060891837  || Decoder Loss:  0.071079746 Validation Decoder Loss:  0.39194107
Model: siamese_net_lr_0.07105719638376069 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.39194104
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 132, 10, 20, 1)    13        
_________________________________________________________________
reshape_39 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 13
Trainable params: 13
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 1320, 20, 1)       608       
=================================================================
Total params: 608
Trainable params: 608
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 3245, 20, 1)       1927      
=================================================================
Total params: 1,927
Trainable params: 1,927
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.60920125  || Decoder Loss:  0.9009152 Validation Decoder Loss:  1.6405132
Encoder Loss:  0.6186156  || Decoder Loss:  0.91381675 Validation Decoder Loss:  1.6366496
Encoder Loss:  0.61690974  || Decoder Loss:  0.9091519 Validation Decoder Loss:  1.631073
Encoder Loss:  0.6146508  || Decoder Loss:  0.9029873 Validation Decoder Loss:  1.6232114
Encoder Loss:  0.6117125  || Decoder Loss:  0.89497256 Validation Decoder Loss:  1.6121163
Encoder Loss:  0.6078324  || Decoder Loss:  0.8843926 Validation Decoder Loss:  1.595978
Encoder Loss:  0.60243744  || Decoder Loss:  0.8696881 Validation Decoder Loss:  1.5708282
Encoder Loss:  0.5940786  || Decoder Loss:  0.8469126 Validation Decoder Loss:  1.5257379
Encoder Loss:  0.5776372  || Decoder Loss:  0.8021069 Validation Decoder Loss:  1.4134332
Encoder Loss:  0.5103211  || Decoder Loss:  0.6182641 Validation Decoder Loss:  0.6810763
Encoder Loss:  0.31303886  || Decoder Loss:  0.09687872 Validation Decoder Loss:  0.3358556
Encoder Loss:  0.30092227  || Decoder Loss:  0.043420125 Validation Decoder Loss:  0.34795797
Encoder Loss:  0.3006209  || Decoder Loss:  0.042510286 Validation Decoder Loss:  0.35545784
Encoder Loss:  0.3004594  || Decoder Loss:  0.042266488 Validation Decoder Loss:  0.35993546
Encoder Loss:  0.3003116  || Decoder Loss:  0.04213784 Validation Decoder Loss:  0.36265254
Encoder Loss:  0.30014345  || Decoder Loss:  0.04204965 Validation Decoder Loss:  0.36427218
Encoder Loss:  0.29992992  || Decoder Loss:  0.041975874 Validation Decoder Loss:  0.3652101
Encoder Loss:  0.29964203  || Decoder Loss:  0.041906267 Validation Decoder Loss:  0.3657312
Encoder Loss:  0.29923517  || Decoder Loss:  0.041836668 Validation Decoder Loss:  0.36599627
Encoder Loss:  0.29862574  || Decoder Loss:  0.041765183 Validation Decoder Loss:  0.36609298
Encoder Loss:  0.2976217  || Decoder Loss:  0.041691028 Validation Decoder Loss:  0.36605045
Encoder Loss:  0.2956074  || Decoder Loss:  0.041615997 Validation Decoder Loss:  0.36580104
Encoder Loss:  0.2879152  || Decoder Loss:  0.041607104 Validation Decoder Loss:  0.36419472
Encoder Loss:  0.36996093  || Decoder Loss:  0.510308 Validation Decoder Loss:  1.6058402
Encoder Loss:  0.29505756  || Decoder Loss:  0.50964904 Validation Decoder Loss:  1.6133206
Encoder Loss:  0.27142808  || Decoder Loss:  0.54667616 Validation Decoder Loss:  0.49655995
Encoder Loss:  0.2375934  || Decoder Loss:  0.48003536 Validation Decoder Loss:  0.38800263
Encoder Loss:  0.21866915  || Decoder Loss:  0.47610238 Validation Decoder Loss:  0.72712755
Encoder Loss:  0.22272731  || Decoder Loss:  0.46823663 Validation Decoder Loss:  0.83832455
Encoder Loss:  0.20731081  || Decoder Loss:  0.45375988 Validation Decoder Loss:  0.89012796
Encoder Loss:  0.19084004  || Decoder Loss:  0.38267526 Validation Decoder Loss:  0.7774305
Encoder Loss:  0.17051709  || Decoder Loss:  0.33344597 Validation Decoder Loss:  0.72451365
Encoder Loss:  0.13580026  || Decoder Loss:  0.25010857 Validation Decoder Loss:  0.45087296
Encoder Loss:  0.10079056  || Decoder Loss:  0.16085011 Validation Decoder Loss:  0.4842281
Encoder Loss:  0.12951003  || Decoder Loss:  0.24116573 Validation Decoder Loss:  0.77536035
Encoder Loss:  0.11404275  || Decoder Loss:  0.19503075 Validation Decoder Loss:  0.6362985
Encoder Loss:  0.09794705  || Decoder Loss:  0.15603828 Validation Decoder Loss:  0.4939487
Encoder Loss:  0.08482664  || Decoder Loss:  0.12212383 Validation Decoder Loss:  0.40626737
Encoder Loss:  0.089868486  || Decoder Loss:  0.13314058 Validation Decoder Loss:  0.52296937
Encoder Loss:  0.07012817  || Decoder Loss:  0.07497153 Validation Decoder Loss:  0.3578294
Model: siamese_net_lr_0.04887287387085358 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3578294
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 244, 5, 20, 1)     119       
_________________________________________________________________
reshape_40 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 1220, 20, 1)       2027      
=================================================================
Total params: 2,027
Trainable params: 2,027
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 3245, 20, 1)       2027      
=================================================================
Total params: 2,027
Trainable params: 2,027
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6391565  || Decoder Loss:  0.89422196 Validation Decoder Loss:  1.6340625
Encoder Loss:  0.6502147  || Decoder Loss:  0.91214293 Validation Decoder Loss:  1.6276253
Encoder Loss:  0.64521676  || Decoder Loss:  0.9044323 Validation Decoder Loss:  1.619839
Encoder Loss:  0.6296793  || Decoder Loss:  0.8952377 Validation Decoder Loss:  1.617115
Encoder Loss:  0.33346435  || Decoder Loss:  0.51339644 Validation Decoder Loss:  1.6793417
Encoder Loss:  0.30117294  || Decoder Loss:  0.57804227 Validation Decoder Loss:  1.0833908
Encoder Loss:  0.22875763  || Decoder Loss:  0.45060584 Validation Decoder Loss:  1.42272
Encoder Loss:  0.23559272  || Decoder Loss:  0.4650626 Validation Decoder Loss:  1.3094425
Encoder Loss:  0.22781399  || Decoder Loss:  0.45178097 Validation Decoder Loss:  1.2693217
Encoder Loss:  0.21366721  || Decoder Loss:  0.41782048 Validation Decoder Loss:  1.522689
Encoder Loss:  0.24860537  || Decoder Loss:  0.49485558 Validation Decoder Loss:  0.9411287
Encoder Loss:  0.24061845  || Decoder Loss:  0.47537708 Validation Decoder Loss:  1.1197518
Encoder Loss:  0.25251147  || Decoder Loss:  0.4899683 Validation Decoder Loss:  1.0948606
Encoder Loss:  0.24239399  || Decoder Loss:  0.4827414 Validation Decoder Loss:  1.0123332
Encoder Loss:  0.22327457  || Decoder Loss:  0.44083515 Validation Decoder Loss:  0.9179336
Encoder Loss:  0.22456022  || Decoder Loss:  0.43847087 Validation Decoder Loss:  0.9539206
Encoder Loss:  0.23568979  || Decoder Loss:  0.46662703 Validation Decoder Loss:  0.9947097
Encoder Loss:  0.21837181  || Decoder Loss:  0.42816943 Validation Decoder Loss:  0.9100179
Encoder Loss:  0.23941408  || Decoder Loss:  0.47435135 Validation Decoder Loss:  1.0167034
Encoder Loss:  0.24388401  || Decoder Loss:  0.4823148 Validation Decoder Loss:  1.0474371
Encoder Loss:  0.23612304  || Decoder Loss:  0.46363536 Validation Decoder Loss:  0.9448571
Encoder Loss:  0.19183597  || Decoder Loss:  0.36462393 Validation Decoder Loss:  1.0302637
Encoder Loss:  0.1544406  || Decoder Loss:  0.28371984 Validation Decoder Loss:  0.89207906
Encoder Loss:  0.21643825  || Decoder Loss:  0.42322552 Validation Decoder Loss:  0.6469143
Encoder Loss:  0.17232327  || Decoder Loss:  0.32263842 Validation Decoder Loss:  0.6059147
Encoder Loss:  0.15697905  || Decoder Loss:  0.2894659 Validation Decoder Loss:  0.76737195
Encoder Loss:  0.15054516  || Decoder Loss:  0.27439195 Validation Decoder Loss:  0.5871799
Encoder Loss:  0.14356644  || Decoder Loss:  0.25777042 Validation Decoder Loss:  0.69019127
Encoder Loss:  0.11996695  || Decoder Loss:  0.20108548 Validation Decoder Loss:  0.7208477
Encoder Loss:  0.11319934  || Decoder Loss:  0.18919699 Validation Decoder Loss:  0.5254594
Encoder Loss:  0.103380635  || Decoder Loss:  0.15793103 Validation Decoder Loss:  0.7613673
Encoder Loss:  0.10179567  || Decoder Loss:  0.16257009 Validation Decoder Loss:  0.53938913
Encoder Loss:  0.080019474  || Decoder Loss:  0.11617539 Validation Decoder Loss:  0.43372115
Encoder Loss:  0.071955964  || Decoder Loss:  0.0967271 Validation Decoder Loss:  0.38974077
Encoder Loss:  0.09327789  || Decoder Loss:  0.13953874 Validation Decoder Loss:  0.5908457
Encoder Loss:  0.08119842  || Decoder Loss:  0.11387896 Validation Decoder Loss:  0.35573098
Encoder Loss:  0.05833406  || Decoder Loss:  0.058821354 Validation Decoder Loss:  0.39132264
Encoder Loss:  0.05444668  || Decoder Loss:  0.05093488 Validation Decoder Loss:  0.394203
Encoder Loss:  0.050825767  || Decoder Loss:  0.04870757 Validation Decoder Loss:  0.37239254
Encoder Loss:  0.049470935  || Decoder Loss:  0.04599423 Validation Decoder Loss:  0.3761788
Model: siamese_net_lr_0.04755178083959654 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3761788
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 140, 13, 20, 1)    127       
_________________________________________________________________
reshape_41 (Reshape)         (None, 1820, 20, 1)       0         
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 1820, 20, 1)       1427      
=================================================================
Total params: 1,427
Trainable params: 1,427
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 3245, 20, 1)       1427      
=================================================================
Total params: 1,427
Trainable params: 1,427
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2924806  || Decoder Loss:  0.097163334 Validation Decoder Loss:  0.34558013
Encoder Loss:  0.27536535  || Decoder Loss:  0.07772127 Validation Decoder Loss:  0.33335054
Encoder Loss:  0.30580056  || Decoder Loss:  0.5233397 Validation Decoder Loss:  0.84505093
Encoder Loss:  0.24253838  || Decoder Loss:  0.47622555 Validation Decoder Loss:  1.1484367
Encoder Loss:  0.24282438  || Decoder Loss:  0.4746617 Validation Decoder Loss:  1.0415974
Encoder Loss:  0.24488893  || Decoder Loss:  0.49022093 Validation Decoder Loss:  0.9844427
Encoder Loss:  0.25855657  || Decoder Loss:  0.5156699 Validation Decoder Loss:  1.0480676
Encoder Loss:  0.25059757  || Decoder Loss:  0.5014201 Validation Decoder Loss:  1.0300578
Encoder Loss:  0.24702255  || Decoder Loss:  0.50184226 Validation Decoder Loss:  1.0757942
Encoder Loss:  0.24551153  || Decoder Loss:  0.50177675 Validation Decoder Loss:  0.97122335
Encoder Loss:  0.24455161  || Decoder Loss:  0.48996145 Validation Decoder Loss:  1.13047
Encoder Loss:  0.2602142  || Decoder Loss:  0.5048593 Validation Decoder Loss:  1.0701098
Encoder Loss:  0.24624445  || Decoder Loss:  0.49855042 Validation Decoder Loss:  1.0653305
Encoder Loss:  0.2456327  || Decoder Loss:  0.49027494 Validation Decoder Loss:  1.0536647
Encoder Loss:  0.24288687  || Decoder Loss:  0.49537408 Validation Decoder Loss:  0.9698391
Encoder Loss:  0.25390363  || Decoder Loss:  0.50981134 Validation Decoder Loss:  0.8852253
Encoder Loss:  0.24445409  || Decoder Loss:  0.48846135 Validation Decoder Loss:  0.91479516
Encoder Loss:  0.23363705  || Decoder Loss:  0.47018525 Validation Decoder Loss:  0.9164567
Encoder Loss:  0.22590417  || Decoder Loss:  0.44833001 Validation Decoder Loss:  0.9807127
Encoder Loss:  0.23464927  || Decoder Loss:  0.4720294 Validation Decoder Loss:  1.0401328
Encoder Loss:  0.24512412  || Decoder Loss:  0.49885058 Validation Decoder Loss:  0.9647627
Encoder Loss:  0.24140579  || Decoder Loss:  0.4920829 Validation Decoder Loss:  0.97043663
Encoder Loss:  0.2394989  || Decoder Loss:  0.49168813 Validation Decoder Loss:  0.98342943
Encoder Loss:  0.24471386  || Decoder Loss:  0.4956295 Validation Decoder Loss:  0.90722966
Encoder Loss:  0.24897641  || Decoder Loss:  0.48943734 Validation Decoder Loss:  0.93849236
Encoder Loss:  0.24411795  || Decoder Loss:  0.49153548 Validation Decoder Loss:  0.93135154
Encoder Loss:  0.23991615  || Decoder Loss:  0.48870268 Validation Decoder Loss:  0.95374143
Encoder Loss:  0.24074261  || Decoder Loss:  0.4903632 Validation Decoder Loss:  0.9554174
Encoder Loss:  0.24719107  || Decoder Loss:  0.49842796 Validation Decoder Loss:  0.9047722
Encoder Loss:  0.23707104  || Decoder Loss:  0.47891304 Validation Decoder Loss:  1.0261714
Encoder Loss:  0.23924167  || Decoder Loss:  0.48001048 Validation Decoder Loss:  0.8679759
Encoder Loss:  0.22776265  || Decoder Loss:  0.4544636 Validation Decoder Loss:  0.9720061
Encoder Loss:  0.23494726  || Decoder Loss:  0.47322667 Validation Decoder Loss:  0.97202253
Encoder Loss:  0.23925708  || Decoder Loss:  0.49092317 Validation Decoder Loss:  0.95746315
Encoder Loss:  0.23959047  || Decoder Loss:  0.49026787 Validation Decoder Loss:  0.9487041
Encoder Loss:  0.23918709  || Decoder Loss:  0.48786232 Validation Decoder Loss:  0.9277541
Encoder Loss:  0.24175161  || Decoder Loss:  0.48796463 Validation Decoder Loss:  0.97631
Encoder Loss:  0.23776625  || Decoder Loss:  0.48444235 Validation Decoder Loss:  1.0412511
Encoder Loss:  0.23005085  || Decoder Loss:  0.46594855 Validation Decoder Loss:  0.9438073
Encoder Loss:  0.23022012  || Decoder Loss:  0.4681162 Validation Decoder Loss:  0.91092134
Model: siamese_net_lr_0.06212680879012349 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.91092134
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 454, 5, 20, 1)     77        
_________________________________________________________________
reshape_42 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3804699  || Decoder Loss:  0.18968348 Validation Decoder Loss:  0.35517505
Encoder Loss:  0.37958446  || Decoder Loss:  0.06309702 Validation Decoder Loss:  0.35239315
Encoder Loss:  0.37885186  || Decoder Loss:  0.059973836 Validation Decoder Loss:  0.34555483
Encoder Loss:  0.37778866  || Decoder Loss:  0.056340016 Validation Decoder Loss:  0.3364143
Encoder Loss:  0.37657067  || Decoder Loss:  0.05402258 Validation Decoder Loss:  0.33331662
Encoder Loss:  0.37410957  || Decoder Loss:  0.05029974 Validation Decoder Loss:  0.33014843
Encoder Loss:  0.36624053  || Decoder Loss:  0.037543938 Validation Decoder Loss:  0.33944342
Encoder Loss:  0.27670023  || Decoder Loss:  0.03264269 Validation Decoder Loss:  0.3706727
Encoder Loss:  0.17910476  || Decoder Loss:  0.27946946 Validation Decoder Loss:  1.5084686
Encoder Loss:  0.14621866  || Decoder Loss:  0.4161499 Validation Decoder Loss:  0.3268115
Encoder Loss:  0.1492057  || Decoder Loss:  0.4013641 Validation Decoder Loss:  0.82950926
Encoder Loss:  0.0728457  || Decoder Loss:  0.14695285 Validation Decoder Loss:  0.34452233
Encoder Loss:  0.056266412  || Decoder Loss:  0.03571963 Validation Decoder Loss:  0.38618737
Encoder Loss:  0.057844378  || Decoder Loss:  0.034482695 Validation Decoder Loss:  0.34448814
Encoder Loss:  0.05697181  || Decoder Loss:  0.032662608 Validation Decoder Loss:  0.34946072
Encoder Loss:  0.06469739  || Decoder Loss:  0.032663263 Validation Decoder Loss:  0.3563497
Encoder Loss:  0.060557872  || Decoder Loss:  0.03250764 Validation Decoder Loss:  0.34745884
Encoder Loss:  0.06259385  || Decoder Loss:  0.032490622 Validation Decoder Loss:  0.35172328
Encoder Loss:  0.05767867  || Decoder Loss:  0.032407884 Validation Decoder Loss:  0.34900188
Encoder Loss:  0.053527843  || Decoder Loss:  0.03230952 Validation Decoder Loss:  0.35100007
Encoder Loss:  0.06388543  || Decoder Loss:  0.032442104 Validation Decoder Loss:  0.3623137
Encoder Loss:  0.056306783  || Decoder Loss:  0.032291424 Validation Decoder Loss:  0.34598404
Encoder Loss:  0.060938716  || Decoder Loss:  0.03237274 Validation Decoder Loss:  0.34759247
Encoder Loss:  0.061505117  || Decoder Loss:  0.03236342 Validation Decoder Loss:  0.3440172
Encoder Loss:  0.061382543  || Decoder Loss:  0.032304857 Validation Decoder Loss:  0.351372
Encoder Loss:  0.057762727  || Decoder Loss:  0.032218926 Validation Decoder Loss:  0.34027094
Encoder Loss:  0.057845518  || Decoder Loss:  0.032281086 Validation Decoder Loss:  0.34926674
Encoder Loss:  0.054117337  || Decoder Loss:  0.032127514 Validation Decoder Loss:  0.34666348
Encoder Loss:  0.0591467  || Decoder Loss:  0.032175966 Validation Decoder Loss:  0.35275495
Encoder Loss:  0.05692869  || Decoder Loss:  0.0320761 Validation Decoder Loss:  0.345482
Encoder Loss:  0.055126764  || Decoder Loss:  0.032123376 Validation Decoder Loss:  0.35067266
Encoder Loss:  0.050623626  || Decoder Loss:  0.032065704 Validation Decoder Loss:  0.34677252
Encoder Loss:  0.054575924  || Decoder Loss:  0.032083426 Validation Decoder Loss:  0.339791
Encoder Loss:  0.05622311  || Decoder Loss:  0.032087952 Validation Decoder Loss:  0.3538099
Encoder Loss:  0.05635302  || Decoder Loss:  0.032067925 Validation Decoder Loss:  0.33978364
Encoder Loss:  0.054744802  || Decoder Loss:  0.032297563 Validation Decoder Loss:  0.34579915
Encoder Loss:  0.054614104  || Decoder Loss:  0.03249089 Validation Decoder Loss:  0.35194582
Encoder Loss:  0.057505444  || Decoder Loss:  0.03286095 Validation Decoder Loss:  0.34847033
Encoder Loss:  0.05169402  || Decoder Loss:  0.032693006 Validation Decoder Loss:  0.34444803
Encoder Loss:  0.0523767  || Decoder Loss:  0.032796547 Validation Decoder Loss:  0.3451489
Model: siamese_net_lr_0.013091850524540828 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3451489
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 444, 5, 20, 1)     130       
_________________________________________________________________
reshape_43 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 130
Trainable params: 130
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 2220, 20, 1)       1027      
=================================================================
Total params: 1,027
Trainable params: 1,027
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 3245, 20, 1)       1027      
=================================================================
Total params: 1,027
Trainable params: 1,027
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30202037  || Decoder Loss:  0.23603894 Validation Decoder Loss:  1.6357654
Encoder Loss:  0.65709615  || Decoder Loss:  0.9208603 Validation Decoder Loss:  1.6292064
Encoder Loss:  0.3347247  || Decoder Loss:  0.46245402 Validation Decoder Loss:  0.37590504
Encoder Loss:  0.055947676  || Decoder Loss:  0.047708984 Validation Decoder Loss:  0.30947372
Encoder Loss:  0.053065907  || Decoder Loss:  0.0430328 Validation Decoder Loss:  0.33234173
Encoder Loss:  0.058721136  || Decoder Loss:  0.035435818 Validation Decoder Loss:  0.3417908
Encoder Loss:  0.050793257  || Decoder Loss:  0.03432585 Validation Decoder Loss:  0.34651804
Encoder Loss:  0.04847581  || Decoder Loss:  0.0341023 Validation Decoder Loss:  0.34561807
Encoder Loss:  0.045958735  || Decoder Loss:  0.033844158 Validation Decoder Loss:  0.34404552
Encoder Loss:  0.048939973  || Decoder Loss:  0.03376072 Validation Decoder Loss:  0.3443914
Encoder Loss:  0.05838912  || Decoder Loss:  0.03371239 Validation Decoder Loss:  0.34739998
Encoder Loss:  0.049307957  || Decoder Loss:  0.033505842 Validation Decoder Loss:  0.34411186
Encoder Loss:  0.04902824  || Decoder Loss:  0.03335419 Validation Decoder Loss:  0.34322268
Encoder Loss:  0.045875315  || Decoder Loss:  0.033295937 Validation Decoder Loss:  0.34258056
Encoder Loss:  0.04944379  || Decoder Loss:  0.03321263 Validation Decoder Loss:  0.34261912
Encoder Loss:  0.04625816  || Decoder Loss:  0.033139583 Validation Decoder Loss:  0.34475672
Encoder Loss:  0.043906786  || Decoder Loss:  0.0330322 Validation Decoder Loss:  0.34343046
Encoder Loss:  0.045820285  || Decoder Loss:  0.03297341 Validation Decoder Loss:  0.3420239
Encoder Loss:  0.048046038  || Decoder Loss:  0.03306852 Validation Decoder Loss:  0.34579796
Encoder Loss:  0.05017211  || Decoder Loss:  0.032951206 Validation Decoder Loss:  0.34522426
Encoder Loss:  0.04711098  || Decoder Loss:  0.032924008 Validation Decoder Loss:  0.34609106
Encoder Loss:  0.047984153  || Decoder Loss:  0.03286531 Validation Decoder Loss:  0.34630534
Encoder Loss:  0.048449587  || Decoder Loss:  0.03280124 Validation Decoder Loss:  0.34501213
Encoder Loss:  0.045886092  || Decoder Loss:  0.03272124 Validation Decoder Loss:  0.34152496
Encoder Loss:  0.045217447  || Decoder Loss:  0.032711405 Validation Decoder Loss:  0.3417186
Encoder Loss:  0.045016307  || Decoder Loss:  0.03268376 Validation Decoder Loss:  0.34506106
Encoder Loss:  0.046189  || Decoder Loss:  0.032718375 Validation Decoder Loss:  0.34426615
Encoder Loss:  0.045028254  || Decoder Loss:  0.0326285 Validation Decoder Loss:  0.34287366
Encoder Loss:  0.04484022  || Decoder Loss:  0.032637045 Validation Decoder Loss:  0.3454303
Encoder Loss:  0.04612361  || Decoder Loss:  0.03277926 Validation Decoder Loss:  0.34668761
Encoder Loss:  0.045249835  || Decoder Loss:  0.03342322 Validation Decoder Loss:  0.34433645
Encoder Loss:  0.044859152  || Decoder Loss:  0.033019345 Validation Decoder Loss:  0.34542507
Encoder Loss:  0.044560812  || Decoder Loss:  0.032853812 Validation Decoder Loss:  0.34136617
Encoder Loss:  0.04651987  || Decoder Loss:  0.03259489 Validation Decoder Loss:  0.3421047
Encoder Loss:  0.04431311  || Decoder Loss:  0.032466516 Validation Decoder Loss:  0.34385648
Encoder Loss:  0.04463416  || Decoder Loss:  0.032587264 Validation Decoder Loss:  0.34464833
Encoder Loss:  0.044501495  || Decoder Loss:  0.032759033 Validation Decoder Loss:  0.3456238
Encoder Loss:  0.04684205  || Decoder Loss:  0.032901946 Validation Decoder Loss:  0.34980574
Encoder Loss:  0.04580371  || Decoder Loss:  0.03368258 Validation Decoder Loss:  0.34685403
Encoder Loss:  0.046732243  || Decoder Loss:  0.03301939 Validation Decoder Loss:  0.34734535
Model: siamese_net_lr_0.004355381741183351 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34734535
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 80, 29, 20, 1)     426       
_________________________________________________________________
reshape_44 (Reshape)         (None, 2320, 20, 1)       0         
=================================================================
Total params: 426
Trainable params: 426
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 2320, 20, 1)       927       
=================================================================
Total params: 927
Trainable params: 927
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 3245, 20, 1)       927       
=================================================================
Total params: 927
Trainable params: 927
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5054321  || Decoder Loss:  0.9090848 Validation Decoder Loss:  1.6337821
Encoder Loss:  0.4313454  || Decoder Loss:  0.92777467 Validation Decoder Loss:  1.6335478
Encoder Loss:  0.52967966  || Decoder Loss:  0.9273741 Validation Decoder Loss:  1.6330693
Encoder Loss:  0.5296374  || Decoder Loss:  0.92679524 Validation Decoder Loss:  1.6324518
Encoder Loss:  0.5284647  || Decoder Loss:  0.9260701 Validation Decoder Loss:  1.6317008
Encoder Loss:  0.5266173  || Decoder Loss:  0.92519003 Validation Decoder Loss:  1.6307925
Encoder Loss:  0.52351785  || Decoder Loss:  0.9241202 Validation Decoder Loss:  1.6296782
Encoder Loss:  0.5168368  || Decoder Loss:  0.92278725 Validation Decoder Loss:  1.62825
Encoder Loss:  0.44831634  || Decoder Loss:  0.921103 Validation Decoder Loss:  1.626488
Encoder Loss:  0.48415783  || Decoder Loss:  0.91865575 Validation Decoder Loss:  1.6237769
Encoder Loss:  0.40861094  || Decoder Loss:  0.91206175 Validation Decoder Loss:  1.6094898
Encoder Loss:  0.19517183  || Decoder Loss:  0.5113119 Validation Decoder Loss:  1.2449822
Encoder Loss:  0.14481156  || Decoder Loss:  0.49547824 Validation Decoder Loss:  0.77537954
Encoder Loss:  0.140223  || Decoder Loss:  0.49266955 Validation Decoder Loss:  0.73061496
Encoder Loss:  0.13657083  || Decoder Loss:  0.49953777 Validation Decoder Loss:  0.7455454
Encoder Loss:  0.12897433  || Decoder Loss:  0.48138824 Validation Decoder Loss:  0.94641066
Encoder Loss:  0.12645784  || Decoder Loss:  0.47050744 Validation Decoder Loss:  0.8096038
Encoder Loss:  0.12186561  || Decoder Loss:  0.4466139 Validation Decoder Loss:  0.8027725
Encoder Loss:  0.113017045  || Decoder Loss:  0.3980744 Validation Decoder Loss:  0.9762641
Encoder Loss:  0.1282869  || Decoder Loss:  0.48266143 Validation Decoder Loss:  0.97339857
Encoder Loss:  0.12738782  || Decoder Loss:  0.47758412 Validation Decoder Loss:  0.9741793
Encoder Loss:  0.12623765  || Decoder Loss:  0.47134343 Validation Decoder Loss:  0.97342896
Encoder Loss:  0.12155571  || Decoder Loss:  0.4455177 Validation Decoder Loss:  0.9382472
Encoder Loss:  0.10765533  || Decoder Loss:  0.36858276 Validation Decoder Loss:  0.8901322
Encoder Loss:  0.10126533  || Decoder Loss:  0.33317208 Validation Decoder Loss:  0.84195054
Encoder Loss:  0.09321645  || Decoder Loss:  0.2885804 Validation Decoder Loss:  0.69448245
Encoder Loss:  0.123953015  || Decoder Loss:  0.45879346 Validation Decoder Loss:  0.9904256
Encoder Loss:  0.12576097  || Decoder Loss:  0.46878526 Validation Decoder Loss:  0.9788885
Encoder Loss:  0.11470989  || Decoder Loss:  0.4072173 Validation Decoder Loss:  0.96694267
Encoder Loss:  0.117320195  || Decoder Loss:  0.422198 Validation Decoder Loss:  0.9849667
Encoder Loss:  0.12817551  || Decoder Loss:  0.4824378 Validation Decoder Loss:  0.9886621
Encoder Loss:  0.12855873  || Decoder Loss:  0.48382768 Validation Decoder Loss:  0.9896196
Encoder Loss:  0.12807126  || Decoder Loss:  0.4818352 Validation Decoder Loss:  0.9862064
Encoder Loss:  0.12762082  || Decoder Loss:  0.47931275 Validation Decoder Loss:  0.9828104
Encoder Loss:  0.12660971  || Decoder Loss:  0.47366825 Validation Decoder Loss:  0.97168434
Encoder Loss:  0.119226076  || Decoder Loss:  0.43283913 Validation Decoder Loss:  0.8264788
Encoder Loss:  0.12406476  || Decoder Loss:  0.45913535 Validation Decoder Loss:  0.9957169
Encoder Loss:  0.1286735  || Decoder Loss:  0.4841131 Validation Decoder Loss:  0.99747217
Encoder Loss:  0.12852012  || Decoder Loss:  0.4838336 Validation Decoder Loss:  0.99665713
Encoder Loss:  0.12838997  || Decoder Loss:  0.48311502 Validation Decoder Loss:  0.99984175
Model: siamese_net_lr_0.045504375551546544 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99984175
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 195, 6, 20, 1)     139       
_________________________________________________________________
reshape_45 (Reshape)         (None, 1170, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 1170, 20, 1)       908       
=================================================================
Total params: 908
Trainable params: 908
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 3245, 20, 1)       908       
=================================================================
Total params: 908
Trainable params: 908
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.90469915  || Decoder Loss:  0.90680885 Validation Decoder Loss:  1.6324779
Encoder Loss:  0.91718346  || Decoder Loss:  0.91931033 Validation Decoder Loss:  1.6004438
Encoder Loss:  0.8234056  || Decoder Loss:  0.82511175 Validation Decoder Loss:  1.2500389
Encoder Loss:  0.432328  || Decoder Loss:  0.43227252 Validation Decoder Loss:  0.5902135
Encoder Loss:  0.14493713  || Decoder Loss:  0.14359017 Validation Decoder Loss:  0.39841032
Encoder Loss:  0.086237624  || Decoder Loss:  0.084635384 Validation Decoder Loss:  0.36969477
Encoder Loss:  0.0802279  || Decoder Loss:  0.0786166 Validation Decoder Loss:  0.36728448
Encoder Loss:  0.08365835  || Decoder Loss:  0.08211064 Validation Decoder Loss:  0.37085137
Encoder Loss:  0.22179584  || Decoder Loss:  0.22139926 Validation Decoder Loss:  1.6020484
Encoder Loss:  0.5704255  || Decoder Loss:  0.57239217 Validation Decoder Loss:  1.1455572
Encoder Loss:  0.46984014  || Decoder Loss:  0.47161502 Validation Decoder Loss:  1.2415667
Encoder Loss:  0.47429794  || Decoder Loss:  0.4761134 Validation Decoder Loss:  1.1803018
Encoder Loss:  0.47582248  || Decoder Loss:  0.47766417 Validation Decoder Loss:  1.0918815
Encoder Loss:  0.44066897  || Decoder Loss:  0.44237354 Validation Decoder Loss:  1.0370097
Encoder Loss:  0.44045383  || Decoder Loss:  0.44217217 Validation Decoder Loss:  1.0700741
Encoder Loss:  0.40498948  || Decoder Loss:  0.40655124 Validation Decoder Loss:  1.0378715
Encoder Loss:  0.3186119  || Decoder Loss:  0.31978884 Validation Decoder Loss:  0.7176533
Encoder Loss:  0.3337815  || Decoder Loss:  0.33503938 Validation Decoder Loss:  0.96279925
Encoder Loss:  0.47955906  || Decoder Loss:  0.4814748 Validation Decoder Loss:  0.9602313
Encoder Loss:  0.47541615  || Decoder Loss:  0.47731504 Validation Decoder Loss:  0.956838
Encoder Loss:  0.43639386  || Decoder Loss:  0.4381174 Validation Decoder Loss:  0.91742027
Encoder Loss:  0.3662285  || Decoder Loss:  0.36763194 Validation Decoder Loss:  0.5793826
Encoder Loss:  0.19797306  || Decoder Loss:  0.19860348 Validation Decoder Loss:  0.6599927
Encoder Loss:  0.21816011  || Decoder Loss:  0.21890284 Validation Decoder Loss:  0.634928
Encoder Loss:  0.13123678  || Decoder Loss:  0.13157442 Validation Decoder Loss:  0.40883023
Encoder Loss:  0.08897838  || Decoder Loss:  0.08912842 Validation Decoder Loss:  0.40236092
Encoder Loss:  0.08040694  || Decoder Loss:  0.08047799 Validation Decoder Loss:  0.39483577
Encoder Loss:  0.059181247  || Decoder Loss:  0.0592101 Validation Decoder Loss:  0.34576052
Encoder Loss:  0.0415271  || Decoder Loss:  0.041452378 Validation Decoder Loss:  0.3453668
Encoder Loss:  0.03893236  || Decoder Loss:  0.038855564 Validation Decoder Loss:  0.3564271
Encoder Loss:  0.04160476  || Decoder Loss:  0.041533213 Validation Decoder Loss:  0.36262232
Encoder Loss:  0.040840063  || Decoder Loss:  0.040783726 Validation Decoder Loss:  0.35787597
Encoder Loss:  0.03919138  || Decoder Loss:  0.039129984 Validation Decoder Loss:  0.3571396
Encoder Loss:  0.037721947  || Decoder Loss:  0.037642952 Validation Decoder Loss:  0.35369515
Encoder Loss:  0.037685722  || Decoder Loss:  0.037596032 Validation Decoder Loss:  0.3537655
Encoder Loss:  0.036459878  || Decoder Loss:  0.036377784 Validation Decoder Loss:  0.3544594
Encoder Loss:  0.03709202  || Decoder Loss:  0.037007548 Validation Decoder Loss:  0.3565402
Encoder Loss:  0.03915528  || Decoder Loss:  0.039048105 Validation Decoder Loss:  0.35128087
Encoder Loss:  0.039004467  || Decoder Loss:  0.03890961 Validation Decoder Loss:  0.37065065
Encoder Loss:  0.04000397  || Decoder Loss:  0.039938416 Validation Decoder Loss:  0.37507612
Model: siamese_net_lr_0.032858534600525034 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37507612
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 137, 10, 20, 1)    67        
_________________________________________________________________
reshape_46 (Reshape)         (None, 1370, 20, 1)       0         
=================================================================
Total params: 67
Trainable params: 67
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 1370, 20, 1)       508       
=================================================================
Total params: 508
Trainable params: 508
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 3245, 20, 1)       1877      
=================================================================
Total params: 1,877
Trainable params: 1,877
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8907882  || Decoder Loss:  0.9004165 Validation Decoder Loss:  1.6404953
Encoder Loss:  0.9018713  || Decoder Loss:  0.9112503 Validation Decoder Loss:  1.6356065
Encoder Loss:  0.89638305  || Decoder Loss:  0.90564865 Validation Decoder Loss:  1.6285505
Encoder Loss:  0.889045  || Decoder Loss:  0.8981614 Validation Decoder Loss:  1.6184137
Encoder Loss:  0.8792261  || Decoder Loss:  0.8881422 Validation Decoder Loss:  1.6035026
Encoder Loss:  0.865466  || Decoder Loss:  0.874102 Validation Decoder Loss:  1.5799277
Encoder Loss:  0.8438012  || Decoder Loss:  0.8519943 Validation Decoder Loss:  1.536175
Encoder Loss:  0.79836005  || Decoder Loss:  0.80562055 Validation Decoder Loss:  1.4128486
Encoder Loss:  0.5308939  || Decoder Loss:  0.532639 Validation Decoder Loss:  0.39591146
Encoder Loss:  0.05886292  || Decoder Loss:  0.050871905 Validation Decoder Loss:  0.3340165
Encoder Loss:  0.049988452  || Decoder Loss:  0.04183873 Validation Decoder Loss:  0.34518057
Encoder Loss:  0.049318686  || Decoder Loss:  0.041345306 Validation Decoder Loss:  0.3515135
Encoder Loss:  0.048952017  || Decoder Loss:  0.040961005 Validation Decoder Loss:  0.3558419
Encoder Loss:  0.048963923  || Decoder Loss:  0.04076247 Validation Decoder Loss:  0.35886133
Encoder Loss:  0.04887913  || Decoder Loss:  0.04068312 Validation Decoder Loss:  0.36089584
Encoder Loss:  0.048854776  || Decoder Loss:  0.04066763 Validation Decoder Loss:  0.36222637
Encoder Loss:  0.04886075  || Decoder Loss:  0.040685445 Validation Decoder Loss:  0.36309463
Encoder Loss:  0.048883688  || Decoder Loss:  0.04072389 Validation Decoder Loss:  0.36368746
Encoder Loss:  0.04891992  || Decoder Loss:  0.04078082 Validation Decoder Loss:  0.36413836
Encoder Loss:  0.04897111  || Decoder Loss:  0.040860835 Validation Decoder Loss:  0.36454353
Encoder Loss:  0.049043268  || Decoder Loss:  0.040975694 Validation Decoder Loss:  0.36498675
Encoder Loss:  0.049150005  || Decoder Loss:  0.041152164 Validation Decoder Loss:  0.36558843
Encoder Loss:  0.04932828  || Decoder Loss:  0.04146603 Validation Decoder Loss:  0.36669338
Encoder Loss:  0.049764834  || Decoder Loss:  0.042314038 Validation Decoder Loss:  0.371284
Encoder Loss:  0.3355064  || Decoder Loss:  0.33804065 Validation Decoder Loss:  0.92412966
Encoder Loss:  0.44379005  || Decoder Loss:  0.45151183 Validation Decoder Loss:  1.3800002
Encoder Loss:  0.44817907  || Decoder Loss:  0.4559198 Validation Decoder Loss:  1.4323668
Encoder Loss:  0.44698438  || Decoder Loss:  0.45475194 Validation Decoder Loss:  1.3626432
Encoder Loss:  0.42769456  || Decoder Loss:  0.4351466 Validation Decoder Loss:  1.3121105
Encoder Loss:  0.41403377  || Decoder Loss:  0.4212198 Validation Decoder Loss:  1.2664347
Encoder Loss:  0.44798446  || Decoder Loss:  0.45585534 Validation Decoder Loss:  0.98708373
Encoder Loss:  0.44152123  || Decoder Loss:  0.44932422 Validation Decoder Loss:  1.104767
Encoder Loss:  0.44629753  || Decoder Loss:  0.45419914 Validation Decoder Loss:  1.0390527
Encoder Loss:  0.453695  || Decoder Loss:  0.46178845 Validation Decoder Loss:  1.2785699
Encoder Loss:  0.42143276  || Decoder Loss:  0.4288755 Validation Decoder Loss:  1.2337453
Encoder Loss:  0.3918302  || Decoder Loss:  0.39866656 Validation Decoder Loss:  0.963177
Encoder Loss:  0.38177595  || Decoder Loss:  0.388392 Validation Decoder Loss:  0.8209573
Encoder Loss:  0.4098977  || Decoder Loss:  0.41719884 Validation Decoder Loss:  0.97735703
Encoder Loss:  0.48079568  || Decoder Loss:  0.48956516 Validation Decoder Loss:  0.98176384
Encoder Loss:  0.48059937  || Decoder Loss:  0.48937377 Validation Decoder Loss:  0.98036134
Model: siamese_net_lr_0.0801936339774911 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.98036134
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 67, 10, 20, 1)     9         
_________________________________________________________________
reshape_47 (Reshape)         (None, 670, 20, 1)        0         
=================================================================
Total params: 9
Trainable params: 9
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 670, 20, 1)        2577      
=================================================================
Total params: 2,577
Trainable params: 2,577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 3245, 20, 1)       1908      
=================================================================
Total params: 1,908
Trainable params: 1,908
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6429803  || Decoder Loss:  0.9008125 Validation Decoder Loss:  1.6430471
Encoder Loss:  0.6544359  || Decoder Loss:  0.9163873 Validation Decoder Loss:  1.6414279
Encoder Loss:  0.6535573  || Decoder Loss:  0.9144327 Validation Decoder Loss:  1.6392846
Encoder Loss:  0.6524178  || Decoder Loss:  0.91197324 Validation Decoder Loss:  1.6365697
Encoder Loss:  0.6509356  || Decoder Loss:  0.9090137 Validation Decoder Loss:  1.6332304
Encoder Loss:  0.6489209  || Decoder Loss:  0.90553033 Validation Decoder Loss:  1.6291703
Encoder Loss:  0.64613533  || Decoder Loss:  0.9014615 Validation Decoder Loss:  1.6242269
Encoder Loss:  0.64210343  || Decoder Loss:  0.89668727 Validation Decoder Loss:  1.6181822
Encoder Loss:  0.6343735  || Decoder Loss:  0.8909128 Validation Decoder Loss:  1.6108878
Encoder Loss:  0.45978278  || Decoder Loss:  0.60003805 Validation Decoder Loss:  0.4002481
Encoder Loss:  0.33304  || Decoder Loss:  0.49503624 Validation Decoder Loss:  1.6039588
Encoder Loss:  0.26850015  || Decoder Loss:  0.4768015 Validation Decoder Loss:  1.5812614
Encoder Loss:  0.26901713  || Decoder Loss:  0.49341884 Validation Decoder Loss:  1.5515419
Encoder Loss:  0.24899013  || Decoder Loss:  0.46245897 Validation Decoder Loss:  1.2981994
Encoder Loss:  0.23530646  || Decoder Loss:  0.43998614 Validation Decoder Loss:  1.4460484
Encoder Loss:  0.24705797  || Decoder Loss:  0.46992356 Validation Decoder Loss:  1.3033515
Encoder Loss:  0.20297304  || Decoder Loss:  0.3769764 Validation Decoder Loss:  1.4870399
Encoder Loss:  0.20980604  || Decoder Loss:  0.38577193 Validation Decoder Loss:  1.3392669
Encoder Loss:  0.20671125  || Decoder Loss:  0.37209755 Validation Decoder Loss:  0.76480526
Encoder Loss:  0.14835593  || Decoder Loss:  0.2461987 Validation Decoder Loss:  0.63269067
Encoder Loss:  0.1596088  || Decoder Loss:  0.28125745 Validation Decoder Loss:  0.9733059
Encoder Loss:  0.15646595  || Decoder Loss:  0.2579419 Validation Decoder Loss:  0.6324334
Encoder Loss:  0.17382315  || Decoder Loss:  0.3017554 Validation Decoder Loss:  0.9183127
Encoder Loss:  0.16689819  || Decoder Loss:  0.29018125 Validation Decoder Loss:  0.79854655
Encoder Loss:  0.1287603  || Decoder Loss:  0.19988742 Validation Decoder Loss:  0.5132166
Encoder Loss:  0.1032405  || Decoder Loss:  0.1512481 Validation Decoder Loss:  0.57054055
Encoder Loss:  0.10921018  || Decoder Loss:  0.1580846 Validation Decoder Loss:  0.7247151
Encoder Loss:  0.09879596  || Decoder Loss:  0.1492486 Validation Decoder Loss:  0.542518
Encoder Loss:  0.08504922  || Decoder Loss:  0.10973703 Validation Decoder Loss:  0.42334637
Encoder Loss:  0.09117457  || Decoder Loss:  0.11792647 Validation Decoder Loss:  0.39041576
Encoder Loss:  0.17103064  || Decoder Loss:  0.29259118 Validation Decoder Loss:  0.7353147
Encoder Loss:  0.1517216  || Decoder Loss:  0.26389048 Validation Decoder Loss:  0.40497828
Encoder Loss:  0.07530763  || Decoder Loss:  0.085745335 Validation Decoder Loss:  0.5524932
Encoder Loss:  0.11786468  || Decoder Loss:  0.17190076 Validation Decoder Loss:  0.46787292
Encoder Loss:  0.08984434  || Decoder Loss:  0.11650286 Validation Decoder Loss:  0.37838078
Encoder Loss:  0.06268016  || Decoder Loss:  0.054404344 Validation Decoder Loss:  0.5647545
Encoder Loss:  0.09135038  || Decoder Loss:  0.124138094 Validation Decoder Loss:  0.38804078
Encoder Loss:  0.09679787  || Decoder Loss:  0.14356531 Validation Decoder Loss:  0.4914062
Encoder Loss:  0.079509035  || Decoder Loss:  0.09864804 Validation Decoder Loss:  0.48029286
Encoder Loss:  0.091892794  || Decoder Loss:  0.12699561 Validation Decoder Loss:  0.6781888
Model: siamese_net_lr_0.09288620019309037 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.6781888
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 172, 10, 20, 1)    219       
_________________________________________________________________
reshape_48 (Reshape)         (None, 1720, 20, 1)       0         
=================================================================
Total params: 219
Trainable params: 219
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 1720, 20, 1)       1527      
=================================================================
Total params: 1,527
Trainable params: 1,527
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 3245, 20, 1)       1527      
=================================================================
Total params: 1,527
Trainable params: 1,527
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40750217  || Decoder Loss:  0.10049962 Validation Decoder Loss:  0.3128156
Encoder Loss:  0.41194144  || Decoder Loss:  0.054093495 Validation Decoder Loss:  0.34119508
Encoder Loss:  0.41062745  || Decoder Loss:  0.046703264 Validation Decoder Loss:  0.33292437
Encoder Loss:  0.40879238  || Decoder Loss:  0.04321509 Validation Decoder Loss:  0.3340354
Encoder Loss:  0.38418353  || Decoder Loss:  0.04074337 Validation Decoder Loss:  0.33606803
Encoder Loss:  0.40927216  || Decoder Loss:  0.039002642 Validation Decoder Loss:  0.3379462
Encoder Loss:  0.40856266  || Decoder Loss:  0.037710086 Validation Decoder Loss:  0.34066635
Encoder Loss:  0.4075848  || Decoder Loss:  0.036672622 Validation Decoder Loss:  0.3430703
Encoder Loss:  0.40636143  || Decoder Loss:  0.035912953 Validation Decoder Loss:  0.34570783
Encoder Loss:  0.40479073  || Decoder Loss:  0.035498522 Validation Decoder Loss:  0.3492723
Encoder Loss:  0.4026955  || Decoder Loss:  0.03555675 Validation Decoder Loss:  0.35535818
Encoder Loss:  0.39974242  || Decoder Loss:  0.03632091 Validation Decoder Loss:  0.36268887
Encoder Loss:  0.39520073  || Decoder Loss:  0.038258184 Validation Decoder Loss:  0.37043393
Encoder Loss:  0.3869661  || Decoder Loss:  0.04194544 Validation Decoder Loss:  0.3863737
Encoder Loss:  0.3647958  || Decoder Loss:  0.04702628 Validation Decoder Loss:  0.38116533
Encoder Loss:  0.21501455  || Decoder Loss:  0.24973834 Validation Decoder Loss:  0.76282585
Encoder Loss:  0.12548673  || Decoder Loss:  0.48917317 Validation Decoder Loss:  0.56379443
Encoder Loss:  0.12529783  || Decoder Loss:  0.48054183 Validation Decoder Loss:  0.60193825
Encoder Loss:  0.12354203  || Decoder Loss:  0.47582603 Validation Decoder Loss:  0.63989526
Encoder Loss:  0.11774374  || Decoder Loss:  0.48311388 Validation Decoder Loss:  0.57742906
Encoder Loss:  0.122007154  || Decoder Loss:  0.48114663 Validation Decoder Loss:  0.6534226
Encoder Loss:  0.11233316  || Decoder Loss:  0.48619828 Validation Decoder Loss:  0.6428926
Encoder Loss:  0.110576995  || Decoder Loss:  0.48617023 Validation Decoder Loss:  0.66439223
Encoder Loss:  0.109778516  || Decoder Loss:  0.48836815 Validation Decoder Loss:  0.67146814
Encoder Loss:  0.10866191  || Decoder Loss:  0.49391025 Validation Decoder Loss:  0.7022712
Encoder Loss:  0.106133245  || Decoder Loss:  0.49467292 Validation Decoder Loss:  0.6803758
Encoder Loss:  0.10450822  || Decoder Loss:  0.48779655 Validation Decoder Loss:  0.67736745
Encoder Loss:  0.104128435  || Decoder Loss:  0.48371816 Validation Decoder Loss:  0.74094653
Encoder Loss:  0.10051721  || Decoder Loss:  0.48198685 Validation Decoder Loss:  0.72329676
Encoder Loss:  0.10103191  || Decoder Loss:  0.48336613 Validation Decoder Loss:  0.6847884
Encoder Loss:  0.10117925  || Decoder Loss:  0.47813323 Validation Decoder Loss:  0.7065245
Encoder Loss:  0.09636592  || Decoder Loss:  0.48195854 Validation Decoder Loss:  0.7371734
Encoder Loss:  0.09479052  || Decoder Loss:  0.47742966 Validation Decoder Loss:  0.7682644
Encoder Loss:  0.09582832  || Decoder Loss:  0.4799652 Validation Decoder Loss:  0.7398589
Encoder Loss:  0.09740314  || Decoder Loss:  0.48472995 Validation Decoder Loss:  0.8254912
Encoder Loss:  0.09422918  || Decoder Loss:  0.4767004 Validation Decoder Loss:  0.80996406
Encoder Loss:  0.10095663  || Decoder Loss:  0.47159877 Validation Decoder Loss:  0.8710874
Encoder Loss:  0.09468646  || Decoder Loss:  0.4775455 Validation Decoder Loss:  0.8369464
Encoder Loss:  0.09211318  || Decoder Loss:  0.47252834 Validation Decoder Loss:  0.8864214
Encoder Loss:  0.09279427  || Decoder Loss:  0.4714502 Validation Decoder Loss:  0.9270388
Model: siamese_net_lr_0.07652549516398821 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9270388
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 155, 14, 20, 1)    175       
_________________________________________________________________
reshape_49 (Reshape)         (None, 2170, 20, 1)       0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 2170, 20, 1)       1077      
=================================================================
Total params: 1,077
Trainable params: 1,077
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 3245, 20, 1)       1077      
=================================================================
Total params: 1,077
Trainable params: 1,077
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.67202616  || Decoder Loss:  0.9082609 Validation Decoder Loss:  1.6360028
Encoder Loss:  0.68895906  || Decoder Loss:  0.92450833 Validation Decoder Loss:  1.6347183
Encoder Loss:  0.6884814  || Decoder Loss:  0.92362237 Validation Decoder Loss:  1.6330556
Encoder Loss:  0.6878295  || Decoder Loss:  0.92245764 Validation Decoder Loss:  1.6309476
Encoder Loss:  0.68699455  || Decoder Loss:  0.9209666 Validation Decoder Loss:  1.6282952
Encoder Loss:  0.6859204  || Decoder Loss:  0.9190436 Validation Decoder Loss:  1.6248914
Encoder Loss:  0.6844881  || Decoder Loss:  0.91646636 Validation Decoder Loss:  1.6202835
Encoder Loss:  0.6824218  || Decoder Loss:  0.9127127 Validation Decoder Loss:  1.6133072
Encoder Loss:  0.67887306  || Decoder Loss:  0.9061577 Validation Decoder Loss:  1.5995696
Encoder Loss:  0.66766566  || Decoder Loss:  0.884731 Validation Decoder Loss:  1.5084116
Encoder Loss:  0.3346942  || Decoder Loss:  0.22811732 Validation Decoder Loss:  0.35216898
Encoder Loss:  0.24439886  || Decoder Loss:  0.06690928 Validation Decoder Loss:  0.3520617
Encoder Loss:  0.25448704  || Decoder Loss:  0.06714386 Validation Decoder Loss:  0.35124567
Encoder Loss:  0.25432247  || Decoder Loss:  0.0671269 Validation Decoder Loss:  0.35038978
Encoder Loss:  0.25408265  || Decoder Loss:  0.06710474 Validation Decoder Loss:  0.3495391
Encoder Loss:  0.25378585  || Decoder Loss:  0.06709942 Validation Decoder Loss:  0.34870324
Encoder Loss:  0.25340343  || Decoder Loss:  0.067119926 Validation Decoder Loss:  0.34789234
Encoder Loss:  0.25287768  || Decoder Loss:  0.06717926 Validation Decoder Loss:  0.34712297
Encoder Loss:  0.25208893  || Decoder Loss:  0.06730164 Validation Decoder Loss:  0.3464275
Encoder Loss:  0.25075093  || Decoder Loss:  0.06754002 Validation Decoder Loss:  0.3458854
Encoder Loss:  0.24798597  || Decoder Loss:  0.068046 Validation Decoder Loss:  0.34577695
Encoder Loss:  0.23899029  || Decoder Loss:  0.06961691 Validation Decoder Loss:  0.348657
Encoder Loss:  0.30978432  || Decoder Loss:  0.39922798 Validation Decoder Loss:  0.66268957
Encoder Loss:  0.2677349  || Decoder Loss:  0.45358607 Validation Decoder Loss:  1.3286195
Encoder Loss:  0.26083302  || Decoder Loss:  0.44846442 Validation Decoder Loss:  1.2080653
Encoder Loss:  0.244944  || Decoder Loss:  0.4198351 Validation Decoder Loss:  1.1010982
Encoder Loss:  0.23754522  || Decoder Loss:  0.40880105 Validation Decoder Loss:  1.1389804
Encoder Loss:  0.24490772  || Decoder Loss:  0.4215263 Validation Decoder Loss:  1.0193725
Encoder Loss:  0.22919558  || Decoder Loss:  0.3960624 Validation Decoder Loss:  1.0443302
Encoder Loss:  0.24979386  || Decoder Loss:  0.43719468 Validation Decoder Loss:  1.0048723
Encoder Loss:  0.26797047  || Decoder Loss:  0.47173756 Validation Decoder Loss:  0.9851327
Encoder Loss:  0.27159846  || Decoder Loss:  0.4829679 Validation Decoder Loss:  1.0506966
Encoder Loss:  0.26413062  || Decoder Loss:  0.4644278 Validation Decoder Loss:  1.0376732
Encoder Loss:  0.25510028  || Decoder Loss:  0.44697624 Validation Decoder Loss:  1.0294977
Encoder Loss:  0.22553739  || Decoder Loss:  0.38944465 Validation Decoder Loss:  0.8833073
Encoder Loss:  0.2796279  || Decoder Loss:  0.49077883 Validation Decoder Loss:  0.9632398
Encoder Loss:  0.2842396  || Decoder Loss:  0.4981202 Validation Decoder Loss:  1.0294347
Encoder Loss:  0.28059712  || Decoder Loss:  0.49731332 Validation Decoder Loss:  1.0181587
Encoder Loss:  0.2816265  || Decoder Loss:  0.4977827 Validation Decoder Loss:  0.96629995
Encoder Loss:  0.28227752  || Decoder Loss:  0.49077007 Validation Decoder Loss:  0.98591864
Model: siamese_net_lr_0.06610889515716295 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.98591864
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 154, 5, 20, 1)     92        
_________________________________________________________________
reshape_50 (Reshape)         (None, 770, 20, 1)        0         
=================================================================
Total params: 92
Trainable params: 92
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 770, 20, 1)        170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 3245, 20, 1)       1708      
=================================================================
Total params: 1,708
Trainable params: 1,708
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.439302  || Decoder Loss:  0.8932125 Validation Decoder Loss:  1.6396056
Encoder Loss:  0.44551334  || Decoder Loss:  0.9089439 Validation Decoder Loss:  1.6376069
Encoder Loss:  0.44504014  || Decoder Loss:  0.9071085 Validation Decoder Loss:  1.6349158
Encoder Loss:  0.4443848  || Decoder Loss:  0.9047708 Validation Decoder Loss:  1.6315404
Encoder Loss:  0.4434956  || Decoder Loss:  0.9019105 Validation Decoder Loss:  1.6274142
Encoder Loss:  0.44229355  || Decoder Loss:  0.8984671 Validation Decoder Loss:  1.6224061
Encoder Loss:  0.44065148  || Decoder Loss:  0.894327 Validation Decoder Loss:  1.6162932
Encoder Loss:  0.43835095  || Decoder Loss:  0.8892915 Validation Decoder Loss:  1.6086917
Encoder Loss:  0.4349739  || Decoder Loss:  0.8830021 Validation Decoder Loss:  1.5988894
Encoder Loss:  0.42957506  || Decoder Loss:  0.8747325 Validation Decoder Loss:  1.585328
Encoder Loss:  0.41929233  || Decoder Loss:  0.86260706 Validation Decoder Loss:  1.5631592
Encoder Loss:  0.38619775  || Decoder Loss:  0.8367498 Validation Decoder Loss:  1.479886
Encoder Loss:  0.17883001  || Decoder Loss:  0.49060836 Validation Decoder Loss:  0.9772721
Encoder Loss:  0.08223343  || Decoder Loss:  0.50079954 Validation Decoder Loss:  0.83600354
Encoder Loss:  0.07967503  || Decoder Loss:  0.5003588 Validation Decoder Loss:  0.83779496
Encoder Loss:  0.078239  || Decoder Loss:  0.50092745 Validation Decoder Loss:  0.816754
Encoder Loss:  0.075997755  || Decoder Loss:  0.49863565 Validation Decoder Loss:  0.7944859
Encoder Loss:  0.07362831  || Decoder Loss:  0.49488908 Validation Decoder Loss:  0.7900552
Encoder Loss:  0.071882516  || Decoder Loss:  0.49520925 Validation Decoder Loss:  0.81469166
Encoder Loss:  0.06843433  || Decoder Loss:  0.49489304 Validation Decoder Loss:  0.83920884
Encoder Loss:  0.066331394  || Decoder Loss:  0.49040616 Validation Decoder Loss:  0.8495939
Encoder Loss:  0.057542134  || Decoder Loss:  0.4960014 Validation Decoder Loss:  0.87388116
Encoder Loss:  0.05202293  || Decoder Loss:  0.49067366 Validation Decoder Loss:  0.87557715
Encoder Loss:  0.05117208  || Decoder Loss:  0.49188432 Validation Decoder Loss:  0.8757916
Encoder Loss:  0.05091696  || Decoder Loss:  0.48717296 Validation Decoder Loss:  0.8817789
Encoder Loss:  0.05081432  || Decoder Loss:  0.48191768 Validation Decoder Loss:  0.86655676
Encoder Loss:  0.05318203  || Decoder Loss:  0.47886184 Validation Decoder Loss:  0.88905346
Encoder Loss:  0.056549776  || Decoder Loss:  0.48172915 Validation Decoder Loss:  0.90521145
Encoder Loss:  0.0528197  || Decoder Loss:  0.4838097 Validation Decoder Loss:  0.899011
Encoder Loss:  0.05234288  || Decoder Loss:  0.48127526 Validation Decoder Loss:  0.9372654
Encoder Loss:  0.051196814  || Decoder Loss:  0.4801593 Validation Decoder Loss:  0.9354699
Encoder Loss:  0.050936718  || Decoder Loss:  0.47459498 Validation Decoder Loss:  0.9341705
Encoder Loss:  0.05036999  || Decoder Loss:  0.4734894 Validation Decoder Loss:  0.9394329
Encoder Loss:  0.05021427  || Decoder Loss:  0.4728937 Validation Decoder Loss:  0.949184
Encoder Loss:  0.050192147  || Decoder Loss:  0.47039428 Validation Decoder Loss:  0.9650206
Encoder Loss:  0.050249223  || Decoder Loss:  0.46675968 Validation Decoder Loss:  0.99107254
Encoder Loss:  0.050251734  || Decoder Loss:  0.46391892 Validation Decoder Loss:  0.9942942
Encoder Loss:  0.05031921  || Decoder Loss:  0.45624778 Validation Decoder Loss:  1.0306828
Encoder Loss:  0.050302792  || Decoder Loss:  0.44654748 Validation Decoder Loss:  1.0889728
Encoder Loss:  0.050141983  || Decoder Loss:  0.4420402 Validation Decoder Loss:  1.1235353
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1235353
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 302, 10, 20, 1)    301       
_________________________________________________________________
reshape_51 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7111963  || Decoder Loss:  0.9383025 Validation Decoder Loss:  1.6530253
Encoder Loss:  0.72870725  || Decoder Loss:  0.9629119 Validation Decoder Loss:  1.653364
Encoder Loss:  0.7285018  || Decoder Loss:  0.9627495 Validation Decoder Loss:  1.6537689
Encoder Loss:  0.7282188  || Decoder Loss:  0.9625268 Validation Decoder Loss:  1.6542835
Encoder Loss:  0.7278446  || Decoder Loss:  0.96224266 Validation Decoder Loss:  1.6549273
Encoder Loss:  0.72734755  || Decoder Loss:  0.9618851 Validation Decoder Loss:  1.6557262
Encoder Loss:  0.72666776  || Decoder Loss:  0.961432 Validation Decoder Loss:  1.6567211
Encoder Loss:  0.7256838  || Decoder Loss:  0.9608421 Validation Decoder Loss:  1.6579765
Encoder Loss:  0.72411245  || Decoder Loss:  0.9600318 Validation Decoder Loss:  1.6596057
Encoder Loss:  0.7211518  || Decoder Loss:  0.9587811 Validation Decoder Loss:  1.6618161
Encoder Loss:  0.71342325  || Decoder Loss:  0.9561027 Validation Decoder Loss:  1.6645037
Encoder Loss:  0.578047  || Decoder Loss:  0.80560297 Validation Decoder Loss:  1.5135303
Encoder Loss:  0.37368897  || Decoder Loss:  0.5811468 Validation Decoder Loss:  1.19975
Encoder Loss:  0.29205263  || Decoder Loss:  0.47327176 Validation Decoder Loss:  1.2350624
Encoder Loss:  0.2897566  || Decoder Loss:  0.47387996 Validation Decoder Loss:  1.1245466
Encoder Loss:  0.2685389  || Decoder Loss:  0.43906564 Validation Decoder Loss:  1.0268643
Encoder Loss:  0.26677835  || Decoder Loss:  0.43918437 Validation Decoder Loss:  1.0769217
Encoder Loss:  0.24708423  || Decoder Loss:  0.4036297 Validation Decoder Loss:  0.9464763
Encoder Loss:  0.19228472  || Decoder Loss:  0.3057025 Validation Decoder Loss:  0.6845618
Encoder Loss:  0.14450377  || Decoder Loss:  0.21964365 Validation Decoder Loss:  0.5946192
Encoder Loss:  0.132391  || Decoder Loss:  0.19488442 Validation Decoder Loss:  0.64370394
Encoder Loss:  0.10633492  || Decoder Loss:  0.14806087 Validation Decoder Loss:  0.37354118
Encoder Loss:  0.053435773  || Decoder Loss:  0.05113299 Validation Decoder Loss:  0.3479957
Encoder Loss:  0.046777047  || Decoder Loss:  0.037124764 Validation Decoder Loss:  0.3471142
Encoder Loss:  0.044955168  || Decoder Loss:  0.036093276 Validation Decoder Loss:  0.3496873
Encoder Loss:  0.045852747  || Decoder Loss:  0.036103442 Validation Decoder Loss:  0.35542977
Encoder Loss:  0.047375984  || Decoder Loss:  0.037149858 Validation Decoder Loss:  0.35849065
Encoder Loss:  0.047761694  || Decoder Loss:  0.038557123 Validation Decoder Loss:  0.34860802
Encoder Loss:  0.04435037  || Decoder Loss:  0.035347816 Validation Decoder Loss:  0.3542465
Encoder Loss:  0.04979047  || Decoder Loss:  0.03824258 Validation Decoder Loss:  0.34744614
Encoder Loss:  0.04502688  || Decoder Loss:  0.03545615 Validation Decoder Loss:  0.35268706
Encoder Loss:  0.04503592  || Decoder Loss:  0.036974385 Validation Decoder Loss:  0.354266
Encoder Loss:  0.04595017  || Decoder Loss:  0.038119763 Validation Decoder Loss:  0.3496759
Encoder Loss:  0.044110302  || Decoder Loss:  0.03610738 Validation Decoder Loss:  0.35205954
Encoder Loss:  0.044259496  || Decoder Loss:  0.036563985 Validation Decoder Loss:  0.3486421
Encoder Loss:  0.044554707  || Decoder Loss:  0.035541028 Validation Decoder Loss:  0.35114822
Encoder Loss:  0.044510785  || Decoder Loss:  0.036737137 Validation Decoder Loss:  0.3529365
Encoder Loss:  0.046934843  || Decoder Loss:  0.03731964 Validation Decoder Loss:  0.35095417
Encoder Loss:  0.045731004  || Decoder Loss:  0.036430184 Validation Decoder Loss:  0.35151014
Encoder Loss:  0.046222545  || Decoder Loss:  0.036690712 Validation Decoder Loss:  0.3562375
Model: siamese_net_lr_0.04250055510466156 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3562375
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 634, 5, 20, 1)     257       
_________________________________________________________________
reshape_52 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051423408  || Decoder Loss:  0.051423408 Validation Decoder Loss:  0.34785628
Encoder Loss:  0.034149706  || Decoder Loss:  0.034149706 Validation Decoder Loss:  0.34784305
Encoder Loss:  0.03412857  || Decoder Loss:  0.03412857 Validation Decoder Loss:  0.347831
Encoder Loss:  0.03410539  || Decoder Loss:  0.03410539 Validation Decoder Loss:  0.347818
Encoder Loss:  0.03408029  || Decoder Loss:  0.03408029 Validation Decoder Loss:  0.34780425
Encoder Loss:  0.034054063  || Decoder Loss:  0.034054063 Validation Decoder Loss:  0.34779018
Encoder Loss:  0.034027424  || Decoder Loss:  0.034027424 Validation Decoder Loss:  0.3477762
Encoder Loss:  0.034000933  || Decoder Loss:  0.034000933 Validation Decoder Loss:  0.34776255
Encoder Loss:  0.033975054  || Decoder Loss:  0.033975054 Validation Decoder Loss:  0.34774944
Encoder Loss:  0.033950124  || Decoder Loss:  0.033950124 Validation Decoder Loss:  0.34773707
Encoder Loss:  0.03392643  || Decoder Loss:  0.03392643 Validation Decoder Loss:  0.3477255
Encoder Loss:  0.033904158  || Decoder Loss:  0.033904158 Validation Decoder Loss:  0.34771484
Encoder Loss:  0.03388345  || Decoder Loss:  0.03388345 Validation Decoder Loss:  0.3477051
Encoder Loss:  0.033864368  || Decoder Loss:  0.033864368 Validation Decoder Loss:  0.3476963
Encoder Loss:  0.03384693  || Decoder Loss:  0.03384693 Validation Decoder Loss:  0.34768838
Encoder Loss:  0.03383113  || Decoder Loss:  0.03383113 Validation Decoder Loss:  0.34768137
Encoder Loss:  0.03381692  || Decoder Loss:  0.03381692 Validation Decoder Loss:  0.3476752
Encoder Loss:  0.03380422  || Decoder Loss:  0.03380422 Validation Decoder Loss:  0.34766987
Encoder Loss:  0.033792943  || Decoder Loss:  0.033792943 Validation Decoder Loss:  0.34766522
Encoder Loss:  0.033782985  || Decoder Loss:  0.033782985 Validation Decoder Loss:  0.34766126
Encoder Loss:  0.033774234  || Decoder Loss:  0.033774234 Validation Decoder Loss:  0.34765792
Encoder Loss:  0.03376659  || Decoder Loss:  0.03376659 Validation Decoder Loss:  0.34765515
Encoder Loss:  0.033759933  || Decoder Loss:  0.033759933 Validation Decoder Loss:  0.34765288
Encoder Loss:  0.033754144  || Decoder Loss:  0.033754144 Validation Decoder Loss:  0.347651
Encoder Loss:  0.03374914  || Decoder Loss:  0.03374914 Validation Decoder Loss:  0.3476495
Encoder Loss:  0.033744816  || Decoder Loss:  0.033744816 Validation Decoder Loss:  0.34764838
Encoder Loss:  0.03374108  || Decoder Loss:  0.03374108 Validation Decoder Loss:  0.34764752
Encoder Loss:  0.033737853  || Decoder Loss:  0.033737853 Validation Decoder Loss:  0.3476469
Encoder Loss:  0.03373507  || Decoder Loss:  0.03373507 Validation Decoder Loss:  0.34764653
Encoder Loss:  0.033732664  || Decoder Loss:  0.033732664 Validation Decoder Loss:  0.34764627
Encoder Loss:  0.033730578  || Decoder Loss:  0.033730578 Validation Decoder Loss:  0.3476462
Encoder Loss:  0.03372876  || Decoder Loss:  0.03372876 Validation Decoder Loss:  0.34764627
Encoder Loss:  0.033727176  || Decoder Loss:  0.033727176 Validation Decoder Loss:  0.34764645
Encoder Loss:  0.033725783  || Decoder Loss:  0.033725783 Validation Decoder Loss:  0.34764665
Encoder Loss:  0.03372455  || Decoder Loss:  0.03372455 Validation Decoder Loss:  0.34764698
Encoder Loss:  0.033723455  || Decoder Loss:  0.033723455 Validation Decoder Loss:  0.3476474
Encoder Loss:  0.033722475  || Decoder Loss:  0.033722475 Validation Decoder Loss:  0.3476478
Encoder Loss:  0.03372159  || Decoder Loss:  0.03372159 Validation Decoder Loss:  0.34764826
Encoder Loss:  0.03372078  || Decoder Loss:  0.03372078 Validation Decoder Loss:  0.34764874
Encoder Loss:  0.033720043  || Decoder Loss:  0.033720043 Validation Decoder Loss:  0.34764934
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3476493
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 317, 10, 20, 1)    131       
_________________________________________________________________
reshape_53 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.053864058  || Decoder Loss:  0.053864058 Validation Decoder Loss:  0.34536916
Encoder Loss:  0.035041515  || Decoder Loss:  0.035041515 Validation Decoder Loss:  0.3456947
Encoder Loss:  0.03473328  || Decoder Loss:  0.03473328 Validation Decoder Loss:  0.34609088
Encoder Loss:  0.034440774  || Decoder Loss:  0.034440774 Validation Decoder Loss:  0.3465271
Encoder Loss:  0.03420358  || Decoder Loss:  0.03420358 Validation Decoder Loss:  0.34695786
Encoder Loss:  0.034039807  || Decoder Loss:  0.034039807 Validation Decoder Loss:  0.34733966
Encoder Loss:  0.03394186  || Decoder Loss:  0.03394186 Validation Decoder Loss:  0.34764653
Encoder Loss:  0.033889238  || Decoder Loss:  0.033889238 Validation Decoder Loss:  0.34787446
Encoder Loss:  0.033862565  || Decoder Loss:  0.033862565 Validation Decoder Loss:  0.34803402
Encoder Loss:  0.03384912  || Decoder Loss:  0.03384912 Validation Decoder Loss:  0.34814134
Encoder Loss:  0.033842016  || Decoder Loss:  0.033842016 Validation Decoder Loss:  0.34821144
Encoder Loss:  0.033837892  || Decoder Loss:  0.033837892 Validation Decoder Loss:  0.3482566
Encoder Loss:  0.033835217  || Decoder Loss:  0.033835217 Validation Decoder Loss:  0.34828553
Encoder Loss:  0.033833284  || Decoder Loss:  0.033833284 Validation Decoder Loss:  0.3483042
Encoder Loss:  0.03383177  || Decoder Loss:  0.03383177 Validation Decoder Loss:  0.3483165
Encoder Loss:  0.03383051  || Decoder Loss:  0.03383051 Validation Decoder Loss:  0.34832487
Encoder Loss:  0.033829417  || Decoder Loss:  0.033829417 Validation Decoder Loss:  0.34833074
Encoder Loss:  0.03382845  || Decoder Loss:  0.03382845 Validation Decoder Loss:  0.34833497
Encoder Loss:  0.033827573  || Decoder Loss:  0.033827573 Validation Decoder Loss:  0.3483382
Encoder Loss:  0.033826765  || Decoder Loss:  0.033826765 Validation Decoder Loss:  0.3483407
Encoder Loss:  0.03382602  || Decoder Loss:  0.03382602 Validation Decoder Loss:  0.3483427
Encoder Loss:  0.033825323  || Decoder Loss:  0.033825323 Validation Decoder Loss:  0.34834427
Encoder Loss:  0.033824667  || Decoder Loss:  0.033824667 Validation Decoder Loss:  0.34834558
Encoder Loss:  0.033824064  || Decoder Loss:  0.033824064 Validation Decoder Loss:  0.3483467
Encoder Loss:  0.033823486  || Decoder Loss:  0.033823486 Validation Decoder Loss:  0.34834763
Encoder Loss:  0.033822957  || Decoder Loss:  0.033822957 Validation Decoder Loss:  0.34834844
Encoder Loss:  0.033822462  || Decoder Loss:  0.033822462 Validation Decoder Loss:  0.34834915
Encoder Loss:  0.033821985  || Decoder Loss:  0.033821985 Validation Decoder Loss:  0.34834978
Encoder Loss:  0.03382155  || Decoder Loss:  0.03382155 Validation Decoder Loss:  0.34835035
Encoder Loss:  0.033821143  || Decoder Loss:  0.033821143 Validation Decoder Loss:  0.34835088
Encoder Loss:  0.03382076  || Decoder Loss:  0.03382076 Validation Decoder Loss:  0.34835136
Encoder Loss:  0.033820406  || Decoder Loss:  0.033820406 Validation Decoder Loss:  0.3483518
Encoder Loss:  0.03382007  || Decoder Loss:  0.03382007 Validation Decoder Loss:  0.34835213
Encoder Loss:  0.033819754  || Decoder Loss:  0.033819754 Validation Decoder Loss:  0.34835255
Encoder Loss:  0.03381946  || Decoder Loss:  0.03381946 Validation Decoder Loss:  0.3483529
Encoder Loss:  0.0338192  || Decoder Loss:  0.0338192 Validation Decoder Loss:  0.3483532
Encoder Loss:  0.033818945  || Decoder Loss:  0.033818945 Validation Decoder Loss:  0.3483535
Encoder Loss:  0.033818707  || Decoder Loss:  0.033818707 Validation Decoder Loss:  0.3483538
Encoder Loss:  0.033818495  || Decoder Loss:  0.033818495 Validation Decoder Loss:  0.34835407
Encoder Loss:  0.03381829  || Decoder Loss:  0.03381829 Validation Decoder Loss:  0.34835434
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34835434
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 317, 10, 20, 1)    257       
_________________________________________________________________
reshape_54 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4734989  || Decoder Loss:  0.4734989 Validation Decoder Loss:  0.92386067
Encoder Loss:  0.4145061  || Decoder Loss:  0.4145061 Validation Decoder Loss:  0.82597053
Encoder Loss:  0.35549667  || Decoder Loss:  0.35549667 Validation Decoder Loss:  0.7408042
Encoder Loss:  0.3056456  || Decoder Loss:  0.3056456 Validation Decoder Loss:  0.6734772
Encoder Loss:  0.2659443  || Decoder Loss:  0.2659443 Validation Decoder Loss:  0.6220865
Encoder Loss:  0.23494714  || Decoder Loss:  0.23494714 Validation Decoder Loss:  0.5830033
Encoder Loss:  0.21069793  || Decoder Loss:  0.21069793 Validation Decoder Loss:  0.5529163
Encoder Loss:  0.19148636  || Decoder Loss:  0.19148636 Validation Decoder Loss:  0.5293271
Encoder Loss:  0.17601298  || Decoder Loss:  0.17601298 Validation Decoder Loss:  0.5104697
Encoder Loss:  0.1633384  || Decoder Loss:  0.1633384 Validation Decoder Loss:  0.4951148
Encoder Loss:  0.15279093  || Decoder Loss:  0.15279093 Validation Decoder Loss:  0.48240197
Encoder Loss:  0.14388753  || Decoder Loss:  0.14388753 Validation Decoder Loss:  0.47172022
Encoder Loss:  0.13627604  || Decoder Loss:  0.13627604 Validation Decoder Loss:  0.46262768
Encoder Loss:  0.12969574  || Decoder Loss:  0.12969574 Validation Decoder Loss:  0.454799
Encoder Loss:  0.12395037  || Decoder Loss:  0.12395037 Validation Decoder Loss:  0.4479903
Encoder Loss:  0.118889816  || Decoder Loss:  0.118889816 Validation Decoder Loss:  0.44201568
Encoder Loss:  0.11439769  || Decoder Loss:  0.11439769 Validation Decoder Loss:  0.43673137
Encoder Loss:  0.110382326  || Decoder Loss:  0.110382326 Validation Decoder Loss:  0.43202445
Encoder Loss:  0.10677071  || Decoder Loss:  0.10677071 Validation Decoder Loss:  0.4278052
Encoder Loss:  0.10350401  || Decoder Loss:  0.10350401 Validation Decoder Loss:  0.42400143
Encoder Loss:  0.10053422  || Decoder Loss:  0.10053422 Validation Decoder Loss:  0.42055452
Encoder Loss:  0.09782196  || Decoder Loss:  0.09782196 Validation Decoder Loss:  0.41741624
Encoder Loss:  0.09533446  || Decoder Loss:  0.09533446 Validation Decoder Loss:  0.4145467
Encoder Loss:  0.093044326  || Decoder Loss:  0.093044326 Validation Decoder Loss:  0.4119127
Encoder Loss:  0.090928465  || Decoder Loss:  0.090928465 Validation Decoder Loss:  0.40948611
Encoder Loss:  0.088967256  || Decoder Loss:  0.088967256 Validation Decoder Loss:  0.4072432
Encoder Loss:  0.087143935  || Decoder Loss:  0.087143935 Validation Decoder Loss:  0.4051637
Encoder Loss:  0.08544408  || Decoder Loss:  0.08544408 Validation Decoder Loss:  0.4032302
Encoder Loss:  0.083855264  || Decoder Loss:  0.083855264 Validation Decoder Loss:  0.40142778
Encoder Loss:  0.08236664  || Decoder Loss:  0.08236664 Validation Decoder Loss:  0.39974338
Encoder Loss:  0.08096876  || Decoder Loss:  0.08096876 Validation Decoder Loss:  0.39816558
Encoder Loss:  0.07965332  || Decoder Loss:  0.07965332 Validation Decoder Loss:  0.39668462
Encoder Loss:  0.078412995  || Decoder Loss:  0.078412995 Validation Decoder Loss:  0.39529163
Encoder Loss:  0.07724139  || Decoder Loss:  0.07724139 Validation Decoder Loss:  0.39397892
Encoder Loss:  0.07613272  || Decoder Loss:  0.07613272 Validation Decoder Loss:  0.3927397
Encoder Loss:  0.07508189  || Decoder Loss:  0.07508189 Validation Decoder Loss:  0.3915679
Encoder Loss:  0.07408434  || Decoder Loss:  0.07408434 Validation Decoder Loss:  0.39045805
Encoder Loss:  0.07313598  || Decoder Loss:  0.07313598 Validation Decoder Loss:  0.38940534
Encoder Loss:  0.07223311  || Decoder Loss:  0.07223311 Validation Decoder Loss:  0.3884054
Encoder Loss:  0.07137244  || Decoder Loss:  0.07137244 Validation Decoder Loss:  0.38745427
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38745427
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 634, 5, 20, 1)     572       
_________________________________________________________________
reshape_55 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 572
Trainable params: 572
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20415388  || Decoder Loss:  0.50027806 Validation Decoder Loss:  0.9945501
Encoder Loss:  0.17664298  || Decoder Loss:  0.43538776 Validation Decoder Loss:  0.917079
Encoder Loss:  0.15914589  || Decoder Loss:  0.38572663 Validation Decoder Loss:  0.83557904
Encoder Loss:  0.14479683  || Decoder Loss:  0.3402884 Validation Decoder Loss:  0.76758593
Encoder Loss:  0.1326905  || Decoder Loss:  0.30193985 Validation Decoder Loss:  0.71219033
Encoder Loss:  0.12268801  || Decoder Loss:  0.27045178 Validation Decoder Loss:  0.6675452
Encoder Loss:  0.11448108  || Decoder Loss:  0.24481301 Validation Decoder Loss:  0.6314624
Encoder Loss:  0.10767395  || Decoder Loss:  0.2238525 Validation Decoder Loss:  0.60235596
Encoder Loss:  0.10187628  || Decoder Loss:  0.20657948 Validation Decoder Loss:  0.5785562
Encoder Loss:  0.09720206  || Decoder Loss:  0.19230774 Validation Decoder Loss:  0.5583969
Encoder Loss:  0.09315037  || Decoder Loss:  0.18018727 Validation Decoder Loss:  0.54152346
Encoder Loss:  0.08963684  || Decoder Loss:  0.16982058 Validation Decoder Loss:  0.5270902
Encoder Loss:  0.086617544  || Decoder Loss:  0.16088805 Validation Decoder Loss:  0.5142989
Encoder Loss:  0.08427411  || Decoder Loss:  0.15311736 Validation Decoder Loss:  0.50346744
Encoder Loss:  0.081888884  || Decoder Loss:  0.14632463 Validation Decoder Loss:  0.49366432
Encoder Loss:  0.080224454  || Decoder Loss:  0.14030644 Validation Decoder Loss:  0.4853631
Encoder Loss:  0.07819141  || Decoder Loss:  0.13495517 Validation Decoder Loss:  0.4775663
Encoder Loss:  0.07704182  || Decoder Loss:  0.13015579 Validation Decoder Loss:  0.4710173
Encoder Loss:  0.07526238  || Decoder Loss:  0.12583973 Validation Decoder Loss:  0.4647292
Encoder Loss:  0.074201904  || Decoder Loss:  0.12191324 Validation Decoder Loss:  0.45931938
Encoder Loss:  0.07292119  || Decoder Loss:  0.118340686 Validation Decoder Loss:  0.45425677
Encoder Loss:  0.07188418  || Decoder Loss:  0.11507377 Validation Decoder Loss:  0.44966847
Encoder Loss:  0.07090409  || Decoder Loss:  0.1120757 Validation Decoder Loss:  0.44545805
Encoder Loss:  0.07000167  || Decoder Loss:  0.10930687 Validation Decoder Loss:  0.44158942
Encoder Loss:  0.06915184  || Decoder Loss:  0.10674558 Validation Decoder Loss:  0.43801615
Encoder Loss:  0.06836526  || Decoder Loss:  0.104370005 Validation Decoder Loss:  0.43468934
Encoder Loss:  0.06763877  || Decoder Loss:  0.10215429 Validation Decoder Loss:  0.43160546
Encoder Loss:  0.06696167  || Decoder Loss:  0.10008672 Validation Decoder Loss:  0.42872995
Encoder Loss:  0.066306  || Decoder Loss:  0.0981529 Validation Decoder Loss:  0.42604285
Encoder Loss:  0.06569407  || Decoder Loss:  0.09633753 Validation Decoder Loss:  0.4235226
Encoder Loss:  0.06512757  || Decoder Loss:  0.09463022 Validation Decoder Loss:  0.42115536
Encoder Loss:  0.06460538  || Decoder Loss:  0.093021125 Validation Decoder Loss:  0.41893074
Encoder Loss:  0.064129904  || Decoder Loss:  0.091503754 Validation Decoder Loss:  0.41684565
Encoder Loss:  0.06360228  || Decoder Loss:  0.090064675 Validation Decoder Loss:  0.41485888
Encoder Loss:  0.06316094  || Decoder Loss:  0.08870366 Validation Decoder Loss:  0.41298455
Encoder Loss:  0.062744945  || Decoder Loss:  0.08741126 Validation Decoder Loss:  0.41121122
Encoder Loss:  0.06237403  || Decoder Loss:  0.086185224 Validation Decoder Loss:  0.4095373
Encoder Loss:  0.061975535  || Decoder Loss:  0.085016586 Validation Decoder Loss:  0.40793696
Encoder Loss:  0.06156799  || Decoder Loss:  0.08389845 Validation Decoder Loss:  0.40640724
Encoder Loss:  0.061246853  || Decoder Loss:  0.08283526 Validation Decoder Loss:  0.40496054
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.4049605
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 302, 10, 20, 1)    301       
_________________________________________________________________
reshape_56 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.052482724  || Decoder Loss:  0.052482724 Validation Decoder Loss:  0.3440346
Encoder Loss:  0.033860493  || Decoder Loss:  0.033860493 Validation Decoder Loss:  0.34404176
Encoder Loss:  0.033848885  || Decoder Loss:  0.033848885 Validation Decoder Loss:  0.34405267
Encoder Loss:  0.03383545  || Decoder Loss:  0.03383545 Validation Decoder Loss:  0.34406576
Encoder Loss:  0.03382058  || Decoder Loss:  0.03382058 Validation Decoder Loss:  0.34408066
Encoder Loss:  0.0338047  || Decoder Loss:  0.0338047 Validation Decoder Loss:  0.34409705
Encoder Loss:  0.03378815  || Decoder Loss:  0.03378815 Validation Decoder Loss:  0.34411487
Encoder Loss:  0.033771217  || Decoder Loss:  0.033771217 Validation Decoder Loss:  0.34413394
Encoder Loss:  0.033754114  || Decoder Loss:  0.033754114 Validation Decoder Loss:  0.34415418
Encoder Loss:  0.033737022  || Decoder Loss:  0.033737022 Validation Decoder Loss:  0.34417543
Encoder Loss:  0.033720102  || Decoder Loss:  0.033720102 Validation Decoder Loss:  0.3441976
Encoder Loss:  0.03370346  || Decoder Loss:  0.03370346 Validation Decoder Loss:  0.34422058
Encoder Loss:  0.03368719  || Decoder Loss:  0.03368719 Validation Decoder Loss:  0.34424424
Encoder Loss:  0.033671364  || Decoder Loss:  0.033671364 Validation Decoder Loss:  0.34426856
Encoder Loss:  0.03365603  || Decoder Loss:  0.03365603 Validation Decoder Loss:  0.34429342
Encoder Loss:  0.03364121  || Decoder Loss:  0.03364121 Validation Decoder Loss:  0.3443187
Encoder Loss:  0.033626936  || Decoder Loss:  0.033626936 Validation Decoder Loss:  0.34434432
Encoder Loss:  0.033613216  || Decoder Loss:  0.033613216 Validation Decoder Loss:  0.3443702
Encoder Loss:  0.033600036  || Decoder Loss:  0.033600036 Validation Decoder Loss:  0.3443963
Encoder Loss:  0.033587392  || Decoder Loss:  0.033587392 Validation Decoder Loss:  0.34442258
Encoder Loss:  0.033575274  || Decoder Loss:  0.033575274 Validation Decoder Loss:  0.3444489
Encoder Loss:  0.03356366  || Decoder Loss:  0.03356366 Validation Decoder Loss:  0.34447527
Encoder Loss:  0.03355253  || Decoder Loss:  0.03355253 Validation Decoder Loss:  0.3445016
Encoder Loss:  0.033541866  || Decoder Loss:  0.033541866 Validation Decoder Loss:  0.3445279
Encoder Loss:  0.033531643  || Decoder Loss:  0.033531643 Validation Decoder Loss:  0.3445541
Encoder Loss:  0.033521827  || Decoder Loss:  0.033521827 Validation Decoder Loss:  0.3445801
Encoder Loss:  0.033512402  || Decoder Loss:  0.033512402 Validation Decoder Loss:  0.34460604
Encoder Loss:  0.033503357  || Decoder Loss:  0.033503357 Validation Decoder Loss:  0.3446318
Encoder Loss:  0.033494648  || Decoder Loss:  0.033494648 Validation Decoder Loss:  0.3446573
Encoder Loss:  0.03348627  || Decoder Loss:  0.03348627 Validation Decoder Loss:  0.34468257
Encoder Loss:  0.033478197  || Decoder Loss:  0.033478197 Validation Decoder Loss:  0.34470767
Encoder Loss:  0.033470407  || Decoder Loss:  0.033470407 Validation Decoder Loss:  0.34473246
Encoder Loss:  0.033462893  || Decoder Loss:  0.033462893 Validation Decoder Loss:  0.34475702
Encoder Loss:  0.033455633  || Decoder Loss:  0.033455633 Validation Decoder Loss:  0.3447813
Encoder Loss:  0.033448614  || Decoder Loss:  0.033448614 Validation Decoder Loss:  0.3448054
Encoder Loss:  0.03344182  || Decoder Loss:  0.03344182 Validation Decoder Loss:  0.34482914
Encoder Loss:  0.03343524  || Decoder Loss:  0.03343524 Validation Decoder Loss:  0.34485263
Encoder Loss:  0.03342887  || Decoder Loss:  0.03342887 Validation Decoder Loss:  0.34487587
Encoder Loss:  0.03342269  || Decoder Loss:  0.03342269 Validation Decoder Loss:  0.34489882
Encoder Loss:  0.033416696  || Decoder Loss:  0.033416696 Validation Decoder Loss:  0.3449215
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3449215
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 454, 5, 20, 1)     140       
_________________________________________________________________
reshape_57 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 140
Trainable params: 140
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06388447  || Decoder Loss:  0.06388447 Validation Decoder Loss:  0.36661237
Encoder Loss:  0.042696785  || Decoder Loss:  0.042696785 Validation Decoder Loss:  0.36621618
Encoder Loss:  0.042421516  || Decoder Loss:  0.042421516 Validation Decoder Loss:  0.36573038
Encoder Loss:  0.042095706  || Decoder Loss:  0.042095706 Validation Decoder Loss:  0.36516964
Encoder Loss:  0.041729525  || Decoder Loss:  0.041729525 Validation Decoder Loss:  0.36454964
Encoder Loss:  0.041332275  || Decoder Loss:  0.041332275 Validation Decoder Loss:  0.36388293
Encoder Loss:  0.040911555  || Decoder Loss:  0.040911555 Validation Decoder Loss:  0.3631799
Encoder Loss:  0.040473703  || Decoder Loss:  0.040473703 Validation Decoder Loss:  0.3624491
Encoder Loss:  0.040024176  || Decoder Loss:  0.040024176 Validation Decoder Loss:  0.3616979
Encoder Loss:  0.039567757  || Decoder Loss:  0.039567757 Validation Decoder Loss:  0.3609329
Encoder Loss:  0.039108742  || Decoder Loss:  0.039108742 Validation Decoder Loss:  0.36015972
Encoder Loss:  0.038650997  || Decoder Loss:  0.038650997 Validation Decoder Loss:  0.3593836
Encoder Loss:  0.038198035  || Decoder Loss:  0.038198035 Validation Decoder Loss:  0.35860926
Encoder Loss:  0.037753068  || Decoder Loss:  0.037753068 Validation Decoder Loss:  0.357841
Encoder Loss:  0.037319057  || Decoder Loss:  0.037319057 Validation Decoder Loss:  0.35708278
Encoder Loss:  0.036898676  || Decoder Loss:  0.036898676 Validation Decoder Loss:  0.35633826
Encoder Loss:  0.03649435  || Decoder Loss:  0.03649435 Validation Decoder Loss:  0.35561076
Encoder Loss:  0.03610824  || Decoder Loss:  0.03610824 Validation Decoder Loss:  0.35490352
Encoder Loss:  0.035742246  || Decoder Loss:  0.035742246 Validation Decoder Loss:  0.3542192
Encoder Loss:  0.035397932  || Decoder Loss:  0.035397932 Validation Decoder Loss:  0.3535606
Encoder Loss:  0.03507659  || Decoder Loss:  0.03507659 Validation Decoder Loss:  0.35292983
Encoder Loss:  0.03477912  || Decoder Loss:  0.03477912 Validation Decoder Loss:  0.35232896
Encoder Loss:  0.034506083  || Decoder Loss:  0.034506083 Validation Decoder Loss:  0.35175955
Encoder Loss:  0.034257658  || Decoder Loss:  0.034257658 Validation Decoder Loss:  0.35122293
Encoder Loss:  0.034033626  || Decoder Loss:  0.034033626 Validation Decoder Loss:  0.35072
Encoder Loss:  0.033833407  || Decoder Loss:  0.033833407 Validation Decoder Loss:  0.3502512
Encoder Loss:  0.033656076  || Decoder Loss:  0.033656076 Validation Decoder Loss:  0.34981665
Encoder Loss:  0.033500385  || Decoder Loss:  0.033500385 Validation Decoder Loss:  0.34941617
Encoder Loss:  0.033364844  || Decoder Loss:  0.033364844 Validation Decoder Loss:  0.349049
Encoder Loss:  0.03324776  || Decoder Loss:  0.03324776 Validation Decoder Loss:  0.34871423
Encoder Loss:  0.033147313  || Decoder Loss:  0.033147313 Validation Decoder Loss:  0.34841058
Encoder Loss:  0.03306163  || Decoder Loss:  0.03306163 Validation Decoder Loss:  0.3481365
Encoder Loss:  0.032988854  || Decoder Loss:  0.032988854 Validation Decoder Loss:  0.34789038
Encoder Loss:  0.032927174  || Decoder Loss:  0.032927174 Validation Decoder Loss:  0.34767026
Encoder Loss:  0.032874927  || Decoder Loss:  0.032874927 Validation Decoder Loss:  0.34747428
Encoder Loss:  0.03283056  || Decoder Loss:  0.03283056 Validation Decoder Loss:  0.3473005
Encoder Loss:  0.0327927  || Decoder Loss:  0.0327927 Validation Decoder Loss:  0.347147
Encoder Loss:  0.032760173  || Decoder Loss:  0.032760173 Validation Decoder Loss:  0.3470118
Encoder Loss:  0.032731954  || Decoder Loss:  0.032731954 Validation Decoder Loss:  0.34689322
Encoder Loss:  0.032707185  || Decoder Loss:  0.032707185 Validation Decoder Loss:  0.34678942
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34678945
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 454, 5, 20, 1)     392       
_________________________________________________________________
reshape_58 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 392
Trainable params: 392
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15577444  || Decoder Loss:  0.5193499 Validation Decoder Loss:  1.2168591
Encoder Loss:  0.0648133  || Decoder Loss:  0.49664566 Validation Decoder Loss:  1.217945
Encoder Loss:  0.06431238  || Decoder Loss:  0.49760938 Validation Decoder Loss:  1.1441672
Encoder Loss:  0.061297584  || Decoder Loss:  0.5003964 Validation Decoder Loss:  1.1610098
Encoder Loss:  0.056917135  || Decoder Loss:  0.4948226 Validation Decoder Loss:  1.164379
Encoder Loss:  0.06453682  || Decoder Loss:  0.49656555 Validation Decoder Loss:  1.1327367
Encoder Loss:  0.06461811  || Decoder Loss:  0.50368476 Validation Decoder Loss:  0.9878062
Encoder Loss:  0.08577374  || Decoder Loss:  0.47118324 Validation Decoder Loss:  1.0881174
Encoder Loss:  0.060636416  || Decoder Loss:  0.49592236 Validation Decoder Loss:  1.1567631
Encoder Loss:  0.07412103  || Decoder Loss:  0.48780596 Validation Decoder Loss:  1.2791773
Encoder Loss:  0.07718283  || Decoder Loss:  0.4955582 Validation Decoder Loss:  1.282267
Encoder Loss:  0.06968662  || Decoder Loss:  0.4967666 Validation Decoder Loss:  1.079077
Encoder Loss:  0.069918245  || Decoder Loss:  0.49064744 Validation Decoder Loss:  1.1897712
Encoder Loss:  0.057416935  || Decoder Loss:  0.4942341 Validation Decoder Loss:  1.206006
Encoder Loss:  0.055435315  || Decoder Loss:  0.4927023 Validation Decoder Loss:  1.1386315
Encoder Loss:  0.05647408  || Decoder Loss:  0.49289474 Validation Decoder Loss:  1.1567955
Encoder Loss:  0.05619606  || Decoder Loss:  0.4871417 Validation Decoder Loss:  1.1306226
Encoder Loss:  0.06162447  || Decoder Loss:  0.48872346 Validation Decoder Loss:  1.1206362
Encoder Loss:  0.056011938  || Decoder Loss:  0.48461464 Validation Decoder Loss:  1.1516502
Encoder Loss:  0.05950718  || Decoder Loss:  0.48899543 Validation Decoder Loss:  1.0708839
Encoder Loss:  0.06284105  || Decoder Loss:  0.4779081 Validation Decoder Loss:  1.096679
Encoder Loss:  0.05651091  || Decoder Loss:  0.4806374 Validation Decoder Loss:  1.0420535
Encoder Loss:  0.05978118  || Decoder Loss:  0.47880614 Validation Decoder Loss:  1.0487874
Encoder Loss:  0.05545494  || Decoder Loss:  0.47936237 Validation Decoder Loss:  1.0445552
Encoder Loss:  0.059582166  || Decoder Loss:  0.47976425 Validation Decoder Loss:  1.0347111
Encoder Loss:  0.0560055  || Decoder Loss:  0.47692055 Validation Decoder Loss:  1.0704277
Encoder Loss:  0.059490208  || Decoder Loss:  0.47539082 Validation Decoder Loss:  1.0809445
Encoder Loss:  0.055471886  || Decoder Loss:  0.47246853 Validation Decoder Loss:  1.0689285
Encoder Loss:  0.057538114  || Decoder Loss:  0.46891877 Validation Decoder Loss:  1.1418796
Encoder Loss:  0.067423075  || Decoder Loss:  0.47050643 Validation Decoder Loss:  1.0723615
Encoder Loss:  0.058986574  || Decoder Loss:  0.46134645 Validation Decoder Loss:  0.8835499
Encoder Loss:  0.058189955  || Decoder Loss:  0.46977857 Validation Decoder Loss:  0.9930032
Encoder Loss:  0.056386765  || Decoder Loss:  0.4482497 Validation Decoder Loss:  0.98636913
Encoder Loss:  0.063588046  || Decoder Loss:  0.45875823 Validation Decoder Loss:  0.9266908
Encoder Loss:  0.05608702  || Decoder Loss:  0.4743359 Validation Decoder Loss:  1.1603181
Encoder Loss:  0.057484083  || Decoder Loss:  0.45143306 Validation Decoder Loss:  1.0082438
Encoder Loss:  0.054362785  || Decoder Loss:  0.45574936 Validation Decoder Loss:  0.969824
Encoder Loss:  0.055474292  || Decoder Loss:  0.45471257 Validation Decoder Loss:  1.157069
Encoder Loss:  0.058029868  || Decoder Loss:  0.49832493 Validation Decoder Loss:  1.1595455
Encoder Loss:  0.057942208  || Decoder Loss:  0.49679658 Validation Decoder Loss:  1.1827404
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1827404
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 634, 5, 20, 1)     194       
_________________________________________________________________
reshape_59 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.87096506  || Decoder Loss:  0.9429308 Validation Decoder Loss:  1.6587852
Encoder Loss:  0.8928077  || Decoder Loss:  0.96710837 Validation Decoder Loss:  1.6588025
Encoder Loss:  0.89260983  || Decoder Loss:  0.967095 Validation Decoder Loss:  1.658808
Encoder Loss:  0.88167983  || Decoder Loss:  0.9670754 Validation Decoder Loss:  1.6588079
Encoder Loss:  0.89190537  || Decoder Loss:  0.96705353 Validation Decoder Loss:  1.6588099
Encoder Loss:  0.8919364  || Decoder Loss:  0.96702546 Validation Decoder Loss:  1.6588137
Encoder Loss:  0.8917292  || Decoder Loss:  0.96699333 Validation Decoder Loss:  1.6588165
Encoder Loss:  0.89133066  || Decoder Loss:  0.96695703 Validation Decoder Loss:  1.6588173
Encoder Loss:  0.8899904  || Decoder Loss:  0.96691585 Validation Decoder Loss:  1.6588156
Encoder Loss:  0.88490194  || Decoder Loss:  0.9668705 Validation Decoder Loss:  1.658803
Encoder Loss:  0.8912948  || Decoder Loss:  0.9668283 Validation Decoder Loss:  1.65878
Encoder Loss:  0.8890755  || Decoder Loss:  0.96678483 Validation Decoder Loss:  1.6587479
Encoder Loss:  0.87246656  || Decoder Loss:  0.96674126 Validation Decoder Loss:  1.6586982
Encoder Loss:  0.8507  || Decoder Loss:  0.9666982 Validation Decoder Loss:  1.6586158
Encoder Loss:  0.85088134  || Decoder Loss:  0.96665925 Validation Decoder Loss:  1.6585042
Encoder Loss:  0.8457487  || Decoder Loss:  0.9666164 Validation Decoder Loss:  1.6583713
Encoder Loss:  0.8459021  || Decoder Loss:  0.96656936 Validation Decoder Loss:  1.6582079
Encoder Loss:  0.8433175  || Decoder Loss:  0.96651536 Validation Decoder Loss:  1.6580144
Encoder Loss:  0.8415404  || Decoder Loss:  0.96645284 Validation Decoder Loss:  1.6577688
Encoder Loss:  0.8414055  || Decoder Loss:  0.96637946 Validation Decoder Loss:  1.6574628
Encoder Loss:  0.83920306  || Decoder Loss:  0.96628517 Validation Decoder Loss:  1.6570673
Encoder Loss:  0.8380629  || Decoder Loss:  0.96616066 Validation Decoder Loss:  1.6565278
Encoder Loss:  0.8388857  || Decoder Loss:  0.9659802 Validation Decoder Loss:  1.6557324
Encoder Loss:  0.8399084  || Decoder Loss:  0.96567786 Validation Decoder Loss:  1.654361
Encoder Loss:  0.83725625  || Decoder Loss:  0.9649971 Validation Decoder Loss:  1.6508054
Encoder Loss:  0.6729699  || Decoder Loss:  0.7750816 Validation Decoder Loss:  0.33726287
Encoder Loss:  0.037285563  || Decoder Loss:  0.032931972 Validation Decoder Loss:  0.33874032
Encoder Loss:  0.037796065  || Decoder Loss:  0.03293767 Validation Decoder Loss:  0.33878896
Encoder Loss:  0.037259407  || Decoder Loss:  0.032940418 Validation Decoder Loss:  0.3387864
Encoder Loss:  0.039828084  || Decoder Loss:  0.032943536 Validation Decoder Loss:  0.33878037
Encoder Loss:  0.04036347  || Decoder Loss:  0.032947265 Validation Decoder Loss:  0.338772
Encoder Loss:  0.037277747  || Decoder Loss:  0.03295122 Validation Decoder Loss:  0.33876294
Encoder Loss:  0.037816323  || Decoder Loss:  0.032954417 Validation Decoder Loss:  0.33875877
Encoder Loss:  0.03777512  || Decoder Loss:  0.032956436 Validation Decoder Loss:  0.33875412
Encoder Loss:  0.037685085  || Decoder Loss:  0.032959174 Validation Decoder Loss:  0.33875006
Encoder Loss:  0.036864154  || Decoder Loss:  0.03296118 Validation Decoder Loss:  0.33874542
Encoder Loss:  0.036838163  || Decoder Loss:  0.032963466 Validation Decoder Loss:  0.33874336
Encoder Loss:  0.03750604  || Decoder Loss:  0.032966033 Validation Decoder Loss:  0.33873773
Encoder Loss:  0.039042644  || Decoder Loss:  0.03296937 Validation Decoder Loss:  0.3387316
Encoder Loss:  0.037984867  || Decoder Loss:  0.032972127 Validation Decoder Loss:  0.33872664
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33872664
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 604, 5, 20, 1)     542       
_________________________________________________________________
reshape_60 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 542
Trainable params: 542
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0753432  || Decoder Loss:  0.0753432 Validation Decoder Loss:  0.37380326
Encoder Loss:  0.04794758  || Decoder Loss:  0.04794758 Validation Decoder Loss:  0.3710898
Encoder Loss:  0.045906905  || Decoder Loss:  0.045906905 Validation Decoder Loss:  0.3679836
Encoder Loss:  0.043673806  || Decoder Loss:  0.043673806 Validation Decoder Loss:  0.36470768
Encoder Loss:  0.041429754  || Decoder Loss:  0.041429754 Validation Decoder Loss:  0.361495
Encoder Loss:  0.03934217  || Decoder Loss:  0.03934217 Validation Decoder Loss:  0.35854307
Encoder Loss:  0.037548028  || Decoder Loss:  0.037548028 Validation Decoder Loss:  0.3560006
Encoder Loss:  0.0361385  || Decoder Loss:  0.0361385 Validation Decoder Loss:  0.35395283
Encoder Loss:  0.035141878  || Decoder Loss:  0.035141878 Validation Decoder Loss:  0.35241038
Encoder Loss:  0.03451744  || Decoder Loss:  0.03451744 Validation Decoder Loss:  0.35131487
Encoder Loss:  0.034172975  || Decoder Loss:  0.034172975 Validation Decoder Loss:  0.3505664
Encoder Loss:  0.034002498  || Decoder Loss:  0.034002498 Validation Decoder Loss:  0.35005927
Encoder Loss:  0.033921313  || Decoder Loss:  0.033921313 Validation Decoder Loss:  0.3497076
Encoder Loss:  0.03387882  || Decoder Loss:  0.03387882 Validation Decoder Loss:  0.34945232
Encoder Loss:  0.033851407  || Decoder Loss:  0.033851407 Validation Decoder Loss:  0.34925658
Encoder Loss:  0.03383011  || Decoder Loss:  0.03383011 Validation Decoder Loss:  0.34909853
Encoder Loss:  0.033811957  || Decoder Loss:  0.033811957 Validation Decoder Loss:  0.3489656
Encoder Loss:  0.033796016  || Decoder Loss:  0.033796016 Validation Decoder Loss:  0.34885076
Encoder Loss:  0.0337819  || Decoder Loss:  0.0337819 Validation Decoder Loss:  0.34875014
Encoder Loss:  0.03376936  || Decoder Loss:  0.03376936 Validation Decoder Loss:  0.34866148
Encoder Loss:  0.033758204  || Decoder Loss:  0.033758204 Validation Decoder Loss:  0.34858334
Encoder Loss:  0.03374824  || Decoder Loss:  0.03374824 Validation Decoder Loss:  0.3485146
Encoder Loss:  0.03373932  || Decoder Loss:  0.03373932 Validation Decoder Loss:  0.34845436
Encoder Loss:  0.03373131  || Decoder Loss:  0.03373131 Validation Decoder Loss:  0.34840184
Encoder Loss:  0.033724073  || Decoder Loss:  0.033724073 Validation Decoder Loss:  0.34835637
Encoder Loss:  0.033717513  || Decoder Loss:  0.033717513 Validation Decoder Loss:  0.34831712
Encoder Loss:  0.033711534  || Decoder Loss:  0.033711534 Validation Decoder Loss:  0.34828347
Encoder Loss:  0.033706058  || Decoder Loss:  0.033706058 Validation Decoder Loss:  0.34825486
Encoder Loss:  0.033701032  || Decoder Loss:  0.033701032 Validation Decoder Loss:  0.3482306
Encoder Loss:  0.033696383  || Decoder Loss:  0.033696383 Validation Decoder Loss:  0.34821022
Encoder Loss:  0.033692062  || Decoder Loss:  0.033692062 Validation Decoder Loss:  0.34819326
Encoder Loss:  0.033688035  || Decoder Loss:  0.033688035 Validation Decoder Loss:  0.34817928
Encoder Loss:  0.033684265  || Decoder Loss:  0.033684265 Validation Decoder Loss:  0.3481679
Encoder Loss:  0.03368073  || Decoder Loss:  0.03368073 Validation Decoder Loss:  0.34815875
Encoder Loss:  0.033677384  || Decoder Loss:  0.033677384 Validation Decoder Loss:  0.34815156
Encoder Loss:  0.033674218  || Decoder Loss:  0.033674218 Validation Decoder Loss:  0.34814602
Encoder Loss:  0.033671215  || Decoder Loss:  0.033671215 Validation Decoder Loss:  0.34814185
Encoder Loss:  0.03366835  || Decoder Loss:  0.03366835 Validation Decoder Loss:  0.348139
Encoder Loss:  0.033665605  || Decoder Loss:  0.033665605 Validation Decoder Loss:  0.34813708
Encoder Loss:  0.03366298  || Decoder Loss:  0.03366298 Validation Decoder Loss:  0.34813607
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34813607
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 302, 10, 20, 1)    479       
_________________________________________________________________
reshape_61 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 479
Trainable params: 479
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.80982095  || Decoder Loss:  0.9437431 Validation Decoder Loss:  1.6523688
Encoder Loss:  0.8259388  || Decoder Loss:  0.962183 Validation Decoder Loss:  1.6527045
Encoder Loss:  0.81985164  || Decoder Loss:  0.96187294 Validation Decoder Loss:  1.653233
Encoder Loss:  0.8251746  || Decoder Loss:  0.9614413 Validation Decoder Loss:  1.6540532
Encoder Loss:  0.8246541  || Decoder Loss:  0.96081716 Validation Decoder Loss:  1.6553912
Encoder Loss:  0.8238133  || Decoder Loss:  0.95989084 Validation Decoder Loss:  1.6578789
Encoder Loss:  0.82240105  || Decoder Loss:  0.9582626 Validation Decoder Loss:  1.6641614
Encoder Loss:  0.67835885  || Decoder Loss:  0.76298505 Validation Decoder Loss:  0.37227276
Encoder Loss:  0.14729694  || Decoder Loss:  0.042120114 Validation Decoder Loss:  0.36594945
Encoder Loss:  0.14819044  || Decoder Loss:  0.04407616 Validation Decoder Loss:  0.3698757
Encoder Loss:  0.1495282  || Decoder Loss:  0.046964113 Validation Decoder Loss:  0.37606114
Encoder Loss:  0.15157796  || Decoder Loss:  0.051367976 Validation Decoder Loss:  0.38565356
Encoder Loss:  0.15497099  || Decoder Loss:  0.058616303 Validation Decoder Loss:  0.4019153
Encoder Loss:  0.16142984  || Decoder Loss:  0.07230093 Validation Decoder Loss:  0.43496385
Encoder Loss:  0.17834151  || Decoder Loss:  0.1075179 Validation Decoder Loss:  0.5419963
Encoder Loss:  0.3000138  || Decoder Loss:  0.3336211 Validation Decoder Loss:  1.2605656
Encoder Loss:  0.3954062  || Decoder Loss:  0.5062147 Validation Decoder Loss:  1.1097165
Encoder Loss:  0.37796792  || Decoder Loss:  0.49092093 Validation Decoder Loss:  1.1090403
Encoder Loss:  0.37730384  || Decoder Loss:  0.49089932 Validation Decoder Loss:  1.1137424
Encoder Loss:  0.37802964  || Decoder Loss:  0.4925367 Validation Decoder Loss:  1.1178579
Encoder Loss:  0.37878078  || Decoder Loss:  0.49398336 Validation Decoder Loss:  1.1131291
Encoder Loss:  0.38035002  || Decoder Loss:  0.49651104 Validation Decoder Loss:  1.1088609
Encoder Loss:  0.38077167  || Decoder Loss:  0.49719647 Validation Decoder Loss:  1.100594
Encoder Loss:  0.37960804  || Decoder Loss:  0.49657655 Validation Decoder Loss:  1.1143076
Encoder Loss:  0.37995338  || Decoder Loss:  0.49694377 Validation Decoder Loss:  1.0954119
Encoder Loss:  0.38264397  || Decoder Loss:  0.49890435 Validation Decoder Loss:  1.0934063
Encoder Loss:  0.3796571  || Decoder Loss:  0.4956895 Validation Decoder Loss:  1.1182431
Encoder Loss:  0.38121268  || Decoder Loss:  0.49840707 Validation Decoder Loss:  1.1140106
Encoder Loss:  0.37958705  || Decoder Loss:  0.4969846 Validation Decoder Loss:  1.1115328
Encoder Loss:  0.37916106  || Decoder Loss:  0.4964762 Validation Decoder Loss:  1.1023685
Encoder Loss:  0.3805272  || Decoder Loss:  0.49731708 Validation Decoder Loss:  1.0978518
Encoder Loss:  0.37870938  || Decoder Loss:  0.4943435 Validation Decoder Loss:  1.1232588
Encoder Loss:  0.38155812  || Decoder Loss:  0.4984317 Validation Decoder Loss:  1.1307108
Encoder Loss:  0.37993652  || Decoder Loss:  0.49632397 Validation Decoder Loss:  1.1126639
Encoder Loss:  0.3793204  || Decoder Loss:  0.4963813 Validation Decoder Loss:  1.1300094
Encoder Loss:  0.3802985  || Decoder Loss:  0.49769303 Validation Decoder Loss:  1.1150043
Encoder Loss:  0.37939224  || Decoder Loss:  0.49614406 Validation Decoder Loss:  1.0987916
Encoder Loss:  0.37870055  || Decoder Loss:  0.49401855 Validation Decoder Loss:  1.1156529
Encoder Loss:  0.38143715  || Decoder Loss:  0.49686095 Validation Decoder Loss:  1.1046569
Encoder Loss:  0.37864485  || Decoder Loss:  0.4950014 Validation Decoder Loss:  1.1194818
Model: siamese_net_lr_0.06597066708815337 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1194818
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 317, 10, 20, 1)    131       
_________________________________________________________________
reshape_62 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8518102  || Decoder Loss:  0.9494289 Validation Decoder Loss:  1.6578498
Encoder Loss:  0.8681705  || Decoder Loss:  0.96737826 Validation Decoder Loss:  1.6578419
Encoder Loss:  0.8680396  || Decoder Loss:  0.9673391 Validation Decoder Loss:  1.6578422
Encoder Loss:  0.86767036  || Decoder Loss:  0.9672855 Validation Decoder Loss:  1.6578393
Encoder Loss:  0.8648684  || Decoder Loss:  0.96721655 Validation Decoder Loss:  1.6578271
Encoder Loss:  0.86796904  || Decoder Loss:  0.9671325 Validation Decoder Loss:  1.657799
Encoder Loss:  0.86788005  || Decoder Loss:  0.9670271 Validation Decoder Loss:  1.6577463
Encoder Loss:  0.867742  || Decoder Loss:  0.96688646 Validation Decoder Loss:  1.6576444
Encoder Loss:  0.8675412  || Decoder Loss:  0.9666778 Validation Decoder Loss:  1.6574236
Encoder Loss:  0.867179  || Decoder Loss:  0.96628267 Validation Decoder Loss:  1.6567465
Encoder Loss:  0.770185  || Decoder Loss:  0.8465788 Validation Decoder Loss:  0.34116322
Encoder Loss:  0.11082956  || Decoder Loss:  0.03245956 Validation Decoder Loss:  0.34125903
Encoder Loss:  0.11077907  || Decoder Loss:  0.03255712 Validation Decoder Loss:  0.34113103
Encoder Loss:  0.110582925  || Decoder Loss:  0.03260059 Validation Decoder Loss:  0.34098434
Encoder Loss:  0.11004034  || Decoder Loss:  0.032647334 Validation Decoder Loss:  0.34082556
Encoder Loss:  0.101763815  || Decoder Loss:  0.032700837 Validation Decoder Loss:  0.3406676
Encoder Loss:  0.10876403  || Decoder Loss:  0.032756492 Validation Decoder Loss:  0.34049213
Encoder Loss:  0.10791455  || Decoder Loss:  0.03282708 Validation Decoder Loss:  0.3402885
Encoder Loss:  0.09441869  || Decoder Loss:  0.032913942 Validation Decoder Loss:  0.34007296
Encoder Loss:  0.04834585  || Decoder Loss:  0.03299314 Validation Decoder Loss:  0.3399576
Encoder Loss:  0.041529503  || Decoder Loss:  0.033026885 Validation Decoder Loss:  0.339912
Encoder Loss:  0.03985495  || Decoder Loss:  0.033052202 Validation Decoder Loss:  0.33987504
Encoder Loss:  0.040147692  || Decoder Loss:  0.033077426 Validation Decoder Loss:  0.3398443
Encoder Loss:  0.04235962  || Decoder Loss:  0.03310157 Validation Decoder Loss:  0.33980262
Encoder Loss:  0.040107477  || Decoder Loss:  0.033129245 Validation Decoder Loss:  0.33976418
Encoder Loss:  0.039469715  || Decoder Loss:  0.03315071 Validation Decoder Loss:  0.33971936
Encoder Loss:  0.040260367  || Decoder Loss:  0.03318007 Validation Decoder Loss:  0.3396735
Encoder Loss:  0.042079147  || Decoder Loss:  0.03320655 Validation Decoder Loss:  0.33963192
Encoder Loss:  0.038325295  || Decoder Loss:  0.033241853 Validation Decoder Loss:  0.3395785
Encoder Loss:  0.038731717  || Decoder Loss:  0.033290483 Validation Decoder Loss:  0.33952227
Encoder Loss:  0.04016991  || Decoder Loss:  0.03333633 Validation Decoder Loss:  0.33946565
Encoder Loss:  0.04083602  || Decoder Loss:  0.033385605 Validation Decoder Loss:  0.33940881
Encoder Loss:  0.041313812  || Decoder Loss:  0.033428527 Validation Decoder Loss:  0.33935258
Encoder Loss:  0.03924574  || Decoder Loss:  0.03347303 Validation Decoder Loss:  0.33930278
Encoder Loss:  0.03922007  || Decoder Loss:  0.033516936 Validation Decoder Loss:  0.339247
Encoder Loss:  0.03981561  || Decoder Loss:  0.033559665 Validation Decoder Loss:  0.3391818
Encoder Loss:  0.041557737  || Decoder Loss:  0.033632096 Validation Decoder Loss:  0.33908126
Encoder Loss:  0.038996283  || Decoder Loss:  0.03371859 Validation Decoder Loss:  0.33896816
Encoder Loss:  0.03937171  || Decoder Loss:  0.033810884 Validation Decoder Loss:  0.33884764
Encoder Loss:  0.04053856  || Decoder Loss:  0.033915713 Validation Decoder Loss:  0.3386791
Model: siamese_net_lr_0.07930112977184761 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3386791
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 634, 5, 20, 1)     446       
_________________________________________________________________
reshape_63 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 446
Trainable params: 446
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.86021614  || Decoder Loss:  0.9451659 Validation Decoder Loss:  1.6603417
Encoder Loss:  0.87983483  || Decoder Loss:  0.9662392 Validation Decoder Loss:  1.66014
Encoder Loss:  0.8796722  || Decoder Loss:  0.9660816 Validation Decoder Loss:  1.6598845
Encoder Loss:  0.87945443  || Decoder Loss:  0.9658691 Validation Decoder Loss:  1.6595383
Encoder Loss:  0.8791762  || Decoder Loss:  0.9655974 Validation Decoder Loss:  1.6590744
Encoder Loss:  0.8788251  || Decoder Loss:  0.96525365 Validation Decoder Loss:  1.658452
Encoder Loss:  0.8783799  || Decoder Loss:  0.9648157 Validation Decoder Loss:  1.6576037
Encoder Loss:  0.8778007  || Decoder Loss:  0.96423966 Validation Decoder Loss:  1.6563877
Encoder Loss:  0.8769708  || Decoder Loss:  0.9633936 Validation Decoder Loss:  1.6542995
Encoder Loss:  0.8180142  || Decoder Loss:  0.8929332 Validation Decoder Loss:  0.3429747
Encoder Loss:  0.10365495  || Decoder Loss:  0.037146002 Validation Decoder Loss:  0.3438658
Encoder Loss:  0.10418643  || Decoder Loss:  0.038120337 Validation Decoder Loss:  0.34554762
Encoder Loss:  0.104852945  || Decoder Loss:  0.03944682 Validation Decoder Loss:  0.34776685
Encoder Loss:  0.10482362  || Decoder Loss:  0.04117123 Validation Decoder Loss:  0.35074335
Encoder Loss:  0.10437498  || Decoder Loss:  0.043383032 Validation Decoder Loss:  0.35466647
Encoder Loss:  0.10946888  || Decoder Loss:  0.046467863 Validation Decoder Loss:  0.36051035
Encoder Loss:  0.11240599  || Decoder Loss:  0.0510267 Validation Decoder Loss:  0.3694414
Encoder Loss:  0.11708169  || Decoder Loss:  0.058266673 Validation Decoder Loss:  0.38453493
Encoder Loss:  0.12582673  || Decoder Loss:  0.07167858 Validation Decoder Loss:  0.41589066
Encoder Loss:  0.14958282  || Decoder Loss:  0.10741672 Validation Decoder Loss:  0.53044873
Encoder Loss:  0.34298515  || Decoder Loss:  0.37413362 Validation Decoder Loss:  1.2414935
Encoder Loss:  0.42389846  || Decoder Loss:  0.49053127 Validation Decoder Loss:  1.1083586
Encoder Loss:  0.41523004  || Decoder Loss:  0.4840649 Validation Decoder Loss:  1.1293594
Encoder Loss:  0.4168189  || Decoder Loss:  0.48604777 Validation Decoder Loss:  1.120724
Encoder Loss:  0.4293179  || Decoder Loss:  0.50298965 Validation Decoder Loss:  1.1873962
Encoder Loss:  0.44137597  || Decoder Loss:  0.51808053 Validation Decoder Loss:  1.0862201
Encoder Loss:  0.4080903  || Decoder Loss:  0.47855264 Validation Decoder Loss:  1.0982137
Encoder Loss:  0.4126271  || Decoder Loss:  0.48424596 Validation Decoder Loss:  1.0858171
Encoder Loss:  0.4035987  || Decoder Loss:  0.4734685 Validation Decoder Loss:  1.0664661
Encoder Loss:  0.39751765  || Decoder Loss:  0.46617833 Validation Decoder Loss:  1.0756035
Encoder Loss:  0.40274188  || Decoder Loss:  0.47239304 Validation Decoder Loss:  1.091284
Encoder Loss:  0.4062732  || Decoder Loss:  0.47671318 Validation Decoder Loss:  1.0724274
Encoder Loss:  0.40197226  || Decoder Loss:  0.47154316 Validation Decoder Loss:  1.0928165
Encoder Loss:  0.4072627  || Decoder Loss:  0.477955 Validation Decoder Loss:  1.0754038
Encoder Loss:  0.3989879  || Decoder Loss:  0.46803033 Validation Decoder Loss:  1.079534
Encoder Loss:  0.40087342  || Decoder Loss:  0.47034514 Validation Decoder Loss:  1.0700028
Encoder Loss:  0.40054122  || Decoder Loss:  0.46992713 Validation Decoder Loss:  1.08431
Encoder Loss:  0.40193024  || Decoder Loss:  0.4716307 Validation Decoder Loss:  1.0676713
Encoder Loss:  0.39295527  || Decoder Loss:  0.4608468 Validation Decoder Loss:  1.0373533
Encoder Loss:  0.3125919  || Decoder Loss:  0.36459747 Validation Decoder Loss:  1.007447
Model: siamese_net_lr_0.08918780387816555 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.007447
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_64 (Conv3DT (None, 634, 5, 20, 1)     68        
_________________________________________________________________
reshape_64 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 68
Trainable params: 68
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.064185135  || Decoder Loss:  0.06477637 Validation Decoder Loss:  0.34929037
Encoder Loss:  0.04686244  || Decoder Loss:  0.03647362 Validation Decoder Loss:  0.34898144
Encoder Loss:  0.06710752  || Decoder Loss:  0.03593649 Validation Decoder Loss:  0.35128635
Encoder Loss:  0.12009341  || Decoder Loss:  0.036610205 Validation Decoder Loss:  0.35218954
Encoder Loss:  0.066077664  || Decoder Loss:  0.035352807 Validation Decoder Loss:  0.35263476
Encoder Loss:  0.061315417  || Decoder Loss:  0.036082085 Validation Decoder Loss:  0.3485301
Encoder Loss:  0.051527735  || Decoder Loss:  0.03474275 Validation Decoder Loss:  0.34849086
Encoder Loss:  0.05262455  || Decoder Loss:  0.034538265 Validation Decoder Loss:  0.34841192
Encoder Loss:  0.049421154  || Decoder Loss:  0.034367632 Validation Decoder Loss:  0.34824157
Encoder Loss:  0.04523557  || Decoder Loss:  0.034246866 Validation Decoder Loss:  0.34815767
Encoder Loss:  0.045026258  || Decoder Loss:  0.03414586 Validation Decoder Loss:  0.34812367
Encoder Loss:  0.04501041  || Decoder Loss:  0.034062687 Validation Decoder Loss:  0.34807208
Encoder Loss:  0.0446409  || Decoder Loss:  0.034040615 Validation Decoder Loss:  0.34814984
Encoder Loss:  0.044617925  || Decoder Loss:  0.033979144 Validation Decoder Loss:  0.34813702
Encoder Loss:  0.044502445  || Decoder Loss:  0.033945307 Validation Decoder Loss:  0.34812963
Encoder Loss:  0.044577792  || Decoder Loss:  0.03391415 Validation Decoder Loss:  0.34812707
Encoder Loss:  0.044461954  || Decoder Loss:  0.03389021 Validation Decoder Loss:  0.3481004
Encoder Loss:  0.04452505  || Decoder Loss:  0.033874143 Validation Decoder Loss:  0.34812993
Encoder Loss:  0.044474468  || Decoder Loss:  0.033857565 Validation Decoder Loss:  0.348111
Encoder Loss:  0.044404916  || Decoder Loss:  0.0338465 Validation Decoder Loss:  0.34813026
Encoder Loss:  0.044387855  || Decoder Loss:  0.033837944 Validation Decoder Loss:  0.34812462
Encoder Loss:  0.04444434  || Decoder Loss:  0.033829607 Validation Decoder Loss:  0.3481327
Encoder Loss:  0.04432755  || Decoder Loss:  0.033824746 Validation Decoder Loss:  0.34813303
Encoder Loss:  0.044358052  || Decoder Loss:  0.033823147 Validation Decoder Loss:  0.34813356
Encoder Loss:  0.04431028  || Decoder Loss:  0.033819526 Validation Decoder Loss:  0.34812602
Encoder Loss:  0.044306085  || Decoder Loss:  0.033816136 Validation Decoder Loss:  0.34813148
Encoder Loss:  0.0442534  || Decoder Loss:  0.033814892 Validation Decoder Loss:  0.34813187
Encoder Loss:  0.044238586  || Decoder Loss:  0.03381314 Validation Decoder Loss:  0.3481205
Encoder Loss:  0.044218183  || Decoder Loss:  0.033811778 Validation Decoder Loss:  0.34811395
Encoder Loss:  0.044206325  || Decoder Loss:  0.03381034 Validation Decoder Loss:  0.34810558
Encoder Loss:  0.0441868  || Decoder Loss:  0.033809606 Validation Decoder Loss:  0.3480987
Encoder Loss:  0.044175595  || Decoder Loss:  0.0338088 Validation Decoder Loss:  0.3480918
Encoder Loss:  0.04416741  || Decoder Loss:  0.03380821 Validation Decoder Loss:  0.34808695
Encoder Loss:  0.04417101  || Decoder Loss:  0.03380801 Validation Decoder Loss:  0.34808284
Encoder Loss:  0.044181805  || Decoder Loss:  0.03380734 Validation Decoder Loss:  0.3480782
Encoder Loss:  0.044177618  || Decoder Loss:  0.033808287 Validation Decoder Loss:  0.34808674
Encoder Loss:  0.044183172  || Decoder Loss:  0.033808693 Validation Decoder Loss:  0.3480894
Encoder Loss:  0.044155203  || Decoder Loss:  0.033811986 Validation Decoder Loss:  0.34811336
Encoder Loss:  0.044142958  || Decoder Loss:  0.03381407 Validation Decoder Loss:  0.34810776
Encoder Loss:  0.044133324  || Decoder Loss:  0.033814732 Validation Decoder Loss:  0.34810275
Model: siamese_net_lr_0.003395738918459172 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34810275
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 317, 10, 20, 1)    769       
_________________________________________________________________
reshape_65 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 769
Trainable params: 769
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13379534  || Decoder Loss:  0.12019734 Validation Decoder Loss:  0.34709743
Encoder Loss:  0.059176303  || Decoder Loss:  0.042530414 Validation Decoder Loss:  0.35445094
Encoder Loss:  0.047577724  || Decoder Loss:  0.040475756 Validation Decoder Loss:  0.35642904
Encoder Loss:  0.046510663  || Decoder Loss:  0.038500346 Validation Decoder Loss:  0.35273015
Encoder Loss:  0.04574451  || Decoder Loss:  0.037232347 Validation Decoder Loss:  0.35241413
Encoder Loss:  0.045901928  || Decoder Loss:  0.036891207 Validation Decoder Loss:  0.35179502
Encoder Loss:  0.045326486  || Decoder Loss:  0.036163352 Validation Decoder Loss:  0.3501349
Encoder Loss:  0.044997986  || Decoder Loss:  0.035558935 Validation Decoder Loss:  0.34897122
Encoder Loss:  0.044834174  || Decoder Loss:  0.0351622 Validation Decoder Loss:  0.34807456
Encoder Loss:  0.04472673  || Decoder Loss:  0.03488742 Validation Decoder Loss:  0.34740096
Encoder Loss:  0.04471186  || Decoder Loss:  0.034696113 Validation Decoder Loss:  0.34679425
Encoder Loss:  0.044865828  || Decoder Loss:  0.034588132 Validation Decoder Loss:  0.34659278
Encoder Loss:  0.044692226  || Decoder Loss:  0.03453008 Validation Decoder Loss:  0.34618974
Encoder Loss:  0.044564735  || Decoder Loss:  0.034492373 Validation Decoder Loss:  0.3460566
Encoder Loss:  0.044537514  || Decoder Loss:  0.03442605 Validation Decoder Loss:  0.34594154
Encoder Loss:  0.044516064  || Decoder Loss:  0.03437088 Validation Decoder Loss:  0.3457983
Encoder Loss:  0.044603273  || Decoder Loss:  0.034348916 Validation Decoder Loss:  0.3458744
Encoder Loss:  0.04452814  || Decoder Loss:  0.03438743 Validation Decoder Loss:  0.3461548
Encoder Loss:  0.04451299  || Decoder Loss:  0.034326125 Validation Decoder Loss:  0.34615138
Encoder Loss:  0.04447174  || Decoder Loss:  0.034294505 Validation Decoder Loss:  0.34638438
Encoder Loss:  0.044483725  || Decoder Loss:  0.03420795 Validation Decoder Loss:  0.34602457
Encoder Loss:  0.044481367  || Decoder Loss:  0.034196943 Validation Decoder Loss:  0.34631687
Encoder Loss:  0.04443817  || Decoder Loss:  0.03417803 Validation Decoder Loss:  0.34626606
Encoder Loss:  0.044390246  || Decoder Loss:  0.03414198 Validation Decoder Loss:  0.34626862
Encoder Loss:  0.04438145  || Decoder Loss:  0.034117226 Validation Decoder Loss:  0.34625614
Encoder Loss:  0.044359885  || Decoder Loss:  0.034089867 Validation Decoder Loss:  0.34622532
Encoder Loss:  0.044370946  || Decoder Loss:  0.034065224 Validation Decoder Loss:  0.34626558
Encoder Loss:  0.044361282  || Decoder Loss:  0.034081947 Validation Decoder Loss:  0.3463807
Encoder Loss:  0.04434535  || Decoder Loss:  0.03406717 Validation Decoder Loss:  0.34640545
Encoder Loss:  0.044333335  || Decoder Loss:  0.03401535 Validation Decoder Loss:  0.3462422
Encoder Loss:  0.044317726  || Decoder Loss:  0.033996396 Validation Decoder Loss:  0.3462527
Encoder Loss:  0.044317495  || Decoder Loss:  0.03399401 Validation Decoder Loss:  0.3462699
Encoder Loss:  0.04431433  || Decoder Loss:  0.033983566 Validation Decoder Loss:  0.34626585
Encoder Loss:  0.04431592  || Decoder Loss:  0.03396097 Validation Decoder Loss:  0.3462922
Encoder Loss:  0.044307765  || Decoder Loss:  0.033969995 Validation Decoder Loss:  0.3462714
Encoder Loss:  0.044297446  || Decoder Loss:  0.033942286 Validation Decoder Loss:  0.34628356
Encoder Loss:  0.044315018  || Decoder Loss:  0.03397023 Validation Decoder Loss:  0.34656405
Encoder Loss:  0.04446415  || Decoder Loss:  0.033932716 Validation Decoder Loss:  0.34651005
Encoder Loss:  0.044331446  || Decoder Loss:  0.033899624 Validation Decoder Loss:  0.3462871
Encoder Loss:  0.04429944  || Decoder Loss:  0.033914622 Validation Decoder Loss:  0.3464246
Model: siamese_net_lr_0.002271134988490934 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3464246
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 317, 10, 20, 1)    131       
_________________________________________________________________
reshape_66 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13084477  || Decoder Loss:  0.07541782 Validation Decoder Loss:  0.34921825
Encoder Loss:  0.10662522  || Decoder Loss:  0.035962995 Validation Decoder Loss:  0.34783518
Encoder Loss:  0.07712789  || Decoder Loss:  0.03644565 Validation Decoder Loss:  0.35547686
Encoder Loss:  0.051068693  || Decoder Loss:  0.039709706 Validation Decoder Loss:  0.35580194
Encoder Loss:  0.04991313  || Decoder Loss:  0.038476285 Validation Decoder Loss:  0.35402596
Encoder Loss:  0.04612514  || Decoder Loss:  0.03740336 Validation Decoder Loss:  0.3525561
Encoder Loss:  0.045530792  || Decoder Loss:  0.036574528 Validation Decoder Loss:  0.35169542
Encoder Loss:  0.045291565  || Decoder Loss:  0.035995908 Validation Decoder Loss:  0.35111374
Encoder Loss:  0.04511409  || Decoder Loss:  0.03557969 Validation Decoder Loss:  0.35057518
Encoder Loss:  0.044993397  || Decoder Loss:  0.03526729 Validation Decoder Loss:  0.35019192
Encoder Loss:  0.04489305  || Decoder Loss:  0.035026673 Validation Decoder Loss:  0.3498943
Encoder Loss:  0.044817306  || Decoder Loss:  0.03484129 Validation Decoder Loss:  0.34964362
Encoder Loss:  0.044755712  || Decoder Loss:  0.034692872 Validation Decoder Loss:  0.34943783
Encoder Loss:  0.044699766  || Decoder Loss:  0.034574356 Validation Decoder Loss:  0.349272
Encoder Loss:  0.04466471  || Decoder Loss:  0.034478888 Validation Decoder Loss:  0.34914
Encoder Loss:  0.04462838  || Decoder Loss:  0.034396447 Validation Decoder Loss:  0.34898484
Encoder Loss:  0.044605445  || Decoder Loss:  0.034335066 Validation Decoder Loss:  0.3489569
Encoder Loss:  0.044559855  || Decoder Loss:  0.03427375 Validation Decoder Loss:  0.34884036
Encoder Loss:  0.044535592  || Decoder Loss:  0.0342234 Validation Decoder Loss:  0.34875888
Encoder Loss:  0.044516392  || Decoder Loss:  0.034185313 Validation Decoder Loss:  0.348729
Encoder Loss:  0.04449678  || Decoder Loss:  0.03414679 Validation Decoder Loss:  0.34869725
Encoder Loss:  0.04448378  || Decoder Loss:  0.034121834 Validation Decoder Loss:  0.34866422
Encoder Loss:  0.04446772  || Decoder Loss:  0.034086723 Validation Decoder Loss:  0.34863788
Encoder Loss:  0.044451725  || Decoder Loss:  0.03406222 Validation Decoder Loss:  0.34860212
Encoder Loss:  0.04443841  || Decoder Loss:  0.03403919 Validation Decoder Loss:  0.3485869
Encoder Loss:  0.044424962  || Decoder Loss:  0.034016103 Validation Decoder Loss:  0.34860885
Encoder Loss:  0.04441691  || Decoder Loss:  0.034002904 Validation Decoder Loss:  0.34863913
Encoder Loss:  0.044411853  || Decoder Loss:  0.033989083 Validation Decoder Loss:  0.34858102
Encoder Loss:  0.044396378  || Decoder Loss:  0.033965487 Validation Decoder Loss:  0.3485838
Encoder Loss:  0.04439008  || Decoder Loss:  0.033954702 Validation Decoder Loss:  0.3485805
Encoder Loss:  0.04437802  || Decoder Loss:  0.033937313 Validation Decoder Loss:  0.3485824
Encoder Loss:  0.044369455  || Decoder Loss:  0.033929463 Validation Decoder Loss:  0.34860373
Encoder Loss:  0.044363726  || Decoder Loss:  0.033916913 Validation Decoder Loss:  0.34860256
Encoder Loss:  0.044353615  || Decoder Loss:  0.033908065 Validation Decoder Loss:  0.34860742
Encoder Loss:  0.044352595  || Decoder Loss:  0.033897284 Validation Decoder Loss:  0.3486542
Encoder Loss:  0.044342674  || Decoder Loss:  0.03389408 Validation Decoder Loss:  0.34865987
Encoder Loss:  0.044328593  || Decoder Loss:  0.033884894 Validation Decoder Loss:  0.34864318
Encoder Loss:  0.04432719  || Decoder Loss:  0.033876818 Validation Decoder Loss:  0.34862065
Encoder Loss:  0.044321626  || Decoder Loss:  0.033867124 Validation Decoder Loss:  0.34861273
Encoder Loss:  0.04432662  || Decoder Loss:  0.03386062 Validation Decoder Loss:  0.34867752
Model: siamese_net_lr_0.002543287043756106 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34867752
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_67 (Conv3DT (None, 634, 5, 20, 1)     131       
_________________________________________________________________
reshape_67 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16021025  || Decoder Loss:  0.057194095 Validation Decoder Loss:  0.3423255
Encoder Loss:  0.1939317  || Decoder Loss:  0.03250018 Validation Decoder Loss:  0.3423159
Encoder Loss:  0.2833967  || Decoder Loss:  0.03284809 Validation Decoder Loss:  0.34280336
Encoder Loss:  0.24640562  || Decoder Loss:  0.08810081 Validation Decoder Loss:  0.3445183
Encoder Loss:  0.19453001  || Decoder Loss:  0.22250092 Validation Decoder Loss:  0.34897733
Encoder Loss:  0.067866154  || Decoder Loss:  0.040470667 Validation Decoder Loss:  0.35190737
Encoder Loss:  0.05378944  || Decoder Loss:  0.038426653 Validation Decoder Loss:  0.35123095
Encoder Loss:  0.05671351  || Decoder Loss:  0.03709549 Validation Decoder Loss:  0.34899008
Encoder Loss:  0.06914267  || Decoder Loss:  0.036195613 Validation Decoder Loss:  0.3484338
Encoder Loss:  0.0615687  || Decoder Loss:  0.035678256 Validation Decoder Loss:  0.35028222
Encoder Loss:  0.060030278  || Decoder Loss:  0.035312057 Validation Decoder Loss:  0.3501523
Encoder Loss:  0.04744147  || Decoder Loss:  0.03477269 Validation Decoder Loss:  0.34827602
Encoder Loss:  0.04648229  || Decoder Loss:  0.03420721 Validation Decoder Loss:  0.34944123
Encoder Loss:  0.045734122  || Decoder Loss:  0.034655266 Validation Decoder Loss:  0.34908104
Encoder Loss:  0.045252983  || Decoder Loss:  0.034420162 Validation Decoder Loss:  0.3492955
Encoder Loss:  0.045135953  || Decoder Loss:  0.034349002 Validation Decoder Loss:  0.34921062
Encoder Loss:  0.04514098  || Decoder Loss:  0.034259226 Validation Decoder Loss:  0.3491516
Encoder Loss:  0.04499536  || Decoder Loss:  0.03418742 Validation Decoder Loss:  0.34914428
Encoder Loss:  0.0449912  || Decoder Loss:  0.034131385 Validation Decoder Loss:  0.3490428
Encoder Loss:  0.04490045  || Decoder Loss:  0.03407929 Validation Decoder Loss:  0.34904838
Encoder Loss:  0.044839945  || Decoder Loss:  0.034040958 Validation Decoder Loss:  0.3490132
Encoder Loss:  0.04486469  || Decoder Loss:  0.034000598 Validation Decoder Loss:  0.3489427
Encoder Loss:  0.0448329  || Decoder Loss:  0.033961 Validation Decoder Loss:  0.3489316
Encoder Loss:  0.044799615  || Decoder Loss:  0.033931505 Validation Decoder Loss:  0.34888518
Encoder Loss:  0.044807207  || Decoder Loss:  0.033895053 Validation Decoder Loss:  0.34884036
Encoder Loss:  0.044747636  || Decoder Loss:  0.03386698 Validation Decoder Loss:  0.348853
Encoder Loss:  0.044743694  || Decoder Loss:  0.033860892 Validation Decoder Loss:  0.3488391
Encoder Loss:  0.044739313  || Decoder Loss:  0.03384376 Validation Decoder Loss:  0.34881014
Encoder Loss:  0.04472623  || Decoder Loss:  0.03382603 Validation Decoder Loss:  0.34879774
Encoder Loss:  0.044722017  || Decoder Loss:  0.033817828 Validation Decoder Loss:  0.34878922
Encoder Loss:  0.044717755  || Decoder Loss:  0.033808865 Validation Decoder Loss:  0.34877425
Encoder Loss:  0.0447122  || Decoder Loss:  0.03379923 Validation Decoder Loss:  0.34876162
Encoder Loss:  0.044707414  || Decoder Loss:  0.033790614 Validation Decoder Loss:  0.34874982
Encoder Loss:  0.044703532  || Decoder Loss:  0.03378229 Validation Decoder Loss:  0.34873658
Encoder Loss:  0.04469826  || Decoder Loss:  0.033770822 Validation Decoder Loss:  0.34871852
Encoder Loss:  0.044692382  || Decoder Loss:  0.033757593 Validation Decoder Loss:  0.3486969
Encoder Loss:  0.044684757  || Decoder Loss:  0.033738043 Validation Decoder Loss:  0.34866533
Encoder Loss:  0.044673566  || Decoder Loss:  0.03371641 Validation Decoder Loss:  0.34868953
Encoder Loss:  0.044681426  || Decoder Loss:  0.03373298 Validation Decoder Loss:  0.34867585
Encoder Loss:  0.044667803  || Decoder Loss:  0.033708103 Validation Decoder Loss:  0.3486815
Model: siamese_net_lr_0.009352547183517246 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3486815
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 317, 10, 20, 1)    257       
_________________________________________________________________
reshape_68 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.58042186  || Decoder Loss:  0.947258 Validation Decoder Loss:  1.6608865
Encoder Loss:  0.5508083  || Decoder Loss:  0.9663473 Validation Decoder Loss:  1.6606858
Encoder Loss:  0.59331757  || Decoder Loss:  0.9662152 Validation Decoder Loss:  1.6603646
Encoder Loss:  0.50173277  || Decoder Loss:  0.96599305 Validation Decoder Loss:  1.6597202
Encoder Loss:  0.43426713  || Decoder Loss:  0.9655653 Validation Decoder Loss:  1.6577268
Encoder Loss:  0.2699505  || Decoder Loss:  0.6297808 Validation Decoder Loss:  0.33745384
Encoder Loss:  0.07411629  || Decoder Loss:  0.03331819 Validation Decoder Loss:  0.33785203
Encoder Loss:  0.09574127  || Decoder Loss:  0.033360448 Validation Decoder Loss:  0.33786583
Encoder Loss:  0.07927114  || Decoder Loss:  0.033387054 Validation Decoder Loss:  0.33784807
Encoder Loss:  0.08100778  || Decoder Loss:  0.033409066 Validation Decoder Loss:  0.3378416
Encoder Loss:  0.06117773  || Decoder Loss:  0.033429176 Validation Decoder Loss:  0.33782166
Encoder Loss:  0.060844317  || Decoder Loss:  0.033442505 Validation Decoder Loss:  0.33781725
Encoder Loss:  0.061132073  || Decoder Loss:  0.033455383 Validation Decoder Loss:  0.33779782
Encoder Loss:  0.0727869  || Decoder Loss:  0.0334724 Validation Decoder Loss:  0.337785
Encoder Loss:  0.07390526  || Decoder Loss:  0.033496536 Validation Decoder Loss:  0.33776784
Encoder Loss:  0.054608177  || Decoder Loss:  0.033520833 Validation Decoder Loss:  0.33773673
Encoder Loss:  0.056162924  || Decoder Loss:  0.03354504 Validation Decoder Loss:  0.337699
Encoder Loss:  0.06630896  || Decoder Loss:  0.033573102 Validation Decoder Loss:  0.33768773
Encoder Loss:  0.06936147  || Decoder Loss:  0.033596113 Validation Decoder Loss:  0.33767056
Encoder Loss:  0.06469008  || Decoder Loss:  0.033620983 Validation Decoder Loss:  0.3376605
Encoder Loss:  0.06438049  || Decoder Loss:  0.033647213 Validation Decoder Loss:  0.3376492
Encoder Loss:  0.05497445  || Decoder Loss:  0.03367388 Validation Decoder Loss:  0.33762485
Encoder Loss:  0.058597375  || Decoder Loss:  0.033697564 Validation Decoder Loss:  0.33760116
Encoder Loss:  0.05343453  || Decoder Loss:  0.03372049 Validation Decoder Loss:  0.33755916
Encoder Loss:  0.054793306  || Decoder Loss:  0.033749305 Validation Decoder Loss:  0.33749375
Encoder Loss:  0.066571  || Decoder Loss:  0.033784725 Validation Decoder Loss:  0.337467
Encoder Loss:  0.055269077  || Decoder Loss:  0.03381695 Validation Decoder Loss:  0.33744434
Encoder Loss:  0.057408646  || Decoder Loss:  0.03384736 Validation Decoder Loss:  0.33740127
Encoder Loss:  0.062585056  || Decoder Loss:  0.03388319 Validation Decoder Loss:  0.33739096
Encoder Loss:  0.06471454  || Decoder Loss:  0.033913523 Validation Decoder Loss:  0.3373704
Encoder Loss:  0.055131864  || Decoder Loss:  0.03394777 Validation Decoder Loss:  0.33733177
Encoder Loss:  0.05146719  || Decoder Loss:  0.033987433 Validation Decoder Loss:  0.3372674
Encoder Loss:  0.05070158  || Decoder Loss:  0.03403627 Validation Decoder Loss:  0.33717507
Encoder Loss:  0.054149102  || Decoder Loss:  0.03409678 Validation Decoder Loss:  0.3371115
Encoder Loss:  0.050602384  || Decoder Loss:  0.034151252 Validation Decoder Loss:  0.33701605
Encoder Loss:  0.05712904  || Decoder Loss:  0.03421225 Validation Decoder Loss:  0.33693653
Encoder Loss:  0.051466193  || Decoder Loss:  0.03427408 Validation Decoder Loss:  0.33685574
Encoder Loss:  0.05428297  || Decoder Loss:  0.03432925 Validation Decoder Loss:  0.3368232
Encoder Loss:  0.056277223  || Decoder Loss:  0.03436808 Validation Decoder Loss:  0.33680454
Encoder Loss:  0.051792298  || Decoder Loss:  0.0344084 Validation Decoder Loss:  0.33671603
Model: siamese_net_lr_0.05521760102553733 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33671606
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 317, 10, 20, 1)    1147      
_________________________________________________________________
reshape_69 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 1,147
Trainable params: 1,147
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5922009  || Decoder Loss:  0.9379239 Validation Decoder Loss:  1.6659319
Encoder Loss:  0.617537  || Decoder Loss:  0.95744914 Validation Decoder Loss:  1.6652629
Encoder Loss:  0.61554265  || Decoder Loss:  0.9556868 Validation Decoder Loss:  1.6640455
Encoder Loss:  0.6126228  || Decoder Loss:  0.95297545 Validation Decoder Loss:  1.6616342
Encoder Loss:  0.6081445  || Decoder Loss:  0.9478401 Validation Decoder Loss:  1.6532648
Encoder Loss:  0.47204727  || Decoder Loss:  0.5735498 Validation Decoder Loss:  0.3461578
Encoder Loss:  0.28476584  || Decoder Loss:  0.058870893 Validation Decoder Loss:  0.35209483
Encoder Loss:  0.28025046  || Decoder Loss:  0.06815116 Validation Decoder Loss:  0.36563677
Encoder Loss:  0.27265766  || Decoder Loss:  0.08563254 Validation Decoder Loss:  0.3982308
Encoder Loss:  0.2551883  || Decoder Loss:  0.13685471 Validation Decoder Loss:  0.57127476
Encoder Loss:  0.23882176  || Decoder Loss:  0.44074604 Validation Decoder Loss:  0.99689376
Encoder Loss:  0.21561229  || Decoder Loss:  0.46563375 Validation Decoder Loss:  1.0337479
Encoder Loss:  0.21814516  || Decoder Loss:  0.4711939 Validation Decoder Loss:  1.0093596
Encoder Loss:  0.21508284  || Decoder Loss:  0.46951365 Validation Decoder Loss:  1.0294378
Encoder Loss:  0.215799  || Decoder Loss:  0.4718367 Validation Decoder Loss:  1.0346276
Encoder Loss:  0.21527165  || Decoder Loss:  0.47290874 Validation Decoder Loss:  1.0512676
Encoder Loss:  0.21525317  || Decoder Loss:  0.47428325 Validation Decoder Loss:  1.0607152
Encoder Loss:  0.21504028  || Decoder Loss:  0.47559562 Validation Decoder Loss:  1.0666268
Encoder Loss:  0.21475464  || Decoder Loss:  0.4772833 Validation Decoder Loss:  1.07637
Encoder Loss:  0.21439764  || Decoder Loss:  0.47939155 Validation Decoder Loss:  1.0781326
Encoder Loss:  0.21283287  || Decoder Loss:  0.4791124 Validation Decoder Loss:  1.0890393
Encoder Loss:  0.21221036  || Decoder Loss:  0.48081234 Validation Decoder Loss:  1.091276
Encoder Loss:  0.21196958  || Decoder Loss:  0.482825 Validation Decoder Loss:  1.0967777
Encoder Loss:  0.21054888  || Decoder Loss:  0.48109704 Validation Decoder Loss:  1.0786697
Encoder Loss:  0.20455769  || Decoder Loss:  0.47098392 Validation Decoder Loss:  1.0327004
Encoder Loss:  0.17364673  || Decoder Loss:  0.3885225 Validation Decoder Loss:  0.772087
Encoder Loss:  0.0953473  || Decoder Loss:  0.17273337 Validation Decoder Loss:  0.36872512
Encoder Loss:  0.05524484  || Decoder Loss:  0.05693976 Validation Decoder Loss:  0.3505153
Encoder Loss:  0.046435174  || Decoder Loss:  0.036847834 Validation Decoder Loss:  0.34813777
Encoder Loss:  0.046953984  || Decoder Loss:  0.03424839 Validation Decoder Loss:  0.34273738
Encoder Loss:  0.049229864  || Decoder Loss:  0.033925213 Validation Decoder Loss:  0.34199375
Encoder Loss:  0.046949454  || Decoder Loss:  0.034327563 Validation Decoder Loss:  0.35334116
Encoder Loss:  0.0494598  || Decoder Loss:  0.034828793 Validation Decoder Loss:  0.3422717
Encoder Loss:  0.04699148  || Decoder Loss:  0.034774393 Validation Decoder Loss:  0.33653915
Encoder Loss:  0.048141755  || Decoder Loss:  0.0357543 Validation Decoder Loss:  0.33535832
Encoder Loss:  0.047849964  || Decoder Loss:  0.03603431 Validation Decoder Loss:  0.34305125
Encoder Loss:  0.047240116  || Decoder Loss:  0.03451807 Validation Decoder Loss:  0.33572268
Encoder Loss:  0.04672189  || Decoder Loss:  0.036128733 Validation Decoder Loss:  0.3368664
Encoder Loss:  0.049487032  || Decoder Loss:  0.035547182 Validation Decoder Loss:  0.33753633
Encoder Loss:  0.0490817  || Decoder Loss:  0.03601772 Validation Decoder Loss:  0.35236716
Model: siamese_net_lr_0.0561451594635567 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35236716
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_70 (Conv3DT (None, 634, 5, 20, 1)     446       
_________________________________________________________________
reshape_70 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 446
Trainable params: 446
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.60386556  || Decoder Loss:  0.94646406 Validation Decoder Loss:  1.6590829
Encoder Loss:  0.62159693  || Decoder Loss:  0.96404886 Validation Decoder Loss:  1.6555578
Encoder Loss:  0.49045822  || Decoder Loss:  0.582762 Validation Decoder Loss:  0.3386245
Encoder Loss:  0.3021917  || Decoder Loss:  0.03592365 Validation Decoder Loss:  0.3412438
Encoder Loss:  0.30104965  || Decoder Loss:  0.038477883 Validation Decoder Loss:  0.34596145
Encoder Loss:  0.29887313  || Decoder Loss:  0.04334959 Validation Decoder Loss:  0.3564488
Encoder Loss:  0.29385272  || Decoder Loss:  0.054757744 Validation Decoder Loss:  0.38644207
Encoder Loss:  0.27070057  || Decoder Loss:  0.115139075 Validation Decoder Loss:  0.78594804
Encoder Loss:  0.22616228  || Decoder Loss:  0.46645942 Validation Decoder Loss:  1.0849988
Encoder Loss:  0.2026838  || Decoder Loss:  0.45428026 Validation Decoder Loss:  1.0479071
Encoder Loss:  0.1952281  || Decoder Loss:  0.4466981 Validation Decoder Loss:  1.0681667
Encoder Loss:  0.18931384  || Decoder Loss:  0.42968953 Validation Decoder Loss:  0.9665171
Encoder Loss:  0.11879891  || Decoder Loss:  0.23161635 Validation Decoder Loss:  0.34355107
Encoder Loss:  0.054993737  || Decoder Loss:  0.051854014 Validation Decoder Loss:  0.3281268
Encoder Loss:  0.047088455  || Decoder Loss:  0.035615698 Validation Decoder Loss:  0.33875787
Encoder Loss:  0.050892383  || Decoder Loss:  0.033998117 Validation Decoder Loss:  0.3433801
Encoder Loss:  0.048230015  || Decoder Loss:  0.033891667 Validation Decoder Loss:  0.34254074
Encoder Loss:  0.04915362  || Decoder Loss:  0.03384567 Validation Decoder Loss:  0.3436888
Encoder Loss:  0.049587443  || Decoder Loss:  0.033846825 Validation Decoder Loss:  0.3442752
Encoder Loss:  0.050039843  || Decoder Loss:  0.033852067 Validation Decoder Loss:  0.34483683
Encoder Loss:  0.049629692  || Decoder Loss:  0.03386086 Validation Decoder Loss:  0.34520477
Encoder Loss:  0.048099786  || Decoder Loss:  0.033856414 Validation Decoder Loss:  0.34470415
Encoder Loss:  0.048660435  || Decoder Loss:  0.033839002 Validation Decoder Loss:  0.34366617
Encoder Loss:  0.05681559  || Decoder Loss:  0.033815864 Validation Decoder Loss:  0.34315443
Encoder Loss:  0.050097562  || Decoder Loss:  0.03380203 Validation Decoder Loss:  0.34309846
Encoder Loss:  0.04839114  || Decoder Loss:  0.03379475 Validation Decoder Loss:  0.34350002
Encoder Loss:  0.055527467  || Decoder Loss:  0.033793453 Validation Decoder Loss:  0.34391493
Encoder Loss:  0.048203036  || Decoder Loss:  0.033792183 Validation Decoder Loss:  0.34415823
Encoder Loss:  0.049605314  || Decoder Loss:  0.033787996 Validation Decoder Loss:  0.34399593
Encoder Loss:  0.04884212  || Decoder Loss:  0.033775207 Validation Decoder Loss:  0.34333998
Encoder Loss:  0.04862714  || Decoder Loss:  0.033764888 Validation Decoder Loss:  0.3430882
Encoder Loss:  0.050546754  || Decoder Loss:  0.033756863 Validation Decoder Loss:  0.34325334
Encoder Loss:  0.052243534  || Decoder Loss:  0.033753846 Validation Decoder Loss:  0.34324417
Encoder Loss:  0.050129827  || Decoder Loss:  0.03374915 Validation Decoder Loss:  0.34367305
Encoder Loss:  0.05071618  || Decoder Loss:  0.03374801 Validation Decoder Loss:  0.34355533
Encoder Loss:  0.05015978  || Decoder Loss:  0.03374731 Validation Decoder Loss:  0.34295842
Encoder Loss:  0.049492013  || Decoder Loss:  0.033741444 Validation Decoder Loss:  0.34281972
Encoder Loss:  0.047496416  || Decoder Loss:  0.033734363 Validation Decoder Loss:  0.3432445
Encoder Loss:  0.04782709  || Decoder Loss:  0.033729993 Validation Decoder Loss:  0.3432563
Encoder Loss:  0.045636725  || Decoder Loss:  0.03372575 Validation Decoder Loss:  0.34345934
Model: siamese_net_lr_0.029244646997633766 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34345934
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 317, 10, 20, 1)    1525      
_________________________________________________________________
reshape_71 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 1,525
Trainable params: 1,525
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0973869  || Decoder Loss:  0.112979695 Validation Decoder Loss:  0.376437
Encoder Loss:  0.055744015  || Decoder Loss:  0.04234405 Validation Decoder Loss:  0.3491632
Encoder Loss:  0.049725026  || Decoder Loss:  0.041030277 Validation Decoder Loss:  0.3567617
Encoder Loss:  0.047891755  || Decoder Loss:  0.040363073 Validation Decoder Loss:  0.35400215
Encoder Loss:  0.04739251  || Decoder Loss:  0.039727982 Validation Decoder Loss:  0.35359412
Encoder Loss:  0.047084946  || Decoder Loss:  0.03918396 Validation Decoder Loss:  0.35399193
Encoder Loss:  0.046852197  || Decoder Loss:  0.038747128 Validation Decoder Loss:  0.35294944
Encoder Loss:  0.046690747  || Decoder Loss:  0.038321506 Validation Decoder Loss:  0.35284615
Encoder Loss:  0.04655174  || Decoder Loss:  0.037941262 Validation Decoder Loss:  0.3521635
Encoder Loss:  0.04643508  || Decoder Loss:  0.0375947 Validation Decoder Loss:  0.3520708
Encoder Loss:  0.046337496  || Decoder Loss:  0.03727961 Validation Decoder Loss:  0.35178286
Encoder Loss:  0.046241663  || Decoder Loss:  0.036992084 Validation Decoder Loss:  0.35137308
Encoder Loss:  0.04616255  || Decoder Loss:  0.036733896 Validation Decoder Loss:  0.35142696
Encoder Loss:  0.04607843  || Decoder Loss:  0.036498096 Validation Decoder Loss:  0.3510272
Encoder Loss:  0.046027247  || Decoder Loss:  0.03627877 Validation Decoder Loss:  0.35121712
Encoder Loss:  0.046058014  || Decoder Loss:  0.036084414 Validation Decoder Loss:  0.35030574
Encoder Loss:  0.046278663  || Decoder Loss:  0.035909142 Validation Decoder Loss:  0.3511517
Encoder Loss:  0.046659388  || Decoder Loss:  0.03574441 Validation Decoder Loss:  0.35119343
Encoder Loss:  0.04644397  || Decoder Loss:  0.035603095 Validation Decoder Loss:  0.3497793
Encoder Loss:  0.04586065  || Decoder Loss:  0.035447463 Validation Decoder Loss:  0.35076225
Encoder Loss:  0.045726437  || Decoder Loss:  0.035317812 Validation Decoder Loss:  0.35008335
Encoder Loss:  0.04567242  || Decoder Loss:  0.035195753 Validation Decoder Loss:  0.35042757
Encoder Loss:  0.045632105  || Decoder Loss:  0.035083946 Validation Decoder Loss:  0.35005885
Encoder Loss:  0.04564747  || Decoder Loss:  0.03498278 Validation Decoder Loss:  0.35023946
Encoder Loss:  0.04572093  || Decoder Loss:  0.034894943 Validation Decoder Loss:  0.3497641
Encoder Loss:  0.045654334  || Decoder Loss:  0.03481459 Validation Decoder Loss:  0.34996217
Encoder Loss:  0.045545302  || Decoder Loss:  0.03473829 Validation Decoder Loss:  0.35005707
Encoder Loss:  0.04552655  || Decoder Loss:  0.03467228 Validation Decoder Loss:  0.3498675
Encoder Loss:  0.045526795  || Decoder Loss:  0.034612115 Validation Decoder Loss:  0.3500269
Encoder Loss:  0.045636054  || Decoder Loss:  0.034561403 Validation Decoder Loss:  0.35017687
Encoder Loss:  0.045610327  || Decoder Loss:  0.034513712 Validation Decoder Loss:  0.350144
Encoder Loss:  0.04559124  || Decoder Loss:  0.034473456 Validation Decoder Loss:  0.34933236
Encoder Loss:  0.04554405  || Decoder Loss:  0.034438062 Validation Decoder Loss:  0.34958237
Encoder Loss:  0.045504276  || Decoder Loss:  0.034401078 Validation Decoder Loss:  0.3494462
Encoder Loss:  0.045441814  || Decoder Loss:  0.03437026 Validation Decoder Loss:  0.34960514
Encoder Loss:  0.04540799  || Decoder Loss:  0.034342464 Validation Decoder Loss:  0.34957922
Encoder Loss:  0.04546695  || Decoder Loss:  0.034319226 Validation Decoder Loss:  0.3493063
Encoder Loss:  0.045400213  || Decoder Loss:  0.034294542 Validation Decoder Loss:  0.3495799
Encoder Loss:  0.045474295  || Decoder Loss:  0.034274276 Validation Decoder Loss:  0.34946808
Encoder Loss:  0.04541751  || Decoder Loss:  0.034254767 Validation Decoder Loss:  0.34959036
Model: siamese_net_lr_0.0010311599332535947 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34959036
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 634, 5, 20, 1)     383       
_________________________________________________________________
reshape_72 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 383
Trainable params: 383
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29357547  || Decoder Loss:  0.05626554 Validation Decoder Loss:  0.33677793
Encoder Loss:  0.3010171  || Decoder Loss:  0.033852227 Validation Decoder Loss:  0.3369065
Encoder Loss:  0.30086958  || Decoder Loss:  0.034112576 Validation Decoder Loss:  0.3370917
Encoder Loss:  0.3006268  || Decoder Loss:  0.034450583 Validation Decoder Loss:  0.33737844
Encoder Loss:  0.30029806  || Decoder Loss:  0.03489812 Validation Decoder Loss:  0.33781153
Encoder Loss:  0.29985684  || Decoder Loss:  0.035487026 Validation Decoder Loss:  0.33845285
Encoder Loss:  0.2992542  || Decoder Loss:  0.03626375 Validation Decoder Loss:  0.33939326
Encoder Loss:  0.29839602  || Decoder Loss:  0.037299838 Validation Decoder Loss:  0.34077352
Encoder Loss:  0.2970633  || Decoder Loss:  0.038711824 Validation Decoder Loss:  0.3428275
Encoder Loss:  0.29443642  || Decoder Loss:  0.04070529 Validation Decoder Loss:  0.34598207
Encoder Loss:  0.26048964  || Decoder Loss:  0.04363898 Validation Decoder Loss:  0.35074946
Encoder Loss:  0.12506646  || Decoder Loss:  0.04672999 Validation Decoder Loss:  0.35420844
Encoder Loss:  0.13089012  || Decoder Loss:  0.04960057 Validation Decoder Loss:  0.3588251
Encoder Loss:  0.07735331  || Decoder Loss:  0.051963434 Validation Decoder Loss:  0.36110783
Encoder Loss:  0.09546205  || Decoder Loss:  0.05375679 Validation Decoder Loss:  0.36444008
Encoder Loss:  0.09974712  || Decoder Loss:  0.056624766 Validation Decoder Loss:  0.36972368
Encoder Loss:  0.08110311  || Decoder Loss:  0.060472723 Validation Decoder Loss:  0.37505046
Encoder Loss:  0.06931099  || Decoder Loss:  0.06292727 Validation Decoder Loss:  0.3778756
Encoder Loss:  0.06554106  || Decoder Loss:  0.064547405 Validation Decoder Loss:  0.3795513
Encoder Loss:  0.08367127  || Decoder Loss:  0.06665122 Validation Decoder Loss:  0.3837828
Encoder Loss:  0.075904444  || Decoder Loss:  0.0600544 Validation Decoder Loss:  0.38369727
Encoder Loss:  0.067689136  || Decoder Loss:  0.06371061 Validation Decoder Loss:  0.3723819
Encoder Loss:  0.05587464  || Decoder Loss:  0.05031397 Validation Decoder Loss:  0.35498267
Encoder Loss:  0.057253543  || Decoder Loss:  0.03588217 Validation Decoder Loss:  0.34611464
Encoder Loss:  0.050200824  || Decoder Loss:  0.033982683 Validation Decoder Loss:  0.34663042
Encoder Loss:  0.046982355  || Decoder Loss:  0.03378181 Validation Decoder Loss:  0.34739143
Encoder Loss:  0.04598292  || Decoder Loss:  0.03384992 Validation Decoder Loss:  0.34796533
Encoder Loss:  0.04601461  || Decoder Loss:  0.03396173 Validation Decoder Loss:  0.3485996
Encoder Loss:  0.0456551  || Decoder Loss:  0.033998404 Validation Decoder Loss:  0.34900784
Encoder Loss:  0.045772295  || Decoder Loss:  0.034002494 Validation Decoder Loss:  0.3489409
Encoder Loss:  0.045847043  || Decoder Loss:  0.033988215 Validation Decoder Loss:  0.34864378
Encoder Loss:  0.045214176  || Decoder Loss:  0.033962604 Validation Decoder Loss:  0.3483147
Encoder Loss:  0.044935  || Decoder Loss:  0.033908874 Validation Decoder Loss:  0.34809119
Encoder Loss:  0.04472194  || Decoder Loss:  0.033852383 Validation Decoder Loss:  0.34785914
Encoder Loss:  0.04483237  || Decoder Loss:  0.0338169 Validation Decoder Loss:  0.34781173
Encoder Loss:  0.044750262  || Decoder Loss:  0.033800248 Validation Decoder Loss:  0.3479278
Encoder Loss:  0.044645514  || Decoder Loss:  0.033785585 Validation Decoder Loss:  0.3480523
Encoder Loss:  0.044635173  || Decoder Loss:  0.033766795 Validation Decoder Loss:  0.34797397
Encoder Loss:  0.04460328  || Decoder Loss:  0.033752374 Validation Decoder Loss:  0.34791073
Encoder Loss:  0.044603914  || Decoder Loss:  0.0337421 Validation Decoder Loss:  0.34785956
Model: siamese_net_lr_0.047986697061753306 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34785956
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_73 (Conv3DT (None, 604, 5, 20, 1)     227       
_________________________________________________________________
reshape_73 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.69601417  || Decoder Loss:  0.94371057 Validation Decoder Loss:  1.6557348
Encoder Loss:  0.7009604  || Decoder Loss:  0.9621016 Validation Decoder Loss:  1.6594237
Encoder Loss:  0.6811872  || Decoder Loss:  0.93302816 Validation Decoder Loss:  0.44109613
Encoder Loss:  0.23629299  || Decoder Loss:  0.038359556 Validation Decoder Loss:  0.35233116
Encoder Loss:  0.23540206  || Decoder Loss:  0.037612513 Validation Decoder Loss:  0.35172984
Encoder Loss:  0.23460558  || Decoder Loss:  0.03818567 Validation Decoder Loss:  0.35168117
Encoder Loss:  0.23273407  || Decoder Loss:  0.03900696 Validation Decoder Loss:  0.3517943
Encoder Loss:  0.22428684  || Decoder Loss:  0.04038654 Validation Decoder Loss:  0.35235497
Encoder Loss:  0.18659951  || Decoder Loss:  0.044176307 Validation Decoder Loss:  0.3593986
Encoder Loss:  0.29973906  || Decoder Loss:  0.4553663 Validation Decoder Loss:  1.1178489
Encoder Loss:  0.26271537  || Decoder Loss:  0.44935966 Validation Decoder Loss:  0.9183262
Encoder Loss:  0.23132236  || Decoder Loss:  0.39529777 Validation Decoder Loss:  1.0580258
Encoder Loss:  0.1804232  || Decoder Loss:  0.2930465 Validation Decoder Loss:  0.5637452
Encoder Loss:  0.10009603  || Decoder Loss:  0.13849843 Validation Decoder Loss:  0.55735606
Encoder Loss:  0.06383061  || Decoder Loss:  0.07155321 Validation Decoder Loss:  0.3621993
Encoder Loss:  0.04855861  || Decoder Loss:  0.04064105 Validation Decoder Loss:  0.36848232
Encoder Loss:  0.05035234  || Decoder Loss:  0.04076379 Validation Decoder Loss:  0.35234022
Encoder Loss:  0.051757444  || Decoder Loss:  0.037591316 Validation Decoder Loss:  0.34957784
Encoder Loss:  0.046525  || Decoder Loss:  0.035533696 Validation Decoder Loss:  0.35349217
Encoder Loss:  0.05334887  || Decoder Loss:  0.03696002 Validation Decoder Loss:  0.34835282
Encoder Loss:  0.0488566  || Decoder Loss:  0.037367962 Validation Decoder Loss:  0.34801114
Encoder Loss:  0.04999738  || Decoder Loss:  0.039480727 Validation Decoder Loss:  0.35321933
Encoder Loss:  0.048139475  || Decoder Loss:  0.037256718 Validation Decoder Loss:  0.34979784
Encoder Loss:  0.050456878  || Decoder Loss:  0.03748438 Validation Decoder Loss:  0.3498242
Encoder Loss:  0.053179298  || Decoder Loss:  0.03596954 Validation Decoder Loss:  0.34722832
Encoder Loss:  0.05318593  || Decoder Loss:  0.03704817 Validation Decoder Loss:  0.352063
Encoder Loss:  0.052989997  || Decoder Loss:  0.03769747 Validation Decoder Loss:  0.37016416
Encoder Loss:  0.049074885  || Decoder Loss:  0.040757593 Validation Decoder Loss:  0.34893474
Encoder Loss:  0.04822183  || Decoder Loss:  0.03581597 Validation Decoder Loss:  0.3586321
Encoder Loss:  0.052360624  || Decoder Loss:  0.038305517 Validation Decoder Loss:  0.3619015
Encoder Loss:  0.052915834  || Decoder Loss:  0.039950028 Validation Decoder Loss:  0.35292533
Encoder Loss:  0.05123397  || Decoder Loss:  0.037293516 Validation Decoder Loss:  0.35637885
Encoder Loss:  0.047256723  || Decoder Loss:  0.037624784 Validation Decoder Loss:  0.35261923
Encoder Loss:  0.046539124  || Decoder Loss:  0.037724704 Validation Decoder Loss:  0.3516376
Encoder Loss:  0.05006506  || Decoder Loss:  0.037589956 Validation Decoder Loss:  0.35241398
Encoder Loss:  0.045064975  || Decoder Loss:  0.035516664 Validation Decoder Loss:  0.35585085
Encoder Loss:  0.04926535  || Decoder Loss:  0.03831863 Validation Decoder Loss:  0.35501876
Encoder Loss:  0.045122568  || Decoder Loss:  0.0362415 Validation Decoder Loss:  0.35998774
Encoder Loss:  0.04666323  || Decoder Loss:  0.03848761 Validation Decoder Loss:  0.3496567
Encoder Loss:  0.04441915  || Decoder Loss:  0.03510521 Validation Decoder Loss:  0.35029948
Model: siamese_net_lr_0.037732662690953656 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35029948
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 634, 5, 20, 1)     257       
_________________________________________________________________
reshape_74 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.83322436  || Decoder Loss:  0.9424675 Validation Decoder Loss:  1.6609781
Encoder Loss:  0.85416055  || Decoder Loss:  0.96649384 Validation Decoder Loss:  1.6609864
Encoder Loss:  0.85409963  || Decoder Loss:  0.9664503 Validation Decoder Loss:  1.6609759
Encoder Loss:  0.8540134  || Decoder Loss:  0.9663882 Validation Decoder Loss:  1.6609597
Encoder Loss:  0.85390055  || Decoder Loss:  0.96631277 Validation Decoder Loss:  1.6609378
Encoder Loss:  0.8537514  || Decoder Loss:  0.96622366 Validation Decoder Loss:  1.6609092
Encoder Loss:  0.8535395  || Decoder Loss:  0.96611995 Validation Decoder Loss:  1.6608715
Encoder Loss:  0.8531627  || Decoder Loss:  0.9659999 Validation Decoder Loss:  1.6608222
Encoder Loss:  0.8492868  || Decoder Loss:  0.9658612 Validation Decoder Loss:  1.6607542
Encoder Loss:  0.8528251  || Decoder Loss:  0.96570694 Validation Decoder Loss:  1.6606776
Encoder Loss:  0.8526619  || Decoder Loss:  0.96553224 Validation Decoder Loss:  1.6605855
Encoder Loss:  0.8521821  || Decoder Loss:  0.96533114 Validation Decoder Loss:  1.6604688
Encoder Loss:  0.8510889  || Decoder Loss:  0.96509933 Validation Decoder Loss:  1.6603203
Encoder Loss:  0.8197236  || Decoder Loss:  0.964842 Validation Decoder Loss:  1.6601243
Encoder Loss:  0.78442687  || Decoder Loss:  0.96464384 Validation Decoder Loss:  1.6598678
Encoder Loss:  0.774375  || Decoder Loss:  0.9644885 Validation Decoder Loss:  1.6595197
Encoder Loss:  0.77360207  || Decoder Loss:  0.9642947 Validation Decoder Loss:  1.6589346
Encoder Loss:  0.7754917  || Decoder Loss:  0.96396345 Validation Decoder Loss:  1.6576939
Encoder Loss:  0.7734951  || Decoder Loss:  0.96273375 Validation Decoder Loss:  1.6483548
Encoder Loss:  0.18493624  || Decoder Loss:  0.21600348 Validation Decoder Loss:  0.33783627
Encoder Loss:  0.042841956  || Decoder Loss:  0.034781765 Validation Decoder Loss:  0.33788854
Encoder Loss:  0.043459505  || Decoder Loss:  0.034813818 Validation Decoder Loss:  0.33789217
Encoder Loss:  0.04042629  || Decoder Loss:  0.03484409 Validation Decoder Loss:  0.3378482
Encoder Loss:  0.044712197  || Decoder Loss:  0.034878418 Validation Decoder Loss:  0.33783266
Encoder Loss:  0.0409502  || Decoder Loss:  0.034910824 Validation Decoder Loss:  0.33779824
Encoder Loss:  0.041517314  || Decoder Loss:  0.034942392 Validation Decoder Loss:  0.3377721
Encoder Loss:  0.041198675  || Decoder Loss:  0.034978162 Validation Decoder Loss:  0.3377344
Encoder Loss:  0.042167135  || Decoder Loss:  0.035011537 Validation Decoder Loss:  0.3377239
Encoder Loss:  0.043577045  || Decoder Loss:  0.035043664 Validation Decoder Loss:  0.33771035
Encoder Loss:  0.04185318  || Decoder Loss:  0.035083774 Validation Decoder Loss:  0.33768332
Encoder Loss:  0.041882936  || Decoder Loss:  0.03511727 Validation Decoder Loss:  0.33764675
Encoder Loss:  0.041642684  || Decoder Loss:  0.035154425 Validation Decoder Loss:  0.33761495
Encoder Loss:  0.04534423  || Decoder Loss:  0.03519281 Validation Decoder Loss:  0.33759803
Encoder Loss:  0.041603927  || Decoder Loss:  0.035234284 Validation Decoder Loss:  0.33757168
Encoder Loss:  0.041717365  || Decoder Loss:  0.03528018 Validation Decoder Loss:  0.33751288
Encoder Loss:  0.04372687  || Decoder Loss:  0.035333186 Validation Decoder Loss:  0.3375005
Encoder Loss:  0.04146966  || Decoder Loss:  0.035375744 Validation Decoder Loss:  0.33747727
Encoder Loss:  0.042840555  || Decoder Loss:  0.035414744 Validation Decoder Loss:  0.33745933
Encoder Loss:  0.041321553  || Decoder Loss:  0.035458203 Validation Decoder Loss:  0.33742815
Encoder Loss:  0.04165327  || Decoder Loss:  0.035502676 Validation Decoder Loss:  0.3373902
Model: siamese_net_lr_0.06975375246686732 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33739018
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 89, 30, 20, 1)     469       
_________________________________________________________________
reshape_75 (Reshape)         (None, 2670, 20, 1)       0         
=================================================================
Total params: 469
Trainable params: 469
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 2670, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 3245, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.720998  || Decoder Loss:  0.92523843 Validation Decoder Loss:  1.6427574
Encoder Loss:  0.73037946  || Decoder Loss:  0.9433065 Validation Decoder Loss:  1.642861
Encoder Loss:  0.7346387  || Decoder Loss:  0.9425093 Validation Decoder Loss:  1.643002
Encoder Loss:  0.7334613  || Decoder Loss:  0.94144225 Validation Decoder Loss:  1.6431831
Encoder Loss:  0.7318685  || Decoder Loss:  0.9400803 Validation Decoder Loss:  1.6434058
Encoder Loss:  0.72972  || Decoder Loss:  0.9383409 Validation Decoder Loss:  1.6436574
Encoder Loss:  0.7266521  || Decoder Loss:  0.9360534 Validation Decoder Loss:  1.6438816
Encoder Loss:  0.72110826  || Decoder Loss:  0.9328398 Validation Decoder Loss:  1.6438615
Encoder Loss:  0.7094607  || Decoder Loss:  0.9277815 Validation Decoder Loss:  1.642627
Encoder Loss:  0.70140433  || Decoder Loss:  0.91572815 Validation Decoder Loss:  1.6268895
Encoder Loss:  0.450816  || Decoder Loss:  0.612485 Validation Decoder Loss:  1.0450993
Encoder Loss:  0.33768073  || Decoder Loss:  0.51000327 Validation Decoder Loss:  0.8949119
Encoder Loss:  0.27245867  || Decoder Loss:  0.40026432 Validation Decoder Loss:  0.9168691
Encoder Loss:  0.33225146  || Decoder Loss:  0.5046304 Validation Decoder Loss:  0.89092606
Encoder Loss:  0.28522167  || Decoder Loss:  0.425698 Validation Decoder Loss:  1.0106726
Encoder Loss:  0.2995094  || Decoder Loss:  0.4526614 Validation Decoder Loss:  1.0580633
Encoder Loss:  0.29922011  || Decoder Loss:  0.4535491 Validation Decoder Loss:  1.0423617
Encoder Loss:  0.29641736  || Decoder Loss:  0.45184234 Validation Decoder Loss:  1.0647042
Encoder Loss:  0.29224578  || Decoder Loss:  0.44651318 Validation Decoder Loss:  1.0579326
Encoder Loss:  0.28139114  || Decoder Loss:  0.43073875 Validation Decoder Loss:  1.0234705
Encoder Loss:  0.21097665  || Decoder Loss:  0.312784 Validation Decoder Loss:  0.9179182
Encoder Loss:  0.31022042  || Decoder Loss:  0.48431075 Validation Decoder Loss:  0.9783883
Encoder Loss:  0.31297642  || Decoder Loss:  0.49052274 Validation Decoder Loss:  0.9855865
Encoder Loss:  0.3109111  || Decoder Loss:  0.48896444 Validation Decoder Loss:  0.98910975
Encoder Loss:  0.30832812  || Decoder Loss:  0.48793885 Validation Decoder Loss:  0.9879927
Encoder Loss:  0.30879837  || Decoder Loss:  0.4864119 Validation Decoder Loss:  0.983124
Encoder Loss:  0.30635223  || Decoder Loss:  0.48267 Validation Decoder Loss:  0.9761119
Encoder Loss:  0.2939733  || Decoder Loss:  0.46441737 Validation Decoder Loss:  0.5860101
Encoder Loss:  0.28959262  || Decoder Loss:  0.45562214 Validation Decoder Loss:  0.94088626
Encoder Loss:  0.27558625  || Decoder Loss:  0.4282841 Validation Decoder Loss:  0.77125376
Encoder Loss:  0.2951129  || Decoder Loss:  0.46463612 Validation Decoder Loss:  0.9927949
Encoder Loss:  0.31001046  || Decoder Loss:  0.4901664 Validation Decoder Loss:  0.9932101
Encoder Loss:  0.31181794  || Decoder Loss:  0.4897076 Validation Decoder Loss:  0.99229145
Encoder Loss:  0.31022447  || Decoder Loss:  0.4889826 Validation Decoder Loss:  0.99076647
Encoder Loss:  0.30731145  || Decoder Loss:  0.48749587 Validation Decoder Loss:  0.98633283
Encoder Loss:  0.3067027  || Decoder Loss:  0.48483998 Validation Decoder Loss:  0.98207104
Encoder Loss:  0.30463  || Decoder Loss:  0.47859347 Validation Decoder Loss:  0.9492688
Encoder Loss:  0.27373594  || Decoder Loss:  0.4272287 Validation Decoder Loss:  0.98547935
Encoder Loss:  0.30825576  || Decoder Loss:  0.48781148 Validation Decoder Loss:  0.9935266
Encoder Loss:  0.3093169  || Decoder Loss:  0.48970804 Validation Decoder Loss:  0.99264485
Model: siamese_net_lr_0.036279852050248994 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99264485
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_76 (Conv3DT (None, 445, 6, 20, 1)     513       
_________________________________________________________________
reshape_76 (Reshape)         (None, 2670, 20, 1)       0         
=================================================================
Total params: 513
Trainable params: 513
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 2670, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 3245, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26914907  || Decoder Loss:  0.47288406 Validation Decoder Loss:  0.9919224
Encoder Loss:  0.24095522  || Decoder Loss:  0.42556068 Validation Decoder Loss:  0.87083244
Encoder Loss:  0.20709966  || Decoder Loss:  0.35944545 Validation Decoder Loss:  0.76262426
Encoder Loss:  0.17882301  || Decoder Loss:  0.30362546 Validation Decoder Loss:  0.68163526
Encoder Loss:  0.15697388  || Decoder Loss:  0.26051217 Validation Decoder Loss:  0.62247086
Encoder Loss:  0.14035536  || Decoder Loss:  0.22769344 Validation Decoder Loss:  0.579194
Encoder Loss:  0.12769836  || Decoder Loss:  0.20258991 Validation Decoder Loss:  0.54675424
Encoder Loss:  0.11776322  || Decoder Loss:  0.18305099 Validation Decoder Loss:  0.5220262
Encoder Loss:  0.10996067  || Decoder Loss:  0.16752449 Validation Decoder Loss:  0.50252944
Encoder Loss:  0.10354886  || Decoder Loss:  0.15495549 Validation Decoder Loss:  0.48695934
Encoder Loss:  0.09836224  || Decoder Loss:  0.14459081 Validation Decoder Loss:  0.47413093
Encoder Loss:  0.09388548  || Decoder Loss:  0.1359025 Validation Decoder Loss:  0.4635263
Encoder Loss:  0.09018345  || Decoder Loss:  0.12851873 Validation Decoder Loss:  0.4545366
Encoder Loss:  0.0869548  || Decoder Loss:  0.12216244 Validation Decoder Loss:  0.44685113
Encoder Loss:  0.084159635  || Decoder Loss:  0.116631225 Validation Decoder Loss:  0.44017828
Encoder Loss:  0.08163667  || Decoder Loss:  0.111770675 Validation Decoder Loss:  0.43437278
Encoder Loss:  0.07947503  || Decoder Loss:  0.10746632 Validation Decoder Loss:  0.42924964
Encoder Loss:  0.077555455  || Decoder Loss:  0.10362394 Validation Decoder Loss:  0.4246663
Encoder Loss:  0.075746305  || Decoder Loss:  0.10017031 Validation Decoder Loss:  0.42057744
Encoder Loss:  0.074162774  || Decoder Loss:  0.09705076 Validation Decoder Loss:  0.41690043
Encoder Loss:  0.072731525  || Decoder Loss:  0.09421648 Validation Decoder Loss:  0.4135711
Encoder Loss:  0.07141529  || Decoder Loss:  0.0916288 Validation Decoder Loss:  0.41054654
Encoder Loss:  0.070208564  || Decoder Loss:  0.08925575 Validation Decoder Loss:  0.4077962
Encoder Loss:  0.06910341  || Decoder Loss:  0.08707102 Validation Decoder Loss:  0.40526873
Encoder Loss:  0.068076186  || Decoder Loss:  0.0850521 Validation Decoder Loss:  0.40295705
Encoder Loss:  0.067142144  || Decoder Loss:  0.08318032 Validation Decoder Loss:  0.4008083
Encoder Loss:  0.06624654  || Decoder Loss:  0.08143964 Validation Decoder Loss:  0.39882624
Encoder Loss:  0.06542612  || Decoder Loss:  0.079816274 Validation Decoder Loss:  0.3969833
Encoder Loss:  0.064658254  || Decoder Loss:  0.078298256 Validation Decoder Loss:  0.39526537
Encoder Loss:  0.06393324  || Decoder Loss:  0.076875344 Validation Decoder Loss:  0.39366657
Encoder Loss:  0.063256316  || Decoder Loss:  0.075538576 Validation Decoder Loss:  0.39217347
Encoder Loss:  0.06264603  || Decoder Loss:  0.074279964 Validation Decoder Loss:  0.39075342
Encoder Loss:  0.062023144  || Decoder Loss:  0.07309269 Validation Decoder Loss:  0.3894442
Encoder Loss:  0.061469465  || Decoder Loss:  0.07197073 Validation Decoder Loss:  0.38818884
Encoder Loss:  0.060908712  || Decoder Loss:  0.07090824 Validation Decoder Loss:  0.38702327
Encoder Loss:  0.06040296  || Decoder Loss:  0.06990049 Validation Decoder Loss:  0.38592157
Encoder Loss:  0.059932012  || Decoder Loss:  0.06894323 Validation Decoder Loss:  0.38485876
Encoder Loss:  0.059448015  || Decoder Loss:  0.06803311 Validation Decoder Loss:  0.38386708
Encoder Loss:  0.05901727  || Decoder Loss:  0.06716579 Validation Decoder Loss:  0.38293266
Encoder Loss:  0.058608674  || Decoder Loss:  0.06633819 Validation Decoder Loss:  0.38202095
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38202095
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 604, 5, 20, 1)     542       
_________________________________________________________________
reshape_77 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 542
Trainable params: 542
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.73914766  || Decoder Loss:  0.9462558 Validation Decoder Loss:  1.6484523
Encoder Loss:  0.75228274  || Decoder Loss:  0.9629708 Validation Decoder Loss:  1.6471727
Encoder Loss:  0.7517439  || Decoder Loss:  0.96244466 Validation Decoder Loss:  1.6449298
Encoder Loss:  0.75077087  || Decoder Loss:  0.9614822 Validation Decoder Loss:  1.64117
Encoder Loss:  0.7489408  || Decoder Loss:  0.9596593 Validation Decoder Loss:  1.6347128
Encoder Loss:  0.74531054  || Decoder Loss:  0.9560242 Validation Decoder Loss:  1.6230602
Encoder Loss:  0.737592  || Decoder Loss:  0.94825745 Validation Decoder Loss:  1.6000278
Encoder Loss:  0.7189396  || Decoder Loss:  0.92934096 Validation Decoder Loss:  1.5440556
Encoder Loss:  0.6533181  || Decoder Loss:  0.86125183 Validation Decoder Loss:  1.2774861
Encoder Loss:  0.36403507  || Decoder Loss:  0.53276485 Validation Decoder Loss:  0.88716435
Encoder Loss:  0.315273  || Decoder Loss:  0.49098215 Validation Decoder Loss:  0.82176894
Encoder Loss:  0.30028075  || Decoder Loss:  0.46672565 Validation Decoder Loss:  1.0454266
Encoder Loss:  0.2934426  || Decoder Loss:  0.45700714 Validation Decoder Loss:  1.1258991
Encoder Loss:  0.3131695  || Decoder Loss:  0.49175388 Validation Decoder Loss:  1.1348019
Encoder Loss:  0.31446663  || Decoder Loss:  0.49410263 Validation Decoder Loss:  1.130219
Encoder Loss:  0.31403685  || Decoder Loss:  0.49335912 Validation Decoder Loss:  1.1106787
Encoder Loss:  0.31382686  || Decoder Loss:  0.4915513 Validation Decoder Loss:  1.1449466
Encoder Loss:  0.3141362  || Decoder Loss:  0.492774 Validation Decoder Loss:  1.12848
Encoder Loss:  0.31326738  || Decoder Loss:  0.4923409 Validation Decoder Loss:  1.128992
Encoder Loss:  0.31521475  || Decoder Loss:  0.4947404 Validation Decoder Loss:  1.1245962
Encoder Loss:  0.3148178  || Decoder Loss:  0.49362782 Validation Decoder Loss:  1.1169136
Encoder Loss:  0.31512448  || Decoder Loss:  0.49223474 Validation Decoder Loss:  1.1178629
Encoder Loss:  0.31211483  || Decoder Loss:  0.4897703 Validation Decoder Loss:  1.1186855
Encoder Loss:  0.31163028  || Decoder Loss:  0.48888505 Validation Decoder Loss:  1.1245291
Encoder Loss:  0.31171834  || Decoder Loss:  0.48899078 Validation Decoder Loss:  1.1181519
Encoder Loss:  0.30809066  || Decoder Loss:  0.48196056 Validation Decoder Loss:  1.1262498
Encoder Loss:  0.29468593  || Decoder Loss:  0.46064734 Validation Decoder Loss:  0.8110032
Encoder Loss:  0.29307798  || Decoder Loss:  0.45746487 Validation Decoder Loss:  1.1178918
Encoder Loss:  0.30603874  || Decoder Loss:  0.47919 Validation Decoder Loss:  1.0827123
Encoder Loss:  0.28185865  || Decoder Loss:  0.43827236 Validation Decoder Loss:  0.8383477
Encoder Loss:  0.31236747  || Decoder Loss:  0.49187252 Validation Decoder Loss:  0.83757377
Encoder Loss:  0.31316018  || Decoder Loss:  0.4919826 Validation Decoder Loss:  0.85880923
Encoder Loss:  0.31317523  || Decoder Loss:  0.49240112 Validation Decoder Loss:  0.84075725
Encoder Loss:  0.31308678  || Decoder Loss:  0.49206203 Validation Decoder Loss:  0.8530097
Encoder Loss:  0.31314117  || Decoder Loss:  0.4916789 Validation Decoder Loss:  0.83529115
Encoder Loss:  0.31271398  || Decoder Loss:  0.49124393 Validation Decoder Loss:  0.81787694
Encoder Loss:  0.3119352  || Decoder Loss:  0.48942378 Validation Decoder Loss:  0.8195322
Encoder Loss:  0.31136313  || Decoder Loss:  0.48897168 Validation Decoder Loss:  0.8344445
Encoder Loss:  0.30935872  || Decoder Loss:  0.48481223 Validation Decoder Loss:  0.8072289
Encoder Loss:  0.3083483  || Decoder Loss:  0.4830835 Validation Decoder Loss:  0.8034382
Model: siamese_net_lr_0.045295001575507025 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8034382
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 317, 10, 20, 1)    1525      
_________________________________________________________________
reshape_78 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 1,525
Trainable params: 1,525
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31641778  || Decoder Loss:  0.1880961 Validation Decoder Loss:  0.34513253
Encoder Loss:  0.29497156  || Decoder Loss:  0.037358437 Validation Decoder Loss:  0.34739572
Encoder Loss:  0.2717415  || Decoder Loss:  0.040302906 Validation Decoder Loss:  0.35177737
Encoder Loss:  0.2889891  || Decoder Loss:  0.045873534 Validation Decoder Loss:  0.36213374
Encoder Loss:  0.25388795  || Decoder Loss:  0.058224417 Validation Decoder Loss:  0.38586116
Encoder Loss:  0.26842552  || Decoder Loss:  0.087050036 Validation Decoder Loss:  0.45931828
Encoder Loss:  0.23020467  || Decoder Loss:  0.22421724 Validation Decoder Loss:  0.9897953
Encoder Loss:  0.20556663  || Decoder Loss:  0.4542322 Validation Decoder Loss:  0.950047
Encoder Loss:  0.12426576  || Decoder Loss:  0.23711495 Validation Decoder Loss:  0.43401405
Encoder Loss:  0.05791956  || Decoder Loss:  0.05355625 Validation Decoder Loss:  0.34275448
Encoder Loss:  0.05118113  || Decoder Loss:  0.035157032 Validation Decoder Loss:  0.34578973
Encoder Loss:  0.049988598  || Decoder Loss:  0.034060083 Validation Decoder Loss:  0.3444279
Encoder Loss:  0.048595466  || Decoder Loss:  0.03389368 Validation Decoder Loss:  0.34413353
Encoder Loss:  0.0472038  || Decoder Loss:  0.033900954 Validation Decoder Loss:  0.34387445
Encoder Loss:  0.04631123  || Decoder Loss:  0.033931874 Validation Decoder Loss:  0.34392953
Encoder Loss:  0.04600348  || Decoder Loss:  0.03395976 Validation Decoder Loss:  0.34393257
Encoder Loss:  0.046176303  || Decoder Loss:  0.033968408 Validation Decoder Loss:  0.34387136
Encoder Loss:  0.047145292  || Decoder Loss:  0.033947233 Validation Decoder Loss:  0.34358525
Encoder Loss:  0.047741827  || Decoder Loss:  0.033909667 Validation Decoder Loss:  0.34344923
Encoder Loss:  0.046182808  || Decoder Loss:  0.033878185 Validation Decoder Loss:  0.34362918
Encoder Loss:  0.046105634  || Decoder Loss:  0.033853773 Validation Decoder Loss:  0.34384853
Encoder Loss:  0.046469375  || Decoder Loss:  0.033833403 Validation Decoder Loss:  0.3439951
Encoder Loss:  0.045904547  || Decoder Loss:  0.033808194 Validation Decoder Loss:  0.34376383
Encoder Loss:  0.047372192  || Decoder Loss:  0.033783164 Validation Decoder Loss:  0.3438112
Encoder Loss:  0.045465525  || Decoder Loss:  0.03377401 Validation Decoder Loss:  0.3446347
Encoder Loss:  0.045382112  || Decoder Loss:  0.033812832 Validation Decoder Loss:  0.34589177
Encoder Loss:  0.0453187  || Decoder Loss:  0.0338927 Validation Decoder Loss:  0.34667006
Encoder Loss:  0.04522742  || Decoder Loss:  0.033925828 Validation Decoder Loss:  0.34514228
Encoder Loss:  0.04499771  || Decoder Loss:  0.033856504 Validation Decoder Loss:  0.34487784
Encoder Loss:  0.044929698  || Decoder Loss:  0.033894572 Validation Decoder Loss:  0.34448773
Encoder Loss:  0.044927683  || Decoder Loss:  0.0340085 Validation Decoder Loss:  0.34324038
Encoder Loss:  0.045068856  || Decoder Loss:  0.034282017 Validation Decoder Loss:  0.34240106
Encoder Loss:  0.04510272  || Decoder Loss:  0.034549788 Validation Decoder Loss:  0.3428752
Encoder Loss:  0.045059055  || Decoder Loss:  0.03455755 Validation Decoder Loss:  0.34236228
Encoder Loss:  0.0451207  || Decoder Loss:  0.03467233 Validation Decoder Loss:  0.34303266
Encoder Loss:  0.04505786  || Decoder Loss:  0.034565613 Validation Decoder Loss:  0.34243265
Encoder Loss:  0.045119997  || Decoder Loss:  0.034678627 Validation Decoder Loss:  0.34332114
Encoder Loss:  0.044970263  || Decoder Loss:  0.034529764 Validation Decoder Loss:  0.3424735
Encoder Loss:  0.045088693  || Decoder Loss:  0.034656607 Validation Decoder Loss:  0.34348455
Encoder Loss:  0.04501604  || Decoder Loss:  0.034486435 Validation Decoder Loss:  0.34256172
Model: siamese_net_lr_0.024226237549952036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34256172
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_79 (Conv3DT (None, 302, 10, 20, 1)    353       
_________________________________________________________________
reshape_79 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08751308  || Decoder Loss:  0.15455933 Validation Decoder Loss:  0.3847098
Encoder Loss:  0.052684013  || Decoder Loss:  0.053670984 Validation Decoder Loss:  0.36980385
Encoder Loss:  0.05029171  || Decoder Loss:  0.04879153 Validation Decoder Loss:  0.36438438
Encoder Loss:  0.04926465  || Decoder Loss:  0.046116628 Validation Decoder Loss:  0.36041027
Encoder Loss:  0.048548236  || Decoder Loss:  0.04418007 Validation Decoder Loss:  0.35773957
Encoder Loss:  0.048052426  || Decoder Loss:  0.042718392 Validation Decoder Loss:  0.35592055
Encoder Loss:  0.047660057  || Decoder Loss:  0.0415803 Validation Decoder Loss:  0.35455585
Encoder Loss:  0.04733752  || Decoder Loss:  0.040642094 Validation Decoder Loss:  0.3535499
Encoder Loss:  0.047072362  || Decoder Loss:  0.039874345 Validation Decoder Loss:  0.3527086
Encoder Loss:  0.046845894  || Decoder Loss:  0.039220627 Validation Decoder Loss:  0.35198945
Encoder Loss:  0.046658363  || Decoder Loss:  0.03866099 Validation Decoder Loss:  0.35134494
Encoder Loss:  0.046519116  || Decoder Loss:  0.038172193 Validation Decoder Loss:  0.35090828
Encoder Loss:  0.047308225  || Decoder Loss:  0.037754107 Validation Decoder Loss:  0.35052323
Encoder Loss:  0.047826353  || Decoder Loss:  0.037386827 Validation Decoder Loss:  0.35015213
Encoder Loss:  0.046298165  || Decoder Loss:  0.037095953 Validation Decoder Loss:  0.34959203
Encoder Loss:  0.046055783  || Decoder Loss:  0.03676376 Validation Decoder Loss:  0.34936443
Encoder Loss:  0.04592865  || Decoder Loss:  0.03648766 Validation Decoder Loss:  0.34930456
Encoder Loss:  0.045890763  || Decoder Loss:  0.036282677 Validation Decoder Loss:  0.34879333
Encoder Loss:  0.04575663  || Decoder Loss:  0.03606176 Validation Decoder Loss:  0.34848052
Encoder Loss:  0.04568876  || Decoder Loss:  0.035875052 Validation Decoder Loss:  0.34833553
Encoder Loss:  0.045628075  || Decoder Loss:  0.035710286 Validation Decoder Loss:  0.34813553
Encoder Loss:  0.045572184  || Decoder Loss:  0.03555948 Validation Decoder Loss:  0.34788328
Encoder Loss:  0.04552453  || Decoder Loss:  0.03542201 Validation Decoder Loss:  0.34762728
Encoder Loss:  0.045475144  || Decoder Loss:  0.035296965 Validation Decoder Loss:  0.34739062
Encoder Loss:  0.045436315  || Decoder Loss:  0.035184044 Validation Decoder Loss:  0.3472022
Encoder Loss:  0.04539432  || Decoder Loss:  0.035080433 Validation Decoder Loss:  0.3470362
Encoder Loss:  0.045358524  || Decoder Loss:  0.034986675 Validation Decoder Loss:  0.34691066
Encoder Loss:  0.045325767  || Decoder Loss:  0.03490062 Validation Decoder Loss:  0.34681115
Encoder Loss:  0.04529605  || Decoder Loss:  0.034821007 Validation Decoder Loss:  0.34670076
Encoder Loss:  0.045268666  || Decoder Loss:  0.034747817 Validation Decoder Loss:  0.3466015
Encoder Loss:  0.045236915  || Decoder Loss:  0.034679316 Validation Decoder Loss:  0.34647924
Encoder Loss:  0.04521534  || Decoder Loss:  0.034617726 Validation Decoder Loss:  0.34640253
Encoder Loss:  0.04518833  || Decoder Loss:  0.03455847 Validation Decoder Loss:  0.34630597
Encoder Loss:  0.04516692  || Decoder Loss:  0.034504384 Validation Decoder Loss:  0.34623238
Encoder Loss:  0.045149036  || Decoder Loss:  0.03445291 Validation Decoder Loss:  0.34616274
Encoder Loss:  0.04512696  || Decoder Loss:  0.034405258 Validation Decoder Loss:  0.34610027
Encoder Loss:  0.045106206  || Decoder Loss:  0.034360573 Validation Decoder Loss:  0.34605205
Encoder Loss:  0.04508944  || Decoder Loss:  0.034321316 Validation Decoder Loss:  0.34606794
Encoder Loss:  0.045079872  || Decoder Loss:  0.034280285 Validation Decoder Loss:  0.3460521
Encoder Loss:  0.045058865  || Decoder Loss:  0.034243777 Validation Decoder Loss:  0.34599042
Model: siamese_net_lr_0.00038592614940493984 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34599042
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 634, 5, 20, 1)     572       
_________________________________________________________________
reshape_80 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 572
Trainable params: 572
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2283159  || Decoder Loss:  0.553163 Validation Decoder Loss:  0.95300835
Encoder Loss:  0.1608294  || Decoder Loss:  0.41316968 Validation Decoder Loss:  0.77768564
Encoder Loss:  0.14080618  || Decoder Loss:  0.3454764 Validation Decoder Loss:  0.70418805
Encoder Loss:  0.12537813  || Decoder Loss:  0.2933741 Validation Decoder Loss:  0.6373924
Encoder Loss:  0.1137325  || Decoder Loss:  0.25337544 Validation Decoder Loss:  0.58607733
Encoder Loss:  0.10498783  || Decoder Loss:  0.22210123 Validation Decoder Loss:  0.55037624
Encoder Loss:  0.098234  || Decoder Loss:  0.19863926 Validation Decoder Loss:  0.52353334
Encoder Loss:  0.092969745  || Decoder Loss:  0.1806547 Validation Decoder Loss:  0.50233066
Encoder Loss:  0.088750355  || Decoder Loss:  0.16601181 Validation Decoder Loss:  0.48583364
Encoder Loss:  0.08531028  || Decoder Loss:  0.15432036 Validation Decoder Loss:  0.47233894
Encoder Loss:  0.0824166  || Decoder Loss:  0.14456996 Validation Decoder Loss:  0.4612164
Encoder Loss:  0.07996397  || Decoder Loss:  0.13634801 Validation Decoder Loss:  0.4519962
Encoder Loss:  0.07781764  || Decoder Loss:  0.12940879 Validation Decoder Loss:  0.4441565
Encoder Loss:  0.075898245  || Decoder Loss:  0.123418264 Validation Decoder Loss:  0.43719357
Encoder Loss:  0.074292764  || Decoder Loss:  0.1181211 Validation Decoder Loss:  0.43127114
Encoder Loss:  0.07283251  || Decoder Loss:  0.11349083 Validation Decoder Loss:  0.42597437
Encoder Loss:  0.07157115  || Decoder Loss:  0.10934372 Validation Decoder Loss:  0.42152315
Encoder Loss:  0.07027848  || Decoder Loss:  0.105719164 Validation Decoder Loss:  0.417306
Encoder Loss:  0.0692651  || Decoder Loss:  0.1023863 Validation Decoder Loss:  0.41355503
Encoder Loss:  0.06831003  || Decoder Loss:  0.099363536 Validation Decoder Loss:  0.4102821
Encoder Loss:  0.0673836  || Decoder Loss:  0.09667717 Validation Decoder Loss:  0.40727627
Encoder Loss:  0.06650672  || Decoder Loss:  0.094217405 Validation Decoder Loss:  0.40458906
Encoder Loss:  0.06561747  || Decoder Loss:  0.091962464 Validation Decoder Loss:  0.4020661
Encoder Loss:  0.06484023  || Decoder Loss:  0.08986316 Validation Decoder Loss:  0.3996806
Encoder Loss:  0.0641825  || Decoder Loss:  0.087920085 Validation Decoder Loss:  0.39754814
Encoder Loss:  0.06354255  || Decoder Loss:  0.08611825 Validation Decoder Loss:  0.39554498
Encoder Loss:  0.062876694  || Decoder Loss:  0.08447484 Validation Decoder Loss:  0.39384753
Encoder Loss:  0.06217806  || Decoder Loss:  0.08296518 Validation Decoder Loss:  0.39227346
Encoder Loss:  0.061437353  || Decoder Loss:  0.08157254 Validation Decoder Loss:  0.39064497
Encoder Loss:  0.060949065  || Decoder Loss:  0.08016502 Validation Decoder Loss:  0.38919836
Encoder Loss:  0.06033904  || Decoder Loss:  0.07889266 Validation Decoder Loss:  0.38767278
Encoder Loss:  0.05993182  || Decoder Loss:  0.077640295 Validation Decoder Loss:  0.38643938
Encoder Loss:  0.05928023  || Decoder Loss:  0.076544076 Validation Decoder Loss:  0.38515437
Encoder Loss:  0.05882314  || Decoder Loss:  0.07545124 Validation Decoder Loss:  0.383974
Encoder Loss:  0.058341593  || Decoder Loss:  0.07442395 Validation Decoder Loss:  0.38279158
Encoder Loss:  0.057984132  || Decoder Loss:  0.07342932 Validation Decoder Loss:  0.3817112
Encoder Loss:  0.057566155  || Decoder Loss:  0.072514474 Validation Decoder Loss:  0.38075048
Encoder Loss:  0.05710745  || Decoder Loss:  0.071657345 Validation Decoder Loss:  0.37980694
Encoder Loss:  0.05681168  || Decoder Loss:  0.070838735 Validation Decoder Loss:  0.37893468
Encoder Loss:  0.05657726  || Decoder Loss:  0.07006886 Validation Decoder Loss:  0.37809086
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37809086
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 151, 20, 20, 1)    1409      
_________________________________________________________________
reshape_81 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 1,409
Trainable params: 1,409
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6574311  || Decoder Loss:  0.9291442 Validation Decoder Loss:  1.6573955
Encoder Loss:  0.66577286  || Decoder Loss:  0.94329035 Validation Decoder Loss:  1.6539971
Encoder Loss:  0.6566999  || Decoder Loss:  0.9364665 Validation Decoder Loss:  1.6453686
Encoder Loss:  0.4695225  || Decoder Loss:  0.63350874 Validation Decoder Loss:  0.369317
Encoder Loss:  0.12179115  || Decoder Loss:  0.08875021 Validation Decoder Loss:  0.38297173
Encoder Loss:  0.10333759  || Decoder Loss:  0.10194817 Validation Decoder Loss:  0.39913273
Encoder Loss:  0.10722066  || Decoder Loss:  0.120557144 Validation Decoder Loss:  0.43238908
Encoder Loss:  0.12324061  || Decoder Loss:  0.16302139 Validation Decoder Loss:  0.53748655
Encoder Loss:  0.14043786  || Decoder Loss:  0.23653826 Validation Decoder Loss:  0.65433395
Encoder Loss:  0.17892775  || Decoder Loss:  0.3246544 Validation Decoder Loss:  0.79787916
Encoder Loss:  0.20893674  || Decoder Loss:  0.39058265 Validation Decoder Loss:  0.87685287
Encoder Loss:  0.22761852  || Decoder Loss:  0.43142793 Validation Decoder Loss:  0.9262162
Encoder Loss:  0.23692752  || Decoder Loss:  0.45153704 Validation Decoder Loss:  0.95430624
Encoder Loss:  0.24437258  || Decoder Loss:  0.46754792 Validation Decoder Loss:  0.9737407
Encoder Loss:  0.24887234  || Decoder Loss:  0.47733834 Validation Decoder Loss:  0.9790128
Encoder Loss:  0.25088504  || Decoder Loss:  0.48169053 Validation Decoder Loss:  0.98695636
Encoder Loss:  0.25186175  || Decoder Loss:  0.48381442 Validation Decoder Loss:  0.98697364
Encoder Loss:  0.24953435  || Decoder Loss:  0.47868407 Validation Decoder Loss:  0.9712986
Encoder Loss:  0.24567695  || Decoder Loss:  0.47035766 Validation Decoder Loss:  0.96990526
Encoder Loss:  0.24755757  || Decoder Loss:  0.47434878 Validation Decoder Loss:  0.97530615
Encoder Loss:  0.25215763  || Decoder Loss:  0.4843746 Validation Decoder Loss:  0.99683845
Encoder Loss:  0.25580332  || Decoder Loss:  0.49208966 Validation Decoder Loss:  0.99266446
Encoder Loss:  0.25200212  || Decoder Loss:  0.4838854 Validation Decoder Loss:  0.9753064
Encoder Loss:  0.23924787  || Decoder Loss:  0.45641258 Validation Decoder Loss:  0.9008405
Encoder Loss:  0.22173178  || Decoder Loss:  0.41868225 Validation Decoder Loss:  0.65623593
Encoder Loss:  0.20097883  || Decoder Loss:  0.3741937 Validation Decoder Loss:  0.9601381
Encoder Loss:  0.24065976  || Decoder Loss:  0.45955777 Validation Decoder Loss:  0.9486691
Encoder Loss:  0.23908111  || Decoder Loss:  0.45618647 Validation Decoder Loss:  0.9472476
Encoder Loss:  0.19803056  || Decoder Loss:  0.36776227 Validation Decoder Loss:  0.93170387
Encoder Loss:  0.2377151  || Decoder Loss:  0.45317027 Validation Decoder Loss:  0.9020179
Encoder Loss:  0.22749718  || Decoder Loss:  0.4312107 Validation Decoder Loss:  0.8405894
Encoder Loss:  0.124445245  || Decoder Loss:  0.20960005 Validation Decoder Loss:  0.37871218
Encoder Loss:  0.057162404  || Decoder Loss:  0.06490778 Validation Decoder Loss:  0.367478
Encoder Loss:  0.048855837  || Decoder Loss:  0.04708518 Validation Decoder Loss:  0.3639536
Encoder Loss:  0.04439642  || Decoder Loss:  0.03759954 Validation Decoder Loss:  0.34856758
Encoder Loss:  0.04256697  || Decoder Loss:  0.033460863 Validation Decoder Loss:  0.34635043
Encoder Loss:  0.04273523  || Decoder Loss:  0.033959404 Validation Decoder Loss:  0.35470963
Encoder Loss:  0.044112902  || Decoder Loss:  0.036785547 Validation Decoder Loss:  0.3464901
Encoder Loss:  0.04251574  || Decoder Loss:  0.033529446 Validation Decoder Loss:  0.34673613
Encoder Loss:  0.042729303  || Decoder Loss:  0.03390092 Validation Decoder Loss:  0.3492524
Model: siamese_net_lr_0.03482327495529289 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34925237
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_82 (Conv3DT (None, 317, 10, 20, 1)    131       
_________________________________________________________________
reshape_82 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17364429  || Decoder Loss:  0.4664217 Validation Decoder Loss:  0.90337807
Encoder Loss:  0.15317541  || Decoder Loss:  0.397211 Validation Decoder Loss:  0.7930635
Encoder Loss:  0.13403676  || Decoder Loss:  0.33231518 Validation Decoder Loss:  0.7013893
Encoder Loss:  0.11884811  || Decoder Loss:  0.28082606 Validation Decoder Loss:  0.63499284
Encoder Loss:  0.107430935  || Decoder Loss:  0.24214293 Validation Decoder Loss:  0.58712167
Encoder Loss:  0.098881066  || Decoder Loss:  0.21319446 Validation Decoder Loss:  0.551885
Encoder Loss:  0.09237913  || Decoder Loss:  0.19118729 Validation Decoder Loss:  0.5254847
Encoder Loss:  0.08731286  || Decoder Loss:  0.17406057 Validation Decoder Loss:  0.5052054
Encoder Loss:  0.08328264  || Decoder Loss:  0.16043772 Validation Decoder Loss:  0.48911554
Encoder Loss:  0.08000669  || Decoder Loss:  0.14935105 Validation Decoder Loss:  0.4760352
Encoder Loss:  0.07730385  || Decoder Loss:  0.14019006 Validation Decoder Loss:  0.4651774
Encoder Loss:  0.075007886  || Decoder Loss:  0.13250206 Validation Decoder Loss:  0.45626128
Encoder Loss:  0.0730787  || Decoder Loss:  0.1259374 Validation Decoder Loss:  0.4485583
Encoder Loss:  0.071387276  || Decoder Loss:  0.120263174 Validation Decoder Loss:  0.44201964
Encoder Loss:  0.06993458  || Decoder Loss:  0.11532273 Validation Decoder Loss:  0.43625787
Encoder Loss:  0.068638496  || Decoder Loss:  0.11095906 Validation Decoder Loss:  0.43120244
Encoder Loss:  0.067482635  || Decoder Loss:  0.10708934 Validation Decoder Loss:  0.42677742
Encoder Loss:  0.066473626  || Decoder Loss:  0.10362309 Validation Decoder Loss:  0.42279425
Encoder Loss:  0.06554468  || Decoder Loss:  0.100510694 Validation Decoder Loss:  0.4192236
Encoder Loss:  0.0647053  || Decoder Loss:  0.09768766 Validation Decoder Loss:  0.41600758
Encoder Loss:  0.063953914  || Decoder Loss:  0.09512013 Validation Decoder Loss:  0.41307575
Encoder Loss:  0.06325332  || Decoder Loss:  0.092771046 Validation Decoder Loss:  0.41040593
Encoder Loss:  0.062619016  || Decoder Loss:  0.090613626 Validation Decoder Loss:  0.4079498
Encoder Loss:  0.06202689  || Decoder Loss:  0.088624194 Validation Decoder Loss:  0.405696
Encoder Loss:  0.061476372  || Decoder Loss:  0.086781874 Validation Decoder Loss:  0.40361392
Encoder Loss:  0.06097199  || Decoder Loss:  0.085071966 Validation Decoder Loss:  0.4016852
Encoder Loss:  0.06049987  || Decoder Loss:  0.08347908 Validation Decoder Loss:  0.39989263
Encoder Loss:  0.06005953  || Decoder Loss:  0.08199153 Validation Decoder Loss:  0.39822307
Encoder Loss:  0.05964707  || Decoder Loss:  0.080599576 Validation Decoder Loss:  0.3966612
Encoder Loss:  0.059258528  || Decoder Loss:  0.07929237 Validation Decoder Loss:  0.39519888
Encoder Loss:  0.05889665  || Decoder Loss:  0.078062296 Validation Decoder Loss:  0.39382485
Encoder Loss:  0.058546524  || Decoder Loss:  0.076904885 Validation Decoder Loss:  0.3925342
Encoder Loss:  0.058232132  || Decoder Loss:  0.07580852 Validation Decoder Loss:  0.39131004
Encoder Loss:  0.057913885  || Decoder Loss:  0.07477245 Validation Decoder Loss:  0.39015764
Encoder Loss:  0.05761898  || Decoder Loss:  0.07379098 Validation Decoder Loss:  0.38907206
Encoder Loss:  0.0573495  || Decoder Loss:  0.072858654 Validation Decoder Loss:  0.38803598
Encoder Loss:  0.057082973  || Decoder Loss:  0.07197102 Validation Decoder Loss:  0.38705033
Encoder Loss:  0.056819946  || Decoder Loss:  0.071127355 Validation Decoder Loss:  0.3861224
Encoder Loss:  0.05659366  || Decoder Loss:  0.07032212 Validation Decoder Loss:  0.38522905
Encoder Loss:  0.05635303  || Decoder Loss:  0.06955362 Validation Decoder Loss:  0.38438645
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38438645
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 604, 5, 20, 1)     227       
_________________________________________________________________
reshape_83 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6071951  || Decoder Loss:  0.94915175 Validation Decoder Loss:  1.6563678
Encoder Loss:  0.6162426  || Decoder Loss:  0.9620389 Validation Decoder Loss:  1.6569841
Encoder Loss:  0.6145962  || Decoder Loss:  0.961549 Validation Decoder Loss:  1.6576728
Encoder Loss:  0.6042933  || Decoder Loss:  0.9608891 Validation Decoder Loss:  1.6568551
Encoder Loss:  0.32213673  || Decoder Loss:  0.49302003 Validation Decoder Loss:  0.90689164
Encoder Loss:  0.20831776  || Decoder Loss:  0.41925883 Validation Decoder Loss:  1.084264
Encoder Loss:  0.18162228  || Decoder Loss:  0.42163795 Validation Decoder Loss:  0.6752734
Encoder Loss:  0.087680414  || Decoder Loss:  0.14963588 Validation Decoder Loss:  0.3945769
Encoder Loss:  0.05402194  || Decoder Loss:  0.045569796 Validation Decoder Loss:  0.3587684
Encoder Loss:  0.050530303  || Decoder Loss:  0.036471978 Validation Decoder Loss:  0.35626453
Encoder Loss:  0.049286377  || Decoder Loss:  0.035391606 Validation Decoder Loss:  0.35450897
Encoder Loss:  0.05009167  || Decoder Loss:  0.03481591 Validation Decoder Loss:  0.35405463
Encoder Loss:  0.051037833  || Decoder Loss:  0.034675285 Validation Decoder Loss:  0.35124224
Encoder Loss:  0.049414877  || Decoder Loss:  0.03428421 Validation Decoder Loss:  0.3504572
Encoder Loss:  0.050909538  || Decoder Loss:  0.034079596 Validation Decoder Loss:  0.34995434
Encoder Loss:  0.056498647  || Decoder Loss:  0.034158703 Validation Decoder Loss:  0.34908456
Encoder Loss:  0.04912874  || Decoder Loss:  0.033910245 Validation Decoder Loss:  0.3481785
Encoder Loss:  0.048707247  || Decoder Loss:  0.03385285 Validation Decoder Loss:  0.34786522
Encoder Loss:  0.047377434  || Decoder Loss:  0.033802725 Validation Decoder Loss:  0.34760612
Encoder Loss:  0.04971829  || Decoder Loss:  0.033776153 Validation Decoder Loss:  0.34748796
Encoder Loss:  0.048975043  || Decoder Loss:  0.033739783 Validation Decoder Loss:  0.34716225
Encoder Loss:  0.048878785  || Decoder Loss:  0.033745855 Validation Decoder Loss:  0.34707284
Encoder Loss:  0.04869126  || Decoder Loss:  0.03372796 Validation Decoder Loss:  0.3472532
Encoder Loss:  0.049285885  || Decoder Loss:  0.03372242 Validation Decoder Loss:  0.34728652
Encoder Loss:  0.052121997  || Decoder Loss:  0.033714715 Validation Decoder Loss:  0.3478068
Encoder Loss:  0.05610869  || Decoder Loss:  0.033675965 Validation Decoder Loss:  0.34738198
Encoder Loss:  0.05576871  || Decoder Loss:  0.033677384 Validation Decoder Loss:  0.34686315
Encoder Loss:  0.055398222  || Decoder Loss:  0.033714518 Validation Decoder Loss:  0.34706974
Encoder Loss:  0.05107592  || Decoder Loss:  0.033688497 Validation Decoder Loss:  0.34692192
Encoder Loss:  0.04656538  || Decoder Loss:  0.03365234 Validation Decoder Loss:  0.34689015
Encoder Loss:  0.04756682  || Decoder Loss:  0.03367328 Validation Decoder Loss:  0.34698018
Encoder Loss:  0.046839405  || Decoder Loss:  0.033635613 Validation Decoder Loss:  0.34702224
Encoder Loss:  0.046944954  || Decoder Loss:  0.033633135 Validation Decoder Loss:  0.3469349
Encoder Loss:  0.04759407  || Decoder Loss:  0.03363286 Validation Decoder Loss:  0.3468964
Encoder Loss:  0.051820874  || Decoder Loss:  0.033668 Validation Decoder Loss:  0.34703773
Encoder Loss:  0.050305694  || Decoder Loss:  0.03366458 Validation Decoder Loss:  0.34762734
Encoder Loss:  0.05008078  || Decoder Loss:  0.03364888 Validation Decoder Loss:  0.34757406
Encoder Loss:  0.047365133  || Decoder Loss:  0.03364036 Validation Decoder Loss:  0.3475495
Encoder Loss:  0.049871825  || Decoder Loss:  0.033652805 Validation Decoder Loss:  0.34770262
Encoder Loss:  0.04839183  || Decoder Loss:  0.033629753 Validation Decoder Loss:  0.347068
Model: siamese_net_lr_0.016897387303312802 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.347068
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 454, 5, 20, 1)     203       
_________________________________________________________________
reshape_84 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 203
Trainable params: 203
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12449322  || Decoder Loss:  0.51516175 Validation Decoder Loss:  0.8896085
Encoder Loss:  0.10571304  || Decoder Loss:  0.4514938 Validation Decoder Loss:  0.81463695
Encoder Loss:  0.09671686  || Decoder Loss:  0.39258996 Validation Decoder Loss:  0.7308464
Encoder Loss:  0.08875287  || Decoder Loss:  0.3336531 Validation Decoder Loss:  0.65069383
Encoder Loss:  0.08157031  || Decoder Loss:  0.2795463 Validation Decoder Loss:  0.5846978
Encoder Loss:  0.07581658  || Decoder Loss:  0.23602152 Validation Decoder Loss:  0.5376638
Encoder Loss:  0.0715539  || Decoder Loss:  0.20380849 Validation Decoder Loss:  0.505957
Encoder Loss:  0.06843933  || Decoder Loss:  0.18039255 Validation Decoder Loss:  0.48403817
Encoder Loss:  0.06608581  || Decoder Loss:  0.16285965 Validation Decoder Loss:  0.46810436
Encoder Loss:  0.06424015  || Decoder Loss:  0.14926454 Validation Decoder Loss:  0.45578927
Encoder Loss:  0.0627549  || Decoder Loss:  0.13841316 Validation Decoder Loss:  0.4461726
Encoder Loss:  0.06152926  || Decoder Loss:  0.12955062 Validation Decoder Loss:  0.4382716
Encoder Loss:  0.0604954  || Decoder Loss:  0.12216583 Validation Decoder Loss:  0.43169197
Encoder Loss:  0.059610236  || Decoder Loss:  0.11591189 Validation Decoder Loss:  0.42614675
Encoder Loss:  0.058842864  || Decoder Loss:  0.11053991 Validation Decoder Loss:  0.42138484
Encoder Loss:  0.05818076  || Decoder Loss:  0.10589286 Validation Decoder Loss:  0.417328
Encoder Loss:  0.05761043  || Decoder Loss:  0.10182252 Validation Decoder Loss:  0.41371405
Encoder Loss:  0.05710351  || Decoder Loss:  0.098208435 Validation Decoder Loss:  0.41047305
Encoder Loss:  0.05665259  || Decoder Loss:  0.094975054 Validation Decoder Loss:  0.40757692
Encoder Loss:  0.056260623  || Decoder Loss:  0.09207412 Validation Decoder Loss:  0.40501517
Encoder Loss:  0.055906862  || Decoder Loss:  0.08944508 Validation Decoder Loss:  0.40256235
Encoder Loss:  0.055589665  || Decoder Loss:  0.08704385 Validation Decoder Loss:  0.40034497
Encoder Loss:  0.055299573  || Decoder Loss:  0.08485168 Validation Decoder Loss:  0.39827305
Encoder Loss:  0.055035554  || Decoder Loss:  0.08283149 Validation Decoder Loss:  0.39636385
Encoder Loss:  0.054788016  || Decoder Loss:  0.0809723 Validation Decoder Loss:  0.39461178
Encoder Loss:  0.05456754  || Decoder Loss:  0.07924658 Validation Decoder Loss:  0.3929271
Encoder Loss:  0.05434227  || Decoder Loss:  0.077640615 Validation Decoder Loss:  0.3913808
Encoder Loss:  0.05415096  || Decoder Loss:  0.076139815 Validation Decoder Loss:  0.38993078
Encoder Loss:  0.053961348  || Decoder Loss:  0.07473918 Validation Decoder Loss:  0.38849226
Encoder Loss:  0.053776667  || Decoder Loss:  0.0734244 Validation Decoder Loss:  0.38720468
Encoder Loss:  0.053616762  || Decoder Loss:  0.07219002 Validation Decoder Loss:  0.38602266
Encoder Loss:  0.053471737  || Decoder Loss:  0.07102815 Validation Decoder Loss:  0.38488877
Encoder Loss:  0.053323645  || Decoder Loss:  0.06992811 Validation Decoder Loss:  0.38369268
Encoder Loss:  0.053173326  || Decoder Loss:  0.06888692 Validation Decoder Loss:  0.38263232
Encoder Loss:  0.053040795  || Decoder Loss:  0.06790327 Validation Decoder Loss:  0.3816443
Encoder Loss:  0.052918304  || Decoder Loss:  0.066969454 Validation Decoder Loss:  0.38068703
Encoder Loss:  0.052796826  || Decoder Loss:  0.06608171 Validation Decoder Loss:  0.37978148
Encoder Loss:  0.052683778  || Decoder Loss:  0.065236874 Validation Decoder Loss:  0.3789274
Encoder Loss:  0.05259675  || Decoder Loss:  0.06443105 Validation Decoder Loss:  0.3780756
Encoder Loss:  0.05248398  || Decoder Loss:  0.063661605 Validation Decoder Loss:  0.37726945
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37726945
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_85 (Conv3DT (None, 454, 5, 20, 1)     14        
_________________________________________________________________
reshape_85 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 14
Trainable params: 14
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50660014  || Decoder Loss:  0.9164581 Validation Decoder Loss:  1.6329715
Encoder Loss:  0.5165802  || Decoder Loss:  0.931143 Validation Decoder Loss:  1.6310875
Encoder Loss:  0.51639295  || Decoder Loss:  0.9300126 Validation Decoder Loss:  1.6281974
Encoder Loss:  0.5161017  || Decoder Loss:  0.9283264 Validation Decoder Loss:  1.6239194
Encoder Loss:  0.5156598  || Decoder Loss:  0.9257162 Validation Decoder Loss:  1.6169608
Encoder Loss:  0.514883  || Decoder Loss:  0.92090714 Validation Decoder Loss:  1.6021829
Encoder Loss:  0.51216567  || Decoder Loss:  0.9024579 Validation Decoder Loss:  1.4680942
Encoder Loss:  0.41053838  || Decoder Loss:  0.17490844 Validation Decoder Loss:  0.34610468
Encoder Loss:  0.39440206  || Decoder Loss:  0.061173853 Validation Decoder Loss:  0.3476103
Encoder Loss:  0.39399803  || Decoder Loss:  0.061165113 Validation Decoder Loss:  0.34775698
Encoder Loss:  0.3933733  || Decoder Loss:  0.061013356 Validation Decoder Loss:  0.34778678
Encoder Loss:  0.3923703  || Decoder Loss:  0.060841214 Validation Decoder Loss:  0.3477874
Encoder Loss:  0.39046356  || Decoder Loss:  0.06065464 Validation Decoder Loss:  0.34777266
Encoder Loss:  0.38434175  || Decoder Loss:  0.060465284 Validation Decoder Loss:  0.34787548
Encoder Loss:  0.428544  || Decoder Loss:  0.59057593 Validation Decoder Loss:  1.652319
Encoder Loss:  0.51260775  || Decoder Loss:  0.9388913 Validation Decoder Loss:  1.652291
Encoder Loss:  0.5121493  || Decoder Loss:  0.9387356 Validation Decoder Loss:  1.6522504
Encoder Loss:  0.5110898  || Decoder Loss:  0.9385338 Validation Decoder Loss:  1.6522398
Encoder Loss:  0.50928473  || Decoder Loss:  0.93830633 Validation Decoder Loss:  1.6522679
Encoder Loss:  0.4918315  || Decoder Loss:  0.93804246 Validation Decoder Loss:  1.652339
Encoder Loss:  0.50318426  || Decoder Loss:  0.9376987 Validation Decoder Loss:  1.6524479
Encoder Loss:  0.46913707  || Decoder Loss:  0.93580866 Validation Decoder Loss:  0.56881595
Encoder Loss:  0.19811577  || Decoder Loss:  0.3684957 Validation Decoder Loss:  1.0078508
Encoder Loss:  0.17579025  || Decoder Loss:  0.4908202 Validation Decoder Loss:  1.6367145
Encoder Loss:  0.1863409  || Decoder Loss:  0.5000212 Validation Decoder Loss:  0.52069205
Encoder Loss:  0.12408845  || Decoder Loss:  0.45328346 Validation Decoder Loss:  0.8497197
Encoder Loss:  0.10912746  || Decoder Loss:  0.39541802 Validation Decoder Loss:  0.9740303
Encoder Loss:  0.10254118  || Decoder Loss:  0.2877114 Validation Decoder Loss:  0.75882065
Encoder Loss:  0.08128788  || Decoder Loss:  0.09912858 Validation Decoder Loss:  0.36277768
Encoder Loss:  0.06080214  || Decoder Loss:  0.036421664 Validation Decoder Loss:  0.35428786
Encoder Loss:  0.06328718  || Decoder Loss:  0.032436457 Validation Decoder Loss:  0.34999526
Encoder Loss:  0.061596  || Decoder Loss:  0.03192074 Validation Decoder Loss:  0.3505589
Encoder Loss:  0.06664112  || Decoder Loss:  0.03246038 Validation Decoder Loss:  0.34801126
Encoder Loss:  0.058776427  || Decoder Loss:  0.03183888 Validation Decoder Loss:  0.34815794
Encoder Loss:  0.06124577  || Decoder Loss:  0.031944487 Validation Decoder Loss:  0.34862325
Encoder Loss:  0.054752555  || Decoder Loss:  0.031716708 Validation Decoder Loss:  0.3492297
Encoder Loss:  0.06427543  || Decoder Loss:  0.032552768 Validation Decoder Loss:  0.35053402
Encoder Loss:  0.071287155  || Decoder Loss:  0.03328593 Validation Decoder Loss:  0.3596038
Encoder Loss:  0.06172247  || Decoder Loss:  0.036250923 Validation Decoder Loss:  0.3478207
Encoder Loss:  0.061931923  || Decoder Loss:  0.033982515 Validation Decoder Loss:  0.35076046
Model: siamese_net_lr_0.02702014322851543 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35076046
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 454, 5, 20, 1)     329       
_________________________________________________________________
reshape_86 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 329
Trainable params: 329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.520513  || Decoder Loss:  0.9022418 Validation Decoder Loss:  1.6321042
Encoder Loss:  0.5117604  || Decoder Loss:  0.9119732 Validation Decoder Loss:  1.6066747
Encoder Loss:  0.45954955  || Decoder Loss:  0.5622933 Validation Decoder Loss:  0.33745033
Encoder Loss:  0.359157  || Decoder Loss:  0.08670467 Validation Decoder Loss:  0.36270863
Encoder Loss:  0.28461608  || Decoder Loss:  0.30863464 Validation Decoder Loss:  1.3474467
Encoder Loss:  0.17295495  || Decoder Loss:  0.47876674 Validation Decoder Loss:  1.0356836
Encoder Loss:  0.15217392  || Decoder Loss:  0.47012684 Validation Decoder Loss:  1.0475329
Encoder Loss:  0.14728884  || Decoder Loss:  0.46624961 Validation Decoder Loss:  0.9601087
Encoder Loss:  0.1400016  || Decoder Loss:  0.4545412 Validation Decoder Loss:  1.0347366
Encoder Loss:  0.13769883  || Decoder Loss:  0.4536557 Validation Decoder Loss:  1.0140555
Encoder Loss:  0.13634574  || Decoder Loss:  0.4546392 Validation Decoder Loss:  1.0492456
Encoder Loss:  0.13669524  || Decoder Loss:  0.45466453 Validation Decoder Loss:  1.1201843
Encoder Loss:  0.13235229  || Decoder Loss:  0.44871646 Validation Decoder Loss:  1.0607259
Encoder Loss:  0.13181521  || Decoder Loss:  0.44209436 Validation Decoder Loss:  0.9790471
Encoder Loss:  0.108060054  || Decoder Loss:  0.3303063 Validation Decoder Loss:  0.55733037
Encoder Loss:  0.078474805  || Decoder Loss:  0.1851789 Validation Decoder Loss:  0.44996256
Encoder Loss:  0.06803583  || Decoder Loss:  0.11557088 Validation Decoder Loss:  0.39892837
Encoder Loss:  0.052412532  || Decoder Loss:  0.04466106 Validation Decoder Loss:  0.36997342
Encoder Loss:  0.050163597  || Decoder Loss:  0.034803655 Validation Decoder Loss:  0.35335928
Encoder Loss:  0.057547096  || Decoder Loss:  0.033505615 Validation Decoder Loss:  0.34967786
Encoder Loss:  0.05718994  || Decoder Loss:  0.033159398 Validation Decoder Loss:  0.3546768
Encoder Loss:  0.05762674  || Decoder Loss:  0.034021705 Validation Decoder Loss:  0.3835713
Encoder Loss:  0.05400067  || Decoder Loss:  0.037441883 Validation Decoder Loss:  0.34128958
Encoder Loss:  0.05156626  || Decoder Loss:  0.034155264 Validation Decoder Loss:  0.34011328
Encoder Loss:  0.053575147  || Decoder Loss:  0.03566375 Validation Decoder Loss:  0.3657278
Encoder Loss:  0.056337323  || Decoder Loss:  0.035226636 Validation Decoder Loss:  0.33828735
Encoder Loss:  0.05261324  || Decoder Loss:  0.035730742 Validation Decoder Loss:  0.3551106
Encoder Loss:  0.05433331  || Decoder Loss:  0.034047317 Validation Decoder Loss:  0.3687157
Encoder Loss:  0.05313686  || Decoder Loss:  0.034489598 Validation Decoder Loss:  0.3558764
Encoder Loss:  0.049603548  || Decoder Loss:  0.033501927 Validation Decoder Loss:  0.37276497
Encoder Loss:  0.051306896  || Decoder Loss:  0.03494034 Validation Decoder Loss:  0.35739952
Encoder Loss:  0.054291878  || Decoder Loss:  0.03378327 Validation Decoder Loss:  0.36898226
Encoder Loss:  0.054168306  || Decoder Loss:  0.03614497 Validation Decoder Loss:  0.37414932
Encoder Loss:  0.052031755  || Decoder Loss:  0.036216155 Validation Decoder Loss:  0.340697
Encoder Loss:  0.052222654  || Decoder Loss:  0.03650106 Validation Decoder Loss:  0.3484446
Encoder Loss:  0.050197396  || Decoder Loss:  0.03326607 Validation Decoder Loss:  0.35024828
Encoder Loss:  0.051064663  || Decoder Loss:  0.034113616 Validation Decoder Loss:  0.3448543
Encoder Loss:  0.052258763  || Decoder Loss:  0.034351934 Validation Decoder Loss:  0.33915326
Encoder Loss:  0.053271517  || Decoder Loss:  0.036597583 Validation Decoder Loss:  0.35791975
Encoder Loss:  0.052341633  || Decoder Loss:  0.034116935 Validation Decoder Loss:  0.35766685
Model: siamese_net_lr_0.011740672577455582 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35766685
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 267, 10, 20, 1)    283       
_________________________________________________________________
reshape_87 (Reshape)         (None, 2670, 20, 1)       0         
=================================================================
Total params: 283
Trainable params: 283
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 2670, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 3245, 20, 1)       577       
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27732122  || Decoder Loss:  0.4708458 Validation Decoder Loss:  0.9099464
Encoder Loss:  0.23962925  || Decoder Loss:  0.4026002 Validation Decoder Loss:  0.796894
Encoder Loss:  0.2029034  || Decoder Loss:  0.33422536 Validation Decoder Loss:  0.6981491
Encoder Loss:  0.17257962  || Decoder Loss:  0.277704 Validation Decoder Loss:  0.62311757
Encoder Loss:  0.14948541  || Decoder Loss:  0.2347019 Validation Decoder Loss:  0.5687847
Encoder Loss:  0.13235539  || Decoder Loss:  0.20281841 Validation Decoder Loss:  0.52995616
Encoder Loss:  0.11959301  || Decoder Loss:  0.1790454 Validation Decoder Loss:  0.5013212
Encoder Loss:  0.109850734  || Decoder Loss:  0.16093653 Validation Decoder Loss:  0.479919
Encoder Loss:  0.10228633  || Decoder Loss:  0.14680138 Validation Decoder Loss:  0.46341413
Encoder Loss:  0.09628639  || Decoder Loss:  0.13550524 Validation Decoder Loss:  0.4504097
Encoder Loss:  0.09132392  || Decoder Loss:  0.1262992 Validation Decoder Loss:  0.43978778
Encoder Loss:  0.08717854  || Decoder Loss:  0.11864712 Validation Decoder Loss:  0.43101537
Encoder Loss:  0.083667845  || Decoder Loss:  0.112199314 Validation Decoder Loss:  0.4237082
Encoder Loss:  0.08070783  || Decoder Loss:  0.10668452 Validation Decoder Loss:  0.41751832
Encoder Loss:  0.07814786  || Decoder Loss:  0.10191305 Validation Decoder Loss:  0.41218328
Encoder Loss:  0.07597335  || Decoder Loss:  0.09774253 Validation Decoder Loss:  0.40756965
Encoder Loss:  0.07398555  || Decoder Loss:  0.09407169 Validation Decoder Loss:  0.40352395
Encoder Loss:  0.07222506  || Decoder Loss:  0.09081023 Validation Decoder Loss:  0.39997607
Encoder Loss:  0.07066389  || Decoder Loss:  0.08789462 Validation Decoder Loss:  0.39683166
Encoder Loss:  0.06926169  || Decoder Loss:  0.08527003 Validation Decoder Loss:  0.3940028
Encoder Loss:  0.06798223  || Decoder Loss:  0.08289613 Validation Decoder Loss:  0.3914463
Encoder Loss:  0.06678692  || Decoder Loss:  0.080738544 Validation Decoder Loss:  0.3891456
Encoder Loss:  0.06578214  || Decoder Loss:  0.07876455 Validation Decoder Loss:  0.38701892
Encoder Loss:  0.064676955  || Decoder Loss:  0.0769566 Validation Decoder Loss:  0.3851261
Encoder Loss:  0.0638518  || Decoder Loss:  0.075288035 Validation Decoder Loss:  0.383375
Encoder Loss:  0.06302536  || Decoder Loss:  0.07374783 Validation Decoder Loss:  0.38175705
Encoder Loss:  0.06225947  || Decoder Loss:  0.072318785 Validation Decoder Loss:  0.3802423
Encoder Loss:  0.061544996  || Decoder Loss:  0.07099009 Validation Decoder Loss:  0.37886286
Encoder Loss:  0.060875505  || Decoder Loss:  0.06975109 Validation Decoder Loss:  0.37757882
Encoder Loss:  0.06024843  || Decoder Loss:  0.06859259 Validation Decoder Loss:  0.37637758
Encoder Loss:  0.059658814  || Decoder Loss:  0.067506626 Validation Decoder Loss:  0.3752541
Encoder Loss:  0.05910568  || Decoder Loss:  0.066486314 Validation Decoder Loss:  0.37419897
Encoder Loss:  0.05858593  || Decoder Loss:  0.06552556 Validation Decoder Loss:  0.373227
Encoder Loss:  0.05808014  || Decoder Loss:  0.06461976 Validation Decoder Loss:  0.372295
Encoder Loss:  0.05758018  || Decoder Loss:  0.0637634 Validation Decoder Loss:  0.3714251
Encoder Loss:  0.0571125  || Decoder Loss:  0.06295289 Validation Decoder Loss:  0.37060696
Encoder Loss:  0.05672407  || Decoder Loss:  0.06218391 Validation Decoder Loss:  0.3698143
Encoder Loss:  0.0562789  || Decoder Loss:  0.06145345 Validation Decoder Loss:  0.36909342
Encoder Loss:  0.055931974  || Decoder Loss:  0.060758926 Validation Decoder Loss:  0.36840802
Encoder Loss:  0.055568222  || Decoder Loss:  0.06009762 Validation Decoder Loss:  0.36774617
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3677462
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_88 (Conv3DT (None, 634, 5, 20, 1)     68        
_________________________________________________________________
reshape_88 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 68
Trainable params: 68
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6371909  || Decoder Loss:  0.9513185 Validation Decoder Loss:  1.6565893
Encoder Loss:  0.64907885  || Decoder Loss:  0.9673222 Validation Decoder Loss:  1.6565764
Encoder Loss:  0.6490461  || Decoder Loss:  0.9673118 Validation Decoder Loss:  1.6565629
Encoder Loss:  0.64899945  || Decoder Loss:  0.9672966 Validation Decoder Loss:  1.6565465
Encoder Loss:  0.64893776  || Decoder Loss:  0.96727806 Validation Decoder Loss:  1.6565268
Encoder Loss:  0.6488564  || Decoder Loss:  0.9672563 Validation Decoder Loss:  1.6565036
Encoder Loss:  0.6487474  || Decoder Loss:  0.9672318 Validation Decoder Loss:  1.6564763
Encoder Loss:  0.6485961  || Decoder Loss:  0.9672036 Validation Decoder Loss:  1.6564444
Encoder Loss:  0.6483726  || Decoder Loss:  0.9671718 Validation Decoder Loss:  1.6564071
Encoder Loss:  0.64800256  || Decoder Loss:  0.9671358 Validation Decoder Loss:  1.6563634
Encoder Loss:  0.6472143  || Decoder Loss:  0.96709466 Validation Decoder Loss:  1.6563116
Encoder Loss:  0.6370541  || Decoder Loss:  0.96704733 Validation Decoder Loss:  1.6562488
Encoder Loss:  0.646531  || Decoder Loss:  0.9669952 Validation Decoder Loss:  1.6561781
Encoder Loss:  0.64750695  || Decoder Loss:  0.96693933 Validation Decoder Loss:  1.6560951
Encoder Loss:  0.6467273  || Decoder Loss:  0.9668756 Validation Decoder Loss:  1.655993
Encoder Loss:  0.64430135  || Decoder Loss:  0.96680176 Validation Decoder Loss:  1.6558644
Encoder Loss:  0.6210376  || Decoder Loss:  0.9667168 Validation Decoder Loss:  1.6556952
Encoder Loss:  0.6438182  || Decoder Loss:  0.9666076 Validation Decoder Loss:  1.6554615
Encoder Loss:  0.6431244  || Decoder Loss:  0.9664611 Validation Decoder Loss:  1.6551387
Encoder Loss:  0.6408953  || Decoder Loss:  0.9662636 Validation Decoder Loss:  1.6546576
Encoder Loss:  0.63177574  || Decoder Loss:  0.9659679 Validation Decoder Loss:  1.6538407
Encoder Loss:  0.4758385  || Decoder Loss:  0.9654332 Validation Decoder Loss:  1.6519856
Encoder Loss:  0.43632168  || Decoder Loss:  0.9630397 Validation Decoder Loss:  1.625996
Encoder Loss:  0.12230568  || Decoder Loss:  0.13321044 Validation Decoder Loss:  0.34205952
Encoder Loss:  0.05717759  || Decoder Loss:  0.03285656 Validation Decoder Loss:  0.34211293
Encoder Loss:  0.057304848  || Decoder Loss:  0.032865733 Validation Decoder Loss:  0.3421103
Encoder Loss:  0.058145676  || Decoder Loss:  0.032869577 Validation Decoder Loss:  0.34210443
Encoder Loss:  0.061196186  || Decoder Loss:  0.032873966 Validation Decoder Loss:  0.3420969
Encoder Loss:  0.05488336  || Decoder Loss:  0.032877788 Validation Decoder Loss:  0.3420908
Encoder Loss:  0.055385567  || Decoder Loss:  0.032881644 Validation Decoder Loss:  0.34208357
Encoder Loss:  0.063436456  || Decoder Loss:  0.03288536 Validation Decoder Loss:  0.34207597
Encoder Loss:  0.052962676  || Decoder Loss:  0.03289133 Validation Decoder Loss:  0.3420682
Encoder Loss:  0.061772954  || Decoder Loss:  0.032896753 Validation Decoder Loss:  0.34206164
Encoder Loss:  0.04952945  || Decoder Loss:  0.03290131 Validation Decoder Loss:  0.34205523
Encoder Loss:  0.05228357  || Decoder Loss:  0.03290507 Validation Decoder Loss:  0.3420468
Encoder Loss:  0.047944058  || Decoder Loss:  0.032910608 Validation Decoder Loss:  0.3420373
Encoder Loss:  0.060597423  || Decoder Loss:  0.03291505 Validation Decoder Loss:  0.3420292
Encoder Loss:  0.052430652  || Decoder Loss:  0.032920185 Validation Decoder Loss:  0.3420223
Encoder Loss:  0.05044323  || Decoder Loss:  0.032926425 Validation Decoder Loss:  0.34201306
Encoder Loss:  0.052179426  || Decoder Loss:  0.0329308 Validation Decoder Loss:  0.3420064
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3420064
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 634, 5, 20, 1)     194       
_________________________________________________________________
reshape_89 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.52574027  || Decoder Loss:  0.9483525 Validation Decoder Loss:  1.6593952
Encoder Loss:  0.47369334  || Decoder Loss:  0.9670162 Validation Decoder Loss:  1.6593242
Encoder Loss:  0.4971096  || Decoder Loss:  0.9669831 Validation Decoder Loss:  1.6592684
Encoder Loss:  0.40637273  || Decoder Loss:  0.9669347 Validation Decoder Loss:  1.6591814
Encoder Loss:  0.37006912  || Decoder Loss:  0.96687406 Validation Decoder Loss:  1.6590428
Encoder Loss:  0.42646798  || Decoder Loss:  0.96679056 Validation Decoder Loss:  1.6588391
Encoder Loss:  0.37277266  || Decoder Loss:  0.96667016 Validation Decoder Loss:  1.6585026
Encoder Loss:  0.37058023  || Decoder Loss:  0.9664746 Validation Decoder Loss:  1.6578621
Encoder Loss:  0.36421698  || Decoder Loss:  0.9660312 Validation Decoder Loss:  1.6559724
Encoder Loss:  0.27837083  || Decoder Loss:  0.69708496 Validation Decoder Loss:  0.339689
Encoder Loss:  0.06120931  || Decoder Loss:  0.032628063 Validation Decoder Loss:  0.34011796
Encoder Loss:  0.0672758  || Decoder Loss:  0.032665208 Validation Decoder Loss:  0.34012508
Encoder Loss:  0.059929997  || Decoder Loss:  0.03267303 Validation Decoder Loss:  0.34011254
Encoder Loss:  0.055205043  || Decoder Loss:  0.032679893 Validation Decoder Loss:  0.34009522
Encoder Loss:  0.06606528  || Decoder Loss:  0.0326863 Validation Decoder Loss:  0.3400795
Encoder Loss:  0.08864505  || Decoder Loss:  0.03269208 Validation Decoder Loss:  0.34005314
Encoder Loss:  0.06572156  || Decoder Loss:  0.03269942 Validation Decoder Loss:  0.34003252
Encoder Loss:  0.056394525  || Decoder Loss:  0.032708123 Validation Decoder Loss:  0.34001008
Encoder Loss:  0.06992934  || Decoder Loss:  0.032715272 Validation Decoder Loss:  0.33999282
Encoder Loss:  0.058213994  || Decoder Loss:  0.032720625 Validation Decoder Loss:  0.33998126
Encoder Loss:  0.056268044  || Decoder Loss:  0.032725327 Validation Decoder Loss:  0.33996364
Encoder Loss:  0.057560954  || Decoder Loss:  0.03273337 Validation Decoder Loss:  0.33994514
Encoder Loss:  0.055850163  || Decoder Loss:  0.03274255 Validation Decoder Loss:  0.33992398
Encoder Loss:  0.057514206  || Decoder Loss:  0.032751206 Validation Decoder Loss:  0.33990902
Encoder Loss:  0.05247368  || Decoder Loss:  0.032760248 Validation Decoder Loss:  0.33988228
Encoder Loss:  0.05804873  || Decoder Loss:  0.032773566 Validation Decoder Loss:  0.33985728
Encoder Loss:  0.06722521  || Decoder Loss:  0.032783404 Validation Decoder Loss:  0.3398375
Encoder Loss:  0.055897284  || Decoder Loss:  0.032791853 Validation Decoder Loss:  0.3398143
Encoder Loss:  0.051079676  || Decoder Loss:  0.032809835 Validation Decoder Loss:  0.33977497
Encoder Loss:  0.056507092  || Decoder Loss:  0.03282802 Validation Decoder Loss:  0.33975524
Encoder Loss:  0.054770928  || Decoder Loss:  0.03283743 Validation Decoder Loss:  0.33973712
Encoder Loss:  0.060197484  || Decoder Loss:  0.032851633 Validation Decoder Loss:  0.33970898
Encoder Loss:  0.057827827  || Decoder Loss:  0.03286843 Validation Decoder Loss:  0.33967358
Encoder Loss:  0.060639504  || Decoder Loss:  0.032883614 Validation Decoder Loss:  0.33965033
Encoder Loss:  0.058876902  || Decoder Loss:  0.032893438 Validation Decoder Loss:  0.33962756
Encoder Loss:  0.055536766  || Decoder Loss:  0.03290934 Validation Decoder Loss:  0.33959246
Encoder Loss:  0.051963452  || Decoder Loss:  0.032926444 Validation Decoder Loss:  0.3395628
Encoder Loss:  0.061573386  || Decoder Loss:  0.03294071 Validation Decoder Loss:  0.33953995
Encoder Loss:  0.05739324  || Decoder Loss:  0.0329492 Validation Decoder Loss:  0.33952022
Encoder Loss:  0.05353212  || Decoder Loss:  0.032965116 Validation Decoder Loss:  0.33949122
Model: siamese_net_lr_0.0698451916162774 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33949122
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 604, 5, 20, 1)     38        
_________________________________________________________________
reshape_90 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 38
Trainable params: 38
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07968939  || Decoder Loss:  0.13205975 Validation Decoder Loss:  0.35810778
Encoder Loss:  0.053253874  || Decoder Loss:  0.04916947 Validation Decoder Loss:  0.3560161
Encoder Loss:  0.051506415  || Decoder Loss:  0.045232642 Validation Decoder Loss:  0.35260308
Encoder Loss:  0.05009352  || Decoder Loss:  0.043598324 Validation Decoder Loss:  0.35287777
Encoder Loss:  0.050074685  || Decoder Loss:  0.042255413 Validation Decoder Loss:  0.35144606
Encoder Loss:  0.049359355  || Decoder Loss:  0.041037574 Validation Decoder Loss:  0.35065258
Encoder Loss:  0.049086507  || Decoder Loss:  0.040292554 Validation Decoder Loss:  0.3493261
Encoder Loss:  0.04846122  || Decoder Loss:  0.039427444 Validation Decoder Loss:  0.34964132
Encoder Loss:  0.048534915  || Decoder Loss:  0.038913388 Validation Decoder Loss:  0.3490632
Encoder Loss:  0.04797619  || Decoder Loss:  0.0384219 Validation Decoder Loss:  0.34889233
Encoder Loss:  0.0478925  || Decoder Loss:  0.03791366 Validation Decoder Loss:  0.34933227
Encoder Loss:  0.047484137  || Decoder Loss:  0.037619945 Validation Decoder Loss:  0.34849983
Encoder Loss:  0.047549468  || Decoder Loss:  0.037122857 Validation Decoder Loss:  0.34760433
Encoder Loss:  0.04845891  || Decoder Loss:  0.03663166 Validation Decoder Loss:  0.34824756
Encoder Loss:  0.048436247  || Decoder Loss:  0.036675815 Validation Decoder Loss:  0.34867638
Encoder Loss:  0.047149453  || Decoder Loss:  0.036396917 Validation Decoder Loss:  0.34828568
Encoder Loss:  0.047193855  || Decoder Loss:  0.03621946 Validation Decoder Loss:  0.34794536
Encoder Loss:  0.047034815  || Decoder Loss:  0.03593872 Validation Decoder Loss:  0.34833735
Encoder Loss:  0.04682724  || Decoder Loss:  0.035769645 Validation Decoder Loss:  0.3480921
Encoder Loss:  0.046817932  || Decoder Loss:  0.03560524 Validation Decoder Loss:  0.34851098
Encoder Loss:  0.046701785  || Decoder Loss:  0.035573293 Validation Decoder Loss:  0.34860903
Encoder Loss:  0.046618562  || Decoder Loss:  0.035406932 Validation Decoder Loss:  0.34841806
Encoder Loss:  0.046591062  || Decoder Loss:  0.03523307 Validation Decoder Loss:  0.34840345
Encoder Loss:  0.04660998  || Decoder Loss:  0.035177607 Validation Decoder Loss:  0.3487598
Encoder Loss:  0.0464786  || Decoder Loss:  0.03508817 Validation Decoder Loss:  0.34849352
Encoder Loss:  0.046440374  || Decoder Loss:  0.034925167 Validation Decoder Loss:  0.3485527
Encoder Loss:  0.04640767  || Decoder Loss:  0.03486858 Validation Decoder Loss:  0.34855384
Encoder Loss:  0.046352524  || Decoder Loss:  0.03478024 Validation Decoder Loss:  0.34848988
Encoder Loss:  0.046329755  || Decoder Loss:  0.034760274 Validation Decoder Loss:  0.34850115
Encoder Loss:  0.046294764  || Decoder Loss:  0.03462819 Validation Decoder Loss:  0.34847102
Encoder Loss:  0.046246495  || Decoder Loss:  0.03457273 Validation Decoder Loss:  0.34850395
Encoder Loss:  0.04620926  || Decoder Loss:  0.034503203 Validation Decoder Loss:  0.34843022
Encoder Loss:  0.046202768  || Decoder Loss:  0.034461975 Validation Decoder Loss:  0.34844548
Encoder Loss:  0.04618604  || Decoder Loss:  0.03441148 Validation Decoder Loss:  0.3484265
Encoder Loss:  0.0461568  || Decoder Loss:  0.03435269 Validation Decoder Loss:  0.3485099
Encoder Loss:  0.046131734  || Decoder Loss:  0.034303475 Validation Decoder Loss:  0.3483922
Encoder Loss:  0.046123166  || Decoder Loss:  0.034257844 Validation Decoder Loss:  0.34846893
Encoder Loss:  0.046101537  || Decoder Loss:  0.034222916 Validation Decoder Loss:  0.3484375
Encoder Loss:  0.04609173  || Decoder Loss:  0.034184664 Validation Decoder Loss:  0.34848017
Encoder Loss:  0.04607562  || Decoder Loss:  0.0341604 Validation Decoder Loss:  0.3484931
Model: siamese_net_lr_0.0004685034791288607 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3484931
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_91 (Conv3DT (None, 302, 10, 20, 1)    227       
_________________________________________________________________
reshape_91 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07479797  || Decoder Loss:  0.44646224 Validation Decoder Loss:  0.9637077
Encoder Loss:  0.05576081  || Decoder Loss:  0.43461117 Validation Decoder Loss:  0.8844166
Encoder Loss:  0.05425046  || Decoder Loss:  0.38336158 Validation Decoder Loss:  0.81419677
Encoder Loss:  0.05458644  || Decoder Loss:  0.33852363 Validation Decoder Loss:  0.74942577
Encoder Loss:  0.054798413  || Decoder Loss:  0.29936886 Validation Decoder Loss:  0.69348896
Encoder Loss:  0.054847483  || Decoder Loss:  0.2659952 Validation Decoder Loss:  0.64694834
Encoder Loss:  0.054771196  || Decoder Loss:  0.23822948 Validation Decoder Loss:  0.609359
Encoder Loss:  0.054730993  || Decoder Loss:  0.21540423 Validation Decoder Loss:  0.5788622
Encoder Loss:  0.05470834  || Decoder Loss:  0.19650635 Validation Decoder Loss:  0.55375373
Encoder Loss:  0.054578077  || Decoder Loss:  0.18087177 Validation Decoder Loss:  0.5332488
Encoder Loss:  0.05449706  || Decoder Loss:  0.16779186 Validation Decoder Loss:  0.5162798
Encoder Loss:  0.054479633  || Decoder Loss:  0.15674555 Validation Decoder Loss:  0.5019625
Encoder Loss:  0.05442007  || Decoder Loss:  0.14732772 Validation Decoder Loss:  0.4897979
Encoder Loss:  0.054364778  || Decoder Loss:  0.13920972 Validation Decoder Loss:  0.47932696
Encoder Loss:  0.054274675  || Decoder Loss:  0.13215233 Validation Decoder Loss:  0.47021264
Encoder Loss:  0.0541098  || Decoder Loss:  0.12596925 Validation Decoder Loss:  0.4622375
Encoder Loss:  0.053937525  || Decoder Loss:  0.12054266 Validation Decoder Loss:  0.45541242
Encoder Loss:  0.05393711  || Decoder Loss:  0.115722485 Validation Decoder Loss:  0.44931948
Encoder Loss:  0.05392884  || Decoder Loss:  0.11139703 Validation Decoder Loss:  0.4438529
Encoder Loss:  0.05381349  || Decoder Loss:  0.10756674 Validation Decoder Loss:  0.4390242
Encoder Loss:  0.053812183  || Decoder Loss:  0.104064435 Validation Decoder Loss:  0.43460238
Encoder Loss:  0.053683832  || Decoder Loss:  0.10092616 Validation Decoder Loss:  0.43066236
Encoder Loss:  0.05368059  || Decoder Loss:  0.09803979 Validation Decoder Loss:  0.42706078
Encoder Loss:  0.053638384  || Decoder Loss:  0.09539639 Validation Decoder Loss:  0.4237411
Encoder Loss:  0.053518664  || Decoder Loss:  0.092985764 Validation Decoder Loss:  0.42068025
Encoder Loss:  0.053412184  || Decoder Loss:  0.09075032 Validation Decoder Loss:  0.417884
Encoder Loss:  0.053315524  || Decoder Loss:  0.08868361 Validation Decoder Loss:  0.41526783
Encoder Loss:  0.053143166  || Decoder Loss:  0.08677177 Validation Decoder Loss:  0.41283935
Encoder Loss:  0.053028584  || Decoder Loss:  0.084974624 Validation Decoder Loss:  0.41059285
Encoder Loss:  0.052854892  || Decoder Loss:  0.08330249 Validation Decoder Loss:  0.40841323
Encoder Loss:  0.05256602  || Decoder Loss:  0.08170701 Validation Decoder Loss:  0.40634578
Encoder Loss:  0.052302968  || Decoder Loss:  0.08024116 Validation Decoder Loss:  0.40459636
Encoder Loss:  0.052304164  || Decoder Loss:  0.07888153 Validation Decoder Loss:  0.4029237
Encoder Loss:  0.052258026  || Decoder Loss:  0.077603266 Validation Decoder Loss:  0.40132982
Encoder Loss:  0.052096378  || Decoder Loss:  0.07638696 Validation Decoder Loss:  0.3998895
Encoder Loss:  0.052132312  || Decoder Loss:  0.07524824 Validation Decoder Loss:  0.39846015
Encoder Loss:  0.052018575  || Decoder Loss:  0.07416441 Validation Decoder Loss:  0.39715767
Encoder Loss:  0.051981993  || Decoder Loss:  0.0731417 Validation Decoder Loss:  0.3959033
Encoder Loss:  0.0519331  || Decoder Loss:  0.07216886 Validation Decoder Loss:  0.39471033
Encoder Loss:  0.051876687  || Decoder Loss:  0.0712427 Validation Decoder Loss:  0.39357775
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.39357772
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 604, 5, 20, 1)     101       
_________________________________________________________________
reshape_92 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 101
Trainable params: 101
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15751997  || Decoder Loss:  0.07394957 Validation Decoder Loss:  0.34978268
Encoder Loss:  0.092415  || Decoder Loss:  0.038112115 Validation Decoder Loss:  0.35021555
Encoder Loss:  0.050892524  || Decoder Loss:  0.03662644 Validation Decoder Loss:  0.34910005
Encoder Loss:  0.047458142  || Decoder Loss:  0.03579915 Validation Decoder Loss:  0.3485946
Encoder Loss:  0.047716185  || Decoder Loss:  0.035304796 Validation Decoder Loss:  0.34847796
Encoder Loss:  0.048033748  || Decoder Loss:  0.03497549 Validation Decoder Loss:  0.34777373
Encoder Loss:  0.047547597  || Decoder Loss:  0.034729216 Validation Decoder Loss:  0.34693128
Encoder Loss:  0.050519843  || Decoder Loss:  0.03449304 Validation Decoder Loss:  0.34787315
Encoder Loss:  0.047254033  || Decoder Loss:  0.03442734 Validation Decoder Loss:  0.34793708
Encoder Loss:  0.048199773  || Decoder Loss:  0.03419126 Validation Decoder Loss:  0.34759703
Encoder Loss:  0.054489568  || Decoder Loss:  0.034312572 Validation Decoder Loss:  0.3476277
Encoder Loss:  0.09472432  || Decoder Loss:  0.034543987 Validation Decoder Loss:  0.34625345
Encoder Loss:  0.073657624  || Decoder Loss:  0.03412544 Validation Decoder Loss:  0.34633172
Encoder Loss:  0.06900099  || Decoder Loss:  0.034059796 Validation Decoder Loss:  0.34835792
Encoder Loss:  0.05895465  || Decoder Loss:  0.034016374 Validation Decoder Loss:  0.34798917
Encoder Loss:  0.058601838  || Decoder Loss:  0.0339648 Validation Decoder Loss:  0.3482668
Encoder Loss:  0.060670227  || Decoder Loss:  0.03397014 Validation Decoder Loss:  0.34722883
Encoder Loss:  0.05924036  || Decoder Loss:  0.033876248 Validation Decoder Loss:  0.34754837
Encoder Loss:  0.07446994  || Decoder Loss:  0.03390337 Validation Decoder Loss:  0.3482265
Encoder Loss:  0.06077349  || Decoder Loss:  0.03384522 Validation Decoder Loss:  0.34787154
Encoder Loss:  0.05332228  || Decoder Loss:  0.033820264 Validation Decoder Loss:  0.348474
Encoder Loss:  0.05385327  || Decoder Loss:  0.03379632 Validation Decoder Loss:  0.34788364
Encoder Loss:  0.05293521  || Decoder Loss:  0.033770114 Validation Decoder Loss:  0.34851563
Encoder Loss:  0.05407573  || Decoder Loss:  0.033732034 Validation Decoder Loss:  0.34784728
Encoder Loss:  0.054462362  || Decoder Loss:  0.03372972 Validation Decoder Loss:  0.34721977
Encoder Loss:  0.06802558  || Decoder Loss:  0.03367916 Validation Decoder Loss:  0.34806132
Encoder Loss:  0.05542347  || Decoder Loss:  0.033704396 Validation Decoder Loss:  0.34767097
Encoder Loss:  0.05239322  || Decoder Loss:  0.033673335 Validation Decoder Loss:  0.3477587
Encoder Loss:  0.057233676  || Decoder Loss:  0.0336472 Validation Decoder Loss:  0.34775406
Encoder Loss:  0.054277584  || Decoder Loss:  0.033669822 Validation Decoder Loss:  0.34791985
Encoder Loss:  0.053594004  || Decoder Loss:  0.033610545 Validation Decoder Loss:  0.34773672
Encoder Loss:  0.056392018  || Decoder Loss:  0.03359152 Validation Decoder Loss:  0.34787437
Encoder Loss:  0.049505148  || Decoder Loss:  0.03363076 Validation Decoder Loss:  0.34787378
Encoder Loss:  0.051580224  || Decoder Loss:  0.03363707 Validation Decoder Loss:  0.3480592
Encoder Loss:  0.054032926  || Decoder Loss:  0.033602294 Validation Decoder Loss:  0.34834355
Encoder Loss:  0.05413549  || Decoder Loss:  0.033608474 Validation Decoder Loss:  0.3475175
Encoder Loss:  0.051996924  || Decoder Loss:  0.033590995 Validation Decoder Loss:  0.3479098
Encoder Loss:  0.0573117  || Decoder Loss:  0.03355217 Validation Decoder Loss:  0.34824878
Encoder Loss:  0.0539638  || Decoder Loss:  0.0336028 Validation Decoder Loss:  0.34745252
Encoder Loss:  0.05709601  || Decoder Loss:  0.033562228 Validation Decoder Loss:  0.34800667
Model: siamese_net_lr_0.0023227206386443084 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34800667
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 302, 10, 20, 1)    301       
_________________________________________________________________
reshape_93 (Reshape)         (None, 3020, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7035552  || Decoder Loss:  0.9440254 Validation Decoder Loss:  1.6521128
Encoder Loss:  0.72196555  || Decoder Loss:  0.96303785 Validation Decoder Loss:  1.6523618
Encoder Loss:  0.7218216  || Decoder Loss:  0.9629268 Validation Decoder Loss:  1.6525568
Encoder Loss:  0.7216301  || Decoder Loss:  0.9627762 Validation Decoder Loss:  1.6527857
Encoder Loss:  0.7213865  || Decoder Loss:  0.96259004 Validation Decoder Loss:  1.6530559
Encoder Loss:  0.7210803  || Decoder Loss:  0.9623649 Validation Decoder Loss:  1.6533693
Encoder Loss:  0.7206942  || Decoder Loss:  0.96209455 Validation Decoder Loss:  1.6537287
Encoder Loss:  0.7201987  || Decoder Loss:  0.9617689 Validation Decoder Loss:  1.6541375
Encoder Loss:  0.7195416  || Decoder Loss:  0.96137255 Validation Decoder Loss:  1.6546003
Encoder Loss:  0.7186212  || Decoder Loss:  0.9608786 Validation Decoder Loss:  1.6551225
Encoder Loss:  0.7172118  || Decoder Loss:  0.9602363 Validation Decoder Loss:  1.655708
Encoder Loss:  0.7147119  || Decoder Loss:  0.95932436 Validation Decoder Loss:  1.6563466
Encoder Loss:  0.70888513  || Decoder Loss:  0.957722 Validation Decoder Loss:  1.6568607
Encoder Loss:  0.6756688  || Decoder Loss:  0.94862 Validation Decoder Loss:  1.5576046
Encoder Loss:  0.29159936  || Decoder Loss:  0.456786 Validation Decoder Loss:  0.9041395
Encoder Loss:  0.26026013  || Decoder Loss:  0.42560998 Validation Decoder Loss:  0.6939993
Encoder Loss:  0.13793682  || Decoder Loss:  0.2029739 Validation Decoder Loss:  0.78959686
Encoder Loss:  0.12465689  || Decoder Loss:  0.1796459 Validation Decoder Loss:  0.42165184
Encoder Loss:  0.057857193  || Decoder Loss:  0.05607111 Validation Decoder Loss:  0.35604885
Encoder Loss:  0.04944767  || Decoder Loss:  0.041515913 Validation Decoder Loss:  0.35914993
Encoder Loss:  0.04843228  || Decoder Loss:  0.04076276 Validation Decoder Loss:  0.34600306
Encoder Loss:  0.04611196  || Decoder Loss:  0.034845155 Validation Decoder Loss:  0.35633737
Encoder Loss:  0.046475336  || Decoder Loss:  0.038045477 Validation Decoder Loss:  0.34712222
Encoder Loss:  0.044091463  || Decoder Loss:  0.03529723 Validation Decoder Loss:  0.3528581
Encoder Loss:  0.047120094  || Decoder Loss:  0.037612326 Validation Decoder Loss:  0.348596
Encoder Loss:  0.04556899  || Decoder Loss:  0.03536965 Validation Decoder Loss:  0.35146737
Encoder Loss:  0.047876917  || Decoder Loss:  0.03647293 Validation Decoder Loss:  0.351774
Encoder Loss:  0.049447652  || Decoder Loss:  0.03779482 Validation Decoder Loss:  0.36525917
Encoder Loss:  0.050313253  || Decoder Loss:  0.04084252 Validation Decoder Loss:  0.35292515
Encoder Loss:  0.046921745  || Decoder Loss:  0.037268594 Validation Decoder Loss:  0.3536024
Encoder Loss:  0.04520157  || Decoder Loss:  0.035865337 Validation Decoder Loss:  0.3528142
Encoder Loss:  0.045331866  || Decoder Loss:  0.036484975 Validation Decoder Loss:  0.35140678
Encoder Loss:  0.047456354  || Decoder Loss:  0.036509093 Validation Decoder Loss:  0.3557543
Encoder Loss:  0.047248702  || Decoder Loss:  0.038240667 Validation Decoder Loss:  0.3508816
Encoder Loss:  0.048279  || Decoder Loss:  0.037336346 Validation Decoder Loss:  0.35594013
Encoder Loss:  0.04899256  || Decoder Loss:  0.038260788 Validation Decoder Loss:  0.35420308
Encoder Loss:  0.05116  || Decoder Loss:  0.037546545 Validation Decoder Loss:  0.35069144
Encoder Loss:  0.04800485  || Decoder Loss:  0.038157433 Validation Decoder Loss:  0.3508227
Encoder Loss:  0.049735524  || Decoder Loss:  0.037886437 Validation Decoder Loss:  0.35155076
Encoder Loss:  0.045472004  || Decoder Loss:  0.036758825 Validation Decoder Loss:  0.3547703
Model: siamese_net_lr_0.04255038255654559 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3547703
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_94 (Conv3DT (None, 314, 5, 20, 1)     63        
_________________________________________________________________
reshape_94 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 1570, 20, 1)       1677      
=================================================================
Total params: 1,677
Trainable params: 1,677
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 3245, 20, 1)       1677      
=================================================================
Total params: 1,677
Trainable params: 1,677
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20943266  || Decoder Loss:  0.12851118 Validation Decoder Loss:  0.3333041
Encoder Loss:  0.17229958  || Decoder Loss:  0.07081972 Validation Decoder Loss:  0.32973695
Encoder Loss:  0.16843995  || Decoder Loss:  0.06555402 Validation Decoder Loss:  0.32522434
Encoder Loss:  0.16370049  || Decoder Loss:  0.059089236 Validation Decoder Loss:  0.3217215
Encoder Loss:  0.15824924  || Decoder Loss:  0.051654387 Validation Decoder Loss:  0.3209121
Encoder Loss:  0.15266863  || Decoder Loss:  0.04404521 Validation Decoder Loss:  0.32571462
Encoder Loss:  0.14884949  || Decoder Loss:  0.038845375 Validation Decoder Loss:  0.33458287
Encoder Loss:  0.14751993  || Decoder Loss:  0.03705 Validation Decoder Loss:  0.3357215
Encoder Loss:  0.1466782  || Decoder Loss:  0.03592485 Validation Decoder Loss:  0.33546793
Encoder Loss:  0.14595641  || Decoder Loss:  0.034968056 Validation Decoder Loss:  0.33617225
Encoder Loss:  0.14535537  || Decoder Loss:  0.034181904 Validation Decoder Loss:  0.3366658
Encoder Loss:  0.14487135  || Decoder Loss:  0.033562772 Validation Decoder Loss:  0.33711582
Encoder Loss:  0.14449  || Decoder Loss:  0.033093333 Validation Decoder Loss:  0.33751023
Encoder Loss:  0.14418949  || Decoder Loss:  0.03274698 Validation Decoder Loss:  0.33783525
Encoder Loss:  0.14394496  || Decoder Loss:  0.03249456 Validation Decoder Loss:  0.33810732
Encoder Loss:  0.14373235  || Decoder Loss:  0.0323107 Validation Decoder Loss:  0.33834666
Encoder Loss:  0.14352994  || Decoder Loss:  0.032177478 Validation Decoder Loss:  0.3385809
Encoder Loss:  0.14331567  || Decoder Loss:  0.032084435 Validation Decoder Loss:  0.33883733
Encoder Loss:  0.14306125  || Decoder Loss:  0.032027446 Validation Decoder Loss:  0.339144
Encoder Loss:  0.14271954  || Decoder Loss:  0.032008454 Validation Decoder Loss:  0.33953613
Encoder Loss:  0.14219283  || Decoder Loss:  0.03203816 Validation Decoder Loss:  0.34007904
Encoder Loss:  0.14121898  || Decoder Loss:  0.032148566 Validation Decoder Loss:  0.3409608
Encoder Loss:  0.138693  || Decoder Loss:  0.03247747 Validation Decoder Loss:  0.34326833
Encoder Loss:  0.23729937  || Decoder Loss:  0.2085472 Validation Decoder Loss:  1.664596
Encoder Loss:  0.3810377  || Decoder Loss:  0.49104485 Validation Decoder Loss:  1.1784563
Encoder Loss:  0.353988  || Decoder Loss:  0.45937997 Validation Decoder Loss:  1.2404847
Encoder Loss:  0.3626648  || Decoder Loss:  0.469489 Validation Decoder Loss:  1.0089355
Encoder Loss:  0.37326524  || Decoder Loss:  0.48855582 Validation Decoder Loss:  0.99655116
Encoder Loss:  0.37630194  || Decoder Loss:  0.48990327 Validation Decoder Loss:  1.0163059
Encoder Loss:  0.37626848  || Decoder Loss:  0.48950708 Validation Decoder Loss:  0.9866195
Encoder Loss:  0.37638327  || Decoder Loss:  0.4926776 Validation Decoder Loss:  1.009313
Encoder Loss:  0.37965897  || Decoder Loss:  0.49185094 Validation Decoder Loss:  1.0476494
Encoder Loss:  0.37930897  || Decoder Loss:  0.49206847 Validation Decoder Loss:  0.99219817
Encoder Loss:  0.3736568  || Decoder Loss:  0.4898844 Validation Decoder Loss:  0.9933165
Encoder Loss:  0.37607345  || Decoder Loss:  0.49162728 Validation Decoder Loss:  1.0377502
Encoder Loss:  0.37591657  || Decoder Loss:  0.491174 Validation Decoder Loss:  1.0388902
Encoder Loss:  0.37437645  || Decoder Loss:  0.49083966 Validation Decoder Loss:  0.9844487
Encoder Loss:  0.37124336  || Decoder Loss:  0.48347077 Validation Decoder Loss:  1.0802577
Encoder Loss:  0.38083306  || Decoder Loss:  0.48975182 Validation Decoder Loss:  1.0526754
Encoder Loss:  0.372609  || Decoder Loss:  0.48785874 Validation Decoder Loss:  1.0249223
Model: siamese_net_lr_0.08565178475375795 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0249223
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 90, 18, 20, 1)     379       
_________________________________________________________________
reshape_95 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 379
Trainable params: 379
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 1620, 20, 1)       1627      
=================================================================
Total params: 1,627
Trainable params: 1,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 3245, 20, 1)       8         
=================================================================
Total params: 8
Trainable params: 8
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11310134  || Decoder Loss:  0.06972266 Validation Decoder Loss:  0.3442112
Encoder Loss:  0.08391799  || Decoder Loss:  0.035493724 Validation Decoder Loss:  0.3442098
Encoder Loss:  0.08397251  || Decoder Loss:  0.03567132 Validation Decoder Loss:  0.34429574
Encoder Loss:  0.084003665  || Decoder Loss:  0.035868924 Validation Decoder Loss:  0.34466484
Encoder Loss:  0.083902046  || Decoder Loss:  0.035979103 Validation Decoder Loss:  0.34511614
Encoder Loss:  0.083368406  || Decoder Loss:  0.03568934 Validation Decoder Loss:  0.34569955
Encoder Loss:  0.0820917  || Decoder Loss:  0.034694187 Validation Decoder Loss:  0.34761897
Encoder Loss:  0.081171826  || Decoder Loss:  0.034332715 Validation Decoder Loss:  0.34724325
Encoder Loss:  0.079938024  || Decoder Loss:  0.034045912 Validation Decoder Loss:  0.3474552
Encoder Loss:  0.07786673  || Decoder Loss:  0.03388873 Validation Decoder Loss:  0.34748444
Encoder Loss:  0.07225932  || Decoder Loss:  0.033862993 Validation Decoder Loss:  0.3474731
Encoder Loss:  0.053929105  || Decoder Loss:  0.033935927 Validation Decoder Loss:  0.3476317
Encoder Loss:  0.040879738  || Decoder Loss:  0.033984996 Validation Decoder Loss:  0.34759247
Encoder Loss:  0.03865744  || Decoder Loss:  0.033987615 Validation Decoder Loss:  0.3476079
Encoder Loss:  0.038992323  || Decoder Loss:  0.033982255 Validation Decoder Loss:  0.34761858
Encoder Loss:  0.037939426  || Decoder Loss:  0.033970367 Validation Decoder Loss:  0.3476448
Encoder Loss:  0.037932374  || Decoder Loss:  0.03395738 Validation Decoder Loss:  0.3476714
Encoder Loss:  0.037769996  || Decoder Loss:  0.033945367 Validation Decoder Loss:  0.3476953
Encoder Loss:  0.037574526  || Decoder Loss:  0.033936244 Validation Decoder Loss:  0.34771425
Encoder Loss:  0.037303828  || Decoder Loss:  0.03392993 Validation Decoder Loss:  0.34772786
Encoder Loss:  0.036976233  || Decoder Loss:  0.033926032 Validation Decoder Loss:  0.34772986
Encoder Loss:  0.036952738  || Decoder Loss:  0.033923294 Validation Decoder Loss:  0.3477312
Encoder Loss:  0.036601517  || Decoder Loss:  0.033920974 Validation Decoder Loss:  0.3477257
Encoder Loss:  0.03646278  || Decoder Loss:  0.033918336 Validation Decoder Loss:  0.3477109
Encoder Loss:  0.0364208  || Decoder Loss:  0.0339154 Validation Decoder Loss:  0.34769368
Encoder Loss:  0.036679182  || Decoder Loss:  0.033914056 Validation Decoder Loss:  0.34768158
Encoder Loss:  0.036708836  || Decoder Loss:  0.033913888 Validation Decoder Loss:  0.3476721
Encoder Loss:  0.036963865  || Decoder Loss:  0.03391327 Validation Decoder Loss:  0.34766364
Encoder Loss:  0.03648039  || Decoder Loss:  0.03391274 Validation Decoder Loss:  0.34766954
Encoder Loss:  0.036445547  || Decoder Loss:  0.033913363 Validation Decoder Loss:  0.34767035
Encoder Loss:  0.036401737  || Decoder Loss:  0.033913653 Validation Decoder Loss:  0.34767094
Encoder Loss:  0.036903497  || Decoder Loss:  0.033913326 Validation Decoder Loss:  0.3476783
Encoder Loss:  0.037403297  || Decoder Loss:  0.033913404 Validation Decoder Loss:  0.34769726
Encoder Loss:  0.03771649  || Decoder Loss:  0.033914167 Validation Decoder Loss:  0.347724
Encoder Loss:  0.036654714  || Decoder Loss:  0.03391568 Validation Decoder Loss:  0.34773684
Encoder Loss:  0.036373485  || Decoder Loss:  0.033915587 Validation Decoder Loss:  0.34773824
Encoder Loss:  0.036862146  || Decoder Loss:  0.033915102 Validation Decoder Loss:  0.3477369
Encoder Loss:  0.036756873  || Decoder Loss:  0.033914786 Validation Decoder Loss:  0.3477039
Encoder Loss:  0.036541983  || Decoder Loss:  0.03391394 Validation Decoder Loss:  0.3476992
Encoder Loss:  0.036454674  || Decoder Loss:  0.03391386 Validation Decoder Loss:  0.34769443
Model: siamese_net_lr_0.06979208720179443 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34769443
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 324, 5, 20, 1)     73        
_________________________________________________________________
reshape_96 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 73
Trainable params: 73
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 1620, 20, 1)       1627      
=================================================================
Total params: 1,627
Trainable params: 1,627
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 3245, 20, 1)       8         
=================================================================
Total params: 8
Trainable params: 8
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09615882  || Decoder Loss:  0.058450125 Validation Decoder Loss:  0.34622905
Encoder Loss:  0.07453378  || Decoder Loss:  0.033509 Validation Decoder Loss:  0.346077
Encoder Loss:  0.07440147  || Decoder Loss:  0.033373807 Validation Decoder Loss:  0.34584615
Encoder Loss:  0.0743387  || Decoder Loss:  0.033321444 Validation Decoder Loss:  0.3456447
Encoder Loss:  0.07427767  || Decoder Loss:  0.03327965 Validation Decoder Loss:  0.34543318
Encoder Loss:  0.07421966  || Decoder Loss:  0.03325582 Validation Decoder Loss:  0.34521276
Encoder Loss:  0.07418248  || Decoder Loss:  0.033281323 Validation Decoder Loss:  0.34501097
Encoder Loss:  0.07420203  || Decoder Loss:  0.033417538 Validation Decoder Loss:  0.3448966
Encoder Loss:  0.07432276  || Decoder Loss:  0.033757 Validation Decoder Loss:  0.34501123
Encoder Loss:  0.07448081  || Decoder Loss:  0.03435201 Validation Decoder Loss:  0.34557474
Encoder Loss:  0.072985284  || Decoder Loss:  0.034005713 Validation Decoder Loss:  0.3469063
Encoder Loss:  0.05646794  || Decoder Loss:  0.033913277 Validation Decoder Loss:  0.34771043
Encoder Loss:  0.04113913  || Decoder Loss:  0.033954386 Validation Decoder Loss:  0.34754145
Encoder Loss:  0.03748263  || Decoder Loss:  0.03389792 Validation Decoder Loss:  0.34772453
Encoder Loss:  0.037165094  || Decoder Loss:  0.033932913 Validation Decoder Loss:  0.34773576
Encoder Loss:  0.037023865  || Decoder Loss:  0.033935323 Validation Decoder Loss:  0.3477562
Encoder Loss:  0.03684207  || Decoder Loss:  0.03393449 Validation Decoder Loss:  0.34776527
Encoder Loss:  0.0368054  || Decoder Loss:  0.033928633 Validation Decoder Loss:  0.34776747
Encoder Loss:  0.036841884  || Decoder Loss:  0.033919886 Validation Decoder Loss:  0.34775552
Encoder Loss:  0.036723252  || Decoder Loss:  0.033913642 Validation Decoder Loss:  0.34776115
Encoder Loss:  0.036718134  || Decoder Loss:  0.033917617 Validation Decoder Loss:  0.34777352
Encoder Loss:  0.036352176  || Decoder Loss:  0.03392261 Validation Decoder Loss:  0.34777945
Encoder Loss:  0.036269523  || Decoder Loss:  0.03392662 Validation Decoder Loss:  0.3477779
Encoder Loss:  0.036961723  || Decoder Loss:  0.03392801 Validation Decoder Loss:  0.3477827
Encoder Loss:  0.03719689  || Decoder Loss:  0.03393242 Validation Decoder Loss:  0.3477929
Encoder Loss:  0.036996733  || Decoder Loss:  0.03394393 Validation Decoder Loss:  0.34779873
Encoder Loss:  0.037170593  || Decoder Loss:  0.033946782 Validation Decoder Loss:  0.34780455
Encoder Loss:  0.036814693  || Decoder Loss:  0.033942893 Validation Decoder Loss:  0.34780523
Encoder Loss:  0.036316894  || Decoder Loss:  0.03394706 Validation Decoder Loss:  0.34780112
Encoder Loss:  0.037001766  || Decoder Loss:  0.033949107 Validation Decoder Loss:  0.34780863
Encoder Loss:  0.036370143  || Decoder Loss:  0.03396008 Validation Decoder Loss:  0.34780386
Encoder Loss:  0.036264114  || Decoder Loss:  0.0339531 Validation Decoder Loss:  0.34780294
Encoder Loss:  0.036257  || Decoder Loss:  0.03395121 Validation Decoder Loss:  0.3478045
Encoder Loss:  0.036792595  || Decoder Loss:  0.033949334 Validation Decoder Loss:  0.34781486
Encoder Loss:  0.036524426  || Decoder Loss:  0.03395187 Validation Decoder Loss:  0.34783015
Encoder Loss:  0.036228884  || Decoder Loss:  0.033952944 Validation Decoder Loss:  0.34782693
Encoder Loss:  0.036477115  || Decoder Loss:  0.033955943 Validation Decoder Loss:  0.34784073
Encoder Loss:  0.036723986  || Decoder Loss:  0.03395827 Validation Decoder Loss:  0.3478348
Encoder Loss:  0.036472544  || Decoder Loss:  0.03396083 Validation Decoder Loss:  0.34783947
Encoder Loss:  0.03722388  || Decoder Loss:  0.033965338 Validation Decoder Loss:  0.34784195
Model: siamese_net_lr_0.06842932738331187 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34784192
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_97 (Conv3DT (None, 317, 10, 20, 1)    131       
_________________________________________________________________
reshape_97 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.62576413  || Decoder Loss:  0.94585425 Validation Decoder Loss:  1.6576352
Encoder Loss:  0.6501638  || Decoder Loss:  0.9673877 Validation Decoder Loss:  1.6576426
Encoder Loss:  0.6499024  || Decoder Loss:  0.967381 Validation Decoder Loss:  1.6576481
Encoder Loss:  0.6491887  || Decoder Loss:  0.96736914 Validation Decoder Loss:  1.6576539
Encoder Loss:  0.64710283  || Decoder Loss:  0.9673547 Validation Decoder Loss:  1.6576602
Encoder Loss:  0.5912739  || Decoder Loss:  0.9673377 Validation Decoder Loss:  1.6576613
Encoder Loss:  0.6468866  || Decoder Loss:  0.9673201 Validation Decoder Loss:  1.6576648
Encoder Loss:  0.6469796  || Decoder Loss:  0.9672991 Validation Decoder Loss:  1.6576719
Encoder Loss:  0.64506334  || Decoder Loss:  0.9672754 Validation Decoder Loss:  1.6576791
Encoder Loss:  0.63668  || Decoder Loss:  0.9672486 Validation Decoder Loss:  1.6576852
Encoder Loss:  0.48975724  || Decoder Loss:  0.9672206 Validation Decoder Loss:  1.6576753
Encoder Loss:  0.45399818  || Decoder Loss:  0.9671993 Validation Decoder Loss:  1.6576512
Encoder Loss:  0.44166705  || Decoder Loss:  0.96717894 Validation Decoder Loss:  1.6576189
Encoder Loss:  0.42233127  || Decoder Loss:  0.9671573 Validation Decoder Loss:  1.6575814
Encoder Loss:  0.42761052  || Decoder Loss:  0.9671337 Validation Decoder Loss:  1.6575379
Encoder Loss:  0.44551784  || Decoder Loss:  0.9671083 Validation Decoder Loss:  1.6574937
Encoder Loss:  0.45027447  || Decoder Loss:  0.9670788 Validation Decoder Loss:  1.6574372
Encoder Loss:  0.4296514  || Decoder Loss:  0.96704745 Validation Decoder Loss:  1.6573776
Encoder Loss:  0.42716137  || Decoder Loss:  0.96701163 Validation Decoder Loss:  1.6573007
Encoder Loss:  0.43055344  || Decoder Loss:  0.9669727 Validation Decoder Loss:  1.6572099
Encoder Loss:  0.42926216  || Decoder Loss:  0.9669266 Validation Decoder Loss:  1.6571064
Encoder Loss:  0.421682  || Decoder Loss:  0.9668726 Validation Decoder Loss:  1.6569816
Encoder Loss:  0.4234809  || Decoder Loss:  0.9668094 Validation Decoder Loss:  1.6568234
Encoder Loss:  0.42818955  || Decoder Loss:  0.9667339 Validation Decoder Loss:  1.6566191
Encoder Loss:  0.4230323  || Decoder Loss:  0.96663916 Validation Decoder Loss:  1.656351
Encoder Loss:  0.42393726  || Decoder Loss:  0.9665127 Validation Decoder Loss:  1.6559732
Encoder Loss:  0.42327094  || Decoder Loss:  0.96633154 Validation Decoder Loss:  1.6553994
Encoder Loss:  0.41815317  || Decoder Loss:  0.96602404 Validation Decoder Loss:  1.6543522
Encoder Loss:  0.4247071  || Decoder Loss:  0.9653012 Validation Decoder Loss:  1.6512592
Encoder Loss:  0.31062558  || Decoder Loss:  0.66388404 Validation Decoder Loss:  0.34036008
Encoder Loss:  0.06138006  || Decoder Loss:  0.032435115 Validation Decoder Loss:  0.3409052
Encoder Loss:  0.060196105  || Decoder Loss:  0.03246042 Validation Decoder Loss:  0.34092274
Encoder Loss:  0.050901316  || Decoder Loss:  0.032465395 Validation Decoder Loss:  0.34090912
Encoder Loss:  0.04950896  || Decoder Loss:  0.032470047 Validation Decoder Loss:  0.34089112
Encoder Loss:  0.048732992  || Decoder Loss:  0.03247559 Validation Decoder Loss:  0.3408664
Encoder Loss:  0.051209897  || Decoder Loss:  0.032480992 Validation Decoder Loss:  0.34084958
Encoder Loss:  0.04915047  || Decoder Loss:  0.03248611 Validation Decoder Loss:  0.34082395
Encoder Loss:  0.05123491  || Decoder Loss:  0.032490376 Validation Decoder Loss:  0.3408019
Encoder Loss:  0.048717074  || Decoder Loss:  0.03249643 Validation Decoder Loss:  0.34077007
Encoder Loss:  0.050929815  || Decoder Loss:  0.032502875 Validation Decoder Loss:  0.3407511
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3407511
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 317, 10, 20, 1)    391       
_________________________________________________________________
reshape_98 (Reshape)         (None, 3170, 20, 1)       0         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.65472496  || Decoder Loss:  0.95076567 Validation Decoder Loss:  1.660159
Encoder Loss:  0.66656107  || Decoder Loss:  0.9665602 Validation Decoder Loss:  1.6602094
Encoder Loss:  0.6661454  || Decoder Loss:  0.9665157 Validation Decoder Loss:  1.6602945
Encoder Loss:  0.66366273  || Decoder Loss:  0.9664534 Validation Decoder Loss:  1.6603996
Encoder Loss:  0.64291877  || Decoder Loss:  0.9663761 Validation Decoder Loss:  1.6605166
Encoder Loss:  0.6565403  || Decoder Loss:  0.96628 Validation Decoder Loss:  1.6606563
Encoder Loss:  0.5781952  || Decoder Loss:  0.9661686 Validation Decoder Loss:  1.6607903
Encoder Loss:  0.561853  || Decoder Loss:  0.9660653 Validation Decoder Loss:  1.6609392
Encoder Loss:  0.5006447  || Decoder Loss:  0.9659433 Validation Decoder Loss:  1.6610725
Encoder Loss:  0.488218  || Decoder Loss:  0.96579254 Validation Decoder Loss:  1.6612186
Encoder Loss:  0.46659675  || Decoder Loss:  0.96556425 Validation Decoder Loss:  1.6613829
Encoder Loss:  0.44779968  || Decoder Loss:  0.9651137 Validation Decoder Loss:  1.6615357
Encoder Loss:  0.44930023  || Decoder Loss:  0.9631027 Validation Decoder Loss:  1.6578567
Encoder Loss:  0.12562194  || Decoder Loss:  0.2116573 Validation Decoder Loss:  0.3404922
Encoder Loss:  0.053792782  || Decoder Loss:  0.033664666 Validation Decoder Loss:  0.34035933
Encoder Loss:  0.06267375  || Decoder Loss:  0.03367487 Validation Decoder Loss:  0.34033218
Encoder Loss:  0.07659179  || Decoder Loss:  0.033690453 Validation Decoder Loss:  0.34030527
Encoder Loss:  0.055623006  || Decoder Loss:  0.033707634 Validation Decoder Loss:  0.340281
Encoder Loss:  0.048280172  || Decoder Loss:  0.033721503 Validation Decoder Loss:  0.34024262
Encoder Loss:  0.054299235  || Decoder Loss:  0.033742312 Validation Decoder Loss:  0.3402079
Encoder Loss:  0.0487221  || Decoder Loss:  0.03376259 Validation Decoder Loss:  0.34017384
Encoder Loss:  0.05522323  || Decoder Loss:  0.03377884 Validation Decoder Loss:  0.3401448
Encoder Loss:  0.05479649  || Decoder Loss:  0.03379269 Validation Decoder Loss:  0.34012467
Encoder Loss:  0.050739914  || Decoder Loss:  0.033801798 Validation Decoder Loss:  0.3400966
Encoder Loss:  0.047763154  || Decoder Loss:  0.03382374 Validation Decoder Loss:  0.34004667
Encoder Loss:  0.05413594  || Decoder Loss:  0.03385017 Validation Decoder Loss:  0.34001124
Encoder Loss:  0.050463166  || Decoder Loss:  0.033867963 Validation Decoder Loss:  0.3399791
Encoder Loss:  0.051156946  || Decoder Loss:  0.033883236 Validation Decoder Loss:  0.33995235
Encoder Loss:  0.04997833  || Decoder Loss:  0.033902396 Validation Decoder Loss:  0.3399128
Encoder Loss:  0.059950043  || Decoder Loss:  0.03392252 Validation Decoder Loss:  0.3398739
Encoder Loss:  0.050877318  || Decoder Loss:  0.03394239 Validation Decoder Loss:  0.33983314
Encoder Loss:  0.05019691  || Decoder Loss:  0.03396447 Validation Decoder Loss:  0.33979496
Encoder Loss:  0.0536326  || Decoder Loss:  0.03398227 Validation Decoder Loss:  0.3397641
Encoder Loss:  0.05327189  || Decoder Loss:  0.033999372 Validation Decoder Loss:  0.33973137
Encoder Loss:  0.047276773  || Decoder Loss:  0.034022257 Validation Decoder Loss:  0.3396775
Encoder Loss:  0.051423173  || Decoder Loss:  0.034059864 Validation Decoder Loss:  0.33962184
Encoder Loss:  0.047794737  || Decoder Loss:  0.034093257 Validation Decoder Loss:  0.33956927
Encoder Loss:  0.049574193  || Decoder Loss:  0.034125973 Validation Decoder Loss:  0.33951473
Encoder Loss:  0.053636774  || Decoder Loss:  0.034152724 Validation Decoder Loss:  0.33946568
Encoder Loss:  0.049580682  || Decoder Loss:  0.03418644 Validation Decoder Loss:  0.33939964
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33939964
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 454, 5, 20, 1)     329       
_________________________________________________________________
reshape_99 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 329
Trainable params: 329
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 2270, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 3245, 20, 1)       977       
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.51729214  || Decoder Loss:  0.9075863 Validation Decoder Loss:  1.6310099
Encoder Loss:  0.5269914  || Decoder Loss:  0.9222481 Validation Decoder Loss:  1.6272362
Encoder Loss:  0.5243269  || Decoder Loss:  0.9191548 Validation Decoder Loss:  1.6216195
Encoder Loss:  0.5132228  || Decoder Loss:  0.91449785 Validation Decoder Loss:  1.6131065
Encoder Loss:  0.5186874  || Decoder Loss:  0.90733415 Validation Decoder Loss:  1.597749
Encoder Loss:  0.50960743  || Decoder Loss:  0.89327866 Validation Decoder Loss:  1.56047
Encoder Loss:  0.44375932  || Decoder Loss:  0.62081116 Validation Decoder Loss:  0.42365295
Encoder Loss:  0.25419033  || Decoder Loss:  0.34310216 Validation Decoder Loss:  1.3755199
Encoder Loss:  0.15083084  || Decoder Loss:  0.47502494 Validation Decoder Loss:  1.2986438
Encoder Loss:  0.14343062  || Decoder Loss:  0.4845905 Validation Decoder Loss:  1.2503685
Encoder Loss:  0.13702528  || Decoder Loss:  0.47497404 Validation Decoder Loss:  1.2249007
Encoder Loss:  0.13401783  || Decoder Loss:  0.47655803 Validation Decoder Loss:  1.2444556
Encoder Loss:  0.1333409  || Decoder Loss:  0.4789464 Validation Decoder Loss:  1.2111801
Encoder Loss:  0.12860948  || Decoder Loss:  0.47461373 Validation Decoder Loss:  1.2410836
Encoder Loss:  0.13147368  || Decoder Loss:  0.47823542 Validation Decoder Loss:  1.244834
Encoder Loss:  0.12963924  || Decoder Loss:  0.47802058 Validation Decoder Loss:  1.2298393
Encoder Loss:  0.13111717  || Decoder Loss:  0.47203133 Validation Decoder Loss:  1.2096648
Encoder Loss:  0.1277978  || Decoder Loss:  0.47422275 Validation Decoder Loss:  1.2175757
Encoder Loss:  0.12609561  || Decoder Loss:  0.47064054 Validation Decoder Loss:  1.1959543
Encoder Loss:  0.12714386  || Decoder Loss:  0.46996132 Validation Decoder Loss:  1.2498149
Encoder Loss:  0.13094003  || Decoder Loss:  0.47342864 Validation Decoder Loss:  1.161561
Encoder Loss:  0.12807734  || Decoder Loss:  0.46615317 Validation Decoder Loss:  1.1797532
Encoder Loss:  0.1291634  || Decoder Loss:  0.46289483 Validation Decoder Loss:  1.3067533
Encoder Loss:  0.14005417  || Decoder Loss:  0.4703696 Validation Decoder Loss:  1.2940149
Encoder Loss:  0.12600595  || Decoder Loss:  0.46203834 Validation Decoder Loss:  1.2041767
Encoder Loss:  0.12591733  || Decoder Loss:  0.4390503 Validation Decoder Loss:  0.736316
Encoder Loss:  0.11452276  || Decoder Loss:  0.3852634 Validation Decoder Loss:  1.2280633
Encoder Loss:  0.13025913  || Decoder Loss:  0.48490605 Validation Decoder Loss:  1.2412043
Encoder Loss:  0.119163886  || Decoder Loss:  0.43296432 Validation Decoder Loss:  0.548015
Encoder Loss:  0.12028259  || Decoder Loss:  0.42863777 Validation Decoder Loss:  1.2648246
Encoder Loss:  0.120491244  || Decoder Loss:  0.40681973 Validation Decoder Loss:  0.6989106
Encoder Loss:  0.1113616  || Decoder Loss:  0.38740593 Validation Decoder Loss:  0.5463973
Encoder Loss:  0.0932921  || Decoder Loss:  0.27452034 Validation Decoder Loss:  1.0713439
Encoder Loss:  0.13367978  || Decoder Loss:  0.48442605 Validation Decoder Loss:  1.140479
Encoder Loss:  0.13047582  || Decoder Loss:  0.48920962 Validation Decoder Loss:  1.139569
Encoder Loss:  0.12835282  || Decoder Loss:  0.48718348 Validation Decoder Loss:  1.1389084
Encoder Loss:  0.13118288  || Decoder Loss:  0.48590565 Validation Decoder Loss:  1.1159279
Encoder Loss:  0.12834547  || Decoder Loss:  0.47639215 Validation Decoder Loss:  1.1087868
Encoder Loss:  0.11052107  || Decoder Loss:  0.36850566 Validation Decoder Loss:  0.70765305
Encoder Loss:  0.1026798  || Decoder Loss:  0.33683044 Validation Decoder Loss:  0.76733124
Model: siamese_net_lr_0.0271614749175475 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.76733124
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_100 (Conv3D (None, 634, 5, 20, 1)     446       
_________________________________________________________________
reshape_100 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 446
Trainable params: 446
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.599995  || Decoder Loss:  0.64517015 Validation Decoder Loss:  0.51152337
Encoder Loss:  0.31651592  || Decoder Loss:  0.34820688 Validation Decoder Loss:  0.2768759
Encoder Loss:  0.080350876  || Decoder Loss:  0.08233068 Validation Decoder Loss:  0.4310323
Encoder Loss:  0.03958396  || Decoder Loss:  0.03685473 Validation Decoder Loss:  0.36310536
Encoder Loss:  0.036584027  || Decoder Loss:  0.033680633 Validation Decoder Loss:  0.35040402
Encoder Loss:  0.037799183  || Decoder Loss:  0.033407178 Validation Decoder Loss:  0.34845892
Encoder Loss:  0.038105533  || Decoder Loss:  0.03338041 Validation Decoder Loss:  0.34323692
Encoder Loss:  0.039934292  || Decoder Loss:  0.03690171 Validation Decoder Loss:  0.34870794
Encoder Loss:  0.04633847  || Decoder Loss:  0.042972002 Validation Decoder Loss:  0.35152903
Encoder Loss:  0.041337967  || Decoder Loss:  0.0383173 Validation Decoder Loss:  0.3664341
Encoder Loss:  0.042300053  || Decoder Loss:  0.040257767 Validation Decoder Loss:  0.36634004
Encoder Loss:  0.04162134  || Decoder Loss:  0.03922375 Validation Decoder Loss:  0.3440831
Encoder Loss:  0.040484775  || Decoder Loss:  0.037259895 Validation Decoder Loss:  0.35558283
Encoder Loss:  0.043383967  || Decoder Loss:  0.041057095 Validation Decoder Loss:  0.37891853
Encoder Loss:  0.04388949  || Decoder Loss:  0.041564178 Validation Decoder Loss:  0.37303388
Encoder Loss:  0.04374038  || Decoder Loss:  0.041137043 Validation Decoder Loss:  0.36070627
Encoder Loss:  0.042741798  || Decoder Loss:  0.04092179 Validation Decoder Loss:  0.3450791
Encoder Loss:  0.040630743  || Decoder Loss:  0.03834709 Validation Decoder Loss:  0.3671826
Encoder Loss:  0.042323127  || Decoder Loss:  0.040518288 Validation Decoder Loss:  0.34991872
Encoder Loss:  0.042853225  || Decoder Loss:  0.041065477 Validation Decoder Loss:  0.36711466
Encoder Loss:  0.041273758  || Decoder Loss:  0.039123297 Validation Decoder Loss:  0.37325376
Encoder Loss:  0.042982377  || Decoder Loss:  0.041197944 Validation Decoder Loss:  0.34803224
Encoder Loss:  0.039801832  || Decoder Loss:  0.037749063 Validation Decoder Loss:  0.34985325
Encoder Loss:  0.04013194  || Decoder Loss:  0.038028184 Validation Decoder Loss:  0.35006428
Encoder Loss:  0.04007592  || Decoder Loss:  0.038016625 Validation Decoder Loss:  0.3472049
Encoder Loss:  0.040128503  || Decoder Loss:  0.038093247 Validation Decoder Loss:  0.34865502
Encoder Loss:  0.039866522  || Decoder Loss:  0.03814343 Validation Decoder Loss:  0.35258728
Encoder Loss:  0.040390387  || Decoder Loss:  0.03850491 Validation Decoder Loss:  0.36230716
Encoder Loss:  0.041131724  || Decoder Loss:  0.03943489 Validation Decoder Loss:  0.35049924
Encoder Loss:  0.040203813  || Decoder Loss:  0.03736984 Validation Decoder Loss:  0.34599128
Encoder Loss:  0.041929036  || Decoder Loss:  0.03968613 Validation Decoder Loss:  0.34612226
Encoder Loss:  0.04119868  || Decoder Loss:  0.03923862 Validation Decoder Loss:  0.34934747
Encoder Loss:  0.040388383  || Decoder Loss:  0.038280047 Validation Decoder Loss:  0.35379905
Encoder Loss:  0.04158058  || Decoder Loss:  0.039175082 Validation Decoder Loss:  0.3627473
Encoder Loss:  0.041045535  || Decoder Loss:  0.039080955 Validation Decoder Loss:  0.3554009
Encoder Loss:  0.040593043  || Decoder Loss:  0.039052136 Validation Decoder Loss:  0.35355
Encoder Loss:  0.03984701  || Decoder Loss:  0.03795203 Validation Decoder Loss:  0.34582394
Encoder Loss:  0.03945504  || Decoder Loss:  0.037440576 Validation Decoder Loss:  0.3551013
Encoder Loss:  0.041282997  || Decoder Loss:  0.03925841 Validation Decoder Loss:  0.3628598
Encoder Loss:  0.04230593  || Decoder Loss:  0.040247835 Validation Decoder Loss:  0.3473639
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3473639
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 78, 40, 20, 1)     121       
_________________________________________________________________
reshape_101 (Reshape)        (None, 3120, 20, 1)       0         
=================================================================
Total params: 121
Trainable params: 121
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 3120, 20, 1)       127       
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 3245, 20, 1)       127       
=================================================================
Total params: 127
Trainable params: 127
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22551407  || Decoder Loss:  0.08862801 Validation Decoder Loss:  0.34431672
Encoder Loss:  0.20119843  || Decoder Loss:  0.032610215 Validation Decoder Loss:  0.34419665
Encoder Loss:  0.20119359  || Decoder Loss:  0.032623947 Validation Decoder Loss:  0.3441756
Encoder Loss:  0.20116052  || Decoder Loss:  0.032621354 Validation Decoder Loss:  0.34415942
Encoder Loss:  0.20110914  || Decoder Loss:  0.032616723 Validation Decoder Loss:  0.34413955
Encoder Loss:  0.20103003  || Decoder Loss:  0.0326111 Validation Decoder Loss:  0.34411496
Encoder Loss:  0.20090286  || Decoder Loss:  0.03260409 Validation Decoder Loss:  0.34408578
Encoder Loss:  0.20068727  || Decoder Loss:  0.03259473 Validation Decoder Loss:  0.3440528
Encoder Loss:  0.20029639  || Decoder Loss:  0.03258125 Validation Decoder Loss:  0.3440179
Encoder Loss:  0.19951847  || Decoder Loss:  0.032560788 Validation Decoder Loss:  0.34398454
Encoder Loss:  0.19768144  || Decoder Loss:  0.032529596 Validation Decoder Loss:  0.34395814
Encoder Loss:  0.19036755  || Decoder Loss:  0.03249602 Validation Decoder Loss:  0.34393832
Encoder Loss:  0.2980644  || Decoder Loss:  0.36587387 Validation Decoder Loss:  0.9122882
Encoder Loss:  0.2635578  || Decoder Loss:  0.38837123 Validation Decoder Loss:  0.43557158
Encoder Loss:  0.12083539  || Decoder Loss:  0.15100813 Validation Decoder Loss:  0.3808271
Encoder Loss:  0.065049104  || Decoder Loss:  0.055411715 Validation Decoder Loss:  0.35062096
Encoder Loss:  0.051518206  || Decoder Loss:  0.03581951 Validation Decoder Loss:  0.34528774
Encoder Loss:  0.047844693  || Decoder Loss:  0.034487695 Validation Decoder Loss:  0.34499332
Encoder Loss:  0.045915235  || Decoder Loss:  0.03397715 Validation Decoder Loss:  0.3453768
Encoder Loss:  0.045444638  || Decoder Loss:  0.03385706 Validation Decoder Loss:  0.34579086
Encoder Loss:  0.044755355  || Decoder Loss:  0.0336011 Validation Decoder Loss:  0.347162
Encoder Loss:  0.049110204  || Decoder Loss:  0.033852078 Validation Decoder Loss:  0.34616768
Encoder Loss:  0.045170937  || Decoder Loss:  0.03392406 Validation Decoder Loss:  0.3475405
Encoder Loss:  0.046108376  || Decoder Loss:  0.03396856 Validation Decoder Loss:  0.3463562
Encoder Loss:  0.05300396  || Decoder Loss:  0.033857387 Validation Decoder Loss:  0.34671706
Encoder Loss:  0.046066575  || Decoder Loss:  0.033693906 Validation Decoder Loss:  0.3479859
Encoder Loss:  0.051890098  || Decoder Loss:  0.033764273 Validation Decoder Loss:  0.34809342
Encoder Loss:  0.043554615  || Decoder Loss:  0.03373058 Validation Decoder Loss:  0.34778422
Encoder Loss:  0.04367049  || Decoder Loss:  0.033678897 Validation Decoder Loss:  0.34777743
Encoder Loss:  0.0434679  || Decoder Loss:  0.033666123 Validation Decoder Loss:  0.3478386
Encoder Loss:  0.043197155  || Decoder Loss:  0.03364636 Validation Decoder Loss:  0.3478833
Encoder Loss:  0.04608219  || Decoder Loss:  0.03362185 Validation Decoder Loss:  0.3478026
Encoder Loss:  0.04480349  || Decoder Loss:  0.03358619 Validation Decoder Loss:  0.34829402
Encoder Loss:  0.04444945  || Decoder Loss:  0.03361946 Validation Decoder Loss:  0.34881338
Encoder Loss:  0.043664604  || Decoder Loss:  0.03368394 Validation Decoder Loss:  0.34828305
Encoder Loss:  0.04421129  || Decoder Loss:  0.03363664 Validation Decoder Loss:  0.34836105
Encoder Loss:  0.046356104  || Decoder Loss:  0.033638123 Validation Decoder Loss:  0.3479458
Encoder Loss:  0.05040004  || Decoder Loss:  0.03361924 Validation Decoder Loss:  0.3478976
Encoder Loss:  0.047149945  || Decoder Loss:  0.033678178 Validation Decoder Loss:  0.3483297
Encoder Loss:  0.04461033  || Decoder Loss:  0.033652637 Validation Decoder Loss:  0.34787965
Model: siamese_net_lr_0.027509448958054596 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34787965
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 634, 5, 20, 1)     572       
_________________________________________________________________
reshape_102 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 572
Trainable params: 572
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6331163  || Decoder Loss:  0.9435366 Validation Decoder Loss:  1.6556557
Encoder Loss:  0.64643174  || Decoder Loss:  0.967474 Validation Decoder Loss:  1.6553334
Encoder Loss:  0.6454508  || Decoder Loss:  0.96732086 Validation Decoder Loss:  1.6548505
Encoder Loss:  0.6304961  || Decoder Loss:  0.96708643 Validation Decoder Loss:  1.6542201
Encoder Loss:  0.6458712  || Decoder Loss:  0.96674776 Validation Decoder Loss:  1.6533079
Encoder Loss:  0.6453479  || Decoder Loss:  0.96622413 Validation Decoder Loss:  1.6520438
Encoder Loss:  0.64450544  || Decoder Loss:  0.96540314 Validation Decoder Loss:  1.6502525
Encoder Loss:  0.6431751  || Decoder Loss:  0.96408045 Validation Decoder Loss:  1.6476067
Encoder Loss:  0.6409955  || Decoder Loss:  0.9618727 Validation Decoder Loss:  1.6434758
Encoder Loss:  0.63725317  || Decoder Loss:  0.95802253 Validation Decoder Loss:  1.6365336
Encoder Loss:  0.6303945  || Decoder Loss:  0.9508638 Validation Decoder Loss:  1.6235541
Encoder Loss:  0.6163526  || Decoder Loss:  0.9359613 Validation Decoder Loss:  1.5943738
Encoder Loss:  0.57965875  || Decoder Loss:  0.8958737 Validation Decoder Loss:  1.4935027
Encoder Loss:  0.38991416  || Decoder Loss:  0.65924853 Validation Decoder Loss:  0.46845257
Encoder Loss:  0.19024548  || Decoder Loss:  0.3507191 Validation Decoder Loss:  0.8316344
Encoder Loss:  0.2145764  || Decoder Loss:  0.45480168 Validation Decoder Loss:  0.8340912
Encoder Loss:  0.14244074  || Decoder Loss:  0.27659103 Validation Decoder Loss:  0.62032616
Encoder Loss:  0.12757371  || Decoder Loss:  0.24185608 Validation Decoder Loss:  0.8324603
Encoder Loss:  0.13958234  || Decoder Loss:  0.27551147 Validation Decoder Loss:  0.36644492
Encoder Loss:  0.06367794  || Decoder Loss:  0.07989872 Validation Decoder Loss:  0.37243643
Encoder Loss:  0.059057765  || Decoder Loss:  0.063481055 Validation Decoder Loss:  0.38266218
Encoder Loss:  0.05047953  || Decoder Loss:  0.04414499 Validation Decoder Loss:  0.343967
Encoder Loss:  0.046518575  || Decoder Loss:  0.03494616 Validation Decoder Loss:  0.3465283
Encoder Loss:  0.045106817  || Decoder Loss:  0.03372674 Validation Decoder Loss:  0.3458268
Encoder Loss:  0.045558237  || Decoder Loss:  0.03363257 Validation Decoder Loss:  0.34702852
Encoder Loss:  0.04670455  || Decoder Loss:  0.033761393 Validation Decoder Loss:  0.34796426
Encoder Loss:  0.046748456  || Decoder Loss:  0.03388553 Validation Decoder Loss:  0.3463214
Encoder Loss:  0.046723805  || Decoder Loss:  0.03370173 Validation Decoder Loss:  0.34476227
Encoder Loss:  0.045127764  || Decoder Loss:  0.03395226 Validation Decoder Loss:  0.34392998
Encoder Loss:  0.045407  || Decoder Loss:  0.034305528 Validation Decoder Loss:  0.34294415
Encoder Loss:  0.04681552  || Decoder Loss:  0.03481183 Validation Decoder Loss:  0.34193215
Encoder Loss:  0.04639779  || Decoder Loss:  0.035510853 Validation Decoder Loss:  0.34164983
Encoder Loss:  0.046737038  || Decoder Loss:  0.035751067 Validation Decoder Loss:  0.34130406
Encoder Loss:  0.047081992  || Decoder Loss:  0.03603145 Validation Decoder Loss:  0.34108487
Encoder Loss:  0.04650979  || Decoder Loss:  0.036129925 Validation Decoder Loss:  0.34091067
Encoder Loss:  0.047230385  || Decoder Loss:  0.03615635 Validation Decoder Loss:  0.34048924
Encoder Loss:  0.04674256  || Decoder Loss:  0.03656317 Validation Decoder Loss:  0.3412624
Encoder Loss:  0.04705195  || Decoder Loss:  0.03518533 Validation Decoder Loss:  0.34069622
Encoder Loss:  0.047303878  || Decoder Loss:  0.037664868 Validation Decoder Loss:  0.344278
Encoder Loss:  0.045890912  || Decoder Loss:  0.034225896 Validation Decoder Loss:  0.34911913
Model: siamese_net_lr_0.06109193348111653 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34911913
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_103 (Conv3D (None, 634, 5, 20, 1)     320       
_________________________________________________________________
reshape_103 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 320
Trainable params: 320
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.8372084  || Decoder Loss:  0.94344103 Validation Decoder Loss:  1.663467
Encoder Loss:  0.8608683  || Decoder Loss:  0.966035 Validation Decoder Loss:  1.6634243
Encoder Loss:  0.8531221  || Decoder Loss:  0.96594423 Validation Decoder Loss:  1.6633801
Encoder Loss:  0.85935783  || Decoder Loss:  0.9658263 Validation Decoder Loss:  1.6632762
Encoder Loss:  0.8421977  || Decoder Loss:  0.9656732 Validation Decoder Loss:  1.6631376
Encoder Loss:  0.8215285  || Decoder Loss:  0.965537 Validation Decoder Loss:  1.6630183
Encoder Loss:  0.7968499  || Decoder Loss:  0.9654475 Validation Decoder Loss:  1.6629374
Encoder Loss:  0.7914418  || Decoder Loss:  0.96539354 Validation Decoder Loss:  1.6628722
Encoder Loss:  0.79903  || Decoder Loss:  0.96533847 Validation Decoder Loss:  1.6627766
Encoder Loss:  0.7886103  || Decoder Loss:  0.9652764 Validation Decoder Loss:  1.662704
Encoder Loss:  0.7889831  || Decoder Loss:  0.965228 Validation Decoder Loss:  1.6626177
Encoder Loss:  0.7887742  || Decoder Loss:  0.965181 Validation Decoder Loss:  1.6625315
Encoder Loss:  0.7884012  || Decoder Loss:  0.96512395 Validation Decoder Loss:  1.6624423
Encoder Loss:  0.78742486  || Decoder Loss:  0.9650535 Validation Decoder Loss:  1.6623473
Encoder Loss:  0.7869034  || Decoder Loss:  0.964977 Validation Decoder Loss:  1.6622312
Encoder Loss:  0.7852487  || Decoder Loss:  0.9648939 Validation Decoder Loss:  1.6621037
Encoder Loss:  0.785093  || Decoder Loss:  0.96479106 Validation Decoder Loss:  1.6619539
Encoder Loss:  0.7902236  || Decoder Loss:  0.96467507 Validation Decoder Loss:  1.6617019
Encoder Loss:  0.78944993  || Decoder Loss:  0.9645438 Validation Decoder Loss:  1.6613612
Encoder Loss:  0.78618956  || Decoder Loss:  0.9643939 Validation Decoder Loss:  1.660927
Encoder Loss:  0.78994423  || Decoder Loss:  0.96419775 Validation Decoder Loss:  1.6602657
Encoder Loss:  0.78822255  || Decoder Loss:  0.96390474 Validation Decoder Loss:  1.6591585
Encoder Loss:  0.78553414  || Decoder Loss:  0.96333486 Validation Decoder Loss:  1.6565528
Encoder Loss:  0.72754127  || Decoder Loss:  0.8922664 Validation Decoder Loss:  0.33297795
Encoder Loss:  0.042126656  || Decoder Loss:  0.034865115 Validation Decoder Loss:  0.33566993
Encoder Loss:  0.041759804  || Decoder Loss:  0.034964193 Validation Decoder Loss:  0.33569574
Encoder Loss:  0.042422976  || Decoder Loss:  0.035020754 Validation Decoder Loss:  0.33570066
Encoder Loss:  0.04167067  || Decoder Loss:  0.035075553 Validation Decoder Loss:  0.33567625
Encoder Loss:  0.041668743  || Decoder Loss:  0.035137694 Validation Decoder Loss:  0.33562627
Encoder Loss:  0.041441765  || Decoder Loss:  0.035196003 Validation Decoder Loss:  0.3356216
Encoder Loss:  0.042394005  || Decoder Loss:  0.03523282 Validation Decoder Loss:  0.33563596
Encoder Loss:  0.04310087  || Decoder Loss:  0.035287105 Validation Decoder Loss:  0.33563694
Encoder Loss:  0.04068509  || Decoder Loss:  0.035344657 Validation Decoder Loss:  0.33561057
Encoder Loss:  0.040975854  || Decoder Loss:  0.03540666 Validation Decoder Loss:  0.33556873
Encoder Loss:  0.041788004  || Decoder Loss:  0.03546572 Validation Decoder Loss:  0.33556646
Encoder Loss:  0.04322876  || Decoder Loss:  0.03552238 Validation Decoder Loss:  0.3355679
Encoder Loss:  0.04086843  || Decoder Loss:  0.035598755 Validation Decoder Loss:  0.33553112
Encoder Loss:  0.0403095  || Decoder Loss:  0.035683982 Validation Decoder Loss:  0.33545375
Encoder Loss:  0.044391945  || Decoder Loss:  0.035763003 Validation Decoder Loss:  0.3354566
Encoder Loss:  0.04205577  || Decoder Loss:  0.03584063 Validation Decoder Loss:  0.3354559
Model: siamese_net_lr_0.07519923954545071 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3354559
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 151, 20, 20, 1)    1057      
_________________________________________________________________
reshape_104 (Reshape)        (None, 3020, 20, 1)       0         
=================================================================
Total params: 1,057
Trainable params: 1,057
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 3020, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 3245, 20, 1)       227       
=================================================================
Total params: 227
Trainable params: 227
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.54280126  || Decoder Loss:  0.9313767 Validation Decoder Loss:  1.658983
Encoder Loss:  0.46939933  || Decoder Loss:  0.5870724 Validation Decoder Loss:  0.35055667
Encoder Loss:  0.32632646  || Decoder Loss:  0.05653336 Validation Decoder Loss:  0.3554889
Encoder Loss:  0.3193643  || Decoder Loss:  0.0663151 Validation Decoder Loss:  0.37019402
Encoder Loss:  0.30464596  || Decoder Loss:  0.08823146 Validation Decoder Loss:  0.42002124
Encoder Loss:  0.24619703  || Decoder Loss:  0.25702432 Validation Decoder Loss:  1.2754861
Encoder Loss:  0.22015814  || Decoder Loss:  0.50278366 Validation Decoder Loss:  1.1969501
Encoder Loss:  0.1988971  || Decoder Loss:  0.48911855 Validation Decoder Loss:  1.0904438
Encoder Loss:  0.18192188  || Decoder Loss:  0.46789855 Validation Decoder Loss:  1.0690969
Encoder Loss:  0.18028381  || Decoder Loss:  0.4695422 Validation Decoder Loss:  1.0780205
Encoder Loss:  0.17897797  || Decoder Loss:  0.46972588 Validation Decoder Loss:  1.0845673
Encoder Loss:  0.17774002  || Decoder Loss:  0.46888936 Validation Decoder Loss:  1.0987487
Encoder Loss:  0.17689717  || Decoder Loss:  0.46925968 Validation Decoder Loss:  1.0951757
Encoder Loss:  0.17226423  || Decoder Loss:  0.4571498 Validation Decoder Loss:  0.97830164
Encoder Loss:  0.15585665  || Decoder Loss:  0.3983466 Validation Decoder Loss:  0.6605636
Encoder Loss:  0.10594782  || Decoder Loss:  0.2153455 Validation Decoder Loss:  0.66792595
Encoder Loss:  0.08258354  || Decoder Loss:  0.1297298 Validation Decoder Loss:  0.46757054
Encoder Loss:  0.064367235  || Decoder Loss:  0.06509918 Validation Decoder Loss:  0.38401544
Encoder Loss:  0.0555986  || Decoder Loss:  0.043027334 Validation Decoder Loss:  0.356816
Encoder Loss:  0.051065814  || Decoder Loss:  0.034571048 Validation Decoder Loss:  0.34755185
Encoder Loss:  0.048044566  || Decoder Loss:  0.03397306 Validation Decoder Loss:  0.3447091
Encoder Loss:  0.050385375  || Decoder Loss:  0.033860825 Validation Decoder Loss:  0.34422818
Encoder Loss:  0.055832487  || Decoder Loss:  0.034091998 Validation Decoder Loss:  0.34887707
Encoder Loss:  0.051289134  || Decoder Loss:  0.03694704 Validation Decoder Loss:  0.35590178
Encoder Loss:  0.056127567  || Decoder Loss:  0.03893069 Validation Decoder Loss:  0.3481006
Encoder Loss:  0.049258042  || Decoder Loss:  0.038384195 Validation Decoder Loss:  0.35369253
Encoder Loss:  0.051405128  || Decoder Loss:  0.038598727 Validation Decoder Loss:  0.35190704
Encoder Loss:  0.056228984  || Decoder Loss:  0.041276556 Validation Decoder Loss:  0.34925282
Encoder Loss:  0.04952873  || Decoder Loss:  0.03863573 Validation Decoder Loss:  0.35355923
Encoder Loss:  0.04898809  || Decoder Loss:  0.037184235 Validation Decoder Loss:  0.3578244
Encoder Loss:  0.04989467  || Decoder Loss:  0.040096063 Validation Decoder Loss:  0.35306215
Encoder Loss:  0.04981128  || Decoder Loss:  0.03940118 Validation Decoder Loss:  0.34686887
Encoder Loss:  0.050103903  || Decoder Loss:  0.03577653 Validation Decoder Loss:  0.35316086
Encoder Loss:  0.05418001  || Decoder Loss:  0.03884459 Validation Decoder Loss:  0.3561656
Encoder Loss:  0.05067766  || Decoder Loss:  0.04042785 Validation Decoder Loss:  0.34789586
Encoder Loss:  0.048998423  || Decoder Loss:  0.03632762 Validation Decoder Loss:  0.35479385
Encoder Loss:  0.04918231  || Decoder Loss:  0.038832337 Validation Decoder Loss:  0.35488412
Encoder Loss:  0.052512284  || Decoder Loss:  0.03949159 Validation Decoder Loss:  0.3445775
Encoder Loss:  0.051080666  || Decoder Loss:  0.03619903 Validation Decoder Loss:  0.3533102
Encoder Loss:  0.050474502  || Decoder Loss:  0.038106784 Validation Decoder Loss:  0.3493251
Model: siamese_net_lr_0.02271966235786854 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3493251
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 634, 5, 20, 1)     257       
_________________________________________________________________
reshape_105 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 3170, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [5.89485229e-02 7.32696291e-02 3.41291014e-02 9.06975504e-01
 2.69107805e-01 1.71458980e-02 3.17000000e+03]
Optimized Validation Decoder Loss: 0.3350878059864044











Optimizing at level  2
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_270 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 634, 5, 20, 1)     564       
_________________________________________________________________
reshape_106 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_272 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_274 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08168104  || Decoder Loss:  0.054226745 Validation Decoder Loss:  0.3408751
Encoder Loss:  0.07648754  || Decoder Loss:  0.0814641 Validation Decoder Loss:  0.34497476
Encoder Loss:  0.08343667  || Decoder Loss:  0.104637966 Validation Decoder Loss:  0.35084867
Encoder Loss:  0.076625645  || Decoder Loss:  0.10101322 Validation Decoder Loss:  0.34957564
Encoder Loss:  0.064846426  || Decoder Loss:  0.078597456 Validation Decoder Loss:  0.34936452
Encoder Loss:  0.06488057  || Decoder Loss:  0.07925245 Validation Decoder Loss:  0.3495504
Encoder Loss:  0.06488711  || Decoder Loss:  0.07944943 Validation Decoder Loss:  0.34960967
Encoder Loss:  0.06487171  || Decoder Loss:  0.0794775 Validation Decoder Loss:  0.34974605
Encoder Loss:  0.06482701  || Decoder Loss:  0.07940923 Validation Decoder Loss:  0.349862
Encoder Loss:  0.06478436  || Decoder Loss:  0.07934127 Validation Decoder Loss:  0.35016707
Encoder Loss:  0.06476497  || Decoder Loss:  0.079309456 Validation Decoder Loss:  0.35052454
Encoder Loss:  0.06474988  || Decoder Loss:  0.07928502 Validation Decoder Loss:  0.35087287
Encoder Loss:  0.064731576  || Decoder Loss:  0.079253204 Validation Decoder Loss:  0.35119927
Encoder Loss:  0.06468421  || Decoder Loss:  0.07916452 Validation Decoder Loss:  0.3513658
Encoder Loss:  0.064607926  || Decoder Loss:  0.079014406 Validation Decoder Loss:  0.35143107
Encoder Loss:  0.06450203  || Decoder Loss:  0.078805715 Validation Decoder Loss:  0.35131603
Encoder Loss:  0.06435928  || Decoder Loss:  0.07852253 Validation Decoder Loss:  0.35110897
Encoder Loss:  0.06418356  || Decoder Loss:  0.0781737 Validation Decoder Loss:  0.350825
Encoder Loss:  0.06396133  || Decoder Loss:  0.07773236 Validation Decoder Loss:  0.35044733
Encoder Loss:  0.06366481  || Decoder Loss:  0.07714331 Validation Decoder Loss:  0.3499376
Encoder Loss:  0.06322758  || Decoder Loss:  0.07627462 Validation Decoder Loss:  0.34919408
Encoder Loss:  0.062440276  || Decoder Loss:  0.07471 Validation Decoder Loss:  0.34775168
Encoder Loss:  0.059421387  || Decoder Loss:  0.06870944 Validation Decoder Loss:  0.3388001
Encoder Loss:  0.064953364  || Decoder Loss:  0.07970642 Validation Decoder Loss:  0.35218924
Encoder Loss:  0.06557763  || Decoder Loss:  0.08094771 Validation Decoder Loss:  0.3521204
Encoder Loss:  0.06555661  || Decoder Loss:  0.080906264 Validation Decoder Loss:  0.35197017
Encoder Loss:  0.06551693  || Decoder Loss:  0.080827534 Validation Decoder Loss:  0.35184392
Encoder Loss:  0.06547474  || Decoder Loss:  0.08074444 Validation Decoder Loss:  0.35170382
Encoder Loss:  0.065436564  || Decoder Loss:  0.08066848 Validation Decoder Loss:  0.3516068
Encoder Loss:  0.06539312  || Decoder Loss:  0.08058256 Validation Decoder Loss:  0.3514047
Encoder Loss:  0.06535061  || Decoder Loss:  0.0804975 Validation Decoder Loss:  0.35124725
Encoder Loss:  0.065315574  || Decoder Loss:  0.08042818 Validation Decoder Loss:  0.3510912
Encoder Loss:  0.06527658  || Decoder Loss:  0.08035166 Validation Decoder Loss:  0.35094512
Encoder Loss:  0.065239094  || Decoder Loss:  0.08027526 Validation Decoder Loss:  0.3507836
Encoder Loss:  0.06522737  || Decoder Loss:  0.080250174 Validation Decoder Loss:  0.3508674
Encoder Loss:  0.06521919  || Decoder Loss:  0.08022744 Validation Decoder Loss:  0.35063803
Encoder Loss:  0.065196164  || Decoder Loss:  0.08018684 Validation Decoder Loss:  0.35050714
Encoder Loss:  0.06517181  || Decoder Loss:  0.08014338 Validation Decoder Loss:  0.35033455
Encoder Loss:  0.06513342  || Decoder Loss:  0.080069095 Validation Decoder Loss:  0.35016653
Encoder Loss:  0.065095626  || Decoder Loss:  0.07999457 Validation Decoder Loss:  0.35004014
Model: siamese_net_lr_0.02488178117241809 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35004014
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 140, 5, 20, 1)     78        
_________________________________________________________________
dropout_276 (Dropout)        (None, 140, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 634, 5, 20, 1)     357       
_________________________________________________________________
reshape_107 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 435
Trainable params: 435
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 3190, 20, 1)       57        
_________________________________________________________________
dropout_278 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 3170, 20, 1)       22        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_280 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3120104  || Decoder Loss:  0.30192563 Validation Decoder Loss:  0.7523289
Encoder Loss:  0.19490904  || Decoder Loss:  0.5056904 Validation Decoder Loss:  1.0373981
Encoder Loss:  0.17167945  || Decoder Loss:  0.4980974 Validation Decoder Loss:  1.077656
Encoder Loss:  0.17216925  || Decoder Loss:  0.49940386 Validation Decoder Loss:  1.0555737
Encoder Loss:  0.17162518  || Decoder Loss:  0.4969106 Validation Decoder Loss:  1.058362
Encoder Loss:  0.17017855  || Decoder Loss:  0.4917056 Validation Decoder Loss:  0.9284607
Encoder Loss:  0.17257784  || Decoder Loss:  0.5014227 Validation Decoder Loss:  0.9079834
Encoder Loss:  0.17164734  || Decoder Loss:  0.4980159 Validation Decoder Loss:  0.9046358
Encoder Loss:  0.17346402  || Decoder Loss:  0.49671975 Validation Decoder Loss:  0.9057656
Encoder Loss:  0.17093724  || Decoder Loss:  0.5002958 Validation Decoder Loss:  0.9298427
Encoder Loss:  0.17117962  || Decoder Loss:  0.49862635 Validation Decoder Loss:  0.9158962
Encoder Loss:  0.17139667  || Decoder Loss:  0.499837 Validation Decoder Loss:  0.90609384
Encoder Loss:  0.17093149  || Decoder Loss:  0.49808753 Validation Decoder Loss:  0.95286727
Encoder Loss:  0.17451897  || Decoder Loss:  0.500727 Validation Decoder Loss:  0.89195156
Encoder Loss:  0.17249577  || Decoder Loss:  0.50007063 Validation Decoder Loss:  0.94591415
Encoder Loss:  0.17246895  || Decoder Loss:  0.50002825 Validation Decoder Loss:  0.9048069
Encoder Loss:  0.1713936  || Decoder Loss:  0.49956864 Validation Decoder Loss:  0.9197085
Encoder Loss:  0.17132598  || Decoder Loss:  0.49792916 Validation Decoder Loss:  0.86388457
Encoder Loss:  0.17004204  || Decoder Loss:  0.49726132 Validation Decoder Loss:  0.9111686
Encoder Loss:  0.17185086  || Decoder Loss:  0.5005891 Validation Decoder Loss:  0.88102645
Encoder Loss:  0.16994202  || Decoder Loss:  0.49858096 Validation Decoder Loss:  0.90496576
Encoder Loss:  0.17111069  || Decoder Loss:  0.4992204 Validation Decoder Loss:  0.94675064
Encoder Loss:  0.17099  || Decoder Loss:  0.49800813 Validation Decoder Loss:  1.1137127
Encoder Loss:  0.1692875  || Decoder Loss:  0.49783233 Validation Decoder Loss:  1.0594242
Encoder Loss:  0.16930473  || Decoder Loss:  0.49518883 Validation Decoder Loss:  0.9705677
Encoder Loss:  0.16888835  || Decoder Loss:  0.4953789 Validation Decoder Loss:  0.92251086
Encoder Loss:  0.16837542  || Decoder Loss:  0.49497086 Validation Decoder Loss:  0.995765
Encoder Loss:  0.16938119  || Decoder Loss:  0.4954165 Validation Decoder Loss:  0.98369277
Encoder Loss:  0.16973133  || Decoder Loss:  0.49517745 Validation Decoder Loss:  0.9763558
Encoder Loss:  0.17203434  || Decoder Loss:  0.49757737 Validation Decoder Loss:  0.9713895
Encoder Loss:  0.16968563  || Decoder Loss:  0.49528542 Validation Decoder Loss:  1.0341033
Encoder Loss:  0.16870682  || Decoder Loss:  0.4949086 Validation Decoder Loss:  0.9827051
Encoder Loss:  0.16900335  || Decoder Loss:  0.49460107 Validation Decoder Loss:  0.9953048
Encoder Loss:  0.1690261  || Decoder Loss:  0.49482682 Validation Decoder Loss:  0.95396125
Encoder Loss:  0.16966018  || Decoder Loss:  0.49448708 Validation Decoder Loss:  0.8858012
Encoder Loss:  0.16919063  || Decoder Loss:  0.49456543 Validation Decoder Loss:  1.0564462
Encoder Loss:  0.17100783  || Decoder Loss:  0.4972188 Validation Decoder Loss:  1.0974566
Encoder Loss:  0.16900837  || Decoder Loss:  0.49408433 Validation Decoder Loss:  0.97524923
Encoder Loss:  0.16977054  || Decoder Loss:  0.49487486 Validation Decoder Loss:  1.0030752
Encoder Loss:  0.16898823  || Decoder Loss:  0.49437279 Validation Decoder Loss:  1.0688095
Model: siamese_net_lr_0.07579670900968268 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0688095
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_282 (Dropout)        (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 634, 5, 20, 1)     270       
_________________________________________________________________
reshape_108 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 282
Trainable params: 282
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_328"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_284 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 3240, 20, 1)       72        
_________________________________________________________________
dropout_286 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 3245, 20, 1)       7         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.105795056  || Decoder Loss:  0.06864857 Validation Decoder Loss:  0.3342713
Encoder Loss:  0.26045585  || Decoder Loss:  0.036324497 Validation Decoder Loss:  0.33152506
Encoder Loss:  0.31455958  || Decoder Loss:  0.049412217 Validation Decoder Loss:  0.3504457
Encoder Loss:  0.0772512  || Decoder Loss:  0.040247172 Validation Decoder Loss:  0.33137697
Encoder Loss:  0.054829925  || Decoder Loss:  0.034044754 Validation Decoder Loss:  0.34825158
Encoder Loss:  0.05013965  || Decoder Loss:  0.03377688 Validation Decoder Loss:  0.34745848
Encoder Loss:  0.049681373  || Decoder Loss:  0.033682995 Validation Decoder Loss:  0.3472575
Encoder Loss:  0.049477708  || Decoder Loss:  0.033661533 Validation Decoder Loss:  0.34713078
Encoder Loss:  0.049386982  || Decoder Loss:  0.033648733 Validation Decoder Loss:  0.34709558
Encoder Loss:  0.049377743  || Decoder Loss:  0.033643927 Validation Decoder Loss:  0.34710634
Encoder Loss:  0.049373053  || Decoder Loss:  0.033640124 Validation Decoder Loss:  0.34710264
Encoder Loss:  0.0493593  || Decoder Loss:  0.033635512 Validation Decoder Loss:  0.3471454
Encoder Loss:  0.049347635  || Decoder Loss:  0.03362923 Validation Decoder Loss:  0.3472457
Encoder Loss:  0.049369436  || Decoder Loss:  0.033621233 Validation Decoder Loss:  0.34721717
Encoder Loss:  0.049364742  || Decoder Loss:  0.033617765 Validation Decoder Loss:  0.3472743
Encoder Loss:  0.04934594  || Decoder Loss:  0.033614077 Validation Decoder Loss:  0.3472884
Encoder Loss:  0.049327545  || Decoder Loss:  0.03361044 Validation Decoder Loss:  0.34728923
Encoder Loss:  0.049355436  || Decoder Loss:  0.03360615 Validation Decoder Loss:  0.3472899
Encoder Loss:  0.049338803  || Decoder Loss:  0.033603087 Validation Decoder Loss:  0.34730333
Encoder Loss:  0.049333517  || Decoder Loss:  0.033598855 Validation Decoder Loss:  0.3472795
Encoder Loss:  0.049320884  || Decoder Loss:  0.033593036 Validation Decoder Loss:  0.34723845
Encoder Loss:  0.049304865  || Decoder Loss:  0.03358371 Validation Decoder Loss:  0.34714383
Encoder Loss:  0.049319126  || Decoder Loss:  0.033566616 Validation Decoder Loss:  0.3469248
Encoder Loss:  0.049297094  || Decoder Loss:  0.033564046 Validation Decoder Loss:  0.3469488
Encoder Loss:  0.049318112  || Decoder Loss:  0.033585563 Validation Decoder Loss:  0.34760725
Encoder Loss:  0.06308467  || Decoder Loss:  0.30739802 Validation Decoder Loss:  1.006345
Encoder Loss:  0.072797395  || Decoder Loss:  0.5006314 Validation Decoder Loss:  1.004472
Encoder Loss:  0.072683506  || Decoder Loss:  0.498461 Validation Decoder Loss:  1.0013956
Encoder Loss:  0.07256898  || Decoder Loss:  0.49596858 Validation Decoder Loss:  0.9981282
Encoder Loss:  0.072396085  || Decoder Loss:  0.4933474 Validation Decoder Loss:  0.9946145
Encoder Loss:  0.07224403  || Decoder Loss:  0.4904081 Validation Decoder Loss:  0.99046624
Encoder Loss:  0.07206017  || Decoder Loss:  0.48684376 Validation Decoder Loss:  0.9851489
Encoder Loss:  0.0718227  || Decoder Loss:  0.48208663 Validation Decoder Loss:  0.97749585
Encoder Loss:  0.07143836  || Decoder Loss:  0.474479 Validation Decoder Loss:  0.9632131
Encoder Loss:  0.0704653  || Decoder Loss:  0.45527428 Validation Decoder Loss:  0.9054446
Encoder Loss:  0.06664118  || Decoder Loss:  0.37837878 Validation Decoder Loss:  0.79226303
Encoder Loss:  0.065617785  || Decoder Loss:  0.35893685 Validation Decoder Loss:  0.7879114
Encoder Loss:  0.0655058  || Decoder Loss:  0.3567006 Validation Decoder Loss:  0.78542304
Encoder Loss:  0.065473855  || Decoder Loss:  0.3550201 Validation Decoder Loss:  0.7843883
Encoder Loss:  0.06531161  || Decoder Loss:  0.35283175 Validation Decoder Loss:  0.7787012
Model: siamese_net_lr_0.038266118007226825 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7787012
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_288 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 634, 5, 20, 1)     303       
_________________________________________________________________
reshape_109 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 325
Trainable params: 325
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_290 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_292 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051852413  || Decoder Loss:  0.05156049 Validation Decoder Loss:  0.34463394
Encoder Loss:  0.03262698  || Decoder Loss:  0.03249226 Validation Decoder Loss:  0.33357495
Encoder Loss:  0.03221021  || Decoder Loss:  0.03210109 Validation Decoder Loss:  0.33756694
Encoder Loss:  0.032128796  || Decoder Loss:  0.032024737 Validation Decoder Loss:  0.33773702
Encoder Loss:  0.032098595  || Decoder Loss:  0.03199477 Validation Decoder Loss:  0.33766264
Encoder Loss:  0.032077633  || Decoder Loss:  0.031973783 Validation Decoder Loss:  0.33761862
Encoder Loss:  0.032060966  || Decoder Loss:  0.031957068 Validation Decoder Loss:  0.33759883
Encoder Loss:  0.032046333  || Decoder Loss:  0.031942397 Validation Decoder Loss:  0.3375867
Encoder Loss:  0.032032847  || Decoder Loss:  0.03192886 Validation Decoder Loss:  0.33758086
Encoder Loss:  0.032019876  || Decoder Loss:  0.031915855 Validation Decoder Loss:  0.33758378
Encoder Loss:  0.032007035  || Decoder Loss:  0.031902965 Validation Decoder Loss:  0.33759552
Encoder Loss:  0.031994086  || Decoder Loss:  0.031889983 Validation Decoder Loss:  0.33761537
Encoder Loss:  0.031980935  || Decoder Loss:  0.03187679 Validation Decoder Loss:  0.3376379
Encoder Loss:  0.031967416  || Decoder Loss:  0.03186323 Validation Decoder Loss:  0.3376636
Encoder Loss:  0.031953506  || Decoder Loss:  0.03184928 Validation Decoder Loss:  0.3376925
Encoder Loss:  0.031939235  || Decoder Loss:  0.031834953 Validation Decoder Loss:  0.3377277
Encoder Loss:  0.03192459  || Decoder Loss:  0.03182026 Validation Decoder Loss:  0.33776742
Encoder Loss:  0.031909715  || Decoder Loss:  0.031805348 Validation Decoder Loss:  0.33780903
Encoder Loss:  0.031894773  || Decoder Loss:  0.031790398 Validation Decoder Loss:  0.33785543
Encoder Loss:  0.031880092  || Decoder Loss:  0.031775642 Validation Decoder Loss:  0.33790165
Encoder Loss:  0.031865623  || Decoder Loss:  0.031761166 Validation Decoder Loss:  0.33794826
Encoder Loss:  0.031851873  || Decoder Loss:  0.031747296 Validation Decoder Loss:  0.33799165
Encoder Loss:  0.03183893  || Decoder Loss:  0.031734366 Validation Decoder Loss:  0.33802792
Encoder Loss:  0.031827096  || Decoder Loss:  0.03172246 Validation Decoder Loss:  0.33806628
Encoder Loss:  0.03181648  || Decoder Loss:  0.031711806 Validation Decoder Loss:  0.33810365
Encoder Loss:  0.03180711  || Decoder Loss:  0.031702448 Validation Decoder Loss:  0.3381397
Encoder Loss:  0.031799108  || Decoder Loss:  0.031694397 Validation Decoder Loss:  0.33817774
Encoder Loss:  0.031792227  || Decoder Loss:  0.031687547 Validation Decoder Loss:  0.33820555
Encoder Loss:  0.031786717  || Decoder Loss:  0.03168196 Validation Decoder Loss:  0.33823222
Encoder Loss:  0.031782012  || Decoder Loss:  0.031677287 Validation Decoder Loss:  0.33825728
Encoder Loss:  0.031778105  || Decoder Loss:  0.03167341 Validation Decoder Loss:  0.33828184
Encoder Loss:  0.031774994  || Decoder Loss:  0.031670272 Validation Decoder Loss:  0.33830163
Encoder Loss:  0.031772353  || Decoder Loss:  0.03166754 Validation Decoder Loss:  0.33832023
Encoder Loss:  0.03176993  || Decoder Loss:  0.031665217 Validation Decoder Loss:  0.33832705
Encoder Loss:  0.031768  || Decoder Loss:  0.03166317 Validation Decoder Loss:  0.33833504
Encoder Loss:  0.031765968  || Decoder Loss:  0.03166127 Validation Decoder Loss:  0.33834273
Encoder Loss:  0.03176457  || Decoder Loss:  0.031659625 Validation Decoder Loss:  0.33834755
Encoder Loss:  0.031762965  || Decoder Loss:  0.03165807 Validation Decoder Loss:  0.33835995
Encoder Loss:  0.03176132  || Decoder Loss:  0.031656552 Validation Decoder Loss:  0.33834457
Encoder Loss:  0.031760197  || Decoder Loss:  0.03165527 Validation Decoder Loss:  0.33833003
Model: siamese_net_lr_0.006190787407184609 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33833003
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 258, 5, 20, 1)     196       
_________________________________________________________________
dropout_294 (Dropout)        (None, 258, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 634, 5, 20, 1)     378       
_________________________________________________________________
reshape_110 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_296 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_298 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.7291571  || Decoder Loss:  0.8706417 Validation Decoder Loss:  1.5793278
Encoder Loss:  0.66024226  || Decoder Loss:  0.7998537 Validation Decoder Loss:  1.32768
Encoder Loss:  0.3905719  || Decoder Loss:  0.5061344 Validation Decoder Loss:  1.0847526
Encoder Loss:  0.37744164  || Decoder Loss:  0.5014494 Validation Decoder Loss:  1.0110852
Encoder Loss:  0.37611744  || Decoder Loss:  0.4999131 Validation Decoder Loss:  1.0405489
Encoder Loss:  0.37409833  || Decoder Loss:  0.49917343 Validation Decoder Loss:  1.0454566
Encoder Loss:  0.3755396  || Decoder Loss:  0.50048757 Validation Decoder Loss:  1.038327
Encoder Loss:  0.37484497  || Decoder Loss:  0.5005915 Validation Decoder Loss:  1.0260456
Encoder Loss:  0.37523305  || Decoder Loss:  0.50100785 Validation Decoder Loss:  1.0252421
Encoder Loss:  0.3753971  || Decoder Loss:  0.50111246 Validation Decoder Loss:  1.0092487
Encoder Loss:  0.37555614  || Decoder Loss:  0.50107837 Validation Decoder Loss:  0.9889363
Encoder Loss:  0.37467232  || Decoder Loss:  0.50072557 Validation Decoder Loss:  0.9904642
Encoder Loss:  0.37489587  || Decoder Loss:  0.50081474 Validation Decoder Loss:  0.98529387
Encoder Loss:  0.37482843  || Decoder Loss:  0.50035715 Validation Decoder Loss:  0.9736461
Encoder Loss:  0.37438193  || Decoder Loss:  0.5002767 Validation Decoder Loss:  0.9680882
Encoder Loss:  0.3746418  || Decoder Loss:  0.5008538 Validation Decoder Loss:  0.95792234
Encoder Loss:  0.37471646  || Decoder Loss:  0.50092894 Validation Decoder Loss:  0.9566749
Encoder Loss:  0.3741711  || Decoder Loss:  0.49940056 Validation Decoder Loss:  0.9414218
Encoder Loss:  0.3742192  || Decoder Loss:  0.5001517 Validation Decoder Loss:  0.9432852
Encoder Loss:  0.37396836  || Decoder Loss:  0.49973676 Validation Decoder Loss:  0.93902
Encoder Loss:  0.3740548  || Decoder Loss:  0.5000077 Validation Decoder Loss:  0.93565136
Encoder Loss:  0.3739362  || Decoder Loss:  0.4998196 Validation Decoder Loss:  0.9328031
Encoder Loss:  0.37401974  || Decoder Loss:  0.49999043 Validation Decoder Loss:  0.9297261
Encoder Loss:  0.3740571  || Decoder Loss:  0.50004405 Validation Decoder Loss:  0.9272544
Encoder Loss:  0.37402913  || Decoder Loss:  0.5000403 Validation Decoder Loss:  0.9239137
Encoder Loss:  0.3740781  || Decoder Loss:  0.50011945 Validation Decoder Loss:  0.92119074
Encoder Loss:  0.37398076  || Decoder Loss:  0.4999792 Validation Decoder Loss:  0.91793513
Encoder Loss:  0.37395206  || Decoder Loss:  0.500015 Validation Decoder Loss:  0.91597795
Encoder Loss:  0.37406814  || Decoder Loss:  0.50017047 Validation Decoder Loss:  0.9138918
Encoder Loss:  0.3740685  || Decoder Loss:  0.50021416 Validation Decoder Loss:  0.91042185
Encoder Loss:  0.37380204  || Decoder Loss:  0.49981368 Validation Decoder Loss:  0.9085858
Encoder Loss:  0.37396225  || Decoder Loss:  0.50010544 Validation Decoder Loss:  0.9064418
Encoder Loss:  0.37381852  || Decoder Loss:  0.49994007 Validation Decoder Loss:  0.90436596
Encoder Loss:  0.37383953  || Decoder Loss:  0.4999595 Validation Decoder Loss:  0.9024521
Encoder Loss:  0.37359267  || Decoder Loss:  0.49965155 Validation Decoder Loss:  0.90193415
Encoder Loss:  0.37368488  || Decoder Loss:  0.49983826 Validation Decoder Loss:  0.8998952
Encoder Loss:  0.37357178  || Decoder Loss:  0.4995031 Validation Decoder Loss:  0.89894927
Encoder Loss:  0.37353438  || Decoder Loss:  0.49966788 Validation Decoder Loss:  0.8996358
Encoder Loss:  0.37340796  || Decoder Loss:  0.49956855 Validation Decoder Loss:  0.89979804
Encoder Loss:  0.3727565  || Decoder Loss:  0.49871093 Validation Decoder Loss:  0.9859861
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.0812374838551418 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9859861
Started Optimization Process
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_300 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 634, 5, 20, 1)     493       
_________________________________________________________________
reshape_111 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 503
Trainable params: 503
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_340"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_302 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_304 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09974753  || Decoder Loss:  0.073296994 Validation Decoder Loss:  0.4043706
Encoder Loss:  0.07168578  || Decoder Loss:  0.069638625 Validation Decoder Loss:  0.41352707
Encoder Loss:  0.067635685  || Decoder Loss:  0.07280573 Validation Decoder Loss:  0.41772896
Encoder Loss:  0.33964726  || Decoder Loss:  0.6169791 Validation Decoder Loss:  1.5749495
Encoder Loss:  0.49114183  || Decoder Loss:  0.92192477 Validation Decoder Loss:  1.570526
Encoder Loss:  0.4925446  || Decoder Loss:  0.918507 Validation Decoder Loss:  1.5616393
Encoder Loss:  0.49102807  || Decoder Loss:  0.9139228 Validation Decoder Loss:  1.5493245
Encoder Loss:  0.4850757  || Decoder Loss:  0.9077282 Validation Decoder Loss:  1.5364494
Encoder Loss:  0.4640124  || Decoder Loss:  0.8710851 Validation Decoder Loss:  1.5199083
Encoder Loss:  0.4799753  || Decoder Loss:  0.9030211 Validation Decoder Loss:  1.5325003
Encoder Loss:  0.4791318  || Decoder Loss:  0.9023827 Validation Decoder Loss:  1.5300303
Encoder Loss:  0.44572413  || Decoder Loss:  0.8364858 Validation Decoder Loss:  0.36109877
Encoder Loss:  0.07757299  || Decoder Loss:  0.10476069 Validation Decoder Loss:  0.4654707
Encoder Loss:  0.073168986  || Decoder Loss:  0.09602917 Validation Decoder Loss:  0.46441042
Encoder Loss:  0.07205809  || Decoder Loss:  0.09381496 Validation Decoder Loss:  0.45756027
Encoder Loss:  0.14873938  || Decoder Loss:  0.24625279 Validation Decoder Loss:  0.46743774
Encoder Loss:  0.074459136  || Decoder Loss:  0.098592766 Validation Decoder Loss:  0.4675361
Encoder Loss:  0.07447182  || Decoder Loss:  0.098619014 Validation Decoder Loss:  0.46744007
Encoder Loss:  0.07445082  || Decoder Loss:  0.09857757 Validation Decoder Loss:  0.46734115
Encoder Loss:  0.074426234  || Decoder Loss:  0.09852945 Validation Decoder Loss:  0.46723405
Encoder Loss:  0.07440208  || Decoder Loss:  0.098481216 Validation Decoder Loss:  0.4671226
Encoder Loss:  0.074376866  || Decoder Loss:  0.09843172 Validation Decoder Loss:  0.46700272
Encoder Loss:  0.074351504  || Decoder Loss:  0.09838124 Validation Decoder Loss:  0.4668855
Encoder Loss:  0.074325636  || Decoder Loss:  0.09833045 Validation Decoder Loss:  0.46677297
Encoder Loss:  0.074300714  || Decoder Loss:  0.09828049 Validation Decoder Loss:  0.46666086
Encoder Loss:  0.074276574  || Decoder Loss:  0.09823165 Validation Decoder Loss:  0.46653873
Encoder Loss:  0.07425202  || Decoder Loss:  0.09818169 Validation Decoder Loss:  0.46636
Encoder Loss:  0.07422691  || Decoder Loss:  0.09814115 Validation Decoder Loss:  0.466264
Encoder Loss:  0.07419949  || Decoder Loss:  0.09808691 Validation Decoder Loss:  0.46614105
Encoder Loss:  0.07417116  || Decoder Loss:  0.09802976 Validation Decoder Loss:  0.46599025
Encoder Loss:  0.07414916  || Decoder Loss:  0.09798513 Validation Decoder Loss:  0.46593964
Encoder Loss:  0.07413023  || Decoder Loss:  0.097934686 Validation Decoder Loss:  0.46572807
Encoder Loss:  0.07416102  || Decoder Loss:  0.09795304 Validation Decoder Loss:  0.46612984
Encoder Loss:  0.074167386  || Decoder Loss:  0.09798564 Validation Decoder Loss:  0.4659152
Encoder Loss:  0.07414746  || Decoder Loss:  0.09797313 Validation Decoder Loss:  0.4658779
Encoder Loss:  0.07422395  || Decoder Loss:  0.09801661 Validation Decoder Loss:  0.46608454
Encoder Loss:  0.074175216  || Decoder Loss:  0.098010905 Validation Decoder Loss:  0.46604598
Encoder Loss:  0.074184634  || Decoder Loss:  0.09804739 Validation Decoder Loss:  0.4659258
Encoder Loss:  0.074291214  || Decoder Loss:  0.098148644 Validation Decoder Loss:  0.46635836
Encoder Loss:  0.07434685  || Decoder Loss:  0.09827422 Validation Decoder Loss:  0.46655738
Model: siamese_net_lr_0.024881784624266243 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.46655738
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_306 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 634, 5, 20, 1)     552       
_________________________________________________________________
reshape_112 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_344"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_308 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_310 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051406983  || Decoder Loss:  0.051406983 Validation Decoder Loss:  0.34393144
Encoder Loss:  0.03216231  || Decoder Loss:  0.03216231 Validation Decoder Loss:  0.34313762
Encoder Loss:  0.032076634  || Decoder Loss:  0.032076634 Validation Decoder Loss:  0.3428649
Encoder Loss:  0.032008663  || Decoder Loss:  0.032008663 Validation Decoder Loss:  0.34299916
Encoder Loss:  0.031956792  || Decoder Loss:  0.031956792 Validation Decoder Loss:  0.34320018
Encoder Loss:  0.031916782  || Decoder Loss:  0.031916782 Validation Decoder Loss:  0.34326404
Encoder Loss:  0.03188352  || Decoder Loss:  0.03188352 Validation Decoder Loss:  0.34327814
Encoder Loss:  0.031855028  || Decoder Loss:  0.031855028 Validation Decoder Loss:  0.34330267
Encoder Loss:  0.031830184  || Decoder Loss:  0.031830184 Validation Decoder Loss:  0.34333003
Encoder Loss:  0.031808104  || Decoder Loss:  0.031808104 Validation Decoder Loss:  0.34335715
Encoder Loss:  0.031788167  || Decoder Loss:  0.031788167 Validation Decoder Loss:  0.34338403
Encoder Loss:  0.031769928  || Decoder Loss:  0.031769928 Validation Decoder Loss:  0.34341058
Encoder Loss:  0.03175307  || Decoder Loss:  0.03175307 Validation Decoder Loss:  0.34343663
Encoder Loss:  0.03173741  || Decoder Loss:  0.03173741 Validation Decoder Loss:  0.3434621
Encoder Loss:  0.03172277  || Decoder Loss:  0.03172277 Validation Decoder Loss:  0.34348705
Encoder Loss:  0.031709082  || Decoder Loss:  0.031709082 Validation Decoder Loss:  0.34351125
Encoder Loss:  0.031696294  || Decoder Loss:  0.031696294 Validation Decoder Loss:  0.34353432
Encoder Loss:  0.03168437  || Decoder Loss:  0.03168437 Validation Decoder Loss:  0.34355605
Encoder Loss:  0.031673282  || Decoder Loss:  0.031673282 Validation Decoder Loss:  0.34357625
Encoder Loss:  0.031663023  || Decoder Loss:  0.031663023 Validation Decoder Loss:  0.34359536
Encoder Loss:  0.031653527  || Decoder Loss:  0.031653527 Validation Decoder Loss:  0.34361404
Encoder Loss:  0.031644724  || Decoder Loss:  0.031644724 Validation Decoder Loss:  0.34363312
Encoder Loss:  0.031636566  || Decoder Loss:  0.031636566 Validation Decoder Loss:  0.3436529
Encoder Loss:  0.031628996  || Decoder Loss:  0.031628996 Validation Decoder Loss:  0.34367332
Encoder Loss:  0.03162201  || Decoder Loss:  0.03162201 Validation Decoder Loss:  0.3436939
Encoder Loss:  0.03161558  || Decoder Loss:  0.03161558 Validation Decoder Loss:  0.34371412
Encoder Loss:  0.03160968  || Decoder Loss:  0.03160968 Validation Decoder Loss:  0.3437338
Encoder Loss:  0.031604256  || Decoder Loss:  0.031604256 Validation Decoder Loss:  0.34375286
Encoder Loss:  0.031599272  || Decoder Loss:  0.031599272 Validation Decoder Loss:  0.34377146
Encoder Loss:  0.031594664  || Decoder Loss:  0.031594664 Validation Decoder Loss:  0.34378934
Encoder Loss:  0.03159041  || Decoder Loss:  0.03159041 Validation Decoder Loss:  0.34380633
Encoder Loss:  0.031586472  || Decoder Loss:  0.031586472 Validation Decoder Loss:  0.34382206
Encoder Loss:  0.031582817  || Decoder Loss:  0.031582817 Validation Decoder Loss:  0.3438365
Encoder Loss:  0.031579405  || Decoder Loss:  0.031579405 Validation Decoder Loss:  0.34384954
Encoder Loss:  0.03157623  || Decoder Loss:  0.03157623 Validation Decoder Loss:  0.34386134
Encoder Loss:  0.031573266  || Decoder Loss:  0.031573266 Validation Decoder Loss:  0.34387177
Encoder Loss:  0.03157049  || Decoder Loss:  0.03157049 Validation Decoder Loss:  0.3438811
Encoder Loss:  0.031567886  || Decoder Loss:  0.031567886 Validation Decoder Loss:  0.34388915
Encoder Loss:  0.031565443  || Decoder Loss:  0.031565443 Validation Decoder Loss:  0.34389603
Encoder Loss:  0.031563137  || Decoder Loss:  0.031563137 Validation Decoder Loss:  0.34390178
Model: siamese_net_lr_0.005103829945387472 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34390175
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_312 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 634, 5, 20, 1)     54        
_________________________________________________________________
reshape_113 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_314 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_316 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.065103345  || Decoder Loss:  0.06508494 Validation Decoder Loss:  0.34529737
Encoder Loss:  0.033245917  || Decoder Loss:  0.033215865 Validation Decoder Loss:  0.34491798
Encoder Loss:  0.032855973  || Decoder Loss:  0.03283113 Validation Decoder Loss:  0.34482124
Encoder Loss:  0.032674283  || Decoder Loss:  0.032650102 Validation Decoder Loss:  0.34455103
Encoder Loss:  0.03256513  || Decoder Loss:  0.032540828 Validation Decoder Loss:  0.34443802
Encoder Loss:  0.03249584  || Decoder Loss:  0.03247149 Validation Decoder Loss:  0.34440628
Encoder Loss:  0.032455985  || Decoder Loss:  0.032431632 Validation Decoder Loss:  0.34433755
Encoder Loss:  0.032405093  || Decoder Loss:  0.032380678 Validation Decoder Loss:  0.3442956
Encoder Loss:  0.032373372  || Decoder Loss:  0.03234892 Validation Decoder Loss:  0.34425393
Encoder Loss:  0.032340594  || Decoder Loss:  0.032316145 Validation Decoder Loss:  0.34422353
Encoder Loss:  0.03231266  || Decoder Loss:  0.032288156 Validation Decoder Loss:  0.34421194
Encoder Loss:  0.032291695  || Decoder Loss:  0.03226718 Validation Decoder Loss:  0.34419414
Encoder Loss:  0.0322651  || Decoder Loss:  0.032240592 Validation Decoder Loss:  0.34417558
Encoder Loss:  0.032242723  || Decoder Loss:  0.03221814 Validation Decoder Loss:  0.34417903
Encoder Loss:  0.032220777  || Decoder Loss:  0.032196186 Validation Decoder Loss:  0.34416223
Encoder Loss:  0.032197658  || Decoder Loss:  0.032173082 Validation Decoder Loss:  0.34416765
Encoder Loss:  0.03217835  || Decoder Loss:  0.032153744 Validation Decoder Loss:  0.3441676
Encoder Loss:  0.032155447  || Decoder Loss:  0.032130834 Validation Decoder Loss:  0.3441674
Encoder Loss:  0.032133263  || Decoder Loss:  0.032108635 Validation Decoder Loss:  0.34417757
Encoder Loss:  0.03211176  || Decoder Loss:  0.032087106 Validation Decoder Loss:  0.34418744
Encoder Loss:  0.03208921  || Decoder Loss:  0.032064546 Validation Decoder Loss:  0.3442049
Encoder Loss:  0.032066002  || Decoder Loss:  0.032041308 Validation Decoder Loss:  0.3442207
Encoder Loss:  0.03204253  || Decoder Loss:  0.032017827 Validation Decoder Loss:  0.34425026
Encoder Loss:  0.032019317  || Decoder Loss:  0.031994592 Validation Decoder Loss:  0.34427708
Encoder Loss:  0.03199552  || Decoder Loss:  0.03197077 Validation Decoder Loss:  0.34430754
Encoder Loss:  0.031970706  || Decoder Loss:  0.031945944 Validation Decoder Loss:  0.34435093
Encoder Loss:  0.03194851  || Decoder Loss:  0.03192374 Validation Decoder Loss:  0.34439498
Encoder Loss:  0.03192513  || Decoder Loss:  0.031900316 Validation Decoder Loss:  0.34443521
Encoder Loss:  0.031899355  || Decoder Loss:  0.031874496 Validation Decoder Loss:  0.34447348
Encoder Loss:  0.031877022  || Decoder Loss:  0.03185214 Validation Decoder Loss:  0.34452564
Encoder Loss:  0.03185763  || Decoder Loss:  0.031832732 Validation Decoder Loss:  0.34456336
Encoder Loss:  0.031839196  || Decoder Loss:  0.031814273 Validation Decoder Loss:  0.34460256
Encoder Loss:  0.0318224  || Decoder Loss:  0.031797457 Validation Decoder Loss:  0.34462222
Encoder Loss:  0.031806234  || Decoder Loss:  0.031781267 Validation Decoder Loss:  0.34464663
Encoder Loss:  0.031792708  || Decoder Loss:  0.031767722 Validation Decoder Loss:  0.34465706
Encoder Loss:  0.03177808  || Decoder Loss:  0.03175308 Validation Decoder Loss:  0.3446554
Encoder Loss:  0.031766336  || Decoder Loss:  0.031741325 Validation Decoder Loss:  0.34466767
Encoder Loss:  0.031756703  || Decoder Loss:  0.03173169 Validation Decoder Loss:  0.3446667
Encoder Loss:  0.031746257  || Decoder Loss:  0.031721238 Validation Decoder Loss:  0.34466195
Encoder Loss:  0.03173645  || Decoder Loss:  0.031711414 Validation Decoder Loss:  0.34465995
Model: siamese_net_lr_0.005693858864500191 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34465998
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_318 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 634, 5, 20, 1)     67        
_________________________________________________________________
reshape_114 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 77
Trainable params: 77
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_352"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_320 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_322 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.111213416  || Decoder Loss:  0.07560112 Validation Decoder Loss:  0.34538972
Encoder Loss:  0.054991826  || Decoder Loss:  0.035414826 Validation Decoder Loss:  0.34434667
Encoder Loss:  0.053227324  || Decoder Loss:  0.032722816 Validation Decoder Loss:  0.33992374
Encoder Loss:  0.05324248  || Decoder Loss:  0.032490455 Validation Decoder Loss:  0.34036773
Encoder Loss:  0.053159133  || Decoder Loss:  0.032441836 Validation Decoder Loss:  0.3402793
Encoder Loss:  0.053135205  || Decoder Loss:  0.032448497 Validation Decoder Loss:  0.34007326
Encoder Loss:  0.05217936  || Decoder Loss:  0.03270085 Validation Decoder Loss:  0.34010768
Encoder Loss:  0.052714653  || Decoder Loss:  0.032776114 Validation Decoder Loss:  0.33978033
Encoder Loss:  0.052887898  || Decoder Loss:  0.032395747 Validation Decoder Loss:  0.33947492
Encoder Loss:  0.052281845  || Decoder Loss:  0.032368943 Validation Decoder Loss:  0.33932936
Encoder Loss:  0.05176722  || Decoder Loss:  0.032449253 Validation Decoder Loss:  0.33876032
Encoder Loss:  0.050270952  || Decoder Loss:  0.032372724 Validation Decoder Loss:  0.33868423
Encoder Loss:  0.053183995  || Decoder Loss:  0.03238183 Validation Decoder Loss:  0.3384475
Encoder Loss:  0.051798023  || Decoder Loss:  0.032363545 Validation Decoder Loss:  0.3381515
Encoder Loss:  0.053331126  || Decoder Loss:  0.032322947 Validation Decoder Loss:  0.33876935
Encoder Loss:  0.05434426  || Decoder Loss:  0.032415356 Validation Decoder Loss:  0.33771944
Encoder Loss:  0.054039456  || Decoder Loss:  0.032361675 Validation Decoder Loss:  0.3376884
Encoder Loss:  0.05135281  || Decoder Loss:  0.03231188 Validation Decoder Loss:  0.33774802
Encoder Loss:  0.05666647  || Decoder Loss:  0.032297242 Validation Decoder Loss:  0.33776456
Encoder Loss:  0.0524978  || Decoder Loss:  0.03238603 Validation Decoder Loss:  0.3379643
Encoder Loss:  0.052827615  || Decoder Loss:  0.03232302 Validation Decoder Loss:  0.33792585
Encoder Loss:  0.053073134  || Decoder Loss:  0.032327343 Validation Decoder Loss:  0.33829832
Encoder Loss:  0.050474577  || Decoder Loss:  0.032326493 Validation Decoder Loss:  0.33824003
Encoder Loss:  0.052816257  || Decoder Loss:  0.032307718 Validation Decoder Loss:  0.33767492
Encoder Loss:  0.053045556  || Decoder Loss:  0.032327615 Validation Decoder Loss:  0.33785787
Encoder Loss:  0.051984083  || Decoder Loss:  0.032317 Validation Decoder Loss:  0.33805144
Encoder Loss:  0.056978963  || Decoder Loss:  0.032475132 Validation Decoder Loss:  0.3344006
Encoder Loss:  0.056141872  || Decoder Loss:  0.032466453 Validation Decoder Loss:  0.33794332
Encoder Loss:  0.055871263  || Decoder Loss:  0.032384925 Validation Decoder Loss:  0.33899587
Encoder Loss:  0.055584595  || Decoder Loss:  0.032536656 Validation Decoder Loss:  0.33961576
Encoder Loss:  0.05533484  || Decoder Loss:  0.03271632 Validation Decoder Loss:  0.34391063
Encoder Loss:  0.055099875  || Decoder Loss:  0.032655865 Validation Decoder Loss:  0.34536523
Encoder Loss:  0.054879524  || Decoder Loss:  0.032435834 Validation Decoder Loss:  0.34161764
Encoder Loss:  0.054691624  || Decoder Loss:  0.03237247 Validation Decoder Loss:  0.34162918
Encoder Loss:  0.054524973  || Decoder Loss:  0.03235832 Validation Decoder Loss:  0.34066883
Encoder Loss:  0.054374576  || Decoder Loss:  0.032359272 Validation Decoder Loss:  0.34034395
Encoder Loss:  0.05414959  || Decoder Loss:  0.032376513 Validation Decoder Loss:  0.34086728
Encoder Loss:  0.0526881  || Decoder Loss:  0.03240881 Validation Decoder Loss:  0.33609262
Encoder Loss:  0.049994845  || Decoder Loss:  0.032420717 Validation Decoder Loss:  0.3421403
Encoder Loss:  0.052596685  || Decoder Loss:  0.03241194 Validation Decoder Loss:  0.33470947
Model: siamese_net_lr_0.0970214041033728 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33470947
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_324 (Dropout)        (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 634, 5, 20, 1)     562       
_________________________________________________________________
reshape_115 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_326 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_328 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.6211272  || Decoder Loss:  0.91131234 Validation Decoder Loss:  1.4297031
Encoder Loss:  0.26678088  || Decoder Loss:  0.22054228 Validation Decoder Loss:  0.7995356
Encoder Loss:  0.26235783  || Decoder Loss:  0.4921991 Validation Decoder Loss:  0.95364404
Encoder Loss:  0.244005  || Decoder Loss:  0.48463812 Validation Decoder Loss:  1.0004592
Encoder Loss:  0.24694721  || Decoder Loss:  0.49869308 Validation Decoder Loss:  1.0022987
Encoder Loss:  0.24653769  || Decoder Loss:  0.4977377 Validation Decoder Loss:  1.0015438
Encoder Loss:  0.24642047  || Decoder Loss:  0.49784452 Validation Decoder Loss:  1.0085459
Encoder Loss:  0.24619144  || Decoder Loss:  0.49774182 Validation Decoder Loss:  1.0112197
Encoder Loss:  0.2460624  || Decoder Loss:  0.4967168 Validation Decoder Loss:  1.0501051
Encoder Loss:  0.24784526  || Decoder Loss:  0.50033957 Validation Decoder Loss:  1.0182049
Encoder Loss:  0.24705142  || Decoder Loss:  0.49854934 Validation Decoder Loss:  1.0115752
Encoder Loss:  0.2461178  || Decoder Loss:  0.49698704 Validation Decoder Loss:  1.0097351
Encoder Loss:  0.24601589  || Decoder Loss:  0.49647877 Validation Decoder Loss:  1.0245206
Encoder Loss:  0.24799338  || Decoder Loss:  0.5003062 Validation Decoder Loss:  1.0156674
Encoder Loss:  0.24618955  || Decoder Loss:  0.49727738 Validation Decoder Loss:  1.0270348
Encoder Loss:  0.24620573  || Decoder Loss:  0.49762332 Validation Decoder Loss:  1.0297606
Encoder Loss:  0.24610117  || Decoder Loss:  0.4967977 Validation Decoder Loss:  1.0958741
Encoder Loss:  0.24626489  || Decoder Loss:  0.4972124 Validation Decoder Loss:  1.0381405
Encoder Loss:  0.24611825  || Decoder Loss:  0.49687347 Validation Decoder Loss:  1.0339363
Encoder Loss:  0.24605538  || Decoder Loss:  0.49720597 Validation Decoder Loss:  1.0488502
Encoder Loss:  0.24578175  || Decoder Loss:  0.4966928 Validation Decoder Loss:  1.1043857
Encoder Loss:  0.2457844  || Decoder Loss:  0.4964282 Validation Decoder Loss:  1.093359
Encoder Loss:  0.2454881  || Decoder Loss:  0.49601096 Validation Decoder Loss:  1.0827527
Encoder Loss:  0.24540322  || Decoder Loss:  0.49579644 Validation Decoder Loss:  1.0818497
Encoder Loss:  0.2452144  || Decoder Loss:  0.49534807 Validation Decoder Loss:  1.0663258
Encoder Loss:  0.24550375  || Decoder Loss:  0.49581748 Validation Decoder Loss:  1.0637121
Encoder Loss:  0.24733044  || Decoder Loss:  0.50005454 Validation Decoder Loss:  1.0229826
Encoder Loss:  0.2468518  || Decoder Loss:  0.49923456 Validation Decoder Loss:  1.0690591
Encoder Loss:  0.24660397  || Decoder Loss:  0.49868435 Validation Decoder Loss:  1.1190996
Encoder Loss:  0.24633755  || Decoder Loss:  0.49815777 Validation Decoder Loss:  1.0966549
Encoder Loss:  0.24657726  || Decoder Loss:  0.49845436 Validation Decoder Loss:  1.0055726
Encoder Loss:  0.24670139  || Decoder Loss:  0.4988036 Validation Decoder Loss:  1.0873109
Encoder Loss:  0.24655256  || Decoder Loss:  0.49862182 Validation Decoder Loss:  1.0924162
Encoder Loss:  0.24550818  || Decoder Loss:  0.49634933 Validation Decoder Loss:  1.0975275
Encoder Loss:  0.24532664  || Decoder Loss:  0.49590942 Validation Decoder Loss:  1.039992
Encoder Loss:  0.24506864  || Decoder Loss:  0.49533895 Validation Decoder Loss:  1.0130296
Encoder Loss:  0.24471694  || Decoder Loss:  0.49452645 Validation Decoder Loss:  1.0080583
Encoder Loss:  0.24209684  || Decoder Loss:  0.48855904 Validation Decoder Loss:  1.0227305
Encoder Loss:  0.2459184  || Decoder Loss:  0.4971215 Validation Decoder Loss:  0.9841788
Encoder Loss:  0.24771757  || Decoder Loss:  0.50128007 Validation Decoder Loss:  0.963573
Model: siamese_net_lr_0.08418498165925245 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.963573
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_330 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_116 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_332 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_334 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05467755  || Decoder Loss:  0.05429045 Validation Decoder Loss:  0.33116412
Encoder Loss:  0.03311914  || Decoder Loss:  0.032816574 Validation Decoder Loss:  0.33884835
Encoder Loss:  0.03270577  || Decoder Loss:  0.032416485 Validation Decoder Loss:  0.33627898
Encoder Loss:  0.032629382  || Decoder Loss:  0.032343186 Validation Decoder Loss:  0.33675718
Encoder Loss:  0.032583162  || Decoder Loss:  0.032296475 Validation Decoder Loss:  0.33672225
Encoder Loss:  0.032536563  || Decoder Loss:  0.03224927 Validation Decoder Loss:  0.33650094
Encoder Loss:  0.03248822  || Decoder Loss:  0.032200202 Validation Decoder Loss:  0.3363849
Encoder Loss:  0.032437377  || Decoder Loss:  0.032148764 Validation Decoder Loss:  0.33625758
Encoder Loss:  0.032384437  || Decoder Loss:  0.03209505 Validation Decoder Loss:  0.33614108
Encoder Loss:  0.03232972  || Decoder Loss:  0.03203966 Validation Decoder Loss:  0.3360886
Encoder Loss:  0.032274682  || Decoder Loss:  0.031983875 Validation Decoder Loss:  0.336033
Encoder Loss:  0.032221694  || Decoder Loss:  0.031930216 Validation Decoder Loss:  0.33601588
Encoder Loss:  0.03217373  || Decoder Loss:  0.03188166 Validation Decoder Loss:  0.33601424
Encoder Loss:  0.032132197  || Decoder Loss:  0.031839613 Validation Decoder Loss:  0.33595932
Encoder Loss:  0.032095328  || Decoder Loss:  0.03180229 Validation Decoder Loss:  0.33586812
Encoder Loss:  0.03206083  || Decoder Loss:  0.031767417 Validation Decoder Loss:  0.33574075
Encoder Loss:  0.03202845  || Decoder Loss:  0.031734683 Validation Decoder Loss:  0.3355949
Encoder Loss:  0.03199896  || Decoder Loss:  0.031704847 Validation Decoder Loss:  0.33544916
Encoder Loss:  0.03197304  || Decoder Loss:  0.031678695 Validation Decoder Loss:  0.33532816
Encoder Loss:  0.03195115  || Decoder Loss:  0.031656604 Validation Decoder Loss:  0.33522224
Encoder Loss:  0.031933084  || Decoder Loss:  0.03163839 Validation Decoder Loss:  0.33511096
Encoder Loss:  0.031918492  || Decoder Loss:  0.031623732 Validation Decoder Loss:  0.33508426
Encoder Loss:  0.031906098  || Decoder Loss:  0.031611223 Validation Decoder Loss:  0.33490586
Encoder Loss:  0.031895608  || Decoder Loss:  0.03160067 Validation Decoder Loss:  0.33499956
Encoder Loss:  0.031887066  || Decoder Loss:  0.031592052 Validation Decoder Loss:  0.33488747
Encoder Loss:  0.031878456  || Decoder Loss:  0.031583443 Validation Decoder Loss:  0.3348118
Encoder Loss:  0.031870667  || Decoder Loss:  0.031575575 Validation Decoder Loss:  0.3347783
Encoder Loss:  0.031863976  || Decoder Loss:  0.031568836 Validation Decoder Loss:  0.33473086
Encoder Loss:  0.031857572  || Decoder Loss:  0.03156241 Validation Decoder Loss:  0.33470625
Encoder Loss:  0.031851612  || Decoder Loss:  0.031556398 Validation Decoder Loss:  0.3346048
Encoder Loss:  0.031846188  || Decoder Loss:  0.031550895 Validation Decoder Loss:  0.3346684
Encoder Loss:  0.031841043  || Decoder Loss:  0.03154571 Validation Decoder Loss:  0.33445597
Encoder Loss:  0.031836446  || Decoder Loss:  0.031541064 Validation Decoder Loss:  0.33463293
Encoder Loss:  0.031831786  || Decoder Loss:  0.03153634 Validation Decoder Loss:  0.33438465
Encoder Loss:  0.03182762  || Decoder Loss:  0.031532153 Validation Decoder Loss:  0.33456928
Encoder Loss:  0.031823684  || Decoder Loss:  0.03152816 Validation Decoder Loss:  0.33445248
Encoder Loss:  0.03181958  || Decoder Loss:  0.03152401 Validation Decoder Loss:  0.33439827
Encoder Loss:  0.03181601  || Decoder Loss:  0.031520423 Validation Decoder Loss:  0.33444104
Encoder Loss:  0.03181263  || Decoder Loss:  0.031517018 Validation Decoder Loss:  0.3344283
Encoder Loss:  0.031809  || Decoder Loss:  0.031513344 Validation Decoder Loss:  0.33424762
Model: siamese_net_lr_0.0075570632476476855 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33424762
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_336 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 634, 5, 20, 1)     54        
_________________________________________________________________
reshape_117 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_364"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_338 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_340 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07155643  || Decoder Loss:  0.05477148 Validation Decoder Loss:  0.3513582
Encoder Loss:  0.050633807  || Decoder Loss:  0.034974314 Validation Decoder Loss:  0.3575123
Encoder Loss:  0.04342675  || Decoder Loss:  0.03316823 Validation Decoder Loss:  0.3437819
Encoder Loss:  0.04290177  || Decoder Loss:  0.032656983 Validation Decoder Loss:  0.3439716
Encoder Loss:  0.04508109  || Decoder Loss:  0.03262176 Validation Decoder Loss:  0.3446624
Encoder Loss:  0.04234682  || Decoder Loss:  0.032572087 Validation Decoder Loss:  0.3441052
Encoder Loss:  0.041844934  || Decoder Loss:  0.0325429 Validation Decoder Loss:  0.34339935
Encoder Loss:  0.043259434  || Decoder Loss:  0.03255811 Validation Decoder Loss:  0.34496483
Encoder Loss:  0.043788914  || Decoder Loss:  0.032557834 Validation Decoder Loss:  0.34357026
Encoder Loss:  0.04162552  || Decoder Loss:  0.032507 Validation Decoder Loss:  0.34387383
Encoder Loss:  0.04346746  || Decoder Loss:  0.032570962 Validation Decoder Loss:  0.34407246
Encoder Loss:  0.043001972  || Decoder Loss:  0.03268756 Validation Decoder Loss:  0.34093326
Encoder Loss:  0.042145167  || Decoder Loss:  0.032512423 Validation Decoder Loss:  0.34401453
Encoder Loss:  0.042809345  || Decoder Loss:  0.032540053 Validation Decoder Loss:  0.34251377
Encoder Loss:  0.04178541  || Decoder Loss:  0.032433376 Validation Decoder Loss:  0.34358972
Encoder Loss:  0.04134577  || Decoder Loss:  0.03241219 Validation Decoder Loss:  0.34410727
Encoder Loss:  0.041403193  || Decoder Loss:  0.032403577 Validation Decoder Loss:  0.34377077
Encoder Loss:  0.041485056  || Decoder Loss:  0.032392368 Validation Decoder Loss:  0.34336156
Encoder Loss:  0.042255364  || Decoder Loss:  0.032391928 Validation Decoder Loss:  0.34347922
Encoder Loss:  0.04130842  || Decoder Loss:  0.03241783 Validation Decoder Loss:  0.34327608
Encoder Loss:  0.041146208  || Decoder Loss:  0.032373093 Validation Decoder Loss:  0.34427726
Encoder Loss:  0.04220969  || Decoder Loss:  0.032422923 Validation Decoder Loss:  0.34255737
Encoder Loss:  0.04165206  || Decoder Loss:  0.032398745 Validation Decoder Loss:  0.34285244
Encoder Loss:  0.041280273  || Decoder Loss:  0.032376904 Validation Decoder Loss:  0.34238553
Encoder Loss:  0.0406605  || Decoder Loss:  0.03235285 Validation Decoder Loss:  0.34288374
Encoder Loss:  0.0417741  || Decoder Loss:  0.0323727 Validation Decoder Loss:  0.34470755
Encoder Loss:  0.044105407  || Decoder Loss:  0.03319138 Validation Decoder Loss:  0.33728743
Encoder Loss:  0.041195516  || Decoder Loss:  0.032516554 Validation Decoder Loss:  0.3415792
Encoder Loss:  0.04096962  || Decoder Loss:  0.03233394 Validation Decoder Loss:  0.34241182
Encoder Loss:  0.041173793  || Decoder Loss:  0.03232413 Validation Decoder Loss:  0.34342414
Encoder Loss:  0.041754838  || Decoder Loss:  0.032307595 Validation Decoder Loss:  0.34432983
Encoder Loss:  0.042128745  || Decoder Loss:  0.032422382 Validation Decoder Loss:  0.34191352
Encoder Loss:  0.041953392  || Decoder Loss:  0.03232331 Validation Decoder Loss:  0.34497514
Encoder Loss:  0.04089255  || Decoder Loss:  0.032258525 Validation Decoder Loss:  0.34342617
Encoder Loss:  0.04126269  || Decoder Loss:  0.032243114 Validation Decoder Loss:  0.34315705
Encoder Loss:  0.043628875  || Decoder Loss:  0.03280687 Validation Decoder Loss:  0.33898568
Encoder Loss:  0.07808458  || Decoder Loss:  0.09448133 Validation Decoder Loss:  0.37703577
Encoder Loss:  0.064684466  || Decoder Loss:  0.07201311 Validation Decoder Loss:  0.33282527
Encoder Loss:  0.044731975  || Decoder Loss:  0.0391091 Validation Decoder Loss:  0.3368869
Encoder Loss:  0.043354765  || Decoder Loss:  0.03367564 Validation Decoder Loss:  0.3431149
Model: siamese_net_lr_0.021081185896368957 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34311497
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_342 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 634, 5, 20, 1)     303       
_________________________________________________________________
reshape_118 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 325
Trainable params: 325
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_344 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_346 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10276923  || Decoder Loss:  0.092167825 Validation Decoder Loss:  0.3265129
Encoder Loss:  0.11740411  || Decoder Loss:  0.108543575 Validation Decoder Loss:  0.28206635
Encoder Loss:  0.28414395  || Decoder Loss:  0.36830667 Validation Decoder Loss:  0.715352
Encoder Loss:  0.115541175  || Decoder Loss:  0.13931236 Validation Decoder Loss:  0.7030498
Encoder Loss:  0.114233404  || Decoder Loss:  0.13765457 Validation Decoder Loss:  0.7014406
Encoder Loss:  0.11419513  || Decoder Loss:  0.13772194 Validation Decoder Loss:  0.7009923
Encoder Loss:  0.11369856  || Decoder Loss:  0.13704717 Validation Decoder Loss:  0.6988056
Encoder Loss:  0.113257535  || Decoder Loss:  0.13643797 Validation Decoder Loss:  0.69845736
Encoder Loss:  0.11286893  || Decoder Loss:  0.13591196 Validation Decoder Loss:  0.6969402
Encoder Loss:  0.11187103  || Decoder Loss:  0.13455749 Validation Decoder Loss:  0.69214094
Encoder Loss:  0.10967266  || Decoder Loss:  0.13155374 Validation Decoder Loss:  0.6823684
Encoder Loss:  0.10497438  || Decoder Loss:  0.12512356 Validation Decoder Loss:  0.6566159
Encoder Loss:  0.08029362  || Decoder Loss:  0.091376744 Validation Decoder Loss:  0.5866449
Encoder Loss:  0.0545041  || Decoder Loss:  0.056107942 Validation Decoder Loss:  0.37350053
Encoder Loss:  0.039117254  || Decoder Loss:  0.035067853 Validation Decoder Loss:  0.34264427
Encoder Loss:  0.037717007  || Decoder Loss:  0.03315406 Validation Decoder Loss:  0.34757465
Encoder Loss:  0.037555564  || Decoder Loss:  0.032934558 Validation Decoder Loss:  0.3480107
Encoder Loss:  0.037510596  || Decoder Loss:  0.03287407 Validation Decoder Loss:  0.34614757
Encoder Loss:  0.03748237  || Decoder Loss:  0.032836262 Validation Decoder Loss:  0.34594202
Encoder Loss:  0.037460122  || Decoder Loss:  0.032805394 Validation Decoder Loss:  0.34561002
Encoder Loss:  0.037439767  || Decoder Loss:  0.03277855 Validation Decoder Loss:  0.34520864
Encoder Loss:  0.037422474  || Decoder Loss:  0.032754607 Validation Decoder Loss:  0.3447889
Encoder Loss:  0.037405103  || Decoder Loss:  0.032733027 Validation Decoder Loss:  0.34436125
Encoder Loss:  0.0373901  || Decoder Loss:  0.03271335 Validation Decoder Loss:  0.34393328
Encoder Loss:  0.037376508  || Decoder Loss:  0.032695424 Validation Decoder Loss:  0.3435102
Encoder Loss:  0.037364215  || Decoder Loss:  0.03267906 Validation Decoder Loss:  0.34311342
Encoder Loss:  0.037352838  || Decoder Loss:  0.032664143 Validation Decoder Loss:  0.3427414
Encoder Loss:  0.037342478  || Decoder Loss:  0.032650474 Validation Decoder Loss:  0.34238213
Encoder Loss:  0.03733269  || Decoder Loss:  0.03263794 Validation Decoder Loss:  0.34201926
Encoder Loss:  0.03732388  || Decoder Loss:  0.032626465 Validation Decoder Loss:  0.3416527
Encoder Loss:  0.037315786  || Decoder Loss:  0.032615975 Validation Decoder Loss:  0.34127724
Encoder Loss:  0.03730842  || Decoder Loss:  0.03260642 Validation Decoder Loss:  0.3408829
Encoder Loss:  0.03730181  || Decoder Loss:  0.032597765 Validation Decoder Loss:  0.34045744
Encoder Loss:  0.03729577  || Decoder Loss:  0.032590013 Validation Decoder Loss:  0.340004
Encoder Loss:  0.037290324  || Decoder Loss:  0.03258314 Validation Decoder Loss:  0.33951294
Encoder Loss:  0.03728551  || Decoder Loss:  0.032577235 Validation Decoder Loss:  0.3389928
Encoder Loss:  0.037281424  || Decoder Loss:  0.03257235 Validation Decoder Loss:  0.33847868
Encoder Loss:  0.037278377  || Decoder Loss:  0.03256856 Validation Decoder Loss:  0.3380379
Encoder Loss:  0.03727598  || Decoder Loss:  0.03256571 Validation Decoder Loss:  0.3377906
Encoder Loss:  0.0372733  || Decoder Loss:  0.032563157 Validation Decoder Loss:  0.3378792
Model: siamese_net_lr_0.02757308077989416 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3378792
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_348 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 634, 5, 20, 1)     380       
_________________________________________________________________
reshape_119 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 404
Trainable params: 404
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_350 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_352 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24725445  || Decoder Loss:  0.34286773 Validation Decoder Loss:  0.74782443
Encoder Loss:  0.18746388  || Decoder Loss:  0.34602094 Validation Decoder Loss:  0.4756194
Encoder Loss:  0.05771494  || Decoder Loss:  0.065629095 Validation Decoder Loss:  0.3514616
Encoder Loss:  0.045117605  || Decoder Loss:  0.03472971 Validation Decoder Loss:  0.34167987
Encoder Loss:  0.043314558  || Decoder Loss:  0.032437466 Validation Decoder Loss:  0.34050614
Encoder Loss:  0.04299397  || Decoder Loss:  0.032303516 Validation Decoder Loss:  0.34064412
Encoder Loss:  0.044713892  || Decoder Loss:  0.032279726 Validation Decoder Loss:  0.3404156
Encoder Loss:  0.0446494  || Decoder Loss:  0.032262467 Validation Decoder Loss:  0.3403603
Encoder Loss:  0.04469453  || Decoder Loss:  0.03224193 Validation Decoder Loss:  0.33993405
Encoder Loss:  0.04789369  || Decoder Loss:  0.032223355 Validation Decoder Loss:  0.33992606
Encoder Loss:  0.04323377  || Decoder Loss:  0.032200772 Validation Decoder Loss:  0.3397848
Encoder Loss:  0.042923525  || Decoder Loss:  0.032180615 Validation Decoder Loss:  0.33988708
Encoder Loss:  0.0444063  || Decoder Loss:  0.03215799 Validation Decoder Loss:  0.33944345
Encoder Loss:  0.04386885  || Decoder Loss:  0.032133028 Validation Decoder Loss:  0.33920065
Encoder Loss:  0.044819377  || Decoder Loss:  0.032115597 Validation Decoder Loss:  0.33976316
Encoder Loss:  0.043834854  || Decoder Loss:  0.032100055 Validation Decoder Loss:  0.3390578
Encoder Loss:  0.042940203  || Decoder Loss:  0.032077286 Validation Decoder Loss:  0.3394001
Encoder Loss:  0.0426076  || Decoder Loss:  0.03206852 Validation Decoder Loss:  0.33891326
Encoder Loss:  0.04487957  || Decoder Loss:  0.032046 Validation Decoder Loss:  0.33971566
Encoder Loss:  0.044023905  || Decoder Loss:  0.032097757 Validation Decoder Loss:  0.3396368
Encoder Loss:  0.044699244  || Decoder Loss:  0.03230997 Validation Decoder Loss:  0.3338315
Encoder Loss:  0.045179367  || Decoder Loss:  0.033256184 Validation Decoder Loss:  0.33122122
Encoder Loss:  0.044101086  || Decoder Loss:  0.033581115 Validation Decoder Loss:  0.33721927
Encoder Loss:  0.0447583  || Decoder Loss:  0.032836862 Validation Decoder Loss:  0.33991954
Encoder Loss:  0.043360658  || Decoder Loss:  0.03219477 Validation Decoder Loss:  0.3391266
Encoder Loss:  0.04350378  || Decoder Loss:  0.032193866 Validation Decoder Loss:  0.34022456
Encoder Loss:  0.043012545  || Decoder Loss:  0.032110833 Validation Decoder Loss:  0.33851856
Encoder Loss:  0.04263578  || Decoder Loss:  0.032008328 Validation Decoder Loss:  0.3393115
Encoder Loss:  0.043350335  || Decoder Loss:  0.032288387 Validation Decoder Loss:  0.35681796
Encoder Loss:  0.048925042  || Decoder Loss:  0.041328125 Validation Decoder Loss:  0.3296467
Encoder Loss:  0.04474953  || Decoder Loss:  0.034391936 Validation Decoder Loss:  0.34642518
Encoder Loss:  0.04329109  || Decoder Loss:  0.032118794 Validation Decoder Loss:  0.33711287
Encoder Loss:  0.04321979  || Decoder Loss:  0.031944636 Validation Decoder Loss:  0.3391921
Encoder Loss:  0.042976886  || Decoder Loss:  0.03191306 Validation Decoder Loss:  0.3391142
Encoder Loss:  0.0433283  || Decoder Loss:  0.03190966 Validation Decoder Loss:  0.33962706
Encoder Loss:  0.04396944  || Decoder Loss:  0.031892058 Validation Decoder Loss:  0.3392288
Encoder Loss:  0.04301179  || Decoder Loss:  0.031906545 Validation Decoder Loss:  0.33903915
Encoder Loss:  0.04509926  || Decoder Loss:  0.03193065 Validation Decoder Loss:  0.33575064
Encoder Loss:  0.04468479  || Decoder Loss:  0.031903747 Validation Decoder Loss:  0.33332443
Encoder Loss:  0.045243274  || Decoder Loss:  0.03330924 Validation Decoder Loss:  0.33165023
Model: siamese_net_lr_0.06147461641943928 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3316502
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_354 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_120 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_376"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_356 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_358 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15961996  || Decoder Loss:  0.14759938 Validation Decoder Loss:  0.39722615
Encoder Loss:  0.045122333  || Decoder Loss:  0.03568159 Validation Decoder Loss:  0.3542182
Encoder Loss:  0.04029904  || Decoder Loss:  0.032762423 Validation Decoder Loss:  0.337515
Encoder Loss:  0.04046731  || Decoder Loss:  0.03270641 Validation Decoder Loss:  0.32974905
Encoder Loss:  0.0401081  || Decoder Loss:  0.03263195 Validation Decoder Loss:  0.3215784
Encoder Loss:  0.04047034  || Decoder Loss:  0.03290371 Validation Decoder Loss:  0.32895917
Encoder Loss:  0.040736925  || Decoder Loss:  0.0325869 Validation Decoder Loss:  0.33078513
Encoder Loss:  0.040234555  || Decoder Loss:  0.032738365 Validation Decoder Loss:  0.33129352
Encoder Loss:  0.040039316  || Decoder Loss:  0.032573935 Validation Decoder Loss:  0.32008433
Encoder Loss:  0.039895866  || Decoder Loss:  0.032637846 Validation Decoder Loss:  0.31500316
Encoder Loss:  0.039477676  || Decoder Loss:  0.032634426 Validation Decoder Loss:  0.33847085
Encoder Loss:  0.040885914  || Decoder Loss:  0.032374512 Validation Decoder Loss:  0.3393771
Encoder Loss:  0.048051678  || Decoder Loss:  0.04078777 Validation Decoder Loss:  0.3696711
Encoder Loss:  0.040627263  || Decoder Loss:  0.03314667 Validation Decoder Loss:  0.32581416
Encoder Loss:  0.039551083  || Decoder Loss:  0.032343186 Validation Decoder Loss:  0.33809733
Encoder Loss:  0.039406568  || Decoder Loss:  0.032229178 Validation Decoder Loss:  0.3404003
Encoder Loss:  0.039690435  || Decoder Loss:  0.032206707 Validation Decoder Loss:  0.33969897
Encoder Loss:  0.039460443  || Decoder Loss:  0.032345228 Validation Decoder Loss:  0.34080648
Encoder Loss:  0.03974719  || Decoder Loss:  0.032350942 Validation Decoder Loss:  0.34146237
Encoder Loss:  0.0409724  || Decoder Loss:  0.032225836 Validation Decoder Loss:  0.33672357
Encoder Loss:  0.04090374  || Decoder Loss:  0.032265138 Validation Decoder Loss:  0.34212834
Encoder Loss:  0.039997682  || Decoder Loss:  0.03238636 Validation Decoder Loss:  0.33996117
Encoder Loss:  0.039556686  || Decoder Loss:  0.03253808 Validation Decoder Loss:  0.3393144
Encoder Loss:  0.03941035  || Decoder Loss:  0.032185834 Validation Decoder Loss:  0.33879313
Encoder Loss:  0.039213333  || Decoder Loss:  0.03216228 Validation Decoder Loss:  0.33963507
Encoder Loss:  0.03956738  || Decoder Loss:  0.03215789 Validation Decoder Loss:  0.3362618
Encoder Loss:  0.04015604  || Decoder Loss:  0.03228784 Validation Decoder Loss:  0.33788007
Encoder Loss:  0.039505094  || Decoder Loss:  0.03228195 Validation Decoder Loss:  0.33979318
Encoder Loss:  0.040004406  || Decoder Loss:  0.03215114 Validation Decoder Loss:  0.33754689
Encoder Loss:  0.040042385  || Decoder Loss:  0.032221567 Validation Decoder Loss:  0.3384998
Encoder Loss:  0.04026055  || Decoder Loss:  0.03227779 Validation Decoder Loss:  0.33942416
Encoder Loss:  0.039283488  || Decoder Loss:  0.032175615 Validation Decoder Loss:  0.33876622
Encoder Loss:  0.03885646  || Decoder Loss:  0.03214267 Validation Decoder Loss:  0.33828312
Encoder Loss:  0.03889361  || Decoder Loss:  0.032260977 Validation Decoder Loss:  0.33801132
Encoder Loss:  0.03874291  || Decoder Loss:  0.03215539 Validation Decoder Loss:  0.3380128
Encoder Loss:  0.03872663  || Decoder Loss:  0.03210751 Validation Decoder Loss:  0.33747247
Encoder Loss:  0.038897645  || Decoder Loss:  0.032208607 Validation Decoder Loss:  0.33635736
Encoder Loss:  0.038735315  || Decoder Loss:  0.0321383 Validation Decoder Loss:  0.33727664
Encoder Loss:  0.03873925  || Decoder Loss:  0.03209545 Validation Decoder Loss:  0.33678055
Encoder Loss:  0.038830806  || Decoder Loss:  0.03221377 Validation Decoder Loss:  0.3365635
Model: siamese_net_lr_0.03929910255460198 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3365635
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 82, 5, 20, 1)      20        
_________________________________________________________________
dropout_360 (Dropout)        (None, 82, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 634, 5, 20, 1)     68        
_________________________________________________________________
reshape_121 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 88
Trainable params: 88
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_362 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_364 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19855602  || Decoder Loss:  0.21749859 Validation Decoder Loss:  0.3232438
Encoder Loss:  0.07554985  || Decoder Loss:  0.080359794 Validation Decoder Loss:  0.3482205
Encoder Loss:  0.03907045  || Decoder Loss:  0.0337417 Validation Decoder Loss:  0.35184577
Encoder Loss:  0.03878788  || Decoder Loss:  0.032999083 Validation Decoder Loss:  0.34151095
Encoder Loss:  0.037743755  || Decoder Loss:  0.032689195 Validation Decoder Loss:  0.34109494
Encoder Loss:  0.038755354  || Decoder Loss:  0.03264363 Validation Decoder Loss:  0.34267336
Encoder Loss:  0.038154826  || Decoder Loss:  0.032606527 Validation Decoder Loss:  0.34258935
Encoder Loss:  0.038353458  || Decoder Loss:  0.03257316 Validation Decoder Loss:  0.3425512
Encoder Loss:  0.03921276  || Decoder Loss:  0.032543123 Validation Decoder Loss:  0.34486383
Encoder Loss:  0.037594218  || Decoder Loss:  0.032472044 Validation Decoder Loss:  0.3425857
Encoder Loss:  0.037779573  || Decoder Loss:  0.032432828 Validation Decoder Loss:  0.34269443
Encoder Loss:  0.037289947  || Decoder Loss:  0.032388743 Validation Decoder Loss:  0.3427884
Encoder Loss:  0.037514474  || Decoder Loss:  0.032361496 Validation Decoder Loss:  0.34326345
Encoder Loss:  0.03748065  || Decoder Loss:  0.03233042 Validation Decoder Loss:  0.34368527
Encoder Loss:  0.03744125  || Decoder Loss:  0.03229451 Validation Decoder Loss:  0.3436337
Encoder Loss:  0.03740572  || Decoder Loss:  0.032266837 Validation Decoder Loss:  0.34358323
Encoder Loss:  0.037477836  || Decoder Loss:  0.032381486 Validation Decoder Loss:  0.3434016
Encoder Loss:  0.037300184  || Decoder Loss:  0.032245975 Validation Decoder Loss:  0.34484726
Encoder Loss:  0.037666917  || Decoder Loss:  0.032287627 Validation Decoder Loss:  0.34296852
Encoder Loss:  0.039299227  || Decoder Loss:  0.03233526 Validation Decoder Loss:  0.34354222
Encoder Loss:  0.038692504  || Decoder Loss:  0.03230155 Validation Decoder Loss:  0.34336394
Encoder Loss:  0.037746456  || Decoder Loss:  0.032248866 Validation Decoder Loss:  0.34650812
Encoder Loss:  0.037307743  || Decoder Loss:  0.032277174 Validation Decoder Loss:  0.34610868
Encoder Loss:  0.037637357  || Decoder Loss:  0.032345936 Validation Decoder Loss:  0.3458766
Encoder Loss:  0.036984287  || Decoder Loss:  0.032237932 Validation Decoder Loss:  0.3457772
Encoder Loss:  0.03733373  || Decoder Loss:  0.03237926 Validation Decoder Loss:  0.34633195
Encoder Loss:  0.037375208  || Decoder Loss:  0.032328416 Validation Decoder Loss:  0.3464111
Encoder Loss:  0.037602108  || Decoder Loss:  0.03225876 Validation Decoder Loss:  0.34497792
Encoder Loss:  0.037738897  || Decoder Loss:  0.03227459 Validation Decoder Loss:  0.3469897
Encoder Loss:  0.037705254  || Decoder Loss:  0.03223899 Validation Decoder Loss:  0.34519944
Encoder Loss:  0.03755609  || Decoder Loss:  0.032330953 Validation Decoder Loss:  0.34748378
Encoder Loss:  0.03756932  || Decoder Loss:  0.032287143 Validation Decoder Loss:  0.34540695
Encoder Loss:  0.038035884  || Decoder Loss:  0.032272123 Validation Decoder Loss:  0.34388584
Encoder Loss:  0.04089348  || Decoder Loss:  0.036102667 Validation Decoder Loss:  0.3753559
Encoder Loss:  0.03911141  || Decoder Loss:  0.03475279 Validation Decoder Loss:  0.34551823
Encoder Loss:  0.037458733  || Decoder Loss:  0.03260303 Validation Decoder Loss:  0.34269398
Encoder Loss:  0.03838909  || Decoder Loss:  0.0326064 Validation Decoder Loss:  0.34498143
Encoder Loss:  0.037839457  || Decoder Loss:  0.03247857 Validation Decoder Loss:  0.3458268
Encoder Loss:  0.038329028  || Decoder Loss:  0.032528676 Validation Decoder Loss:  0.34980962
Encoder Loss:  0.038233113  || Decoder Loss:  0.03248039 Validation Decoder Loss:  0.35005823
Model: siamese_net_lr_0.03849328405232509 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3500582
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_155 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_366 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_156 (Conv3D (None, 634, 5, 20, 1)     137       
_________________________________________________________________
reshape_122 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_368 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_370 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31765464  || Decoder Loss:  0.446072 Validation Decoder Loss:  0.37743112
Encoder Loss:  0.06542268  || Decoder Loss:  0.07015185 Validation Decoder Loss:  0.36738086
Encoder Loss:  0.044275627  || Decoder Loss:  0.034486137 Validation Decoder Loss:  0.3455308
Encoder Loss:  0.042983435  || Decoder Loss:  0.03262699 Validation Decoder Loss:  0.34232408
Encoder Loss:  0.041873  || Decoder Loss:  0.032442704 Validation Decoder Loss:  0.34107637
Encoder Loss:  0.040925168  || Decoder Loss:  0.032389756 Validation Decoder Loss:  0.34047133
Encoder Loss:  0.041017264  || Decoder Loss:  0.032370828 Validation Decoder Loss:  0.34048486
Encoder Loss:  0.041806735  || Decoder Loss:  0.032346934 Validation Decoder Loss:  0.34024155
Encoder Loss:  0.040508255  || Decoder Loss:  0.03235985 Validation Decoder Loss:  0.3399405
Encoder Loss:  0.041795887  || Decoder Loss:  0.032319512 Validation Decoder Loss:  0.33991417
Encoder Loss:  0.041729163  || Decoder Loss:  0.032279063 Validation Decoder Loss:  0.3394026
Encoder Loss:  0.03956242  || Decoder Loss:  0.032261483 Validation Decoder Loss:  0.33878535
Encoder Loss:  0.03945111  || Decoder Loss:  0.03227346 Validation Decoder Loss:  0.33870876
Encoder Loss:  0.03944302  || Decoder Loss:  0.03227368 Validation Decoder Loss:  0.33846813
Encoder Loss:  0.039430566  || Decoder Loss:  0.032272045 Validation Decoder Loss:  0.33829662
Encoder Loss:  0.039422024  || Decoder Loss:  0.032264728 Validation Decoder Loss:  0.3381668
Encoder Loss:  0.039413143  || Decoder Loss:  0.032256283 Validation Decoder Loss:  0.3380925
Encoder Loss:  0.03941393  || Decoder Loss:  0.032257166 Validation Decoder Loss:  0.3380744
Encoder Loss:  0.039407488  || Decoder Loss:  0.032258727 Validation Decoder Loss:  0.33801085
Encoder Loss:  0.039401706  || Decoder Loss:  0.032251474 Validation Decoder Loss:  0.33799636
Encoder Loss:  0.039395463  || Decoder Loss:  0.032248534 Validation Decoder Loss:  0.3379848
Encoder Loss:  0.039402194  || Decoder Loss:  0.032249484 Validation Decoder Loss:  0.33799148
Encoder Loss:  0.039391395  || Decoder Loss:  0.032246236 Validation Decoder Loss:  0.33795044
Encoder Loss:  0.03938832  || Decoder Loss:  0.032239612 Validation Decoder Loss:  0.33795792
Encoder Loss:  0.039388843  || Decoder Loss:  0.03223909 Validation Decoder Loss:  0.33796096
Encoder Loss:  0.039381642  || Decoder Loss:  0.03223355 Validation Decoder Loss:  0.33794564
Encoder Loss:  0.0393783  || Decoder Loss:  0.032229856 Validation Decoder Loss:  0.33796084
Encoder Loss:  0.039379105  || Decoder Loss:  0.032226816 Validation Decoder Loss:  0.3379508
Encoder Loss:  0.039380528  || Decoder Loss:  0.03222173 Validation Decoder Loss:  0.3379561
Encoder Loss:  0.03937586  || Decoder Loss:  0.032219928 Validation Decoder Loss:  0.3379861
Encoder Loss:  0.039369415  || Decoder Loss:  0.03221607 Validation Decoder Loss:  0.3379502
Encoder Loss:  0.039379515  || Decoder Loss:  0.032211833 Validation Decoder Loss:  0.33801162
Encoder Loss:  0.039369836  || Decoder Loss:  0.032206956 Validation Decoder Loss:  0.3379777
Encoder Loss:  0.039381288  || Decoder Loss:  0.032203067 Validation Decoder Loss:  0.3380452
Encoder Loss:  0.039427713  || Decoder Loss:  0.032200735 Validation Decoder Loss:  0.33798808
Encoder Loss:  0.039380945  || Decoder Loss:  0.032188717 Validation Decoder Loss:  0.33792454
Encoder Loss:  0.039368864  || Decoder Loss:  0.032198615 Validation Decoder Loss:  0.3379088
Encoder Loss:  0.03939499  || Decoder Loss:  0.032186206 Validation Decoder Loss:  0.33798888
Encoder Loss:  0.039387435  || Decoder Loss:  0.032179505 Validation Decoder Loss:  0.33792904
Encoder Loss:  0.03947042  || Decoder Loss:  0.032178655 Validation Decoder Loss:  0.33803844
Model: siamese_net_lr_0.04485799440509456 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33803844
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_158 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_372 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_159 (Conv3D (None, 634, 5, 20, 1)     200       
_________________________________________________________________
reshape_123 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_374 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_376 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.78231215  || Decoder Loss:  0.9415359 Validation Decoder Loss:  1.5765092
Encoder Loss:  0.40819633  || Decoder Loss:  0.52134395 Validation Decoder Loss:  0.98001134
Encoder Loss:  0.3936566  || Decoder Loss:  0.50653005 Validation Decoder Loss:  0.98684156
Encoder Loss:  0.3904806  || Decoder Loss:  0.50293195 Validation Decoder Loss:  0.99958175
Encoder Loss:  0.39001024  || Decoder Loss:  0.5022288 Validation Decoder Loss:  0.99723464
Encoder Loss:  0.38855743  || Decoder Loss:  0.500202 Validation Decoder Loss:  0.998392
Encoder Loss:  0.38746598  || Decoder Loss:  0.49861217 Validation Decoder Loss:  0.99652433
Encoder Loss:  0.3861763  || Decoder Loss:  0.496841 Validation Decoder Loss:  0.99187356
Encoder Loss:  0.38539165  || Decoder Loss:  0.49549294 Validation Decoder Loss:  0.9993763
Encoder Loss:  0.3833976  || Decoder Loss:  0.49323732 Validation Decoder Loss:  0.9925896
Encoder Loss:  0.3795772  || Decoder Loss:  0.487816 Validation Decoder Loss:  0.96501637
Encoder Loss:  0.34545487  || Decoder Loss:  0.4425953 Validation Decoder Loss:  0.79855317
Encoder Loss:  0.08217961  || Decoder Loss:  0.09198759 Validation Decoder Loss:  0.34587383
Encoder Loss:  0.038436733  || Decoder Loss:  0.03391831 Validation Decoder Loss:  0.34366566
Encoder Loss:  0.037163194  || Decoder Loss:  0.032554246 Validation Decoder Loss:  0.344258
Encoder Loss:  0.037126865  || Decoder Loss:  0.032485355 Validation Decoder Loss:  0.34468204
Encoder Loss:  0.03711891  || Decoder Loss:  0.032471508 Validation Decoder Loss:  0.3450072
Encoder Loss:  0.038420606  || Decoder Loss:  0.032513306 Validation Decoder Loss:  0.34515187
Encoder Loss:  0.037677847  || Decoder Loss:  0.032477606 Validation Decoder Loss:  0.3455974
Encoder Loss:  0.037482947  || Decoder Loss:  0.03250583 Validation Decoder Loss:  0.34553772
Encoder Loss:  0.03711275  || Decoder Loss:  0.032455858 Validation Decoder Loss:  0.34519607
Encoder Loss:  0.037400045  || Decoder Loss:  0.032459944 Validation Decoder Loss:  0.34510288
Encoder Loss:  0.037622046  || Decoder Loss:  0.032473993 Validation Decoder Loss:  0.346012
Encoder Loss:  0.03740527  || Decoder Loss:  0.03246269 Validation Decoder Loss:  0.3460183
Encoder Loss:  0.03705142  || Decoder Loss:  0.03244293 Validation Decoder Loss:  0.34542486
Encoder Loss:  0.037343446  || Decoder Loss:  0.032447837 Validation Decoder Loss:  0.34566015
Encoder Loss:  0.03747706  || Decoder Loss:  0.032443892 Validation Decoder Loss:  0.3462053
Encoder Loss:  0.037963577  || Decoder Loss:  0.03245652 Validation Decoder Loss:  0.34625006
Encoder Loss:  0.03708357  || Decoder Loss:  0.032430574 Validation Decoder Loss:  0.34526628
Encoder Loss:  0.037168395  || Decoder Loss:  0.032427147 Validation Decoder Loss:  0.34550637
Encoder Loss:  0.037265833  || Decoder Loss:  0.032413382 Validation Decoder Loss:  0.34494182
Encoder Loss:  0.037113205  || Decoder Loss:  0.032450818 Validation Decoder Loss:  0.34952146
Encoder Loss:  0.036855604  || Decoder Loss:  0.032431286 Validation Decoder Loss:  0.34732258
Encoder Loss:  0.03680931  || Decoder Loss:  0.032403406 Validation Decoder Loss:  0.34602427
Encoder Loss:  0.03678206  || Decoder Loss:  0.032392334 Validation Decoder Loss:  0.34581563
Encoder Loss:  0.036777344  || Decoder Loss:  0.03238647 Validation Decoder Loss:  0.34572387
Encoder Loss:  0.0367734  || Decoder Loss:  0.032380853 Validation Decoder Loss:  0.34565002
Encoder Loss:  0.03676905  || Decoder Loss:  0.03237513 Validation Decoder Loss:  0.34556186
Encoder Loss:  0.036765207  || Decoder Loss:  0.03236955 Validation Decoder Loss:  0.3454935
Encoder Loss:  0.03676032  || Decoder Loss:  0.032364074 Validation Decoder Loss:  0.34545445
Model: siamese_net_lr_0.058763928384749274 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34545445
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_161 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_378 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_162 (Conv3D (None, 634, 5, 20, 1)     89        
_________________________________________________________________
reshape_124 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_392"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_380 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_382 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07978309  || Decoder Loss:  0.05348493 Validation Decoder Loss:  0.34366584
Encoder Loss:  0.04410234  || Decoder Loss:  0.032630313 Validation Decoder Loss:  0.34306446
Encoder Loss:  0.04014862  || Decoder Loss:  0.031930164 Validation Decoder Loss:  0.34303316
Encoder Loss:  0.040049277  || Decoder Loss:  0.031769022 Validation Decoder Loss:  0.34308964
Encoder Loss:  0.039310794  || Decoder Loss:  0.031698573 Validation Decoder Loss:  0.3431341
Encoder Loss:  0.040379476  || Decoder Loss:  0.0316295 Validation Decoder Loss:  0.34285927
Encoder Loss:  0.04332616  || Decoder Loss:  0.031633716 Validation Decoder Loss:  0.343147
Encoder Loss:  0.041768182  || Decoder Loss:  0.031561702 Validation Decoder Loss:  0.3430832
Encoder Loss:  0.04040257  || Decoder Loss:  0.031437337 Validation Decoder Loss:  0.3434385
Encoder Loss:  0.039995197  || Decoder Loss:  0.031380232 Validation Decoder Loss:  0.34373817
Encoder Loss:  0.038754217  || Decoder Loss:  0.031332873 Validation Decoder Loss:  0.34390998
Encoder Loss:  0.04011028  || Decoder Loss:  0.031338766 Validation Decoder Loss:  0.34375596
Encoder Loss:  0.039942514  || Decoder Loss:  0.03136214 Validation Decoder Loss:  0.3439793
Encoder Loss:  0.03898196  || Decoder Loss:  0.0312557 Validation Decoder Loss:  0.34408206
Encoder Loss:  0.038663972  || Decoder Loss:  0.031298533 Validation Decoder Loss:  0.34413388
Encoder Loss:  0.038460486  || Decoder Loss:  0.03116381 Validation Decoder Loss:  0.3443684
Encoder Loss:  0.038763255  || Decoder Loss:  0.031240799 Validation Decoder Loss:  0.3446071
Encoder Loss:  0.039491262  || Decoder Loss:  0.031140793 Validation Decoder Loss:  0.34477723
Encoder Loss:  0.040798977  || Decoder Loss:  0.031649273 Validation Decoder Loss:  0.34393358
Encoder Loss:  0.039057564  || Decoder Loss:  0.0314279 Validation Decoder Loss:  0.34406036
Encoder Loss:  0.03836137  || Decoder Loss:  0.031307265 Validation Decoder Loss:  0.34422147
Encoder Loss:  0.038192905  || Decoder Loss:  0.03116268 Validation Decoder Loss:  0.3445273
Encoder Loss:  0.039427537  || Decoder Loss:  0.03117122 Validation Decoder Loss:  0.3448978
Encoder Loss:  0.039352003  || Decoder Loss:  0.03116497 Validation Decoder Loss:  0.34472954
Encoder Loss:  0.039382704  || Decoder Loss:  0.031220011 Validation Decoder Loss:  0.3456286
Encoder Loss:  0.03933678  || Decoder Loss:  0.031268068 Validation Decoder Loss:  0.34471196
Encoder Loss:  0.03806281  || Decoder Loss:  0.031103466 Validation Decoder Loss:  0.34511518
Encoder Loss:  0.038519528  || Decoder Loss:  0.03118705 Validation Decoder Loss:  0.34484905
Encoder Loss:  0.039078046  || Decoder Loss:  0.03116766 Validation Decoder Loss:  0.34627807
Encoder Loss:  0.03859283  || Decoder Loss:  0.031192685 Validation Decoder Loss:  0.34481242
Encoder Loss:  0.03888266  || Decoder Loss:  0.031338792 Validation Decoder Loss:  0.34574547
Encoder Loss:  0.03997954  || Decoder Loss:  0.031404696 Validation Decoder Loss:  0.34487993
Encoder Loss:  0.039189804  || Decoder Loss:  0.031155525 Validation Decoder Loss:  0.34489512
Encoder Loss:  0.038187638  || Decoder Loss:  0.031212486 Validation Decoder Loss:  0.3450334
Encoder Loss:  0.038676653  || Decoder Loss:  0.031116271 Validation Decoder Loss:  0.34619468
Encoder Loss:  0.039486997  || Decoder Loss:  0.03130471 Validation Decoder Loss:  0.3440937
Encoder Loss:  0.03998127  || Decoder Loss:  0.031146996 Validation Decoder Loss:  0.34458405
Encoder Loss:  0.039494716  || Decoder Loss:  0.03149092 Validation Decoder Loss:  0.345121
Encoder Loss:  0.0381728  || Decoder Loss:  0.031213142 Validation Decoder Loss:  0.3455872
Encoder Loss:  0.037940096  || Decoder Loss:  0.031177647 Validation Decoder Loss:  0.34486926
Model: siamese_net_lr_0.021060270254557596 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3448693
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_164 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_384 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_165 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_125 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_386 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_388 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2010993  || Decoder Loss:  0.12527427 Validation Decoder Loss:  0.38375336
Encoder Loss:  0.19732434  || Decoder Loss:  0.107114665 Validation Decoder Loss:  0.4195189
Encoder Loss:  0.21191795  || Decoder Loss:  0.14684927 Validation Decoder Loss:  0.53335893
Encoder Loss:  0.2968725  || Decoder Loss:  0.35199428 Validation Decoder Loss:  1.1100626
Encoder Loss:  0.34334633  || Decoder Loss:  0.47998673 Validation Decoder Loss:  1.0555946
Encoder Loss:  0.33315602  || Decoder Loss:  0.46845067 Validation Decoder Loss:  0.91317034
Encoder Loss:  0.3474847  || Decoder Loss:  0.49207228 Validation Decoder Loss:  0.8946333
Encoder Loss:  0.34821597  || Decoder Loss:  0.491973 Validation Decoder Loss:  0.93741506
Encoder Loss:  0.35111862  || Decoder Loss:  0.49546137 Validation Decoder Loss:  0.90274185
Encoder Loss:  0.3482563  || Decoder Loss:  0.49322426 Validation Decoder Loss:  0.889247
Encoder Loss:  0.34766984  || Decoder Loss:  0.49214202 Validation Decoder Loss:  0.8711413
Encoder Loss:  0.3470313  || Decoder Loss:  0.4905179 Validation Decoder Loss:  0.89778054
Encoder Loss:  0.34629956  || Decoder Loss:  0.490327 Validation Decoder Loss:  0.8760497
Encoder Loss:  0.34259656  || Decoder Loss:  0.48505643 Validation Decoder Loss:  0.8744557
Encoder Loss:  0.34888577  || Decoder Loss:  0.49277115 Validation Decoder Loss:  0.88184273
Encoder Loss:  0.34723  || Decoder Loss:  0.49151963 Validation Decoder Loss:  0.872041
Encoder Loss:  0.3462182  || Decoder Loss:  0.49028093 Validation Decoder Loss:  0.8838073
Encoder Loss:  0.34483945  || Decoder Loss:  0.48752898 Validation Decoder Loss:  0.86470145
Encoder Loss:  0.3444098  || Decoder Loss:  0.4872236 Validation Decoder Loss:  0.85192716
Encoder Loss:  0.33691826  || Decoder Loss:  0.47723365 Validation Decoder Loss:  0.832433
Encoder Loss:  0.3305212  || Decoder Loss:  0.4668463 Validation Decoder Loss:  1.1364639
Encoder Loss:  0.3494991  || Decoder Loss:  0.495012 Validation Decoder Loss:  1.1081884
Encoder Loss:  0.34913406  || Decoder Loss:  0.4940919 Validation Decoder Loss:  1.1151475
Encoder Loss:  0.3503575  || Decoder Loss:  0.49590182 Validation Decoder Loss:  1.1122917
Encoder Loss:  0.3490883  || Decoder Loss:  0.4939281 Validation Decoder Loss:  1.1462846
Encoder Loss:  0.34927627  || Decoder Loss:  0.49521592 Validation Decoder Loss:  1.1303135
Encoder Loss:  0.3486816  || Decoder Loss:  0.49347192 Validation Decoder Loss:  1.1276993
Encoder Loss:  0.34900433  || Decoder Loss:  0.493691 Validation Decoder Loss:  1.1600974
Encoder Loss:  0.35160404  || Decoder Loss:  0.49484584 Validation Decoder Loss:  1.1732138
Encoder Loss:  0.35020342  || Decoder Loss:  0.49598733 Validation Decoder Loss:  1.1417962
Encoder Loss:  0.34931937  || Decoder Loss:  0.49358943 Validation Decoder Loss:  1.1591446
Encoder Loss:  0.351108  || Decoder Loss:  0.4961938 Validation Decoder Loss:  1.1433212
Encoder Loss:  0.34866297  || Decoder Loss:  0.49399647 Validation Decoder Loss:  1.142492
Encoder Loss:  0.34879288  || Decoder Loss:  0.49428463 Validation Decoder Loss:  1.1534626
Encoder Loss:  0.34832814  || Decoder Loss:  0.49393827 Validation Decoder Loss:  1.1402673
Encoder Loss:  0.34787914  || Decoder Loss:  0.49314427 Validation Decoder Loss:  1.1424301
Encoder Loss:  0.3482403  || Decoder Loss:  0.49287665 Validation Decoder Loss:  1.1760767
Encoder Loss:  0.35208678  || Decoder Loss:  0.49676022 Validation Decoder Loss:  1.1438386
Encoder Loss:  0.34804428  || Decoder Loss:  0.49335927 Validation Decoder Loss:  1.1596694
Encoder Loss:  0.3490195  || Decoder Loss:  0.49361247 Validation Decoder Loss:  1.1683046
Model: siamese_net_lr_0.027353594989183647 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1683046
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_167 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_390 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_168 (Conv3D (None, 634, 5, 20, 1)     550       
_________________________________________________________________
reshape_126 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_392 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_394 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19905582  || Decoder Loss:  0.29528013 Validation Decoder Loss:  0.92505157
Encoder Loss:  0.24796192  || Decoder Loss:  0.4660877 Validation Decoder Loss:  1.2150522
Encoder Loss:  0.27521232  || Decoder Loss:  0.52742726 Validation Decoder Loss:  1.1698765
Encoder Loss:  0.2588993  || Decoder Loss:  0.49311677 Validation Decoder Loss:  1.1612039
Encoder Loss:  0.26187193  || Decoder Loss:  0.499498 Validation Decoder Loss:  1.1659855
Encoder Loss:  0.26221406  || Decoder Loss:  0.5002232 Validation Decoder Loss:  1.1639742
Encoder Loss:  0.26154956  || Decoder Loss:  0.4988177 Validation Decoder Loss:  1.1626974
Encoder Loss:  0.26134127  || Decoder Loss:  0.49837533 Validation Decoder Loss:  1.1629083
Encoder Loss:  0.26120436  || Decoder Loss:  0.49807292 Validation Decoder Loss:  1.1618291
Encoder Loss:  0.26106143  || Decoder Loss:  0.49777794 Validation Decoder Loss:  1.1619815
Encoder Loss:  0.26110727  || Decoder Loss:  0.49787456 Validation Decoder Loss:  1.1619484
Encoder Loss:  0.2610591  || Decoder Loss:  0.49777657 Validation Decoder Loss:  1.1617742
Encoder Loss:  0.26086035  || Decoder Loss:  0.4973495 Validation Decoder Loss:  1.1609769
Encoder Loss:  0.26049685  || Decoder Loss:  0.4965828 Validation Decoder Loss:  1.1595483
Encoder Loss:  0.25812376  || Decoder Loss:  0.4915428 Validation Decoder Loss:  0.82218003
Encoder Loss:  0.25954542  || Decoder Loss:  0.49456024 Validation Decoder Loss:  0.8288281
Encoder Loss:  0.25734055  || Decoder Loss:  0.48988613 Validation Decoder Loss:  0.8341465
Encoder Loss:  0.26171392  || Decoder Loss:  0.49916276 Validation Decoder Loss:  0.8341503
Encoder Loss:  0.2618901  || Decoder Loss:  0.49953717 Validation Decoder Loss:  0.83443284
Encoder Loss:  0.26184645  || Decoder Loss:  0.49944413 Validation Decoder Loss:  0.8344115
Encoder Loss:  0.2618645  || Decoder Loss:  0.49948156 Validation Decoder Loss:  0.8343113
Encoder Loss:  0.2619122  || Decoder Loss:  0.4995796 Validation Decoder Loss:  0.83394873
Encoder Loss:  0.26160908  || Decoder Loss:  0.4989383 Validation Decoder Loss:  0.8337683
Encoder Loss:  0.2617842  || Decoder Loss:  0.4993097 Validation Decoder Loss:  0.83350056
Encoder Loss:  0.2618045  || Decoder Loss:  0.49935478 Validation Decoder Loss:  0.83407587
Encoder Loss:  0.26182702  || Decoder Loss:  0.49938306 Validation Decoder Loss:  0.8342123
Encoder Loss:  0.26234174  || Decoder Loss:  0.5004993 Validation Decoder Loss:  0.8345651
Encoder Loss:  0.26204628  || Decoder Loss:  0.4998579 Validation Decoder Loss:  0.8328756
Encoder Loss:  0.26156375  || Decoder Loss:  0.49884766 Validation Decoder Loss:  0.83269966
Encoder Loss:  0.26178443  || Decoder Loss:  0.4993187 Validation Decoder Loss:  0.833488
Encoder Loss:  0.2617983  || Decoder Loss:  0.49934074 Validation Decoder Loss:  0.83258927
Encoder Loss:  0.261819  || Decoder Loss:  0.49938285 Validation Decoder Loss:  0.83379394
Encoder Loss:  0.26196206  || Decoder Loss:  0.49967477 Validation Decoder Loss:  0.834394
Encoder Loss:  0.26185915  || Decoder Loss:  0.49947053 Validation Decoder Loss:  0.8331649
Encoder Loss:  0.26176104  || Decoder Loss:  0.49925968 Validation Decoder Loss:  0.8322691
Encoder Loss:  0.26173338  || Decoder Loss:  0.49920148 Validation Decoder Loss:  0.8331226
Encoder Loss:  0.26205954  || Decoder Loss:  0.4998865 Validation Decoder Loss:  0.83509856
Encoder Loss:  0.2618393  || Decoder Loss:  0.49941802 Validation Decoder Loss:  0.8316269
Encoder Loss:  0.26187077  || Decoder Loss:  0.49949038 Validation Decoder Loss:  0.8324029
Encoder Loss:  0.26190966  || Decoder Loss:  0.4995793 Validation Decoder Loss:  0.8322582
Model: siamese_net_lr_0.04782081468412485 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8322582
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_170 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_396 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_171 (Conv3D (None, 634, 5, 20, 1)     457       
_________________________________________________________________
reshape_127 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 485
Trainable params: 485
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_404"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_398 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_400 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.078784674  || Decoder Loss:  0.077881455 Validation Decoder Loss:  0.33710304
Encoder Loss:  0.044563297  || Decoder Loss:  0.038382985 Validation Decoder Loss:  0.33646086
Encoder Loss:  0.041161984  || Decoder Loss:  0.033537153 Validation Decoder Loss:  0.33412224
Encoder Loss:  0.04051088  || Decoder Loss:  0.03319354 Validation Decoder Loss:  0.32912546
Encoder Loss:  0.040027156  || Decoder Loss:  0.03411686 Validation Decoder Loss:  0.33127564
Encoder Loss:  0.041419726  || Decoder Loss:  0.03559582 Validation Decoder Loss:  0.33065826
Encoder Loss:  0.04329221  || Decoder Loss:  0.03717705 Validation Decoder Loss:  0.32959312
Encoder Loss:  0.042127028  || Decoder Loss:  0.036197737 Validation Decoder Loss:  0.3290304
Encoder Loss:  0.0421497  || Decoder Loss:  0.03599197 Validation Decoder Loss:  0.3664201
Encoder Loss:  0.040898968  || Decoder Loss:  0.036160752 Validation Decoder Loss:  0.32519785
Encoder Loss:  0.04060456  || Decoder Loss:  0.033611532 Validation Decoder Loss:  0.32355252
Encoder Loss:  0.054822978  || Decoder Loss:  0.05174509 Validation Decoder Loss:  0.4150346
Encoder Loss:  0.048678324  || Decoder Loss:  0.045377992 Validation Decoder Loss:  0.3381865
Encoder Loss:  0.04227204  || Decoder Loss:  0.03618939 Validation Decoder Loss:  0.38263342
Encoder Loss:  0.04046043  || Decoder Loss:  0.03507443 Validation Decoder Loss:  0.33068025
Encoder Loss:  0.03950114  || Decoder Loss:  0.03389094 Validation Decoder Loss:  0.32749572
Encoder Loss:  0.040103424  || Decoder Loss:  0.034629058 Validation Decoder Loss:  0.31904322
Encoder Loss:  0.040693134  || Decoder Loss:  0.034157798 Validation Decoder Loss:  0.3551929
Encoder Loss:  0.042115726  || Decoder Loss:  0.037629366 Validation Decoder Loss:  0.3179914
Encoder Loss:  0.040380627  || Decoder Loss:  0.035076316 Validation Decoder Loss:  0.32717764
Encoder Loss:  0.03951196  || Decoder Loss:  0.0333271 Validation Decoder Loss:  0.33987826
Encoder Loss:  0.044306852  || Decoder Loss:  0.04080153 Validation Decoder Loss:  0.3165968
Encoder Loss:  0.042286504  || Decoder Loss:  0.037582282 Validation Decoder Loss:  0.31658655
Encoder Loss:  0.039915312  || Decoder Loss:  0.034111872 Validation Decoder Loss:  0.32351854
Encoder Loss:  0.037991602  || Decoder Loss:  0.03180712 Validation Decoder Loss:  0.32860434
Encoder Loss:  0.038412172  || Decoder Loss:  0.03182151 Validation Decoder Loss:  0.33168918
Encoder Loss:  0.040020328  || Decoder Loss:  0.034857795 Validation Decoder Loss:  0.35206205
Encoder Loss:  0.043913346  || Decoder Loss:  0.04051118 Validation Decoder Loss:  0.37291956
Encoder Loss:  0.038999997  || Decoder Loss:  0.033407524 Validation Decoder Loss:  0.3331616
Encoder Loss:  0.03803224  || Decoder Loss:  0.031650662 Validation Decoder Loss:  0.3349521
Encoder Loss:  0.041241817  || Decoder Loss:  0.036384705 Validation Decoder Loss:  0.31447247
Encoder Loss:  0.03974466  || Decoder Loss:  0.034595296 Validation Decoder Loss:  0.32712126
Encoder Loss:  0.037659835  || Decoder Loss:  0.031616155 Validation Decoder Loss:  0.33316532
Encoder Loss:  0.037719082  || Decoder Loss:  0.031541854 Validation Decoder Loss:  0.33814818
Encoder Loss:  0.0390911  || Decoder Loss:  0.03225133 Validation Decoder Loss:  0.3160325
Encoder Loss:  0.04362989  || Decoder Loss:  0.038832963 Validation Decoder Loss:  0.33483177
Encoder Loss:  0.05478321  || Decoder Loss:  0.055556346 Validation Decoder Loss:  0.36691016
Encoder Loss:  0.056703277  || Decoder Loss:  0.057921786 Validation Decoder Loss:  0.46223697
Encoder Loss:  0.043874275  || Decoder Loss:  0.040028926 Validation Decoder Loss:  0.35317528
Encoder Loss:  0.037913796  || Decoder Loss:  0.0319982 Validation Decoder Loss:  0.32797116
Model: siamese_net_lr_0.039706933319862414 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32797116
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_173 (Conv3D (None, 80, 5, 20, 1)      18        
_________________________________________________________________
dropout_402 (Dropout)        (None, 80, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_174 (Conv3D (None, 634, 5, 20, 1)     556       
_________________________________________________________________
reshape_128 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_404 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_406 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28628004  || Decoder Loss:  0.46783382 Validation Decoder Loss:  0.6875827
Encoder Loss:  0.28326344  || Decoder Loss:  0.4940615 Validation Decoder Loss:  0.71140915
Encoder Loss:  0.2824654  || Decoder Loss:  0.4957015 Validation Decoder Loss:  0.7102697
Encoder Loss:  0.27841267  || Decoder Loss:  0.4885916 Validation Decoder Loss:  1.2411363
Encoder Loss:  0.2835564  || Decoder Loss:  0.49714366 Validation Decoder Loss:  1.254224
Encoder Loss:  0.28332818  || Decoder Loss:  0.4991119 Validation Decoder Loss:  1.2207632
Encoder Loss:  0.28407565  || Decoder Loss:  0.49788922 Validation Decoder Loss:  1.2126323
Encoder Loss:  0.28386474  || Decoder Loss:  0.49794006 Validation Decoder Loss:  1.2302784
Encoder Loss:  0.28322762  || Decoder Loss:  0.49838948 Validation Decoder Loss:  1.226378
Encoder Loss:  0.2833087  || Decoder Loss:  0.49650115 Validation Decoder Loss:  1.2218639
Encoder Loss:  0.28356618  || Decoder Loss:  0.49888924 Validation Decoder Loss:  0.7695811
Encoder Loss:  0.28262115  || Decoder Loss:  0.49850693 Validation Decoder Loss:  1.1482792
Encoder Loss:  0.2814259  || Decoder Loss:  0.49553937 Validation Decoder Loss:  0.75031614
Encoder Loss:  0.2822001  || Decoder Loss:  0.49583882 Validation Decoder Loss:  0.79115385
Encoder Loss:  0.28570744  || Decoder Loss:  0.5003384 Validation Decoder Loss:  0.7591722
Encoder Loss:  0.2858013  || Decoder Loss:  0.49582073 Validation Decoder Loss:  0.7796849
Encoder Loss:  0.2799715  || Decoder Loss:  0.49077538 Validation Decoder Loss:  1.1259129
Encoder Loss:  0.28027543  || Decoder Loss:  0.49233535 Validation Decoder Loss:  0.94931597
Encoder Loss:  0.27885085  || Decoder Loss:  0.48975354 Validation Decoder Loss:  1.061975
Encoder Loss:  0.2799443  || Decoder Loss:  0.49178165 Validation Decoder Loss:  0.75639915
Encoder Loss:  0.27782086  || Decoder Loss:  0.48972008 Validation Decoder Loss:  0.97082764
Encoder Loss:  0.28011575  || Decoder Loss:  0.4923453 Validation Decoder Loss:  0.7655934
Encoder Loss:  0.28358686  || Decoder Loss:  0.49608403 Validation Decoder Loss:  1.1623265
Encoder Loss:  0.2822335  || Decoder Loss:  0.49624017 Validation Decoder Loss:  1.1653906
Encoder Loss:  0.28050265  || Decoder Loss:  0.49407232 Validation Decoder Loss:  0.7666701
Encoder Loss:  0.27895442  || Decoder Loss:  0.4905697 Validation Decoder Loss:  0.7649514
Encoder Loss:  0.27928588  || Decoder Loss:  0.4903491 Validation Decoder Loss:  0.83490497
Encoder Loss:  0.27850384  || Decoder Loss:  0.489637 Validation Decoder Loss:  0.78488594
Encoder Loss:  0.27729753  || Decoder Loss:  0.4888689 Validation Decoder Loss:  0.8401501
Encoder Loss:  0.27804786  || Decoder Loss:  0.48887363 Validation Decoder Loss:  0.8413079
Encoder Loss:  0.27901825  || Decoder Loss:  0.49039635 Validation Decoder Loss:  0.7658369
Encoder Loss:  0.279995  || Decoder Loss:  0.49210835 Validation Decoder Loss:  0.7676134
Encoder Loss:  0.28035003  || Decoder Loss:  0.492885 Validation Decoder Loss:  0.8413253
Encoder Loss:  0.27875218  || Decoder Loss:  0.4891348 Validation Decoder Loss:  1.1316452
Encoder Loss:  0.28317428  || Decoder Loss:  0.49466074 Validation Decoder Loss:  0.7658504
Encoder Loss:  0.27912715  || Decoder Loss:  0.49095786 Validation Decoder Loss:  1.0938873
Encoder Loss:  0.27814868  || Decoder Loss:  0.4887789 Validation Decoder Loss:  0.8545196
Encoder Loss:  0.27742958  || Decoder Loss:  0.48751616 Validation Decoder Loss:  0.82220936
Encoder Loss:  0.27739486  || Decoder Loss:  0.48723307 Validation Decoder Loss:  0.84339947
Encoder Loss:  0.28366563  || Decoder Loss:  0.50136817 Validation Decoder Loss:  0.82699966
Model: siamese_net_lr_0.05829392271504877 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.82699966
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_176 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_408 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_177 (Conv3D (None, 634, 5, 20, 1)     564       
_________________________________________________________________
reshape_129 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_412"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_410 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_412 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25882652  || Decoder Loss:  0.2445379 Validation Decoder Loss:  1.0886953
Encoder Loss:  0.29538974  || Decoder Loss:  0.51276296 Validation Decoder Loss:  0.9995307
Encoder Loss:  0.2765121  || Decoder Loss:  0.49587163 Validation Decoder Loss:  1.020865
Encoder Loss:  0.27706474  || Decoder Loss:  0.4985632 Validation Decoder Loss:  1.0215492
Encoder Loss:  0.2762082  || Decoder Loss:  0.4984555 Validation Decoder Loss:  1.0311781
Encoder Loss:  0.27629855  || Decoder Loss:  0.49836326 Validation Decoder Loss:  1.0580442
Encoder Loss:  0.27705693  || Decoder Loss:  0.49829063 Validation Decoder Loss:  1.0569493
Encoder Loss:  0.2761268  || Decoder Loss:  0.4981461 Validation Decoder Loss:  1.0647628
Encoder Loss:  0.275241  || Decoder Loss:  0.49781558 Validation Decoder Loss:  1.0794914
Encoder Loss:  0.27688888  || Decoder Loss:  0.49966326 Validation Decoder Loss:  1.0810703
Encoder Loss:  0.2753433  || Decoder Loss:  0.49761674 Validation Decoder Loss:  1.0949976
Encoder Loss:  0.27618068  || Decoder Loss:  0.4981067 Validation Decoder Loss:  1.0949305
Encoder Loss:  0.2768256  || Decoder Loss:  0.49845985 Validation Decoder Loss:  1.0686772
Encoder Loss:  0.27349663  || Decoder Loss:  0.4856821 Validation Decoder Loss:  1.1134641
Encoder Loss:  0.2789151  || Decoder Loss:  0.50022995 Validation Decoder Loss:  1.096497
Encoder Loss:  0.27777767  || Decoder Loss:  0.49875495 Validation Decoder Loss:  1.1048652
Encoder Loss:  0.27604553  || Decoder Loss:  0.49983048 Validation Decoder Loss:  1.099281
Encoder Loss:  0.27632388  || Decoder Loss:  0.49780834 Validation Decoder Loss:  1.1208868
Encoder Loss:  0.2770822  || Decoder Loss:  0.49963203 Validation Decoder Loss:  1.122957
Encoder Loss:  0.2764875  || Decoder Loss:  0.49995625 Validation Decoder Loss:  1.1250823
Encoder Loss:  0.27852404  || Decoder Loss:  0.50041366 Validation Decoder Loss:  1.1150308
Encoder Loss:  0.2767711  || Decoder Loss:  0.5004311 Validation Decoder Loss:  1.1211293
Encoder Loss:  0.27705804  || Decoder Loss:  0.50028735 Validation Decoder Loss:  1.1257173
Encoder Loss:  0.27622616  || Decoder Loss:  0.50035036 Validation Decoder Loss:  1.1251218
Encoder Loss:  0.27782097  || Decoder Loss:  0.5009578 Validation Decoder Loss:  1.0991896
Encoder Loss:  0.2779636  || Decoder Loss:  0.4972895 Validation Decoder Loss:  1.1043644
Encoder Loss:  0.2770317  || Decoder Loss:  0.4978888 Validation Decoder Loss:  1.121726
Encoder Loss:  0.27615368  || Decoder Loss:  0.4987951 Validation Decoder Loss:  1.1307964
Encoder Loss:  0.27584344  || Decoder Loss:  0.4992808 Validation Decoder Loss:  1.1312269
Encoder Loss:  0.27634352  || Decoder Loss:  0.49930924 Validation Decoder Loss:  1.1327369
Encoder Loss:  0.2771614  || Decoder Loss:  0.4992921 Validation Decoder Loss:  1.1295981
Encoder Loss:  0.27637628  || Decoder Loss:  0.4979534 Validation Decoder Loss:  1.1188873
Encoder Loss:  0.2771048  || Decoder Loss:  0.4989521 Validation Decoder Loss:  0.842079
Encoder Loss:  0.27696723  || Decoder Loss:  0.5003984 Validation Decoder Loss:  0.8497884
Encoder Loss:  0.2756716  || Decoder Loss:  0.4984574 Validation Decoder Loss:  1.105764
Encoder Loss:  0.27578822  || Decoder Loss:  0.49855134 Validation Decoder Loss:  1.121958
Encoder Loss:  0.27538344  || Decoder Loss:  0.49710843 Validation Decoder Loss:  0.80987954
Encoder Loss:  0.2743037  || Decoder Loss:  0.49614534 Validation Decoder Loss:  0.88405013
Encoder Loss:  0.27296227  || Decoder Loss:  0.49404225 Validation Decoder Loss:  0.80478466
Encoder Loss:  0.2739074  || Decoder Loss:  0.49477252 Validation Decoder Loss:  0.8668977
Model: siamese_net_lr_0.06500600440408702 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8668977
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_179 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_414 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_180 (Conv3D (None, 634, 5, 20, 1)     279       
_________________________________________________________________
reshape_130 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 307
Trainable params: 307
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_416"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_416 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_418 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33005345  || Decoder Loss:  0.5417521 Validation Decoder Loss:  1.2164216
Encoder Loss:  0.27005184  || Decoder Loss:  0.5351122 Validation Decoder Loss:  0.9793928
Encoder Loss:  0.24863066  || Decoder Loss:  0.49531642 Validation Decoder Loss:  0.96885175
Encoder Loss:  0.24912241  || Decoder Loss:  0.49440452 Validation Decoder Loss:  1.0298455
Encoder Loss:  0.24849068  || Decoder Loss:  0.49344045 Validation Decoder Loss:  0.9981066
Encoder Loss:  0.24792972  || Decoder Loss:  0.49134812 Validation Decoder Loss:  1.017997
Encoder Loss:  0.24717817  || Decoder Loss:  0.49083173 Validation Decoder Loss:  0.96797824
Encoder Loss:  0.24952362  || Decoder Loss:  0.49510196 Validation Decoder Loss:  0.93228173
Encoder Loss:  0.23660845  || Decoder Loss:  0.4663112 Validation Decoder Loss:  0.9010297
Encoder Loss:  0.08575498  || Decoder Loss:  0.12731941 Validation Decoder Loss:  0.35444063
Encoder Loss:  0.045175284  || Decoder Loss:  0.03449428 Validation Decoder Loss:  0.34490597
Encoder Loss:  0.04402579  || Decoder Loss:  0.032711573 Validation Decoder Loss:  0.34450442
Encoder Loss:  0.04427731  || Decoder Loss:  0.032590136 Validation Decoder Loss:  0.34443665
Encoder Loss:  0.043182656  || Decoder Loss:  0.03257907 Validation Decoder Loss:  0.34465784
Encoder Loss:  0.043881673  || Decoder Loss:  0.0325779 Validation Decoder Loss:  0.34433126
Encoder Loss:  0.046132445  || Decoder Loss:  0.03258847 Validation Decoder Loss:  0.3443818
Encoder Loss:  0.04315501  || Decoder Loss:  0.032573786 Validation Decoder Loss:  0.3445235
Encoder Loss:  0.043363314  || Decoder Loss:  0.03256593 Validation Decoder Loss:  0.34429118
Encoder Loss:  0.04294893  || Decoder Loss:  0.032566797 Validation Decoder Loss:  0.34446296
Encoder Loss:  0.043873787  || Decoder Loss:  0.032567922 Validation Decoder Loss:  0.34374213
Encoder Loss:  0.04316719  || Decoder Loss:  0.032568093 Validation Decoder Loss:  0.34378955
Encoder Loss:  0.043919988  || Decoder Loss:  0.0325862 Validation Decoder Loss:  0.34324363
Encoder Loss:  0.043905243  || Decoder Loss:  0.032607924 Validation Decoder Loss:  0.34302568
Encoder Loss:  0.043871075  || Decoder Loss:  0.032609753 Validation Decoder Loss:  0.34305784
Encoder Loss:  0.04383183  || Decoder Loss:  0.03259678 Validation Decoder Loss:  0.34324753
Encoder Loss:  0.043791715  || Decoder Loss:  0.032577153 Validation Decoder Loss:  0.34346277
Encoder Loss:  0.043754157  || Decoder Loss:  0.032558925 Validation Decoder Loss:  0.34359664
Encoder Loss:  0.04372024  || Decoder Loss:  0.03254496 Validation Decoder Loss:  0.3436489
Encoder Loss:  0.043688964  || Decoder Loss:  0.03253341 Validation Decoder Loss:  0.34366184
Encoder Loss:  0.043659702  || Decoder Loss:  0.03252316 Validation Decoder Loss:  0.3436622
Encoder Loss:  0.043632593  || Decoder Loss:  0.03251482 Validation Decoder Loss:  0.34366766
Encoder Loss:  0.04360749  || Decoder Loss:  0.032508273 Validation Decoder Loss:  0.34368062
Encoder Loss:  0.04358392  || Decoder Loss:  0.03250272 Validation Decoder Loss:  0.34370077
Encoder Loss:  0.043561596  || Decoder Loss:  0.032497693 Validation Decoder Loss:  0.34372723
Encoder Loss:  0.04354034  || Decoder Loss:  0.03249294 Validation Decoder Loss:  0.3437613
Encoder Loss:  0.043520037  || Decoder Loss:  0.032488383 Validation Decoder Loss:  0.34380516
Encoder Loss:  0.0435006  || Decoder Loss:  0.032483954 Validation Decoder Loss:  0.34385997
Encoder Loss:  0.043481935  || Decoder Loss:  0.03247959 Validation Decoder Loss:  0.34392327
Encoder Loss:  0.043463964  || Decoder Loss:  0.032475196 Validation Decoder Loss:  0.34398493
Encoder Loss:  0.043446586  || Decoder Loss:  0.03247065 Validation Decoder Loss:  0.3440252
Model: siamese_net_lr_0.09076688723766192 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3440252
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_182 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_420 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_183 (Conv3D (None, 634, 5, 20, 1)     190       
_________________________________________________________________
reshape_131 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_422 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_424 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.076308094  || Decoder Loss:  0.06617333 Validation Decoder Loss:  0.29599974
Encoder Loss:  0.041607328  || Decoder Loss:  0.040024117 Validation Decoder Loss:  0.35085744
Encoder Loss:  0.035331015  || Decoder Loss:  0.03310852 Validation Decoder Loss:  0.344058
Encoder Loss:  0.03471089  || Decoder Loss:  0.032473836 Validation Decoder Loss:  0.34678167
Encoder Loss:  0.034569155  || Decoder Loss:  0.032386053 Validation Decoder Loss:  0.3461235
Encoder Loss:  0.034462456  || Decoder Loss:  0.032343093 Validation Decoder Loss:  0.34614
Encoder Loss:  0.034667913  || Decoder Loss:  0.032399226 Validation Decoder Loss:  0.3476009
Encoder Loss:  0.034435764  || Decoder Loss:  0.032317083 Validation Decoder Loss:  0.34574848
Encoder Loss:  0.034355864  || Decoder Loss:  0.032273877 Validation Decoder Loss:  0.34548563
Encoder Loss:  0.034351833  || Decoder Loss:  0.032259345 Validation Decoder Loss:  0.34559214
Encoder Loss:  0.034354363  || Decoder Loss:  0.032240327 Validation Decoder Loss:  0.34598297
Encoder Loss:  0.03432322  || Decoder Loss:  0.03223406 Validation Decoder Loss:  0.3457694
Encoder Loss:  0.03430902  || Decoder Loss:  0.03221604 Validation Decoder Loss:  0.34542534
Encoder Loss:  0.034286488  || Decoder Loss:  0.032201864 Validation Decoder Loss:  0.34529018
Encoder Loss:  0.034274194  || Decoder Loss:  0.032189667 Validation Decoder Loss:  0.34509647
Encoder Loss:  0.03426908  || Decoder Loss:  0.032177113 Validation Decoder Loss:  0.3450783
Encoder Loss:  0.034257285  || Decoder Loss:  0.032169245 Validation Decoder Loss:  0.3456518
Encoder Loss:  0.03425034  || Decoder Loss:  0.032158647 Validation Decoder Loss:  0.34488922
Encoder Loss:  0.034247562  || Decoder Loss:  0.032150324 Validation Decoder Loss:  0.34561685
Encoder Loss:  0.034231987  || Decoder Loss:  0.03214656 Validation Decoder Loss:  0.34528401
Encoder Loss:  0.034214918  || Decoder Loss:  0.0321242 Validation Decoder Loss:  0.34530255
Encoder Loss:  0.034211993  || Decoder Loss:  0.032115813 Validation Decoder Loss:  0.3460691
Encoder Loss:  0.03423252  || Decoder Loss:  0.032117177 Validation Decoder Loss:  0.345808
Encoder Loss:  0.03418314  || Decoder Loss:  0.032090753 Validation Decoder Loss:  0.34556568
Encoder Loss:  0.03416749  || Decoder Loss:  0.03207737 Validation Decoder Loss:  0.3453377
Encoder Loss:  0.034217454  || Decoder Loss:  0.03212907 Validation Decoder Loss:  0.3460775
Encoder Loss:  0.03419819  || Decoder Loss:  0.032106034 Validation Decoder Loss:  0.34584936
Encoder Loss:  0.034145996  || Decoder Loss:  0.0320531 Validation Decoder Loss:  0.34519207
Encoder Loss:  0.034136802  || Decoder Loss:  0.032041673 Validation Decoder Loss:  0.345946
Encoder Loss:  0.034135886  || Decoder Loss:  0.032035235 Validation Decoder Loss:  0.34551558
Encoder Loss:  0.03412778  || Decoder Loss:  0.032029334 Validation Decoder Loss:  0.34565794
Encoder Loss:  0.034127608  || Decoder Loss:  0.032031607 Validation Decoder Loss:  0.34560943
Encoder Loss:  0.034116764  || Decoder Loss:  0.032019243 Validation Decoder Loss:  0.34554327
Encoder Loss:  0.03411985  || Decoder Loss:  0.032007754 Validation Decoder Loss:  0.34572524
Encoder Loss:  0.034157366  || Decoder Loss:  0.032024305 Validation Decoder Loss:  0.34641266
Encoder Loss:  0.034147542  || Decoder Loss:  0.03201715 Validation Decoder Loss:  0.3442543
Encoder Loss:  0.034112576  || Decoder Loss:  0.032008193 Validation Decoder Loss:  0.34567076
Encoder Loss:  0.034095332  || Decoder Loss:  0.03199914 Validation Decoder Loss:  0.345935
Encoder Loss:  0.03416239  || Decoder Loss:  0.032078817 Validation Decoder Loss:  0.3459419
Encoder Loss:  0.03410407  || Decoder Loss:  0.03201033 Validation Decoder Loss:  0.3459969
Model: siamese_net_lr_0.040318105843332334 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34599692
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_185 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_426 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_186 (Conv3D (None, 634, 5, 20, 1)     190       
_________________________________________________________________
reshape_132 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_428 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_430 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0873408  || Decoder Loss:  0.13410498 Validation Decoder Loss:  0.36229426
Encoder Loss:  0.061174072  || Decoder Loss:  0.046345763 Validation Decoder Loss:  0.32993424
Encoder Loss:  0.06422437  || Decoder Loss:  0.0398046 Validation Decoder Loss:  0.334352
Encoder Loss:  0.06244235  || Decoder Loss:  0.03327167 Validation Decoder Loss:  0.3458639
Encoder Loss:  0.05881027  || Decoder Loss:  0.03241288 Validation Decoder Loss:  0.34276894
Encoder Loss:  0.052167643  || Decoder Loss:  0.032368578 Validation Decoder Loss:  0.3409552
Encoder Loss:  0.053759802  || Decoder Loss:  0.032337498 Validation Decoder Loss:  0.3405447
Encoder Loss:  0.056534916  || Decoder Loss:  0.032442436 Validation Decoder Loss:  0.33619523
Encoder Loss:  0.05194449  || Decoder Loss:  0.03238651 Validation Decoder Loss:  0.34056625
Encoder Loss:  0.05529661  || Decoder Loss:  0.03236537 Validation Decoder Loss:  0.3421032
Encoder Loss:  0.05290112  || Decoder Loss:  0.032324232 Validation Decoder Loss:  0.3392399
Encoder Loss:  0.052464515  || Decoder Loss:  0.032310788 Validation Decoder Loss:  0.3417105
Encoder Loss:  0.052988533  || Decoder Loss:  0.032307807 Validation Decoder Loss:  0.3409625
Encoder Loss:  0.056678824  || Decoder Loss:  0.03246106 Validation Decoder Loss:  0.3398214
Encoder Loss:  0.053039085  || Decoder Loss:  0.032366365 Validation Decoder Loss:  0.33988392
Encoder Loss:  0.052813426  || Decoder Loss:  0.03235233 Validation Decoder Loss:  0.3404849
Encoder Loss:  0.05402124  || Decoder Loss:  0.032312986 Validation Decoder Loss:  0.34105378
Encoder Loss:  0.05268601  || Decoder Loss:  0.03227719 Validation Decoder Loss:  0.34127992
Encoder Loss:  0.051633626  || Decoder Loss:  0.032257557 Validation Decoder Loss:  0.34195045
Encoder Loss:  0.055426802  || Decoder Loss:  0.032406554 Validation Decoder Loss:  0.3410444
Encoder Loss:  0.058337413  || Decoder Loss:  0.032941554 Validation Decoder Loss:  0.34325063
Encoder Loss:  0.054145202  || Decoder Loss:  0.03236618 Validation Decoder Loss:  0.33913368
Encoder Loss:  0.05230366  || Decoder Loss:  0.032357473 Validation Decoder Loss:  0.3411463
Encoder Loss:  0.0512312  || Decoder Loss:  0.03222238 Validation Decoder Loss:  0.34164524
Encoder Loss:  0.053597216  || Decoder Loss:  0.032256782 Validation Decoder Loss:  0.3420084
Encoder Loss:  0.051978916  || Decoder Loss:  0.03223235 Validation Decoder Loss:  0.3423521
Encoder Loss:  0.053810712  || Decoder Loss:  0.03224776 Validation Decoder Loss:  0.34042993
Encoder Loss:  0.057815466  || Decoder Loss:  0.032413095 Validation Decoder Loss:  0.34510103
Encoder Loss:  0.05253821  || Decoder Loss:  0.032403454 Validation Decoder Loss:  0.3414749
Encoder Loss:  0.051637  || Decoder Loss:  0.03229723 Validation Decoder Loss:  0.34395054
Encoder Loss:  0.05238151  || Decoder Loss:  0.032223236 Validation Decoder Loss:  0.3427113
Encoder Loss:  0.052096084  || Decoder Loss:  0.03219571 Validation Decoder Loss:  0.34193993
Encoder Loss:  0.051946446  || Decoder Loss:  0.03221823 Validation Decoder Loss:  0.34420162
Encoder Loss:  0.05183877  || Decoder Loss:  0.03222181 Validation Decoder Loss:  0.3433404
Encoder Loss:  0.051370125  || Decoder Loss:  0.032152295 Validation Decoder Loss:  0.342626
Encoder Loss:  0.053089384  || Decoder Loss:  0.03226794 Validation Decoder Loss:  0.34382734
Encoder Loss:  0.053933393  || Decoder Loss:  0.032236975 Validation Decoder Loss:  0.34377813
Encoder Loss:  0.05524892  || Decoder Loss:  0.032313533 Validation Decoder Loss:  0.34319907
Encoder Loss:  0.053419713  || Decoder Loss:  0.0321822 Validation Decoder Loss:  0.34361568
Encoder Loss:  0.052161265  || Decoder Loss:  0.032173738 Validation Decoder Loss:  0.3436175
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3436175
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_188 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_432 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_189 (Conv3D (None, 634, 5, 20, 1)     279       
_________________________________________________________________
reshape_133 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 307
Trainable params: 307
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_428"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_434 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_436 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18564837  || Decoder Loss:  0.12528414 Validation Decoder Loss:  0.36470124
Encoder Loss:  0.1351916  || Decoder Loss:  0.1421913 Validation Decoder Loss:  0.63599956
Encoder Loss:  0.32320702  || Decoder Loss:  0.508055 Validation Decoder Loss:  0.57872367
Encoder Loss:  0.09828177  || Decoder Loss:  0.13102299 Validation Decoder Loss:  0.31713325
Encoder Loss:  0.043302167  || Decoder Loss:  0.038714997 Validation Decoder Loss:  0.33182234
Encoder Loss:  0.039882578  || Decoder Loss:  0.032989524 Validation Decoder Loss:  0.3393979
Encoder Loss:  0.03960139  || Decoder Loss:  0.03251938 Validation Decoder Loss:  0.3397357
Encoder Loss:  0.039575327  || Decoder Loss:  0.03247476 Validation Decoder Loss:  0.33984983
Encoder Loss:  0.039568428  || Decoder Loss:  0.03246325 Validation Decoder Loss:  0.3400126
Encoder Loss:  0.039563272  || Decoder Loss:  0.03245515 Validation Decoder Loss:  0.34007764
Encoder Loss:  0.039558917  || Decoder Loss:  0.032447685 Validation Decoder Loss:  0.34006637
Encoder Loss:  0.039554697  || Decoder Loss:  0.032440614 Validation Decoder Loss:  0.34006086
Encoder Loss:  0.039550588  || Decoder Loss:  0.032433785 Validation Decoder Loss:  0.3400731
Encoder Loss:  0.039546248  || Decoder Loss:  0.032427087 Validation Decoder Loss:  0.34007317
Encoder Loss:  0.039542064  || Decoder Loss:  0.032420367 Validation Decoder Loss:  0.3400793
Encoder Loss:  0.039537773  || Decoder Loss:  0.032413673 Validation Decoder Loss:  0.34008017
Encoder Loss:  0.039533384  || Decoder Loss:  0.032406893 Validation Decoder Loss:  0.3400725
Encoder Loss:  0.03952978  || Decoder Loss:  0.032400224 Validation Decoder Loss:  0.34009868
Encoder Loss:  0.039525356  || Decoder Loss:  0.032393727 Validation Decoder Loss:  0.34009582
Encoder Loss:  0.03952149  || Decoder Loss:  0.03238708 Validation Decoder Loss:  0.34011304
Encoder Loss:  0.039517246  || Decoder Loss:  0.032380447 Validation Decoder Loss:  0.34011668
Encoder Loss:  0.039513268  || Decoder Loss:  0.032373723 Validation Decoder Loss:  0.3401258
Encoder Loss:  0.03950904  || Decoder Loss:  0.032366995 Validation Decoder Loss:  0.34013185
Encoder Loss:  0.03950496  || Decoder Loss:  0.032360192 Validation Decoder Loss:  0.340141
Encoder Loss:  0.039500713  || Decoder Loss:  0.03235333 Validation Decoder Loss:  0.34014726
Encoder Loss:  0.039496683  || Decoder Loss:  0.032346413 Validation Decoder Loss:  0.34015846
Encoder Loss:  0.039492283  || Decoder Loss:  0.032339457 Validation Decoder Loss:  0.34016168
Encoder Loss:  0.03948821  || Decoder Loss:  0.032332417 Validation Decoder Loss:  0.3401785
Encoder Loss:  0.039483763  || Decoder Loss:  0.03232528 Validation Decoder Loss:  0.34018594
Encoder Loss:  0.03947951  || Decoder Loss:  0.032318007 Validation Decoder Loss:  0.34019664
Encoder Loss:  0.039474912  || Decoder Loss:  0.03231065 Validation Decoder Loss:  0.34020334
Encoder Loss:  0.039470598  || Decoder Loss:  0.03230319 Validation Decoder Loss:  0.340218
Encoder Loss:  0.039466113  || Decoder Loss:  0.03229565 Validation Decoder Loss:  0.3402312
Encoder Loss:  0.039461356  || Decoder Loss:  0.032287996 Validation Decoder Loss:  0.34024048
Encoder Loss:  0.03945668  || Decoder Loss:  0.032280196 Validation Decoder Loss:  0.34024853
Encoder Loss:  0.039451912  || Decoder Loss:  0.032272287 Validation Decoder Loss:  0.34025404
Encoder Loss:  0.039447255  || Decoder Loss:  0.03226428 Validation Decoder Loss:  0.34025794
Encoder Loss:  0.039442483  || Decoder Loss:  0.032256242 Validation Decoder Loss:  0.34025997
Encoder Loss:  0.03943762  || Decoder Loss:  0.03224813 Validation Decoder Loss:  0.34025675
Encoder Loss:  0.039432786  || Decoder Loss:  0.032239925 Validation Decoder Loss:  0.34024787
Model: siamese_net_lr_0.06102685060706449 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34024787
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_191 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_438 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_192 (Conv3D (None, 634, 5, 20, 1)     457       
_________________________________________________________________
reshape_134 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 485
Trainable params: 485
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_440 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_442 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42438954  || Decoder Loss:  0.47059035 Validation Decoder Loss:  0.8748356
Encoder Loss:  0.3564115  || Decoder Loss:  0.39458385 Validation Decoder Loss:  0.7602893
Encoder Loss:  0.29330188  || Decoder Loss:  0.32360128 Validation Decoder Loss:  0.66642463
Encoder Loss:  0.24361265  || Decoder Loss:  0.26768932 Validation Decoder Loss:  0.59872407
Encoder Loss:  0.20690511  || Decoder Loss:  0.22638261 Validation Decoder Loss:  0.55102754
Encoder Loss:  0.18009602  || Decoder Loss:  0.19622298 Validation Decoder Loss:  0.5169793
Encoder Loss:  0.16018452  || Decoder Loss:  0.17382377 Validation Decoder Loss:  0.4921236
Encoder Loss:  0.14496799  || Decoder Loss:  0.15670748 Validation Decoder Loss:  0.47343564
Encoder Loss:  0.13309477  || Decoder Loss:  0.1433499 Validation Decoder Loss:  0.4589894
Encoder Loss:  0.123536795  || Decoder Loss:  0.13259691 Validation Decoder Loss:  0.44743955
Encoder Loss:  0.11573367  || Decoder Loss:  0.123819634 Validation Decoder Loss:  0.43814176
Encoder Loss:  0.109235026  || Decoder Loss:  0.116508596 Validation Decoder Loss:  0.43049508
Encoder Loss:  0.103758745  || Decoder Loss:  0.11034806 Validation Decoder Loss:  0.42412525
Encoder Loss:  0.09906353  || Decoder Loss:  0.1050669 Validation Decoder Loss:  0.41871738
Encoder Loss:  0.095010385  || Decoder Loss:  0.100507796 Validation Decoder Loss:  0.41409695
Encoder Loss:  0.09147229  || Decoder Loss:  0.09652811 Validation Decoder Loss:  0.41014755
Encoder Loss:  0.08837165  || Decoder Loss:  0.09304151 Validation Decoder Loss:  0.40676463
Encoder Loss:  0.08563341  || Decoder Loss:  0.08996168 Validation Decoder Loss:  0.40379912
Encoder Loss:  0.08318758  || Decoder Loss:  0.08721089 Validation Decoder Loss:  0.40119743
Encoder Loss:  0.08099255  || Decoder Loss:  0.08474241 Validation Decoder Loss:  0.3989152
Encoder Loss:  0.07901881  || Decoder Loss:  0.08252266 Validation Decoder Loss:  0.3968767
Encoder Loss:  0.07722806  || Decoder Loss:  0.08050902 Validation Decoder Loss:  0.3950535
Encoder Loss:  0.07559472  || Decoder Loss:  0.07867259 Validation Decoder Loss:  0.39340934
Encoder Loss:  0.07410524  || Decoder Loss:  0.07699856 Validation Decoder Loss:  0.3919689
Encoder Loss:  0.07274495  || Decoder Loss:  0.0754685 Validation Decoder Loss:  0.39064965
Encoder Loss:  0.071497895  || Decoder Loss:  0.07406709 Validation Decoder Loss:  0.38949084
Encoder Loss:  0.07035442  || Decoder Loss:  0.07278201 Validation Decoder Loss:  0.38845953
Encoder Loss:  0.06930763  || Decoder Loss:  0.07160545 Validation Decoder Loss:  0.38755274
Encoder Loss:  0.06834505  || Decoder Loss:  0.07052367 Validation Decoder Loss:  0.38674575
Encoder Loss:  0.06745539  || Decoder Loss:  0.06952337 Validation Decoder Loss:  0.38601503
Encoder Loss:  0.06663015  || Decoder Loss:  0.0685961 Validation Decoder Loss:  0.38536593
Encoder Loss:  0.06586996  || Decoder Loss:  0.06774198 Validation Decoder Loss:  0.38478732
Encoder Loss:  0.065158986  || Decoder Loss:  0.06694347 Validation Decoder Loss:  0.38426024
Encoder Loss:  0.06450007  || Decoder Loss:  0.06620302 Validation Decoder Loss:  0.3838055
Encoder Loss:  0.06389103  || Decoder Loss:  0.06551938 Validation Decoder Loss:  0.3834297
Encoder Loss:  0.06333704  || Decoder Loss:  0.06489731 Validation Decoder Loss:  0.38309002
Encoder Loss:  0.0628069  || Decoder Loss:  0.06430194 Validation Decoder Loss:  0.38276014
Encoder Loss:  0.06230642  || Decoder Loss:  0.06374012 Validation Decoder Loss:  0.3824757
Encoder Loss:  0.06186058  || Decoder Loss:  0.06323943 Validation Decoder Loss:  0.3823018
Encoder Loss:  0.061441794  || Decoder Loss:  0.06276946 Validation Decoder Loss:  0.38208768
Model: siamese_net_lr_1e-05 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38208765
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_194 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_444 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_195 (Conv3D (None, 634, 5, 20, 1)     12        
_________________________________________________________________
reshape_135 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 40
Trainable params: 40
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_446 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_448 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19074653  || Decoder Loss:  0.12732139 Validation Decoder Loss:  0.3434183
Encoder Loss:  0.06369624  || Decoder Loss:  0.041232795 Validation Decoder Loss:  0.34614292
Encoder Loss:  0.052448735  || Decoder Loss:  0.035897385 Validation Decoder Loss:  0.34834573
Encoder Loss:  0.05035813  || Decoder Loss:  0.03516974 Validation Decoder Loss:  0.34711486
Encoder Loss:  0.05012006  || Decoder Loss:  0.03360684 Validation Decoder Loss:  0.345174
Encoder Loss:  0.050055124  || Decoder Loss:  0.03291188 Validation Decoder Loss:  0.34437385
Encoder Loss:  0.050025877  || Decoder Loss:  0.03267033 Validation Decoder Loss:  0.3439843
Encoder Loss:  0.050025787  || Decoder Loss:  0.03257126 Validation Decoder Loss:  0.343754
Encoder Loss:  0.05003726  || Decoder Loss:  0.03252471 Validation Decoder Loss:  0.34362584
Encoder Loss:  0.050036274  || Decoder Loss:  0.03249924 Validation Decoder Loss:  0.34354272
Encoder Loss:  0.05003197  || Decoder Loss:  0.032483123 Validation Decoder Loss:  0.34350434
Encoder Loss:  0.05003549  || Decoder Loss:  0.03246882 Validation Decoder Loss:  0.34348255
Encoder Loss:  0.050043672  || Decoder Loss:  0.03245441 Validation Decoder Loss:  0.34347633
Encoder Loss:  0.050059184  || Decoder Loss:  0.032438956 Validation Decoder Loss:  0.34349754
Encoder Loss:  0.050053462  || Decoder Loss:  0.032423094 Validation Decoder Loss:  0.34349734
Encoder Loss:  0.050062872  || Decoder Loss:  0.03240724 Validation Decoder Loss:  0.3435215
Encoder Loss:  0.050048485  || Decoder Loss:  0.03239332 Validation Decoder Loss:  0.34354252
Encoder Loss:  0.05005079  || Decoder Loss:  0.03238065 Validation Decoder Loss:  0.34358427
Encoder Loss:  0.050398286  || Decoder Loss:  0.032367524 Validation Decoder Loss:  0.34371734
Encoder Loss:  0.050672717  || Decoder Loss:  0.032356378 Validation Decoder Loss:  0.34365493
Encoder Loss:  0.05051592  || Decoder Loss:  0.03234509 Validation Decoder Loss:  0.34370863
Encoder Loss:  0.0508889  || Decoder Loss:  0.032337505 Validation Decoder Loss:  0.34357223
Encoder Loss:  0.053491723  || Decoder Loss:  0.032330755 Validation Decoder Loss:  0.3438797
Encoder Loss:  0.05297382  || Decoder Loss:  0.0323192 Validation Decoder Loss:  0.34393144
Encoder Loss:  0.051407922  || Decoder Loss:  0.032312453 Validation Decoder Loss:  0.3438772
Encoder Loss:  0.050148  || Decoder Loss:  0.032306187 Validation Decoder Loss:  0.34381238
Encoder Loss:  0.050047506  || Decoder Loss:  0.032299403 Validation Decoder Loss:  0.3438186
Encoder Loss:  0.05004379  || Decoder Loss:  0.032295953 Validation Decoder Loss:  0.3438469
Encoder Loss:  0.05005033  || Decoder Loss:  0.032290183 Validation Decoder Loss:  0.34381312
Encoder Loss:  0.05002756  || Decoder Loss:  0.03228497 Validation Decoder Loss:  0.34380674
Encoder Loss:  0.050071117  || Decoder Loss:  0.032279372 Validation Decoder Loss:  0.34378216
Encoder Loss:  0.05004559  || Decoder Loss:  0.032273978 Validation Decoder Loss:  0.34382248
Encoder Loss:  0.050130278  || Decoder Loss:  0.032268487 Validation Decoder Loss:  0.34377405
Encoder Loss:  0.050042983  || Decoder Loss:  0.032262146 Validation Decoder Loss:  0.34381452
Encoder Loss:  0.050025076  || Decoder Loss:  0.03225687 Validation Decoder Loss:  0.34380314
Encoder Loss:  0.050020963  || Decoder Loss:  0.03225125 Validation Decoder Loss:  0.34380955
Encoder Loss:  0.050082598  || Decoder Loss:  0.032245737 Validation Decoder Loss:  0.34380078
Encoder Loss:  0.05005194  || Decoder Loss:  0.032239072 Validation Decoder Loss:  0.34382105
Encoder Loss:  0.05001913  || Decoder Loss:  0.032232 Validation Decoder Loss:  0.34384412
Encoder Loss:  0.050021227  || Decoder Loss:  0.0322251 Validation Decoder Loss:  0.3438428
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34384286
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_197 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_450 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_198 (Conv3D (None, 634, 5, 20, 1)     380       
_________________________________________________________________
reshape_136 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 404
Trainable params: 404
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_452 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_454 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11927043  || Decoder Loss:  0.10824251 Validation Decoder Loss:  0.33170062
Encoder Loss:  0.05386443  || Decoder Loss:  0.03508485 Validation Decoder Loss:  0.3396086
Encoder Loss:  0.04864194  || Decoder Loss:  0.033213474 Validation Decoder Loss:  0.34221232
Encoder Loss:  0.04747513  || Decoder Loss:  0.03305925 Validation Decoder Loss:  0.3440529
Encoder Loss:  0.047263082  || Decoder Loss:  0.033005252 Validation Decoder Loss:  0.3439393
Encoder Loss:  0.046951156  || Decoder Loss:  0.032959167 Validation Decoder Loss:  0.34371388
Encoder Loss:  0.048139516  || Decoder Loss:  0.032922033 Validation Decoder Loss:  0.343672
Encoder Loss:  0.046981536  || Decoder Loss:  0.032880396 Validation Decoder Loss:  0.34374404
Encoder Loss:  0.04659925  || Decoder Loss:  0.03285585 Validation Decoder Loss:  0.3438664
Encoder Loss:  0.04660627  || Decoder Loss:  0.032830354 Validation Decoder Loss:  0.3437643
Encoder Loss:  0.046615306  || Decoder Loss:  0.03280297 Validation Decoder Loss:  0.34376326
Encoder Loss:  0.046406854  || Decoder Loss:  0.032777444 Validation Decoder Loss:  0.34392968
Encoder Loss:  0.046356842  || Decoder Loss:  0.032758668 Validation Decoder Loss:  0.34402025
Encoder Loss:  0.04639708  || Decoder Loss:  0.032739613 Validation Decoder Loss:  0.34404168
Encoder Loss:  0.04634624  || Decoder Loss:  0.0327202 Validation Decoder Loss:  0.34424034
Encoder Loss:  0.04625187  || Decoder Loss:  0.032709576 Validation Decoder Loss:  0.34463537
Encoder Loss:  0.046205603  || Decoder Loss:  0.03269528 Validation Decoder Loss:  0.3446219
Encoder Loss:  0.046187054  || Decoder Loss:  0.032677814 Validation Decoder Loss:  0.34462428
Encoder Loss:  0.04617351  || Decoder Loss:  0.032660928 Validation Decoder Loss:  0.34459656
Encoder Loss:  0.046164755  || Decoder Loss:  0.032645024 Validation Decoder Loss:  0.34457555
Encoder Loss:  0.046154175  || Decoder Loss:  0.03262996 Validation Decoder Loss:  0.3445419
Encoder Loss:  0.04614728  || Decoder Loss:  0.032615248 Validation Decoder Loss:  0.34447697
Encoder Loss:  0.04613732  || Decoder Loss:  0.03260067 Validation Decoder Loss:  0.34437817
Encoder Loss:  0.046133865  || Decoder Loss:  0.032586243 Validation Decoder Loss:  0.3442117
Encoder Loss:  0.04612149  || Decoder Loss:  0.032571867 Validation Decoder Loss:  0.34404424
Encoder Loss:  0.04610853  || Decoder Loss:  0.03255855 Validation Decoder Loss:  0.34389877
Encoder Loss:  0.04609632  || Decoder Loss:  0.032546062 Validation Decoder Loss:  0.34377828
Encoder Loss:  0.04608449  || Decoder Loss:  0.032534476 Validation Decoder Loss:  0.34369874
Encoder Loss:  0.046074156  || Decoder Loss:  0.032523595 Validation Decoder Loss:  0.34365848
Encoder Loss:  0.04606683  || Decoder Loss:  0.032513097 Validation Decoder Loss:  0.34361058
Encoder Loss:  0.04606101  || Decoder Loss:  0.03250257 Validation Decoder Loss:  0.3435066
Encoder Loss:  0.046049666  || Decoder Loss:  0.03249248 Validation Decoder Loss:  0.34341535
Encoder Loss:  0.046047017  || Decoder Loss:  0.032482404 Validation Decoder Loss:  0.34325445
Encoder Loss:  0.046034884  || Decoder Loss:  0.03247211 Validation Decoder Loss:  0.34312093
Encoder Loss:  0.046026874  || Decoder Loss:  0.032462955 Validation Decoder Loss:  0.34301484
Encoder Loss:  0.046027016  || Decoder Loss:  0.032454256 Validation Decoder Loss:  0.34286729
Encoder Loss:  0.046012584  || Decoder Loss:  0.032445613 Validation Decoder Loss:  0.34277323
Encoder Loss:  0.046008684  || Decoder Loss:  0.032437313 Validation Decoder Loss:  0.34266225
Encoder Loss:  0.04599801  || Decoder Loss:  0.032429352 Validation Decoder Loss:  0.34256297
Encoder Loss:  0.04599508  || Decoder Loss:  0.03242175 Validation Decoder Loss:  0.34245807
Model: siamese_net_lr_0.0066274923159888146 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34245807
Model: "sequential_442"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_200 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_456 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_201 (Conv3D (None, 634, 5, 20, 1)     12        
_________________________________________________________________
reshape_137 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 40
Trainable params: 40
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_444"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_458 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_445"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_460 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07104183  || Decoder Loss:  0.068774976 Validation Decoder Loss:  0.673193
Encoder Loss:  0.06306448  || Decoder Loss:  0.0628338 Validation Decoder Loss:  0.35722607
Encoder Loss:  0.035106506  || Decoder Loss:  0.03457273 Validation Decoder Loss:  0.34605014
Encoder Loss:  0.033205334  || Decoder Loss:  0.03263934 Validation Decoder Loss:  0.34362346
Encoder Loss:  0.032852355  || Decoder Loss:  0.032328002 Validation Decoder Loss:  0.34264547
Encoder Loss:  0.032776315  || Decoder Loss:  0.032224726 Validation Decoder Loss:  0.3421662
Encoder Loss:  0.03271821  || Decoder Loss:  0.032175396 Validation Decoder Loss:  0.3419702
Encoder Loss:  0.032734618  || Decoder Loss:  0.032146152 Validation Decoder Loss:  0.341793
Encoder Loss:  0.03270206  || Decoder Loss:  0.03212588 Validation Decoder Loss:  0.34168988
Encoder Loss:  0.03266089  || Decoder Loss:  0.032107577 Validation Decoder Loss:  0.34164047
Encoder Loss:  0.032617338  || Decoder Loss:  0.032092225 Validation Decoder Loss:  0.34168553
Encoder Loss:  0.032647096  || Decoder Loss:  0.03207694 Validation Decoder Loss:  0.34167165
Encoder Loss:  0.032647155  || Decoder Loss:  0.032067724 Validation Decoder Loss:  0.341677
Encoder Loss:  0.03263332  || Decoder Loss:  0.032058228 Validation Decoder Loss:  0.3416598
Encoder Loss:  0.032608453  || Decoder Loss:  0.032049183 Validation Decoder Loss:  0.3417007
Encoder Loss:  0.03258851  || Decoder Loss:  0.032043144 Validation Decoder Loss:  0.34178692
Encoder Loss:  0.03258142  || Decoder Loss:  0.032035414 Validation Decoder Loss:  0.3418616
Encoder Loss:  0.03259803  || Decoder Loss:  0.032032847 Validation Decoder Loss:  0.34195665
Encoder Loss:  0.032552876  || Decoder Loss:  0.0320287 Validation Decoder Loss:  0.34207925
Encoder Loss:  0.032627568  || Decoder Loss:  0.032028332 Validation Decoder Loss:  0.3421479
Encoder Loss:  0.032576833  || Decoder Loss:  0.03202477 Validation Decoder Loss:  0.34212
Encoder Loss:  0.03257229  || Decoder Loss:  0.03201921 Validation Decoder Loss:  0.3421138
Encoder Loss:  0.03256498  || Decoder Loss:  0.032013293 Validation Decoder Loss:  0.34211498
Encoder Loss:  0.032558724  || Decoder Loss:  0.03200701 Validation Decoder Loss:  0.34213218
Encoder Loss:  0.032523967  || Decoder Loss:  0.0320008 Validation Decoder Loss:  0.34218717
Encoder Loss:  0.032544456  || Decoder Loss:  0.031996988 Validation Decoder Loss:  0.3422945
Encoder Loss:  0.03257181  || Decoder Loss:  0.03199425 Validation Decoder Loss:  0.34230876
Encoder Loss:  0.03254129  || Decoder Loss:  0.03198954 Validation Decoder Loss:  0.34234402
Encoder Loss:  0.032532517  || Decoder Loss:  0.031983033 Validation Decoder Loss:  0.34239537
Encoder Loss:  0.032539055  || Decoder Loss:  0.031976968 Validation Decoder Loss:  0.34247482
Encoder Loss:  0.03252153  || Decoder Loss:  0.031969655 Validation Decoder Loss:  0.34256428
Encoder Loss:  0.032509346  || Decoder Loss:  0.031963214 Validation Decoder Loss:  0.34256303
Encoder Loss:  0.032490216  || Decoder Loss:  0.03195614 Validation Decoder Loss:  0.34267318
Encoder Loss:  0.032510873  || Decoder Loss:  0.03195084 Validation Decoder Loss:  0.34267616
Encoder Loss:  0.03257108  || Decoder Loss:  0.031940416 Validation Decoder Loss:  0.34283173
Encoder Loss:  0.03247605  || Decoder Loss:  0.03192902 Validation Decoder Loss:  0.34289432
Encoder Loss:  0.032469496  || Decoder Loss:  0.03191777 Validation Decoder Loss:  0.3429884
Encoder Loss:  0.032483052  || Decoder Loss:  0.03190743 Validation Decoder Loss:  0.34300143
Encoder Loss:  0.03245128  || Decoder Loss:  0.031899646 Validation Decoder Loss:  0.3429379
Encoder Loss:  0.032539416  || Decoder Loss:  0.031916767 Validation Decoder Loss:  0.3431519
Model: siamese_net_lr_0.047978882405602254 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34315193
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_203 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_462 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_204 (Conv3D (None, 634, 5, 20, 1)     271       
_________________________________________________________________
reshape_138 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 3190, 20, 1)       57        
_________________________________________________________________
dropout_464 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 3170, 20, 1)       22        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_449"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_466 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36290902  || Decoder Loss:  0.63677 Validation Decoder Loss:  1.1981221
Encoder Loss:  0.22898488  || Decoder Loss:  0.52635354 Validation Decoder Loss:  1.014582
Encoder Loss:  0.2167073  || Decoder Loss:  0.4966067 Validation Decoder Loss:  1.0000314
Encoder Loss:  0.21858905  || Decoder Loss:  0.4957933 Validation Decoder Loss:  1.0290496
Encoder Loss:  0.21757786  || Decoder Loss:  0.49713516 Validation Decoder Loss:  1.0035105
Encoder Loss:  0.21586297  || Decoder Loss:  0.49526313 Validation Decoder Loss:  1.0019851
Encoder Loss:  0.21598195  || Decoder Loss:  0.4951589 Validation Decoder Loss:  1.0027689
Encoder Loss:  0.21542631  || Decoder Loss:  0.49503267 Validation Decoder Loss:  1.0027502
Encoder Loss:  0.21583953  || Decoder Loss:  0.4949776 Validation Decoder Loss:  1.0009141
Encoder Loss:  0.2157195  || Decoder Loss:  0.494393 Validation Decoder Loss:  0.9999812
Encoder Loss:  0.21558017  || Decoder Loss:  0.4941871 Validation Decoder Loss:  0.9985754
Encoder Loss:  0.21491759  || Decoder Loss:  0.49398246 Validation Decoder Loss:  1.003963
Encoder Loss:  0.21615122  || Decoder Loss:  0.49411306 Validation Decoder Loss:  1.0038241
Encoder Loss:  0.21522537  || Decoder Loss:  0.49361983 Validation Decoder Loss:  1.0034866
Encoder Loss:  0.2161387  || Decoder Loss:  0.49337777 Validation Decoder Loss:  0.9916435
Encoder Loss:  0.21441002  || Decoder Loss:  0.4924759 Validation Decoder Loss:  0.99963677
Encoder Loss:  0.21596695  || Decoder Loss:  0.49313217 Validation Decoder Loss:  0.9748702
Encoder Loss:  0.21710616  || Decoder Loss:  0.48925838 Validation Decoder Loss:  1.0090575
Encoder Loss:  0.21374026  || Decoder Loss:  0.4906566 Validation Decoder Loss:  0.9703233
Encoder Loss:  0.2128513  || Decoder Loss:  0.48674956 Validation Decoder Loss:  0.9968426
Encoder Loss:  0.2059591  || Decoder Loss:  0.46625113 Validation Decoder Loss:  1.1616318
Encoder Loss:  0.2212768  || Decoder Loss:  0.50563204 Validation Decoder Loss:  0.9818075
Encoder Loss:  0.21667847  || Decoder Loss:  0.49497786 Validation Decoder Loss:  0.95773864
Encoder Loss:  0.21402732  || Decoder Loss:  0.49207997 Validation Decoder Loss:  0.9688553
Encoder Loss:  0.2142776  || Decoder Loss:  0.48964477 Validation Decoder Loss:  1.0205361
Encoder Loss:  0.2136813  || Decoder Loss:  0.4887222 Validation Decoder Loss:  0.9995917
Encoder Loss:  0.21243484  || Decoder Loss:  0.48632365 Validation Decoder Loss:  0.98630273
Encoder Loss:  0.21667923  || Decoder Loss:  0.49361798 Validation Decoder Loss:  0.93505347
Encoder Loss:  0.21509175  || Decoder Loss:  0.48807895 Validation Decoder Loss:  0.9976183
Encoder Loss:  0.21265323  || Decoder Loss:  0.48571625 Validation Decoder Loss:  0.98843694
Encoder Loss:  0.21568185  || Decoder Loss:  0.49424443 Validation Decoder Loss:  0.9933293
Encoder Loss:  0.21520166  || Decoder Loss:  0.49334365 Validation Decoder Loss:  0.9945057
Encoder Loss:  0.21511164  || Decoder Loss:  0.49316588 Validation Decoder Loss:  0.9948936
Encoder Loss:  0.21485065  || Decoder Loss:  0.4925097 Validation Decoder Loss:  0.9951963
Encoder Loss:  0.21461056  || Decoder Loss:  0.49192512 Validation Decoder Loss:  0.99767745
Encoder Loss:  0.21584189  || Decoder Loss:  0.4912594 Validation Decoder Loss:  0.9867656
Encoder Loss:  0.21529835  || Decoder Loss:  0.48993683 Validation Decoder Loss:  1.0003524
Encoder Loss:  0.21359082  || Decoder Loss:  0.4897882 Validation Decoder Loss:  0.99481374
Encoder Loss:  0.21215302  || Decoder Loss:  0.48603642 Validation Decoder Loss:  0.994335
Encoder Loss:  0.20527641  || Decoder Loss:  0.46942177 Validation Decoder Loss:  0.99055743
Model: siamese_net_lr_0.09593945190109894 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99055743
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_206 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_468 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_207 (Conv3D (None, 634, 5, 20, 1)     544       
_________________________________________________________________
reshape_139 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_470 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_472 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05646923  || Decoder Loss:  0.05673916 Validation Decoder Loss:  0.35225898
Encoder Loss:  0.039824013  || Decoder Loss:  0.0330157 Validation Decoder Loss:  0.34044278
Encoder Loss:  0.039518207  || Decoder Loss:  0.03258769 Validation Decoder Loss:  0.34206104
Encoder Loss:  0.039424647  || Decoder Loss:  0.032505225 Validation Decoder Loss:  0.34419551
Encoder Loss:  0.03939148  || Decoder Loss:  0.032462846 Validation Decoder Loss:  0.3427036
Encoder Loss:  0.039375514  || Decoder Loss:  0.032439657 Validation Decoder Loss:  0.3409617
Encoder Loss:  0.039368782  || Decoder Loss:  0.032429162 Validation Decoder Loss:  0.3391816
Encoder Loss:  0.039365184  || Decoder Loss:  0.032428045 Validation Decoder Loss:  0.3371573
Encoder Loss:  0.039370403  || Decoder Loss:  0.03243396 Validation Decoder Loss:  0.33611694
Encoder Loss:  0.039366983  || Decoder Loss:  0.032433864 Validation Decoder Loss:  0.3359344
Encoder Loss:  0.03936242  || Decoder Loss:  0.032425713 Validation Decoder Loss:  0.33605653
Encoder Loss:  0.039353136  || Decoder Loss:  0.032413714 Validation Decoder Loss:  0.33618402
Encoder Loss:  0.039345574  || Decoder Loss:  0.032401517 Validation Decoder Loss:  0.33621475
Encoder Loss:  0.039343406  || Decoder Loss:  0.032390215 Validation Decoder Loss:  0.3362641
Encoder Loss:  0.03937618  || Decoder Loss:  0.032385804 Validation Decoder Loss:  0.33719355
Encoder Loss:  0.039336238  || Decoder Loss:  0.032387454 Validation Decoder Loss:  0.338353
Encoder Loss:  0.039332576  || Decoder Loss:  0.0323772 Validation Decoder Loss:  0.3387835
Encoder Loss:  0.039325453  || Decoder Loss:  0.03236485 Validation Decoder Loss:  0.33924565
Encoder Loss:  0.039316215  || Decoder Loss:  0.032352284 Validation Decoder Loss:  0.34012735
Encoder Loss:  0.03931102  || Decoder Loss:  0.032338824 Validation Decoder Loss:  0.34106228
Encoder Loss:  0.03930463  || Decoder Loss:  0.032322623 Validation Decoder Loss:  0.3425477
Encoder Loss:  0.03928618  || Decoder Loss:  0.03230355 Validation Decoder Loss:  0.34412807
Encoder Loss:  0.039273072  || Decoder Loss:  0.032280896 Validation Decoder Loss:  0.34447956
Encoder Loss:  0.039264318  || Decoder Loss:  0.03226587 Validation Decoder Loss:  0.3445819
Encoder Loss:  0.039257675  || Decoder Loss:  0.032253493 Validation Decoder Loss:  0.34452352
Encoder Loss:  0.03924937  || Decoder Loss:  0.032242987 Validation Decoder Loss:  0.34425437
Encoder Loss:  0.03924415  || Decoder Loss:  0.032235976 Validation Decoder Loss:  0.34409815
Encoder Loss:  0.039240465  || Decoder Loss:  0.03222996 Validation Decoder Loss:  0.34388438
Encoder Loss:  0.039242372  || Decoder Loss:  0.032224856 Validation Decoder Loss:  0.34364712
Encoder Loss:  0.03923621  || Decoder Loss:  0.032220725 Validation Decoder Loss:  0.3433078
Encoder Loss:  0.03923062  || Decoder Loss:  0.032215964 Validation Decoder Loss:  0.3430333
Encoder Loss:  0.039233327  || Decoder Loss:  0.032211408 Validation Decoder Loss:  0.34273738
Encoder Loss:  0.039227746  || Decoder Loss:  0.032208703 Validation Decoder Loss:  0.34257132
Encoder Loss:  0.03923818  || Decoder Loss:  0.032207273 Validation Decoder Loss:  0.3427043
Encoder Loss:  0.039233595  || Decoder Loss:  0.032210328 Validation Decoder Loss:  0.34265983
Encoder Loss:  0.039227415  || Decoder Loss:  0.03221121 Validation Decoder Loss:  0.3425879
Encoder Loss:  0.039228268  || Decoder Loss:  0.032208756 Validation Decoder Loss:  0.34245455
Encoder Loss:  0.03922382  || Decoder Loss:  0.03220707 Validation Decoder Loss:  0.34235758
Encoder Loss:  0.03922527  || Decoder Loss:  0.03220551 Validation Decoder Loss:  0.34225053
Encoder Loss:  0.039223332  || Decoder Loss:  0.03220371 Validation Decoder Loss:  0.34211847
Model: siamese_net_lr_0.004456267587540862 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3421185
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_209 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_474 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_210 (Conv3D (None, 634, 5, 20, 1)     89        
_________________________________________________________________
reshape_140 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 3190, 20, 1)       57        
_________________________________________________________________
dropout_476 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 3170, 20, 1)       22        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_457"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 3220, 20, 1)       52        
_________________________________________________________________
dropout_478 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 3245, 20, 1)       27        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3211017  || Decoder Loss:  0.1541544 Validation Decoder Loss:  0.35703677
Encoder Loss:  0.17881909  || Decoder Loss:  0.4056922 Validation Decoder Loss:  1.5725079
Encoder Loss:  0.14851384  || Decoder Loss:  0.5277327 Validation Decoder Loss:  0.8946656
Encoder Loss:  0.13636892  || Decoder Loss:  0.49090862 Validation Decoder Loss:  0.9328886
Encoder Loss:  0.13747391  || Decoder Loss:  0.49498427 Validation Decoder Loss:  0.94472635
Encoder Loss:  0.13632052  || Decoder Loss:  0.4937092 Validation Decoder Loss:  0.9022
Encoder Loss:  0.13090697  || Decoder Loss:  0.46600828 Validation Decoder Loss:  0.7956755
Encoder Loss:  0.1259092  || Decoder Loss:  0.44226065 Validation Decoder Loss:  0.79364365
Encoder Loss:  0.09263775  || Decoder Loss:  0.26291916 Validation Decoder Loss:  0.43849245
Encoder Loss:  0.059148084  || Decoder Loss:  0.09334144 Validation Decoder Loss:  0.35130924
Encoder Loss:  0.049136262  || Decoder Loss:  0.035361864 Validation Decoder Loss:  0.34500268
Encoder Loss:  0.04750151  || Decoder Loss:  0.032424197 Validation Decoder Loss:  0.34298623
Encoder Loss:  0.047464922  || Decoder Loss:  0.032241903 Validation Decoder Loss:  0.34257174
Encoder Loss:  0.048052385  || Decoder Loss:  0.032211028 Validation Decoder Loss:  0.34367713
Encoder Loss:  0.049523126  || Decoder Loss:  0.03228622 Validation Decoder Loss:  0.34431088
Encoder Loss:  0.052353736  || Decoder Loss:  0.033450082 Validation Decoder Loss:  0.35865775
Encoder Loss:  0.04999886  || Decoder Loss:  0.03540808 Validation Decoder Loss:  0.34331906
Encoder Loss:  0.048617095  || Decoder Loss:  0.03286943 Validation Decoder Loss:  0.34240872
Encoder Loss:  0.048224397  || Decoder Loss:  0.032313574 Validation Decoder Loss:  0.34385774
Encoder Loss:  0.04930942  || Decoder Loss:  0.032580927 Validation Decoder Loss:  0.34303498
Encoder Loss:  0.04805602  || Decoder Loss:  0.032506146 Validation Decoder Loss:  0.34308606
Encoder Loss:  0.048045807  || Decoder Loss:  0.032419268 Validation Decoder Loss:  0.34445554
Encoder Loss:  0.049261257  || Decoder Loss:  0.032311957 Validation Decoder Loss:  0.34324875
Encoder Loss:  0.04736178  || Decoder Loss:  0.032245312 Validation Decoder Loss:  0.34339276
Encoder Loss:  0.04799973  || Decoder Loss:  0.032893628 Validation Decoder Loss:  0.34764028
Encoder Loss:  0.049545623  || Decoder Loss:  0.03287137 Validation Decoder Loss:  0.34947366
Encoder Loss:  0.05494508  || Decoder Loss:  0.048453495 Validation Decoder Loss:  0.43191826
Encoder Loss:  0.12542443  || Decoder Loss:  0.42950258 Validation Decoder Loss:  1.5577376
Encoder Loss:  0.14825986  || Decoder Loss:  0.5479009 Validation Decoder Loss:  1.0142615
Encoder Loss:  0.13799542  || Decoder Loss:  0.49656287 Validation Decoder Loss:  0.9970293
Encoder Loss:  0.13694486  || Decoder Loss:  0.49959037 Validation Decoder Loss:  1.009468
Encoder Loss:  0.13601321  || Decoder Loss:  0.49711183 Validation Decoder Loss:  0.99630654
Encoder Loss:  0.13673115  || Decoder Loss:  0.5002837 Validation Decoder Loss:  1.0346508
Encoder Loss:  0.13837773  || Decoder Loss:  0.5072704 Validation Decoder Loss:  1.0000858
Encoder Loss:  0.13674206  || Decoder Loss:  0.49991038 Validation Decoder Loss:  1.0080924
Encoder Loss:  0.13663922  || Decoder Loss:  0.49866763 Validation Decoder Loss:  1.005803
Encoder Loss:  0.1357955  || Decoder Loss:  0.49731025 Validation Decoder Loss:  1.0011499
Encoder Loss:  0.13601835  || Decoder Loss:  0.49884567 Validation Decoder Loss:  1.0052693
Encoder Loss:  0.13585627  || Decoder Loss:  0.4973384 Validation Decoder Loss:  1.0079081
Encoder Loss:  0.13552362  || Decoder Loss:  0.49586502 Validation Decoder Loss:  1.013089
Model: siamese_net_lr_0.09871564874243619 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.013089
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_212 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_480 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_213 (Conv3D (None, 634, 5, 20, 1)     170       
_________________________________________________________________
reshape_141 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_482 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_461"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_484 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33936164  || Decoder Loss:  0.10519502 Validation Decoder Loss:  0.37158763
Encoder Loss:  0.21362093  || Decoder Loss:  0.294252 Validation Decoder Loss:  1.6109207
Encoder Loss:  0.1041454  || Decoder Loss:  0.43940845 Validation Decoder Loss:  0.4554496
Encoder Loss:  0.054694027  || Decoder Loss:  0.07187762 Validation Decoder Loss:  0.32201016
Encoder Loss:  0.051363144  || Decoder Loss:  0.036094937 Validation Decoder Loss:  0.35537106
Encoder Loss:  0.050499693  || Decoder Loss:  0.032784943 Validation Decoder Loss:  0.33559465
Encoder Loss:  0.050441753  || Decoder Loss:  0.032461002 Validation Decoder Loss:  0.3390837
Encoder Loss:  0.05159617  || Decoder Loss:  0.032435864 Validation Decoder Loss:  0.3404863
Encoder Loss:  0.05091407  || Decoder Loss:  0.03241899 Validation Decoder Loss:  0.33934775
Encoder Loss:  0.051584005  || Decoder Loss:  0.03240733 Validation Decoder Loss:  0.33937937
Encoder Loss:  0.05071589  || Decoder Loss:  0.03240234 Validation Decoder Loss:  0.33838338
Encoder Loss:  0.053035304  || Decoder Loss:  0.032412678 Validation Decoder Loss:  0.33817023
Encoder Loss:  0.05094049  || Decoder Loss:  0.032388486 Validation Decoder Loss:  0.33899388
Encoder Loss:  0.050672803  || Decoder Loss:  0.03238232 Validation Decoder Loss:  0.33856744
Encoder Loss:  0.0505132  || Decoder Loss:  0.03237855 Validation Decoder Loss:  0.33866507
Encoder Loss:  0.049778633  || Decoder Loss:  0.03236605 Validation Decoder Loss:  0.3383214
Encoder Loss:  0.05051073  || Decoder Loss:  0.032365333 Validation Decoder Loss:  0.33809692
Encoder Loss:  0.05233899  || Decoder Loss:  0.032389775 Validation Decoder Loss:  0.33558512
Encoder Loss:  0.056407742  || Decoder Loss:  0.032567214 Validation Decoder Loss:  0.32966757
Encoder Loss:  0.052272607  || Decoder Loss:  0.03255809 Validation Decoder Loss:  0.33876467
Encoder Loss:  0.04975625  || Decoder Loss:  0.032358613 Validation Decoder Loss:  0.33883473
Encoder Loss:  0.05044052  || Decoder Loss:  0.032349363 Validation Decoder Loss:  0.33844274
Encoder Loss:  0.050526544  || Decoder Loss:  0.032350108 Validation Decoder Loss:  0.33844295
Encoder Loss:  0.05041412  || Decoder Loss:  0.03235121 Validation Decoder Loss:  0.337505
Encoder Loss:  0.051369924  || Decoder Loss:  0.03235593 Validation Decoder Loss:  0.3375185
Encoder Loss:  0.05127121  || Decoder Loss:  0.03235153 Validation Decoder Loss:  0.3378424
Encoder Loss:  0.050449457  || Decoder Loss:  0.032339144 Validation Decoder Loss:  0.3402154
Encoder Loss:  0.0505721  || Decoder Loss:  0.032343112 Validation Decoder Loss:  0.33850664
Encoder Loss:  0.050670873  || Decoder Loss:  0.03233285 Validation Decoder Loss:  0.33902684
Encoder Loss:  0.052244667  || Decoder Loss:  0.03235767 Validation Decoder Loss:  0.3353336
Encoder Loss:  0.050583836  || Decoder Loss:  0.032367814 Validation Decoder Loss:  0.3398617
Encoder Loss:  0.05237319  || Decoder Loss:  0.032385334 Validation Decoder Loss:  0.33914602
Encoder Loss:  0.052157335  || Decoder Loss:  0.0324837 Validation Decoder Loss:  0.34256592
Encoder Loss:  0.050865855  || Decoder Loss:  0.03242049 Validation Decoder Loss:  0.33848062
Encoder Loss:  0.050904937  || Decoder Loss:  0.032370128 Validation Decoder Loss:  0.33691406
Encoder Loss:  0.049421053  || Decoder Loss:  0.03231286 Validation Decoder Loss:  0.33872446
Encoder Loss:  0.049434904  || Decoder Loss:  0.032300018 Validation Decoder Loss:  0.338919
Encoder Loss:  0.05173447  || Decoder Loss:  0.032364827 Validation Decoder Loss:  0.34359303
Encoder Loss:  0.052260548  || Decoder Loss:  0.03249982 Validation Decoder Loss:  0.3442818
Encoder Loss:  0.049371067  || Decoder Loss:  0.032432348 Validation Decoder Loss:  0.3377219
Model: siamese_net_lr_0.04467880261140018 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3377219
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_215 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_486 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_216 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_142 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_488 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_465"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_490 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41339007  || Decoder Loss:  0.67080927 Validation Decoder Loss:  0.95375293
Encoder Loss:  0.24712637  || Decoder Loss:  0.49565542 Validation Decoder Loss:  1.189243
Encoder Loss:  0.24140093  || Decoder Loss:  0.49960315 Validation Decoder Loss:  0.78190625
Encoder Loss:  0.2388243  || Decoder Loss:  0.49483478 Validation Decoder Loss:  0.7748933
Encoder Loss:  0.23930319  || Decoder Loss:  0.49395794 Validation Decoder Loss:  0.78934234
Encoder Loss:  0.23975591  || Decoder Loss:  0.4955592 Validation Decoder Loss:  0.7788454
Encoder Loss:  0.23588543  || Decoder Loss:  0.48467907 Validation Decoder Loss:  0.79079926
Encoder Loss:  0.23977776  || Decoder Loss:  0.4946585 Validation Decoder Loss:  1.1674415
Encoder Loss:  0.24113698  || Decoder Loss:  0.49920195 Validation Decoder Loss:  1.2020746
Encoder Loss:  0.24205598  || Decoder Loss:  0.49505395 Validation Decoder Loss:  1.111201
Encoder Loss:  0.24464947  || Decoder Loss:  0.5020937 Validation Decoder Loss:  1.1701721
Encoder Loss:  0.23966157  || Decoder Loss:  0.49538758 Validation Decoder Loss:  1.1670415
Encoder Loss:  0.24078125  || Decoder Loss:  0.4981492 Validation Decoder Loss:  1.1657921
Encoder Loss:  0.24010666  || Decoder Loss:  0.4958759 Validation Decoder Loss:  1.1152167
Encoder Loss:  0.23974662  || Decoder Loss:  0.49583665 Validation Decoder Loss:  1.0844042
Encoder Loss:  0.24053122  || Decoder Loss:  0.49771512 Validation Decoder Loss:  1.1081698
Encoder Loss:  0.23936844  || Decoder Loss:  0.4958745 Validation Decoder Loss:  1.1319866
Encoder Loss:  0.2411759  || Decoder Loss:  0.49538395 Validation Decoder Loss:  1.075949
Encoder Loss:  0.24306211  || Decoder Loss:  0.5001825 Validation Decoder Loss:  1.1321619
Encoder Loss:  0.23886497  || Decoder Loss:  0.49506137 Validation Decoder Loss:  1.090503
Encoder Loss:  0.23858003  || Decoder Loss:  0.49556744 Validation Decoder Loss:  1.0348296
Encoder Loss:  0.23791867  || Decoder Loss:  0.4929041 Validation Decoder Loss:  1.1017631
Encoder Loss:  0.23849621  || Decoder Loss:  0.4941168 Validation Decoder Loss:  1.080106
Encoder Loss:  0.2378484  || Decoder Loss:  0.4928811 Validation Decoder Loss:  1.0544858
Encoder Loss:  0.23831367  || Decoder Loss:  0.49368697 Validation Decoder Loss:  1.0868474
Encoder Loss:  0.23844998  || Decoder Loss:  0.49414662 Validation Decoder Loss:  1.0603416
Encoder Loss:  0.23700333  || Decoder Loss:  0.49111548 Validation Decoder Loss:  1.0525225
Encoder Loss:  0.23558812  || Decoder Loss:  0.48864993 Validation Decoder Loss:  0.9746869
Encoder Loss:  0.24031612  || Decoder Loss:  0.49582675 Validation Decoder Loss:  0.98597884
Encoder Loss:  0.2391943  || Decoder Loss:  0.48818997 Validation Decoder Loss:  0.97057205
Encoder Loss:  0.23785685  || Decoder Loss:  0.49309972 Validation Decoder Loss:  1.0273075
Encoder Loss:  0.22932217  || Decoder Loss:  0.472766 Validation Decoder Loss:  1.0660745
Encoder Loss:  0.23945002  || Decoder Loss:  0.4960439 Validation Decoder Loss:  1.064168
Encoder Loss:  0.2387228  || Decoder Loss:  0.49638474 Validation Decoder Loss:  1.032026
Encoder Loss:  0.23825897  || Decoder Loss:  0.4953264 Validation Decoder Loss:  1.0819932
Encoder Loss:  0.2392339  || Decoder Loss:  0.49707317 Validation Decoder Loss:  0.99885136
Encoder Loss:  0.23149338  || Decoder Loss:  0.4746849 Validation Decoder Loss:  0.85201675
Encoder Loss:  0.23768194  || Decoder Loss:  0.4914455 Validation Decoder Loss:  0.9979525
Encoder Loss:  0.23778513  || Decoder Loss:  0.4925603 Validation Decoder Loss:  0.9634377
Encoder Loss:  0.23283565  || Decoder Loss:  0.48158658 Validation Decoder Loss:  0.89036214
Model: siamese_net_lr_0.0713489853702829 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.89036214
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_218 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_492 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_219 (Conv3D (None, 634, 5, 20, 1)     493       
_________________________________________________________________
reshape_143 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 503
Trainable params: 503
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_494 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_469"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_496 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33524713  || Decoder Loss:  0.23080301 Validation Decoder Loss:  0.43666685
Encoder Loss:  0.27864894  || Decoder Loss:  0.22172076 Validation Decoder Loss:  0.79343367
Encoder Loss:  0.15415318  || Decoder Loss:  0.49590477 Validation Decoder Loss:  0.9901997
Encoder Loss:  0.13123971  || Decoder Loss:  0.50574833 Validation Decoder Loss:  0.9912691
Encoder Loss:  0.12800941  || Decoder Loss:  0.50168556 Validation Decoder Loss:  1.008307
Encoder Loss:  0.12906843  || Decoder Loss:  0.50322825 Validation Decoder Loss:  1.0063393
Encoder Loss:  0.1284717  || Decoder Loss:  0.50235933 Validation Decoder Loss:  0.98962367
Encoder Loss:  0.12732331  || Decoder Loss:  0.5007005 Validation Decoder Loss:  1.0078663
Encoder Loss:  0.12705962  || Decoder Loss:  0.5025636 Validation Decoder Loss:  1.0253938
Encoder Loss:  0.12718251  || Decoder Loss:  0.50294006 Validation Decoder Loss:  1.0236554
Encoder Loss:  0.12747511  || Decoder Loss:  0.50170124 Validation Decoder Loss:  1.0442204
Encoder Loss:  0.12774988  || Decoder Loss:  0.50338113 Validation Decoder Loss:  1.0357039
Encoder Loss:  0.12785447  || Decoder Loss:  0.5024349 Validation Decoder Loss:  1.0536404
Encoder Loss:  0.13006598  || Decoder Loss:  0.50378734 Validation Decoder Loss:  1.0601836
Encoder Loss:  0.12776235  || Decoder Loss:  0.50194895 Validation Decoder Loss:  1.0413487
Encoder Loss:  0.12747528  || Decoder Loss:  0.50078756 Validation Decoder Loss:  1.0414243
Encoder Loss:  0.12890644  || Decoder Loss:  0.50026613 Validation Decoder Loss:  1.0660965
Encoder Loss:  0.12663855  || Decoder Loss:  0.5011566 Validation Decoder Loss:  1.0740442
Encoder Loss:  0.12862226  || Decoder Loss:  0.5019077 Validation Decoder Loss:  1.0638776
Encoder Loss:  0.12830439  || Decoder Loss:  0.5013979 Validation Decoder Loss:  1.0690433
Encoder Loss:  0.12712973  || Decoder Loss:  0.5011827 Validation Decoder Loss:  1.0727737
Encoder Loss:  0.12762089  || Decoder Loss:  0.5009193 Validation Decoder Loss:  1.0709442
Encoder Loss:  0.12750383  || Decoder Loss:  0.50040376 Validation Decoder Loss:  1.0762084
Encoder Loss:  0.12722886  || Decoder Loss:  0.5006577 Validation Decoder Loss:  1.0918019
Encoder Loss:  0.12737387  || Decoder Loss:  0.5014758 Validation Decoder Loss:  1.0768363
Encoder Loss:  0.12749694  || Decoder Loss:  0.49994984 Validation Decoder Loss:  1.0797127
Encoder Loss:  0.12727918  || Decoder Loss:  0.50011426 Validation Decoder Loss:  1.0995085
Encoder Loss:  0.12706873  || Decoder Loss:  0.50074124 Validation Decoder Loss:  1.0859172
Encoder Loss:  0.12718809  || Decoder Loss:  0.4996885 Validation Decoder Loss:  1.0997187
Encoder Loss:  0.12689544  || Decoder Loss:  0.50055414 Validation Decoder Loss:  1.091032
Encoder Loss:  0.1280294  || Decoder Loss:  0.50136256 Validation Decoder Loss:  1.107986
Encoder Loss:  0.12736015  || Decoder Loss:  0.501177 Validation Decoder Loss:  1.1039057
Encoder Loss:  0.1257978  || Decoder Loss:  0.5002898 Validation Decoder Loss:  1.10672
Encoder Loss:  0.12829752  || Decoder Loss:  0.49956512 Validation Decoder Loss:  1.1136451
Encoder Loss:  0.12934636  || Decoder Loss:  0.5016807 Validation Decoder Loss:  1.1194701
Encoder Loss:  0.12734973  || Decoder Loss:  0.49933213 Validation Decoder Loss:  1.1199206
Encoder Loss:  0.12720554  || Decoder Loss:  0.49946544 Validation Decoder Loss:  1.1180334
Encoder Loss:  0.1270362  || Decoder Loss:  0.4996301 Validation Decoder Loss:  1.1201842
Encoder Loss:  0.1269373  || Decoder Loss:  0.49958444 Validation Decoder Loss:  1.1228409
Encoder Loss:  0.12680773  || Decoder Loss:  0.500196 Validation Decoder Loss:  1.1046672
Model: siamese_net_lr_0.0746049826011995 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1046672
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_221 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_498 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_222 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_144 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_500 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_473"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_502 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10265341  || Decoder Loss:  0.054675616 Validation Decoder Loss:  0.3937715
Encoder Loss:  0.04480597  || Decoder Loss:  0.035151564 Validation Decoder Loss:  0.36748916
Encoder Loss:  0.03941959  || Decoder Loss:  0.03254839 Validation Decoder Loss:  0.33570117
Encoder Loss:  0.038133528  || Decoder Loss:  0.032349154 Validation Decoder Loss:  0.33767
Encoder Loss:  0.038611922  || Decoder Loss:  0.03231622 Validation Decoder Loss:  0.346663
Encoder Loss:  0.03889079  || Decoder Loss:  0.032241724 Validation Decoder Loss:  0.34212974
Encoder Loss:  0.03898174  || Decoder Loss:  0.03229552 Validation Decoder Loss:  0.3426763
Encoder Loss:  0.03897022  || Decoder Loss:  0.032212712 Validation Decoder Loss:  0.34516293
Encoder Loss:  0.038591925  || Decoder Loss:  0.032448255 Validation Decoder Loss:  0.34217668
Encoder Loss:  0.038171425  || Decoder Loss:  0.032256905 Validation Decoder Loss:  0.34298855
Encoder Loss:  0.037835814  || Decoder Loss:  0.03217575 Validation Decoder Loss:  0.34219098
Encoder Loss:  0.0377131  || Decoder Loss:  0.032124892 Validation Decoder Loss:  0.34209096
Encoder Loss:  0.03764502  || Decoder Loss:  0.0320737 Validation Decoder Loss:  0.34360865
Encoder Loss:  0.03759474  || Decoder Loss:  0.03201749 Validation Decoder Loss:  0.34406507
Encoder Loss:  0.03774797  || Decoder Loss:  0.032244924 Validation Decoder Loss:  0.3436911
Encoder Loss:  0.037826  || Decoder Loss:  0.03235758 Validation Decoder Loss:  0.34198898
Encoder Loss:  0.03758005  || Decoder Loss:  0.032001287 Validation Decoder Loss:  0.34243855
Encoder Loss:  0.037547097  || Decoder Loss:  0.03195294 Validation Decoder Loss:  0.34264648
Encoder Loss:  0.037519272  || Decoder Loss:  0.031914648 Validation Decoder Loss:  0.34284616
Encoder Loss:  0.037511095  || Decoder Loss:  0.031903103 Validation Decoder Loss:  0.34214097
Encoder Loss:  0.037531935  || Decoder Loss:  0.0319338 Validation Decoder Loss:  0.34246343
Encoder Loss:  0.037502717  || Decoder Loss:  0.0318924 Validation Decoder Loss:  0.3414085
Encoder Loss:  0.037472695  || Decoder Loss:  0.03184524 Validation Decoder Loss:  0.3413067
Encoder Loss:  0.037446275  || Decoder Loss:  0.031804156 Validation Decoder Loss:  0.34104323
Encoder Loss:  0.037599333  || Decoder Loss:  0.03202139 Validation Decoder Loss:  0.33122307
Encoder Loss:  0.03748621  || Decoder Loss:  0.03186603 Validation Decoder Loss:  0.33938932
Encoder Loss:  0.03743041  || Decoder Loss:  0.031786725 Validation Decoder Loss:  0.34033316
Encoder Loss:  0.037419513  || Decoder Loss:  0.03177343 Validation Decoder Loss:  0.3412825
Encoder Loss:  0.037411794  || Decoder Loss:  0.031760197 Validation Decoder Loss:  0.34048945
Encoder Loss:  0.0373987  || Decoder Loss:  0.031742446 Validation Decoder Loss:  0.3406105
Encoder Loss:  0.03741865  || Decoder Loss:  0.031772997 Validation Decoder Loss:  0.3399942
Encoder Loss:  0.03740405  || Decoder Loss:  0.03174931 Validation Decoder Loss:  0.34042147
Encoder Loss:  0.037394557  || Decoder Loss:  0.031735566 Validation Decoder Loss:  0.340077
Encoder Loss:  0.03739928  || Decoder Loss:  0.031743232 Validation Decoder Loss:  0.34061283
Encoder Loss:  0.037387475  || Decoder Loss:  0.031726163 Validation Decoder Loss:  0.3388193
Encoder Loss:  0.037412666  || Decoder Loss:  0.031744517 Validation Decoder Loss:  0.33952174
Encoder Loss:  0.037400316  || Decoder Loss:  0.03173339 Validation Decoder Loss:  0.34067875
Encoder Loss:  0.037382998  || Decoder Loss:  0.03171987 Validation Decoder Loss:  0.33862725
Encoder Loss:  0.03739743  || Decoder Loss:  0.031731024 Validation Decoder Loss:  0.3409842
Encoder Loss:  0.037390053  || Decoder Loss:  0.03172144 Validation Decoder Loss:  0.33916524
Model: siamese_net_lr_0.034778110408211396 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33916524
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_224 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_504 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_225 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_145 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_476"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_506 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_508 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23761383  || Decoder Loss:  0.30813414 Validation Decoder Loss:  1.1842484
Encoder Loss:  0.47382304  || Decoder Loss:  0.89423615 Validation Decoder Loss:  1.4434531
Encoder Loss:  0.4850975  || Decoder Loss:  0.9168895 Validation Decoder Loss:  1.4201998
Encoder Loss:  0.4771442  || Decoder Loss:  0.9012382 Validation Decoder Loss:  1.3665649
Encoder Loss:  0.44900122  || Decoder Loss:  0.8459037 Validation Decoder Loss:  1.093322
Encoder Loss:  0.1430345  || Decoder Loss:  0.23553278 Validation Decoder Loss:  0.6728437
Encoder Loss:  0.088808306  || Decoder Loss:  0.12737912 Validation Decoder Loss:  0.6660351
Encoder Loss:  0.08782536  || Decoder Loss:  0.1254441 Validation Decoder Loss:  0.66358423
Encoder Loss:  0.08725769  || Decoder Loss:  0.12432244 Validation Decoder Loss:  0.6610914
Encoder Loss:  0.0866505  || Decoder Loss:  0.12310914 Validation Decoder Loss:  0.65853196
Encoder Loss:  0.086145505  || Decoder Loss:  0.122105315 Validation Decoder Loss:  0.65627956
Encoder Loss:  0.085687846  || Decoder Loss:  0.12119427 Validation Decoder Loss:  0.6543366
Encoder Loss:  0.08531445  || Decoder Loss:  0.12044959 Validation Decoder Loss:  0.65274155
Encoder Loss:  0.0850292  || Decoder Loss:  0.11987892 Validation Decoder Loss:  0.65162003
Encoder Loss:  0.084772475  || Decoder Loss:  0.11936014 Validation Decoder Loss:  0.6501364
Encoder Loss:  0.08457787  || Decoder Loss:  0.118979104 Validation Decoder Loss:  0.6492994
Encoder Loss:  0.08434612  || Decoder Loss:  0.11851499 Validation Decoder Loss:  0.64820313
Encoder Loss:  0.0841562  || Decoder Loss:  0.11814127 Validation Decoder Loss:  0.64730525
Encoder Loss:  0.08394874  || Decoder Loss:  0.1177308 Validation Decoder Loss:  0.64633906
Encoder Loss:  0.08374908  || Decoder Loss:  0.117326625 Validation Decoder Loss:  0.64527595
Encoder Loss:  0.08357565  || Decoder Loss:  0.11698628 Validation Decoder Loss:  0.64458066
Encoder Loss:  0.08339549  || Decoder Loss:  0.11662163 Validation Decoder Loss:  0.6436373
Encoder Loss:  0.08322131  || Decoder Loss:  0.11627922 Validation Decoder Loss:  0.64266384
Encoder Loss:  0.08303779  || Decoder Loss:  0.115907215 Validation Decoder Loss:  0.6418267
Encoder Loss:  0.082829066  || Decoder Loss:  0.11549768 Validation Decoder Loss:  0.6408211
Encoder Loss:  0.08263496  || Decoder Loss:  0.1151123 Validation Decoder Loss:  0.63989604
Encoder Loss:  0.08242628  || Decoder Loss:  0.1146905 Validation Decoder Loss:  0.63883215
Encoder Loss:  0.082187  || Decoder Loss:  0.11421918 Validation Decoder Loss:  0.63766336
Encoder Loss:  0.08201079  || Decoder Loss:  0.11384127 Validation Decoder Loss:  0.63762665
Encoder Loss:  0.08246128  || Decoder Loss:  0.114725016 Validation Decoder Loss:  0.6412356
Encoder Loss:  0.08292938  || Decoder Loss:  0.115673125 Validation Decoder Loss:  0.6411364
Encoder Loss:  0.08297003  || Decoder Loss:  0.11576833 Validation Decoder Loss:  0.64167535
Encoder Loss:  0.083781585  || Decoder Loss:  0.11729809 Validation Decoder Loss:  0.65382373
Encoder Loss:  0.089534655  || Decoder Loss:  0.12852977 Validation Decoder Loss:  0.7018347
Encoder Loss:  0.13481005  || Decoder Loss:  0.21864124 Validation Decoder Loss:  0.9710292
Encoder Loss:  0.19157244  || Decoder Loss:  0.33236927 Validation Decoder Loss:  1.038645
Encoder Loss:  0.12764345  || Decoder Loss:  0.20491204 Validation Decoder Loss:  0.49143127
Encoder Loss:  0.045414045  || Decoder Loss:  0.040823635 Validation Decoder Loss:  0.37649524
Encoder Loss:  0.041575365  || Decoder Loss:  0.03317454 Validation Decoder Loss:  0.3480143
Encoder Loss:  0.04131551  || Decoder Loss:  0.032659907 Validation Decoder Loss:  0.34307447
Model: siamese_net_lr_0.0722448924432942 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34307447
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_227 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_510 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_228 (Conv3D (None, 634, 5, 20, 1)     101       
_________________________________________________________________
reshape_146 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_480"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_512 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_514 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30433512  || Decoder Loss:  0.29301527 Validation Decoder Loss:  0.3607164
Encoder Loss:  0.17672266  || Decoder Loss:  0.05519795 Validation Decoder Loss:  0.3616993
Encoder Loss:  0.06501059  || Decoder Loss:  0.05604158 Validation Decoder Loss:  0.36183682
Encoder Loss:  0.055102944  || Decoder Loss:  0.05663047 Validation Decoder Loss:  0.36208093
Encoder Loss:  0.053050432  || Decoder Loss:  0.05694379 Validation Decoder Loss:  0.36210245
Encoder Loss:  0.05218279  || Decoder Loss:  0.056944046 Validation Decoder Loss:  0.36199954
Encoder Loss:  0.05246537  || Decoder Loss:  0.056936435 Validation Decoder Loss:  0.36204624
Encoder Loss:  0.052706927  || Decoder Loss:  0.056991342 Validation Decoder Loss:  0.36208665
Encoder Loss:  0.05302982  || Decoder Loss:  0.057068165 Validation Decoder Loss:  0.36217052
Encoder Loss:  0.05316246  || Decoder Loss:  0.05719314 Validation Decoder Loss:  0.36221403
Encoder Loss:  0.05261581  || Decoder Loss:  0.05731509 Validation Decoder Loss:  0.3622958
Encoder Loss:  0.052565895  || Decoder Loss:  0.057379752 Validation Decoder Loss:  0.36236078
Encoder Loss:  0.052622538  || Decoder Loss:  0.05744401 Validation Decoder Loss:  0.36243847
Encoder Loss:  0.053469747  || Decoder Loss:  0.05759065 Validation Decoder Loss:  0.3625384
Encoder Loss:  0.052321605  || Decoder Loss:  0.05776979 Validation Decoder Loss:  0.36264908
Encoder Loss:  0.052782275  || Decoder Loss:  0.057824794 Validation Decoder Loss:  0.36275935
Encoder Loss:  0.053148404  || Decoder Loss:  0.05798458 Validation Decoder Loss:  0.3628738
Encoder Loss:  0.052380305  || Decoder Loss:  0.058163103 Validation Decoder Loss:  0.3629737
Encoder Loss:  0.052746274  || Decoder Loss:  0.05822446 Validation Decoder Loss:  0.3630814
Encoder Loss:  0.05329066  || Decoder Loss:  0.05837154 Validation Decoder Loss:  0.36326903
Encoder Loss:  0.053671118  || Decoder Loss:  0.058774535 Validation Decoder Loss:  0.36345506
Encoder Loss:  0.053557243  || Decoder Loss:  0.059199397 Validation Decoder Loss:  0.36378348
Encoder Loss:  0.05372868  || Decoder Loss:  0.059780423 Validation Decoder Loss:  0.36409032
Encoder Loss:  0.05323803  || Decoder Loss:  0.060290698 Validation Decoder Loss:  0.36438555
Encoder Loss:  0.053541064  || Decoder Loss:  0.060732648 Validation Decoder Loss:  0.3647114
Encoder Loss:  0.052992545  || Decoder Loss:  0.06112678 Validation Decoder Loss:  0.3648131
Encoder Loss:  0.05294669  || Decoder Loss:  0.06112479 Validation Decoder Loss:  0.3647417
Encoder Loss:  0.053187247  || Decoder Loss:  0.060972873 Validation Decoder Loss:  0.3645998
Encoder Loss:  0.052901853  || Decoder Loss:  0.060840048 Validation Decoder Loss:  0.36418676
Encoder Loss:  0.052798085  || Decoder Loss:  0.060224652 Validation Decoder Loss:  0.36309302
Encoder Loss:  0.052702136  || Decoder Loss:  0.058351085 Validation Decoder Loss:  0.35863036
Encoder Loss:  0.05005027  || Decoder Loss:  0.047184743 Validation Decoder Loss:  0.34495005
Encoder Loss:  0.04699149  || Decoder Loss:  0.034258 Validation Decoder Loss:  0.34393463
Encoder Loss:  0.0464367  || Decoder Loss:  0.032158908 Validation Decoder Loss:  0.34151694
Encoder Loss:  0.046455372  || Decoder Loss:  0.032021325 Validation Decoder Loss:  0.34171152
Encoder Loss:  0.046384774  || Decoder Loss:  0.03199268 Validation Decoder Loss:  0.34138465
Encoder Loss:  0.046632767  || Decoder Loss:  0.031971052 Validation Decoder Loss:  0.34149587
Encoder Loss:  0.046245247  || Decoder Loss:  0.031950995 Validation Decoder Loss:  0.34131116
Encoder Loss:  0.046356846  || Decoder Loss:  0.031929556 Validation Decoder Loss:  0.3411568
Encoder Loss:  0.046322547  || Decoder Loss:  0.03190811 Validation Decoder Loss:  0.3411079
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3411079
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_230 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_516 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_231 (Conv3D (None, 634, 5, 20, 1)     12        
_________________________________________________________________
reshape_147 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 40
Trainable params: 40
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_484"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_518 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_520 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15616526  || Decoder Loss:  0.053550646 Validation Decoder Loss:  0.34494394
Encoder Loss:  0.058409408  || Decoder Loss:  0.032367993 Validation Decoder Loss:  0.34218642
Encoder Loss:  0.052922126  || Decoder Loss:  0.03222346 Validation Decoder Loss:  0.3430565
Encoder Loss:  0.053323135  || Decoder Loss:  0.03216088 Validation Decoder Loss:  0.34296197
Encoder Loss:  0.04940564  || Decoder Loss:  0.032101993 Validation Decoder Loss:  0.34299454
Encoder Loss:  0.049267124  || Decoder Loss:  0.032037977 Validation Decoder Loss:  0.34314093
Encoder Loss:  0.049139153  || Decoder Loss:  0.031966392 Validation Decoder Loss:  0.34324878
Encoder Loss:  0.04912061  || Decoder Loss:  0.031886294 Validation Decoder Loss:  0.34335718
Encoder Loss:  0.049139556  || Decoder Loss:  0.031805556 Validation Decoder Loss:  0.3436659
Encoder Loss:  0.04913002  || Decoder Loss:  0.031759724 Validation Decoder Loss:  0.34387186
Encoder Loss:  0.049186327  || Decoder Loss:  0.031738542 Validation Decoder Loss:  0.34399694
Encoder Loss:  0.049966387  || Decoder Loss:  0.031723067 Validation Decoder Loss:  0.34406254
Encoder Loss:  0.05322413  || Decoder Loss:  0.031709127 Validation Decoder Loss:  0.34428132
Encoder Loss:  0.051194247  || Decoder Loss:  0.031693507 Validation Decoder Loss:  0.34441462
Encoder Loss:  0.049857926  || Decoder Loss:  0.031675514 Validation Decoder Loss:  0.34436718
Encoder Loss:  0.049255375  || Decoder Loss:  0.031668346 Validation Decoder Loss:  0.34440786
Encoder Loss:  0.049089085  || Decoder Loss:  0.0316359 Validation Decoder Loss:  0.34448966
Encoder Loss:  0.049073998  || Decoder Loss:  0.03161068 Validation Decoder Loss:  0.3446375
Encoder Loss:  0.0490729  || Decoder Loss:  0.03158432 Validation Decoder Loss:  0.34458816
Encoder Loss:  0.049063683  || Decoder Loss:  0.031528104 Validation Decoder Loss:  0.34463787
Encoder Loss:  0.049065556  || Decoder Loss:  0.03150405 Validation Decoder Loss:  0.34463304
Encoder Loss:  0.04906372  || Decoder Loss:  0.031481415 Validation Decoder Loss:  0.34469414
Encoder Loss:  0.04905806  || Decoder Loss:  0.03147134 Validation Decoder Loss:  0.3446989
Encoder Loss:  0.049056746  || Decoder Loss:  0.03146319 Validation Decoder Loss:  0.3446403
Encoder Loss:  0.049056735  || Decoder Loss:  0.031449642 Validation Decoder Loss:  0.34460944
Encoder Loss:  0.049062643  || Decoder Loss:  0.03144133 Validation Decoder Loss:  0.34463474
Encoder Loss:  0.049057234  || Decoder Loss:  0.031436123 Validation Decoder Loss:  0.3446614
Encoder Loss:  0.049049757  || Decoder Loss:  0.031432804 Validation Decoder Loss:  0.34467527
Encoder Loss:  0.04905197  || Decoder Loss:  0.031429313 Validation Decoder Loss:  0.3446568
Encoder Loss:  0.049056716  || Decoder Loss:  0.0314241 Validation Decoder Loss:  0.3446119
Encoder Loss:  0.049069382  || Decoder Loss:  0.03149034 Validation Decoder Loss:  0.34429532
Encoder Loss:  0.049050827  || Decoder Loss:  0.03148215 Validation Decoder Loss:  0.34460035
Encoder Loss:  0.04904385  || Decoder Loss:  0.031426035 Validation Decoder Loss:  0.34463668
Encoder Loss:  0.049048863  || Decoder Loss:  0.031418428 Validation Decoder Loss:  0.34465796
Encoder Loss:  0.04904638  || Decoder Loss:  0.031449314 Validation Decoder Loss:  0.34462115
Encoder Loss:  0.04905376  || Decoder Loss:  0.031429473 Validation Decoder Loss:  0.34470552
Encoder Loss:  0.04905646  || Decoder Loss:  0.031419843 Validation Decoder Loss:  0.34469867
Encoder Loss:  0.04904428  || Decoder Loss:  0.031414825 Validation Decoder Loss:  0.34466606
Encoder Loss:  0.049058877  || Decoder Loss:  0.031649064 Validation Decoder Loss:  0.34391308
Encoder Loss:  0.04904566  || Decoder Loss:  0.03150325 Validation Decoder Loss:  0.34478807
Model: siamese_net_lr_0.06414840917060673 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34478807
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_233 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_522 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_234 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_148 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_488"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_524 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_526 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28167665  || Decoder Loss:  0.13297614 Validation Decoder Loss:  0.39288443
Encoder Loss:  0.28095484  || Decoder Loss:  0.16273923 Validation Decoder Loss:  0.51538914
Encoder Loss:  0.23014775  || Decoder Loss:  0.51584893 Validation Decoder Loss:  0.73526096
Encoder Loss:  0.18561998  || Decoder Loss:  0.49990302 Validation Decoder Loss:  0.8578037
Encoder Loss:  0.17915006  || Decoder Loss:  0.49976486 Validation Decoder Loss:  0.88129634
Encoder Loss:  0.17885295  || Decoder Loss:  0.5027077 Validation Decoder Loss:  0.8377328
Encoder Loss:  0.17835727  || Decoder Loss:  0.50094485 Validation Decoder Loss:  0.87887454
Encoder Loss:  0.17899168  || Decoder Loss:  0.5028717 Validation Decoder Loss:  0.85148096
Encoder Loss:  0.17905842  || Decoder Loss:  0.5034258 Validation Decoder Loss:  0.8410941
Encoder Loss:  0.18202643  || Decoder Loss:  0.5078119 Validation Decoder Loss:  0.8852383
Encoder Loss:  0.17810543  || Decoder Loss:  0.5017658 Validation Decoder Loss:  0.86552584
Encoder Loss:  0.17721073  || Decoder Loss:  0.49852824 Validation Decoder Loss:  0.89817125
Encoder Loss:  0.18143457  || Decoder Loss:  0.5057606 Validation Decoder Loss:  0.8414539
Encoder Loss:  0.17716183  || Decoder Loss:  0.49736735 Validation Decoder Loss:  0.8789871
Encoder Loss:  0.17733301  || Decoder Loss:  0.49970236 Validation Decoder Loss:  0.87261057
Encoder Loss:  0.18228205  || Decoder Loss:  0.5071651 Validation Decoder Loss:  0.97905815
Encoder Loss:  0.1795431  || Decoder Loss:  0.501855 Validation Decoder Loss:  0.9063563
Encoder Loss:  0.17696808  || Decoder Loss:  0.49696705 Validation Decoder Loss:  0.93620783
Encoder Loss:  0.1772232  || Decoder Loss:  0.4992891 Validation Decoder Loss:  0.92016554
Encoder Loss:  0.17684296  || Decoder Loss:  0.49871618 Validation Decoder Loss:  0.92160356
Encoder Loss:  0.17632839  || Decoder Loss:  0.49679023 Validation Decoder Loss:  0.937361
Encoder Loss:  0.17545937  || Decoder Loss:  0.494901 Validation Decoder Loss:  0.962233
Encoder Loss:  0.17566267  || Decoder Loss:  0.49573955 Validation Decoder Loss:  0.9790919
Encoder Loss:  0.17640531  || Decoder Loss:  0.49437717 Validation Decoder Loss:  0.9692197
Encoder Loss:  0.17568934  || Decoder Loss:  0.49457663 Validation Decoder Loss:  0.96329826
Encoder Loss:  0.17582273  || Decoder Loss:  0.49492085 Validation Decoder Loss:  0.98449665
Encoder Loss:  0.17656389  || Decoder Loss:  0.49483302 Validation Decoder Loss:  0.9884625
Encoder Loss:  0.1776459  || Decoder Loss:  0.49487206 Validation Decoder Loss:  0.99091405
Encoder Loss:  0.17506322  || Decoder Loss:  0.4936683 Validation Decoder Loss:  0.9844203
Encoder Loss:  0.17536636  || Decoder Loss:  0.49327478 Validation Decoder Loss:  0.98027277
Encoder Loss:  0.17506333  || Decoder Loss:  0.49251008 Validation Decoder Loss:  0.9665436
Encoder Loss:  0.1762888  || Decoder Loss:  0.49214348 Validation Decoder Loss:  0.9623363
Encoder Loss:  0.17432603  || Decoder Loss:  0.48931825 Validation Decoder Loss:  0.9930706
Encoder Loss:  0.17559372  || Decoder Loss:  0.4952058 Validation Decoder Loss:  0.9944461
Encoder Loss:  0.17460196  || Decoder Loss:  0.49233192 Validation Decoder Loss:  0.9312147
Encoder Loss:  0.17262283  || Decoder Loss:  0.48485887 Validation Decoder Loss:  0.9370448
Encoder Loss:  0.17222165  || Decoder Loss:  0.48479766 Validation Decoder Loss:  0.8646543
Encoder Loss:  0.17192903  || Decoder Loss:  0.4822197 Validation Decoder Loss:  0.9233545
Encoder Loss:  0.17203073  || Decoder Loss:  0.4834762 Validation Decoder Loss:  0.84597194
Encoder Loss:  0.17246889  || Decoder Loss:  0.48367622 Validation Decoder Loss:  0.92335963
Model: siamese_net_lr_0.09451602149883168 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.92335963
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_236 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_528 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_237 (Conv3D (None, 634, 5, 20, 1)     54        
_________________________________________________________________
reshape_149 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_492"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_530 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_532 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058884505  || Decoder Loss:  0.052020445 Validation Decoder Loss:  0.34315458
Encoder Loss:  0.037717953  || Decoder Loss:  0.03217899 Validation Decoder Loss:  0.34288216
Encoder Loss:  0.036941126  || Decoder Loss:  0.031886403 Validation Decoder Loss:  0.34300196
Encoder Loss:  0.036869347  || Decoder Loss:  0.03183516 Validation Decoder Loss:  0.34307784
Encoder Loss:  0.036820535  || Decoder Loss:  0.031809583 Validation Decoder Loss:  0.34310818
Encoder Loss:  0.036798593  || Decoder Loss:  0.031786498 Validation Decoder Loss:  0.34313828
Encoder Loss:  0.036784854  || Decoder Loss:  0.03176195 Validation Decoder Loss:  0.3431788
Encoder Loss:  0.036763623  || Decoder Loss:  0.03173675 Validation Decoder Loss:  0.3432402
Encoder Loss:  0.036747895  || Decoder Loss:  0.031710017 Validation Decoder Loss:  0.34332278
Encoder Loss:  0.03672056  || Decoder Loss:  0.031683236 Validation Decoder Loss:  0.34340668
Encoder Loss:  0.03669912  || Decoder Loss:  0.031658046 Validation Decoder Loss:  0.34350002
Encoder Loss:  0.036689073  || Decoder Loss:  0.031636402 Validation Decoder Loss:  0.34357682
Encoder Loss:  0.036690786  || Decoder Loss:  0.03161748 Validation Decoder Loss:  0.34364855
Encoder Loss:  0.036667675  || Decoder Loss:  0.03160095 Validation Decoder Loss:  0.34369576
Encoder Loss:  0.036642455  || Decoder Loss:  0.03158534 Validation Decoder Loss:  0.34372026
Encoder Loss:  0.036642656  || Decoder Loss:  0.03157069 Validation Decoder Loss:  0.3437748
Encoder Loss:  0.036636397  || Decoder Loss:  0.031556714 Validation Decoder Loss:  0.34379184
Encoder Loss:  0.036620084  || Decoder Loss:  0.03154286 Validation Decoder Loss:  0.34381425
Encoder Loss:  0.0365998  || Decoder Loss:  0.031528756 Validation Decoder Loss:  0.34381926
Encoder Loss:  0.036590517  || Decoder Loss:  0.031514205 Validation Decoder Loss:  0.34386754
Encoder Loss:  0.03659564  || Decoder Loss:  0.031499654 Validation Decoder Loss:  0.34387863
Encoder Loss:  0.036595523  || Decoder Loss:  0.031485613 Validation Decoder Loss:  0.34391123
Encoder Loss:  0.03657517  || Decoder Loss:  0.031471524 Validation Decoder Loss:  0.3438894
Encoder Loss:  0.03656146  || Decoder Loss:  0.031457514 Validation Decoder Loss:  0.34390372
Encoder Loss:  0.036543597  || Decoder Loss:  0.031443156 Validation Decoder Loss:  0.34387472
Encoder Loss:  0.03652303  || Decoder Loss:  0.031428296 Validation Decoder Loss:  0.34386224
Encoder Loss:  0.03653611  || Decoder Loss:  0.031412736 Validation Decoder Loss:  0.34379637
Encoder Loss:  0.036522474  || Decoder Loss:  0.03139595 Validation Decoder Loss:  0.3436752
Encoder Loss:  0.036516644  || Decoder Loss:  0.031378124 Validation Decoder Loss:  0.34360462
Encoder Loss:  0.036502104  || Decoder Loss:  0.03136138 Validation Decoder Loss:  0.34348994
Encoder Loss:  0.036476504  || Decoder Loss:  0.03134463 Validation Decoder Loss:  0.34335107
Encoder Loss:  0.03644344  || Decoder Loss:  0.03132602 Validation Decoder Loss:  0.34315372
Encoder Loss:  0.036435727  || Decoder Loss:  0.031310238 Validation Decoder Loss:  0.34296054
Encoder Loss:  0.03644095  || Decoder Loss:  0.031296697 Validation Decoder Loss:  0.34278977
Encoder Loss:  0.036451474  || Decoder Loss:  0.031283606 Validation Decoder Loss:  0.34263802
Encoder Loss:  0.036424242  || Decoder Loss:  0.0312771 Validation Decoder Loss:  0.34243542
Encoder Loss:  0.036449168  || Decoder Loss:  0.0312678 Validation Decoder Loss:  0.34238428
Encoder Loss:  0.036420062  || Decoder Loss:  0.03126113 Validation Decoder Loss:  0.34229773
Encoder Loss:  0.036404904  || Decoder Loss:  0.031255394 Validation Decoder Loss:  0.342251
Encoder Loss:  0.036408342  || Decoder Loss:  0.031249406 Validation Decoder Loss:  0.3422339
Model: siamese_net_lr_0.027082631744984806 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3422339
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_239 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_534 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_240 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_150 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_496"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_536 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_538 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13119741  || Decoder Loss:  0.13416302 Validation Decoder Loss:  0.3267622
Encoder Loss:  0.049707547  || Decoder Loss:  0.04777415 Validation Decoder Loss:  0.32457894
Encoder Loss:  0.04587829  || Decoder Loss:  0.043331817 Validation Decoder Loss:  0.32376373
Encoder Loss:  0.043489322  || Decoder Loss:  0.04008211 Validation Decoder Loss:  0.32746837
Encoder Loss:  0.03863205  || Decoder Loss:  0.033108592 Validation Decoder Loss:  0.3362154
Encoder Loss:  0.038129754  || Decoder Loss:  0.03239706 Validation Decoder Loss:  0.3385619
Encoder Loss:  0.037997298  || Decoder Loss:  0.03230325 Validation Decoder Loss:  0.33887613
Encoder Loss:  0.03782609  || Decoder Loss:  0.03226174 Validation Decoder Loss:  0.33893278
Encoder Loss:  0.03775976  || Decoder Loss:  0.03222843 Validation Decoder Loss:  0.33886582
Encoder Loss:  0.037740696  || Decoder Loss:  0.03219465 Validation Decoder Loss:  0.33870298
Encoder Loss:  0.037743445  || Decoder Loss:  0.03215802 Validation Decoder Loss:  0.3385378
Encoder Loss:  0.03767791  || Decoder Loss:  0.03211911 Validation Decoder Loss:  0.33838534
Encoder Loss:  0.037647814  || Decoder Loss:  0.032083284 Validation Decoder Loss:  0.3382653
Encoder Loss:  0.037618503  || Decoder Loss:  0.032046877 Validation Decoder Loss:  0.33815223
Encoder Loss:  0.03759094  || Decoder Loss:  0.03200876 Validation Decoder Loss:  0.33800665
Encoder Loss:  0.03756142  || Decoder Loss:  0.03196806 Validation Decoder Loss:  0.3378226
Encoder Loss:  0.037529517  || Decoder Loss:  0.031925365 Validation Decoder Loss:  0.33760303
Encoder Loss:  0.037498184  || Decoder Loss:  0.03188001 Validation Decoder Loss:  0.33743626
Encoder Loss:  0.037466913  || Decoder Loss:  0.031832486 Validation Decoder Loss:  0.33726835
Encoder Loss:  0.037437707  || Decoder Loss:  0.031782366 Validation Decoder Loss:  0.33711234
Encoder Loss:  0.037396688  || Decoder Loss:  0.031731304 Validation Decoder Loss:  0.33694738
Encoder Loss:  0.03735524  || Decoder Loss:  0.031682853 Validation Decoder Loss:  0.33685246
Encoder Loss:  0.03736012  || Decoder Loss:  0.03164076 Validation Decoder Loss:  0.33684307
Encoder Loss:  0.03736512  || Decoder Loss:  0.03160647 Validation Decoder Loss:  0.33719072
Encoder Loss:  0.03740547  || Decoder Loss:  0.03164688 Validation Decoder Loss:  0.33883142
Encoder Loss:  0.03736807  || Decoder Loss:  0.031585366 Validation Decoder Loss:  0.33853197
Encoder Loss:  0.037352372  || Decoder Loss:  0.03151734 Validation Decoder Loss:  0.3382041
Encoder Loss:  0.037535604  || Decoder Loss:  0.031457026 Validation Decoder Loss:  0.33534604
Encoder Loss:  0.037008077  || Decoder Loss:  0.031132335 Validation Decoder Loss:  0.336726
Encoder Loss:  0.036971156  || Decoder Loss:  0.03112198 Validation Decoder Loss:  0.33829403
Encoder Loss:  0.03698342  || Decoder Loss:  0.031151133 Validation Decoder Loss:  0.33863673
Encoder Loss:  0.036972698  || Decoder Loss:  0.0311464 Validation Decoder Loss:  0.33872277
Encoder Loss:  0.03697206  || Decoder Loss:  0.031145554 Validation Decoder Loss:  0.33858642
Encoder Loss:  0.03697132  || Decoder Loss:  0.03114742 Validation Decoder Loss:  0.33885267
Encoder Loss:  0.03697196  || Decoder Loss:  0.031149652 Validation Decoder Loss:  0.33860117
Encoder Loss:  0.036961246  || Decoder Loss:  0.031135201 Validation Decoder Loss:  0.33891004
Encoder Loss:  0.03696021  || Decoder Loss:  0.031134807 Validation Decoder Loss:  0.33869183
Encoder Loss:  0.03695564  || Decoder Loss:  0.0311274 Validation Decoder Loss:  0.3391009
Encoder Loss:  0.03694843  || Decoder Loss:  0.031119013 Validation Decoder Loss:  0.33882648
Encoder Loss:  0.03694528  || Decoder Loss:  0.031116057 Validation Decoder Loss:  0.33910805
Model: siamese_net_lr_0.039197398644888824 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33910802
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_242 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_540 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_243 (Conv3D (None, 634, 5, 20, 1)     271       
_________________________________________________________________
reshape_151 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_500"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_542 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_544 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14668359  || Decoder Loss:  0.13042898 Validation Decoder Loss:  0.36552534
Encoder Loss:  0.0745068  || Decoder Loss:  0.09059141 Validation Decoder Loss:  0.52035135
Encoder Loss:  0.062295962  || Decoder Loss:  0.075925104 Validation Decoder Loss:  0.38375768
Encoder Loss:  0.044920683  || Decoder Loss:  0.03664942 Validation Decoder Loss:  0.3550718
Encoder Loss:  0.04336899  || Decoder Loss:  0.032860532 Validation Decoder Loss:  0.340404
Encoder Loss:  0.042929307  || Decoder Loss:  0.032489542 Validation Decoder Loss:  0.33720952
Encoder Loss:  0.04286028  || Decoder Loss:  0.032455977 Validation Decoder Loss:  0.33872563
Encoder Loss:  0.04284136  || Decoder Loss:  0.032440584 Validation Decoder Loss:  0.33851892
Encoder Loss:  0.0428422  || Decoder Loss:  0.03243316 Validation Decoder Loss:  0.33842117
Encoder Loss:  0.04283292  || Decoder Loss:  0.032427467 Validation Decoder Loss:  0.338354
Encoder Loss:  0.04282773  || Decoder Loss:  0.032421157 Validation Decoder Loss:  0.33836526
Encoder Loss:  0.04282893  || Decoder Loss:  0.032414872 Validation Decoder Loss:  0.3383516
Encoder Loss:  0.04281987  || Decoder Loss:  0.03240946 Validation Decoder Loss:  0.3383046
Encoder Loss:  0.042815425  || Decoder Loss:  0.03240187 Validation Decoder Loss:  0.33819544
Encoder Loss:  0.04281429  || Decoder Loss:  0.032396007 Validation Decoder Loss:  0.33828527
Encoder Loss:  0.04280906  || Decoder Loss:  0.032389954 Validation Decoder Loss:  0.33832204
Encoder Loss:  0.042816736  || Decoder Loss:  0.03238332 Validation Decoder Loss:  0.33815548
Encoder Loss:  0.042809762  || Decoder Loss:  0.032377206 Validation Decoder Loss:  0.33821428
Encoder Loss:  0.042800773  || Decoder Loss:  0.032370936 Validation Decoder Loss:  0.33826584
Encoder Loss:  0.042794023  || Decoder Loss:  0.03236454 Validation Decoder Loss:  0.33828986
Encoder Loss:  0.042787675  || Decoder Loss:  0.032358065 Validation Decoder Loss:  0.3382796
Encoder Loss:  0.042795703  || Decoder Loss:  0.032351904 Validation Decoder Loss:  0.3381418
Encoder Loss:  0.04279127  || Decoder Loss:  0.032345895 Validation Decoder Loss:  0.3381542
Encoder Loss:  0.042786766  || Decoder Loss:  0.032339595 Validation Decoder Loss:  0.33809954
Encoder Loss:  0.042789973  || Decoder Loss:  0.03233368 Validation Decoder Loss:  0.33798504
Encoder Loss:  0.042788852  || Decoder Loss:  0.032327563 Validation Decoder Loss:  0.33805034
Encoder Loss:  0.042773865  || Decoder Loss:  0.03232168 Validation Decoder Loss:  0.33805817
Encoder Loss:  0.042769346  || Decoder Loss:  0.032315616 Validation Decoder Loss:  0.33795512
Encoder Loss:  0.04276  || Decoder Loss:  0.03230937 Validation Decoder Loss:  0.3379503
Encoder Loss:  0.042756528  || Decoder Loss:  0.032302912 Validation Decoder Loss:  0.3379953
Encoder Loss:  0.04278527  || Decoder Loss:  0.03229698 Validation Decoder Loss:  0.33815965
Encoder Loss:  0.042858854  || Decoder Loss:  0.032291953 Validation Decoder Loss:  0.33746466
Encoder Loss:  0.042816654  || Decoder Loss:  0.032286473 Validation Decoder Loss:  0.33749402
Encoder Loss:  0.042784028  || Decoder Loss:  0.03228104 Validation Decoder Loss:  0.33791572
Encoder Loss:  0.042796172  || Decoder Loss:  0.032276336 Validation Decoder Loss:  0.33809114
Encoder Loss:  0.04276535  || Decoder Loss:  0.032271255 Validation Decoder Loss:  0.33803147
Encoder Loss:  0.04275194  || Decoder Loss:  0.03226744 Validation Decoder Loss:  0.33802503
Encoder Loss:  0.04290937  || Decoder Loss:  0.032266203 Validation Decoder Loss:  0.33744693
Encoder Loss:  0.044011593  || Decoder Loss:  0.032292333 Validation Decoder Loss:  0.33862987
Encoder Loss:  0.043126546  || Decoder Loss:  0.03231161 Validation Decoder Loss:  0.33779362
Model: siamese_net_lr_0.026075428373766932 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33779362
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_245 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_546 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_246 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_152 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_504"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_548 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_550 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15545891  || Decoder Loss:  0.17731088 Validation Decoder Loss:  0.39751318
Encoder Loss:  0.13829894  || Decoder Loss:  0.16432032 Validation Decoder Loss:  0.73212576
Encoder Loss:  0.44984514  || Decoder Loss:  0.6564638 Validation Decoder Loss:  1.1722534
Encoder Loss:  0.41446906  || Decoder Loss:  0.6039498 Validation Decoder Loss:  1.0884299
Encoder Loss:  0.39417747  || Decoder Loss:  0.573302 Validation Decoder Loss:  1.0572498
Encoder Loss:  0.38457313  || Decoder Loss:  0.5587486 Validation Decoder Loss:  1.0436231
Encoder Loss:  0.37510243  || Decoder Loss:  0.5443496 Validation Decoder Loss:  1.0063295
Encoder Loss:  0.30260065  || Decoder Loss:  0.43409684 Validation Decoder Loss:  0.7815951
Encoder Loss:  0.14073214  || Decoder Loss:  0.18794549 Validation Decoder Loss:  0.39325935
Encoder Loss:  0.07525548  || Decoder Loss:  0.08837701 Validation Decoder Loss:  0.36294407
Encoder Loss:  0.053344216  || Decoder Loss:  0.055058654 Validation Decoder Loss:  0.3552714
Encoder Loss:  0.04046879  || Decoder Loss:  0.035483543 Validation Decoder Loss:  0.347051
Encoder Loss:  0.038603015  || Decoder Loss:  0.0326457 Validation Decoder Loss:  0.3454221
Encoder Loss:  0.03847034  || Decoder Loss:  0.032445665 Validation Decoder Loss:  0.3448375
Encoder Loss:  0.038450237  || Decoder Loss:  0.032414146 Validation Decoder Loss:  0.34459782
Encoder Loss:  0.038437333  || Decoder Loss:  0.032396413 Validation Decoder Loss:  0.34448853
Encoder Loss:  0.038427506  || Decoder Loss:  0.03238016 Validation Decoder Loss:  0.34438738
Encoder Loss:  0.038417295  || Decoder Loss:  0.032364666 Validation Decoder Loss:  0.34427732
Encoder Loss:  0.03840797  || Decoder Loss:  0.032350153 Validation Decoder Loss:  0.3441693
Encoder Loss:  0.038399473  || Decoder Loss:  0.032336526 Validation Decoder Loss:  0.34406233
Encoder Loss:  0.038391516  || Decoder Loss:  0.032323666 Validation Decoder Loss:  0.3439586
Encoder Loss:  0.038383413  || Decoder Loss:  0.032311786 Validation Decoder Loss:  0.34386593
Encoder Loss:  0.038376585  || Decoder Loss:  0.03230067 Validation Decoder Loss:  0.3437761
Encoder Loss:  0.038365986  || Decoder Loss:  0.032290354 Validation Decoder Loss:  0.34367892
Encoder Loss:  0.0383578  || Decoder Loss:  0.032281104 Validation Decoder Loss:  0.34358215
Encoder Loss:  0.038352456  || Decoder Loss:  0.0322727 Validation Decoder Loss:  0.3434846
Encoder Loss:  0.038348034  || Decoder Loss:  0.032265276 Validation Decoder Loss:  0.34338006
Encoder Loss:  0.038341984  || Decoder Loss:  0.032258935 Validation Decoder Loss:  0.34327513
Encoder Loss:  0.038339954  || Decoder Loss:  0.032254267 Validation Decoder Loss:  0.34318537
Encoder Loss:  0.03834016  || Decoder Loss:  0.03225227 Validation Decoder Loss:  0.34310812
Encoder Loss:  0.038340818  || Decoder Loss:  0.032252472 Validation Decoder Loss:  0.34301203
Encoder Loss:  0.03833981  || Decoder Loss:  0.032256976 Validation Decoder Loss:  0.34290886
Encoder Loss:  0.038348705  || Decoder Loss:  0.032267608 Validation Decoder Loss:  0.34279874
Encoder Loss:  0.038358252  || Decoder Loss:  0.032286342 Validation Decoder Loss:  0.34269822
Encoder Loss:  0.038375277  || Decoder Loss:  0.03231205 Validation Decoder Loss:  0.34264362
Encoder Loss:  0.038401615  || Decoder Loss:  0.032347716 Validation Decoder Loss:  0.34262812
Encoder Loss:  0.038446236  || Decoder Loss:  0.0324154 Validation Decoder Loss:  0.3426049
Encoder Loss:  0.03852027  || Decoder Loss:  0.03253094 Validation Decoder Loss:  0.3426568
Encoder Loss:  0.03861941  || Decoder Loss:  0.032683786 Validation Decoder Loss:  0.3427602
Encoder Loss:  0.038735937  || Decoder Loss:  0.032861125 Validation Decoder Loss:  0.34287345
Model: siamese_net_lr_0.037223847457707654 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34287345
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_248 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_552 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_249 (Conv3D (None, 634, 5, 20, 1)     137       
_________________________________________________________________
reshape_153 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_508"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_554 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 3170, 20, 1)       2         
_________________________________________________________________
dropout_556 (Dropout)        (None, 3170, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32111305  || Decoder Loss:  0.39361477 Validation Decoder Loss:  0.45097926
Encoder Loss:  0.063113935  || Decoder Loss:  0.05634841 Validation Decoder Loss:  0.35717267
Encoder Loss:  0.042838715  || Decoder Loss:  0.036501013 Validation Decoder Loss:  0.35059342
Encoder Loss:  0.039906505  || Decoder Loss:  0.033610243 Validation Decoder Loss:  0.34768108
Encoder Loss:  0.03892287  || Decoder Loss:  0.032752346 Validation Decoder Loss:  0.3465516
Encoder Loss:  0.038075514  || Decoder Loss:  0.032329775 Validation Decoder Loss:  0.34590858
Encoder Loss:  0.037865493  || Decoder Loss:  0.032173324 Validation Decoder Loss:  0.3452757
Encoder Loss:  0.03826385  || Decoder Loss:  0.03212531 Validation Decoder Loss:  0.34539905
Encoder Loss:  0.03808647  || Decoder Loss:  0.032099523 Validation Decoder Loss:  0.34542805
Encoder Loss:  0.038081147  || Decoder Loss:  0.032086506 Validation Decoder Loss:  0.3454803
Encoder Loss:  0.038342394  || Decoder Loss:  0.032077353 Validation Decoder Loss:  0.34500653
Encoder Loss:  0.039352622  || Decoder Loss:  0.032083336 Validation Decoder Loss:  0.34554952
Encoder Loss:  0.03772644  || Decoder Loss:  0.032062374 Validation Decoder Loss:  0.34575805
Encoder Loss:  0.038305353  || Decoder Loss:  0.032057427 Validation Decoder Loss:  0.34543234
Encoder Loss:  0.038225457  || Decoder Loss:  0.0320507 Validation Decoder Loss:  0.34548575
Encoder Loss:  0.038321063  || Decoder Loss:  0.03204652 Validation Decoder Loss:  0.3455574
Encoder Loss:  0.037416108  || Decoder Loss:  0.0320324 Validation Decoder Loss:  0.3455696
Encoder Loss:  0.03728919  || Decoder Loss:  0.032025054 Validation Decoder Loss:  0.34565967
Encoder Loss:  0.037980508  || Decoder Loss:  0.032017108 Validation Decoder Loss:  0.3454038
Encoder Loss:  0.03742783  || Decoder Loss:  0.032011524 Validation Decoder Loss:  0.34561837
Encoder Loss:  0.037439898  || Decoder Loss:  0.032001987 Validation Decoder Loss:  0.34584153
Encoder Loss:  0.037585206  || Decoder Loss:  0.03199256 Validation Decoder Loss:  0.3458097
Encoder Loss:  0.03767233  || Decoder Loss:  0.03198762 Validation Decoder Loss:  0.3463468
Encoder Loss:  0.038904503  || Decoder Loss:  0.031990666 Validation Decoder Loss:  0.34577543
Encoder Loss:  0.0379319  || Decoder Loss:  0.031974405 Validation Decoder Loss:  0.34599245
Encoder Loss:  0.037943777  || Decoder Loss:  0.031967863 Validation Decoder Loss:  0.3461903
Encoder Loss:  0.03749628  || Decoder Loss:  0.031959847 Validation Decoder Loss:  0.34612763
Encoder Loss:  0.03710818  || Decoder Loss:  0.03195128 Validation Decoder Loss:  0.3459929
Encoder Loss:  0.037889075  || Decoder Loss:  0.031949874 Validation Decoder Loss:  0.34607688
Encoder Loss:  0.037106764  || Decoder Loss:  0.03193761 Validation Decoder Loss:  0.34600636
Encoder Loss:  0.037577678  || Decoder Loss:  0.031932995 Validation Decoder Loss:  0.34541312
Encoder Loss:  0.03856332  || Decoder Loss:  0.031943284 Validation Decoder Loss:  0.34600076
Encoder Loss:  0.037823938  || Decoder Loss:  0.031924006 Validation Decoder Loss:  0.3461166
Encoder Loss:  0.037376657  || Decoder Loss:  0.031914525 Validation Decoder Loss:  0.34610677
Encoder Loss:  0.037396803  || Decoder Loss:  0.031909265 Validation Decoder Loss:  0.3462053
Encoder Loss:  0.03733379  || Decoder Loss:  0.031902302 Validation Decoder Loss:  0.3460731
Encoder Loss:  0.037234474  || Decoder Loss:  0.031897712 Validation Decoder Loss:  0.34618568
Encoder Loss:  0.037718512  || Decoder Loss:  0.031894337 Validation Decoder Loss:  0.34622973
Encoder Loss:  0.037286382  || Decoder Loss:  0.031884734 Validation Decoder Loss:  0.3457746
Encoder Loss:  0.03745664  || Decoder Loss:  0.0318836 Validation Decoder Loss:  0.34594336
Model: siamese_net_lr_0.03791688112718671 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3459434
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_251 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_558 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_252 (Conv3D (None, 634, 5, 20, 1)     54        
_________________________________________________________________
reshape_154 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_512"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_560 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_562 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22886086  || Decoder Loss:  0.28537416 Validation Decoder Loss:  0.37056404
Encoder Loss:  0.051184427  || Decoder Loss:  0.04124774 Validation Decoder Loss:  0.34540433
Encoder Loss:  0.040803567  || Decoder Loss:  0.032429334 Validation Decoder Loss:  0.34258288
Encoder Loss:  0.039390143  || Decoder Loss:  0.032191202 Validation Decoder Loss:  0.34265947
Encoder Loss:  0.03950683  || Decoder Loss:  0.032118145 Validation Decoder Loss:  0.34285074
Encoder Loss:  0.0397477  || Decoder Loss:  0.032079425 Validation Decoder Loss:  0.34289896
Encoder Loss:  0.03969773  || Decoder Loss:  0.0320594 Validation Decoder Loss:  0.34291506
Encoder Loss:  0.039642874  || Decoder Loss:  0.032046083 Validation Decoder Loss:  0.34293222
Encoder Loss:  0.03961246  || Decoder Loss:  0.032035593 Validation Decoder Loss:  0.34293967
Encoder Loss:  0.040348087  || Decoder Loss:  0.032028843 Validation Decoder Loss:  0.34294498
Encoder Loss:  0.03934952  || Decoder Loss:  0.03201942 Validation Decoder Loss:  0.34298122
Encoder Loss:  0.04023859  || Decoder Loss:  0.03201275 Validation Decoder Loss:  0.34298143
Encoder Loss:  0.03958129  || Decoder Loss:  0.03200711 Validation Decoder Loss:  0.34297594
Encoder Loss:  0.038687166  || Decoder Loss:  0.031996462 Validation Decoder Loss:  0.34307146
Encoder Loss:  0.04009778  || Decoder Loss:  0.031991065 Validation Decoder Loss:  0.34309366
Encoder Loss:  0.042476464  || Decoder Loss:  0.032002743 Validation Decoder Loss:  0.3431201
Encoder Loss:  0.04024725  || Decoder Loss:  0.031985264 Validation Decoder Loss:  0.3430832
Encoder Loss:  0.039238583  || Decoder Loss:  0.031980976 Validation Decoder Loss:  0.34305054
Encoder Loss:  0.03970739  || Decoder Loss:  0.03197788 Validation Decoder Loss:  0.3430776
Encoder Loss:  0.04121459  || Decoder Loss:  0.03198011 Validation Decoder Loss:  0.34314966
Encoder Loss:  0.03914498  || Decoder Loss:  0.03196965 Validation Decoder Loss:  0.34309536
Encoder Loss:  0.038800254  || Decoder Loss:  0.03196272 Validation Decoder Loss:  0.34311897
Encoder Loss:  0.03909722  || Decoder Loss:  0.03195785 Validation Decoder Loss:  0.34313488
Encoder Loss:  0.03872402  || Decoder Loss:  0.031952094 Validation Decoder Loss:  0.34317026
Encoder Loss:  0.038674325  || Decoder Loss:  0.03194651 Validation Decoder Loss:  0.34318843
Encoder Loss:  0.03922774  || Decoder Loss:  0.031941574 Validation Decoder Loss:  0.3432361
Encoder Loss:  0.038872994  || Decoder Loss:  0.0319375 Validation Decoder Loss:  0.3432347
Encoder Loss:  0.039477006  || Decoder Loss:  0.031938307 Validation Decoder Loss:  0.34330004
Encoder Loss:  0.04140012  || Decoder Loss:  0.0319576 Validation Decoder Loss:  0.3433364
Encoder Loss:  0.03970431  || Decoder Loss:  0.031935893 Validation Decoder Loss:  0.3432936
Encoder Loss:  0.038994323  || Decoder Loss:  0.031939108 Validation Decoder Loss:  0.34323853
Encoder Loss:  0.039062873  || Decoder Loss:  0.031936627 Validation Decoder Loss:  0.3432554
Encoder Loss:  0.040692486  || Decoder Loss:  0.031955015 Validation Decoder Loss:  0.34330183
Encoder Loss:  0.040352374  || Decoder Loss:  0.031952772 Validation Decoder Loss:  0.3432734
Encoder Loss:  0.038917966  || Decoder Loss:  0.03193855 Validation Decoder Loss:  0.34322178
Encoder Loss:  0.038574323  || Decoder Loss:  0.03193544 Validation Decoder Loss:  0.34322965
Encoder Loss:  0.038909413  || Decoder Loss:  0.031932734 Validation Decoder Loss:  0.3432172
Encoder Loss:  0.038823914  || Decoder Loss:  0.031930096 Validation Decoder Loss:  0.34319687
Encoder Loss:  0.039116666  || Decoder Loss:  0.031927563 Validation Decoder Loss:  0.3432107
Encoder Loss:  0.039018564  || Decoder Loss:  0.0319234 Validation Decoder Loss:  0.3431899
Model: siamese_net_lr_0.03936346813887664 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3431899
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_254 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_564 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_255 (Conv3D (None, 634, 5, 20, 1)     220       
_________________________________________________________________
reshape_155 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 242
Trainable params: 242
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_516"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_566 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_568 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14898354  || Decoder Loss:  0.09963789 Validation Decoder Loss:  0.3491311
Encoder Loss:  0.08328515  || Decoder Loss:  0.095601514 Validation Decoder Loss:  0.36956775
Encoder Loss:  0.048864275  || Decoder Loss:  0.046855025 Validation Decoder Loss:  0.3505039
Encoder Loss:  0.041750222  || Decoder Loss:  0.03456889 Validation Decoder Loss:  0.34719247
Encoder Loss:  0.041376635  || Decoder Loss:  0.03300103 Validation Decoder Loss:  0.3463123
Encoder Loss:  0.04056729  || Decoder Loss:  0.032679666 Validation Decoder Loss:  0.3464796
Encoder Loss:  0.041527305  || Decoder Loss:  0.032528087 Validation Decoder Loss:  0.3468715
Encoder Loss:  0.042287674  || Decoder Loss:  0.032461036 Validation Decoder Loss:  0.34654212
Encoder Loss:  0.04006565  || Decoder Loss:  0.03241427 Validation Decoder Loss:  0.34677744
Encoder Loss:  0.041056935  || Decoder Loss:  0.032401465 Validation Decoder Loss:  0.34608436
Encoder Loss:  0.042580523  || Decoder Loss:  0.032413825 Validation Decoder Loss:  0.3475296
Encoder Loss:  0.04011354  || Decoder Loss:  0.032391954 Validation Decoder Loss:  0.34692276
Encoder Loss:  0.04053403  || Decoder Loss:  0.03238709 Validation Decoder Loss:  0.3466926
Encoder Loss:  0.04034896  || Decoder Loss:  0.032383017 Validation Decoder Loss:  0.347264
Encoder Loss:  0.041566543  || Decoder Loss:  0.032386247 Validation Decoder Loss:  0.34693983
Encoder Loss:  0.041247945  || Decoder Loss:  0.032379717 Validation Decoder Loss:  0.34708154
Encoder Loss:  0.04009589  || Decoder Loss:  0.03237127 Validation Decoder Loss:  0.34743434
Encoder Loss:  0.040024456  || Decoder Loss:  0.032365058 Validation Decoder Loss:  0.3472762
Encoder Loss:  0.040343713  || Decoder Loss:  0.032359358 Validation Decoder Loss:  0.34715116
Encoder Loss:  0.040068354  || Decoder Loss:  0.0323548 Validation Decoder Loss:  0.34708112
Encoder Loss:  0.04037551  || Decoder Loss:  0.032352492 Validation Decoder Loss:  0.34706378
Encoder Loss:  0.04053576  || Decoder Loss:  0.03235105 Validation Decoder Loss:  0.3467289
Encoder Loss:  0.042348586  || Decoder Loss:  0.03235991 Validation Decoder Loss:  0.3453089
Encoder Loss:  0.041568432  || Decoder Loss:  0.032359358 Validation Decoder Loss:  0.34708285
Encoder Loss:  0.04088604  || Decoder Loss:  0.032350596 Validation Decoder Loss:  0.348925
Encoder Loss:  0.04216982  || Decoder Loss:  0.03235195 Validation Decoder Loss:  0.3480649
Encoder Loss:  0.040868483  || Decoder Loss:  0.032338582 Validation Decoder Loss:  0.34713632
Encoder Loss:  0.042074475  || Decoder Loss:  0.03235309 Validation Decoder Loss:  0.3481878
Encoder Loss:  0.04156217  || Decoder Loss:  0.032344643 Validation Decoder Loss:  0.34857172
Encoder Loss:  0.040070027  || Decoder Loss:  0.03232695 Validation Decoder Loss:  0.34731647
Encoder Loss:  0.040090725  || Decoder Loss:  0.032324895 Validation Decoder Loss:  0.3470014
Encoder Loss:  0.040229753  || Decoder Loss:  0.032322668 Validation Decoder Loss:  0.3468521
Encoder Loss:  0.041906454  || Decoder Loss:  0.032327306 Validation Decoder Loss:  0.34662378
Encoder Loss:  0.041111242  || Decoder Loss:  0.032316126 Validation Decoder Loss:  0.34709728
Encoder Loss:  0.039736863  || Decoder Loss:  0.03231195 Validation Decoder Loss:  0.34700733
Encoder Loss:  0.039968193  || Decoder Loss:  0.032306608 Validation Decoder Loss:  0.34710336
Encoder Loss:  0.03978411  || Decoder Loss:  0.03230325 Validation Decoder Loss:  0.34739026
Encoder Loss:  0.04055514  || Decoder Loss:  0.032299966 Validation Decoder Loss:  0.34737885
Encoder Loss:  0.040095605  || Decoder Loss:  0.03229278 Validation Decoder Loss:  0.3469389
Encoder Loss:  0.039892472  || Decoder Loss:  0.032287534 Validation Decoder Loss:  0.34745336
Model: siamese_net_lr_0.03656723842763885 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34745342
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_257 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_570 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_258 (Conv3D (None, 634, 5, 20, 1)     287       
_________________________________________________________________
reshape_156 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 313
Trainable params: 313
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_520"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_572 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_574 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.069753215  || Decoder Loss:  0.082061574 Validation Decoder Loss:  0.28999662
Encoder Loss:  0.050956868  || Decoder Loss:  0.04397142 Validation Decoder Loss:  0.30306882
Encoder Loss:  0.048714258  || Decoder Loss:  0.038100746 Validation Decoder Loss:  0.30965096
Encoder Loss:  0.04811917  || Decoder Loss:  0.035833232 Validation Decoder Loss:  0.31405833
Encoder Loss:  0.047868513  || Decoder Loss:  0.034626573 Validation Decoder Loss:  0.31846488
Encoder Loss:  0.04772772  || Decoder Loss:  0.033788208 Validation Decoder Loss:  0.32329386
Encoder Loss:  0.047618724  || Decoder Loss:  0.03321808 Validation Decoder Loss:  0.32792717
Encoder Loss:  0.047587752  || Decoder Loss:  0.032877296 Validation Decoder Loss:  0.33122057
Encoder Loss:  0.047524072  || Decoder Loss:  0.03268917 Validation Decoder Loss:  0.33292192
Encoder Loss:  0.04749  || Decoder Loss:  0.03257775 Validation Decoder Loss:  0.3335928
Encoder Loss:  0.047456995  || Decoder Loss:  0.032502227 Validation Decoder Loss:  0.33394977
Encoder Loss:  0.047390178  || Decoder Loss:  0.032445297 Validation Decoder Loss:  0.33411407
Encoder Loss:  0.047368556  || Decoder Loss:  0.032400813 Validation Decoder Loss:  0.3342166
Encoder Loss:  0.047375657  || Decoder Loss:  0.03236371 Validation Decoder Loss:  0.33427727
Encoder Loss:  0.04741181  || Decoder Loss:  0.032332603 Validation Decoder Loss:  0.33432573
Encoder Loss:  0.04732988  || Decoder Loss:  0.032304734 Validation Decoder Loss:  0.3342836
Encoder Loss:  0.047335505  || Decoder Loss:  0.03227985 Validation Decoder Loss:  0.33430412
Encoder Loss:  0.04733007  || Decoder Loss:  0.032257237 Validation Decoder Loss:  0.33428907
Encoder Loss:  0.04731991  || Decoder Loss:  0.032236412 Validation Decoder Loss:  0.33425218
Encoder Loss:  0.04731543  || Decoder Loss:  0.032217197 Validation Decoder Loss:  0.33423784
Encoder Loss:  0.047310572  || Decoder Loss:  0.032199554 Validation Decoder Loss:  0.33422202
Encoder Loss:  0.047296494  || Decoder Loss:  0.032182857 Validation Decoder Loss:  0.3341934
Encoder Loss:  0.047325373  || Decoder Loss:  0.032167487 Validation Decoder Loss:  0.33422536
Encoder Loss:  0.04730265  || Decoder Loss:  0.032153465 Validation Decoder Loss:  0.33423346
Encoder Loss:  0.047315277  || Decoder Loss:  0.032140337 Validation Decoder Loss:  0.33427578
Encoder Loss:  0.04726999  || Decoder Loss:  0.03212745 Validation Decoder Loss:  0.3342539
Encoder Loss:  0.047306046  || Decoder Loss:  0.032114636 Validation Decoder Loss:  0.3342681
Encoder Loss:  0.047275443  || Decoder Loss:  0.03210277 Validation Decoder Loss:  0.33425182
Encoder Loss:  0.047303867  || Decoder Loss:  0.03209146 Validation Decoder Loss:  0.33427912
Encoder Loss:  0.047252785  || Decoder Loss:  0.032079946 Validation Decoder Loss:  0.33424112
Encoder Loss:  0.04728871  || Decoder Loss:  0.032068864 Validation Decoder Loss:  0.33426487
Encoder Loss:  0.04724734  || Decoder Loss:  0.032058284 Validation Decoder Loss:  0.3342269
Encoder Loss:  0.047279153  || Decoder Loss:  0.03204787 Validation Decoder Loss:  0.33424482
Encoder Loss:  0.04729375  || Decoder Loss:  0.032038376 Validation Decoder Loss:  0.33426178
Encoder Loss:  0.04727941  || Decoder Loss:  0.032029048 Validation Decoder Loss:  0.33426553
Encoder Loss:  0.047265552  || Decoder Loss:  0.03201951 Validation Decoder Loss:  0.3342576
Encoder Loss:  0.047236726  || Decoder Loss:  0.032009777 Validation Decoder Loss:  0.33421826
Encoder Loss:  0.047248583  || Decoder Loss:  0.032000232 Validation Decoder Loss:  0.33421105
Encoder Loss:  0.04722731  || Decoder Loss:  0.031991225 Validation Decoder Loss:  0.33418164
Encoder Loss:  0.047211584  || Decoder Loss:  0.031982232 Validation Decoder Loss:  0.3341787
Model: siamese_net_lr_0.0015876697423256939 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3341787
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_260 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_576 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_261 (Conv3D (None, 634, 5, 20, 1)     546       
_________________________________________________________________
reshape_157 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_524"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_578 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_580 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2874466  || Decoder Loss:  0.29227307 Validation Decoder Loss:  0.7756202
Encoder Loss:  0.2667104  || Decoder Loss:  0.45088923 Validation Decoder Loss:  0.87434065
Encoder Loss:  0.27742594  || Decoder Loss:  0.5014333 Validation Decoder Loss:  0.82577306
Encoder Loss:  0.27266476  || Decoder Loss:  0.49939156 Validation Decoder Loss:  0.81795263
Encoder Loss:  0.27199215  || Decoder Loss:  0.498802 Validation Decoder Loss:  0.80407184
Encoder Loss:  0.27208844  || Decoder Loss:  0.49896115 Validation Decoder Loss:  0.7994079
Encoder Loss:  0.27278906  || Decoder Loss:  0.4986638 Validation Decoder Loss:  0.793273
Encoder Loss:  0.27172792  || Decoder Loss:  0.49863854 Validation Decoder Loss:  0.7905406
Encoder Loss:  0.27213383  || Decoder Loss:  0.4991063 Validation Decoder Loss:  0.780898
Encoder Loss:  0.2735401  || Decoder Loss:  0.4998316 Validation Decoder Loss:  0.7824154
Encoder Loss:  0.27315754  || Decoder Loss:  0.4977255 Validation Decoder Loss:  0.7856876
Encoder Loss:  0.27307093  || Decoder Loss:  0.5013534 Validation Decoder Loss:  0.792575
Encoder Loss:  0.274838  || Decoder Loss:  0.50522333 Validation Decoder Loss:  0.77315295
Encoder Loss:  0.26800546  || Decoder Loss:  0.49187046 Validation Decoder Loss:  1.2185729
Encoder Loss:  0.26729527  || Decoder Loss:  0.49056405 Validation Decoder Loss:  1.2257098
Encoder Loss:  0.25966993  || Decoder Loss:  0.474969 Validation Decoder Loss:  1.2256677
Encoder Loss:  0.2689505  || Decoder Loss:  0.49378455 Validation Decoder Loss:  1.236555
Encoder Loss:  0.2698997  || Decoder Loss:  0.4960236 Validation Decoder Loss:  1.239223
Encoder Loss:  0.27064478  || Decoder Loss:  0.497623 Validation Decoder Loss:  1.2456837
Encoder Loss:  0.27163935  || Decoder Loss:  0.49966353 Validation Decoder Loss:  1.2460918
Encoder Loss:  0.2713962  || Decoder Loss:  0.49917483 Validation Decoder Loss:  1.2472539
Encoder Loss:  0.27162585  || Decoder Loss:  0.49963996 Validation Decoder Loss:  1.2479389
Encoder Loss:  0.2717345  || Decoder Loss:  0.49986112 Validation Decoder Loss:  1.2477734
Encoder Loss:  0.27161416  || Decoder Loss:  0.49961868 Validation Decoder Loss:  1.2483026
Encoder Loss:  0.27157855  || Decoder Loss:  0.49954554 Validation Decoder Loss:  1.2481112
Encoder Loss:  0.2715377  || Decoder Loss:  0.49946362 Validation Decoder Loss:  1.2483482
Encoder Loss:  0.27162275  || Decoder Loss:  0.4996343 Validation Decoder Loss:  1.2487829
Encoder Loss:  0.2716072  || Decoder Loss:  0.49959847 Validation Decoder Loss:  1.2496396
Encoder Loss:  0.27157962  || Decoder Loss:  0.49954915 Validation Decoder Loss:  1.2476847
Encoder Loss:  0.27154452  || Decoder Loss:  0.4994783 Validation Decoder Loss:  1.2506387
Encoder Loss:  0.27151683  || Decoder Loss:  0.4994263 Validation Decoder Loss:  1.2478577
Encoder Loss:  0.27119112  || Decoder Loss:  0.4987673 Validation Decoder Loss:  1.2494328
Encoder Loss:  0.27141604  || Decoder Loss:  0.49922714 Validation Decoder Loss:  1.2496562
Encoder Loss:  0.2714289  || Decoder Loss:  0.4992504 Validation Decoder Loss:  1.2506772
Encoder Loss:  0.27154565  || Decoder Loss:  0.4994841 Validation Decoder Loss:  1.2504822
Encoder Loss:  0.27146173  || Decoder Loss:  0.4993161 Validation Decoder Loss:  1.2505281
Encoder Loss:  0.27154288  || Decoder Loss:  0.49948487 Validation Decoder Loss:  1.2509379
Encoder Loss:  0.27152276  || Decoder Loss:  0.4994454 Validation Decoder Loss:  1.2509003
Encoder Loss:  0.27155656  || Decoder Loss:  0.4995113 Validation Decoder Loss:  1.2522113
Encoder Loss:  0.27154484  || Decoder Loss:  0.49948314 Validation Decoder Loss:  1.2506313
Model: siamese_net_lr_0.046363673417687365 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2506313
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_263 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_582 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_264 (Conv3D (None, 634, 5, 20, 1)     12        
_________________________________________________________________
reshape_158 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 40
Trainable params: 40
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_528"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_584 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_586 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23160851  || Decoder Loss:  0.2508967 Validation Decoder Loss:  0.35352394
Encoder Loss:  0.049421366  || Decoder Loss:  0.034668166 Validation Decoder Loss:  0.33801603
Encoder Loss:  0.042632796  || Decoder Loss:  0.033933714 Validation Decoder Loss:  0.33633697
Encoder Loss:  0.04111852  || Decoder Loss:  0.033591084 Validation Decoder Loss:  0.33650634
Encoder Loss:  0.04163044  || Decoder Loss:  0.033400856 Validation Decoder Loss:  0.33705986
Encoder Loss:  0.041170284  || Decoder Loss:  0.033241004 Validation Decoder Loss:  0.3372637
Encoder Loss:  0.041001678  || Decoder Loss:  0.033097252 Validation Decoder Loss:  0.3378462
Encoder Loss:  0.04072886  || Decoder Loss:  0.032967232 Validation Decoder Loss:  0.33829206
Encoder Loss:  0.040899687  || Decoder Loss:  0.03286404 Validation Decoder Loss:  0.3386017
Encoder Loss:  0.04097789  || Decoder Loss:  0.032780286 Validation Decoder Loss:  0.33897552
Encoder Loss:  0.040831838  || Decoder Loss:  0.03271402 Validation Decoder Loss:  0.33939368
Encoder Loss:  0.041078042  || Decoder Loss:  0.03265947 Validation Decoder Loss:  0.3396342
Encoder Loss:  0.040784977  || Decoder Loss:  0.032617655 Validation Decoder Loss:  0.3398518
Encoder Loss:  0.040964466  || Decoder Loss:  0.032580804 Validation Decoder Loss:  0.34009287
Encoder Loss:  0.040550847  || Decoder Loss:  0.032548185 Validation Decoder Loss:  0.3403786
Encoder Loss:  0.040509347  || Decoder Loss:  0.032517675 Validation Decoder Loss:  0.3406301
Encoder Loss:  0.040178485  || Decoder Loss:  0.032492224 Validation Decoder Loss:  0.3409284
Encoder Loss:  0.04019953  || Decoder Loss:  0.032470644 Validation Decoder Loss:  0.341191
Encoder Loss:  0.04061368  || Decoder Loss:  0.032453276 Validation Decoder Loss:  0.34135365
Encoder Loss:  0.04036989  || Decoder Loss:  0.0324374 Validation Decoder Loss:  0.34155464
Encoder Loss:  0.04064247  || Decoder Loss:  0.03242305 Validation Decoder Loss:  0.34172326
Encoder Loss:  0.04116431  || Decoder Loss:  0.03240982 Validation Decoder Loss:  0.34182984
Encoder Loss:  0.04050673  || Decoder Loss:  0.0323934 Validation Decoder Loss:  0.3418913
Encoder Loss:  0.041132268  || Decoder Loss:  0.032377597 Validation Decoder Loss:  0.34195548
Encoder Loss:  0.04030777  || Decoder Loss:  0.032362457 Validation Decoder Loss:  0.34205532
Encoder Loss:  0.04054884  || Decoder Loss:  0.03234616 Validation Decoder Loss:  0.3421145
Encoder Loss:  0.04065309  || Decoder Loss:  0.032329716 Validation Decoder Loss:  0.34219745
Encoder Loss:  0.039954778  || Decoder Loss:  0.032314405 Validation Decoder Loss:  0.34232348
Encoder Loss:  0.04032638  || Decoder Loss:  0.032300614 Validation Decoder Loss:  0.34244144
Encoder Loss:  0.040156886  || Decoder Loss:  0.032286026 Validation Decoder Loss:  0.34255213
Encoder Loss:  0.041325472  || Decoder Loss:  0.032270446 Validation Decoder Loss:  0.34257233
Encoder Loss:  0.039991215  || Decoder Loss:  0.032255303 Validation Decoder Loss:  0.34269217
Encoder Loss:  0.041172076  || Decoder Loss:  0.032242164 Validation Decoder Loss:  0.3427353
Encoder Loss:  0.040343028  || Decoder Loss:  0.032225657 Validation Decoder Loss:  0.34279677
Encoder Loss:  0.040449534  || Decoder Loss:  0.032208532 Validation Decoder Loss:  0.34289896
Encoder Loss:  0.042339906  || Decoder Loss:  0.032193653 Validation Decoder Loss:  0.34293076
Encoder Loss:  0.040762182  || Decoder Loss:  0.032179702 Validation Decoder Loss:  0.34296268
Encoder Loss:  0.04023087  || Decoder Loss:  0.03216417 Validation Decoder Loss:  0.34304014
Encoder Loss:  0.039975524  || Decoder Loss:  0.032148466 Validation Decoder Loss:  0.34311572
Encoder Loss:  0.040177383  || Decoder Loss:  0.0321321 Validation Decoder Loss:  0.3431549
Model: siamese_net_lr_0.05156457429871584 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3431549
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_266 (Conv3D (None, 148, 5, 20, 1)     23        
_________________________________________________________________
dropout_588 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_267 (Conv3D (None, 634, 5, 20, 1)     47        
_________________________________________________________________
reshape_159 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_590 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_592 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06040069  || Decoder Loss:  0.061832424 Validation Decoder Loss:  0.3509123
Encoder Loss:  0.03856943  || Decoder Loss:  0.03552897 Validation Decoder Loss:  0.34868705
Encoder Loss:  0.037297606  || Decoder Loss:  0.03399462 Validation Decoder Loss:  0.3477232
Encoder Loss:  0.03668298  || Decoder Loss:  0.0332414 Validation Decoder Loss:  0.34697205
Encoder Loss:  0.036278736  || Decoder Loss:  0.032748833 Validation Decoder Loss:  0.34633136
Encoder Loss:  0.036013246  || Decoder Loss:  0.032425568 Validation Decoder Loss:  0.3457883
Encoder Loss:  0.03584737  || Decoder Loss:  0.032225717 Validation Decoder Loss:  0.34534523
Encoder Loss:  0.03574977  || Decoder Loss:  0.032109395 Validation Decoder Loss:  0.34500366
Encoder Loss:  0.03569237  || Decoder Loss:  0.032044116 Validation Decoder Loss:  0.3447613
Encoder Loss:  0.035660725  || Decoder Loss:  0.03200771 Validation Decoder Loss:  0.34459943
Encoder Loss:  0.035642657  || Decoder Loss:  0.03198661 Validation Decoder Loss:  0.34448332
Encoder Loss:  0.035630904  || Decoder Loss:  0.031974934 Validation Decoder Loss:  0.3443882
Encoder Loss:  0.035625376  || Decoder Loss:  0.031968307 Validation Decoder Loss:  0.34432355
Encoder Loss:  0.03562064  || Decoder Loss:  0.031964134 Validation Decoder Loss:  0.3442714
Encoder Loss:  0.03561681  || Decoder Loss:  0.03196064 Validation Decoder Loss:  0.34422004
Encoder Loss:  0.03561412  || Decoder Loss:  0.031958625 Validation Decoder Loss:  0.34417844
Encoder Loss:  0.035612926  || Decoder Loss:  0.03195717 Validation Decoder Loss:  0.34413368
Encoder Loss:  0.035616666  || Decoder Loss:  0.03196016 Validation Decoder Loss:  0.34411532
Encoder Loss:  0.035619613  || Decoder Loss:  0.031967532 Validation Decoder Loss:  0.34408247
Encoder Loss:  0.03562274  || Decoder Loss:  0.031971883 Validation Decoder Loss:  0.34406134
Encoder Loss:  0.035626065  || Decoder Loss:  0.031977445 Validation Decoder Loss:  0.34404022
Encoder Loss:  0.03562727  || Decoder Loss:  0.03197981 Validation Decoder Loss:  0.34402043
Encoder Loss:  0.03562857  || Decoder Loss:  0.031982005 Validation Decoder Loss:  0.34400487
Encoder Loss:  0.03562827  || Decoder Loss:  0.031982463 Validation Decoder Loss:  0.34398264
Encoder Loss:  0.03562841  || Decoder Loss:  0.031983055 Validation Decoder Loss:  0.34396505
Encoder Loss:  0.03562983  || Decoder Loss:  0.031985145 Validation Decoder Loss:  0.343951
Encoder Loss:  0.035633422  || Decoder Loss:  0.03198994 Validation Decoder Loss:  0.3439455
Encoder Loss:  0.03563606  || Decoder Loss:  0.031993806 Validation Decoder Loss:  0.34392545
Encoder Loss:  0.035637688  || Decoder Loss:  0.031996813 Validation Decoder Loss:  0.3439092
Encoder Loss:  0.035641357  || Decoder Loss:  0.03200052 Validation Decoder Loss:  0.34391513
Encoder Loss:  0.035649337  || Decoder Loss:  0.032009404 Validation Decoder Loss:  0.343914
Encoder Loss:  0.035656802  || Decoder Loss:  0.032019544 Validation Decoder Loss:  0.34392032
Encoder Loss:  0.035663642  || Decoder Loss:  0.032029554 Validation Decoder Loss:  0.34390974
Encoder Loss:  0.035672642  || Decoder Loss:  0.032037728 Validation Decoder Loss:  0.34393728
Encoder Loss:  0.03570918  || Decoder Loss:  0.032066554 Validation Decoder Loss:  0.34408957
Encoder Loss:  0.035767287  || Decoder Loss:  0.0321284 Validation Decoder Loss:  0.3441062
Encoder Loss:  0.035916973  || Decoder Loss:  0.032166973 Validation Decoder Loss:  0.34418505
Encoder Loss:  0.036094476  || Decoder Loss:  0.03217759 Validation Decoder Loss:  0.34417808
Encoder Loss:  0.036277477  || Decoder Loss:  0.03220018 Validation Decoder Loss:  0.34438
Encoder Loss:  0.036032025  || Decoder Loss:  0.03233279 Validation Decoder Loss:  0.34467548
Model: siamese_net_lr_0.0012188389868702323 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34467548
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_269 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_594 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_270 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_160 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_596 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_598 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06250162  || Decoder Loss:  0.054732446 Validation Decoder Loss:  0.33632666
Encoder Loss:  0.037127286  || Decoder Loss:  0.03351698 Validation Decoder Loss:  0.33109808
Encoder Loss:  0.036346395  || Decoder Loss:  0.033475447 Validation Decoder Loss:  0.34241575
Encoder Loss:  0.035403308  || Decoder Loss:  0.03251702 Validation Decoder Loss:  0.3443703
Encoder Loss:  0.03526356  || Decoder Loss:  0.03236617 Validation Decoder Loss:  0.3456786
Encoder Loss:  0.03515335  || Decoder Loss:  0.03227248 Validation Decoder Loss:  0.3444748
Encoder Loss:  0.035042033  || Decoder Loss:  0.032177072 Validation Decoder Loss:  0.34400815
Encoder Loss:  0.034939256  || Decoder Loss:  0.032056693 Validation Decoder Loss:  0.34383965
Encoder Loss:  0.034852136  || Decoder Loss:  0.031953357 Validation Decoder Loss:  0.34376752
Encoder Loss:  0.034797464  || Decoder Loss:  0.031889834 Validation Decoder Loss:  0.34327742
Encoder Loss:  0.034759928  || Decoder Loss:  0.031844955 Validation Decoder Loss:  0.34282285
Encoder Loss:  0.03473112  || Decoder Loss:  0.031811062 Validation Decoder Loss:  0.34243912
Encoder Loss:  0.034707036  || Decoder Loss:  0.031782612 Validation Decoder Loss:  0.34205076
Encoder Loss:  0.03468658  || Decoder Loss:  0.031758126 Validation Decoder Loss:  0.34164143
Encoder Loss:  0.03466724  || Decoder Loss:  0.031735193 Validation Decoder Loss:  0.34119987
Encoder Loss:  0.03464978  || Decoder Loss:  0.031713996 Validation Decoder Loss:  0.34071457
Encoder Loss:  0.034632757  || Decoder Loss:  0.031694468 Validation Decoder Loss:  0.340222
Encoder Loss:  0.034628756  || Decoder Loss:  0.031676654 Validation Decoder Loss:  0.33979177
Encoder Loss:  0.035060074  || Decoder Loss:  0.031656634 Validation Decoder Loss:  0.33935338
Encoder Loss:  0.036264833  || Decoder Loss:  0.031633947 Validation Decoder Loss:  0.33720064
Encoder Loss:  0.03845657  || Decoder Loss:  0.03174473 Validation Decoder Loss:  0.3288909
Encoder Loss:  0.03611946  || Decoder Loss:  0.032970943 Validation Decoder Loss:  0.375037
Encoder Loss:  0.03617432  || Decoder Loss:  0.033450894 Validation Decoder Loss:  0.3240606
Encoder Loss:  0.034944855  || Decoder Loss:  0.03204851 Validation Decoder Loss:  0.3306696
Encoder Loss:  0.03473424  || Decoder Loss:  0.031800415 Validation Decoder Loss:  0.33170754
Encoder Loss:  0.034617294  || Decoder Loss:  0.031662535 Validation Decoder Loss:  0.33466637
Encoder Loss:  0.034578267  || Decoder Loss:  0.0316151 Validation Decoder Loss:  0.33459184
Encoder Loss:  0.034562897  || Decoder Loss:  0.031597946 Validation Decoder Loss:  0.33450478
Encoder Loss:  0.03455206  || Decoder Loss:  0.0315861 Validation Decoder Loss:  0.33446807
Encoder Loss:  0.03454354  || Decoder Loss:  0.03157723 Validation Decoder Loss:  0.33455336
Encoder Loss:  0.034536663  || Decoder Loss:  0.03157039 Validation Decoder Loss:  0.3345136
Encoder Loss:  0.03453065  || Decoder Loss:  0.031565715 Validation Decoder Loss:  0.33443397
Encoder Loss:  0.034528136  || Decoder Loss:  0.03156181 Validation Decoder Loss:  0.33432636
Encoder Loss:  0.034524195  || Decoder Loss:  0.0315588 Validation Decoder Loss:  0.33433738
Encoder Loss:  0.034522243  || Decoder Loss:  0.031554785 Validation Decoder Loss:  0.33436877
Encoder Loss:  0.03451604  || Decoder Loss:  0.031551696 Validation Decoder Loss:  0.33429646
Encoder Loss:  0.0345152  || Decoder Loss:  0.031549104 Validation Decoder Loss:  0.33425298
Encoder Loss:  0.03451415  || Decoder Loss:  0.03154602 Validation Decoder Loss:  0.33426636
Encoder Loss:  0.034509555  || Decoder Loss:  0.03154251 Validation Decoder Loss:  0.33429497
Encoder Loss:  0.034507807  || Decoder Loss:  0.031540878 Validation Decoder Loss:  0.33420724
Model: siamese_net_lr_0.019518527641190195 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3342072
Model: "sequential_538"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_272 (Conv3D (None, 252, 5, 20, 1)     190       
_________________________________________________________________
dropout_600 (Dropout)        (None, 252, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_273 (Conv3D (None, 634, 5, 20, 1)     384       
_________________________________________________________________
reshape_161 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_602 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_604 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4434415  || Decoder Loss:  0.45694187 Validation Decoder Loss:  1.0061462
Encoder Loss:  0.45953837  || Decoder Loss:  0.4936161 Validation Decoder Loss:  0.95514965
Encoder Loss:  0.46551403  || Decoder Loss:  0.5041176 Validation Decoder Loss:  0.93969446
Encoder Loss:  0.45916307  || Decoder Loss:  0.49757454 Validation Decoder Loss:  0.9145969
Encoder Loss:  0.46013945  || Decoder Loss:  0.49848107 Validation Decoder Loss:  0.9279242
Encoder Loss:  0.46130362  || Decoder Loss:  0.49990734 Validation Decoder Loss:  0.92646784
Encoder Loss:  0.45985726  || Decoder Loss:  0.49820125 Validation Decoder Loss:  0.93155956
Encoder Loss:  0.46198025  || Decoder Loss:  0.50062984 Validation Decoder Loss:  0.8995427
Encoder Loss:  0.4606363  || Decoder Loss:  0.4992597 Validation Decoder Loss:  0.91684043
Encoder Loss:  0.45929074  || Decoder Loss:  0.49764338 Validation Decoder Loss:  0.90005696
Encoder Loss:  0.46031344  || Decoder Loss:  0.49911758 Validation Decoder Loss:  0.88283455
Encoder Loss:  0.46005484  || Decoder Loss:  0.49880683 Validation Decoder Loss:  0.88303447
Encoder Loss:  0.45835286  || Decoder Loss:  0.4966924 Validation Decoder Loss:  0.94062746
Encoder Loss:  0.45464572  || Decoder Loss:  0.49257332 Validation Decoder Loss:  0.8591452
Encoder Loss:  0.45893258  || Decoder Loss:  0.49759454 Validation Decoder Loss:  0.8552136
Encoder Loss:  0.45680115  || Decoder Loss:  0.4951009 Validation Decoder Loss:  0.84608305
Encoder Loss:  0.45596474  || Decoder Loss:  0.4942147 Validation Decoder Loss:  0.8478129
Encoder Loss:  0.45772472  || Decoder Loss:  0.49579412 Validation Decoder Loss:  1.0594687
Encoder Loss:  0.4568788  || Decoder Loss:  0.49509257 Validation Decoder Loss:  0.76364696
Encoder Loss:  0.45277625  || Decoder Loss:  0.49073312 Validation Decoder Loss:  0.76705253
Encoder Loss:  0.4519576  || Decoder Loss:  0.48983964 Validation Decoder Loss:  0.8370658
Encoder Loss:  0.4515656  || Decoder Loss:  0.4894495 Validation Decoder Loss:  0.8250445
Encoder Loss:  0.45916644  || Decoder Loss:  0.49777606 Validation Decoder Loss:  0.83519053
Encoder Loss:  0.4592203  || Decoder Loss:  0.4978048 Validation Decoder Loss:  0.8230828
Encoder Loss:  0.45981294  || Decoder Loss:  0.4978309 Validation Decoder Loss:  0.82201946
Encoder Loss:  0.45966417  || Decoder Loss:  0.49797752 Validation Decoder Loss:  0.8396914
Encoder Loss:  0.4587908  || Decoder Loss:  0.4970639 Validation Decoder Loss:  0.8927109
Encoder Loss:  0.45269784  || Decoder Loss:  0.49070895 Validation Decoder Loss:  1.0281587
Encoder Loss:  0.4565308  || Decoder Loss:  0.49472564 Validation Decoder Loss:  1.0991822
Encoder Loss:  0.45892963  || Decoder Loss:  0.49761838 Validation Decoder Loss:  1.0885103
Encoder Loss:  0.45644814  || Decoder Loss:  0.49472564 Validation Decoder Loss:  0.7564272
Encoder Loss:  0.45385468  || Decoder Loss:  0.4919286 Validation Decoder Loss:  0.76904535
Encoder Loss:  0.45366657  || Decoder Loss:  0.49171126 Validation Decoder Loss:  0.8800909
Encoder Loss:  0.4536358  || Decoder Loss:  0.49172324 Validation Decoder Loss:  0.75765127
Encoder Loss:  0.4551044  || Decoder Loss:  0.49333078 Validation Decoder Loss:  0.7559058
Encoder Loss:  0.45521313  || Decoder Loss:  0.49342147 Validation Decoder Loss:  0.77709794
Encoder Loss:  0.45416847  || Decoder Loss:  0.49242428 Validation Decoder Loss:  0.9058455
Encoder Loss:  0.45367047  || Decoder Loss:  0.49186742 Validation Decoder Loss:  0.8267399
Encoder Loss:  0.45460385  || Decoder Loss:  0.4928781 Validation Decoder Loss:  0.8906958
Encoder Loss:  0.45380306  || Decoder Loss:  0.4920642 Validation Decoder Loss:  0.8087843
Model: siamese_net_lr_0.06999938230465023 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8087843
Model: "sequential_542"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_275 (Conv3D (None, 348, 5, 20, 1)     97        
_________________________________________________________________
dropout_606 (Dropout)        (None, 348, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_276 (Conv3D (None, 634, 5, 20, 1)     288       
_________________________________________________________________
reshape_162 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_608 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 3220, 20, 1)       52        
_________________________________________________________________
dropout_610 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 3245, 20, 1)       27        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43223846  || Decoder Loss:  0.4337444 Validation Decoder Loss:  1.3432055
Encoder Loss:  0.7259754  || Decoder Loss:  0.7316234 Validation Decoder Loss:  0.81410706
Encoder Loss:  0.5725311  || Decoder Loss:  0.5779037 Validation Decoder Loss:  1.5495358
Encoder Loss:  0.59948707  || Decoder Loss:  0.6051668 Validation Decoder Loss:  1.3676157
Encoder Loss:  0.4820719  || Decoder Loss:  0.4865485 Validation Decoder Loss:  1.0935843
Encoder Loss:  0.4465847  || Decoder Loss:  0.4506945 Validation Decoder Loss:  1.0841454
Encoder Loss:  0.44443044  || Decoder Loss:  0.44851807 Validation Decoder Loss:  1.0748184
Encoder Loss:  0.44257355  || Decoder Loss:  0.4466419 Validation Decoder Loss:  1.0669366
Encoder Loss:  0.44082147  || Decoder Loss:  0.44487178 Validation Decoder Loss:  1.0577551
Encoder Loss:  0.43888476  || Decoder Loss:  0.44291505 Validation Decoder Loss:  1.0494083
Encoder Loss:  0.4369701  || Decoder Loss:  0.44098052 Validation Decoder Loss:  1.0397836
Encoder Loss:  0.43504488  || Decoder Loss:  0.43903542 Validation Decoder Loss:  1.0311419
Encoder Loss:  0.43304244  || Decoder Loss:  0.4370121 Validation Decoder Loss:  1.0222355
Encoder Loss:  0.43108958  || Decoder Loss:  0.4350391 Validation Decoder Loss:  1.0121081
Encoder Loss:  0.42906865  || Decoder Loss:  0.4329972 Validation Decoder Loss:  1.0021558
Encoder Loss:  0.4270476  || Decoder Loss:  0.4309552 Validation Decoder Loss:  0.9911579
Encoder Loss:  0.42591378  || Decoder Loss:  0.42980966 Validation Decoder Loss:  0.9855853
Encoder Loss:  0.42524377  || Decoder Loss:  0.42913276 Validation Decoder Loss:  0.98505664
Encoder Loss:  0.42548156  || Decoder Loss:  0.42937294 Validation Decoder Loss:  0.9876431
Encoder Loss:  0.42530468  || Decoder Loss:  0.42919418 Validation Decoder Loss:  0.9884056
Encoder Loss:  0.42638126  || Decoder Loss:  0.43028203 Validation Decoder Loss:  0.9943667
Encoder Loss:  0.42690545  || Decoder Loss:  0.43081164 Validation Decoder Loss:  0.99922115
Encoder Loss:  0.42832702  || Decoder Loss:  0.43224785 Validation Decoder Loss:  1.005675
Encoder Loss:  0.4286389  || Decoder Loss:  0.43256298 Validation Decoder Loss:  1.0047113
Encoder Loss:  0.42743358  || Decoder Loss:  0.43134516 Validation Decoder Loss:  1.0055429
Encoder Loss:  0.4282676  || Decoder Loss:  0.4321878 Validation Decoder Loss:  1.0093833
Encoder Loss:  0.4288134  || Decoder Loss:  0.43273938 Validation Decoder Loss:  1.0102289
Encoder Loss:  0.42897147  || Decoder Loss:  0.43289903 Validation Decoder Loss:  1.0091853
Encoder Loss:  0.42784783  || Decoder Loss:  0.43176374 Validation Decoder Loss:  1.0152471
Encoder Loss:  0.43625867  || Decoder Loss:  0.4402617 Validation Decoder Loss:  1.0352309
Encoder Loss:  0.4355809  || Decoder Loss:  0.439577 Validation Decoder Loss:  1.0407327
Encoder Loss:  0.4359148  || Decoder Loss:  0.43991432 Validation Decoder Loss:  1.0426562
Encoder Loss:  0.4364194  || Decoder Loss:  0.44042414 Validation Decoder Loss:  1.0464058
Encoder Loss:  0.43733063  || Decoder Loss:  0.4413448 Validation Decoder Loss:  1.0518894
Encoder Loss:  0.43871242  || Decoder Loss:  0.44274095 Validation Decoder Loss:  1.0577694
Encoder Loss:  0.44010437  || Decoder Loss:  0.44414738 Validation Decoder Loss:  1.0541389
Encoder Loss:  0.44114032  || Decoder Loss:  0.445194 Validation Decoder Loss:  1.0634975
Encoder Loss:  0.44112888  || Decoder Loss:  0.44518244 Validation Decoder Loss:  1.0558991
Encoder Loss:  0.4395432  || Decoder Loss:  0.4435804 Validation Decoder Loss:  1.0645506
Encoder Loss:  0.44214422  || Decoder Loss:  0.44620836 Validation Decoder Loss:  1.0711458
Model: siamese_net_lr_0.09965600224171318 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0711458
Model: "sequential_546"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_278 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_612 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_279 (Conv3D (None, 634, 5, 20, 1)     386       
_________________________________________________________________
reshape_163 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 408
Trainable params: 408
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_614 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_616 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15293074  || Decoder Loss:  0.074828945 Validation Decoder Loss:  0.51886773
Encoder Loss:  0.08006817  || Decoder Loss:  0.07420889 Validation Decoder Loss:  0.31933302
Encoder Loss:  0.04461331  || Decoder Loss:  0.03690907 Validation Decoder Loss:  0.35849956
Encoder Loss:  0.042062502  || Decoder Loss:  0.03317385 Validation Decoder Loss:  0.34307992
Encoder Loss:  0.04222323  || Decoder Loss:  0.032806903 Validation Decoder Loss:  0.34250155
Encoder Loss:  0.04176094  || Decoder Loss:  0.032740008 Validation Decoder Loss:  0.34102982
Encoder Loss:  0.041536164  || Decoder Loss:  0.03269813 Validation Decoder Loss:  0.34031677
Encoder Loss:  0.042001218  || Decoder Loss:  0.032680947 Validation Decoder Loss:  0.34034014
Encoder Loss:  0.04180465  || Decoder Loss:  0.0326579 Validation Decoder Loss:  0.3402909
Encoder Loss:  0.041497506  || Decoder Loss:  0.032653566 Validation Decoder Loss:  0.3397289
Encoder Loss:  0.04179607  || Decoder Loss:  0.032626282 Validation Decoder Loss:  0.34151864
Encoder Loss:  0.04127806  || Decoder Loss:  0.032591134 Validation Decoder Loss:  0.3420142
Encoder Loss:  0.04205822  || Decoder Loss:  0.03256949 Validation Decoder Loss:  0.34237057
Encoder Loss:  0.041412335  || Decoder Loss:  0.032555077 Validation Decoder Loss:  0.3419266
Encoder Loss:  0.04121323  || Decoder Loss:  0.032542497 Validation Decoder Loss:  0.34233254
Encoder Loss:  0.04090888  || Decoder Loss:  0.032527234 Validation Decoder Loss:  0.3421181
Encoder Loss:  0.04157395  || Decoder Loss:  0.032513168 Validation Decoder Loss:  0.3419559
Encoder Loss:  0.04137875  || Decoder Loss:  0.032502614 Validation Decoder Loss:  0.34195662
Encoder Loss:  0.041546546  || Decoder Loss:  0.03249068 Validation Decoder Loss:  0.34205586
Encoder Loss:  0.041154094  || Decoder Loss:  0.032482557 Validation Decoder Loss:  0.3419875
Encoder Loss:  0.041746654  || Decoder Loss:  0.032470122 Validation Decoder Loss:  0.34211025
Encoder Loss:  0.04259676  || Decoder Loss:  0.0324612 Validation Decoder Loss:  0.34134874
Encoder Loss:  0.041259374  || Decoder Loss:  0.032453064 Validation Decoder Loss:  0.3416403
Encoder Loss:  0.04129226  || Decoder Loss:  0.03244312 Validation Decoder Loss:  0.34123385
Encoder Loss:  0.041164506  || Decoder Loss:  0.032430712 Validation Decoder Loss:  0.34082672
Encoder Loss:  0.041643605  || Decoder Loss:  0.032422658 Validation Decoder Loss:  0.3410144
Encoder Loss:  0.041050363  || Decoder Loss:  0.032412317 Validation Decoder Loss:  0.3408929
Encoder Loss:  0.04151951  || Decoder Loss:  0.032403838 Validation Decoder Loss:  0.34152514
Encoder Loss:  0.04213232  || Decoder Loss:  0.032407902 Validation Decoder Loss:  0.34050912
Encoder Loss:  0.041027155  || Decoder Loss:  0.03239289 Validation Decoder Loss:  0.34065393
Encoder Loss:  0.040891882  || Decoder Loss:  0.032381654 Validation Decoder Loss:  0.3406574
Encoder Loss:  0.04144353  || Decoder Loss:  0.032387596 Validation Decoder Loss:  0.3404379
Encoder Loss:  0.041018553  || Decoder Loss:  0.032383643 Validation Decoder Loss:  0.34036788
Encoder Loss:  0.040984135  || Decoder Loss:  0.032387093 Validation Decoder Loss:  0.34092712
Encoder Loss:  0.04131862  || Decoder Loss:  0.03242535 Validation Decoder Loss:  0.34109524
Encoder Loss:  0.04109384  || Decoder Loss:  0.032579087 Validation Decoder Loss:  0.34132552
Encoder Loss:  0.041115373  || Decoder Loss:  0.032437824 Validation Decoder Loss:  0.34071863
Encoder Loss:  0.040973507  || Decoder Loss:  0.0325948 Validation Decoder Loss:  0.34278387
Encoder Loss:  0.040537626  || Decoder Loss:  0.032421477 Validation Decoder Loss:  0.34074372
Encoder Loss:  0.041152205  || Decoder Loss:  0.032478612 Validation Decoder Loss:  0.3413397
Model: siamese_net_lr_0.030650584933547612 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3413397
Model: "sequential_550"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_281 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_618 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_282 (Conv3D (None, 634, 5, 20, 1)     89        
_________________________________________________________________
reshape_164 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_620 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_622 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06569702  || Decoder Loss:  0.056295466 Validation Decoder Loss:  0.34401333
Encoder Loss:  0.037742294  || Decoder Loss:  0.0323383 Validation Decoder Loss:  0.34334707
Encoder Loss:  0.037523527  || Decoder Loss:  0.031883582 Validation Decoder Loss:  0.34312642
Encoder Loss:  0.03738534  || Decoder Loss:  0.031798556 Validation Decoder Loss:  0.34242943
Encoder Loss:  0.037296273  || Decoder Loss:  0.031735122 Validation Decoder Loss:  0.34216374
Encoder Loss:  0.037240077  || Decoder Loss:  0.031670053 Validation Decoder Loss:  0.34174716
Encoder Loss:  0.03704884  || Decoder Loss:  0.03160788 Validation Decoder Loss:  0.34214988
Encoder Loss:  0.036944292  || Decoder Loss:  0.03156721 Validation Decoder Loss:  0.34196734
Encoder Loss:  0.03681885  || Decoder Loss:  0.031515647 Validation Decoder Loss:  0.342003
Encoder Loss:  0.03679175  || Decoder Loss:  0.03149589 Validation Decoder Loss:  0.34200054
Encoder Loss:  0.036775813  || Decoder Loss:  0.03148231 Validation Decoder Loss:  0.3420564
Encoder Loss:  0.036758468  || Decoder Loss:  0.03146513 Validation Decoder Loss:  0.34198815
Encoder Loss:  0.036740422  || Decoder Loss:  0.031445395 Validation Decoder Loss:  0.34201318
Encoder Loss:  0.03672465  || Decoder Loss:  0.031425934 Validation Decoder Loss:  0.34201896
Encoder Loss:  0.036710344  || Decoder Loss:  0.0314088 Validation Decoder Loss:  0.34204632
Encoder Loss:  0.03669889  || Decoder Loss:  0.031392593 Validation Decoder Loss:  0.34204516
Encoder Loss:  0.036684338  || Decoder Loss:  0.0313748 Validation Decoder Loss:  0.34215826
Encoder Loss:  0.03667127  || Decoder Loss:  0.03135667 Validation Decoder Loss:  0.3421594
Encoder Loss:  0.03664941  || Decoder Loss:  0.03132824 Validation Decoder Loss:  0.34231374
Encoder Loss:  0.036634278  || Decoder Loss:  0.03130847 Validation Decoder Loss:  0.342386
Encoder Loss:  0.03662332  || Decoder Loss:  0.031294204 Validation Decoder Loss:  0.34244356
Encoder Loss:  0.03661574  || Decoder Loss:  0.031284876 Validation Decoder Loss:  0.3425126
Encoder Loss:  0.03661062  || Decoder Loss:  0.031279165 Validation Decoder Loss:  0.34254783
Encoder Loss:  0.036608577  || Decoder Loss:  0.031277537 Validation Decoder Loss:  0.3425973
Encoder Loss:  0.036608033  || Decoder Loss:  0.031278037 Validation Decoder Loss:  0.34262305
Encoder Loss:  0.036608838  || Decoder Loss:  0.03127985 Validation Decoder Loss:  0.34263223
Encoder Loss:  0.03660881  || Decoder Loss:  0.031280484 Validation Decoder Loss:  0.3426329
Encoder Loss:  0.036608234  || Decoder Loss:  0.031280693 Validation Decoder Loss:  0.34262937
Encoder Loss:  0.036608152  || Decoder Loss:  0.03128103 Validation Decoder Loss:  0.3426389
Encoder Loss:  0.03660792  || Decoder Loss:  0.03128175 Validation Decoder Loss:  0.34264588
Encoder Loss:  0.036608543  || Decoder Loss:  0.031283304 Validation Decoder Loss:  0.34265193
Encoder Loss:  0.036610633  || Decoder Loss:  0.031285215 Validation Decoder Loss:  0.3426572
Encoder Loss:  0.0366105  || Decoder Loss:  0.031285997 Validation Decoder Loss:  0.34264576
Encoder Loss:  0.036609672  || Decoder Loss:  0.031286243 Validation Decoder Loss:  0.34263584
Encoder Loss:  0.036609527  || Decoder Loss:  0.03128771 Validation Decoder Loss:  0.3426323
Encoder Loss:  0.036610715  || Decoder Loss:  0.031290278 Validation Decoder Loss:  0.34264103
Encoder Loss:  0.036612853  || Decoder Loss:  0.03129307 Validation Decoder Loss:  0.3426314
Encoder Loss:  0.03661404  || Decoder Loss:  0.031295698 Validation Decoder Loss:  0.34263822
Encoder Loss:  0.03661499  || Decoder Loss:  0.031298026 Validation Decoder Loss:  0.34265682
Encoder Loss:  0.036618236  || Decoder Loss:  0.031301223 Validation Decoder Loss:  0.34265
Model: siamese_net_lr_0.022385949820533872 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34265003
Model: "sequential_554"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_284 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_624 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_285 (Conv3D (None, 634, 5, 20, 1)     380       
_________________________________________________________________
reshape_165 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 404
Trainable params: 404
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_626 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 3170, 20, 1)       2         
_________________________________________________________________
dropout_628 (Dropout)        (None, 3170, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39510646  || Decoder Loss:  0.39690128 Validation Decoder Loss:  0.58878964
Encoder Loss:  0.30112448  || Decoder Loss:  0.30262098 Validation Decoder Loss:  0.41035053
Encoder Loss:  0.04384018  || Decoder Loss:  0.043763384 Validation Decoder Loss:  0.35592508
Encoder Loss:  0.03345895  || Decoder Loss:  0.033334073 Validation Decoder Loss:  0.3245318
Encoder Loss:  0.032530032  || Decoder Loss:  0.032408185 Validation Decoder Loss:  0.33504966
Encoder Loss:  0.032476116  || Decoder Loss:  0.032332722 Validation Decoder Loss:  0.336582
Encoder Loss:  0.032435667  || Decoder Loss:  0.03231713 Validation Decoder Loss:  0.33629507
Encoder Loss:  0.032417674  || Decoder Loss:  0.03230525 Validation Decoder Loss:  0.33629906
Encoder Loss:  0.03241979  || Decoder Loss:  0.032295335 Validation Decoder Loss:  0.3360811
Encoder Loss:  0.032439306  || Decoder Loss:  0.0322833 Validation Decoder Loss:  0.3372202
Encoder Loss:  0.03238728  || Decoder Loss:  0.032271788 Validation Decoder Loss:  0.33575737
Encoder Loss:  0.03236904  || Decoder Loss:  0.032259386 Validation Decoder Loss:  0.33595824
Encoder Loss:  0.032353602  || Decoder Loss:  0.032244623 Validation Decoder Loss:  0.33582762
Encoder Loss:  0.03234294  || Decoder Loss:  0.032233715 Validation Decoder Loss:  0.3358646
Encoder Loss:  0.032330543  || Decoder Loss:  0.032220844 Validation Decoder Loss:  0.33590645
Encoder Loss:  0.032317795  || Decoder Loss:  0.032208662 Validation Decoder Loss:  0.33580917
Encoder Loss:  0.03230294  || Decoder Loss:  0.03219386 Validation Decoder Loss:  0.33580005
Encoder Loss:  0.032290448  || Decoder Loss:  0.032181334 Validation Decoder Loss:  0.33577386
Encoder Loss:  0.03227823  || Decoder Loss:  0.032169085 Validation Decoder Loss:  0.33576888
Encoder Loss:  0.032264937  || Decoder Loss:  0.032155722 Validation Decoder Loss:  0.33574742
Encoder Loss:  0.032251824  || Decoder Loss:  0.03214255 Validation Decoder Loss:  0.33570868
Encoder Loss:  0.032238755  || Decoder Loss:  0.032129385 Validation Decoder Loss:  0.33568078
Encoder Loss:  0.03222551  || Decoder Loss:  0.032116074 Validation Decoder Loss:  0.33563018
Encoder Loss:  0.032211766  || Decoder Loss:  0.032102246 Validation Decoder Loss:  0.3355623
Encoder Loss:  0.03219816  || Decoder Loss:  0.032088563 Validation Decoder Loss:  0.33551365
Encoder Loss:  0.032184336  || Decoder Loss:  0.032074668 Validation Decoder Loss:  0.33544654
Encoder Loss:  0.032170225  || Decoder Loss:  0.032060485 Validation Decoder Loss:  0.33540952
Encoder Loss:  0.032156795  || Decoder Loss:  0.032046933 Validation Decoder Loss:  0.33535767
Encoder Loss:  0.03214219  || Decoder Loss:  0.032032285 Validation Decoder Loss:  0.33533502
Encoder Loss:  0.03212862  || Decoder Loss:  0.0320186 Validation Decoder Loss:  0.33532363
Encoder Loss:  0.03211415  || Decoder Loss:  0.03200395 Validation Decoder Loss:  0.3352223
Encoder Loss:  0.032099128  || Decoder Loss:  0.03198869 Validation Decoder Loss:  0.33522516
Encoder Loss:  0.03208701  || Decoder Loss:  0.031972323 Validation Decoder Loss:  0.33510536
Encoder Loss:  0.03209719  || Decoder Loss:  0.03195993 Validation Decoder Loss:  0.33667162
Encoder Loss:  0.032091156  || Decoder Loss:  0.031946093 Validation Decoder Loss:  0.33406863
Encoder Loss:  0.03205991  || Decoder Loss:  0.031932138 Validation Decoder Loss:  0.3341938
Encoder Loss:  0.032032225  || Decoder Loss:  0.03191299 Validation Decoder Loss:  0.33511668
Encoder Loss:  0.032011475  || Decoder Loss:  0.03189829 Validation Decoder Loss:  0.33489192
Encoder Loss:  0.031992484  || Decoder Loss:  0.03188121 Validation Decoder Loss:  0.33468497
Encoder Loss:  0.031978432  || Decoder Loss:  0.03186655 Validation Decoder Loss:  0.33471268
Model: siamese_net_lr_0.0321229344066151 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3347127
Model: "sequential_558"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_287 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
conv3d_transpose_288 (Conv3D (None, 634, 5, 20, 1)     190       
_________________________________________________________________
reshape_166 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 218
Trainable params: 218
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3653553  || Decoder Loss:  0.4336492 Validation Decoder Loss:  0.814793
Encoder Loss:  0.35033333  || Decoder Loss:  0.41950348 Validation Decoder Loss:  0.37662804
Encoder Loss:  0.055002645  || Decoder Loss:  0.055233106 Validation Decoder Loss:  0.34717166
Encoder Loss:  0.037602223  || Decoder Loss:  0.03310966 Validation Decoder Loss:  0.34280527
Encoder Loss:  0.038845833  || Decoder Loss:  0.032629825 Validation Decoder Loss:  0.34214655
Encoder Loss:  0.037036575  || Decoder Loss:  0.03247796 Validation Decoder Loss:  0.33836877
Encoder Loss:  0.036520954  || Decoder Loss:  0.03244231 Validation Decoder Loss:  0.33836716
Encoder Loss:  0.036583878  || Decoder Loss:  0.032436557 Validation Decoder Loss:  0.3391829
Encoder Loss:  0.03705604  || Decoder Loss:  0.03245156 Validation Decoder Loss:  0.34062147
Encoder Loss:  0.036526237  || Decoder Loss:  0.032450136 Validation Decoder Loss:  0.3389501
Encoder Loss:  0.036264416  || Decoder Loss:  0.03242384 Validation Decoder Loss:  0.33963814
Encoder Loss:  0.036424395  || Decoder Loss:  0.03242519 Validation Decoder Loss:  0.33887935
Encoder Loss:  0.03665382  || Decoder Loss:  0.03240888 Validation Decoder Loss:  0.34018153
Encoder Loss:  0.03704872  || Decoder Loss:  0.03242554 Validation Decoder Loss:  0.33918548
Encoder Loss:  0.03633432  || Decoder Loss:  0.032401815 Validation Decoder Loss:  0.33968776
Encoder Loss:  0.036093406  || Decoder Loss:  0.032408316 Validation Decoder Loss:  0.3403589
Encoder Loss:  0.036472663  || Decoder Loss:  0.032469258 Validation Decoder Loss:  0.34046566
Encoder Loss:  0.036091365  || Decoder Loss:  0.03240967 Validation Decoder Loss:  0.33837706
Encoder Loss:  0.035978213  || Decoder Loss:  0.032385238 Validation Decoder Loss:  0.33841965
Encoder Loss:  0.035943564  || Decoder Loss:  0.03236897 Validation Decoder Loss:  0.33842072
Encoder Loss:  0.03593328  || Decoder Loss:  0.03236651 Validation Decoder Loss:  0.3381189
Encoder Loss:  0.0359274  || Decoder Loss:  0.03236197 Validation Decoder Loss:  0.33806208
Encoder Loss:  0.035919834  || Decoder Loss:  0.03235309 Validation Decoder Loss:  0.33819425
Encoder Loss:  0.035912123  || Decoder Loss:  0.03234318 Validation Decoder Loss:  0.3385899
Encoder Loss:  0.035908453  || Decoder Loss:  0.0323391 Validation Decoder Loss:  0.33865893
Encoder Loss:  0.035902992  || Decoder Loss:  0.032332864 Validation Decoder Loss:  0.33877784
Encoder Loss:  0.0358991  || Decoder Loss:  0.03232809 Validation Decoder Loss:  0.33883262
Encoder Loss:  0.03589564  || Decoder Loss:  0.032324165 Validation Decoder Loss:  0.3387699
Encoder Loss:  0.03589249  || Decoder Loss:  0.032321177 Validation Decoder Loss:  0.338722
Encoder Loss:  0.035886604  || Decoder Loss:  0.032313693 Validation Decoder Loss:  0.33882684
Encoder Loss:  0.03588246  || Decoder Loss:  0.032308444 Validation Decoder Loss:  0.33896938
Encoder Loss:  0.03588153  || Decoder Loss:  0.032307748 Validation Decoder Loss:  0.33867443
Encoder Loss:  0.03587758  || Decoder Loss:  0.03230333 Validation Decoder Loss:  0.33875754
Encoder Loss:  0.035869386  || Decoder Loss:  0.03229295 Validation Decoder Loss:  0.33907783
Encoder Loss:  0.035863698  || Decoder Loss:  0.0322857 Validation Decoder Loss:  0.3394447
Encoder Loss:  0.03586498  || Decoder Loss:  0.032285973 Validation Decoder Loss:  0.33899423
Encoder Loss:  0.035856858  || Decoder Loss:  0.032278243 Validation Decoder Loss:  0.33916482
Encoder Loss:  0.03584974  || Decoder Loss:  0.032270305 Validation Decoder Loss:  0.33950377
Encoder Loss:  0.0358458  || Decoder Loss:  0.03226567 Validation Decoder Loss:  0.33947515
Encoder Loss:  0.035842914  || Decoder Loss:  0.03226231 Validation Decoder Loss:  0.33933315
Model: siamese_net_lr_0.047402393695402036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33933315
Model: "sequential_562"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_290 (Conv3D (None, 612, 5, 20, 1)     550       
_________________________________________________________________
dropout_630 (Dropout)        (None, 612, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_291 (Conv3D (None, 634, 5, 20, 1)     24        
_________________________________________________________________
reshape_167 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_632 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_565"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_634 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34144202  || Decoder Loss:  0.073724076 Validation Decoder Loss:  0.35043886
Encoder Loss:  0.36719745  || Decoder Loss:  0.036672127 Validation Decoder Loss:  0.35093784
Encoder Loss:  0.36695334  || Decoder Loss:  0.036926802 Validation Decoder Loss:  0.35197937
Encoder Loss:  0.36652228  || Decoder Loss:  0.037380148 Validation Decoder Loss:  0.35358623
Encoder Loss:  0.36587214  || Decoder Loss:  0.038119987 Validation Decoder Loss:  0.35607064
Encoder Loss:  0.36485696  || Decoder Loss:  0.03937129 Validation Decoder Loss:  0.3600483
Encoder Loss:  0.36315838  || Decoder Loss:  0.04161877 Validation Decoder Loss:  0.36681342
Encoder Loss:  0.3600026  || Decoder Loss:  0.046042904 Validation Decoder Loss:  0.37964195
Encoder Loss:  0.35285854  || Decoder Loss:  0.056493595 Validation Decoder Loss:  0.4115327
Encoder Loss:  0.38463792  || Decoder Loss:  0.38798383 Validation Decoder Loss:  1.5256553
Encoder Loss:  0.35963506  || Decoder Loss:  0.76883096 Validation Decoder Loss:  0.77483475
Encoder Loss:  0.16571695  || Decoder Loss:  0.46420112 Validation Decoder Loss:  0.818903
Encoder Loss:  0.1439315  || Decoder Loss:  0.49516946 Validation Decoder Loss:  0.86245704
Encoder Loss:  0.13811521  || Decoder Loss:  0.495834 Validation Decoder Loss:  0.87732065
Encoder Loss:  0.13571206  || Decoder Loss:  0.49827358 Validation Decoder Loss:  0.8694372
Encoder Loss:  0.13465048  || Decoder Loss:  0.49577165 Validation Decoder Loss:  0.8725557
Encoder Loss:  0.13447107  || Decoder Loss:  0.49590558 Validation Decoder Loss:  0.8815224
Encoder Loss:  0.13173942  || Decoder Loss:  0.49168858 Validation Decoder Loss:  0.84073055
Encoder Loss:  0.13254538  || Decoder Loss:  0.4915187 Validation Decoder Loss:  1.0914202
Encoder Loss:  0.13396674  || Decoder Loss:  0.4971305 Validation Decoder Loss:  1.0999925
Encoder Loss:  0.13439621  || Decoder Loss:  0.49895084 Validation Decoder Loss:  1.1157708
Encoder Loss:  0.13637772  || Decoder Loss:  0.49734554 Validation Decoder Loss:  1.1156728
Encoder Loss:  0.13432695  || Decoder Loss:  0.4986771 Validation Decoder Loss:  1.1150796
Encoder Loss:  0.13630381  || Decoder Loss:  0.49707744 Validation Decoder Loss:  1.1171219
Encoder Loss:  0.13432682  || Decoder Loss:  0.49880782 Validation Decoder Loss:  1.116281
Encoder Loss:  0.13340753  || Decoder Loss:  0.49812588 Validation Decoder Loss:  1.1140277
Encoder Loss:  0.13447504  || Decoder Loss:  0.5003197 Validation Decoder Loss:  1.1097502
Encoder Loss:  0.13452312  || Decoder Loss:  0.49962926 Validation Decoder Loss:  1.1181395
Encoder Loss:  0.13482888  || Decoder Loss:  0.49862438 Validation Decoder Loss:  1.1342978
Encoder Loss:  0.13400339  || Decoder Loss:  0.4966724 Validation Decoder Loss:  1.1416842
Encoder Loss:  0.13477439  || Decoder Loss:  0.49852115 Validation Decoder Loss:  1.1223552
Encoder Loss:  0.13333412  || Decoder Loss:  0.49820492 Validation Decoder Loss:  1.1176999
Encoder Loss:  0.13471998  || Decoder Loss:  0.49913338 Validation Decoder Loss:  1.1251763
Encoder Loss:  0.13352174  || Decoder Loss:  0.49918205 Validation Decoder Loss:  1.1448929
Encoder Loss:  0.13503437  || Decoder Loss:  0.500385 Validation Decoder Loss:  1.1461927
Encoder Loss:  0.13483995  || Decoder Loss:  0.50065076 Validation Decoder Loss:  1.1345814
Encoder Loss:  0.13275719  || Decoder Loss:  0.49867138 Validation Decoder Loss:  1.1494496
Encoder Loss:  0.13381368  || Decoder Loss:  0.4996944 Validation Decoder Loss:  1.1396148
Encoder Loss:  0.13379365  || Decoder Loss:  0.49825603 Validation Decoder Loss:  1.1507435
Encoder Loss:  0.13565655  || Decoder Loss:  0.49832088 Validation Decoder Loss:  1.1392431
Model: siamese_net_lr_0.06613486539770581 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1392431
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_293 (Conv3D (None, 232, 5, 20, 1)     107       
_________________________________________________________________
dropout_636 (Dropout)        (None, 232, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_294 (Conv3D (None, 634, 5, 20, 1)     404       
_________________________________________________________________
reshape_168 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 511
Trainable params: 511
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 3190, 20, 1)       57        
_________________________________________________________________
dropout_638 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 3170, 20, 1)       22        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_569"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_640 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5107351  || Decoder Loss:  0.8836951 Validation Decoder Loss:  1.5880749
Encoder Loss:  0.5069266  || Decoder Loss:  0.8573339 Validation Decoder Loss:  1.4827878
Encoder Loss:  0.34971592  || Decoder Loss:  0.67237854 Validation Decoder Loss:  0.8679442
Encoder Loss:  0.20316702  || Decoder Loss:  0.49298778 Validation Decoder Loss:  0.975343
Encoder Loss:  0.19330025  || Decoder Loss:  0.50095636 Validation Decoder Loss:  0.94805175
Encoder Loss:  0.19323778  || Decoder Loss:  0.49747604 Validation Decoder Loss:  1.0178051
Encoder Loss:  0.19247931  || Decoder Loss:  0.49716783 Validation Decoder Loss:  1.0499372
Encoder Loss:  0.19222125  || Decoder Loss:  0.49747014 Validation Decoder Loss:  1.0356541
Encoder Loss:  0.19117633  || Decoder Loss:  0.49771205 Validation Decoder Loss:  1.0496014
Encoder Loss:  0.19074503  || Decoder Loss:  0.49753752 Validation Decoder Loss:  1.0484289
Encoder Loss:  0.1919343  || Decoder Loss:  0.49813464 Validation Decoder Loss:  1.0510972
Encoder Loss:  0.19101322  || Decoder Loss:  0.4954899 Validation Decoder Loss:  0.99357593
Encoder Loss:  0.19013505  || Decoder Loss:  0.49239045 Validation Decoder Loss:  1.0646625
Encoder Loss:  0.19296713  || Decoder Loss:  0.50304663 Validation Decoder Loss:  0.92057943
Encoder Loss:  0.19461775  || Decoder Loss:  0.51081693 Validation Decoder Loss:  0.9083115
Encoder Loss:  0.18826316  || Decoder Loss:  0.4915529 Validation Decoder Loss:  0.89831483
Encoder Loss:  0.18829021  || Decoder Loss:  0.49169245 Validation Decoder Loss:  0.90335065
Encoder Loss:  0.18994465  || Decoder Loss:  0.49652737 Validation Decoder Loss:  0.9115579
Encoder Loss:  0.19360796  || Decoder Loss:  0.5085202 Validation Decoder Loss:  0.8686675
Encoder Loss:  0.18745375  || Decoder Loss:  0.48827568 Validation Decoder Loss:  0.8838264
Encoder Loss:  0.18775009  || Decoder Loss:  0.49128532 Validation Decoder Loss:  0.88206947
Encoder Loss:  0.18779136  || Decoder Loss:  0.49102166 Validation Decoder Loss:  0.8704411
Encoder Loss:  0.18677406  || Decoder Loss:  0.48770836 Validation Decoder Loss:  0.79961026
Encoder Loss:  0.18443142  || Decoder Loss:  0.480852 Validation Decoder Loss:  0.96298003
Encoder Loss:  0.18587512  || Decoder Loss:  0.48497054 Validation Decoder Loss:  1.067359
Encoder Loss:  0.18747789  || Decoder Loss:  0.489718 Validation Decoder Loss:  0.9565518
Encoder Loss:  0.18487884  || Decoder Loss:  0.4813738 Validation Decoder Loss:  0.81919926
Encoder Loss:  0.18969013  || Decoder Loss:  0.495228 Validation Decoder Loss:  1.1052587
Encoder Loss:  0.19153678  || Decoder Loss:  0.49997434 Validation Decoder Loss:  1.1203039
Encoder Loss:  0.18757552  || Decoder Loss:  0.49097538 Validation Decoder Loss:  1.0895383
Encoder Loss:  0.190889  || Decoder Loss:  0.50153977 Validation Decoder Loss:  1.1312857
Encoder Loss:  0.19266164  || Decoder Loss:  0.50733846 Validation Decoder Loss:  1.1278331
Encoder Loss:  0.19188529  || Decoder Loss:  0.50571364 Validation Decoder Loss:  1.1203716
Encoder Loss:  0.19182725  || Decoder Loss:  0.50553477 Validation Decoder Loss:  1.1286097
Encoder Loss:  0.19128412  || Decoder Loss:  0.5034325 Validation Decoder Loss:  1.1291099
Encoder Loss:  0.19133252  || Decoder Loss:  0.503396 Validation Decoder Loss:  1.1157393
Encoder Loss:  0.18954071  || Decoder Loss:  0.4979044 Validation Decoder Loss:  1.1119015
Encoder Loss:  0.18748118  || Decoder Loss:  0.49186435 Validation Decoder Loss:  1.1121938
Encoder Loss:  0.18824162  || Decoder Loss:  0.4943488 Validation Decoder Loss:  1.1132133
Encoder Loss:  0.18876292  || Decoder Loss:  0.49601704 Validation Decoder Loss:  1.1194508
Model: siamese_net_lr_0.06826037303190602 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1194508
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_296 (Conv3D (None, 474, 5, 20, 1)     412       
_________________________________________________________________
dropout_642 (Dropout)        (None, 474, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_297 (Conv3D (None, 634, 5, 20, 1)     162       
_________________________________________________________________
reshape_169 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_644 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_573"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_646 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27264056  || Decoder Loss:  0.41276824 Validation Decoder Loss:  1.255959
Encoder Loss:  0.14240073  || Decoder Loss:  0.46613643 Validation Decoder Loss:  1.3728831
Encoder Loss:  0.12124357  || Decoder Loss:  0.4933612 Validation Decoder Loss:  1.4000051
Encoder Loss:  0.12283069  || Decoder Loss:  0.47556546 Validation Decoder Loss:  0.64307845
Encoder Loss:  0.12367278  || Decoder Loss:  0.4928064 Validation Decoder Loss:  0.6559535
Encoder Loss:  0.11584218  || Decoder Loss:  0.49341226 Validation Decoder Loss:  0.67475224
Encoder Loss:  0.12993237  || Decoder Loss:  0.50133055 Validation Decoder Loss:  0.7068473
Encoder Loss:  0.12543285  || Decoder Loss:  0.49720514 Validation Decoder Loss:  0.68225455
Encoder Loss:  0.11695736  || Decoder Loss:  0.49412772 Validation Decoder Loss:  0.627946
Encoder Loss:  0.12000187  || Decoder Loss:  0.49435508 Validation Decoder Loss:  0.7019391
Encoder Loss:  0.119413145  || Decoder Loss:  0.4965136 Validation Decoder Loss:  0.65758884
Encoder Loss:  0.1193176  || Decoder Loss:  0.49381295 Validation Decoder Loss:  0.7023421
Encoder Loss:  0.11821598  || Decoder Loss:  0.49885684 Validation Decoder Loss:  0.66848195
Encoder Loss:  0.11205715  || Decoder Loss:  0.48296243 Validation Decoder Loss:  0.71036553
Encoder Loss:  0.11888306  || Decoder Loss:  0.49403733 Validation Decoder Loss:  0.7224842
Encoder Loss:  0.11448832  || Decoder Loss:  0.48505983 Validation Decoder Loss:  0.8224472
Encoder Loss:  0.111475065  || Decoder Loss:  0.48192593 Validation Decoder Loss:  0.96618056
Encoder Loss:  0.116715536  || Decoder Loss:  0.4905066 Validation Decoder Loss:  1.3668227
Encoder Loss:  0.11880291  || Decoder Loss:  0.48888338 Validation Decoder Loss:  0.75729036
Encoder Loss:  0.11347664  || Decoder Loss:  0.48694023 Validation Decoder Loss:  1.056431
Encoder Loss:  0.11521943  || Decoder Loss:  0.48635527 Validation Decoder Loss:  0.8829127
Encoder Loss:  0.1100653  || Decoder Loss:  0.48041928 Validation Decoder Loss:  0.9791312
Encoder Loss:  0.11224189  || Decoder Loss:  0.48228702 Validation Decoder Loss:  0.9346442
Encoder Loss:  0.1126512  || Decoder Loss:  0.48744744 Validation Decoder Loss:  0.91016704
Encoder Loss:  0.11268354  || Decoder Loss:  0.48395303 Validation Decoder Loss:  1.0423555
Encoder Loss:  0.11216348  || Decoder Loss:  0.4830592 Validation Decoder Loss:  0.94175303
Encoder Loss:  0.11090534  || Decoder Loss:  0.48249286 Validation Decoder Loss:  1.0046932
Encoder Loss:  0.111756995  || Decoder Loss:  0.48364794 Validation Decoder Loss:  1.0624764
Encoder Loss:  0.12045699  || Decoder Loss:  0.48826894 Validation Decoder Loss:  1.2618353
Encoder Loss:  0.11178841  || Decoder Loss:  0.48690453 Validation Decoder Loss:  1.2063003
Encoder Loss:  0.11818823  || Decoder Loss:  0.49135017 Validation Decoder Loss:  0.812778
Encoder Loss:  0.11021863  || Decoder Loss:  0.48614824 Validation Decoder Loss:  0.97920203
Encoder Loss:  0.110327356  || Decoder Loss:  0.48644704 Validation Decoder Loss:  1.025345
Encoder Loss:  0.10913814  || Decoder Loss:  0.4850317 Validation Decoder Loss:  1.0736895
Encoder Loss:  0.11031767  || Decoder Loss:  0.48657674 Validation Decoder Loss:  1.0907848
Encoder Loss:  0.109555855  || Decoder Loss:  0.48649567 Validation Decoder Loss:  1.07039
Encoder Loss:  0.10900946  || Decoder Loss:  0.4865326 Validation Decoder Loss:  1.0788895
Encoder Loss:  0.10878448  || Decoder Loss:  0.487158 Validation Decoder Loss:  1.0834277
Encoder Loss:  0.1076089  || Decoder Loss:  0.48695064 Validation Decoder Loss:  1.0429778
Encoder Loss:  0.10757393  || Decoder Loss:  0.4872397 Validation Decoder Loss:  1.0729021
Model: siamese_net_lr_0.05726760013194987 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0729021
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_299 (Conv3D (None, 428, 5, 20, 1)     240       
_________________________________________________________________
dropout_648 (Dropout)        (None, 428, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_300 (Conv3D (None, 634, 5, 20, 1)     208       
_________________________________________________________________
reshape_170 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 448
Trainable params: 448
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_650 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_577"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_652 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20318449  || Decoder Loss:  0.11503837 Validation Decoder Loss:  0.37658978
Encoder Loss:  0.19087724  || Decoder Loss:  0.087260045 Validation Decoder Loss:  0.38298523
Encoder Loss:  0.19217938  || Decoder Loss:  0.0909451 Validation Decoder Loss:  0.3942966
Encoder Loss:  0.19433165  || Decoder Loss:  0.09695805 Validation Decoder Loss:  0.41800386
Encoder Loss:  0.19987926  || Decoder Loss:  0.11183942 Validation Decoder Loss:  0.52849346
Encoder Loss:  0.37808478  || Decoder Loss:  0.43500584 Validation Decoder Loss:  1.047784
Encoder Loss:  0.3645812  || Decoder Loss:  0.48712444 Validation Decoder Loss:  1.3879315
Encoder Loss:  0.353475  || Decoder Loss:  0.49495098 Validation Decoder Loss:  1.4546757
Encoder Loss:  0.35919166  || Decoder Loss:  0.5062673 Validation Decoder Loss:  1.4256512
Encoder Loss:  0.35320953  || Decoder Loss:  0.50079983 Validation Decoder Loss:  1.4190962
Encoder Loss:  0.35333934  || Decoder Loss:  0.5003865 Validation Decoder Loss:  1.4129694
Encoder Loss:  0.35260558  || Decoder Loss:  0.50021714 Validation Decoder Loss:  1.4185524
Encoder Loss:  0.35282803  || Decoder Loss:  0.4993891 Validation Decoder Loss:  1.3876119
Encoder Loss:  0.35194188  || Decoder Loss:  0.49954143 Validation Decoder Loss:  1.3708373
Encoder Loss:  0.35389596  || Decoder Loss:  0.4996687 Validation Decoder Loss:  1.3652413
Encoder Loss:  0.35244086  || Decoder Loss:  0.4999582 Validation Decoder Loss:  1.4047837
Encoder Loss:  0.35310844  || Decoder Loss:  0.5006227 Validation Decoder Loss:  1.4077464
Encoder Loss:  0.35154474  || Decoder Loss:  0.49542552 Validation Decoder Loss:  0.5683843
Encoder Loss:  0.35185605  || Decoder Loss:  0.49773112 Validation Decoder Loss:  0.62564003
Encoder Loss:  0.3545032  || Decoder Loss:  0.50192624 Validation Decoder Loss:  0.5550491
Encoder Loss:  0.3523707  || Decoder Loss:  0.4979033 Validation Decoder Loss:  0.5913571
Encoder Loss:  0.35066348  || Decoder Loss:  0.4967962 Validation Decoder Loss:  0.6151744
Encoder Loss:  0.3514479  || Decoder Loss:  0.49873382 Validation Decoder Loss:  0.6161729
Encoder Loss:  0.35115606  || Decoder Loss:  0.49814355 Validation Decoder Loss:  0.59643304
Encoder Loss:  0.34997746  || Decoder Loss:  0.4974888 Validation Decoder Loss:  0.6131222
Encoder Loss:  0.3512808  || Decoder Loss:  0.49786475 Validation Decoder Loss:  0.579531
Encoder Loss:  0.3498832  || Decoder Loss:  0.49632472 Validation Decoder Loss:  0.6016145
Encoder Loss:  0.35182735  || Decoder Loss:  0.49773324 Validation Decoder Loss:  0.59884727
Encoder Loss:  0.3514399  || Decoder Loss:  0.49860054 Validation Decoder Loss:  0.62041736
Encoder Loss:  0.35060424  || Decoder Loss:  0.49777845 Validation Decoder Loss:  0.59167886
Encoder Loss:  0.34743747  || Decoder Loss:  0.4918485 Validation Decoder Loss:  0.59926367
Encoder Loss:  0.3519426  || Decoder Loss:  0.49910232 Validation Decoder Loss:  0.642174
Encoder Loss:  0.35098562  || Decoder Loss:  0.49890137 Validation Decoder Loss:  0.6088287
Encoder Loss:  0.35069424  || Decoder Loss:  0.4967914 Validation Decoder Loss:  1.3266368
Encoder Loss:  0.35556874  || Decoder Loss:  0.50370747 Validation Decoder Loss:  1.3246343
Encoder Loss:  0.351084  || Decoder Loss:  0.49999607 Validation Decoder Loss:  1.3261483
Encoder Loss:  0.35210505  || Decoder Loss:  0.50133246 Validation Decoder Loss:  1.3223217
Encoder Loss:  0.35174218  || Decoder Loss:  0.50075305 Validation Decoder Loss:  1.2943351
Encoder Loss:  0.35155064  || Decoder Loss:  0.50109977 Validation Decoder Loss:  1.2619765
Encoder Loss:  0.35091254  || Decoder Loss:  0.50065714 Validation Decoder Loss:  1.2418002
Model: siamese_net_lr_0.08138796843100833 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2418002
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_302 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_654 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_303 (Conv3D (None, 634, 5, 20, 1)     77        
_________________________________________________________________
reshape_171 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 109
Trainable params: 109
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_656 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_581"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 3240, 20, 1)       72        
_________________________________________________________________
dropout_658 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 3245, 20, 1)       7         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.084188096  || Decoder Loss:  0.05841402 Validation Decoder Loss:  0.34234175
Encoder Loss:  0.0551082  || Decoder Loss:  0.033933856 Validation Decoder Loss:  0.3404969
Encoder Loss:  0.0504641  || Decoder Loss:  0.035348076 Validation Decoder Loss:  0.34688067
Encoder Loss:  0.049785182  || Decoder Loss:  0.03632678 Validation Decoder Loss:  0.34757984
Encoder Loss:  0.04974741  || Decoder Loss:  0.035202634 Validation Decoder Loss:  0.3471852
Encoder Loss:  0.049711768  || Decoder Loss:  0.034277912 Validation Decoder Loss:  0.34735835
Encoder Loss:  0.049695753  || Decoder Loss:  0.033908315 Validation Decoder Loss:  0.34766626
Encoder Loss:  0.04968939  || Decoder Loss:  0.03379105 Validation Decoder Loss:  0.34771925
Encoder Loss:  0.04968195  || Decoder Loss:  0.033727974 Validation Decoder Loss:  0.3477045
Encoder Loss:  0.049685016  || Decoder Loss:  0.033688582 Validation Decoder Loss:  0.34770274
Encoder Loss:  0.049686894  || Decoder Loss:  0.033656824 Validation Decoder Loss:  0.34773284
Encoder Loss:  0.049740776  || Decoder Loss:  0.0336203 Validation Decoder Loss:  0.34779117
Encoder Loss:  0.049694635  || Decoder Loss:  0.033570226 Validation Decoder Loss:  0.34795296
Encoder Loss:  0.049669914  || Decoder Loss:  0.033544555 Validation Decoder Loss:  0.34804237
Encoder Loss:  0.049648926  || Decoder Loss:  0.03354049 Validation Decoder Loss:  0.3480528
Encoder Loss:  0.049669366  || Decoder Loss:  0.0335439 Validation Decoder Loss:  0.34803206
Encoder Loss:  0.04966543  || Decoder Loss:  0.033542242 Validation Decoder Loss:  0.34803587
Encoder Loss:  0.049641408  || Decoder Loss:  0.03354129 Validation Decoder Loss:  0.34805515
Encoder Loss:  0.049659114  || Decoder Loss:  0.033543643 Validation Decoder Loss:  0.34802943
Encoder Loss:  0.049635313  || Decoder Loss:  0.03354289 Validation Decoder Loss:  0.34802514
Encoder Loss:  0.04965663  || Decoder Loss:  0.033544164 Validation Decoder Loss:  0.34799862
Encoder Loss:  0.04963003  || Decoder Loss:  0.03354367 Validation Decoder Loss:  0.34797353
Encoder Loss:  0.049645375  || Decoder Loss:  0.033543672 Validation Decoder Loss:  0.34793836
Encoder Loss:  0.049625155  || Decoder Loss:  0.033542506 Validation Decoder Loss:  0.34790745
Encoder Loss:  0.049642824  || Decoder Loss:  0.03354239 Validation Decoder Loss:  0.34786248
Encoder Loss:  0.049610313  || Decoder Loss:  0.033540655 Validation Decoder Loss:  0.34782365
Encoder Loss:  0.049634706  || Decoder Loss:  0.03353724 Validation Decoder Loss:  0.34781906
Encoder Loss:  0.049616266  || Decoder Loss:  0.03353545 Validation Decoder Loss:  0.3477701
Encoder Loss:  0.04967678  || Decoder Loss:  0.03353255 Validation Decoder Loss:  0.34773868
Encoder Loss:  0.04965117  || Decoder Loss:  0.033531748 Validation Decoder Loss:  0.34764692
Encoder Loss:  0.04962287  || Decoder Loss:  0.033530284 Validation Decoder Loss:  0.34753746
Encoder Loss:  0.04960783  || Decoder Loss:  0.033527456 Validation Decoder Loss:  0.34746632
Encoder Loss:  0.0495984  || Decoder Loss:  0.033523895 Validation Decoder Loss:  0.34741232
Encoder Loss:  0.04963912  || Decoder Loss:  0.033520076 Validation Decoder Loss:  0.34735915
Encoder Loss:  0.04964033  || Decoder Loss:  0.033516053 Validation Decoder Loss:  0.3472786
Encoder Loss:  0.049632855  || Decoder Loss:  0.033511437 Validation Decoder Loss:  0.34719616
Encoder Loss:  0.04965718  || Decoder Loss:  0.033506412 Validation Decoder Loss:  0.3471113
Encoder Loss:  0.04960824  || Decoder Loss:  0.033499446 Validation Decoder Loss:  0.3469325
Encoder Loss:  0.04965219  || Decoder Loss:  0.033492252 Validation Decoder Loss:  0.3468164
Encoder Loss:  0.049605154  || Decoder Loss:  0.03348301 Validation Decoder Loss:  0.34665987
Model: siamese_net_lr_0.00336843254161034 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34665987
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_305 (Conv3D (None, 558, 5, 20, 1)     433       
_________________________________________________________________
dropout_660 (Dropout)        (None, 558, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_306 (Conv3D (None, 634, 5, 20, 1)     78        
_________________________________________________________________
reshape_172 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 511
Trainable params: 511
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_662 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_585"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_664 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18713911  || Decoder Loss:  0.0673265 Validation Decoder Loss:  0.35952127
Encoder Loss:  0.18124995  || Decoder Loss:  0.048450876 Validation Decoder Loss:  0.36073443
Encoder Loss:  0.18164667  || Decoder Loss:  0.049963497 Validation Decoder Loss:  0.3626692
Encoder Loss:  0.18177053  || Decoder Loss:  0.052180823 Validation Decoder Loss:  0.3659607
Encoder Loss:  0.17340088  || Decoder Loss:  0.055652503 Validation Decoder Loss:  0.37155703
Encoder Loss:  0.11539173  || Decoder Loss:  0.060468208 Validation Decoder Loss:  0.3782815
Encoder Loss:  0.072654456  || Decoder Loss:  0.06374588 Validation Decoder Loss:  0.38101718
Encoder Loss:  0.061939888  || Decoder Loss:  0.06484583 Validation Decoder Loss:  0.38174337
Encoder Loss:  0.059992243  || Decoder Loss:  0.06511744 Validation Decoder Loss:  0.38189682
Encoder Loss:  0.059958648  || Decoder Loss:  0.065163225 Validation Decoder Loss:  0.3819563
Encoder Loss:  0.059919618  || Decoder Loss:  0.0651745 Validation Decoder Loss:  0.38203198
Encoder Loss:  0.059909377  || Decoder Loss:  0.06518238 Validation Decoder Loss:  0.38219517
Encoder Loss:  0.059900664  || Decoder Loss:  0.06518859 Validation Decoder Loss:  0.38237703
Encoder Loss:  0.059897155  || Decoder Loss:  0.06519058 Validation Decoder Loss:  0.38256174
Encoder Loss:  0.0598933  || Decoder Loss:  0.06519039 Validation Decoder Loss:  0.3826819
Encoder Loss:  0.059890714  || Decoder Loss:  0.06518642 Validation Decoder Loss:  0.38262397
Encoder Loss:  0.059887405  || Decoder Loss:  0.06518177 Validation Decoder Loss:  0.38262618
Encoder Loss:  0.059883896  || Decoder Loss:  0.065176696 Validation Decoder Loss:  0.38262126
Encoder Loss:  0.059880313  || Decoder Loss:  0.06517033 Validation Decoder Loss:  0.38260892
Encoder Loss:  0.059875075  || Decoder Loss:  0.06516296 Validation Decoder Loss:  0.3826471
Encoder Loss:  0.05986644  || Decoder Loss:  0.06514935 Validation Decoder Loss:  0.38272816
Encoder Loss:  0.059827436  || Decoder Loss:  0.06509015 Validation Decoder Loss:  0.38495362
Encoder Loss:  0.05996503  || Decoder Loss:  0.065301545 Validation Decoder Loss:  0.3823249
Encoder Loss:  0.059939045  || Decoder Loss:  0.06526163 Validation Decoder Loss:  0.3822629
Encoder Loss:  0.0599352  || Decoder Loss:  0.06525556 Validation Decoder Loss:  0.3821923
Encoder Loss:  0.059930887  || Decoder Loss:  0.06524909 Validation Decoder Loss:  0.38214105
Encoder Loss:  0.059926976  || Decoder Loss:  0.065243095 Validation Decoder Loss:  0.38208267
Encoder Loss:  0.059923295  || Decoder Loss:  0.0652376 Validation Decoder Loss:  0.38204217
Encoder Loss:  0.059919953  || Decoder Loss:  0.06523252 Validation Decoder Loss:  0.3819982
Encoder Loss:  0.05991684  || Decoder Loss:  0.065227695 Validation Decoder Loss:  0.381958
Encoder Loss:  0.059913877  || Decoder Loss:  0.065223366 Validation Decoder Loss:  0.38192624
Encoder Loss:  0.059911147  || Decoder Loss:  0.06521907 Validation Decoder Loss:  0.38189214
Encoder Loss:  0.059908506  || Decoder Loss:  0.06521512 Validation Decoder Loss:  0.38185948
Encoder Loss:  0.059906144  || Decoder Loss:  0.06521145 Validation Decoder Loss:  0.38183355
Encoder Loss:  0.059904054  || Decoder Loss:  0.06520832 Validation Decoder Loss:  0.38180143
Encoder Loss:  0.059902087  || Decoder Loss:  0.0652054 Validation Decoder Loss:  0.38177946
Encoder Loss:  0.059899975  || Decoder Loss:  0.06520233 Validation Decoder Loss:  0.3817562
Encoder Loss:  0.059897713  || Decoder Loss:  0.06519887 Validation Decoder Loss:  0.38173223
Encoder Loss:  0.05989545  || Decoder Loss:  0.065195486 Validation Decoder Loss:  0.38171256
Encoder Loss:  0.059893314  || Decoder Loss:  0.06519217 Validation Decoder Loss:  0.38168663
Model: siamese_net_lr_0.06306280924218036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38168663
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_308 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_666 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_309 (Conv3D (None, 634, 5, 20, 1)     54        
_________________________________________________________________
reshape_173 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_668 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_589"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_670 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39360845  || Decoder Loss:  0.63992393 Validation Decoder Loss:  1.0601879
Encoder Loss:  0.31047058  || Decoder Loss:  0.5138667 Validation Decoder Loss:  1.0297816
Encoder Loss:  0.30091092  || Decoder Loss:  0.50094503 Validation Decoder Loss:  1.0052876
Encoder Loss:  0.2995354  || Decoder Loss:  0.49881583 Validation Decoder Loss:  1.0097507
Encoder Loss:  0.301537  || Decoder Loss:  0.49826694 Validation Decoder Loss:  1.006789
Encoder Loss:  0.29879907  || Decoder Loss:  0.49557522 Validation Decoder Loss:  1.0039195
Encoder Loss:  0.29767784  || Decoder Loss:  0.49644515 Validation Decoder Loss:  0.99692154
Encoder Loss:  0.29658982  || Decoder Loss:  0.49558413 Validation Decoder Loss:  1.0030032
Encoder Loss:  0.29368752  || Decoder Loss:  0.49088985 Validation Decoder Loss:  0.9910585
Encoder Loss:  0.2934359  || Decoder Loss:  0.4884779 Validation Decoder Loss:  1.0310872
Encoder Loss:  0.2869948  || Decoder Loss:  0.47700253 Validation Decoder Loss:  0.96911526
Encoder Loss:  0.29445514  || Decoder Loss:  0.491827 Validation Decoder Loss:  0.9867954
Encoder Loss:  0.29260427  || Decoder Loss:  0.48718876 Validation Decoder Loss:  0.8699332
Encoder Loss:  0.2777991  || Decoder Loss:  0.4563654 Validation Decoder Loss:  0.8886322
Encoder Loss:  0.19761726  || Decoder Loss:  0.3161746 Validation Decoder Loss:  0.3568162
Encoder Loss:  0.059459604  || Decoder Loss:  0.062206473 Validation Decoder Loss:  0.35523322
Encoder Loss:  0.043422036  || Decoder Loss:  0.03529058 Validation Decoder Loss:  0.3435738
Encoder Loss:  0.041359223  || Decoder Loss:  0.032239586 Validation Decoder Loss:  0.3435125
Encoder Loss:  0.04240263  || Decoder Loss:  0.032042414 Validation Decoder Loss:  0.34342396
Encoder Loss:  0.041317686  || Decoder Loss:  0.03199473 Validation Decoder Loss:  0.34326363
Encoder Loss:  0.041280083  || Decoder Loss:  0.03197167 Validation Decoder Loss:  0.3432616
Encoder Loss:  0.040847268  || Decoder Loss:  0.03194914 Validation Decoder Loss:  0.34312648
Encoder Loss:  0.0414059  || Decoder Loss:  0.031932477 Validation Decoder Loss:  0.34315145
Encoder Loss:  0.041782428  || Decoder Loss:  0.031916026 Validation Decoder Loss:  0.34321284
Encoder Loss:  0.04082969  || Decoder Loss:  0.031895496 Validation Decoder Loss:  0.34320813
Encoder Loss:  0.040993337  || Decoder Loss:  0.031885725 Validation Decoder Loss:  0.34330633
Encoder Loss:  0.041175414  || Decoder Loss:  0.031873256 Validation Decoder Loss:  0.34319305
Encoder Loss:  0.04162812  || Decoder Loss:  0.031865764 Validation Decoder Loss:  0.34306753
Encoder Loss:  0.04153308  || Decoder Loss:  0.031857997 Validation Decoder Loss:  0.34286046
Encoder Loss:  0.043409944  || Decoder Loss:  0.031886652 Validation Decoder Loss:  0.34324235
Encoder Loss:  0.041196257  || Decoder Loss:  0.031852853 Validation Decoder Loss:  0.3431031
Encoder Loss:  0.040845804  || Decoder Loss:  0.03183638 Validation Decoder Loss:  0.34314322
Encoder Loss:  0.04088974  || Decoder Loss:  0.031829786 Validation Decoder Loss:  0.34296113
Encoder Loss:  0.04155103  || Decoder Loss:  0.03182781 Validation Decoder Loss:  0.34309062
Encoder Loss:  0.041496534  || Decoder Loss:  0.03182664 Validation Decoder Loss:  0.34289354
Encoder Loss:  0.041328117  || Decoder Loss:  0.031817768 Validation Decoder Loss:  0.34287277
Encoder Loss:  0.041306406  || Decoder Loss:  0.031815097 Validation Decoder Loss:  0.34284577
Encoder Loss:  0.04128732  || Decoder Loss:  0.031812612 Validation Decoder Loss:  0.34281534
Encoder Loss:  0.041269317  || Decoder Loss:  0.03181044 Validation Decoder Loss:  0.34278697
Encoder Loss:  0.04089989  || Decoder Loss:  0.031806283 Validation Decoder Loss:  0.34295893
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34295893
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_311 (Conv3D (None, 150, 5, 20, 1)     25        
_________________________________________________________________
dropout_672 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_312 (Conv3D (None, 634, 5, 20, 1)     337       
_________________________________________________________________
reshape_174 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 362
Trainable params: 362
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_674 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_593"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 3240, 20, 1)       72        
_________________________________________________________________
dropout_676 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 3245, 20, 1)       7         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15817755  || Decoder Loss:  0.17932388 Validation Decoder Loss:  1.0071341
Encoder Loss:  0.3687176  || Decoder Loss:  0.5467641 Validation Decoder Loss:  0.91291404
Encoder Loss:  0.33006382  || Decoder Loss:  0.49149567 Validation Decoder Loss:  0.9134116
Encoder Loss:  0.18917355  || Decoder Loss:  0.26880434 Validation Decoder Loss:  0.5474831
Encoder Loss:  0.059618033  || Decoder Loss:  0.0631044 Validation Decoder Loss:  0.36335585
Encoder Loss:  0.04156629  || Decoder Loss:  0.03488907 Validation Decoder Loss:  0.34188572
Encoder Loss:  0.042086907  || Decoder Loss:  0.034000814 Validation Decoder Loss:  0.3468341
Encoder Loss:  0.04148077  || Decoder Loss:  0.03392886 Validation Decoder Loss:  0.3449592
Encoder Loss:  0.04104246  || Decoder Loss:  0.033906877 Validation Decoder Loss:  0.34519845
Encoder Loss:  0.041835647  || Decoder Loss:  0.03390781 Validation Decoder Loss:  0.34557068
Encoder Loss:  0.042089973  || Decoder Loss:  0.033894915 Validation Decoder Loss:  0.3452957
Encoder Loss:  0.041605014  || Decoder Loss:  0.03388445 Validation Decoder Loss:  0.34461015
Encoder Loss:  0.041370645  || Decoder Loss:  0.03387595 Validation Decoder Loss:  0.3448427
Encoder Loss:  0.040813908  || Decoder Loss:  0.033865526 Validation Decoder Loss:  0.34491307
Encoder Loss:  0.040502355  || Decoder Loss:  0.033852603 Validation Decoder Loss:  0.3443036
Encoder Loss:  0.04106977  || Decoder Loss:  0.033860624 Validation Decoder Loss:  0.34516737
Encoder Loss:  0.042202197  || Decoder Loss:  0.03385453 Validation Decoder Loss:  0.3440658
Encoder Loss:  0.04004909  || Decoder Loss:  0.03383909 Validation Decoder Loss:  0.34388465
Encoder Loss:  0.040048715  || Decoder Loss:  0.033843398 Validation Decoder Loss:  0.3451522
Encoder Loss:  0.039948314  || Decoder Loss:  0.033837862 Validation Decoder Loss:  0.34550917
Encoder Loss:  0.03989152  || Decoder Loss:  0.033816013 Validation Decoder Loss:  0.34402817
Encoder Loss:  0.0398735  || Decoder Loss:  0.033810172 Validation Decoder Loss:  0.34306294
Encoder Loss:  0.03988294  || Decoder Loss:  0.03378624 Validation Decoder Loss:  0.34296846
Encoder Loss:  0.039818212  || Decoder Loss:  0.033774473 Validation Decoder Loss:  0.34229133
Encoder Loss:  0.039795324  || Decoder Loss:  0.033770252 Validation Decoder Loss:  0.34197065
Encoder Loss:  0.039776877  || Decoder Loss:  0.03374427 Validation Decoder Loss:  0.34137446
Encoder Loss:  0.039745405  || Decoder Loss:  0.03371072 Validation Decoder Loss:  0.3407365
Encoder Loss:  0.03973365  || Decoder Loss:  0.033699363 Validation Decoder Loss:  0.34031686
Encoder Loss:  0.039730746  || Decoder Loss:  0.033694725 Validation Decoder Loss:  0.34001237
Encoder Loss:  0.03972816  || Decoder Loss:  0.033691853 Validation Decoder Loss:  0.3399364
Encoder Loss:  0.039728526  || Decoder Loss:  0.033691768 Validation Decoder Loss:  0.3398387
Encoder Loss:  0.039728545  || Decoder Loss:  0.03369065 Validation Decoder Loss:  0.33977193
Encoder Loss:  0.039727323  || Decoder Loss:  0.03368942 Validation Decoder Loss:  0.3397321
Encoder Loss:  0.039727263  || Decoder Loss:  0.033691056 Validation Decoder Loss:  0.3396963
Encoder Loss:  0.039727632  || Decoder Loss:  0.033691227 Validation Decoder Loss:  0.33966726
Encoder Loss:  0.03972871  || Decoder Loss:  0.03369165 Validation Decoder Loss:  0.33963192
Encoder Loss:  0.039729726  || Decoder Loss:  0.03369458 Validation Decoder Loss:  0.3396932
Encoder Loss:  0.039729897  || Decoder Loss:  0.033694908 Validation Decoder Loss:  0.33976138
Encoder Loss:  0.03973124  || Decoder Loss:  0.033697013 Validation Decoder Loss:  0.339737
Encoder Loss:  0.039734825  || Decoder Loss:  0.033695754 Validation Decoder Loss:  0.3401032
Model: siamese_net_lr_0.03528948468565633 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3401032
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_314 (Conv3D (None, 148, 5, 20, 1)     23        
_________________________________________________________________
dropout_678 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_315 (Conv3D (None, 634, 5, 20, 1)     488       
_________________________________________________________________
reshape_175 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 511
Trainable params: 511
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_680 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_597"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_682 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12877938  || Decoder Loss:  0.053153392 Validation Decoder Loss:  0.33701557
Encoder Loss:  0.04243774  || Decoder Loss:  0.03436695 Validation Decoder Loss:  0.34078678
Encoder Loss:  0.040878948  || Decoder Loss:  0.033746332 Validation Decoder Loss:  0.35127634
Encoder Loss:  0.040700823  || Decoder Loss:  0.03338758 Validation Decoder Loss:  0.32551777
Encoder Loss:  0.040385976  || Decoder Loss:  0.033589575 Validation Decoder Loss:  0.3430707
Encoder Loss:  0.040317025  || Decoder Loss:  0.033773948 Validation Decoder Loss:  0.34385455
Encoder Loss:  0.040706653  || Decoder Loss:  0.034565207 Validation Decoder Loss:  0.38409716
Encoder Loss:  0.040054236  || Decoder Loss:  0.033606805 Validation Decoder Loss:  0.34003475
Encoder Loss:  0.039796844  || Decoder Loss:  0.033211466 Validation Decoder Loss:  0.3282557
Encoder Loss:  0.039797645  || Decoder Loss:  0.033219766 Validation Decoder Loss:  0.33557457
Encoder Loss:  0.039797187  || Decoder Loss:  0.033220597 Validation Decoder Loss:  0.33744752
Encoder Loss:  0.039823312  || Decoder Loss:  0.033266343 Validation Decoder Loss:  0.3446985
Encoder Loss:  0.039786324  || Decoder Loss:  0.033207785 Validation Decoder Loss:  0.3288332
Encoder Loss:  0.039797988  || Decoder Loss:  0.033226386 Validation Decoder Loss:  0.3281148
Encoder Loss:  0.03979474  || Decoder Loss:  0.033225395 Validation Decoder Loss:  0.3279088
Encoder Loss:  0.039792065  || Decoder Loss:  0.033224106 Validation Decoder Loss:  0.32914972
Encoder Loss:  0.039781395  || Decoder Loss:  0.03320607 Validation Decoder Loss:  0.32543218
Encoder Loss:  0.03978216  || Decoder Loss:  0.033208042 Validation Decoder Loss:  0.32827148
Encoder Loss:  0.039915357  || Decoder Loss:  0.03342778 Validation Decoder Loss:  0.3363179
Encoder Loss:  0.03990926  || Decoder Loss:  0.033416037 Validation Decoder Loss:  0.33851808
Encoder Loss:  0.039779738  || Decoder Loss:  0.033206817 Validation Decoder Loss:  0.34324956
Encoder Loss:  0.03973844  || Decoder Loss:  0.033140846 Validation Decoder Loss:  0.3377363
Encoder Loss:  0.039744712  || Decoder Loss:  0.033151302 Validation Decoder Loss:  0.33625996
Encoder Loss:  0.03974328  || Decoder Loss:  0.033149965 Validation Decoder Loss:  0.3391085
Encoder Loss:  0.03974605  || Decoder Loss:  0.03315435 Validation Decoder Loss:  0.3311833
Encoder Loss:  0.03975297  || Decoder Loss:  0.033164237 Validation Decoder Loss:  0.3317618
Encoder Loss:  0.039747447  || Decoder Loss:  0.033156604 Validation Decoder Loss:  0.33191496
Encoder Loss:  0.039746612  || Decoder Loss:  0.03315604 Validation Decoder Loss:  0.33301598
Encoder Loss:  0.039744865  || Decoder Loss:  0.033153392 Validation Decoder Loss:  0.33890194
Encoder Loss:  0.03972472  || Decoder Loss:  0.03311981 Validation Decoder Loss:  0.3356244
Encoder Loss:  0.0397577  || Decoder Loss:  0.033174463 Validation Decoder Loss:  0.33270767
Encoder Loss:  0.039784476  || Decoder Loss:  0.033218358 Validation Decoder Loss:  0.33317548
Encoder Loss:  0.03976105  || Decoder Loss:  0.0331804 Validation Decoder Loss:  0.33455488
Encoder Loss:  0.039715786  || Decoder Loss:  0.033105522 Validation Decoder Loss:  0.32935745
Encoder Loss:  0.03976303  || Decoder Loss:  0.033183802 Validation Decoder Loss:  0.33480886
Encoder Loss:  0.039726935  || Decoder Loss:  0.03312378 Validation Decoder Loss:  0.33378953
Encoder Loss:  0.03972511  || Decoder Loss:  0.033121686 Validation Decoder Loss:  0.33887273
Encoder Loss:  0.03971073  || Decoder Loss:  0.03309706 Validation Decoder Loss:  0.33546236
Encoder Loss:  0.039741494  || Decoder Loss:  0.03314842 Validation Decoder Loss:  0.3345517
Encoder Loss:  0.039767295  || Decoder Loss:  0.033190534 Validation Decoder Loss:  0.33881867
Model: siamese_net_lr_0.020004320266380295 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33881867
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_317 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_684 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_318 (Conv3D (None, 634, 5, 20, 1)     263       
_________________________________________________________________
reshape_176 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 295
Trainable params: 295
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_686 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_601"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_688 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33269432  || Decoder Loss:  0.3548847 Validation Decoder Loss:  0.3949074
Encoder Loss:  0.22585699  || Decoder Loss:  0.11629486 Validation Decoder Loss:  0.7042421
Encoder Loss:  0.14592312  || Decoder Loss:  0.43591872 Validation Decoder Loss:  1.0492995
Encoder Loss:  0.12572739  || Decoder Loss:  0.40865052 Validation Decoder Loss:  0.9846012
Encoder Loss:  0.1003196  || Decoder Loss:  0.29790312 Validation Decoder Loss:  0.40330577
Encoder Loss:  0.052536726  || Decoder Loss:  0.056296606 Validation Decoder Loss:  0.34450734
Encoder Loss:  0.04851884  || Decoder Loss:  0.03637089 Validation Decoder Loss:  0.3441424
Encoder Loss:  0.04792288  || Decoder Loss:  0.03345297 Validation Decoder Loss:  0.34460974
Encoder Loss:  0.047200087  || Decoder Loss:  0.03307295 Validation Decoder Loss:  0.3441219
Encoder Loss:  0.047863346  || Decoder Loss:  0.03300574 Validation Decoder Loss:  0.34414715
Encoder Loss:  0.048438855  || Decoder Loss:  0.032979596 Validation Decoder Loss:  0.34461588
Encoder Loss:  0.047761984  || Decoder Loss:  0.03295933 Validation Decoder Loss:  0.3440319
Encoder Loss:  0.048851334  || Decoder Loss:  0.032941446 Validation Decoder Loss:  0.34471783
Encoder Loss:  0.049016543  || Decoder Loss:  0.03292596 Validation Decoder Loss:  0.3429812
Encoder Loss:  0.05168472  || Decoder Loss:  0.03289706 Validation Decoder Loss:  0.34317917
Encoder Loss:  0.049269427  || Decoder Loss:  0.032888804 Validation Decoder Loss:  0.34410614
Encoder Loss:  0.048377275  || Decoder Loss:  0.032875977 Validation Decoder Loss:  0.34422916
Encoder Loss:  0.04750597  || Decoder Loss:  0.032858793 Validation Decoder Loss:  0.34401256
Encoder Loss:  0.048431598  || Decoder Loss:  0.03284142 Validation Decoder Loss:  0.34486932
Encoder Loss:  0.050092325  || Decoder Loss:  0.032838803 Validation Decoder Loss:  0.34374237
Encoder Loss:  0.048820578  || Decoder Loss:  0.032816533 Validation Decoder Loss:  0.3448242
Encoder Loss:  0.048339486  || Decoder Loss:  0.032806765 Validation Decoder Loss:  0.34434077
Encoder Loss:  0.04727979  || Decoder Loss:  0.032791413 Validation Decoder Loss:  0.34395397
Encoder Loss:  0.047827892  || Decoder Loss:  0.032779273 Validation Decoder Loss:  0.3445555
Encoder Loss:  0.04882017  || Decoder Loss:  0.03277032 Validation Decoder Loss:  0.343216
Encoder Loss:  0.05085337  || Decoder Loss:  0.032748275 Validation Decoder Loss:  0.34481525
Encoder Loss:  0.04774358  || Decoder Loss:  0.032744944 Validation Decoder Loss:  0.3439532
Encoder Loss:  0.047847766  || Decoder Loss:  0.032731935 Validation Decoder Loss:  0.3442948
Encoder Loss:  0.048377525  || Decoder Loss:  0.032731827 Validation Decoder Loss:  0.344814
Encoder Loss:  0.048473686  || Decoder Loss:  0.032714598 Validation Decoder Loss:  0.34335852
Encoder Loss:  0.04800992  || Decoder Loss:  0.032704163 Validation Decoder Loss:  0.34360588
Encoder Loss:  0.048721973  || Decoder Loss:  0.032689493 Validation Decoder Loss:  0.34432757
Encoder Loss:  0.05057014  || Decoder Loss:  0.032701343 Validation Decoder Loss:  0.34405607
Encoder Loss:  0.048103742  || Decoder Loss:  0.032680165 Validation Decoder Loss:  0.34404728
Encoder Loss:  0.047700103  || Decoder Loss:  0.032659646 Validation Decoder Loss:  0.34442347
Encoder Loss:  0.048017196  || Decoder Loss:  0.032655507 Validation Decoder Loss:  0.3446795
Encoder Loss:  0.050087858  || Decoder Loss:  0.03265126 Validation Decoder Loss:  0.34356785
Encoder Loss:  0.049230557  || Decoder Loss:  0.032667343 Validation Decoder Loss:  0.34567374
Encoder Loss:  0.0479259  || Decoder Loss:  0.032634277 Validation Decoder Loss:  0.34372342
Encoder Loss:  0.04766915  || Decoder Loss:  0.032623887 Validation Decoder Loss:  0.34451258
Model: siamese_net_lr_0.036430052035850854 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3445126
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_320 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_690 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_321 (Conv3D (None, 634, 5, 20, 1)     356       
_________________________________________________________________
reshape_177 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 388
Trainable params: 388
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_692 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_605"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_694 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16921628  || Decoder Loss:  0.2609891 Validation Decoder Loss:  1.2201493
Encoder Loss:  0.20214054  || Decoder Loss:  0.69192755 Validation Decoder Loss:  0.6921265
Encoder Loss:  0.068603694  || Decoder Loss:  0.12839985 Validation Decoder Loss:  0.7232758
Encoder Loss:  0.07373156  || Decoder Loss:  0.15110871 Validation Decoder Loss:  0.7478739
Encoder Loss:  0.07449256  || Decoder Loss:  0.15453957 Validation Decoder Loss:  0.72774446
Encoder Loss:  0.058114063  || Decoder Loss:  0.08444186 Validation Decoder Loss:  0.44003043
Encoder Loss:  0.04680301  || Decoder Loss:  0.03601809 Validation Decoder Loss:  0.3181013
Encoder Loss:  0.04607892  || Decoder Loss:  0.032995224 Validation Decoder Loss:  0.33118394
Encoder Loss:  0.045994915  || Decoder Loss:  0.03271832 Validation Decoder Loss:  0.33409494
Encoder Loss:  0.04596947  || Decoder Loss:  0.032658186 Validation Decoder Loss:  0.33470905
Encoder Loss:  0.045970127  || Decoder Loss:  0.032633755 Validation Decoder Loss:  0.33456343
Encoder Loss:  0.04596475  || Decoder Loss:  0.0326194 Validation Decoder Loss:  0.33405617
Encoder Loss:  0.045970306  || Decoder Loss:  0.03261048 Validation Decoder Loss:  0.33339125
Encoder Loss:  0.045959946  || Decoder Loss:  0.03260593 Validation Decoder Loss:  0.3323897
Encoder Loss:  0.04596392  || Decoder Loss:  0.03260654 Validation Decoder Loss:  0.3316797
Encoder Loss:  0.045963693  || Decoder Loss:  0.032611467 Validation Decoder Loss:  0.3321735
Encoder Loss:  0.045977265  || Decoder Loss:  0.032613758 Validation Decoder Loss:  0.33547512
Encoder Loss:  0.045951232  || Decoder Loss:  0.032594565 Validation Decoder Loss:  0.33792698
Encoder Loss:  0.045946382  || Decoder Loss:  0.032571584 Validation Decoder Loss:  0.3371381
Encoder Loss:  0.04594329  || Decoder Loss:  0.032565027 Validation Decoder Loss:  0.3372647
Encoder Loss:  0.045944456  || Decoder Loss:  0.032559372 Validation Decoder Loss:  0.337098
Encoder Loss:  0.04593928  || Decoder Loss:  0.03255487 Validation Decoder Loss:  0.33688796
Encoder Loss:  0.04593314  || Decoder Loss:  0.032550856 Validation Decoder Loss:  0.33670846
Encoder Loss:  0.045931883  || Decoder Loss:  0.032546256 Validation Decoder Loss:  0.33643907
Encoder Loss:  0.04593544  || Decoder Loss:  0.032542057 Validation Decoder Loss:  0.3359173
Encoder Loss:  0.045930874  || Decoder Loss:  0.03253911 Validation Decoder Loss:  0.33540666
Encoder Loss:  0.045930713  || Decoder Loss:  0.032535788 Validation Decoder Loss:  0.33536357
Encoder Loss:  0.045931768  || Decoder Loss:  0.032532986 Validation Decoder Loss:  0.33556777
Encoder Loss:  0.045928363  || Decoder Loss:  0.032531634 Validation Decoder Loss:  0.3355401
Encoder Loss:  0.0459276  || Decoder Loss:  0.032529257 Validation Decoder Loss:  0.33546945
Encoder Loss:  0.04592724  || Decoder Loss:  0.03252698 Validation Decoder Loss:  0.3352911
Encoder Loss:  0.045927092  || Decoder Loss:  0.03252561 Validation Decoder Loss:  0.33490112
Encoder Loss:  0.045925595  || Decoder Loss:  0.03252442 Validation Decoder Loss:  0.3342495
Encoder Loss:  0.045925044  || Decoder Loss:  0.03252292 Validation Decoder Loss:  0.3335111
Encoder Loss:  0.045924883  || Decoder Loss:  0.032521956 Validation Decoder Loss:  0.33307517
Encoder Loss:  0.045925554  || Decoder Loss:  0.032522447 Validation Decoder Loss:  0.33308014
Encoder Loss:  0.04592592  || Decoder Loss:  0.032523945 Validation Decoder Loss:  0.33302018
Encoder Loss:  0.045925487  || Decoder Loss:  0.032526147 Validation Decoder Loss:  0.33276352
Encoder Loss:  0.045926753  || Decoder Loss:  0.03252954 Validation Decoder Loss:  0.33233425
Encoder Loss:  0.04592819  || Decoder Loss:  0.032535706 Validation Decoder Loss:  0.3316277
Model: siamese_net_lr_0.04762920838752416 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33162773
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_323 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_696 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_324 (Conv3D (None, 634, 5, 20, 1)     303       
_________________________________________________________________
reshape_178 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 325
Trainable params: 325
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_608"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_698 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_700 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11659076  || Decoder Loss:  0.06349763 Validation Decoder Loss:  0.37702444
Encoder Loss:  0.046893153  || Decoder Loss:  0.035802156 Validation Decoder Loss:  0.33178174
Encoder Loss:  0.040877815  || Decoder Loss:  0.03295433 Validation Decoder Loss:  0.3312521
Encoder Loss:  0.040846504  || Decoder Loss:  0.032660782 Validation Decoder Loss:  0.33904427
Encoder Loss:  0.039470658  || Decoder Loss:  0.032564268 Validation Decoder Loss:  0.33776516
Encoder Loss:  0.039848242  || Decoder Loss:  0.032539092 Validation Decoder Loss:  0.3378322
Encoder Loss:  0.04047472  || Decoder Loss:  0.032529615 Validation Decoder Loss:  0.3400589
Encoder Loss:  0.039984457  || Decoder Loss:  0.032507997 Validation Decoder Loss:  0.33807078
Encoder Loss:  0.041041538  || Decoder Loss:  0.032536246 Validation Decoder Loss:  0.33919904
Encoder Loss:  0.04297156  || Decoder Loss:  0.03262167 Validation Decoder Loss:  0.32834804
Encoder Loss:  0.042477153  || Decoder Loss:  0.03268699 Validation Decoder Loss:  0.338203
Encoder Loss:  0.041747082  || Decoder Loss:  0.03249743 Validation Decoder Loss:  0.3387739
Encoder Loss:  0.03942737  || Decoder Loss:  0.032438733 Validation Decoder Loss:  0.33706406
Encoder Loss:  0.03955795  || Decoder Loss:  0.03243338 Validation Decoder Loss:  0.3362031
Encoder Loss:  0.039732944  || Decoder Loss:  0.032432538 Validation Decoder Loss:  0.334584
Encoder Loss:  0.03945999  || Decoder Loss:  0.03249029 Validation Decoder Loss:  0.3330649
Encoder Loss:  0.03960164  || Decoder Loss:  0.032409154 Validation Decoder Loss:  0.3331643
Encoder Loss:  0.03929471  || Decoder Loss:  0.032426275 Validation Decoder Loss:  0.3358147
Encoder Loss:  0.03915319  || Decoder Loss:  0.032387 Validation Decoder Loss:  0.33461598
Encoder Loss:  0.03897609  || Decoder Loss:  0.0323845 Validation Decoder Loss:  0.3355605
Encoder Loss:  0.03895862  || Decoder Loss:  0.03237124 Validation Decoder Loss:  0.3327763
Encoder Loss:  0.038915828  || Decoder Loss:  0.032370143 Validation Decoder Loss:  0.3354899
Encoder Loss:  0.03893908  || Decoder Loss:  0.03235324 Validation Decoder Loss:  0.33354926
Encoder Loss:  0.03890516  || Decoder Loss:  0.032351736 Validation Decoder Loss:  0.33513469
Encoder Loss:  0.038936183  || Decoder Loss:  0.03234053 Validation Decoder Loss:  0.33529568
Encoder Loss:  0.038878538  || Decoder Loss:  0.032336008 Validation Decoder Loss:  0.3350184
Encoder Loss:  0.038876466  || Decoder Loss:  0.03232562 Validation Decoder Loss:  0.33506376
Encoder Loss:  0.038913485  || Decoder Loss:  0.03232141 Validation Decoder Loss:  0.3348808
Encoder Loss:  0.038916193  || Decoder Loss:  0.032314703 Validation Decoder Loss:  0.33576506
Encoder Loss:  0.03892077  || Decoder Loss:  0.03231392 Validation Decoder Loss:  0.3359993
Encoder Loss:  0.038897447  || Decoder Loss:  0.032328747 Validation Decoder Loss:  0.33396715
Encoder Loss:  0.038871318  || Decoder Loss:  0.032298967 Validation Decoder Loss:  0.3358711
Encoder Loss:  0.03885285  || Decoder Loss:  0.032298367 Validation Decoder Loss:  0.33456904
Encoder Loss:  0.038919922  || Decoder Loss:  0.032295607 Validation Decoder Loss:  0.33560938
Encoder Loss:  0.038979996  || Decoder Loss:  0.03231541 Validation Decoder Loss:  0.33727574
Encoder Loss:  0.03900735  || Decoder Loss:  0.032302536 Validation Decoder Loss:  0.3407438
Encoder Loss:  0.038949903  || Decoder Loss:  0.03229321 Validation Decoder Loss:  0.3335837
Encoder Loss:  0.03891224  || Decoder Loss:  0.03229806 Validation Decoder Loss:  0.3319546
Encoder Loss:  0.038911927  || Decoder Loss:  0.032291178 Validation Decoder Loss:  0.33420116
Encoder Loss:  0.038931206  || Decoder Loss:  0.032300618 Validation Decoder Loss:  0.33678555
Model: siamese_net_lr_0.02263428338499312 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3367855
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_326 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_702 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_327 (Conv3D (None, 634, 5, 20, 1)     469       
_________________________________________________________________
reshape_179 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_612"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_704 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_706 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07201061  || Decoder Loss:  0.074740484 Validation Decoder Loss:  0.32922512
Encoder Loss:  0.04138274  || Decoder Loss:  0.03907115 Validation Decoder Loss:  0.3341071
Encoder Loss:  0.037894797  || Decoder Loss:  0.03512847 Validation Decoder Loss:  0.34058607
Encoder Loss:  0.037458807  || Decoder Loss:  0.034728564 Validation Decoder Loss:  0.34337175
Encoder Loss:  0.037333764  || Decoder Loss:  0.03460017 Validation Decoder Loss:  0.3438568
Encoder Loss:  0.03727358  || Decoder Loss:  0.034531698 Validation Decoder Loss:  0.34390432
Encoder Loss:  0.037188936  || Decoder Loss:  0.034426793 Validation Decoder Loss:  0.34393972
Encoder Loss:  0.037095953  || Decoder Loss:  0.034318134 Validation Decoder Loss:  0.34385002
Encoder Loss:  0.037006844  || Decoder Loss:  0.03421752 Validation Decoder Loss:  0.34368137
Encoder Loss:  0.03693771  || Decoder Loss:  0.034135666 Validation Decoder Loss:  0.34356287
Encoder Loss:  0.036878586  || Decoder Loss:  0.034064636 Validation Decoder Loss:  0.3434619
Encoder Loss:  0.03684135  || Decoder Loss:  0.03400862 Validation Decoder Loss:  0.3433941
Encoder Loss:  0.036793772  || Decoder Loss:  0.033958063 Validation Decoder Loss:  0.3433388
Encoder Loss:  0.036761597  || Decoder Loss:  0.033914518 Validation Decoder Loss:  0.34327593
Encoder Loss:  0.036728404  || Decoder Loss:  0.03388317 Validation Decoder Loss:  0.34324378
Encoder Loss:  0.036700573  || Decoder Loss:  0.03385404 Validation Decoder Loss:  0.3431995
Encoder Loss:  0.03668227  || Decoder Loss:  0.033832707 Validation Decoder Loss:  0.34316552
Encoder Loss:  0.03666909  || Decoder Loss:  0.033813465 Validation Decoder Loss:  0.34314287
Encoder Loss:  0.03665874  || Decoder Loss:  0.033794425 Validation Decoder Loss:  0.34309918
Encoder Loss:  0.036639582  || Decoder Loss:  0.03377981 Validation Decoder Loss:  0.343081
Encoder Loss:  0.036626324  || Decoder Loss:  0.03376615 Validation Decoder Loss:  0.34305635
Encoder Loss:  0.036618397  || Decoder Loss:  0.033757128 Validation Decoder Loss:  0.343055
Encoder Loss:  0.036609862  || Decoder Loss:  0.033746477 Validation Decoder Loss:  0.3430467
Encoder Loss:  0.036611494  || Decoder Loss:  0.03373701 Validation Decoder Loss:  0.34300902
Encoder Loss:  0.03660292  || Decoder Loss:  0.033728454 Validation Decoder Loss:  0.3429894
Encoder Loss:  0.0365958  || Decoder Loss:  0.033720326 Validation Decoder Loss:  0.34295264
Encoder Loss:  0.036585223  || Decoder Loss:  0.033710025 Validation Decoder Loss:  0.34287372
Encoder Loss:  0.036573812  || Decoder Loss:  0.033704504 Validation Decoder Loss:  0.34280348
Encoder Loss:  0.036569595  || Decoder Loss:  0.03369968 Validation Decoder Loss:  0.34276718
Encoder Loss:  0.03657156  || Decoder Loss:  0.033694606 Validation Decoder Loss:  0.3427209
Encoder Loss:  0.036561936  || Decoder Loss:  0.033690516 Validation Decoder Loss:  0.34267086
Encoder Loss:  0.036557753  || Decoder Loss:  0.033687614 Validation Decoder Loss:  0.3426224
Encoder Loss:  0.036555152  || Decoder Loss:  0.033684365 Validation Decoder Loss:  0.34258926
Encoder Loss:  0.036556445  || Decoder Loss:  0.03368158 Validation Decoder Loss:  0.3425246
Encoder Loss:  0.036562193  || Decoder Loss:  0.033677787 Validation Decoder Loss:  0.34243512
Encoder Loss:  0.036552213  || Decoder Loss:  0.03367353 Validation Decoder Loss:  0.34234107
Encoder Loss:  0.03654716  || Decoder Loss:  0.033670414 Validation Decoder Loss:  0.34226155
Encoder Loss:  0.036544014  || Decoder Loss:  0.03366744 Validation Decoder Loss:  0.34220505
Encoder Loss:  0.036537286  || Decoder Loss:  0.033664506 Validation Decoder Loss:  0.3421489
Encoder Loss:  0.036535487  || Decoder Loss:  0.033662543 Validation Decoder Loss:  0.34210646
Model: siamese_net_lr_0.004044418662720782 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34210646
Model: "sequential_614"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_329 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_708 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_330 (Conv3D (None, 634, 5, 20, 1)     493       
_________________________________________________________________
reshape_180 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 503
Trainable params: 503
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 3240, 20, 1)       7         
_________________________________________________________________
dropout_710 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 3170, 20, 1)       72        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_712 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1072922  || Decoder Loss:  0.06096935 Validation Decoder Loss:  0.3520544
Encoder Loss:  0.048187356  || Decoder Loss:  0.033411227 Validation Decoder Loss:  0.34163618
Encoder Loss:  0.047373  || Decoder Loss:  0.03304931 Validation Decoder Loss:  0.34137306
Encoder Loss:  0.046664942  || Decoder Loss:  0.032434117 Validation Decoder Loss:  0.33206376
Encoder Loss:  0.04579968  || Decoder Loss:  0.03253099 Validation Decoder Loss:  0.32126445
Encoder Loss:  0.046950407  || Decoder Loss:  0.032274965 Validation Decoder Loss:  0.3231332
Encoder Loss:  0.046895146  || Decoder Loss:  0.032705322 Validation Decoder Loss:  0.32483834
Encoder Loss:  0.046492446  || Decoder Loss:  0.032193024 Validation Decoder Loss:  0.3246401
Encoder Loss:  0.048878018  || Decoder Loss:  0.032729283 Validation Decoder Loss:  0.32869458
Encoder Loss:  0.054967  || Decoder Loss:  0.035400208 Validation Decoder Loss:  0.35812354
Encoder Loss:  0.054319438  || Decoder Loss:  0.048772298 Validation Decoder Loss:  0.36894864
Encoder Loss:  0.047311436  || Decoder Loss:  0.034684908 Validation Decoder Loss:  0.315423
Encoder Loss:  0.04623149  || Decoder Loss:  0.032473892 Validation Decoder Loss:  0.3263526
Encoder Loss:  0.0445316  || Decoder Loss:  0.03223805 Validation Decoder Loss:  0.32654494
Encoder Loss:  0.045994624  || Decoder Loss:  0.03244136 Validation Decoder Loss:  0.3207935
Encoder Loss:  0.045975804  || Decoder Loss:  0.03314691 Validation Decoder Loss:  0.33934444
Encoder Loss:  0.04574832  || Decoder Loss:  0.0333886 Validation Decoder Loss:  0.33583188
Encoder Loss:  0.04539558  || Decoder Loss:  0.033426 Validation Decoder Loss:  0.3144456
Encoder Loss:  0.044982977  || Decoder Loss:  0.032884043 Validation Decoder Loss:  0.32490957
Encoder Loss:  0.044006687  || Decoder Loss:  0.032220498 Validation Decoder Loss:  0.325631
Encoder Loss:  0.044019297  || Decoder Loss:  0.032477133 Validation Decoder Loss:  0.32082513
Encoder Loss:  0.04401072  || Decoder Loss:  0.032558963 Validation Decoder Loss:  0.32169473
Encoder Loss:  0.043929838  || Decoder Loss:  0.032372177 Validation Decoder Loss:  0.32283083
Encoder Loss:  0.043932162  || Decoder Loss:  0.03240201 Validation Decoder Loss:  0.32204425
Encoder Loss:  0.04390178  || Decoder Loss:  0.032333676 Validation Decoder Loss:  0.324351
Encoder Loss:  0.04386656  || Decoder Loss:  0.032236256 Validation Decoder Loss:  0.324211
Encoder Loss:  0.043899126  || Decoder Loss:  0.032286964 Validation Decoder Loss:  0.32326776
Encoder Loss:  0.0438797  || Decoder Loss:  0.03223911 Validation Decoder Loss:  0.32530499
Encoder Loss:  0.043841634  || Decoder Loss:  0.032148715 Validation Decoder Loss:  0.3260573
Encoder Loss:  0.043828476  || Decoder Loss:  0.032129414 Validation Decoder Loss:  0.32602236
Encoder Loss:  0.043827396  || Decoder Loss:  0.032099366 Validation Decoder Loss:  0.32724
Encoder Loss:  0.04381418  || Decoder Loss:  0.032064747 Validation Decoder Loss:  0.32704926
Encoder Loss:  0.043832257  || Decoder Loss:  0.032037564 Validation Decoder Loss:  0.32812223
Encoder Loss:  0.04382585  || Decoder Loss:  0.032003865 Validation Decoder Loss:  0.32880712
Encoder Loss:  0.043821063  || Decoder Loss:  0.03198101 Validation Decoder Loss:  0.32931685
Encoder Loss:  0.043777272  || Decoder Loss:  0.03197526 Validation Decoder Loss:  0.32943046
Encoder Loss:  0.043764688  || Decoder Loss:  0.031950153 Validation Decoder Loss:  0.32964492
Encoder Loss:  0.04377643  || Decoder Loss:  0.031935494 Validation Decoder Loss:  0.3299243
Encoder Loss:  0.043762803  || Decoder Loss:  0.03192064 Validation Decoder Loss:  0.33002278
Encoder Loss:  0.04375392  || Decoder Loss:  0.031915303 Validation Decoder Loss:  0.3304652
Model: siamese_net_lr_0.017935872817339757 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3304652
Model: "sequential_618"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_332 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_714 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_333 (Conv3D (None, 634, 5, 20, 1)     271       
_________________________________________________________________
reshape_181 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_716 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_621"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_718 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07944754  || Decoder Loss:  0.058118537 Validation Decoder Loss:  0.3477709
Encoder Loss:  0.044632487  || Decoder Loss:  0.03389574 Validation Decoder Loss:  0.3308946
Encoder Loss:  0.044249095  || Decoder Loss:  0.03266581 Validation Decoder Loss:  0.32795942
Encoder Loss:  0.044586886  || Decoder Loss:  0.032548476 Validation Decoder Loss:  0.33531833
Encoder Loss:  0.043858036  || Decoder Loss:  0.032506835 Validation Decoder Loss:  0.32984352
Encoder Loss:  0.04657246  || Decoder Loss:  0.032535326 Validation Decoder Loss:  0.3243213
Encoder Loss:  0.046800755  || Decoder Loss:  0.032628514 Validation Decoder Loss:  0.33617294
Encoder Loss:  0.045267906  || Decoder Loss:  0.032635547 Validation Decoder Loss:  0.3269438
Encoder Loss:  0.042571083  || Decoder Loss:  0.032641552 Validation Decoder Loss:  0.3277797
Encoder Loss:  0.043669928  || Decoder Loss:  0.032585848 Validation Decoder Loss:  0.3195551
Encoder Loss:  0.043019913  || Decoder Loss:  0.03264452 Validation Decoder Loss:  0.3256539
Encoder Loss:  0.043118715  || Decoder Loss:  0.032638434 Validation Decoder Loss:  0.32609707
Encoder Loss:  0.04319731  || Decoder Loss:  0.032564964 Validation Decoder Loss:  0.3181551
Encoder Loss:  0.043370433  || Decoder Loss:  0.032601696 Validation Decoder Loss:  0.32119936
Encoder Loss:  0.043414757  || Decoder Loss:  0.03254496 Validation Decoder Loss:  0.3228103
Encoder Loss:  0.043634195  || Decoder Loss:  0.032619208 Validation Decoder Loss:  0.32179752
Encoder Loss:  0.0435315  || Decoder Loss:  0.032550894 Validation Decoder Loss:  0.32308623
Encoder Loss:  0.043011535  || Decoder Loss:  0.032566987 Validation Decoder Loss:  0.3247276
Encoder Loss:  0.04408968  || Decoder Loss:  0.032545954 Validation Decoder Loss:  0.32842922
Encoder Loss:  0.042268377  || Decoder Loss:  0.032483324 Validation Decoder Loss:  0.3231073
Encoder Loss:  0.04260307  || Decoder Loss:  0.032460526 Validation Decoder Loss:  0.32384503
Encoder Loss:  0.044140767  || Decoder Loss:  0.03246174 Validation Decoder Loss:  0.32424802
Encoder Loss:  0.043162227  || Decoder Loss:  0.032425642 Validation Decoder Loss:  0.32016757
Encoder Loss:  0.043326996  || Decoder Loss:  0.03245686 Validation Decoder Loss:  0.32071513
Encoder Loss:  0.042769443  || Decoder Loss:  0.032462485 Validation Decoder Loss:  0.32330394
Encoder Loss:  0.043730717  || Decoder Loss:  0.032473024 Validation Decoder Loss:  0.33169782
Encoder Loss:  0.04282692  || Decoder Loss:  0.03246068 Validation Decoder Loss:  0.32396883
Encoder Loss:  0.042844623  || Decoder Loss:  0.03241634 Validation Decoder Loss:  0.3194717
Encoder Loss:  0.04240739  || Decoder Loss:  0.032437585 Validation Decoder Loss:  0.32521585
Encoder Loss:  0.042416707  || Decoder Loss:  0.032411907 Validation Decoder Loss:  0.32416722
Encoder Loss:  0.04285048  || Decoder Loss:  0.032470774 Validation Decoder Loss:  0.32629263
Encoder Loss:  0.04325278  || Decoder Loss:  0.03241402 Validation Decoder Loss:  0.32019174
Encoder Loss:  0.044765234  || Decoder Loss:  0.03261523 Validation Decoder Loss:  0.32292873
Encoder Loss:  0.042294793  || Decoder Loss:  0.03242381 Validation Decoder Loss:  0.31619155
Encoder Loss:  0.04353327  || Decoder Loss:  0.032446057 Validation Decoder Loss:  0.318048
Encoder Loss:  0.042857934  || Decoder Loss:  0.03241067 Validation Decoder Loss:  0.32038704
Encoder Loss:  0.04267495  || Decoder Loss:  0.032415625 Validation Decoder Loss:  0.32344782
Encoder Loss:  0.04261918  || Decoder Loss:  0.03241809 Validation Decoder Loss:  0.32215667
Encoder Loss:  0.042632494  || Decoder Loss:  0.032385122 Validation Decoder Loss:  0.32401973
Encoder Loss:  0.042218205  || Decoder Loss:  0.03242026 Validation Decoder Loss:  0.32363856
Model: siamese_net_lr_0.01921767459417844 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3236386
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_335 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_720 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_336 (Conv3D (None, 634, 5, 20, 1)     40        
_________________________________________________________________
reshape_182 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_624"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_722 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 3170, 20, 1)       2         
_________________________________________________________________
dropout_724 (Dropout)        (None, 3170, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4339086  || Decoder Loss:  0.48342174 Validation Decoder Loss:  0.35389605
Encoder Loss:  0.046736  || Decoder Loss:  0.043736853 Validation Decoder Loss:  0.35107887
Encoder Loss:  0.039579216  || Decoder Loss:  0.03714897 Validation Decoder Loss:  0.34561798
Encoder Loss:  0.037073124  || Decoder Loss:  0.034182206 Validation Decoder Loss:  0.34432143
Encoder Loss:  0.036054377  || Decoder Loss:  0.033043757 Validation Decoder Loss:  0.34395918
Encoder Loss:  0.035672046  || Decoder Loss:  0.03254896 Validation Decoder Loss:  0.34399617
Encoder Loss:  0.035656363  || Decoder Loss:  0.032356236 Validation Decoder Loss:  0.34409636
Encoder Loss:  0.035447925  || Decoder Loss:  0.03229574 Validation Decoder Loss:  0.34423992
Encoder Loss:  0.03513266  || Decoder Loss:  0.032273453 Validation Decoder Loss:  0.3443699
Encoder Loss:  0.035308823  || Decoder Loss:  0.032254092 Validation Decoder Loss:  0.34444866
Encoder Loss:  0.03509973  || Decoder Loss:  0.032231692 Validation Decoder Loss:  0.34457448
Encoder Loss:  0.03567733  || Decoder Loss:  0.0322086 Validation Decoder Loss:  0.34459525
Encoder Loss:  0.034997594  || Decoder Loss:  0.032182265 Validation Decoder Loss:  0.34470472
Encoder Loss:  0.03517096  || Decoder Loss:  0.032158732 Validation Decoder Loss:  0.34474608
Encoder Loss:  0.034923766  || Decoder Loss:  0.0321387 Validation Decoder Loss:  0.3449189
Encoder Loss:  0.035297982  || Decoder Loss:  0.032124065 Validation Decoder Loss:  0.3450057
Encoder Loss:  0.03473346  || Decoder Loss:  0.032111026 Validation Decoder Loss:  0.34505993
Encoder Loss:  0.0352983  || Decoder Loss:  0.032102183 Validation Decoder Loss:  0.34513786
Encoder Loss:  0.035062753  || Decoder Loss:  0.032093085 Validation Decoder Loss:  0.34510678
Encoder Loss:  0.034931157  || Decoder Loss:  0.032084063 Validation Decoder Loss:  0.34513175
Encoder Loss:  0.034819055  || Decoder Loss:  0.032075446 Validation Decoder Loss:  0.34520248
Encoder Loss:  0.034663893  || Decoder Loss:  0.032066606 Validation Decoder Loss:  0.34521246
Encoder Loss:  0.03526423  || Decoder Loss:  0.032060932 Validation Decoder Loss:  0.34533998
Encoder Loss:  0.035255145  || Decoder Loss:  0.03205356 Validation Decoder Loss:  0.3452548
Encoder Loss:  0.03484517  || Decoder Loss:  0.032044943 Validation Decoder Loss:  0.3452078
Encoder Loss:  0.035029516  || Decoder Loss:  0.03203833 Validation Decoder Loss:  0.34528726
Encoder Loss:  0.034923974  || Decoder Loss:  0.032030854 Validation Decoder Loss:  0.34520525
Encoder Loss:  0.035345882  || Decoder Loss:  0.032026056 Validation Decoder Loss:  0.34531295
Encoder Loss:  0.034671273  || Decoder Loss:  0.0320165 Validation Decoder Loss:  0.3453067
Encoder Loss:  0.034744646  || Decoder Loss:  0.03200898 Validation Decoder Loss:  0.34533083
Encoder Loss:  0.03473858  || Decoder Loss:  0.03200125 Validation Decoder Loss:  0.34534934
Encoder Loss:  0.03471799  || Decoder Loss:  0.031993445 Validation Decoder Loss:  0.3453546
Encoder Loss:  0.03471708  || Decoder Loss:  0.031985447 Validation Decoder Loss:  0.34536946
Encoder Loss:  0.0347039  || Decoder Loss:  0.031977348 Validation Decoder Loss:  0.34538242
Encoder Loss:  0.03469327  || Decoder Loss:  0.03196914 Validation Decoder Loss:  0.3453901
Encoder Loss:  0.034685355  || Decoder Loss:  0.031960823 Validation Decoder Loss:  0.34540427
Encoder Loss:  0.03467363  || Decoder Loss:  0.03195219 Validation Decoder Loss:  0.34542555
Encoder Loss:  0.034661826  || Decoder Loss:  0.031943522 Validation Decoder Loss:  0.34543723
Encoder Loss:  0.034651242  || Decoder Loss:  0.031934828 Validation Decoder Loss:  0.34544396
Encoder Loss:  0.034640778  || Decoder Loss:  0.031926073 Validation Decoder Loss:  0.3454498
Model: siamese_net_lr_0.03548536708680875 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3454498
Model: "sequential_626"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_338 (Conv3D (None, 150, 5, 20, 1)     88        
_________________________________________________________________
dropout_726 (Dropout)        (None, 150, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_339 (Conv3D (None, 634, 5, 20, 1)     486       
_________________________________________________________________
reshape_183 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_728 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 3240, 20, 1)       72        
_________________________________________________________________
dropout_730 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 3245, 20, 1)       7         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14949384  || Decoder Loss:  0.16399805 Validation Decoder Loss:  0.45857513
Encoder Loss:  0.36316672  || Decoder Loss:  0.48329216 Validation Decoder Loss:  0.7498056
Encoder Loss:  0.37544104  || Decoder Loss:  0.50123113 Validation Decoder Loss:  0.7301396
Encoder Loss:  0.37543678  || Decoder Loss:  0.5007613 Validation Decoder Loss:  0.7473638
Encoder Loss:  0.37469035  || Decoder Loss:  0.5000487 Validation Decoder Loss:  0.74894184
Encoder Loss:  0.37382808  || Decoder Loss:  0.50007665 Validation Decoder Loss:  0.73998183
Encoder Loss:  0.3741646  || Decoder Loss:  0.49787953 Validation Decoder Loss:  0.7437268
Encoder Loss:  0.37791038  || Decoder Loss:  0.50307566 Validation Decoder Loss:  0.73183346
Encoder Loss:  0.37364066  || Decoder Loss:  0.49880195 Validation Decoder Loss:  0.7381377
Encoder Loss:  0.37341905  || Decoder Loss:  0.49735773 Validation Decoder Loss:  0.7382664
Encoder Loss:  0.37510234  || Decoder Loss:  0.4997717 Validation Decoder Loss:  0.73465854
Encoder Loss:  0.3741316  || Decoder Loss:  0.49975684 Validation Decoder Loss:  0.7448857
Encoder Loss:  0.37446353  || Decoder Loss:  0.50037694 Validation Decoder Loss:  0.7555483
Encoder Loss:  0.37516502  || Decoder Loss:  0.5000648 Validation Decoder Loss:  0.74111027
Encoder Loss:  0.37417233  || Decoder Loss:  0.49996322 Validation Decoder Loss:  0.74062574
Encoder Loss:  0.37410438  || Decoder Loss:  0.50003 Validation Decoder Loss:  0.72225136
Encoder Loss:  0.37349042  || Decoder Loss:  0.49878573 Validation Decoder Loss:  0.7486292
Encoder Loss:  0.37420478  || Decoder Loss:  0.5004207 Validation Decoder Loss:  0.74357724
Encoder Loss:  0.37352917  || Decoder Loss:  0.49994528 Validation Decoder Loss:  0.7535192
Encoder Loss:  0.37469208  || Decoder Loss:  0.5004685 Validation Decoder Loss:  0.736005
Encoder Loss:  0.37412223  || Decoder Loss:  0.49978584 Validation Decoder Loss:  0.7372728
Encoder Loss:  0.37365964  || Decoder Loss:  0.49962294 Validation Decoder Loss:  0.7450734
Encoder Loss:  0.3735952  || Decoder Loss:  0.49943653 Validation Decoder Loss:  0.7510444
Encoder Loss:  0.3747256  || Decoder Loss:  0.50012714 Validation Decoder Loss:  0.754948
Encoder Loss:  0.37321854  || Decoder Loss:  0.49907097 Validation Decoder Loss:  0.74780685
Encoder Loss:  0.37334007  || Decoder Loss:  0.4997936 Validation Decoder Loss:  0.7510566
Encoder Loss:  0.37336284  || Decoder Loss:  0.49975908 Validation Decoder Loss:  0.74891716
Encoder Loss:  0.37332535  || Decoder Loss:  0.4984636 Validation Decoder Loss:  0.7746452
Encoder Loss:  0.3774272  || Decoder Loss:  0.50279164 Validation Decoder Loss:  0.7572797
Encoder Loss:  0.3748643  || Decoder Loss:  0.50013125 Validation Decoder Loss:  0.76155996
Encoder Loss:  0.37494195  || Decoder Loss:  0.50090903 Validation Decoder Loss:  0.75218093
Encoder Loss:  0.37284446  || Decoder Loss:  0.49914208 Validation Decoder Loss:  0.7559694
Encoder Loss:  0.37242538  || Decoder Loss:  0.49842888 Validation Decoder Loss:  0.7461051
Encoder Loss:  0.37092167  || Decoder Loss:  0.49619615 Validation Decoder Loss:  0.7581583
Encoder Loss:  0.3743  || Decoder Loss:  0.50079894 Validation Decoder Loss:  0.7653341
Encoder Loss:  0.3739056  || Decoder Loss:  0.49972302 Validation Decoder Loss:  0.7652281
Encoder Loss:  0.37399378  || Decoder Loss:  0.49990535 Validation Decoder Loss:  0.7615639
Encoder Loss:  0.37412742  || Decoder Loss:  0.500713 Validation Decoder Loss:  0.7581817
Encoder Loss:  0.3740882  || Decoder Loss:  0.5002905 Validation Decoder Loss:  0.7524929
Encoder Loss:  0.37480658  || Decoder Loss:  0.5009165 Validation Decoder Loss:  0.77065766
Model: siamese_net_lr_0.05002318429256535 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.77065766
Model: "sequential_630"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_341 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_732 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_342 (Conv3D (None, 634, 5, 20, 1)     271       
_________________________________________________________________
reshape_184 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 301
Trainable params: 301
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_734 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_633"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_736 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.55380005  || Decoder Loss:  0.8300501 Validation Decoder Loss:  1.6298745
Encoder Loss:  0.40068004  || Decoder Loss:  0.5460724 Validation Decoder Loss:  0.49343365
Encoder Loss:  0.26686928  || Decoder Loss:  0.5592525 Validation Decoder Loss:  0.77350533
Encoder Loss:  0.24377617  || Decoder Loss:  0.53373694 Validation Decoder Loss:  1.1864418
Encoder Loss:  0.22907582  || Decoder Loss:  0.5033721 Validation Decoder Loss:  1.214174
Encoder Loss:  0.22726278  || Decoder Loss:  0.4990312 Validation Decoder Loss:  1.5019171
Encoder Loss:  0.23325397  || Decoder Loss:  0.5153037 Validation Decoder Loss:  1.2313373
Encoder Loss:  0.22668469  || Decoder Loss:  0.50013936 Validation Decoder Loss:  1.1112275
Encoder Loss:  0.22733891  || Decoder Loss:  0.49968448 Validation Decoder Loss:  1.0934944
Encoder Loss:  0.22611336  || Decoder Loss:  0.49676594 Validation Decoder Loss:  1.0617216
Encoder Loss:  0.22789326  || Decoder Loss:  0.49952012 Validation Decoder Loss:  1.064122
Encoder Loss:  0.22558765  || Decoder Loss:  0.49622077 Validation Decoder Loss:  1.0625302
Encoder Loss:  0.22538696  || Decoder Loss:  0.4949279 Validation Decoder Loss:  1.0414641
Encoder Loss:  0.22478306  || Decoder Loss:  0.49447808 Validation Decoder Loss:  1.0727209
Encoder Loss:  0.22624072  || Decoder Loss:  0.4972255 Validation Decoder Loss:  1.0414903
Encoder Loss:  0.22451021  || Decoder Loss:  0.49452034 Validation Decoder Loss:  1.0144413
Encoder Loss:  0.22503382  || Decoder Loss:  0.49364388 Validation Decoder Loss:  1.0055361
Encoder Loss:  0.22648966  || Decoder Loss:  0.49484935 Validation Decoder Loss:  1.0498087
Encoder Loss:  0.22595985  || Decoder Loss:  0.49570817 Validation Decoder Loss:  1.0260477
Encoder Loss:  0.2253272  || Decoder Loss:  0.4923838 Validation Decoder Loss:  1.0728285
Encoder Loss:  0.22639747  || Decoder Loss:  0.49794433 Validation Decoder Loss:  1.0118225
Encoder Loss:  0.2246665  || Decoder Loss:  0.4937842 Validation Decoder Loss:  1.020742
Encoder Loss:  0.2251262  || Decoder Loss:  0.49445733 Validation Decoder Loss:  1.049392
Encoder Loss:  0.2247686  || Decoder Loss:  0.49358124 Validation Decoder Loss:  1.0035803
Encoder Loss:  0.22662748  || Decoder Loss:  0.49556962 Validation Decoder Loss:  1.0431731
Encoder Loss:  0.22664434  || Decoder Loss:  0.4961189 Validation Decoder Loss:  1.024139
Encoder Loss:  0.22469392  || Decoder Loss:  0.49316034 Validation Decoder Loss:  1.0240508
Encoder Loss:  0.2240307  || Decoder Loss:  0.49297005 Validation Decoder Loss:  1.0270587
Encoder Loss:  0.22603942  || Decoder Loss:  0.4956146 Validation Decoder Loss:  1.0388771
Encoder Loss:  0.22447932  || Decoder Loss:  0.49264637 Validation Decoder Loss:  1.0288081
Encoder Loss:  0.22478901  || Decoder Loss:  0.49412712 Validation Decoder Loss:  1.0299118
Encoder Loss:  0.22470602  || Decoder Loss:  0.49269116 Validation Decoder Loss:  1.053861
Encoder Loss:  0.2239861  || Decoder Loss:  0.49316934 Validation Decoder Loss:  1.0493592
Encoder Loss:  0.2247988  || Decoder Loss:  0.49388546 Validation Decoder Loss:  1.0450578
Encoder Loss:  0.22512709  || Decoder Loss:  0.49404675 Validation Decoder Loss:  1.0165722
Encoder Loss:  0.22578582  || Decoder Loss:  0.49511388 Validation Decoder Loss:  1.0545005
Encoder Loss:  0.22373779  || Decoder Loss:  0.49222663 Validation Decoder Loss:  1.0370119
Encoder Loss:  0.2245709  || Decoder Loss:  0.4935463 Validation Decoder Loss:  1.0522854
Encoder Loss:  0.22435877  || Decoder Loss:  0.49256706 Validation Decoder Loss:  1.0019802
Encoder Loss:  0.22189032  || Decoder Loss:  0.48698643 Validation Decoder Loss:  1.1060135
Model: siamese_net_lr_0.04942585333462941 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1060135
Model: "sequential_634"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_344 (Conv3D (None, 242, 5, 20, 1)     117       
_________________________________________________________________
dropout_738 (Dropout)        (None, 242, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_345 (Conv3D (None, 634, 5, 20, 1)     153       
_________________________________________________________________
reshape_185 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 270
Trainable params: 270
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_636"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 3190, 20, 1)       57        
_________________________________________________________________
dropout_740 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 3170, 20, 1)       22        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_742 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058011394  || Decoder Loss:  0.05735944 Validation Decoder Loss:  0.3419313
Encoder Loss:  0.038252767  || Decoder Loss:  0.032586392 Validation Decoder Loss:  0.3473456
Encoder Loss:  0.039303962  || Decoder Loss:  0.032292765 Validation Decoder Loss:  0.34926274
Encoder Loss:  0.039771218  || Decoder Loss:  0.032254186 Validation Decoder Loss:  0.35052598
Encoder Loss:  0.037033197  || Decoder Loss:  0.032177825 Validation Decoder Loss:  0.3476332
Encoder Loss:  0.036821812  || Decoder Loss:  0.03213699 Validation Decoder Loss:  0.3485899
Encoder Loss:  0.036850963  || Decoder Loss:  0.03209753 Validation Decoder Loss:  0.34867308
Encoder Loss:  0.03673971  || Decoder Loss:  0.032068674 Validation Decoder Loss:  0.3484426
Encoder Loss:  0.036717366  || Decoder Loss:  0.03203676 Validation Decoder Loss:  0.3488887
Encoder Loss:  0.03664804  || Decoder Loss:  0.032006703 Validation Decoder Loss:  0.3483626
Encoder Loss:  0.036626104  || Decoder Loss:  0.03197756 Validation Decoder Loss:  0.34829605
Encoder Loss:  0.036684327  || Decoder Loss:  0.03195058 Validation Decoder Loss:  0.3487204
Encoder Loss:  0.036645144  || Decoder Loss:  0.0319273 Validation Decoder Loss:  0.3488555
Encoder Loss:  0.03659423  || Decoder Loss:  0.031900857 Validation Decoder Loss:  0.34925568
Encoder Loss:  0.036533203  || Decoder Loss:  0.03186676 Validation Decoder Loss:  0.34911183
Encoder Loss:  0.036536552  || Decoder Loss:  0.03183802 Validation Decoder Loss:  0.34917355
Encoder Loss:  0.036529377  || Decoder Loss:  0.031816248 Validation Decoder Loss:  0.34915203
Encoder Loss:  0.036492605  || Decoder Loss:  0.0317905 Validation Decoder Loss:  0.34927347
Encoder Loss:  0.036496  || Decoder Loss:  0.03176783 Validation Decoder Loss:  0.34937376
Encoder Loss:  0.03648418  || Decoder Loss:  0.031748 Validation Decoder Loss:  0.3494652
Encoder Loss:  0.03646623  || Decoder Loss:  0.03173103 Validation Decoder Loss:  0.34955066
Encoder Loss:  0.03642552  || Decoder Loss:  0.03171682 Validation Decoder Loss:  0.34962583
Encoder Loss:  0.0364622  || Decoder Loss:  0.031703673 Validation Decoder Loss:  0.34971786
Encoder Loss:  0.036513973  || Decoder Loss:  0.031691648 Validation Decoder Loss:  0.34972727
Encoder Loss:  0.03642185  || Decoder Loss:  0.031685337 Validation Decoder Loss:  0.34984562
Encoder Loss:  0.036387816  || Decoder Loss:  0.031673804 Validation Decoder Loss:  0.34972483
Encoder Loss:  0.03639713  || Decoder Loss:  0.031661376 Validation Decoder Loss:  0.3496769
Encoder Loss:  0.036407303  || Decoder Loss:  0.031652097 Validation Decoder Loss:  0.3496768
Encoder Loss:  0.03645395  || Decoder Loss:  0.031642042 Validation Decoder Loss:  0.34973457
Encoder Loss:  0.036416236  || Decoder Loss:  0.031640217 Validation Decoder Loss:  0.34944612
Encoder Loss:  0.036380954  || Decoder Loss:  0.03162731 Validation Decoder Loss:  0.34954548
Encoder Loss:  0.036389817  || Decoder Loss:  0.031624302 Validation Decoder Loss:  0.34962684
Encoder Loss:  0.03635919  || Decoder Loss:  0.031614754 Validation Decoder Loss:  0.34948656
Encoder Loss:  0.0363446  || Decoder Loss:  0.031609967 Validation Decoder Loss:  0.34949476
Encoder Loss:  0.036331903  || Decoder Loss:  0.03160385 Validation Decoder Loss:  0.34945348
Encoder Loss:  0.03634885  || Decoder Loss:  0.031598736 Validation Decoder Loss:  0.34943312
Encoder Loss:  0.036338244  || Decoder Loss:  0.031593043 Validation Decoder Loss:  0.3493266
Encoder Loss:  0.036342844  || Decoder Loss:  0.03158998 Validation Decoder Loss:  0.3492903
Encoder Loss:  0.036333956  || Decoder Loss:  0.03158534 Validation Decoder Loss:  0.3492195
Encoder Loss:  0.03632465  || Decoder Loss:  0.031583272 Validation Decoder Loss:  0.349206
Model: siamese_net_lr_0.013701006751222145 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34920597
Model: "sequential_638"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_347 (Conv3D (None, 148, 5, 20, 1)     23        
_________________________________________________________________
dropout_744 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_348 (Conv3D (None, 634, 5, 20, 1)     341       
_________________________________________________________________
reshape_186 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 364
Trainable params: 364
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_640"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_746 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_748 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08528519  || Decoder Loss:  0.07558887 Validation Decoder Loss:  0.31635353
Encoder Loss:  0.050856486  || Decoder Loss:  0.04013468 Validation Decoder Loss:  0.3729565
Encoder Loss:  0.043732725  || Decoder Loss:  0.035910696 Validation Decoder Loss:  0.3358068
Encoder Loss:  0.042368434  || Decoder Loss:  0.034449946 Validation Decoder Loss:  0.31458265
Encoder Loss:  0.044030823  || Decoder Loss:  0.036785837 Validation Decoder Loss:  0.36091042
Encoder Loss:  0.042227864  || Decoder Loss:  0.034980852 Validation Decoder Loss:  0.33399874
Encoder Loss:  0.041775394  || Decoder Loss:  0.0341238 Validation Decoder Loss:  0.33546644
Encoder Loss:  0.042188  || Decoder Loss:  0.034380738 Validation Decoder Loss:  0.30357218
Encoder Loss:  0.04146799  || Decoder Loss:  0.034090266 Validation Decoder Loss:  0.3300069
Encoder Loss:  0.043246765  || Decoder Loss:  0.034283616 Validation Decoder Loss:  0.31578547
Encoder Loss:  0.04331769  || Decoder Loss:  0.035011154 Validation Decoder Loss:  0.34972084
Encoder Loss:  0.041215163  || Decoder Loss:  0.033264857 Validation Decoder Loss:  0.33978134
Encoder Loss:  0.04076911  || Decoder Loss:  0.03310388 Validation Decoder Loss:  0.33801526
Encoder Loss:  0.040755037  || Decoder Loss:  0.033039913 Validation Decoder Loss:  0.33815566
Encoder Loss:  0.04169532  || Decoder Loss:  0.033098016 Validation Decoder Loss:  0.3304206
Encoder Loss:  0.040533274  || Decoder Loss:  0.033127762 Validation Decoder Loss:  0.3322701
Encoder Loss:  0.040254455  || Decoder Loss:  0.033010412 Validation Decoder Loss:  0.33530825
Encoder Loss:  0.040363174  || Decoder Loss:  0.03299516 Validation Decoder Loss:  0.33661014
Encoder Loss:  0.041518897  || Decoder Loss:  0.033667322 Validation Decoder Loss:  0.3514393
Encoder Loss:  0.039934784  || Decoder Loss:  0.03309269 Validation Decoder Loss:  0.3387844
Encoder Loss:  0.0396394  || Decoder Loss:  0.0329104 Validation Decoder Loss:  0.33610296
Encoder Loss:  0.03953961  || Decoder Loss:  0.032858305 Validation Decoder Loss:  0.3370713
Encoder Loss:  0.03948376  || Decoder Loss:  0.032842867 Validation Decoder Loss:  0.3369223
Encoder Loss:  0.03953079  || Decoder Loss:  0.032919932 Validation Decoder Loss:  0.33110482
Encoder Loss:  0.039502677  || Decoder Loss:  0.03289065 Validation Decoder Loss:  0.33513802
Encoder Loss:  0.039498452  || Decoder Loss:  0.03288623 Validation Decoder Loss:  0.33439556
Encoder Loss:  0.039506286  || Decoder Loss:  0.032899592 Validation Decoder Loss:  0.33315313
Encoder Loss:  0.03949067  || Decoder Loss:  0.03288005 Validation Decoder Loss:  0.3344891
Encoder Loss:  0.0395069  || Decoder Loss:  0.0328997 Validation Decoder Loss:  0.3334127
Encoder Loss:  0.03948608  || Decoder Loss:  0.032866403 Validation Decoder Loss:  0.3340483
Encoder Loss:  0.039485637  || Decoder Loss:  0.03287241 Validation Decoder Loss:  0.33416802
Encoder Loss:  0.03947663  || Decoder Loss:  0.03285958 Validation Decoder Loss:  0.3341284
Encoder Loss:  0.03948365  || Decoder Loss:  0.03286529 Validation Decoder Loss:  0.33366907
Encoder Loss:  0.03946845  || Decoder Loss:  0.032844942 Validation Decoder Loss:  0.3335963
Encoder Loss:  0.039466932  || Decoder Loss:  0.032842558 Validation Decoder Loss:  0.33378714
Encoder Loss:  0.03947077  || Decoder Loss:  0.032843817 Validation Decoder Loss:  0.3343768
Encoder Loss:  0.039456073  || Decoder Loss:  0.032824762 Validation Decoder Loss:  0.33364964
Encoder Loss:  0.039460126  || Decoder Loss:  0.032827217 Validation Decoder Loss:  0.3340883
Encoder Loss:  0.039459582  || Decoder Loss:  0.032825474 Validation Decoder Loss:  0.33324525
Encoder Loss:  0.039446596  || Decoder Loss:  0.032811187 Validation Decoder Loss:  0.33319467
Model: siamese_net_lr_0.03882451269568774 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33319464
Model: "sequential_642"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_350 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_750 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_351 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_187 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_752 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 3190, 20, 1)       22        
_________________________________________________________________
dropout_754 (Dropout)        (None, 3190, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 3245, 20, 1)       57        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32796645  || Decoder Loss:  0.35987994 Validation Decoder Loss:  1.101177
Encoder Loss:  0.43895411  || Decoder Loss:  0.5117244 Validation Decoder Loss:  1.1923907
Encoder Loss:  0.44248998  || Decoder Loss:  0.5174258 Validation Decoder Loss:  1.1604472
Encoder Loss:  0.43536076  || Decoder Loss:  0.50884056 Validation Decoder Loss:  1.0036991
Encoder Loss:  0.4228577  || Decoder Loss:  0.49408713 Validation Decoder Loss:  0.91203976
Encoder Loss:  0.42142135  || Decoder Loss:  0.49224502 Validation Decoder Loss:  0.84251106
Encoder Loss:  0.41720304  || Decoder Loss:  0.4872522 Validation Decoder Loss:  0.84974295
Encoder Loss:  0.4128938  || Decoder Loss:  0.48201016 Validation Decoder Loss:  0.81616646
Encoder Loss:  0.382599  || Decoder Loss:  0.4457329 Validation Decoder Loss:  0.9960809
Encoder Loss:  0.35242042  || Decoder Loss:  0.40958405 Validation Decoder Loss:  0.8545296
Encoder Loss:  0.4170628  || Decoder Loss:  0.4872995 Validation Decoder Loss:  0.8594557
Encoder Loss:  0.41783795  || Decoder Loss:  0.48808545 Validation Decoder Loss:  0.872199
Encoder Loss:  0.41654044  || Decoder Loss:  0.4867345 Validation Decoder Loss:  0.94568735
Encoder Loss:  0.42192322  || Decoder Loss:  0.49287766 Validation Decoder Loss:  0.88015455
Encoder Loss:  0.41528624  || Decoder Loss:  0.48530385 Validation Decoder Loss:  0.86292326
Encoder Loss:  0.4162929  || Decoder Loss:  0.48594925 Validation Decoder Loss:  0.93537414
Encoder Loss:  0.41310376  || Decoder Loss:  0.48234215 Validation Decoder Loss:  0.90808
Encoder Loss:  0.41050258  || Decoder Loss:  0.47892123 Validation Decoder Loss:  0.913278
Encoder Loss:  0.3493655  || Decoder Loss:  0.40650693 Validation Decoder Loss:  0.8044263
Encoder Loss:  0.22457041  || Decoder Loss:  0.25772744 Validation Decoder Loss:  0.6210489
Encoder Loss:  0.29066423  || Decoder Loss:  0.336479 Validation Decoder Loss:  0.9766957
Encoder Loss:  0.32154807  || Decoder Loss:  0.37294143 Validation Decoder Loss:  0.9572793
Encoder Loss:  0.3824496  || Decoder Loss:  0.44554272 Validation Decoder Loss:  0.8457713
Encoder Loss:  0.39831397  || Decoder Loss:  0.4637115 Validation Decoder Loss:  1.0296314
Encoder Loss:  0.41985252  || Decoder Loss:  0.4900506 Validation Decoder Loss:  0.8982351
Encoder Loss:  0.41876733  || Decoder Loss:  0.48891124 Validation Decoder Loss:  0.8501477
Encoder Loss:  0.41748288  || Decoder Loss:  0.48735213 Validation Decoder Loss:  0.95379937
Encoder Loss:  0.41262826  || Decoder Loss:  0.48187676 Validation Decoder Loss:  0.93619436
Encoder Loss:  0.41579854  || Decoder Loss:  0.48589417 Validation Decoder Loss:  0.9096855
Encoder Loss:  0.4194215  || Decoder Loss:  0.49017403 Validation Decoder Loss:  0.93970597
Encoder Loss:  0.41733646  || Decoder Loss:  0.48769096 Validation Decoder Loss:  1.0024011
Encoder Loss:  0.41755313  || Decoder Loss:  0.48796207 Validation Decoder Loss:  0.9069674
Encoder Loss:  0.41399774  || Decoder Loss:  0.4836592 Validation Decoder Loss:  0.9611057
Encoder Loss:  0.41940483  || Decoder Loss:  0.4901665 Validation Decoder Loss:  0.9868933
Encoder Loss:  0.41988075  || Decoder Loss:  0.49056607 Validation Decoder Loss:  0.874138
Encoder Loss:  0.42080343  || Decoder Loss:  0.49076712 Validation Decoder Loss:  0.8987385
Encoder Loss:  0.4038537  || Decoder Loss:  0.47098446 Validation Decoder Loss:  0.961958
Encoder Loss:  0.4121129  || Decoder Loss:  0.4816704 Validation Decoder Loss:  0.96743
Encoder Loss:  0.40659752  || Decoder Loss:  0.4749282 Validation Decoder Loss:  1.0327547
Encoder Loss:  0.40269524  || Decoder Loss:  0.46998838 Validation Decoder Loss:  0.89665663
Model: siamese_net_lr_0.05794095759069996 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.89665663
Model: "sequential_646"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_353 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_756 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_354 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_188 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_758 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_649"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_760 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.110772565  || Decoder Loss:  0.099609986 Validation Decoder Loss:  0.3838396
Encoder Loss:  0.042932633  || Decoder Loss:  0.037509926 Validation Decoder Loss:  0.35892218
Encoder Loss:  0.03674903  || Decoder Loss:  0.03292862 Validation Decoder Loss:  0.34077144
Encoder Loss:  0.035616457  || Decoder Loss:  0.032410875 Validation Decoder Loss:  0.32784545
Encoder Loss:  0.03523345  || Decoder Loss:  0.032330118 Validation Decoder Loss:  0.3285164
Encoder Loss:  0.035070635  || Decoder Loss:  0.03229188 Validation Decoder Loss:  0.33341295
Encoder Loss:  0.03544215  || Decoder Loss:  0.032245155 Validation Decoder Loss:  0.33542144
Encoder Loss:  0.034988016  || Decoder Loss:  0.032201573 Validation Decoder Loss:  0.33387753
Encoder Loss:  0.035500243  || Decoder Loss:  0.032175 Validation Decoder Loss:  0.33331275
Encoder Loss:  0.035281926  || Decoder Loss:  0.03215286 Validation Decoder Loss:  0.33265477
Encoder Loss:  0.03532719  || Decoder Loss:  0.03213186 Validation Decoder Loss:  0.33195117
Encoder Loss:  0.03522825  || Decoder Loss:  0.032116346 Validation Decoder Loss:  0.3313258
Encoder Loss:  0.034928724  || Decoder Loss:  0.03209617 Validation Decoder Loss:  0.33146644
Encoder Loss:  0.035237964  || Decoder Loss:  0.032075882 Validation Decoder Loss:  0.33194774
Encoder Loss:  0.03541372  || Decoder Loss:  0.03206406 Validation Decoder Loss:  0.32495517
Encoder Loss:  0.03496676  || Decoder Loss:  0.032068476 Validation Decoder Loss:  0.32736072
Encoder Loss:  0.034953587  || Decoder Loss:  0.032045197 Validation Decoder Loss:  0.32955694
Encoder Loss:  0.035092577  || Decoder Loss:  0.032026373 Validation Decoder Loss:  0.33093625
Encoder Loss:  0.035245933  || Decoder Loss:  0.032007515 Validation Decoder Loss:  0.32572487
Encoder Loss:  0.034812924  || Decoder Loss:  0.032009147 Validation Decoder Loss:  0.32557222
Encoder Loss:  0.03462746  || Decoder Loss:  0.031973254 Validation Decoder Loss:  0.3269806
Encoder Loss:  0.034969732  || Decoder Loss:  0.031944476 Validation Decoder Loss:  0.3304461
Encoder Loss:  0.03471914  || Decoder Loss:  0.031921636 Validation Decoder Loss:  0.32849932
Encoder Loss:  0.034634884  || Decoder Loss:  0.031891603 Validation Decoder Loss:  0.3284344
Encoder Loss:  0.03464732  || Decoder Loss:  0.031868566 Validation Decoder Loss:  0.3286246
Encoder Loss:  0.034511536  || Decoder Loss:  0.0318448 Validation Decoder Loss:  0.32925344
Encoder Loss:  0.0344711  || Decoder Loss:  0.031815227 Validation Decoder Loss:  0.33034933
Encoder Loss:  0.03463335  || Decoder Loss:  0.031788465 Validation Decoder Loss:  0.33017445
Encoder Loss:  0.034496512  || Decoder Loss:  0.03176641 Validation Decoder Loss:  0.3297094
Encoder Loss:  0.03444619  || Decoder Loss:  0.031744268 Validation Decoder Loss:  0.33058652
Encoder Loss:  0.034411248  || Decoder Loss:  0.03171679 Validation Decoder Loss:  0.33054894
Encoder Loss:  0.034304105  || Decoder Loss:  0.031688984 Validation Decoder Loss:  0.3309428
Encoder Loss:  0.034422856  || Decoder Loss:  0.031663667 Validation Decoder Loss:  0.33143058
Encoder Loss:  0.034473985  || Decoder Loss:  0.03164301 Validation Decoder Loss:  0.33119288
Encoder Loss:  0.034433804  || Decoder Loss:  0.03162439 Validation Decoder Loss:  0.33160943
Encoder Loss:  0.03438373  || Decoder Loss:  0.031609267 Validation Decoder Loss:  0.33178613
Encoder Loss:  0.034348782  || Decoder Loss:  0.031592954 Validation Decoder Loss:  0.3313266
Encoder Loss:  0.034522872  || Decoder Loss:  0.031581264 Validation Decoder Loss:  0.3323052
Encoder Loss:  0.034269404  || Decoder Loss:  0.03156808 Validation Decoder Loss:  0.3305214
Encoder Loss:  0.034254726  || Decoder Loss:  0.031557642 Validation Decoder Loss:  0.33132374
Model: siamese_net_lr_0.01898145607798874 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33132374
Model: "sequential_650"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_356 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
dropout_762 (Dropout)        (None, 90, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_357 (Conv3D (None, 634, 5, 20, 1)     368       
_________________________________________________________________
reshape_189 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 396
Trainable params: 396
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_652"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_272 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_764 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_273 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_653"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_272 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_766 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_273 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3332217  || Decoder Loss:  0.38430458 Validation Decoder Loss:  0.9089519
Encoder Loss:  0.3932631  || Decoder Loss:  0.47553357 Validation Decoder Loss:  0.8651171
Encoder Loss:  0.37411344  || Decoder Loss:  0.45257914 Validation Decoder Loss:  1.0757934
Encoder Loss:  0.40389645  || Decoder Loss:  0.48883688 Validation Decoder Loss:  0.96003705
Encoder Loss:  0.38993397  || Decoder Loss:  0.4712195 Validation Decoder Loss:  0.95631766
Encoder Loss:  0.38568315  || Decoder Loss:  0.4664336 Validation Decoder Loss:  1.0722109
Encoder Loss:  0.34594458  || Decoder Loss:  0.4164909 Validation Decoder Loss:  0.88988286
Encoder Loss:  0.2753374  || Decoder Loss:  0.3286375 Validation Decoder Loss:  1.0555098
Encoder Loss:  0.39549407  || Decoder Loss:  0.47901204 Validation Decoder Loss:  1.0889785
Encoder Loss:  0.39395916  || Decoder Loss:  0.47707608 Validation Decoder Loss:  1.0688555
Encoder Loss:  0.38579053  || Decoder Loss:  0.46716967 Validation Decoder Loss:  1.1236204
Encoder Loss:  0.27360013  || Decoder Loss:  0.32749084 Validation Decoder Loss:  0.78375757
Encoder Loss:  0.39098376  || Decoder Loss:  0.47327834 Validation Decoder Loss:  0.848096
Encoder Loss:  0.39316604  || Decoder Loss:  0.47618046 Validation Decoder Loss:  0.8505212
Encoder Loss:  0.3998201  || Decoder Loss:  0.4841777 Validation Decoder Loss:  0.83295774
Encoder Loss:  0.39081556  || Decoder Loss:  0.47305185 Validation Decoder Loss:  0.8328411
Encoder Loss:  0.37471977  || Decoder Loss:  0.45309165 Validation Decoder Loss:  0.70693344
Encoder Loss:  0.31302127  || Decoder Loss:  0.37637585 Validation Decoder Loss:  0.9854257
Encoder Loss:  0.283529  || Decoder Loss:  0.3390455 Validation Decoder Loss:  0.7541962
Encoder Loss:  0.38604727  || Decoder Loss:  0.46656734 Validation Decoder Loss:  0.7353241
Encoder Loss:  0.38902333  || Decoder Loss:  0.47076905 Validation Decoder Loss:  0.8835515
Encoder Loss:  0.3905264  || Decoder Loss:  0.47283345 Validation Decoder Loss:  0.8533292
Encoder Loss:  0.3834213  || Decoder Loss:  0.46402627 Validation Decoder Loss:  0.83634925
Encoder Loss:  0.3132456  || Decoder Loss:  0.3767579 Validation Decoder Loss:  0.6087357
Encoder Loss:  0.20052288  || Decoder Loss:  0.2365401 Validation Decoder Loss:  0.7480587
Encoder Loss:  0.31120533  || Decoder Loss:  0.37414154 Validation Decoder Loss:  0.9014822
Encoder Loss:  0.24575311  || Decoder Loss:  0.2928411 Validation Decoder Loss:  0.52919734
Encoder Loss:  0.12043034  || Decoder Loss:  0.13699935 Validation Decoder Loss:  0.43238205
Encoder Loss:  0.06598639  || Decoder Loss:  0.06927344 Validation Decoder Loss:  0.3147073
Encoder Loss:  0.038753163  || Decoder Loss:  0.03512104 Validation Decoder Loss:  0.32596892
Encoder Loss:  0.037355773  || Decoder Loss:  0.032796707 Validation Decoder Loss:  0.3343991
Encoder Loss:  0.03644849  || Decoder Loss:  0.032586187 Validation Decoder Loss:  0.33562666
Encoder Loss:  0.036725864  || Decoder Loss:  0.03257305 Validation Decoder Loss:  0.3353238
Encoder Loss:  0.036132213  || Decoder Loss:  0.032567497 Validation Decoder Loss:  0.33599135
Encoder Loss:  0.036386393  || Decoder Loss:  0.032557305 Validation Decoder Loss:  0.33553308
Encoder Loss:  0.036644883  || Decoder Loss:  0.03255212 Validation Decoder Loss:  0.3362005
Encoder Loss:  0.036489442  || Decoder Loss:  0.032545462 Validation Decoder Loss:  0.33529145
Encoder Loss:  0.036633343  || Decoder Loss:  0.03253606 Validation Decoder Loss:  0.3357961
Encoder Loss:  0.036298957  || Decoder Loss:  0.032532886 Validation Decoder Loss:  0.3357485
Encoder Loss:  0.036267683  || Decoder Loss:  0.032530993 Validation Decoder Loss:  0.3360915
Model: siamese_net_lr_0.06714244767057471 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3360915
Model: "sequential_654"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_359 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_768 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_360 (Conv3D (None, 634, 5, 20, 1)     356       
_________________________________________________________________
reshape_190 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 388
Trainable params: 388
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_656"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_274 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_770 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_275 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_657"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_274 (Conv2D (None, 3240, 20, 1)       72        
_________________________________________________________________
dropout_772 (Dropout)        (None, 3240, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_275 (Conv2D (None, 3245, 20, 1)       7         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.091905795  || Decoder Loss:  0.06141922 Validation Decoder Loss:  0.3512199
Encoder Loss:  0.076380774  || Decoder Loss:  0.09190145 Validation Decoder Loss:  0.3653478
Encoder Loss:  0.062342037  || Decoder Loss:  0.080449656 Validation Decoder Loss:  0.39937043
Encoder Loss:  0.066076644  || Decoder Loss:  0.10825868 Validation Decoder Loss:  0.39267164
Encoder Loss:  0.055719733  || Decoder Loss:  0.069460094 Validation Decoder Loss:  0.35648948
Encoder Loss:  0.04618814  || Decoder Loss:  0.03489128 Validation Decoder Loss:  0.34804922
Encoder Loss:  0.045985404  || Decoder Loss:  0.033926148 Validation Decoder Loss:  0.34679043
Encoder Loss:  0.046015166  || Decoder Loss:  0.033903908 Validation Decoder Loss:  0.34657866
Encoder Loss:  0.045915022  || Decoder Loss:  0.033891752 Validation Decoder Loss:  0.34652424
Encoder Loss:  0.045871392  || Decoder Loss:  0.033884306 Validation Decoder Loss:  0.34639978
Encoder Loss:  0.045831013  || Decoder Loss:  0.033873588 Validation Decoder Loss:  0.3463982
Encoder Loss:  0.0458703  || Decoder Loss:  0.033859663 Validation Decoder Loss:  0.34631687
Encoder Loss:  0.045803584  || Decoder Loss:  0.03384778 Validation Decoder Loss:  0.3461499
Encoder Loss:  0.045928303  || Decoder Loss:  0.03383392 Validation Decoder Loss:  0.34605792
Encoder Loss:  0.046911728  || Decoder Loss:  0.033828136 Validation Decoder Loss:  0.34586045
Encoder Loss:  0.04664877  || Decoder Loss:  0.033835582 Validation Decoder Loss:  0.34579194
Encoder Loss:  0.05813803  || Decoder Loss:  0.033860356 Validation Decoder Loss:  0.3465664
Encoder Loss:  0.05321946  || Decoder Loss:  0.03423114 Validation Decoder Loss:  0.34870481
Encoder Loss:  0.047191553  || Decoder Loss:  0.03439727 Validation Decoder Loss:  0.3453604
Encoder Loss:  0.045978967  || Decoder Loss:  0.03411989 Validation Decoder Loss:  0.34574616
Encoder Loss:  0.045954976  || Decoder Loss:  0.033972844 Validation Decoder Loss:  0.34542876
Encoder Loss:  0.045957893  || Decoder Loss:  0.033906844 Validation Decoder Loss:  0.3453514
Encoder Loss:  0.045949493  || Decoder Loss:  0.033891298 Validation Decoder Loss:  0.3453218
Encoder Loss:  0.045931987  || Decoder Loss:  0.0338674 Validation Decoder Loss:  0.34514913
Encoder Loss:  0.045905165  || Decoder Loss:  0.033797763 Validation Decoder Loss:  0.34511247
Encoder Loss:  0.045891624  || Decoder Loss:  0.03377491 Validation Decoder Loss:  0.34503654
Encoder Loss:  0.045895096  || Decoder Loss:  0.033770178 Validation Decoder Loss:  0.34506613
Encoder Loss:  0.045896307  || Decoder Loss:  0.03377374 Validation Decoder Loss:  0.34457186
Encoder Loss:  0.045929693  || Decoder Loss:  0.033910707 Validation Decoder Loss:  0.34768233
Encoder Loss:  0.046013832  || Decoder Loss:  0.034239527 Validation Decoder Loss:  0.3446543
Encoder Loss:  0.04587526  || Decoder Loss:  0.03374297 Validation Decoder Loss:  0.3439569
Encoder Loss:  0.045831967  || Decoder Loss:  0.03367518 Validation Decoder Loss:  0.34366742
Encoder Loss:  0.045815352  || Decoder Loss:  0.033654537 Validation Decoder Loss:  0.34339023
Encoder Loss:  0.045801014  || Decoder Loss:  0.033642497 Validation Decoder Loss:  0.34320804
Encoder Loss:  0.045784224  || Decoder Loss:  0.033637963 Validation Decoder Loss:  0.34303015
Encoder Loss:  0.045778558  || Decoder Loss:  0.033634223 Validation Decoder Loss:  0.34289116
Encoder Loss:  0.045776583  || Decoder Loss:  0.033633977 Validation Decoder Loss:  0.34276897
Encoder Loss:  0.045775175  || Decoder Loss:  0.03363696 Validation Decoder Loss:  0.3426823
Encoder Loss:  0.04576712  || Decoder Loss:  0.033639383 Validation Decoder Loss:  0.34258968
Encoder Loss:  0.04576821  || Decoder Loss:  0.033632673 Validation Decoder Loss:  0.34248286
Model: siamese_net_lr_0.020472365271584015 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34248286
Model: "sequential_658"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_362 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_774 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_363 (Conv3D (None, 634, 5, 20, 1)     374       
_________________________________________________________________
reshape_191 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_660"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_276 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_776 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_277 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_661"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_276 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_778 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_277 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06273804  || Decoder Loss:  0.05314474 Validation Decoder Loss:  0.33775777
Encoder Loss:  0.046844587  || Decoder Loss:  0.03255527 Validation Decoder Loss:  0.33601707
Encoder Loss:  0.04464303  || Decoder Loss:  0.032194998 Validation Decoder Loss:  0.33990538
Encoder Loss:  0.044357676  || Decoder Loss:  0.032115363 Validation Decoder Loss:  0.33876747
Encoder Loss:  0.04385846  || Decoder Loss:  0.032052767 Validation Decoder Loss:  0.33883673
Encoder Loss:  0.043831892  || Decoder Loss:  0.031985372 Validation Decoder Loss:  0.33868343
Encoder Loss:  0.043784793  || Decoder Loss:  0.031910915 Validation Decoder Loss:  0.3385832
Encoder Loss:  0.043737974  || Decoder Loss:  0.031831738 Validation Decoder Loss:  0.33866736
Encoder Loss:  0.043719582  || Decoder Loss:  0.031752497 Validation Decoder Loss:  0.33890325
Encoder Loss:  0.04368069  || Decoder Loss:  0.03168099 Validation Decoder Loss:  0.33902913
Encoder Loss:  0.043690477  || Decoder Loss:  0.03161901 Validation Decoder Loss:  0.33913076
Encoder Loss:  0.04365068  || Decoder Loss:  0.031565826 Validation Decoder Loss:  0.33901653
Encoder Loss:  0.04362062  || Decoder Loss:  0.03152379 Validation Decoder Loss:  0.33898577
Encoder Loss:  0.043610204  || Decoder Loss:  0.03149227 Validation Decoder Loss:  0.3389872
Encoder Loss:  0.043623403  || Decoder Loss:  0.031464204 Validation Decoder Loss:  0.33906734
Encoder Loss:  0.043609783  || Decoder Loss:  0.03143959 Validation Decoder Loss:  0.3391451
Encoder Loss:  0.04360259  || Decoder Loss:  0.03142025 Validation Decoder Loss:  0.33920705
Encoder Loss:  0.043593887  || Decoder Loss:  0.031406015 Validation Decoder Loss:  0.33927527
Encoder Loss:  0.043592304  || Decoder Loss:  0.03139452 Validation Decoder Loss:  0.33931565
Encoder Loss:  0.043590665  || Decoder Loss:  0.03138448 Validation Decoder Loss:  0.33933187
Encoder Loss:  0.04356582  || Decoder Loss:  0.031375427 Validation Decoder Loss:  0.3393672
Encoder Loss:  0.043582723  || Decoder Loss:  0.03136741 Validation Decoder Loss:  0.33937627
Encoder Loss:  0.04358189  || Decoder Loss:  0.031360637 Validation Decoder Loss:  0.3393838
Encoder Loss:  0.04356292  || Decoder Loss:  0.03135499 Validation Decoder Loss:  0.33937672
Encoder Loss:  0.04356224  || Decoder Loss:  0.031349618 Validation Decoder Loss:  0.33935893
Encoder Loss:  0.04357726  || Decoder Loss:  0.031344682 Validation Decoder Loss:  0.339344
Encoder Loss:  0.043564443  || Decoder Loss:  0.031340167 Validation Decoder Loss:  0.3393333
Encoder Loss:  0.04357466  || Decoder Loss:  0.03133613 Validation Decoder Loss:  0.33931953
Encoder Loss:  0.043586727  || Decoder Loss:  0.031332582 Validation Decoder Loss:  0.33929473
Encoder Loss:  0.043565813  || Decoder Loss:  0.031329576 Validation Decoder Loss:  0.33933997
Encoder Loss:  0.04355447  || Decoder Loss:  0.03132647 Validation Decoder Loss:  0.339316
Encoder Loss:  0.043562964  || Decoder Loss:  0.03132355 Validation Decoder Loss:  0.33931267
Encoder Loss:  0.043580256  || Decoder Loss:  0.03132086 Validation Decoder Loss:  0.33929765
Encoder Loss:  0.04360236  || Decoder Loss:  0.03131892 Validation Decoder Loss:  0.33933443
Encoder Loss:  0.04358814  || Decoder Loss:  0.031317987 Validation Decoder Loss:  0.3393554
Encoder Loss:  0.043569118  || Decoder Loss:  0.031316932 Validation Decoder Loss:  0.33933967
Encoder Loss:  0.043549202  || Decoder Loss:  0.031315517 Validation Decoder Loss:  0.3393569
Encoder Loss:  0.043539878  || Decoder Loss:  0.03131396 Validation Decoder Loss:  0.3393323
Encoder Loss:  0.043551326  || Decoder Loss:  0.031312384 Validation Decoder Loss:  0.33933544
Encoder Loss:  0.04356818  || Decoder Loss:  0.031311437 Validation Decoder Loss:  0.33935627
Model: siamese_net_lr_0.0119713794342937 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33935627
Model: "sequential_662"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_365 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_780 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_366 (Conv3D (None, 634, 5, 20, 1)     137       
_________________________________________________________________
reshape_192 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_664"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_278 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_782 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_279 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_665"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_278 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_784 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_279 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13984096  || Decoder Loss:  0.18883125 Validation Decoder Loss:  0.61665004
Encoder Loss:  0.098394945  || Decoder Loss:  0.13516615 Validation Decoder Loss:  0.3518955
Encoder Loss:  0.045149613  || Decoder Loss:  0.03519889 Validation Decoder Loss:  0.34615624
Encoder Loss:  0.043377224  || Decoder Loss:  0.03250436 Validation Decoder Loss:  0.34992287
Encoder Loss:  0.042621113  || Decoder Loss:  0.032221228 Validation Decoder Loss:  0.34910548
Encoder Loss:  0.043795463  || Decoder Loss:  0.032208912 Validation Decoder Loss:  0.34780094
Encoder Loss:  0.048964024  || Decoder Loss:  0.0323254 Validation Decoder Loss:  0.34682226
Encoder Loss:  0.046960615  || Decoder Loss:  0.032313734 Validation Decoder Loss:  0.34964907
Encoder Loss:  0.044779252  || Decoder Loss:  0.032254547 Validation Decoder Loss:  0.35153177
Encoder Loss:  0.041859426  || Decoder Loss:  0.032172643 Validation Decoder Loss:  0.3511291
Encoder Loss:  0.042739443  || Decoder Loss:  0.032179598 Validation Decoder Loss:  0.3515277
Encoder Loss:  0.041538987  || Decoder Loss:  0.032160982 Validation Decoder Loss:  0.3507325
Encoder Loss:  0.04215947  || Decoder Loss:  0.032162968 Validation Decoder Loss:  0.35123062
Encoder Loss:  0.041295398  || Decoder Loss:  0.032176714 Validation Decoder Loss:  0.351157
Encoder Loss:  0.04262574  || Decoder Loss:  0.032173112 Validation Decoder Loss:  0.34922612
Encoder Loss:  0.042436566  || Decoder Loss:  0.032182503 Validation Decoder Loss:  0.35079056
Encoder Loss:  0.040990304  || Decoder Loss:  0.032182306 Validation Decoder Loss:  0.35200927
Encoder Loss:  0.040493704  || Decoder Loss:  0.032105938 Validation Decoder Loss:  0.3488015
Encoder Loss:  0.04058155  || Decoder Loss:  0.03217734 Validation Decoder Loss:  0.3524276
Encoder Loss:  0.04120144  || Decoder Loss:  0.03228488 Validation Decoder Loss:  0.34068337
Encoder Loss:  0.042211186  || Decoder Loss:  0.033083834 Validation Decoder Loss:  0.3466009
Encoder Loss:  0.041324023  || Decoder Loss:  0.0326161 Validation Decoder Loss:  0.347694
Encoder Loss:  0.04041173  || Decoder Loss:  0.032176208 Validation Decoder Loss:  0.35160625
Encoder Loss:  0.04030633  || Decoder Loss:  0.032067753 Validation Decoder Loss:  0.35055727
Encoder Loss:  0.04028818  || Decoder Loss:  0.03205886 Validation Decoder Loss:  0.35060382
Encoder Loss:  0.040286962  || Decoder Loss:  0.032058965 Validation Decoder Loss:  0.3508072
Encoder Loss:  0.040286697  || Decoder Loss:  0.03205895 Validation Decoder Loss:  0.35087448
Encoder Loss:  0.040285263  || Decoder Loss:  0.03205638 Validation Decoder Loss:  0.35089236
Encoder Loss:  0.04028448  || Decoder Loss:  0.03205527 Validation Decoder Loss:  0.3509751
Encoder Loss:  0.040283557  || Decoder Loss:  0.03205342 Validation Decoder Loss:  0.3510307
Encoder Loss:  0.04028257  || Decoder Loss:  0.03205167 Validation Decoder Loss:  0.3510773
Encoder Loss:  0.04028138  || Decoder Loss:  0.032049835 Validation Decoder Loss:  0.35108697
Encoder Loss:  0.040279932  || Decoder Loss:  0.03204808 Validation Decoder Loss:  0.3511555
Encoder Loss:  0.040279455  || Decoder Loss:  0.032046594 Validation Decoder Loss:  0.35124844
Encoder Loss:  0.040278856  || Decoder Loss:  0.03204473 Validation Decoder Loss:  0.3512274
Encoder Loss:  0.04027696  || Decoder Loss:  0.032041773 Validation Decoder Loss:  0.35127088
Encoder Loss:  0.04027559  || Decoder Loss:  0.03203936 Validation Decoder Loss:  0.35130295
Encoder Loss:  0.040274143  || Decoder Loss:  0.032037172 Validation Decoder Loss:  0.35136878
Encoder Loss:  0.040273782  || Decoder Loss:  0.03203556 Validation Decoder Loss:  0.35131767
Encoder Loss:  0.040269632  || Decoder Loss:  0.032031298 Validation Decoder Loss:  0.35125875
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35125875
Model: "sequential_666"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_368 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_786 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_369 (Conv3D (None, 634, 5, 20, 1)     461       
_________________________________________________________________
reshape_193 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 487
Trainable params: 487
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_668"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_280 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_788 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_281 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_669"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_280 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_790 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_281 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15956482  || Decoder Loss:  0.2138925 Validation Decoder Loss:  0.59866995
Encoder Loss:  0.052228708  || Decoder Loss:  0.051778313 Validation Decoder Loss:  0.36117667
Encoder Loss:  0.0410504  || Decoder Loss:  0.03387025 Validation Decoder Loss:  0.33082858
Encoder Loss:  0.040234584  || Decoder Loss:  0.032486543 Validation Decoder Loss:  0.34131676
Encoder Loss:  0.040120736  || Decoder Loss:  0.032318994 Validation Decoder Loss:  0.33385652
Encoder Loss:  0.040100623  || Decoder Loss:  0.032286674 Validation Decoder Loss:  0.3325465
Encoder Loss:  0.04009165  || Decoder Loss:  0.032280132 Validation Decoder Loss:  0.3293362
Encoder Loss:  0.040139116  || Decoder Loss:  0.03235459 Validation Decoder Loss:  0.31909356
Encoder Loss:  0.04021176  || Decoder Loss:  0.032499615 Validation Decoder Loss:  0.31895757
Encoder Loss:  0.040522132  || Decoder Loss:  0.033060323 Validation Decoder Loss:  0.31277233
Encoder Loss:  0.040528547  || Decoder Loss:  0.033079863 Validation Decoder Loss:  0.31342673
Encoder Loss:  0.040467467  || Decoder Loss:  0.032954782 Validation Decoder Loss:  0.31386864
Encoder Loss:  0.04039702  || Decoder Loss:  0.032850135 Validation Decoder Loss:  0.31442308
Encoder Loss:  0.0403408  || Decoder Loss:  0.03273972 Validation Decoder Loss:  0.31514245
Encoder Loss:  0.040282775  || Decoder Loss:  0.03263836 Validation Decoder Loss:  0.31568068
Encoder Loss:  0.040223144  || Decoder Loss:  0.032539617 Validation Decoder Loss:  0.3161682
Encoder Loss:  0.040161047  || Decoder Loss:  0.03242128 Validation Decoder Loss:  0.31710026
Encoder Loss:  0.040106345  || Decoder Loss:  0.032326624 Validation Decoder Loss:  0.31776208
Encoder Loss:  0.040054087  || Decoder Loss:  0.032221355 Validation Decoder Loss:  0.31880343
Encoder Loss:  0.039999675  || Decoder Loss:  0.03213598 Validation Decoder Loss:  0.3191061
Encoder Loss:  0.03994549  || Decoder Loss:  0.032047708 Validation Decoder Loss:  0.3201701
Encoder Loss:  0.03990026  || Decoder Loss:  0.03196189 Validation Decoder Loss:  0.3206584
Encoder Loss:  0.0398701  || Decoder Loss:  0.03190405 Validation Decoder Loss:  0.32085085
Encoder Loss:  0.03984392  || Decoder Loss:  0.031864833 Validation Decoder Loss:  0.32109314
Encoder Loss:  0.03982999  || Decoder Loss:  0.031837706 Validation Decoder Loss:  0.32196572
Encoder Loss:  0.03981355  || Decoder Loss:  0.031813364 Validation Decoder Loss:  0.32336226
Encoder Loss:  0.039801262  || Decoder Loss:  0.03178602 Validation Decoder Loss:  0.3247653
Encoder Loss:  0.03978821  || Decoder Loss:  0.031761106 Validation Decoder Loss:  0.32498187
Encoder Loss:  0.03977661  || Decoder Loss:  0.03174653 Validation Decoder Loss:  0.32446796
Encoder Loss:  0.03977628  || Decoder Loss:  0.0317395 Validation Decoder Loss:  0.32361722
Encoder Loss:  0.03977258  || Decoder Loss:  0.031734906 Validation Decoder Loss:  0.3228687
Encoder Loss:  0.039770685  || Decoder Loss:  0.031731047 Validation Decoder Loss:  0.32217038
Encoder Loss:  0.039767645  || Decoder Loss:  0.031727698 Validation Decoder Loss:  0.32159677
Encoder Loss:  0.0397667  || Decoder Loss:  0.03172522 Validation Decoder Loss:  0.3209874
Encoder Loss:  0.03976515  || Decoder Loss:  0.03172197 Validation Decoder Loss:  0.32070345
Encoder Loss:  0.03976151  || Decoder Loss:  0.031716954 Validation Decoder Loss:  0.32063326
Encoder Loss:  0.03975944  || Decoder Loss:  0.03171155 Validation Decoder Loss:  0.320803
Encoder Loss:  0.03975637  || Decoder Loss:  0.0317063 Validation Decoder Loss:  0.32123458
Encoder Loss:  0.039751954  || Decoder Loss:  0.03170296 Validation Decoder Loss:  0.3217032
Encoder Loss:  0.0397504  || Decoder Loss:  0.0316999 Validation Decoder Loss:  0.32203573
Model: siamese_net_lr_0.03834313132219195 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32203573
Model: "sequential_670"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_371 (Conv3D (None, 386, 5, 20, 1)     261       
_________________________________________________________________
dropout_792 (Dropout)        (None, 386, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_372 (Conv3D (None, 634, 5, 20, 1)     250       
_________________________________________________________________
reshape_194 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 511
Trainable params: 511
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_672"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_282 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_794 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_283 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_673"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_282 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_796 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_283 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30314013  || Decoder Loss:  0.17683934 Validation Decoder Loss:  0.3383542
Encoder Loss:  0.23654598  || Decoder Loss:  0.37621006 Validation Decoder Loss:  0.47623926
Encoder Loss:  0.18067093  || Decoder Loss:  0.49171683 Validation Decoder Loss:  0.62812924
Encoder Loss:  0.17449275  || Decoder Loss:  0.50033456 Validation Decoder Loss:  0.5738205
Encoder Loss:  0.17380859  || Decoder Loss:  0.49670133 Validation Decoder Loss:  0.59576476
Encoder Loss:  0.17419787  || Decoder Loss:  0.5002021 Validation Decoder Loss:  0.6273412
Encoder Loss:  0.17895186  || Decoder Loss:  0.4979952 Validation Decoder Loss:  0.58841926
Encoder Loss:  0.17270969  || Decoder Loss:  0.50017244 Validation Decoder Loss:  0.5774001
Encoder Loss:  0.17158438  || Decoder Loss:  0.50070655 Validation Decoder Loss:  0.5827807
Encoder Loss:  0.17155786  || Decoder Loss:  0.50003654 Validation Decoder Loss:  0.6108006
Encoder Loss:  0.17367491  || Decoder Loss:  0.49923432 Validation Decoder Loss:  0.5352391
Encoder Loss:  0.17548941  || Decoder Loss:  0.49978355 Validation Decoder Loss:  0.58010423
Encoder Loss:  0.16885537  || Decoder Loss:  0.4988395 Validation Decoder Loss:  0.5791632
Encoder Loss:  0.17064875  || Decoder Loss:  0.5007016 Validation Decoder Loss:  0.6003766
Encoder Loss:  0.17202741  || Decoder Loss:  0.50094956 Validation Decoder Loss:  0.5752558
Encoder Loss:  0.17239754  || Decoder Loss:  0.50081986 Validation Decoder Loss:  0.6257631
Encoder Loss:  0.17303862  || Decoder Loss:  0.4993854 Validation Decoder Loss:  0.59730923
Encoder Loss:  0.17202103  || Decoder Loss:  0.50059074 Validation Decoder Loss:  0.6348874
Encoder Loss:  0.17224711  || Decoder Loss:  0.5001125 Validation Decoder Loss:  0.6106843
Encoder Loss:  0.17199634  || Decoder Loss:  0.5013031 Validation Decoder Loss:  0.6052395
Encoder Loss:  0.17031859  || Decoder Loss:  0.50187993 Validation Decoder Loss:  0.6584288
Encoder Loss:  0.16908026  || Decoder Loss:  0.50076985 Validation Decoder Loss:  0.6516185
Encoder Loss:  0.16763423  || Decoder Loss:  0.49936977 Validation Decoder Loss:  0.67763823
Encoder Loss:  0.16898204  || Decoder Loss:  0.5006525 Validation Decoder Loss:  0.6975541
Encoder Loss:  0.16802052  || Decoder Loss:  0.49996728 Validation Decoder Loss:  0.7145536
Encoder Loss:  0.16747269  || Decoder Loss:  0.5003881 Validation Decoder Loss:  0.756148
Encoder Loss:  0.1663006  || Decoder Loss:  0.500374 Validation Decoder Loss:  0.79690766
Encoder Loss:  0.16625929  || Decoder Loss:  0.5007029 Validation Decoder Loss:  0.8236091
Encoder Loss:  0.16643965  || Decoder Loss:  0.5010627 Validation Decoder Loss:  0.8352546
Encoder Loss:  0.16654938  || Decoder Loss:  0.5010158 Validation Decoder Loss:  0.84770834
Encoder Loss:  0.16622503  || Decoder Loss:  0.5007829 Validation Decoder Loss:  0.84884155
Encoder Loss:  0.1663391  || Decoder Loss:  0.500947 Validation Decoder Loss:  0.840513
Encoder Loss:  0.16629258  || Decoder Loss:  0.5010185 Validation Decoder Loss:  0.8392172
Encoder Loss:  0.16626735  || Decoder Loss:  0.50086135 Validation Decoder Loss:  0.844149
Encoder Loss:  0.16615196  || Decoder Loss:  0.5011848 Validation Decoder Loss:  0.83450305
Encoder Loss:  0.16641718  || Decoder Loss:  0.501086 Validation Decoder Loss:  0.833973
Encoder Loss:  0.16601297  || Decoder Loss:  0.500957 Validation Decoder Loss:  0.83157825
Encoder Loss:  0.16588792  || Decoder Loss:  0.5007216 Validation Decoder Loss:  0.8239241
Encoder Loss:  0.16601378  || Decoder Loss:  0.500558 Validation Decoder Loss:  0.840343
Encoder Loss:  0.16526312  || Decoder Loss:  0.49839887 Validation Decoder Loss:  1.193481
Model: siamese_net_lr_0.06589675581826468 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.193481
Model: "sequential_674"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_374 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_798 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_375 (Conv3D (None, 634, 5, 20, 1)     461       
_________________________________________________________________
reshape_195 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 487
Trainable params: 487
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_676"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_284 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_800 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_285 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_677"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_284 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_802 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_285 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1099222  || Decoder Loss:  0.2318419 Validation Decoder Loss:  1.2652929
Encoder Loss:  0.09655177  || Decoder Loss:  0.41063428 Validation Decoder Loss:  1.2211815
Encoder Loss:  0.07072078  || Decoder Loss:  0.21212406 Validation Decoder Loss:  0.48061383
Encoder Loss:  0.049736198  || Decoder Loss:  0.04472004 Validation Decoder Loss:  0.28764278
Encoder Loss:  0.048283834  || Decoder Loss:  0.03364325 Validation Decoder Loss:  0.35723907
Encoder Loss:  0.047993664  || Decoder Loss:  0.032649953 Validation Decoder Loss:  0.33697185
Encoder Loss:  0.047950562  || Decoder Loss:  0.03256228 Validation Decoder Loss:  0.33876106
Encoder Loss:  0.047923066  || Decoder Loss:  0.03253977 Validation Decoder Loss:  0.33976263
Encoder Loss:  0.04787978  || Decoder Loss:  0.03252174 Validation Decoder Loss:  0.33954638
Encoder Loss:  0.047861062  || Decoder Loss:  0.03250427 Validation Decoder Loss:  0.33935815
Encoder Loss:  0.04785694  || Decoder Loss:  0.032488048 Validation Decoder Loss:  0.33927587
Encoder Loss:  0.04785512  || Decoder Loss:  0.032472156 Validation Decoder Loss:  0.33923137
Encoder Loss:  0.047852997  || Decoder Loss:  0.03245637 Validation Decoder Loss:  0.33920157
Encoder Loss:  0.047850627  || Decoder Loss:  0.0324407 Validation Decoder Loss:  0.339167
Encoder Loss:  0.04784924  || Decoder Loss:  0.0324252 Validation Decoder Loss:  0.3391238
Encoder Loss:  0.047846932  || Decoder Loss:  0.032409914 Validation Decoder Loss:  0.33908775
Encoder Loss:  0.04784582  || Decoder Loss:  0.03239511 Validation Decoder Loss:  0.33910364
Encoder Loss:  0.04784439  || Decoder Loss:  0.03238057 Validation Decoder Loss:  0.33904204
Encoder Loss:  0.047842406  || Decoder Loss:  0.03236598 Validation Decoder Loss:  0.33901975
Encoder Loss:  0.047839213  || Decoder Loss:  0.032352086 Validation Decoder Loss:  0.3390237
Encoder Loss:  0.047839448  || Decoder Loss:  0.032338277 Validation Decoder Loss:  0.33893058
Encoder Loss:  0.04783715  || Decoder Loss:  0.032324597 Validation Decoder Loss:  0.33886522
Encoder Loss:  0.047837712  || Decoder Loss:  0.032311298 Validation Decoder Loss:  0.33871394
Encoder Loss:  0.04783683  || Decoder Loss:  0.032298237 Validation Decoder Loss:  0.33864212
Encoder Loss:  0.047834367  || Decoder Loss:  0.03228508 Validation Decoder Loss:  0.33852175
Encoder Loss:  0.04783149  || Decoder Loss:  0.03227262 Validation Decoder Loss:  0.33831674
Encoder Loss:  0.047830354  || Decoder Loss:  0.032260455 Validation Decoder Loss:  0.3383063
Encoder Loss:  0.047829233  || Decoder Loss:  0.032248337 Validation Decoder Loss:  0.33808115
Encoder Loss:  0.047825556  || Decoder Loss:  0.032236136 Validation Decoder Loss:  0.33801377
Encoder Loss:  0.04782777  || Decoder Loss:  0.032225277 Validation Decoder Loss:  0.33810127
Encoder Loss:  0.04782689  || Decoder Loss:  0.032213416 Validation Decoder Loss:  0.33773935
Encoder Loss:  0.047823686  || Decoder Loss:  0.0322025 Validation Decoder Loss:  0.3376219
Encoder Loss:  0.0478195  || Decoder Loss:  0.032191597 Validation Decoder Loss:  0.3373302
Encoder Loss:  0.047818147  || Decoder Loss:  0.032181684 Validation Decoder Loss:  0.3372633
Encoder Loss:  0.047815442  || Decoder Loss:  0.0321718 Validation Decoder Loss:  0.3369542
Encoder Loss:  0.047814563  || Decoder Loss:  0.032162376 Validation Decoder Loss:  0.3365541
Encoder Loss:  0.047816787  || Decoder Loss:  0.032153603 Validation Decoder Loss:  0.33626795
Encoder Loss:  0.04781384  || Decoder Loss:  0.03214451 Validation Decoder Loss:  0.33570644
Encoder Loss:  0.047825646  || Decoder Loss:  0.032136694 Validation Decoder Loss:  0.33514428
Encoder Loss:  0.04782288  || Decoder Loss:  0.03212893 Validation Decoder Loss:  0.3347537
Model: siamese_net_lr_0.022250231464937032 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3347537
Model: "sequential_678"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_377 (Conv3D (None, 84, 5, 20, 1)      22        
_________________________________________________________________
dropout_804 (Dropout)        (None, 84, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_378 (Conv3D (None, 634, 5, 20, 1)     469       
_________________________________________________________________
reshape_196 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 491
Trainable params: 491
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_680"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_286 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_806 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_287 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_681"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_286 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_808 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_287 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22050685  || Decoder Loss:  0.5082681 Validation Decoder Loss:  1.2373704
Encoder Loss:  0.16939636  || Decoder Loss:  0.4907905 Validation Decoder Loss:  1.3110728
Encoder Loss:  0.16593069  || Decoder Loss:  0.49364766 Validation Decoder Loss:  1.3417411
Encoder Loss:  0.16508742  || Decoder Loss:  0.49645492 Validation Decoder Loss:  1.3246717
Encoder Loss:  0.16547614  || Decoder Loss:  0.49470946 Validation Decoder Loss:  1.3266114
Encoder Loss:  0.16526298  || Decoder Loss:  0.49398056 Validation Decoder Loss:  1.2870111
Encoder Loss:  0.16433436  || Decoder Loss:  0.49014148 Validation Decoder Loss:  1.2142721
Encoder Loss:  0.16524401  || Decoder Loss:  0.49193764 Validation Decoder Loss:  1.1684899
Encoder Loss:  0.16392836  || Decoder Loss:  0.49120158 Validation Decoder Loss:  1.1668931
Encoder Loss:  0.16471381  || Decoder Loss:  0.4910582 Validation Decoder Loss:  1.2321213
Encoder Loss:  0.16722459  || Decoder Loss:  0.49362746 Validation Decoder Loss:  1.1883228
Encoder Loss:  0.16589211  || Decoder Loss:  0.49184054 Validation Decoder Loss:  1.1591454
Encoder Loss:  0.16366035  || Decoder Loss:  0.4909523 Validation Decoder Loss:  1.1116223
Encoder Loss:  0.16459295  || Decoder Loss:  0.49009678 Validation Decoder Loss:  1.1918826
Encoder Loss:  0.16425383  || Decoder Loss:  0.4909792 Validation Decoder Loss:  1.0696113
Encoder Loss:  0.16428605  || Decoder Loss:  0.4894691 Validation Decoder Loss:  1.0474608
Encoder Loss:  0.16300787  || Decoder Loss:  0.48794028 Validation Decoder Loss:  1.1847339
Encoder Loss:  0.16218123  || Decoder Loss:  0.4808978 Validation Decoder Loss:  1.3109808
Encoder Loss:  0.16137701  || Decoder Loss:  0.47577766 Validation Decoder Loss:  0.66521955
Encoder Loss:  0.16018873  || Decoder Loss:  0.47296983 Validation Decoder Loss:  0.6905444
Encoder Loss:  0.16404167  || Decoder Loss:  0.48796937 Validation Decoder Loss:  0.6194543
Encoder Loss:  0.16330034  || Decoder Loss:  0.48446965 Validation Decoder Loss:  1.3180106
Encoder Loss:  0.1654537  || Decoder Loss:  0.4975228 Validation Decoder Loss:  1.3014834
Encoder Loss:  0.16594237  || Decoder Loss:  0.4972612 Validation Decoder Loss:  1.3177713
Encoder Loss:  0.16771775  || Decoder Loss:  0.4957552 Validation Decoder Loss:  1.3382292
Encoder Loss:  0.16703019  || Decoder Loss:  0.4988221 Validation Decoder Loss:  1.2810371
Encoder Loss:  0.16484772  || Decoder Loss:  0.4934878 Validation Decoder Loss:  1.1673154
Encoder Loss:  0.16497587  || Decoder Loss:  0.49182594 Validation Decoder Loss:  1.0842525
Encoder Loss:  0.16452461  || Decoder Loss:  0.49050277 Validation Decoder Loss:  1.1998572
Encoder Loss:  0.16456951  || Decoder Loss:  0.49099347 Validation Decoder Loss:  1.1071113
Encoder Loss:  0.16450283  || Decoder Loss:  0.49143925 Validation Decoder Loss:  1.2251885
Encoder Loss:  0.16621412  || Decoder Loss:  0.4927359 Validation Decoder Loss:  0.84224033
Encoder Loss:  0.1643942  || Decoder Loss:  0.49126747 Validation Decoder Loss:  1.0884848
Encoder Loss:  0.1629794  || Decoder Loss:  0.4887327 Validation Decoder Loss:  1.2501017
Encoder Loss:  0.16449994  || Decoder Loss:  0.491051 Validation Decoder Loss:  1.2196555
Encoder Loss:  0.16528131  || Decoder Loss:  0.49183396 Validation Decoder Loss:  1.2834494
Encoder Loss:  0.16530253  || Decoder Loss:  0.4866886 Validation Decoder Loss:  1.3178065
Encoder Loss:  0.16329159  || Decoder Loss:  0.4896477 Validation Decoder Loss:  1.1765463
Encoder Loss:  0.16308862  || Decoder Loss:  0.4880059 Validation Decoder Loss:  1.2712498
Encoder Loss:  0.16298464  || Decoder Loss:  0.48738584 Validation Decoder Loss:  1.2663016
Model: siamese_net_lr_0.1 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.2663016
Model: "sequential_682"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_380 (Conv3D (None, 76, 5, 20, 1)      14        
_________________________________________________________________
dropout_810 (Dropout)        (None, 76, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_381 (Conv3D (None, 634, 5, 20, 1)     335       
_________________________________________________________________
reshape_197 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_684"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_288 (Conv2D)          (None, 3180, 20, 1)       67        
_________________________________________________________________
dropout_812 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_289 (Conv2D)          (None, 3170, 20, 1)       12        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_685"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_288 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_814 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_289 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0913764  || Decoder Loss:  0.09206822 Validation Decoder Loss:  0.4218053
Encoder Loss:  0.046074275  || Decoder Loss:  0.042627927 Validation Decoder Loss:  0.34997478
Encoder Loss:  0.037395082  || Decoder Loss:  0.03383143 Validation Decoder Loss:  0.3478546
Encoder Loss:  0.037227966  || Decoder Loss:  0.032627385 Validation Decoder Loss:  0.34391308
Encoder Loss:  0.03596826  || Decoder Loss:  0.032682687 Validation Decoder Loss:  0.34315664
Encoder Loss:  0.035491284  || Decoder Loss:  0.032541875 Validation Decoder Loss:  0.34331495
Encoder Loss:  0.035416257  || Decoder Loss:  0.032469362 Validation Decoder Loss:  0.34321576
Encoder Loss:  0.035439666  || Decoder Loss:  0.032458752 Validation Decoder Loss:  0.3429138
Encoder Loss:  0.035402372  || Decoder Loss:  0.032467615 Validation Decoder Loss:  0.34287605
Encoder Loss:  0.03521227  || Decoder Loss:  0.03242837 Validation Decoder Loss:  0.3425675
Encoder Loss:  0.035686165  || Decoder Loss:  0.032469768 Validation Decoder Loss:  0.3431894
Encoder Loss:  0.03548862  || Decoder Loss:  0.032485493 Validation Decoder Loss:  0.34262893
Encoder Loss:  0.035444118  || Decoder Loss:  0.03241061 Validation Decoder Loss:  0.34288752
Encoder Loss:  0.03542551  || Decoder Loss:  0.03248193 Validation Decoder Loss:  0.34324676
Encoder Loss:  0.035358477  || Decoder Loss:  0.03250662 Validation Decoder Loss:  0.34412974
Encoder Loss:  0.036210354  || Decoder Loss:  0.032994702 Validation Decoder Loss:  0.3428426
Encoder Loss:  0.036942273  || Decoder Loss:  0.034500606 Validation Decoder Loss:  0.34218594
Encoder Loss:  0.03627579  || Decoder Loss:  0.033530187 Validation Decoder Loss:  0.35785082
Encoder Loss:  0.037912592  || Decoder Loss:  0.035071615 Validation Decoder Loss:  0.34174663
Encoder Loss:  0.036440507  || Decoder Loss:  0.033621103 Validation Decoder Loss:  0.34201458
Encoder Loss:  0.035030495  || Decoder Loss:  0.03241481 Validation Decoder Loss:  0.34245196
Encoder Loss:  0.034909256  || Decoder Loss:  0.03236002 Validation Decoder Loss:  0.34297866
Encoder Loss:  0.03528039  || Decoder Loss:  0.03287103 Validation Decoder Loss:  0.34674782
Encoder Loss:  0.035023354  || Decoder Loss:  0.032590248 Validation Decoder Loss:  0.34300518
Encoder Loss:  0.034994975  || Decoder Loss:  0.03256251 Validation Decoder Loss:  0.345433
Encoder Loss:  0.03515179  || Decoder Loss:  0.032745533 Validation Decoder Loss:  0.34489506
Encoder Loss:  0.034931064  || Decoder Loss:  0.032488294 Validation Decoder Loss:  0.34465522
Encoder Loss:  0.035186972  || Decoder Loss:  0.032789063 Validation Decoder Loss:  0.34520018
Encoder Loss:  0.03529706  || Decoder Loss:  0.032911 Validation Decoder Loss:  0.3463458
Encoder Loss:  0.035002306  || Decoder Loss:  0.032537404 Validation Decoder Loss:  0.3443997
Encoder Loss:  0.035021644  || Decoder Loss:  0.03256108 Validation Decoder Loss:  0.3426665
Encoder Loss:  0.035350166  || Decoder Loss:  0.03296928 Validation Decoder Loss:  0.34625167
Encoder Loss:  0.034875207  || Decoder Loss:  0.032426428 Validation Decoder Loss:  0.34429342
Encoder Loss:  0.03490101  || Decoder Loss:  0.03245738 Validation Decoder Loss:  0.3450812
Encoder Loss:  0.03499184  || Decoder Loss:  0.032564174 Validation Decoder Loss:  0.3457461
Encoder Loss:  0.034895517  || Decoder Loss:  0.032453384 Validation Decoder Loss:  0.34492326
Encoder Loss:  0.034955204  || Decoder Loss:  0.03252258 Validation Decoder Loss:  0.34588364
Encoder Loss:  0.03490611  || Decoder Loss:  0.032466315 Validation Decoder Loss:  0.34493375
Encoder Loss:  0.034846403  || Decoder Loss:  0.032395534 Validation Decoder Loss:  0.34544742
Encoder Loss:  0.03491581  || Decoder Loss:  0.03247166 Validation Decoder Loss:  0.3453682
Model: siamese_net_lr_0.053704063759451144 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3453682
Model: "sequential_686"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_383 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
dropout_816 (Dropout)        (None, 94, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_384 (Conv3D (None, 634, 5, 20, 1)     170       
_________________________________________________________________
reshape_198 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 202
Trainable params: 202
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_688"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_290 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_818 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_291 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_689"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_290 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_820 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_291 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11718512  || Decoder Loss:  0.064027555 Validation Decoder Loss:  0.34204674
Encoder Loss:  0.056400757  || Decoder Loss:  0.04308621 Validation Decoder Loss:  0.36094117
Encoder Loss:  0.051547647  || Decoder Loss:  0.033584632 Validation Decoder Loss:  0.34458783
Encoder Loss:  0.05294905  || Decoder Loss:  0.03245306 Validation Decoder Loss:  0.34619647
Encoder Loss:  0.05519389  || Decoder Loss:  0.032310784 Validation Decoder Loss:  0.34606805
Encoder Loss:  0.052514303  || Decoder Loss:  0.0321811 Validation Decoder Loss:  0.34511787
Encoder Loss:  0.05196248  || Decoder Loss:  0.0321582 Validation Decoder Loss:  0.34990835
Encoder Loss:  0.0585224  || Decoder Loss:  0.03245987 Validation Decoder Loss:  0.34923255
Encoder Loss:  0.058111254  || Decoder Loss:  0.032435346 Validation Decoder Loss:  0.34661785
Encoder Loss:  0.057176992  || Decoder Loss:  0.032377914 Validation Decoder Loss:  0.34594163
Encoder Loss:  0.05656769  || Decoder Loss:  0.03242436 Validation Decoder Loss:  0.34534243
Encoder Loss:  0.056088462  || Decoder Loss:  0.032484397 Validation Decoder Loss:  0.34477702
Encoder Loss:  0.05569221  || Decoder Loss:  0.032532863 Validation Decoder Loss:  0.3444566
Encoder Loss:  0.05535342  || Decoder Loss:  0.032545224 Validation Decoder Loss:  0.3448943
Encoder Loss:  0.055056527  || Decoder Loss:  0.03251311 Validation Decoder Loss:  0.34595326
Encoder Loss:  0.054793004  || Decoder Loss:  0.032452248 Validation Decoder Loss:  0.3468735
Encoder Loss:  0.05456228  || Decoder Loss:  0.032430448 Validation Decoder Loss:  0.34804726
Encoder Loss:  0.054358333  || Decoder Loss:  0.032439753 Validation Decoder Loss:  0.3487402
Encoder Loss:  0.054176517  || Decoder Loss:  0.032473527 Validation Decoder Loss:  0.35049075
Encoder Loss:  0.054011174  || Decoder Loss:  0.03250487 Validation Decoder Loss:  0.3506478
Encoder Loss:  0.053861953  || Decoder Loss:  0.032555234 Validation Decoder Loss:  0.3514632
Encoder Loss:  0.053727373  || Decoder Loss:  0.032629624 Validation Decoder Loss:  0.35071206
Encoder Loss:  0.051214647  || Decoder Loss:  0.03239957 Validation Decoder Loss:  0.34828043
Encoder Loss:  0.051000543  || Decoder Loss:  0.03216405 Validation Decoder Loss:  0.34762087
Encoder Loss:  0.05104661  || Decoder Loss:  0.032167725 Validation Decoder Loss:  0.3473271
Encoder Loss:  0.05040481  || Decoder Loss:  0.03207309 Validation Decoder Loss:  0.3501334
Encoder Loss:  0.054194532  || Decoder Loss:  0.032849547 Validation Decoder Loss:  0.3652467
Encoder Loss:  0.080002695  || Decoder Loss:  0.29791766 Validation Decoder Loss:  0.9956095
Encoder Loss:  0.094669044  || Decoder Loss:  0.49686265 Validation Decoder Loss:  0.99534935
Encoder Loss:  0.09532859  || Decoder Loss:  0.49674687 Validation Decoder Loss:  0.9976762
Encoder Loss:  0.09573949  || Decoder Loss:  0.49686173 Validation Decoder Loss:  0.99514145
Encoder Loss:  0.095290616  || Decoder Loss:  0.49664593 Validation Decoder Loss:  0.99784255
Encoder Loss:  0.09570734  || Decoder Loss:  0.49675316 Validation Decoder Loss:  0.99479413
Encoder Loss:  0.09525826  || Decoder Loss:  0.49649853 Validation Decoder Loss:  0.99804187
Encoder Loss:  0.09566894  || Decoder Loss:  0.4966304 Validation Decoder Loss:  0.99442667
Encoder Loss:  0.09522353  || Decoder Loss:  0.49633163 Validation Decoder Loss:  0.998301
Encoder Loss:  0.09562703  || Decoder Loss:  0.49648884 Validation Decoder Loss:  0.9940249
Encoder Loss:  0.09518572  || Decoder Loss:  0.49613434 Validation Decoder Loss:  0.9986465
Encoder Loss:  0.09558098  || Decoder Loss:  0.4963172 Validation Decoder Loss:  0.9935641
Encoder Loss:  0.09514329  || Decoder Loss:  0.49588776 Validation Decoder Loss:  0.9991275
Model: siamese_net_lr_0.031132917378936004 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9991275
Model: "sequential_690"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_386 (Conv3D (None, 398, 5, 20, 1)     147       
_________________________________________________________________
dropout_822 (Dropout)        (None, 398, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_387 (Conv3D (None, 634, 5, 20, 1)     238       
_________________________________________________________________
reshape_199 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_692"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_292 (Conv2D)          (None, 3180, 20, 1)       67        
_________________________________________________________________
dropout_824 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_293 (Conv2D)          (None, 3170, 20, 1)       12        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_693"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_292 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_826 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_293 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25215968  || Decoder Loss:  0.15008925 Validation Decoder Loss:  0.42633635
Encoder Loss:  0.313921  || Decoder Loss:  0.4035856 Validation Decoder Loss:  0.74286973
Encoder Loss:  0.28486913  || Decoder Loss:  0.47573417 Validation Decoder Loss:  1.0995989
Encoder Loss:  0.27697265  || Decoder Loss:  0.49710426 Validation Decoder Loss:  1.2249365
Encoder Loss:  0.28452992  || Decoder Loss:  0.49425817 Validation Decoder Loss:  1.1183791
Encoder Loss:  0.2793314  || Decoder Loss:  0.50028384 Validation Decoder Loss:  1.1524674
Encoder Loss:  0.27703416  || Decoder Loss:  0.4984749 Validation Decoder Loss:  1.1743747
Encoder Loss:  0.27514696  || Decoder Loss:  0.49667466 Validation Decoder Loss:  0.8044144
Encoder Loss:  0.27423632  || Decoder Loss:  0.49648815 Validation Decoder Loss:  0.69668925
Encoder Loss:  0.2817251  || Decoder Loss:  0.49758404 Validation Decoder Loss:  0.8176618
Encoder Loss:  0.2758346  || Decoder Loss:  0.50039065 Validation Decoder Loss:  0.76147914
Encoder Loss:  0.27411774  || Decoder Loss:  0.49721012 Validation Decoder Loss:  1.1831934
Encoder Loss:  0.2708057  || Decoder Loss:  0.49339163 Validation Decoder Loss:  1.2342594
Encoder Loss:  0.27174374  || Decoder Loss:  0.49774963 Validation Decoder Loss:  1.2260185
Encoder Loss:  0.27202266  || Decoder Loss:  0.4982599 Validation Decoder Loss:  1.2258855
Encoder Loss:  0.27167985  || Decoder Loss:  0.49885282 Validation Decoder Loss:  1.2188828
Encoder Loss:  0.27190715  || Decoder Loss:  0.49800304 Validation Decoder Loss:  1.2428484
Encoder Loss:  0.27163357  || Decoder Loss:  0.498255 Validation Decoder Loss:  1.2361184
Encoder Loss:  0.2708604  || Decoder Loss:  0.49793637 Validation Decoder Loss:  1.2429886
Encoder Loss:  0.27154517  || Decoder Loss:  0.49863857 Validation Decoder Loss:  1.237731
Encoder Loss:  0.2716223  || Decoder Loss:  0.4989966 Validation Decoder Loss:  1.2367159
Encoder Loss:  0.27149597  || Decoder Loss:  0.49848583 Validation Decoder Loss:  1.2383149
Encoder Loss:  0.27095297  || Decoder Loss:  0.49924567 Validation Decoder Loss:  1.2438473
Encoder Loss:  0.27077964  || Decoder Loss:  0.49831936 Validation Decoder Loss:  1.242708
Encoder Loss:  0.27290183  || Decoder Loss:  0.50385815 Validation Decoder Loss:  1.2255992
Encoder Loss:  0.26928285  || Decoder Loss:  0.4967187 Validation Decoder Loss:  1.2141172
Encoder Loss:  0.26634395  || Decoder Loss:  0.49085438 Validation Decoder Loss:  0.9570193
Encoder Loss:  0.26196408  || Decoder Loss:  0.482118 Validation Decoder Loss:  1.016464
Encoder Loss:  0.26025012  || Decoder Loss:  0.4786474 Validation Decoder Loss:  1.0242782
Encoder Loss:  0.25938702  || Decoder Loss:  0.47685128 Validation Decoder Loss:  1.1891625
Encoder Loss:  0.2657213  || Decoder Loss:  0.4898951 Validation Decoder Loss:  1.1270142
Encoder Loss:  0.26173162  || Decoder Loss:  0.48179343 Validation Decoder Loss:  1.1398638
Encoder Loss:  0.2639467  || Decoder Loss:  0.48632637 Validation Decoder Loss:  1.0970957
Encoder Loss:  0.2582534  || Decoder Loss:  0.47471333 Validation Decoder Loss:  1.0551729
Encoder Loss:  0.25896388  || Decoder Loss:  0.4761937 Validation Decoder Loss:  0.8133929
Encoder Loss:  0.26501626  || Decoder Loss:  0.4885326 Validation Decoder Loss:  1.2022564
Encoder Loss:  0.26601556  || Decoder Loss:  0.49057153 Validation Decoder Loss:  1.0694011
Encoder Loss:  0.2652735  || Decoder Loss:  0.48910725 Validation Decoder Loss:  0.9782816
Encoder Loss:  0.26411557  || Decoder Loss:  0.48675156 Validation Decoder Loss:  1.0523485
Encoder Loss:  0.2596916  || Decoder Loss:  0.47771668 Validation Decoder Loss:  0.9958855
Model: siamese_net_lr_0.08563503007737172 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9958855
Model: "sequential_694"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_389 (Conv3D (None, 148, 5, 20, 1)     23        
_________________________________________________________________
dropout_828 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_390 (Conv3D (None, 634, 5, 20, 1)     47        
_________________________________________________________________
reshape_200 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_696"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_294 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_830 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_295 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_697"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_294 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_832 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_295 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1777186  || Decoder Loss:  0.21607447 Validation Decoder Loss:  1.296723
Encoder Loss:  0.1668853  || Decoder Loss:  0.21301608 Validation Decoder Loss:  0.39748436
Encoder Loss:  0.048729125  || Decoder Loss:  0.047755376 Validation Decoder Loss:  0.34452027
Encoder Loss:  0.038122486  || Decoder Loss:  0.03319958 Validation Decoder Loss:  0.34502614
Encoder Loss:  0.03745791  || Decoder Loss:  0.032293305 Validation Decoder Loss:  0.34447706
Encoder Loss:  0.03739209  || Decoder Loss:  0.032203563 Validation Decoder Loss:  0.34455848
Encoder Loss:  0.037383456  || Decoder Loss:  0.032185 Validation Decoder Loss:  0.3446656
Encoder Loss:  0.03736633  || Decoder Loss:  0.032168537 Validation Decoder Loss:  0.34469455
Encoder Loss:  0.03735363  || Decoder Loss:  0.032151654 Validation Decoder Loss:  0.34472263
Encoder Loss:  0.037341166  || Decoder Loss:  0.032135338 Validation Decoder Loss:  0.3447482
Encoder Loss:  0.037332464  || Decoder Loss:  0.032130834 Validation Decoder Loss:  0.34477141
Encoder Loss:  0.03732978  || Decoder Loss:  0.03211427 Validation Decoder Loss:  0.34480655
Encoder Loss:  0.037317708  || Decoder Loss:  0.03210953 Validation Decoder Loss:  0.34482834
Encoder Loss:  0.037304208  || Decoder Loss:  0.032097142 Validation Decoder Loss:  0.34486026
Encoder Loss:  0.037313476  || Decoder Loss:  0.032088872 Validation Decoder Loss:  0.34487817
Encoder Loss:  0.037282825  || Decoder Loss:  0.032064486 Validation Decoder Loss:  0.3449182
Encoder Loss:  0.03728509  || Decoder Loss:  0.032076288 Validation Decoder Loss:  0.34492612
Encoder Loss:  0.0373041  || Decoder Loss:  0.032072276 Validation Decoder Loss:  0.34494025
Encoder Loss:  0.037286926  || Decoder Loss:  0.0320717 Validation Decoder Loss:  0.34496033
Encoder Loss:  0.037297625  || Decoder Loss:  0.032065872 Validation Decoder Loss:  0.34497803
Encoder Loss:  0.037275482  || Decoder Loss:  0.032060303 Validation Decoder Loss:  0.34499985
Encoder Loss:  0.03732314  || Decoder Loss:  0.032052502 Validation Decoder Loss:  0.34501836
Encoder Loss:  0.037336636  || Decoder Loss:  0.032076467 Validation Decoder Loss:  0.34500426
Encoder Loss:  0.037304252  || Decoder Loss:  0.032063123 Validation Decoder Loss:  0.34499186
Encoder Loss:  0.037279796  || Decoder Loss:  0.03204598 Validation Decoder Loss:  0.34506282
Encoder Loss:  0.037260342  || Decoder Loss:  0.032042433 Validation Decoder Loss:  0.34504023
Encoder Loss:  0.03727382  || Decoder Loss:  0.032042712 Validation Decoder Loss:  0.3450667
Encoder Loss:  0.037266225  || Decoder Loss:  0.03203988 Validation Decoder Loss:  0.34506637
Encoder Loss:  0.03726582  || Decoder Loss:  0.03203723 Validation Decoder Loss:  0.3450768
Encoder Loss:  0.037252173  || Decoder Loss:  0.03203987 Validation Decoder Loss:  0.34508407
Encoder Loss:  0.03724148  || Decoder Loss:  0.0320296 Validation Decoder Loss:  0.34509617
Encoder Loss:  0.03724021  || Decoder Loss:  0.032027185 Validation Decoder Loss:  0.34510353
Encoder Loss:  0.037251927  || Decoder Loss:  0.032024927 Validation Decoder Loss:  0.34511244
Encoder Loss:  0.037253164  || Decoder Loss:  0.032022763 Validation Decoder Loss:  0.34511507
Encoder Loss:  0.037245944  || Decoder Loss:  0.03202103 Validation Decoder Loss:  0.3451279
Encoder Loss:  0.03724355  || Decoder Loss:  0.03201683 Validation Decoder Loss:  0.34513265
Encoder Loss:  0.037242845  || Decoder Loss:  0.032010056 Validation Decoder Loss:  0.3451373
Encoder Loss:  0.037240997  || Decoder Loss:  0.032014437 Validation Decoder Loss:  0.34515053
Encoder Loss:  0.037246417  || Decoder Loss:  0.032007385 Validation Decoder Loss:  0.34514567
Encoder Loss:  0.03724366  || Decoder Loss:  0.032020036 Validation Decoder Loss:  0.34515554
Model: siamese_net_lr_0.018661891189316115 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34515554
Model: "sequential_698"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_392 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_834 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_393 (Conv3D (None, 634, 5, 20, 1)     380       
_________________________________________________________________
reshape_201 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 404
Trainable params: 404
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_700"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_296 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_836 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_297 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_701"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_296 (Conv2D (None, 3170, 20, 1)       2         
_________________________________________________________________
dropout_838 (Dropout)        (None, 3170, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_297 (Conv2D (None, 3245, 20, 1)       77        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08004353  || Decoder Loss:  0.07215544 Validation Decoder Loss:  0.3114376
Encoder Loss:  0.04077641  || Decoder Loss:  0.038683888 Validation Decoder Loss:  0.34135425
Encoder Loss:  0.03443229  || Decoder Loss:  0.03290772 Validation Decoder Loss:  0.33827698
Encoder Loss:  0.034055904  || Decoder Loss:  0.03240869 Validation Decoder Loss:  0.34472975
Encoder Loss:  0.03392834  || Decoder Loss:  0.032323707 Validation Decoder Loss:  0.34441867
Encoder Loss:  0.033947866  || Decoder Loss:  0.032283556 Validation Decoder Loss:  0.3437935
Encoder Loss:  0.033988554  || Decoder Loss:  0.032245126 Validation Decoder Loss:  0.3430762
Encoder Loss:  0.033913147  || Decoder Loss:  0.032206707 Validation Decoder Loss:  0.3431623
Encoder Loss:  0.03396839  || Decoder Loss:  0.032168906 Validation Decoder Loss:  0.34388244
Encoder Loss:  0.0337854  || Decoder Loss:  0.032126296 Validation Decoder Loss:  0.34425962
Encoder Loss:  0.033761375  || Decoder Loss:  0.032081246 Validation Decoder Loss:  0.3433496
Encoder Loss:  0.033717755  || Decoder Loss:  0.0320387 Validation Decoder Loss:  0.34322342
Encoder Loss:  0.033684134  || Decoder Loss:  0.031995576 Validation Decoder Loss:  0.34471184
Encoder Loss:  0.03361143  || Decoder Loss:  0.03195177 Validation Decoder Loss:  0.34500003
Encoder Loss:  0.03352411  || Decoder Loss:  0.03191546 Validation Decoder Loss:  0.34444714
Encoder Loss:  0.033560134  || Decoder Loss:  0.031881217 Validation Decoder Loss:  0.34415737
Encoder Loss:  0.033551574  || Decoder Loss:  0.031851858 Validation Decoder Loss:  0.34349316
Encoder Loss:  0.033499323  || Decoder Loss:  0.031834636 Validation Decoder Loss:  0.34347937
Encoder Loss:  0.033485446  || Decoder Loss:  0.031812817 Validation Decoder Loss:  0.34320194
Encoder Loss:  0.03344922  || Decoder Loss:  0.031790674 Validation Decoder Loss:  0.34383678
Encoder Loss:  0.033435844  || Decoder Loss:  0.031775855 Validation Decoder Loss:  0.34380946
Encoder Loss:  0.033355527  || Decoder Loss:  0.031759888 Validation Decoder Loss:  0.34454563
Encoder Loss:  0.033576798  || Decoder Loss:  0.03172258 Validation Decoder Loss:  0.34437478
Encoder Loss:  0.033404537  || Decoder Loss:  0.031694196 Validation Decoder Loss:  0.34388942
Encoder Loss:  0.033414163  || Decoder Loss:  0.031677052 Validation Decoder Loss:  0.34414184
Encoder Loss:  0.033211756  || Decoder Loss:  0.031661224 Validation Decoder Loss:  0.34405306
Encoder Loss:  0.033287216  || Decoder Loss:  0.031646587 Validation Decoder Loss:  0.34378082
Encoder Loss:  0.033200506  || Decoder Loss:  0.031634714 Validation Decoder Loss:  0.3438437
Encoder Loss:  0.033259317  || Decoder Loss:  0.031623594 Validation Decoder Loss:  0.34378695
Encoder Loss:  0.033319533  || Decoder Loss:  0.031612612 Validation Decoder Loss:  0.34363776
Encoder Loss:  0.03325238  || Decoder Loss:  0.031603795 Validation Decoder Loss:  0.34357312
Encoder Loss:  0.033227917  || Decoder Loss:  0.031595018 Validation Decoder Loss:  0.34357473
Encoder Loss:  0.033218943  || Decoder Loss:  0.0315873 Validation Decoder Loss:  0.34367114
Encoder Loss:  0.03326366  || Decoder Loss:  0.031578567 Validation Decoder Loss:  0.34357506
Encoder Loss:  0.03319762  || Decoder Loss:  0.03157581 Validation Decoder Loss:  0.34355903
Encoder Loss:  0.033116218  || Decoder Loss:  0.031570364 Validation Decoder Loss:  0.3434686
Encoder Loss:  0.03322595  || Decoder Loss:  0.031565536 Validation Decoder Loss:  0.34350574
Encoder Loss:  0.03315449  || Decoder Loss:  0.031560227 Validation Decoder Loss:  0.34354347
Encoder Loss:  0.03321157  || Decoder Loss:  0.031560704 Validation Decoder Loss:  0.34351653
Encoder Loss:  0.0331329  || Decoder Loss:  0.03155268 Validation Decoder Loss:  0.34345147
Model: siamese_net_lr_0.0649408394805391 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34345147
Model: "sequential_702"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_395 (Conv3D (None, 76, 5, 20, 1)      14        
_________________________________________________________________
dropout_840 (Dropout)        (None, 76, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_396 (Conv3D (None, 634, 5, 20, 1)     335       
_________________________________________________________________
reshape_202 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_704"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 3180, 20, 1)       67        
_________________________________________________________________
dropout_842 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 3170, 20, 1)       12        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_705"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_298 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_844 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_299 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.051476423  || Decoder Loss:  0.051476423 Validation Decoder Loss:  0.34478065
Encoder Loss:  0.032724693  || Decoder Loss:  0.032724693 Validation Decoder Loss:  0.34445938
Encoder Loss:  0.03263335  || Decoder Loss:  0.03263335 Validation Decoder Loss:  0.34439993
Encoder Loss:  0.032562874  || Decoder Loss:  0.032562874 Validation Decoder Loss:  0.34440637
Encoder Loss:  0.0325004  || Decoder Loss:  0.0325004 Validation Decoder Loss:  0.34447524
Encoder Loss:  0.03244205  || Decoder Loss:  0.03244205 Validation Decoder Loss:  0.34467396
Encoder Loss:  0.032403763  || Decoder Loss:  0.032403763 Validation Decoder Loss:  0.34475482
Encoder Loss:  0.03238417  || Decoder Loss:  0.03238417 Validation Decoder Loss:  0.34471995
Encoder Loss:  0.03237073  || Decoder Loss:  0.03237073 Validation Decoder Loss:  0.34471363
Encoder Loss:  0.032359593  || Decoder Loss:  0.032359593 Validation Decoder Loss:  0.34471262
Encoder Loss:  0.0323503  || Decoder Loss:  0.0323503 Validation Decoder Loss:  0.3447165
Encoder Loss:  0.032342494  || Decoder Loss:  0.032342494 Validation Decoder Loss:  0.3447219
Encoder Loss:  0.03233586  || Decoder Loss:  0.03233586 Validation Decoder Loss:  0.34472764
Encoder Loss:  0.03233019  || Decoder Loss:  0.03233019 Validation Decoder Loss:  0.34473324
Encoder Loss:  0.032325283  || Decoder Loss:  0.032325283 Validation Decoder Loss:  0.34473884
Encoder Loss:  0.032320984  || Decoder Loss:  0.032320984 Validation Decoder Loss:  0.3447445
Encoder Loss:  0.032317165  || Decoder Loss:  0.032317165 Validation Decoder Loss:  0.34475052
Encoder Loss:  0.03231372  || Decoder Loss:  0.03231372 Validation Decoder Loss:  0.3447569
Encoder Loss:  0.032310575  || Decoder Loss:  0.032310575 Validation Decoder Loss:  0.34476364
Encoder Loss:  0.032307696  || Decoder Loss:  0.032307696 Validation Decoder Loss:  0.34477055
Encoder Loss:  0.032305032  || Decoder Loss:  0.032305032 Validation Decoder Loss:  0.34477752
Encoder Loss:  0.03230255  || Decoder Loss:  0.03230255 Validation Decoder Loss:  0.3447844
Encoder Loss:  0.03230025  || Decoder Loss:  0.03230025 Validation Decoder Loss:  0.34479117
Encoder Loss:  0.032298107  || Decoder Loss:  0.032298107 Validation Decoder Loss:  0.34479767
Encoder Loss:  0.032296102  || Decoder Loss:  0.032296102 Validation Decoder Loss:  0.34480387
Encoder Loss:  0.032294232  || Decoder Loss:  0.032294232 Validation Decoder Loss:  0.3448097
Encoder Loss:  0.03229249  || Decoder Loss:  0.03229249 Validation Decoder Loss:  0.34481516
Encoder Loss:  0.032290854  || Decoder Loss:  0.032290854 Validation Decoder Loss:  0.3448202
Encoder Loss:  0.03228934  || Decoder Loss:  0.03228934 Validation Decoder Loss:  0.3448248
Encoder Loss:  0.032287925  || Decoder Loss:  0.032287925 Validation Decoder Loss:  0.34482884
Encoder Loss:  0.032286614  || Decoder Loss:  0.032286614 Validation Decoder Loss:  0.34483245
Encoder Loss:  0.032285403  || Decoder Loss:  0.032285403 Validation Decoder Loss:  0.34483567
Encoder Loss:  0.032284282  || Decoder Loss:  0.032284282 Validation Decoder Loss:  0.34483844
Encoder Loss:  0.032283235  || Decoder Loss:  0.032283235 Validation Decoder Loss:  0.34484082
Encoder Loss:  0.032282278  || Decoder Loss:  0.032282278 Validation Decoder Loss:  0.34484285
Encoder Loss:  0.03228139  || Decoder Loss:  0.03228139 Validation Decoder Loss:  0.34484458
Encoder Loss:  0.03228058  || Decoder Loss:  0.03228058 Validation Decoder Loss:  0.344846
Encoder Loss:  0.032279827  || Decoder Loss:  0.032279827 Validation Decoder Loss:  0.3448472
Encoder Loss:  0.03227913  || Decoder Loss:  0.03227913 Validation Decoder Loss:  0.34484822
Encoder Loss:  0.032278493  || Decoder Loss:  0.032278493 Validation Decoder Loss:  0.34484908
Model: siamese_net_lr_0.06240761464006534 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34484908
Model: "sequential_706"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_398 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_846 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_399 (Conv3D (None, 634, 5, 20, 1)     295       
_________________________________________________________________
reshape_203 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 319
Trainable params: 319
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_708"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_300 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_848 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_709"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_300 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_850 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_301 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08323083  || Decoder Loss:  0.052553196 Validation Decoder Loss:  0.34459218
Encoder Loss:  0.04566021  || Decoder Loss:  0.033078313 Validation Decoder Loss:  0.3402757
Encoder Loss:  0.0426414  || Decoder Loss:  0.032480698 Validation Decoder Loss:  0.34263933
Encoder Loss:  0.041448962  || Decoder Loss:  0.032220677 Validation Decoder Loss:  0.3421316
Encoder Loss:  0.041301347  || Decoder Loss:  0.032231916 Validation Decoder Loss:  0.3424859
Encoder Loss:  0.041212797  || Decoder Loss:  0.032214478 Validation Decoder Loss:  0.3403204
Encoder Loss:  0.04083109  || Decoder Loss:  0.032983825 Validation Decoder Loss:  0.3420362
Encoder Loss:  0.03972585  || Decoder Loss:  0.032037273 Validation Decoder Loss:  0.3428387
Encoder Loss:  0.039404914  || Decoder Loss:  0.03193288 Validation Decoder Loss:  0.34243125
Encoder Loss:  0.039288  || Decoder Loss:  0.031964492 Validation Decoder Loss:  0.34211695
Encoder Loss:  0.0393665  || Decoder Loss:  0.03213774 Validation Decoder Loss:  0.343505
Encoder Loss:  0.039315637  || Decoder Loss:  0.032056343 Validation Decoder Loss:  0.34188625
Encoder Loss:  0.039233655  || Decoder Loss:  0.03191961 Validation Decoder Loss:  0.341857
Encoder Loss:  0.039205145  || Decoder Loss:  0.031873662 Validation Decoder Loss:  0.3420923
Encoder Loss:  0.039216757  || Decoder Loss:  0.03189393 Validation Decoder Loss:  0.3420698
Encoder Loss:  0.03920786  || Decoder Loss:  0.03188147 Validation Decoder Loss:  0.34217256
Encoder Loss:  0.039173465  || Decoder Loss:  0.031826075 Validation Decoder Loss:  0.34232742
Encoder Loss:  0.03918616  || Decoder Loss:  0.031848006 Validation Decoder Loss:  0.3424535
Encoder Loss:  0.039176084  || Decoder Loss:  0.031833265 Validation Decoder Loss:  0.34220505
Encoder Loss:  0.03917309  || Decoder Loss:  0.03182868 Validation Decoder Loss:  0.34231612
Encoder Loss:  0.039178215  || Decoder Loss:  0.031835917 Validation Decoder Loss:  0.34202123
Encoder Loss:  0.039176736  || Decoder Loss:  0.031838864 Validation Decoder Loss:  0.34216842
Encoder Loss:  0.03915709  || Decoder Loss:  0.031807024 Validation Decoder Loss:  0.34238595
Encoder Loss:  0.039169595  || Decoder Loss:  0.031826988 Validation Decoder Loss:  0.34209827
Encoder Loss:  0.0391613  || Decoder Loss:  0.03181017 Validation Decoder Loss:  0.34219897
Encoder Loss:  0.039152518  || Decoder Loss:  0.031804513 Validation Decoder Loss:  0.34211957
Encoder Loss:  0.03917187  || Decoder Loss:  0.031831637 Validation Decoder Loss:  0.34192538
Encoder Loss:  0.03913434  || Decoder Loss:  0.03177807 Validation Decoder Loss:  0.34252548
Encoder Loss:  0.039148513  || Decoder Loss:  0.031795535 Validation Decoder Loss:  0.3418525
Encoder Loss:  0.039144002  || Decoder Loss:  0.031791423 Validation Decoder Loss:  0.34251225
Encoder Loss:  0.039124295  || Decoder Loss:  0.03176457 Validation Decoder Loss:  0.34250712
Encoder Loss:  0.039105743  || Decoder Loss:  0.031735264 Validation Decoder Loss:  0.3425604
Encoder Loss:  0.03910643  || Decoder Loss:  0.031738084 Validation Decoder Loss:  0.34255138
Encoder Loss:  0.039153554  || Decoder Loss:  0.031804007 Validation Decoder Loss:  0.34195977
Encoder Loss:  0.039134797  || Decoder Loss:  0.031770676 Validation Decoder Loss:  0.34225073
Encoder Loss:  0.039128043  || Decoder Loss:  0.031758867 Validation Decoder Loss:  0.3423764
Encoder Loss:  0.03912439  || Decoder Loss:  0.031756643 Validation Decoder Loss:  0.34243077
Encoder Loss:  0.039110623  || Decoder Loss:  0.03173103 Validation Decoder Loss:  0.34225547
Encoder Loss:  0.03912557  || Decoder Loss:  0.031753093 Validation Decoder Loss:  0.34220898
Encoder Loss:  0.03910711  || Decoder Loss:  0.031736217 Validation Decoder Loss:  0.34238565
Model: siamese_net_lr_0.048468378085409006 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34238565
Model: "sequential_710"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_401 (Conv3D (None, 94, 5, 20, 1)      32        
_________________________________________________________________
conv3d_transpose_402 (Conv3D (None, 634, 5, 20, 1)     449       
_________________________________________________________________
reshape_204 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 481
Trainable params: 481
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_712"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_302 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_713"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_302 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
conv2d_transpose_303 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26692292  || Decoder Loss:  0.31509385 Validation Decoder Loss:  1.1217917
Encoder Loss:  0.19970903  || Decoder Loss:  0.51376927 Validation Decoder Loss:  0.9689517
Encoder Loss:  0.1764987  || Decoder Loss:  0.49732232 Validation Decoder Loss:  0.9899945
Encoder Loss:  0.17610091  || Decoder Loss:  0.49779215 Validation Decoder Loss:  1.0125086
Encoder Loss:  0.17677373  || Decoder Loss:  0.49883628 Validation Decoder Loss:  1.0060688
Encoder Loss:  0.17794882  || Decoder Loss:  0.49802506 Validation Decoder Loss:  1.0214287
Encoder Loss:  0.17700773  || Decoder Loss:  0.49796173 Validation Decoder Loss:  1.0262363
Encoder Loss:  0.18023074  || Decoder Loss:  0.49802303 Validation Decoder Loss:  1.0085107
Encoder Loss:  0.18128778  || Decoder Loss:  0.5006969 Validation Decoder Loss:  1.0418057
Encoder Loss:  0.1769125  || Decoder Loss:  0.4987737 Validation Decoder Loss:  1.0433632
Encoder Loss:  0.17730908  || Decoder Loss:  0.49887073 Validation Decoder Loss:  1.0332613
Encoder Loss:  0.17693403  || Decoder Loss:  0.49716634 Validation Decoder Loss:  1.0496308
Encoder Loss:  0.17699948  || Decoder Loss:  0.4970782 Validation Decoder Loss:  1.0477085
Encoder Loss:  0.17556661  || Decoder Loss:  0.4980214 Validation Decoder Loss:  1.0608375
Encoder Loss:  0.17695102  || Decoder Loss:  0.49922702 Validation Decoder Loss:  1.0493402
Encoder Loss:  0.17620943  || Decoder Loss:  0.49806228 Validation Decoder Loss:  1.0550855
Encoder Loss:  0.17697257  || Decoder Loss:  0.49791008 Validation Decoder Loss:  1.0742396
Encoder Loss:  0.17572722  || Decoder Loss:  0.49788934 Validation Decoder Loss:  1.0816959
Encoder Loss:  0.17622465  || Decoder Loss:  0.49896306 Validation Decoder Loss:  1.0717651
Encoder Loss:  0.17587669  || Decoder Loss:  0.49773562 Validation Decoder Loss:  1.0736573
Encoder Loss:  0.17584328  || Decoder Loss:  0.49910966 Validation Decoder Loss:  1.075522
Encoder Loss:  0.17583366  || Decoder Loss:  0.4975341 Validation Decoder Loss:  1.0922456
Encoder Loss:  0.17702217  || Decoder Loss:  0.4987343 Validation Decoder Loss:  1.0888293
Encoder Loss:  0.17602625  || Decoder Loss:  0.4967394 Validation Decoder Loss:  1.1017985
Encoder Loss:  0.1766946  || Decoder Loss:  0.49912375 Validation Decoder Loss:  1.105497
Encoder Loss:  0.17653637  || Decoder Loss:  0.49862915 Validation Decoder Loss:  1.1067964
Encoder Loss:  0.1766961  || Decoder Loss:  0.49755424 Validation Decoder Loss:  1.0936004
Encoder Loss:  0.17684703  || Decoder Loss:  0.49856418 Validation Decoder Loss:  1.1147017
Encoder Loss:  0.17619349  || Decoder Loss:  0.49919719 Validation Decoder Loss:  1.114656
Encoder Loss:  0.17530793  || Decoder Loss:  0.49843198 Validation Decoder Loss:  1.1040817
Encoder Loss:  0.17539449  || Decoder Loss:  0.49755624 Validation Decoder Loss:  1.1044004
Encoder Loss:  0.17532772  || Decoder Loss:  0.49773583 Validation Decoder Loss:  1.0984452
Encoder Loss:  0.17494877  || Decoder Loss:  0.49534404 Validation Decoder Loss:  0.831789
Encoder Loss:  0.17407218  || Decoder Loss:  0.49560314 Validation Decoder Loss:  1.0914252
Encoder Loss:  0.17403887  || Decoder Loss:  0.4919203 Validation Decoder Loss:  0.7730968
Encoder Loss:  0.17325632  || Decoder Loss:  0.48939422 Validation Decoder Loss:  0.814263
Encoder Loss:  0.1731547  || Decoder Loss:  0.48947343 Validation Decoder Loss:  0.98854816
Encoder Loss:  0.17224859  || Decoder Loss:  0.48688954 Validation Decoder Loss:  0.8167165
Encoder Loss:  0.17213528  || Decoder Loss:  0.48605114 Validation Decoder Loss:  0.8585419
Encoder Loss:  0.17285897  || Decoder Loss:  0.48893985 Validation Decoder Loss:  0.77014905
Model: siamese_net_lr_0.05927021966788221 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7701491
Model: "sequential_714"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_404 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_852 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_405 (Conv3D (None, 634, 5, 20, 1)     548       
_________________________________________________________________
reshape_205 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_716"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_304 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
dropout_854 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_717"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_304 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_856 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_305 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19487716  || Decoder Loss:  0.23054089 Validation Decoder Loss:  0.89341074
Encoder Loss:  0.36686367  || Decoder Loss:  0.51575696 Validation Decoder Loss:  0.8845382
Encoder Loss:  0.36147106  || Decoder Loss:  0.5083015 Validation Decoder Loss:  0.9023982
Encoder Loss:  0.36009875  || Decoder Loss:  0.5061308 Validation Decoder Loss:  0.85848916
Encoder Loss:  0.36142933  || Decoder Loss:  0.50661296 Validation Decoder Loss:  0.8785268
Encoder Loss:  0.35919744  || Decoder Loss:  0.50585496 Validation Decoder Loss:  0.87151265
Encoder Loss:  0.35779777  || Decoder Loss:  0.50329083 Validation Decoder Loss:  0.89339405
Encoder Loss:  0.36113864  || Decoder Loss:  0.5064783 Validation Decoder Loss:  0.8560027
Encoder Loss:  0.35752267  || Decoder Loss:  0.5038301 Validation Decoder Loss:  0.8661847
Encoder Loss:  0.35758963  || Decoder Loss:  0.5039669 Validation Decoder Loss:  0.8529054
Encoder Loss:  0.35629186  || Decoder Loss:  0.5015176 Validation Decoder Loss:  0.8633437
Encoder Loss:  0.35723233  || Decoder Loss:  0.5029297 Validation Decoder Loss:  0.85002214
Encoder Loss:  0.3569936  || Decoder Loss:  0.50205714 Validation Decoder Loss:  0.8535908
Encoder Loss:  0.35691983  || Decoder Loss:  0.50331414 Validation Decoder Loss:  0.8449781
Encoder Loss:  0.35795426  || Decoder Loss:  0.5039151 Validation Decoder Loss:  0.85459864
Encoder Loss:  0.3572929  || Decoder Loss:  0.50385255 Validation Decoder Loss:  0.8431739
Encoder Loss:  0.3565277  || Decoder Loss:  0.5027014 Validation Decoder Loss:  0.8416163
Encoder Loss:  0.35677093  || Decoder Loss:  0.5035498 Validation Decoder Loss:  0.8272532
Encoder Loss:  0.35686725  || Decoder Loss:  0.50301325 Validation Decoder Loss:  0.82703674
Encoder Loss:  0.35659546  || Decoder Loss:  0.5028181 Validation Decoder Loss:  0.83314943
Encoder Loss:  0.35689503  || Decoder Loss:  0.5029886 Validation Decoder Loss:  0.8213415
Encoder Loss:  0.3560698  || Decoder Loss:  0.5021742 Validation Decoder Loss:  0.8132785
Encoder Loss:  0.35695523  || Decoder Loss:  0.503318 Validation Decoder Loss:  0.82735825
Encoder Loss:  0.35776967  || Decoder Loss:  0.50312424 Validation Decoder Loss:  0.81887436
Encoder Loss:  0.3558874  || Decoder Loss:  0.502537 Validation Decoder Loss:  0.81700176
Encoder Loss:  0.35598567  || Decoder Loss:  0.50173557 Validation Decoder Loss:  0.8180971
Encoder Loss:  0.35741544  || Decoder Loss:  0.5034239 Validation Decoder Loss:  0.790777
Encoder Loss:  0.35821864  || Decoder Loss:  0.5032168 Validation Decoder Loss:  0.7826012
Encoder Loss:  0.35515678  || Decoder Loss:  0.49850616 Validation Decoder Loss:  0.7873533
Encoder Loss:  0.3540854  || Decoder Loss:  0.49688232 Validation Decoder Loss:  0.8100801
Encoder Loss:  0.35480678  || Decoder Loss:  0.50017357 Validation Decoder Loss:  0.8008867
Encoder Loss:  0.35441047  || Decoder Loss:  0.50014186 Validation Decoder Loss:  0.7957843
Encoder Loss:  0.3527027  || Decoder Loss:  0.49753207 Validation Decoder Loss:  0.9281614
Encoder Loss:  0.3522813  || Decoder Loss:  0.4956267 Validation Decoder Loss:  1.1620219
Encoder Loss:  0.35267967  || Decoder Loss:  0.4972121 Validation Decoder Loss:  1.1499764
Encoder Loss:  0.3532572  || Decoder Loss:  0.49679098 Validation Decoder Loss:  1.155182
Encoder Loss:  0.35003567  || Decoder Loss:  0.49308836 Validation Decoder Loss:  1.066409
Encoder Loss:  0.3459184  || Decoder Loss:  0.48698694 Validation Decoder Loss:  0.9641403
Encoder Loss:  0.34673297  || Decoder Loss:  0.48823678 Validation Decoder Loss:  0.7262039
Encoder Loss:  0.34805357  || Decoder Loss:  0.4906182 Validation Decoder Loss:  0.9675158
Model: siamese_net_lr_0.044901269160429594 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9675158
Model: "sequential_718"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_407 (Conv3D (None, 92, 5, 20, 1)      30        
_________________________________________________________________
dropout_858 (Dropout)        (None, 92, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_408 (Conv3D (None, 634, 5, 20, 1)     89        
_________________________________________________________________
reshape_206 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_720"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_306 (Conv2D)          (None, 3200, 20, 1)       47        
_________________________________________________________________
dropout_860 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 3170, 20, 1)       32        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_721"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_306 (Conv2D (None, 3210, 20, 1)       42        
_________________________________________________________________
dropout_862 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_307 (Conv2D (None, 3245, 20, 1)       37        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.069309264  || Decoder Loss:  0.056550927 Validation Decoder Loss:  0.34910652
Encoder Loss:  0.042508755  || Decoder Loss:  0.03293056 Validation Decoder Loss:  0.34507018
Encoder Loss:  0.040307034  || Decoder Loss:  0.032126654 Validation Decoder Loss:  0.3465469
Encoder Loss:  0.0399654  || Decoder Loss:  0.03207309 Validation Decoder Loss:  0.3469063
Encoder Loss:  0.03971891  || Decoder Loss:  0.032072324 Validation Decoder Loss:  0.34683675
Encoder Loss:  0.03964986  || Decoder Loss:  0.03200821 Validation Decoder Loss:  0.34680897
Encoder Loss:  0.039630618  || Decoder Loss:  0.031985343 Validation Decoder Loss:  0.34688845
Encoder Loss:  0.03961871  || Decoder Loss:  0.031970248 Validation Decoder Loss:  0.34695497
Encoder Loss:  0.039604884  || Decoder Loss:  0.031954717 Validation Decoder Loss:  0.34703398
Encoder Loss:  0.039596878  || Decoder Loss:  0.031946044 Validation Decoder Loss:  0.34708062
Encoder Loss:  0.039586585  || Decoder Loss:  0.031930994 Validation Decoder Loss:  0.3470415
Encoder Loss:  0.03956774  || Decoder Loss:  0.03190705 Validation Decoder Loss:  0.3469864
Encoder Loss:  0.039553586  || Decoder Loss:  0.03189034 Validation Decoder Loss:  0.34696633
Encoder Loss:  0.03954353  || Decoder Loss:  0.031878524 Validation Decoder Loss:  0.34696388
Encoder Loss:  0.039537683  || Decoder Loss:  0.03186934 Validation Decoder Loss:  0.34692356
Encoder Loss:  0.03952594  || Decoder Loss:  0.031853214 Validation Decoder Loss:  0.3468666
Encoder Loss:  0.03951958  || Decoder Loss:  0.031844426 Validation Decoder Loss:  0.34685105
Encoder Loss:  0.039511807  || Decoder Loss:  0.03183594 Validation Decoder Loss:  0.34686354
Encoder Loss:  0.039508518  || Decoder Loss:  0.031832036 Validation Decoder Loss:  0.34687582
Encoder Loss:  0.039505016  || Decoder Loss:  0.031829797 Validation Decoder Loss:  0.3469032
Encoder Loss:  0.039504107  || Decoder Loss:  0.03182847 Validation Decoder Loss:  0.3469415
Encoder Loss:  0.03950289  || Decoder Loss:  0.03182638 Validation Decoder Loss:  0.34698525
Encoder Loss:  0.039499823  || Decoder Loss:  0.031822402 Validation Decoder Loss:  0.3470564
Encoder Loss:  0.039500438  || Decoder Loss:  0.031820573 Validation Decoder Loss:  0.34708828
Encoder Loss:  0.039501887  || Decoder Loss:  0.031819806 Validation Decoder Loss:  0.34711015
Encoder Loss:  0.039507378  || Decoder Loss:  0.031820558 Validation Decoder Loss:  0.34713668
Encoder Loss:  0.03951385  || Decoder Loss:  0.031820394 Validation Decoder Loss:  0.34715527
Encoder Loss:  0.039502956  || Decoder Loss:  0.031822294 Validation Decoder Loss:  0.34716785
Encoder Loss:  0.03950735  || Decoder Loss:  0.03182204 Validation Decoder Loss:  0.34719065
Encoder Loss:  0.03951697  || Decoder Loss:  0.03182212 Validation Decoder Loss:  0.34719086
Encoder Loss:  0.039505426  || Decoder Loss:  0.03182423 Validation Decoder Loss:  0.34720826
Encoder Loss:  0.039502647  || Decoder Loss:  0.031825017 Validation Decoder Loss:  0.34722006
Encoder Loss:  0.039501004  || Decoder Loss:  0.031825043 Validation Decoder Loss:  0.34722948
Encoder Loss:  0.03950253  || Decoder Loss:  0.031824727 Validation Decoder Loss:  0.34723282
Encoder Loss:  0.039499845  || Decoder Loss:  0.031823818 Validation Decoder Loss:  0.34723437
Encoder Loss:  0.03949885  || Decoder Loss:  0.031823367 Validation Decoder Loss:  0.347247
Encoder Loss:  0.03950497  || Decoder Loss:  0.031824645 Validation Decoder Loss:  0.34727222
Encoder Loss:  0.039513215  || Decoder Loss:  0.031827554 Validation Decoder Loss:  0.34726846
Encoder Loss:  0.03951808  || Decoder Loss:  0.031828627 Validation Decoder Loss:  0.3472705
Encoder Loss:  0.03952128  || Decoder Loss:  0.03183075 Validation Decoder Loss:  0.34729907
Model: siamese_net_lr_0.015628786134392145 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34729907
Model: "sequential_722"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_410 (Conv3D (None, 148, 5, 20, 1)     86        
_________________________________________________________________
dropout_864 (Dropout)        (None, 148, 5, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_411 (Conv3D (None, 634, 5, 20, 1)     488       
_________________________________________________________________
reshape_207 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 574
Trainable params: 574
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_724"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_308 (Conv2D)          (None, 3230, 20, 1)       17        
_________________________________________________________________
dropout_866 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 3170, 20, 1)       62        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_725"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_308 (Conv2D (None, 3230, 20, 1)       62        
_________________________________________________________________
dropout_868 (Dropout)        (None, 3230, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_309 (Conv2D (None, 3245, 20, 1)       17        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06609404  || Decoder Loss:  0.06122092 Validation Decoder Loss:  0.44829535
Encoder Loss:  0.04381081  || Decoder Loss:  0.040051136 Validation Decoder Loss:  0.3334816
Encoder Loss:  0.03985911  || Decoder Loss:  0.034368563 Validation Decoder Loss:  0.3302847
Encoder Loss:  0.039572407  || Decoder Loss:  0.03403436 Validation Decoder Loss:  0.3262046
Encoder Loss:  0.039416745  || Decoder Loss:  0.03380038 Validation Decoder Loss:  0.33269924
Encoder Loss:  0.039448474  || Decoder Loss:  0.033850737 Validation Decoder Loss:  0.3340075
Encoder Loss:  0.039341796  || Decoder Loss:  0.03368802 Validation Decoder Loss:  0.31912118
Encoder Loss:  0.039324284  || Decoder Loss:  0.03366206 Validation Decoder Loss:  0.33524817
Encoder Loss:  0.039298054  || Decoder Loss:  0.033622254 Validation Decoder Loss:  0.3432805
Encoder Loss:  0.03924863  || Decoder Loss:  0.033546988 Validation Decoder Loss:  0.33570865
Encoder Loss:  0.039201852  || Decoder Loss:  0.03347598 Validation Decoder Loss:  0.3348691
Encoder Loss:  0.039231796  || Decoder Loss:  0.03352213 Validation Decoder Loss:  0.34609178
Encoder Loss:  0.039199512  || Decoder Loss:  0.033474687 Validation Decoder Loss:  0.3350836
Encoder Loss:  0.039136667  || Decoder Loss:  0.033378605 Validation Decoder Loss:  0.33601403
Encoder Loss:  0.039150797  || Decoder Loss:  0.033400744 Validation Decoder Loss:  0.34292206
Encoder Loss:  0.11588775  || Decoder Loss:  0.1506984 Validation Decoder Loss:  1.4341503
Encoder Loss:  0.3499707  || Decoder Loss:  0.5085049 Validation Decoder Loss:  1.4342266
Encoder Loss:  0.34995633  || Decoder Loss:  0.50848436 Validation Decoder Loss:  1.4334167
Encoder Loss:  0.34932673  || Decoder Loss:  0.50752217 Validation Decoder Loss:  1.4309406
Encoder Loss:  0.3316167  || Decoder Loss:  0.48045215 Validation Decoder Loss:  0.56403637
Encoder Loss:  0.33838832  || Decoder Loss:  0.49080312 Validation Decoder Loss:  0.5661363
Encoder Loss:  0.3388781  || Decoder Loss:  0.49155197 Validation Decoder Loss:  0.5668927
Encoder Loss:  0.3394388  || Decoder Loss:  0.49240974 Validation Decoder Loss:  0.5682646
Encoder Loss:  0.33983228  || Decoder Loss:  0.4930113 Validation Decoder Loss:  0.56880176
Encoder Loss:  0.34017655  || Decoder Loss:  0.49353805 Validation Decoder Loss:  0.5696573
Encoder Loss:  0.34062096  || Decoder Loss:  0.49421751 Validation Decoder Loss:  0.5703506
Encoder Loss:  0.34120357  || Decoder Loss:  0.4951085 Validation Decoder Loss:  0.5721239
Encoder Loss:  0.3418559  || Decoder Loss:  0.49610606 Validation Decoder Loss:  0.57319164
Encoder Loss:  0.34239304  || Decoder Loss:  0.49692717 Validation Decoder Loss:  0.57511306
Encoder Loss:  0.34336367  || Decoder Loss:  0.498411 Validation Decoder Loss:  0.57745785
Encoder Loss:  0.3445009  || Decoder Loss:  0.5001495 Validation Decoder Loss:  0.5807316
Encoder Loss:  0.34619126  || Decoder Loss:  0.50273323 Validation Decoder Loss:  0.58488536
Encoder Loss:  0.34746158  || Decoder Loss:  0.5046757 Validation Decoder Loss:  0.58493245
Encoder Loss:  0.3475151  || Decoder Loss:  0.5047578 Validation Decoder Loss:  0.58495355
Encoder Loss:  0.347637  || Decoder Loss:  0.5049442 Validation Decoder Loss:  0.58537185
Encoder Loss:  0.34791362  || Decoder Loss:  0.5053672 Validation Decoder Loss:  0.585857
Encoder Loss:  0.3478859  || Decoder Loss:  0.505325 Validation Decoder Loss:  0.5853275
Encoder Loss:  0.34798324  || Decoder Loss:  0.5054739 Validation Decoder Loss:  0.58603156
Encoder Loss:  0.34779263  || Decoder Loss:  0.50518274 Validation Decoder Loss:  0.58511543
Encoder Loss:  0.3476417  || Decoder Loss:  0.5049522 Validation Decoder Loss:  0.5851003
Model: siamese_net_lr_0.023460758969850885 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.5851003
Model: "sequential_726"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_413 (Conv3D (None, 90, 5, 20, 1)      28        
_________________________________________________________________
conv3d_transpose_414 (Conv3D (None, 634, 5, 20, 1)     101       
_________________________________________________________________
reshape_208 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_728"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_310 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_729"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_310 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
conv2d_transpose_311 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30577508  || Decoder Loss:  0.3900329 Validation Decoder Loss:  0.43601632
Encoder Loss:  0.051366452  || Decoder Loss:  0.04522948 Validation Decoder Loss:  0.38352
Encoder Loss:  0.04215488  || Decoder Loss:  0.036575146 Validation Decoder Loss:  0.37225217
Encoder Loss:  0.04004094  || Decoder Loss:  0.033657342 Validation Decoder Loss:  0.3637022
Encoder Loss:  0.03931396  || Decoder Loss:  0.032626648 Validation Decoder Loss:  0.3580802
Encoder Loss:  0.03947176  || Decoder Loss:  0.03233062 Validation Decoder Loss:  0.3531235
Encoder Loss:  0.04248438  || Decoder Loss:  0.032435846 Validation Decoder Loss:  0.35162267
Encoder Loss:  0.042251825  || Decoder Loss:  0.032346748 Validation Decoder Loss:  0.35366714
Encoder Loss:  0.040636793  || Decoder Loss:  0.03228806 Validation Decoder Loss:  0.35003543
Encoder Loss:  0.04020041  || Decoder Loss:  0.032171965 Validation Decoder Loss:  0.3511895
Encoder Loss:  0.039394055  || Decoder Loss:  0.03219497 Validation Decoder Loss:  0.3513117
Encoder Loss:  0.03861105  || Decoder Loss:  0.03217802 Validation Decoder Loss:  0.35231334
Encoder Loss:  0.03871372  || Decoder Loss:  0.032177296 Validation Decoder Loss:  0.35424858
Encoder Loss:  0.04050778  || Decoder Loss:  0.032256145 Validation Decoder Loss:  0.3542614
Encoder Loss:  0.04050517  || Decoder Loss:  0.0322549 Validation Decoder Loss:  0.35266608
Encoder Loss:  0.03921819  || Decoder Loss:  0.0322205 Validation Decoder Loss:  0.3526769
Encoder Loss:  0.0392341  || Decoder Loss:  0.032208275 Validation Decoder Loss:  0.3524409
Encoder Loss:  0.03864573  || Decoder Loss:  0.032196455 Validation Decoder Loss:  0.3517683
Encoder Loss:  0.038451146  || Decoder Loss:  0.03217433 Validation Decoder Loss:  0.35202596
Encoder Loss:  0.03846478  || Decoder Loss:  0.032179255 Validation Decoder Loss:  0.3521982
Encoder Loss:  0.038498353  || Decoder Loss:  0.03217397 Validation Decoder Loss:  0.35428613
Encoder Loss:  0.039369848  || Decoder Loss:  0.032268703 Validation Decoder Loss:  0.3511672
Encoder Loss:  0.038532082  || Decoder Loss:  0.032200053 Validation Decoder Loss:  0.35183722
Encoder Loss:  0.038565874  || Decoder Loss:  0.032179546 Validation Decoder Loss:  0.35442835
Encoder Loss:  0.040402737  || Decoder Loss:  0.03228576 Validation Decoder Loss:  0.35080653
Encoder Loss:  0.039928615  || Decoder Loss:  0.03227316 Validation Decoder Loss:  0.3513837
Encoder Loss:  0.03890904  || Decoder Loss:  0.032214534 Validation Decoder Loss:  0.35212445
Encoder Loss:  0.03881568  || Decoder Loss:  0.032182824 Validation Decoder Loss:  0.3510241
Encoder Loss:  0.0385476  || Decoder Loss:  0.032151256 Validation Decoder Loss:  0.35263172
Encoder Loss:  0.038073614  || Decoder Loss:  0.032155976 Validation Decoder Loss:  0.35289448
Encoder Loss:  0.03871206  || Decoder Loss:  0.03216589 Validation Decoder Loss:  0.35213596
Encoder Loss:  0.038253237  || Decoder Loss:  0.032169748 Validation Decoder Loss:  0.3518233
Encoder Loss:  0.038210977  || Decoder Loss:  0.032165997 Validation Decoder Loss:  0.3522754
Encoder Loss:  0.03881663  || Decoder Loss:  0.032204166 Validation Decoder Loss:  0.34977114
Encoder Loss:  0.03886363  || Decoder Loss:  0.032131005 Validation Decoder Loss:  0.3516715
Encoder Loss:  0.038142413  || Decoder Loss:  0.032141782 Validation Decoder Loss:  0.35236627
Encoder Loss:  0.03821588  || Decoder Loss:  0.032112554 Validation Decoder Loss:  0.352701
Encoder Loss:  0.03820621  || Decoder Loss:  0.03211733 Validation Decoder Loss:  0.35230187
Encoder Loss:  0.038609967  || Decoder Loss:  0.032120585 Validation Decoder Loss:  0.3524908
Encoder Loss:  0.038031172  || Decoder Loss:  0.032108117 Validation Decoder Loss:  0.35199827
Model: siamese_net_lr_0.04824893875696397 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35199827
Model: "sequential_730"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_416 (Conv3D (None, 76, 5, 20, 1)      14        
_________________________________________________________________
dropout_870 (Dropout)        (None, 76, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_417 (Conv3D (None, 634, 5, 20, 1)     335       
_________________________________________________________________
reshape_209 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 349
Trainable params: 349
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_732"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_312 (Conv2D)          (None, 3180, 20, 1)       67        
_________________________________________________________________
dropout_872 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 3170, 20, 1)       12        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_733"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_312 (Conv2D (None, 3200, 20, 1)       32        
_________________________________________________________________
dropout_874 (Dropout)        (None, 3200, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_313 (Conv2D (None, 3245, 20, 1)       47        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08866151  || Decoder Loss:  0.079128526 Validation Decoder Loss:  0.4678701
Encoder Loss:  0.07195325  || Decoder Loss:  0.07332327 Validation Decoder Loss:  0.3509828
Encoder Loss:  0.04816477  || Decoder Loss:  0.0476109 Validation Decoder Loss:  0.3653182
Encoder Loss:  0.038602524  || Decoder Loss:  0.037140656 Validation Decoder Loss:  0.33943826
Encoder Loss:  0.03494052  || Decoder Loss:  0.03284517 Validation Decoder Loss:  0.3410713
Encoder Loss:  0.035018492  || Decoder Loss:  0.03245619 Validation Decoder Loss:  0.33970976
Encoder Loss:  0.03450263  || Decoder Loss:  0.03238792 Validation Decoder Loss:  0.3399213
Encoder Loss:  0.034865648  || Decoder Loss:  0.03237469 Validation Decoder Loss:  0.3399115
Encoder Loss:  0.034570314  || Decoder Loss:  0.032467984 Validation Decoder Loss:  0.3412546
Encoder Loss:  0.034843814  || Decoder Loss:  0.032737125 Validation Decoder Loss:  0.3434616
Encoder Loss:  0.0365475  || Decoder Loss:  0.0346563 Validation Decoder Loss:  0.35283244
Encoder Loss:  0.035539426  || Decoder Loss:  0.033358764 Validation Decoder Loss:  0.34413147
Encoder Loss:  0.034677602  || Decoder Loss:  0.032440614 Validation Decoder Loss:  0.34133115
Encoder Loss:  0.03545432  || Decoder Loss:  0.033444032 Validation Decoder Loss:  0.34300405
Encoder Loss:  0.034623682  || Decoder Loss:  0.03238676 Validation Decoder Loss:  0.34057975
Encoder Loss:  0.034547884  || Decoder Loss:  0.03231709 Validation Decoder Loss:  0.34111
Encoder Loss:  0.034508273  || Decoder Loss:  0.03259197 Validation Decoder Loss:  0.34171706
Encoder Loss:  0.03447974  || Decoder Loss:  0.03244222 Validation Decoder Loss:  0.3371577
Encoder Loss:  0.035560593  || Decoder Loss:  0.03364462 Validation Decoder Loss:  0.33724225
Encoder Loss:  0.04382202  || Decoder Loss:  0.042848602 Validation Decoder Loss:  0.3817234
Encoder Loss:  0.05920264  || Decoder Loss:  0.060027286 Validation Decoder Loss:  0.36327803
Encoder Loss:  0.046236224  || Decoder Loss:  0.045476355 Validation Decoder Loss:  0.3311352
Encoder Loss:  0.042887364  || Decoder Loss:  0.041733075 Validation Decoder Loss:  0.33576038
Encoder Loss:  0.03722595  || Decoder Loss:  0.035469156 Validation Decoder Loss:  0.33024588
Encoder Loss:  0.040060844  || Decoder Loss:  0.038542904 Validation Decoder Loss:  0.3353191
Encoder Loss:  0.034839857  || Decoder Loss:  0.032799512 Validation Decoder Loss:  0.33694187
Encoder Loss:  0.034505006  || Decoder Loss:  0.032417692 Validation Decoder Loss:  0.3362502
Encoder Loss:  0.09093943  || Decoder Loss:  0.09472152 Validation Decoder Loss:  0.6798636
Encoder Loss:  0.37499037  || Decoder Loss:  0.41157475 Validation Decoder Loss:  1.0790601
Encoder Loss:  0.40718228  || Decoder Loss:  0.44788048 Validation Decoder Loss:  1.0357573
Encoder Loss:  0.20246258  || Decoder Loss:  0.21961786 Validation Decoder Loss:  0.33607805
Encoder Loss:  0.039244898  || Decoder Loss:  0.037675835 Validation Decoder Loss:  0.33699805
Encoder Loss:  0.034795  || Decoder Loss:  0.03282325 Validation Decoder Loss:  0.3412826
Encoder Loss:  0.03452757  || Decoder Loss:  0.032501314 Validation Decoder Loss:  0.33876455
Encoder Loss:  0.034478415  || Decoder Loss:  0.03245504 Validation Decoder Loss:  0.33821547
Encoder Loss:  0.03446829  || Decoder Loss:  0.032446515 Validation Decoder Loss:  0.33755398
Encoder Loss:  0.034457818  || Decoder Loss:  0.032437548 Validation Decoder Loss:  0.3378647
Encoder Loss:  0.03445339  || Decoder Loss:  0.03242978 Validation Decoder Loss:  0.33777273
Encoder Loss:  0.034439534  || Decoder Loss:  0.03242252 Validation Decoder Loss:  0.33820355
Encoder Loss:  0.034668203  || Decoder Loss:  0.032459963 Validation Decoder Loss:  0.3411808
Model: siamese_net_lr_0.05496042267802987 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34118083
Model: "sequential_734"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_419 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
dropout_876 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_420 (Conv3D (None, 634, 5, 20, 1)     287       
_________________________________________________________________
reshape_210 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 313
Trainable params: 313
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_736"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_314 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_878 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_315 (Conv2D)          (None, 3170, 20, 1)       52        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_737"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_314 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_880 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_315 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08180179  || Decoder Loss:  0.08013031 Validation Decoder Loss:  0.40647477
Encoder Loss:  0.05135182  || Decoder Loss:  0.04175517 Validation Decoder Loss:  0.38646933
Encoder Loss:  0.048393186  || Decoder Loss:  0.038876735 Validation Decoder Loss:  0.37022358
Encoder Loss:  0.04748987  || Decoder Loss:  0.036926977 Validation Decoder Loss:  0.36076534
Encoder Loss:  0.047159754  || Decoder Loss:  0.035816833 Validation Decoder Loss:  0.35620818
Encoder Loss:  0.047004547  || Decoder Loss:  0.03525113 Validation Decoder Loss:  0.3537928
Encoder Loss:  0.04689301  || Decoder Loss:  0.03493369 Validation Decoder Loss:  0.35222238
Encoder Loss:  0.046858348  || Decoder Loss:  0.034726128 Validation Decoder Loss:  0.35141897
Encoder Loss:  0.046803646  || Decoder Loss:  0.034573436 Validation Decoder Loss:  0.3507967
Encoder Loss:  0.046772636  || Decoder Loss:  0.034454547 Validation Decoder Loss:  0.35046613
Encoder Loss:  0.046750065  || Decoder Loss:  0.03435579 Validation Decoder Loss:  0.3502761
Encoder Loss:  0.04672842  || Decoder Loss:  0.034274183 Validation Decoder Loss:  0.35014272
Encoder Loss:  0.04669489  || Decoder Loss:  0.03420449 Validation Decoder Loss:  0.35008222
Encoder Loss:  0.046665903  || Decoder Loss:  0.034145534 Validation Decoder Loss:  0.3499807
Encoder Loss:  0.046637896  || Decoder Loss:  0.03409512 Validation Decoder Loss:  0.3499043
Encoder Loss:  0.046625227  || Decoder Loss:  0.034050938 Validation Decoder Loss:  0.3498591
Encoder Loss:  0.046606194  || Decoder Loss:  0.03401266 Validation Decoder Loss:  0.34982824
Encoder Loss:  0.046606146  || Decoder Loss:  0.03397866 Validation Decoder Loss:  0.3498609
Encoder Loss:  0.046594877  || Decoder Loss:  0.033948846 Validation Decoder Loss:  0.34987578
Encoder Loss:  0.046566293  || Decoder Loss:  0.03392247 Validation Decoder Loss:  0.34989628
Encoder Loss:  0.046558943  || Decoder Loss:  0.033899184 Validation Decoder Loss:  0.34991604
Encoder Loss:  0.04658577  || Decoder Loss:  0.03387771 Validation Decoder Loss:  0.3500024
Encoder Loss:  0.04654498  || Decoder Loss:  0.033858076 Validation Decoder Loss:  0.35008886
Encoder Loss:  0.046558995  || Decoder Loss:  0.03384066 Validation Decoder Loss:  0.3501504
Encoder Loss:  0.04658423  || Decoder Loss:  0.03382427 Validation Decoder Loss:  0.35028556
Encoder Loss:  0.04657393  || Decoder Loss:  0.03380729 Validation Decoder Loss:  0.3504769
Encoder Loss:  0.046555124  || Decoder Loss:  0.033791833 Validation Decoder Loss:  0.35059002
Encoder Loss:  0.046511535  || Decoder Loss:  0.033779718 Validation Decoder Loss:  0.35064352
Encoder Loss:  0.04650566  || Decoder Loss:  0.033768103 Validation Decoder Loss:  0.35074753
Encoder Loss:  0.046501208  || Decoder Loss:  0.033756856 Validation Decoder Loss:  0.35084167
Encoder Loss:  0.046543118  || Decoder Loss:  0.033746146 Validation Decoder Loss:  0.35097784
Encoder Loss:  0.04654139  || Decoder Loss:  0.033732843 Validation Decoder Loss:  0.35126194
Encoder Loss:  0.046560016  || Decoder Loss:  0.033717886 Validation Decoder Loss:  0.35155085
Encoder Loss:  0.046539295  || Decoder Loss:  0.033703092 Validation Decoder Loss:  0.35182905
Encoder Loss:  0.046572365  || Decoder Loss:  0.03368754 Validation Decoder Loss:  0.3521623
Encoder Loss:  0.0465264  || Decoder Loss:  0.03366968 Validation Decoder Loss:  0.35254952
Encoder Loss:  0.046538606  || Decoder Loss:  0.033649683 Validation Decoder Loss:  0.35300457
Encoder Loss:  0.04648859  || Decoder Loss:  0.033623263 Validation Decoder Loss:  0.3535927
Encoder Loss:  0.046536222  || Decoder Loss:  0.033585206 Validation Decoder Loss:  0.3542968
Encoder Loss:  0.04645095  || Decoder Loss:  0.033533018 Validation Decoder Loss:  0.3549942
Model: siamese_net_lr_0.0017781919049058687 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35499418
Model: "sequential_738"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_422 (Conv3D (None, 88, 5, 20, 1)      26        
_________________________________________________________________
conv3d_transpose_423 (Conv3D (None, 634, 5, 20, 1)     287       
_________________________________________________________________
reshape_211 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 313
Trainable params: 313
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_740"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_316 (Conv2D)          (None, 3210, 20, 1)       37        
_________________________________________________________________
conv2d_317 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_741"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_316 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
conv2d_transpose_317 (Conv2D (None, 3245, 20, 1)       67        
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [3.83431313e-02 8.31174517e-01 2.89424262e-01 6.05107793e-01
 4.39708359e-01 9.18116325e-02 4.40000000e+02 3.21000000e+03
 3.18000000e+03]
Optimized Validation Decoder Loss: 0.3220357298851013











Optimizing at level  3
Model: "sequential_742"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_425 (Conv3D (None, 86, 5, 20, 1)      24        
_________________________________________________________________
dropout_882 (Dropout)        (None, 86, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_426 (Conv3D (None, 88, 5, 20, 1)      4         
_________________________________________________________________
dropout_883 (Dropout)        (None, 88, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_427 (Conv3D (None, 634, 5, 20, 1)     548       
_________________________________________________________________
reshape_212 (Reshape)        (None, 3170, 20, 1)       0         
=================================================================
Total params: 576
Trainable params: 576
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_744"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_318 (Conv2D)          (None, 3220, 20, 1)       27        
_________________________________________________________________
dropout_885 (Dropout)        (None, 3220, 20, 1)       0         
_________________________________________________________________
conv2d_319 (Conv2D)          (None, 3210, 20, 1)       12        
_________________________________________________________________
dropout_886 (Dropout)        (None, 3210, 20, 1)       0         
_________________________________________________________________
conv2d_320 (Conv2D)          (None, 3170, 20, 1)       42        
=================================================================
Total params: 81
Trainable params: 81
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_745"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_318 (Conv2D (None, 3180, 20, 1)       12        
_________________________________________________________________
dropout_888 (Dropout)        (None, 3180, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_319 (Conv2D (None, 3230, 20, 1)       52        
_________________________________________________________________
dropout_889 (Dropout)        (None, 3230, 20, 1)       0         
=================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Optimizing at level  4
FINISHED NAS
best_loss, best_depth 0.3220357298851013 3
[(634, 5, 20, 1), (88, 5, 20, 1)] [(3170, 20, 1), (440, 20, 1)]
[(3170, 20, 1), (3210, 20, 1)] [(3170, 20, 1), (3210, 20, 1)]
[(3245, 20, 1), (3180, 20, 1)] [(3170, 20, 1), (3180, 20, 1)]
