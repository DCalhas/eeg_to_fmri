Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(25, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(50, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(75, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(100, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(125, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(150, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(175, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(200, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(225, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(250, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(25, 874, 14)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2020-02-19 17:39:38.663182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-02-19 17:39:38.668164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2020-02-19 17:39:38.668333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-02-19 17:39:38.669589: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-02-19 17:39:38.670803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-02-19 17:39:38.671014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-02-19 17:39:38.672148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-02-19 17:39:38.672687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-02-19 17:39:38.675022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-19 17:39:38.676116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-19 17:39:38.676334: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-02-19 17:39:38.707554: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2020-02-19 17:39:38.708531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f8e8662f0 executing computations on platform Host. Devices:
2020-02-19 17:39:38.708564: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-19 17:39:38.709711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2020-02-19 17:39:38.709752: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-02-19 17:39:38.709768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-02-19 17:39:38.709783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-02-19 17:39:38.709797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-02-19 17:39:38.709811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-02-19 17:39:38.709825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-02-19 17:39:38.709839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-19 17:39:38.711784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-19 17:39:38.711827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-02-19 17:39:38.777688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-19 17:39:38.777716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-19 17:39:38.777725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-19 17:39:38.779356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2020-02-19 17:39:38.780774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f9335eea0 executing computations on platform CUDA. Devices:
2020-02-19 17:39:38.780797: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2020-02-19 17:39:39.988100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-19 17:39:41.596583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(50, 874, 14)
Finished Loading Data
Pairs Created
Optimizing at level  1
NAS BO
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape (Reshape)            (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18788405  || Decoder Loss:  0.2189708 Validation Decoder Loss:  0.4920995
Encoder Loss:  0.18763974  || Decoder Loss:  0.21883686 Validation Decoder Loss:  0.49174768
Encoder Loss:  0.18737148  || Decoder Loss:  0.2186563 Validation Decoder Loss:  0.49145612
Encoder Loss:  0.18709534  || Decoder Loss:  0.21848023 Validation Decoder Loss:  0.49117008
Encoder Loss:  0.18681075  || Decoder Loss:  0.21831195 Validation Decoder Loss:  0.49089703
Encoder Loss:  0.18651237  || Decoder Loss:  0.21814676 Validation Decoder Loss:  0.49063927
Encoder Loss:  0.18619816  || Decoder Loss:  0.2179828 Validation Decoder Loss:  0.49038345
Encoder Loss:  0.1858636  || Decoder Loss:  0.2178177 Validation Decoder Loss:  0.49012986
Encoder Loss:  0.1855051  || Decoder Loss:  0.21764652 Validation Decoder Loss:  0.48995098
Encoder Loss:  0.18511918  || Decoder Loss:  0.21746668 Validation Decoder Loss:  0.4898381
Encoder Loss:  0.18470483  || Decoder Loss:  0.21727702 Validation Decoder Loss:  0.48971108
Encoder Loss:  0.1842579  || Decoder Loss:  0.21707085 Validation Decoder Loss:  0.48956013
Encoder Loss:  0.1837763  || Decoder Loss:  0.21684039 Validation Decoder Loss:  0.48941553
Encoder Loss:  0.18326835  || Decoder Loss:  0.21659353 Validation Decoder Loss:  0.4893016
Encoder Loss:  0.18274793  || Decoder Loss:  0.21635124 Validation Decoder Loss:  0.48926193
Encoder Loss:  0.1822293  || Decoder Loss:  0.21613285 Validation Decoder Loss:  0.4894099
Encoder Loss:  0.18171509  || Decoder Loss:  0.21593769 Validation Decoder Loss:  0.48968694
Encoder Loss:  0.18120721  || Decoder Loss:  0.21576408 Validation Decoder Loss:  0.48992643
Encoder Loss:  0.1807045  || Decoder Loss:  0.21560991 Validation Decoder Loss:  0.49014407
Encoder Loss:  0.18020813  || Decoder Loss:  0.21547122 Validation Decoder Loss:  0.49033564
Encoder Loss:  0.17971313  || Decoder Loss:  0.21534128 Validation Decoder Loss:  0.49052766
Encoder Loss:  0.17921618  || Decoder Loss:  0.21521127 Validation Decoder Loss:  0.4907274
Encoder Loss:  0.17871566  || Decoder Loss:  0.21507588 Validation Decoder Loss:  0.4909457
Encoder Loss:  0.17821617  || Decoder Loss:  0.2149406 Validation Decoder Loss:  0.49115902
Encoder Loss:  0.17772052  || Decoder Loss:  0.21481112 Validation Decoder Loss:  0.49136752
Encoder Loss:  0.17722051  || Decoder Loss:  0.21467409 Validation Decoder Loss:  0.49161643
Encoder Loss:  0.17671427  || Decoder Loss:  0.2145247 Validation Decoder Loss:  0.4918975
Encoder Loss:  0.17621566  || Decoder Loss:  0.21438316 Validation Decoder Loss:  0.49215633
Encoder Loss:  0.17572872  || Decoder Loss:  0.21425685 Validation Decoder Loss:  0.49240306
Encoder Loss:  0.17525259  || Decoder Loss:  0.21414426 Validation Decoder Loss:  0.4926587
Encoder Loss:  0.17478512  || Decoder Loss:  0.21404187 Validation Decoder Loss:  0.49293172
Encoder Loss:  0.17432328  || Decoder Loss:  0.21394365 Validation Decoder Loss:  0.49323028
Encoder Loss:  0.17386478  || Decoder Loss:  0.21384542 Validation Decoder Loss:  0.49355298
Encoder Loss:  0.17341243  || Decoder Loss:  0.2137518 Validation Decoder Loss:  0.493897
Encoder Loss:  0.17297412  || Decoder Loss:  0.21367423 Validation Decoder Loss:  0.49423724
Encoder Loss:  0.17254433  || Decoder Loss:  0.21360633 Validation Decoder Loss:  0.49459296
Encoder Loss:  0.17212102  || Decoder Loss:  0.21354496 Validation Decoder Loss:  0.49496284
Encoder Loss:  0.17170277  || Decoder Loss:  0.21348739 Validation Decoder Loss:  0.4953624
Encoder Loss:  0.17128898  || Decoder Loss:  0.21343336 Validation Decoder Loss:  0.49581158
Encoder Loss:  0.1708822  || Decoder Loss:  0.21338713 Validation Decoder Loss:  0.49625188
Model: bold_synthesis_net_lr_0.000569395702145664 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49625188
NAS BO
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 74, 5, 14, 1)      12        
_________________________________________________________________
reshape_1 (Reshape)          (None, 370, 14, 1)        0         
=================================================================
Total params: 12
Trainable params: 12
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 370, 14, 1)        506       
=================================================================
Total params: 506
Trainable params: 506
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 874, 14, 1)        137       
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19973707  || Decoder Loss:  0.2387575 Validation Decoder Loss:  0.49093476
Encoder Loss:  0.19558299  || Decoder Loss:  0.23350598 Validation Decoder Loss:  0.48994964
Encoder Loss:  0.19361107  || Decoder Loss:  0.23169489 Validation Decoder Loss:  0.48928058
Encoder Loss:  0.19181073  || Decoder Loss:  0.23043208 Validation Decoder Loss:  0.48963344
Encoder Loss:  0.18981382  || Decoder Loss:  0.22915652 Validation Decoder Loss:  0.49220145
Encoder Loss:  0.187536  || Decoder Loss:  0.22766405 Validation Decoder Loss:  0.49677533
Encoder Loss:  0.18512951  || Decoder Loss:  0.22615016 Validation Decoder Loss:  0.5023676
Encoder Loss:  0.18272974  || Decoder Loss:  0.22475402 Validation Decoder Loss:  0.50889647
Encoder Loss:  0.18028465  || Decoder Loss:  0.22334336 Validation Decoder Loss:  0.5154105
Encoder Loss:  0.17781946  || Decoder Loss:  0.22194046 Validation Decoder Loss:  0.5190113
Encoder Loss:  0.17524762  || Decoder Loss:  0.22040479 Validation Decoder Loss:  0.5232415
Encoder Loss:  0.17276792  || Decoder Loss:  0.21905604 Validation Decoder Loss:  0.5257313
Encoder Loss:  0.17021799  || Decoder Loss:  0.21770965 Validation Decoder Loss:  0.525473
Encoder Loss:  0.16789077  || Decoder Loss:  0.2165328 Validation Decoder Loss:  0.5257862
Encoder Loss:  0.16592519  || Decoder Loss:  0.21563083 Validation Decoder Loss:  0.5317143
Encoder Loss:  0.16341424  || Decoder Loss:  0.21374099 Validation Decoder Loss:  0.54530394
Encoder Loss:  0.16065845  || Decoder Loss:  0.2111291 Validation Decoder Loss:  0.55884093
Encoder Loss:  0.15858532  || Decoder Loss:  0.20893833 Validation Decoder Loss:  0.56541544
Encoder Loss:  0.15731995  || Decoder Loss:  0.20755075 Validation Decoder Loss:  0.56750757
Encoder Loss:  0.15613121  || Decoder Loss:  0.20616044 Validation Decoder Loss:  0.5697469
Encoder Loss:  0.1551485  || Decoder Loss:  0.20504807 Validation Decoder Loss:  0.571715
Encoder Loss:  0.15434663  || Decoder Loss:  0.20414287 Validation Decoder Loss:  0.5727942
Encoder Loss:  0.15370853  || Decoder Loss:  0.2033831 Validation Decoder Loss:  0.57361585
Encoder Loss:  0.15320857  || Decoder Loss:  0.202781 Validation Decoder Loss:  0.5741293
Encoder Loss:  0.15283652  || Decoder Loss:  0.20234413 Validation Decoder Loss:  0.5743281
Encoder Loss:  0.15249611  || Decoder Loss:  0.20193319 Validation Decoder Loss:  0.5743688
Encoder Loss:  0.15217069  || Decoder Loss:  0.20152256 Validation Decoder Loss:  0.5741527
Encoder Loss:  0.15187679  || Decoder Loss:  0.20114906 Validation Decoder Loss:  0.5740669
Encoder Loss:  0.15162235  || Decoder Loss:  0.20083068 Validation Decoder Loss:  0.5745319
Encoder Loss:  0.15138674  || Decoder Loss:  0.20053999 Validation Decoder Loss:  0.5755705
Encoder Loss:  0.15113536  || Decoder Loss:  0.20022584 Validation Decoder Loss:  0.57736903
Encoder Loss:  0.15092398  || Decoder Loss:  0.19996971 Validation Decoder Loss:  0.5787038
Encoder Loss:  0.1507041  || Decoder Loss:  0.19969928 Validation Decoder Loss:  0.5796888
Encoder Loss:  0.15048932  || Decoder Loss:  0.19943796 Validation Decoder Loss:  0.58042836
Encoder Loss:  0.15025741  || Decoder Loss:  0.19915271 Validation Decoder Loss:  0.5812355
Encoder Loss:  0.14998482  || Decoder Loss:  0.19880615 Validation Decoder Loss:  0.5824865
Encoder Loss:  0.14975585  || Decoder Loss:  0.1985297 Validation Decoder Loss:  0.5834406
Encoder Loss:  0.14956832  || Decoder Loss:  0.19831756 Validation Decoder Loss:  0.5840377
Encoder Loss:  0.14939055  || Decoder Loss:  0.19812427 Validation Decoder Loss:  0.584412
Encoder Loss:  0.14920193  || Decoder Loss:  0.1979134 Validation Decoder Loss:  0.5848897
Model: bold_synthesis_net_lr_0.00081953672521747 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5848897
NAS BO
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 80, 9, 14, 1)      86        
_________________________________________________________________
reshape_2 (Reshape)          (None, 720, 14, 1)        0         
=================================================================
Total params: 86
Trainable params: 86
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 720, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 874, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17907543  || Decoder Loss:  0.22218688 Validation Decoder Loss:  0.51777804
Encoder Loss:  0.17890997  || Decoder Loss:  0.22213234 Validation Decoder Loss:  0.51766133
Encoder Loss:  0.17874485  || Decoder Loss:  0.22208051 Validation Decoder Loss:  0.51754445
Encoder Loss:  0.17857604  || Decoder Loss:  0.22202864 Validation Decoder Loss:  0.5174285
Encoder Loss:  0.1784035  || Decoder Loss:  0.2219772 Validation Decoder Loss:  0.51731354
Encoder Loss:  0.1782276  || Decoder Loss:  0.22192566 Validation Decoder Loss:  0.5171969
Encoder Loss:  0.17804764  || Decoder Loss:  0.2218735 Validation Decoder Loss:  0.5170808
Encoder Loss:  0.17786527  || Decoder Loss:  0.22182368 Validation Decoder Loss:  0.51696604
Encoder Loss:  0.17768034  || Decoder Loss:  0.22177517 Validation Decoder Loss:  0.5168508
Encoder Loss:  0.17749196  || Decoder Loss:  0.22172737 Validation Decoder Loss:  0.516736
Encoder Loss:  0.1772998  || Decoder Loss:  0.22167985 Validation Decoder Loss:  0.51661986
Encoder Loss:  0.17710453  || Decoder Loss:  0.22163363 Validation Decoder Loss:  0.5165049
Encoder Loss:  0.1769066  || Decoder Loss:  0.22158879 Validation Decoder Loss:  0.51638913
Encoder Loss:  0.17670554  || Decoder Loss:  0.22154485 Validation Decoder Loss:  0.5162737
Encoder Loss:  0.17650162  || Decoder Loss:  0.22150218 Validation Decoder Loss:  0.51615804
Encoder Loss:  0.1762945  || Decoder Loss:  0.22146034 Validation Decoder Loss:  0.51604193
Encoder Loss:  0.17608435  || Decoder Loss:  0.22141862 Validation Decoder Loss:  0.5159247
Encoder Loss:  0.17587201  || Decoder Loss:  0.221377 Validation Decoder Loss:  0.5158064
Encoder Loss:  0.17565718  || Decoder Loss:  0.2213357 Validation Decoder Loss:  0.51568705
Encoder Loss:  0.17543943  || Decoder Loss:  0.22129488 Validation Decoder Loss:  0.5155673
Encoder Loss:  0.17521891  || Decoder Loss:  0.22125463 Validation Decoder Loss:  0.515447
Encoder Loss:  0.1749968  || Decoder Loss:  0.22121611 Validation Decoder Loss:  0.51533157
Encoder Loss:  0.17477486  || Decoder Loss:  0.22118095 Validation Decoder Loss:  0.5152177
Encoder Loss:  0.17455097  || Decoder Loss:  0.22114669 Validation Decoder Loss:  0.51510257
Encoder Loss:  0.17432421  || Decoder Loss:  0.22111224 Validation Decoder Loss:  0.51498705
Encoder Loss:  0.17409493  || Decoder Loss:  0.22107771 Validation Decoder Loss:  0.51487046
Encoder Loss:  0.17386317  || Decoder Loss:  0.22104314 Validation Decoder Loss:  0.51475334
Encoder Loss:  0.17362909  || Decoder Loss:  0.22100858 Validation Decoder Loss:  0.51463485
Encoder Loss:  0.17339252  || Decoder Loss:  0.22097342 Validation Decoder Loss:  0.51451474
Encoder Loss:  0.17315385  || Decoder Loss:  0.2209382 Validation Decoder Loss:  0.51439476
Encoder Loss:  0.17291343  || Decoder Loss:  0.22090328 Validation Decoder Loss:  0.5142754
Encoder Loss:  0.17267132  || Decoder Loss:  0.22086836 Validation Decoder Loss:  0.5141561
Encoder Loss:  0.17242843  || Decoder Loss:  0.22083394 Validation Decoder Loss:  0.5140371
Encoder Loss:  0.17218468  || Decoder Loss:  0.2207999 Validation Decoder Loss:  0.51391584
Encoder Loss:  0.17194036  || Decoder Loss:  0.22076522 Validation Decoder Loss:  0.51379377
Encoder Loss:  0.17169526  || Decoder Loss:  0.2207308 Validation Decoder Loss:  0.5136724
Encoder Loss:  0.17144944  || Decoder Loss:  0.2206962 Validation Decoder Loss:  0.51355004
Encoder Loss:  0.17120244  || Decoder Loss:  0.22066158 Validation Decoder Loss:  0.5134261
Encoder Loss:  0.17095418  || Decoder Loss:  0.2206266 Validation Decoder Loss:  0.51330113
Encoder Loss:  0.17070499  || Decoder Loss:  0.2205912 Validation Decoder Loss:  0.51317453
Model: bold_synthesis_net_lr_6.734355813464679e-05 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.51317453
NAS BO
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 67, 10, 14, 1)     9         
_________________________________________________________________
reshape_3 (Reshape)          (None, 670, 14, 1)        0         
=================================================================
Total params: 9
Trainable params: 9
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 670, 14, 1)        206       
=================================================================
Total params: 206
Trainable params: 206
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 874, 14, 1)        206       
=================================================================
Total params: 206
Trainable params: 206
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14506294  || Decoder Loss:  0.24536392 Validation Decoder Loss:  0.54810804
Encoder Loss:  0.11336775  || Decoder Loss:  0.2118292 Validation Decoder Loss:  0.59512603
Encoder Loss:  0.10646107  || Decoder Loss:  0.20411052 Validation Decoder Loss:  0.59388566
Encoder Loss:  0.10389543  || Decoder Loss:  0.19952433 Validation Decoder Loss:  0.5896021
Encoder Loss:  0.10239078  || Decoder Loss:  0.19770846 Validation Decoder Loss:  0.5838806
Encoder Loss:  0.10136981  || Decoder Loss:  0.19643024 Validation Decoder Loss:  0.58059484
Encoder Loss:  0.10067429  || Decoder Loss:  0.19548483 Validation Decoder Loss:  0.5793887
Encoder Loss:  0.100185215  || Decoder Loss:  0.1948306 Validation Decoder Loss:  0.57894117
Encoder Loss:  0.09974638  || Decoder Loss:  0.19433287 Validation Decoder Loss:  0.58000904
Encoder Loss:  0.09933285  || Decoder Loss:  0.19379695 Validation Decoder Loss:  0.581164
Encoder Loss:  0.09891983  || Decoder Loss:  0.19315822 Validation Decoder Loss:  0.5809435
Encoder Loss:  0.09846701  || Decoder Loss:  0.19225894 Validation Decoder Loss:  0.58104646
Encoder Loss:  0.09796112  || Decoder Loss:  0.1910658 Validation Decoder Loss:  0.5793631
Encoder Loss:  0.09760428  || Decoder Loss:  0.1902154 Validation Decoder Loss:  0.57595575
Encoder Loss:  0.09730744  || Decoder Loss:  0.18948677 Validation Decoder Loss:  0.5760175
Encoder Loss:  0.0971206  || Decoder Loss:  0.18904188 Validation Decoder Loss:  0.5748691
Encoder Loss:  0.096960045  || Decoder Loss:  0.18867916 Validation Decoder Loss:  0.5749023
Encoder Loss:  0.096793406  || Decoder Loss:  0.18826276 Validation Decoder Loss:  0.57468885
Encoder Loss:  0.09668279  || Decoder Loss:  0.18796144 Validation Decoder Loss:  0.5755411
Encoder Loss:  0.0965659  || Decoder Loss:  0.18770123 Validation Decoder Loss:  0.5755038
Encoder Loss:  0.09650014  || Decoder Loss:  0.18749565 Validation Decoder Loss:  0.5749554
Encoder Loss:  0.09640214  || Decoder Loss:  0.18723495 Validation Decoder Loss:  0.5734412
Encoder Loss:  0.096301  || Decoder Loss:  0.18697043 Validation Decoder Loss:  0.5721431
Encoder Loss:  0.09617741  || Decoder Loss:  0.18664655 Validation Decoder Loss:  0.56963384
Encoder Loss:  0.09593903  || Decoder Loss:  0.18595418 Validation Decoder Loss:  0.56712973
Encoder Loss:  0.095671274  || Decoder Loss:  0.18519141 Validation Decoder Loss:  0.56431985
Encoder Loss:  0.095360495  || Decoder Loss:  0.18429306 Validation Decoder Loss:  0.5608506
Encoder Loss:  0.09513258  || Decoder Loss:  0.18360542 Validation Decoder Loss:  0.5577699
Encoder Loss:  0.095006526  || Decoder Loss:  0.18327054 Validation Decoder Loss:  0.5563171
Encoder Loss:  0.09490772  || Decoder Loss:  0.18298097 Validation Decoder Loss:  0.55447286
Encoder Loss:  0.09482008  || Decoder Loss:  0.18275833 Validation Decoder Loss:  0.5528996
Encoder Loss:  0.09474076  || Decoder Loss:  0.18251866 Validation Decoder Loss:  0.55080026
Encoder Loss:  0.09466622  || Decoder Loss:  0.182293 Validation Decoder Loss:  0.5482177
Encoder Loss:  0.09461411  || Decoder Loss:  0.18216357 Validation Decoder Loss:  0.5471514
Encoder Loss:  0.09455509  || Decoder Loss:  0.18199556 Validation Decoder Loss:  0.5453248
Encoder Loss:  0.094505735  || Decoder Loss:  0.18185882 Validation Decoder Loss:  0.54465103
Encoder Loss:  0.09444475  || Decoder Loss:  0.18168768 Validation Decoder Loss:  0.54405993
Encoder Loss:  0.09441278  || Decoder Loss:  0.18165827 Validation Decoder Loss:  0.54232985
Encoder Loss:  0.094349034  || Decoder Loss:  0.18146412 Validation Decoder Loss:  0.5421429
Encoder Loss:  0.09429495  || Decoder Loss:  0.18130904 Validation Decoder Loss:  0.5406972
Model: bold_synthesis_net_lr_0.0008595839000403235 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5406972
NAS BO
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 164, 5, 14, 1)     102       
_________________________________________________________________
reshape_4 (Reshape)          (None, 820, 14, 1)        0         
=================================================================
Total params: 102
Trainable params: 102
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 820, 14, 1)        56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 874, 14, 1)        56        
=================================================================
Total params: 56
Trainable params: 56
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.118198045  || Decoder Loss:  0.22881652 Validation Decoder Loss:  0.52980065
Encoder Loss:  0.11497662  || Decoder Loss:  0.25007814 Validation Decoder Loss:  0.60427344
Encoder Loss:  0.10036026  || Decoder Loss:  0.21408819 Validation Decoder Loss:  0.5847584
Encoder Loss:  0.096650876  || Decoder Loss:  0.20415485 Validation Decoder Loss:  0.58156365
Encoder Loss:  0.095000885  || Decoder Loss:  0.199756 Validation Decoder Loss:  0.5759762
Encoder Loss:  0.0942171  || Decoder Loss:  0.1981667 Validation Decoder Loss:  0.573569
Encoder Loss:  0.093676135  || Decoder Loss:  0.19747506 Validation Decoder Loss:  0.5739949
Encoder Loss:  0.09343101  || Decoder Loss:  0.19780728 Validation Decoder Loss:  0.57593983
Encoder Loss:  0.0933258  || Decoder Loss:  0.19858183 Validation Decoder Loss:  0.5720722
Encoder Loss:  0.09291781  || Decoder Loss:  0.19817808 Validation Decoder Loss:  0.5718278
Encoder Loss:  0.09248954  || Decoder Loss:  0.19757083 Validation Decoder Loss:  0.5715537
Encoder Loss:  0.09217766  || Decoder Loss:  0.19721533 Validation Decoder Loss:  0.57247436
Encoder Loss:  0.091985874  || Decoder Loss:  0.19707404 Validation Decoder Loss:  0.5729241
Encoder Loss:  0.09186412  || Decoder Loss:  0.19707409 Validation Decoder Loss:  0.5747077
Encoder Loss:  0.09182623  || Decoder Loss:  0.19727819 Validation Decoder Loss:  0.57640636
Encoder Loss:  0.09181934  || Decoder Loss:  0.19745737 Validation Decoder Loss:  0.578362
Encoder Loss:  0.0918053  || Decoder Loss:  0.19753873 Validation Decoder Loss:  0.5806287
Encoder Loss:  0.09180801  || Decoder Loss:  0.19763608 Validation Decoder Loss:  0.5828737
Encoder Loss:  0.091793105  || Decoder Loss:  0.19762531 Validation Decoder Loss:  0.5851486
Encoder Loss:  0.09176551  || Decoder Loss:  0.19756179 Validation Decoder Loss:  0.58702636
Encoder Loss:  0.09174594  || Decoder Loss:  0.19748557 Validation Decoder Loss:  0.5885313
Encoder Loss:  0.091703184  || Decoder Loss:  0.19739796 Validation Decoder Loss:  0.5896057
Encoder Loss:  0.09166274  || Decoder Loss:  0.19726235 Validation Decoder Loss:  0.58994704
Encoder Loss:  0.09162121  || Decoder Loss:  0.19713819 Validation Decoder Loss:  0.59041804
Encoder Loss:  0.09158381  || Decoder Loss:  0.19699249 Validation Decoder Loss:  0.5907081
Encoder Loss:  0.09152484  || Decoder Loss:  0.19681573 Validation Decoder Loss:  0.5909088
Encoder Loss:  0.09147049  || Decoder Loss:  0.19662443 Validation Decoder Loss:  0.59062696
Encoder Loss:  0.09141531  || Decoder Loss:  0.19646567 Validation Decoder Loss:  0.5904152
Encoder Loss:  0.09137562  || Decoder Loss:  0.19631037 Validation Decoder Loss:  0.5905362
Encoder Loss:  0.091320485  || Decoder Loss:  0.19616075 Validation Decoder Loss:  0.59051704
Encoder Loss:  0.09129943  || Decoder Loss:  0.19604485 Validation Decoder Loss:  0.59056634
Encoder Loss:  0.09124484  || Decoder Loss:  0.1958503 Validation Decoder Loss:  0.59028643
Encoder Loss:  0.091188364  || Decoder Loss:  0.19568978 Validation Decoder Loss:  0.59007734
Encoder Loss:  0.091150306  || Decoder Loss:  0.19555023 Validation Decoder Loss:  0.5898046
Encoder Loss:  0.09112361  || Decoder Loss:  0.1954239 Validation Decoder Loss:  0.5894257
Encoder Loss:  0.091092356  || Decoder Loss:  0.1953213 Validation Decoder Loss:  0.58925325
Encoder Loss:  0.09106424  || Decoder Loss:  0.19520523 Validation Decoder Loss:  0.5889915
Encoder Loss:  0.0910278  || Decoder Loss:  0.195101 Validation Decoder Loss:  0.58849096
Encoder Loss:  0.09100091  || Decoder Loss:  0.1950141 Validation Decoder Loss:  0.5879913
Encoder Loss:  0.09097364  || Decoder Loss:  0.19492836 Validation Decoder Loss:  0.5877768
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: bold_synthesis_net_lr_0.0008266488723852545 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5877768
Started Optimization Process
NAS BO
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_5 (Reshape)          (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19011328  || Decoder Loss:  0.21913739 Validation Decoder Loss:  0.49151406
Encoder Loss:  0.18976475  || Decoder Loss:  0.21895008 Validation Decoder Loss:  0.4910001
Encoder Loss:  0.18937148  || Decoder Loss:  0.21869504 Validation Decoder Loss:  0.49056882
Encoder Loss:  0.18895754  || Decoder Loss:  0.2184476 Validation Decoder Loss:  0.49018818
Encoder Loss:  0.188518  || Decoder Loss:  0.21820807 Validation Decoder Loss:  0.48982197
Encoder Loss:  0.18804404  || Decoder Loss:  0.21797264 Validation Decoder Loss:  0.48947647
Encoder Loss:  0.18752214  || Decoder Loss:  0.21772584 Validation Decoder Loss:  0.48927552
Encoder Loss:  0.18693931  || Decoder Loss:  0.21745303 Validation Decoder Loss:  0.4891233
Encoder Loss:  0.18628916  || Decoder Loss:  0.2171408 Validation Decoder Loss:  0.4889367
Encoder Loss:  0.18557951  || Decoder Loss:  0.21679333 Validation Decoder Loss:  0.48883647
Encoder Loss:  0.18484035  || Decoder Loss:  0.21645017 Validation Decoder Loss:  0.488999
Encoder Loss:  0.18410046  || Decoder Loss:  0.21614185 Validation Decoder Loss:  0.48936635
Encoder Loss:  0.18336785  || Decoder Loss:  0.21587078 Validation Decoder Loss:  0.48977563
Encoder Loss:  0.18264385  || Decoder Loss:  0.21563175 Validation Decoder Loss:  0.49016243
Encoder Loss:  0.18191667  || Decoder Loss:  0.21539953 Validation Decoder Loss:  0.49058288
Encoder Loss:  0.18119062  || Decoder Loss:  0.21517296 Validation Decoder Loss:  0.4909608
Encoder Loss:  0.18045832  || Decoder Loss:  0.21493825 Validation Decoder Loss:  0.4913859
Encoder Loss:  0.17971827  || Decoder Loss:  0.21469004 Validation Decoder Loss:  0.49183828
Encoder Loss:  0.17899121  || Decoder Loss:  0.21445663 Validation Decoder Loss:  0.49223793
Encoder Loss:  0.17828879  || Decoder Loss:  0.21425554 Validation Decoder Loss:  0.49263233
Encoder Loss:  0.17761064  || Decoder Loss:  0.2140845 Validation Decoder Loss:  0.4930111
Encoder Loss:  0.17694938  || Decoder Loss:  0.21393135 Validation Decoder Loss:  0.4934575
Encoder Loss:  0.17629626  || Decoder Loss:  0.21378012 Validation Decoder Loss:  0.49393576
Encoder Loss:  0.17566092  || Decoder Loss:  0.21364495 Validation Decoder Loss:  0.494431
Encoder Loss:  0.17504671  || Decoder Loss:  0.21353316 Validation Decoder Loss:  0.4949376
Encoder Loss:  0.17444456  || Decoder Loss:  0.21343222 Validation Decoder Loss:  0.49551132
Encoder Loss:  0.17385913  || Decoder Loss:  0.2133489 Validation Decoder Loss:  0.49616116
Encoder Loss:  0.17328313  || Decoder Loss:  0.21327353 Validation Decoder Loss:  0.49680585
Encoder Loss:  0.17271298  || Decoder Loss:  0.21320078 Validation Decoder Loss:  0.49754563
Encoder Loss:  0.1721431  || Decoder Loss:  0.21312065 Validation Decoder Loss:  0.49843976
Encoder Loss:  0.17156951  || Decoder Loss:  0.21303222 Validation Decoder Loss:  0.49942863
Encoder Loss:  0.17099051  || Decoder Loss:  0.21293256 Validation Decoder Loss:  0.50059247
Encoder Loss:  0.17044196  || Decoder Loss:  0.21286663 Validation Decoder Loss:  0.501739
Encoder Loss:  0.16992694  || Decoder Loss:  0.21284294 Validation Decoder Loss:  0.5027179
Encoder Loss:  0.16943516  || Decoder Loss:  0.21284966 Validation Decoder Loss:  0.50360787
Encoder Loss:  0.16898558  || Decoder Loss:  0.21288478 Validation Decoder Loss:  0.5042207
Encoder Loss:  0.16856593  || Decoder Loss:  0.21289575 Validation Decoder Loss:  0.5046222
Encoder Loss:  0.16817391  || Decoder Loss:  0.2128838 Validation Decoder Loss:  0.5048005
Encoder Loss:  0.16780268  || Decoder Loss:  0.21283695 Validation Decoder Loss:  0.504858
Encoder Loss:  0.16747908  || Decoder Loss:  0.21278398 Validation Decoder Loss:  0.5047665
Model: bold_synthesis_net_lr_0.0008489095553641011 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5047665
NAS BO
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_6 (Reshape)          (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20509708  || Decoder Loss:  0.23308587 Validation Decoder Loss:  0.5156687
Encoder Loss:  0.20495026  || Decoder Loss:  0.23309262 Validation Decoder Loss:  0.5155548
Encoder Loss:  0.20471664  || Decoder Loss:  0.232977 Validation Decoder Loss:  0.51546496
Encoder Loss:  0.20447727  || Decoder Loss:  0.23287305 Validation Decoder Loss:  0.515384
Encoder Loss:  0.20423189  || Decoder Loss:  0.2327852 Validation Decoder Loss:  0.5153323
Encoder Loss:  0.2039757  || Decoder Loss:  0.23270981 Validation Decoder Loss:  0.5153012
Encoder Loss:  0.2037118  || Decoder Loss:  0.2326549 Validation Decoder Loss:  0.51530004
Encoder Loss:  0.20343712  || Decoder Loss:  0.23261821 Validation Decoder Loss:  0.5153087
Encoder Loss:  0.203145  || Decoder Loss:  0.23259334 Validation Decoder Loss:  0.5153185
Encoder Loss:  0.2028317  || Decoder Loss:  0.23257318 Validation Decoder Loss:  0.5153248
Encoder Loss:  0.20249677  || Decoder Loss:  0.23255353 Validation Decoder Loss:  0.5153528
Encoder Loss:  0.2021497  || Decoder Loss:  0.23254344 Validation Decoder Loss:  0.5154073
Encoder Loss:  0.20179912  || Decoder Loss:  0.23255368 Validation Decoder Loss:  0.51549065
Encoder Loss:  0.2014443  || Decoder Loss:  0.23257795 Validation Decoder Loss:  0.5156218
Encoder Loss:  0.20108707  || Decoder Loss:  0.2326129 Validation Decoder Loss:  0.5157595
Encoder Loss:  0.20073147  || Decoder Loss:  0.23266116 Validation Decoder Loss:  0.5159304
Encoder Loss:  0.20037428  || Decoder Loss:  0.23271553 Validation Decoder Loss:  0.5161304
Encoder Loss:  0.20000823  || Decoder Loss:  0.23276213 Validation Decoder Loss:  0.5163869
Encoder Loss:  0.19963554  || Decoder Loss:  0.23279981 Validation Decoder Loss:  0.51667476
Encoder Loss:  0.19927247  || Decoder Loss:  0.2328505 Validation Decoder Loss:  0.51702887
Encoder Loss:  0.19891267  || Decoder Loss:  0.23290467 Validation Decoder Loss:  0.51744395
Encoder Loss:  0.1985529  || Decoder Loss:  0.23295613 Validation Decoder Loss:  0.51791316
Encoder Loss:  0.1982086  || Decoder Loss:  0.23302588 Validation Decoder Loss:  0.5184278
Encoder Loss:  0.19788271  || Decoder Loss:  0.23311815 Validation Decoder Loss:  0.5189512
Encoder Loss:  0.19757977  || Decoder Loss:  0.23323803 Validation Decoder Loss:  0.51948035
Encoder Loss:  0.19729742  || Decoder Loss:  0.2333817 Validation Decoder Loss:  0.5200549
Encoder Loss:  0.19703151  || Decoder Loss:  0.23354188 Validation Decoder Loss:  0.52064615
Encoder Loss:  0.19679157  || Decoder Loss:  0.23373187 Validation Decoder Loss:  0.5212603
Encoder Loss:  0.19658129  || Decoder Loss:  0.23395744 Validation Decoder Loss:  0.5219287
Encoder Loss:  0.1963898  || Decoder Loss:  0.2342048 Validation Decoder Loss:  0.52263284
Encoder Loss:  0.19621994  || Decoder Loss:  0.23447701 Validation Decoder Loss:  0.5233836
Encoder Loss:  0.19606861  || Decoder Loss:  0.23477098 Validation Decoder Loss:  0.5241591
Encoder Loss:  0.1959224  || Decoder Loss:  0.23506895 Validation Decoder Loss:  0.5249418
Encoder Loss:  0.19578366  || Decoder Loss:  0.23537345 Validation Decoder Loss:  0.5258734
Encoder Loss:  0.19565322  || Decoder Loss:  0.23568682 Validation Decoder Loss:  0.5268766
Encoder Loss:  0.19552019  || Decoder Loss:  0.23599172 Validation Decoder Loss:  0.52793455
Encoder Loss:  0.19538762  || Decoder Loss:  0.23629704 Validation Decoder Loss:  0.5290452
Encoder Loss:  0.19524714  || Decoder Loss:  0.23658995 Validation Decoder Loss:  0.53011245
Encoder Loss:  0.19509886  || Decoder Loss:  0.23686643 Validation Decoder Loss:  0.53114414
Encoder Loss:  0.19495103  || Decoder Loss:  0.23713951 Validation Decoder Loss:  0.5322397
Model: bold_synthesis_net_lr_0.0007109316966828153 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.53223974
NAS BO
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_7 (Reshape)          (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 420, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331415
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.078991696  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4933142
NAS BO
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_8 (Reshape)          (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14137645  || Decoder Loss:  0.23791008 Validation Decoder Loss:  0.49956253
Encoder Loss:  0.14109662  || Decoder Loss:  0.23776321 Validation Decoder Loss:  0.49949786
Encoder Loss:  0.14082964  || Decoder Loss:  0.23762596 Validation Decoder Loss:  0.4994341
Encoder Loss:  0.14056316  || Decoder Loss:  0.23749325 Validation Decoder Loss:  0.49937084
Encoder Loss:  0.14030251  || Decoder Loss:  0.23736568 Validation Decoder Loss:  0.4993094
Encoder Loss:  0.14004727  || Decoder Loss:  0.23724177 Validation Decoder Loss:  0.49924675
Encoder Loss:  0.1397987  || Decoder Loss:  0.23712197 Validation Decoder Loss:  0.49918565
Encoder Loss:  0.1395737  || Decoder Loss:  0.237009 Validation Decoder Loss:  0.49913034
Encoder Loss:  0.13935971  || Decoder Loss:  0.236902 Validation Decoder Loss:  0.49907777
Encoder Loss:  0.13914645  || Decoder Loss:  0.23679963 Validation Decoder Loss:  0.49902594
Encoder Loss:  0.13894469  || Decoder Loss:  0.23670144 Validation Decoder Loss:  0.4989759
Encoder Loss:  0.1387563  || Decoder Loss:  0.23660848 Validation Decoder Loss:  0.49892917
Encoder Loss:  0.13858114  || Decoder Loss:  0.23652014 Validation Decoder Loss:  0.49888623
Encoder Loss:  0.13841073  || Decoder Loss:  0.23643525 Validation Decoder Loss:  0.49884468
Encoder Loss:  0.13824356  || Decoder Loss:  0.23635213 Validation Decoder Loss:  0.49880436
Encoder Loss:  0.13808192  || Decoder Loss:  0.23627174 Validation Decoder Loss:  0.4987664
Encoder Loss:  0.13792296  || Decoder Loss:  0.23619378 Validation Decoder Loss:  0.49873105
Encoder Loss:  0.13776629  || Decoder Loss:  0.23611812 Validation Decoder Loss:  0.49869838
Encoder Loss:  0.13760929  || Decoder Loss:  0.2360456 Validation Decoder Loss:  0.49866733
Encoder Loss:  0.13745144  || Decoder Loss:  0.2359745 Validation Decoder Loss:  0.4986361
Encoder Loss:  0.13729452  || Decoder Loss:  0.23590434 Validation Decoder Loss:  0.49860448
Encoder Loss:  0.13714103  || Decoder Loss:  0.23583546 Validation Decoder Loss:  0.4985753
Encoder Loss:  0.13698965  || Decoder Loss:  0.23576827 Validation Decoder Loss:  0.49854973
Encoder Loss:  0.1368478  || Decoder Loss:  0.23570445 Validation Decoder Loss:  0.49853075
Encoder Loss:  0.13670717  || Decoder Loss:  0.23564222 Validation Decoder Loss:  0.49851644
Encoder Loss:  0.13656542  || Decoder Loss:  0.23558056 Validation Decoder Loss:  0.49850678
Encoder Loss:  0.13643059  || Decoder Loss:  0.23552182 Validation Decoder Loss:  0.4984988
Encoder Loss:  0.13630271  || Decoder Loss:  0.23546585 Validation Decoder Loss:  0.49849197
Encoder Loss:  0.13617831  || Decoder Loss:  0.23541173 Validation Decoder Loss:  0.49848542
Encoder Loss:  0.13606521  || Decoder Loss:  0.23536184 Validation Decoder Loss:  0.4984792
Encoder Loss:  0.135956  || Decoder Loss:  0.23531465 Validation Decoder Loss:  0.49847358
Encoder Loss:  0.13585077  || Decoder Loss:  0.23526962 Validation Decoder Loss:  0.49846753
Encoder Loss:  0.13574585  || Decoder Loss:  0.23522568 Validation Decoder Loss:  0.49846202
Encoder Loss:  0.13564137  || Decoder Loss:  0.2351828 Validation Decoder Loss:  0.49845636
Encoder Loss:  0.13554148  || Decoder Loss:  0.23514274 Validation Decoder Loss:  0.49845013
Encoder Loss:  0.13544163  || Decoder Loss:  0.23510396 Validation Decoder Loss:  0.49844465
Encoder Loss:  0.13534276  || Decoder Loss:  0.2350662 Validation Decoder Loss:  0.49843892
Encoder Loss:  0.13524435  || Decoder Loss:  0.23502979 Validation Decoder Loss:  0.49843276
Encoder Loss:  0.13514706  || Decoder Loss:  0.23499401 Validation Decoder Loss:  0.49842724
Encoder Loss:  0.13504875  || Decoder Loss:  0.23495841 Validation Decoder Loss:  0.49842414
Model: bold_synthesis_net_lr_7.269442735834086e-05 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49842414
NAS BO
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_9 (Reshape)          (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4631296
NAS BO
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_10 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49331418
NAS BO
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 80, 9, 14, 1)      86        
_________________________________________________________________
reshape_11 (Reshape)         (None, 720, 14, 1)        0         
=================================================================
Total params: 86
Trainable params: 86
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 720, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 874, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19040814  || Decoder Loss:  0.22187959 Validation Decoder Loss:  0.5170054
Encoder Loss:  0.18920818  || Decoder Loss:  0.22147733 Validation Decoder Loss:  0.51610464
Encoder Loss:  0.18788692  || Decoder Loss:  0.22113037 Validation Decoder Loss:  0.5151972
Encoder Loss:  0.1864542  || Decoder Loss:  0.22082593 Validation Decoder Loss:  0.5143143
Encoder Loss:  0.18493481  || Decoder Loss:  0.22054301 Validation Decoder Loss:  0.51338696
Encoder Loss:  0.18336691  || Decoder Loss:  0.22025138 Validation Decoder Loss:  0.5124121
Encoder Loss:  0.18183647  || Decoder Loss:  0.21995506 Validation Decoder Loss:  0.5114165
Encoder Loss:  0.18036729  || Decoder Loss:  0.21961945 Validation Decoder Loss:  0.51034474
Encoder Loss:  0.17899588  || Decoder Loss:  0.2193104 Validation Decoder Loss:  0.5095023
Encoder Loss:  0.17787373  || Decoder Loss:  0.21914837 Validation Decoder Loss:  0.5087857
Encoder Loss:  0.17687906  || Decoder Loss:  0.21905135 Validation Decoder Loss:  0.5082435
Encoder Loss:  0.17608564  || Decoder Loss:  0.21901105 Validation Decoder Loss:  0.5078444
Encoder Loss:  0.175471  || Decoder Loss:  0.21904157 Validation Decoder Loss:  0.5074382
Encoder Loss:  0.17503485  || Decoder Loss:  0.21907887 Validation Decoder Loss:  0.50716776
Encoder Loss:  0.17474367  || Decoder Loss:  0.2191521 Validation Decoder Loss:  0.50688314
Encoder Loss:  0.17452113  || Decoder Loss:  0.21918818 Validation Decoder Loss:  0.5064776
Encoder Loss:  0.17426644  || Decoder Loss:  0.2190536 Validation Decoder Loss:  0.505925
Encoder Loss:  0.17400713  || Decoder Loss:  0.2188416 Validation Decoder Loss:  0.50523305
Encoder Loss:  0.17369317  || Decoder Loss:  0.21852495 Validation Decoder Loss:  0.50443286
Encoder Loss:  0.17335086  || Decoder Loss:  0.21815147 Validation Decoder Loss:  0.50357974
Encoder Loss:  0.17298554  || Decoder Loss:  0.21774416 Validation Decoder Loss:  0.50266
Encoder Loss:  0.17261311  || Decoder Loss:  0.2173223 Validation Decoder Loss:  0.50152206
Encoder Loss:  0.17210257  || Decoder Loss:  0.21670505 Validation Decoder Loss:  0.5004272
Encoder Loss:  0.1717155  || Decoder Loss:  0.21625526 Validation Decoder Loss:  0.4996204
Encoder Loss:  0.17130725  || Decoder Loss:  0.21577388 Validation Decoder Loss:  0.49892402
Encoder Loss:  0.17098178  || Decoder Loss:  0.21540625 Validation Decoder Loss:  0.49844915
Encoder Loss:  0.17075127  || Decoder Loss:  0.2151699 Validation Decoder Loss:  0.49813107
Encoder Loss:  0.17055213  || Decoder Loss:  0.21497509 Validation Decoder Loss:  0.4977585
Encoder Loss:  0.17036003  || Decoder Loss:  0.21478617 Validation Decoder Loss:  0.49741408
Encoder Loss:  0.17017595  || Decoder Loss:  0.21460536 Validation Decoder Loss:  0.49721554
Encoder Loss:  0.17004308  || Decoder Loss:  0.21449184 Validation Decoder Loss:  0.4970447
Encoder Loss:  0.16992462  || Decoder Loss:  0.21439627 Validation Decoder Loss:  0.4968877
Encoder Loss:  0.16980693  || Decoder Loss:  0.21430221 Validation Decoder Loss:  0.496828
Encoder Loss:  0.16969697  || Decoder Loss:  0.21421443 Validation Decoder Loss:  0.49674907
Encoder Loss:  0.1695694  || Decoder Loss:  0.21410087 Validation Decoder Loss:  0.4966683
Encoder Loss:  0.16944373  || Decoder Loss:  0.21399109 Validation Decoder Loss:  0.4966244
Encoder Loss:  0.16930316  || Decoder Loss:  0.21386106 Validation Decoder Loss:  0.49657062
Encoder Loss:  0.1691683  || Decoder Loss:  0.21373802 Validation Decoder Loss:  0.49646735
Encoder Loss:  0.16904123  || Decoder Loss:  0.21362539 Validation Decoder Loss:  0.4964504
Encoder Loss:  0.16892834  || Decoder Loss:  0.21352915 Validation Decoder Loss:  0.49626878
Model: bold_synthesis_net_lr_0.00017391943182113966 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49626878
NAS BO
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 144, 5, 14, 1)     82        
_________________________________________________________________
reshape_12 (Reshape)         (None, 720, 14, 1)        0         
=================================================================
Total params: 82
Trainable params: 82
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 720, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 874, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09097835  || Decoder Loss:  0.22422752 Validation Decoder Loss:  0.5199858
Encoder Loss:  0.076625  || Decoder Loss:  0.2428905 Validation Decoder Loss:  0.5827529
Encoder Loss:  0.064953595  || Decoder Loss:  0.25857404 Validation Decoder Loss:  0.56619215
Encoder Loss:  0.05863615  || Decoder Loss:  0.22661012 Validation Decoder Loss:  0.59066725
Encoder Loss:  0.05578161  || Decoder Loss:  0.21255612 Validation Decoder Loss:  0.5944984
Encoder Loss:  0.054404166  || Decoder Loss:  0.20710282 Validation Decoder Loss:  0.5995907
Encoder Loss:  0.053604566  || Decoder Loss:  0.20488364 Validation Decoder Loss:  0.59823
Encoder Loss:  0.05298598  || Decoder Loss:  0.20363821 Validation Decoder Loss:  0.59752214
Encoder Loss:  0.052486993  || Decoder Loss:  0.20285738 Validation Decoder Loss:  0.59628594
Encoder Loss:  0.052105747  || Decoder Loss:  0.20226365 Validation Decoder Loss:  0.596283
Encoder Loss:  0.05179493  || Decoder Loss:  0.20176613 Validation Decoder Loss:  0.5964442
Encoder Loss:  0.05155486  || Decoder Loss:  0.2011836 Validation Decoder Loss:  0.59608746
Encoder Loss:  0.051363643  || Decoder Loss:  0.20051685 Validation Decoder Loss:  0.5957172
Encoder Loss:  0.051233128  || Decoder Loss:  0.199943 Validation Decoder Loss:  0.59587663
Encoder Loss:  0.051162694  || Decoder Loss:  0.19941527 Validation Decoder Loss:  0.5952738
Encoder Loss:  0.051118392  || Decoder Loss:  0.19885392 Validation Decoder Loss:  0.5943145
Encoder Loss:  0.051095456  || Decoder Loss:  0.19820273 Validation Decoder Loss:  0.5925081
Encoder Loss:  0.051078238  || Decoder Loss:  0.19743241 Validation Decoder Loss:  0.5898276
Encoder Loss:  0.051050536  || Decoder Loss:  0.19638237 Validation Decoder Loss:  0.5865687
Encoder Loss:  0.051051877  || Decoder Loss:  0.19467357 Validation Decoder Loss:  0.58477646
Encoder Loss:  0.05102313  || Decoder Loss:  0.19390908 Validation Decoder Loss:  0.5843352
Encoder Loss:  0.05101813  || Decoder Loss:  0.19365655 Validation Decoder Loss:  0.5846604
Encoder Loss:  0.05099987  || Decoder Loss:  0.19350463 Validation Decoder Loss:  0.5852509
Encoder Loss:  0.050986633  || Decoder Loss:  0.19337173 Validation Decoder Loss:  0.5857817
Encoder Loss:  0.05097723  || Decoder Loss:  0.19325577 Validation Decoder Loss:  0.5863927
Encoder Loss:  0.05098712  || Decoder Loss:  0.19313575 Validation Decoder Loss:  0.58702743
Encoder Loss:  0.050964113  || Decoder Loss:  0.1930285 Validation Decoder Loss:  0.58770865
Encoder Loss:  0.050951496  || Decoder Loss:  0.19294453 Validation Decoder Loss:  0.5882536
Encoder Loss:  0.05095129  || Decoder Loss:  0.19287027 Validation Decoder Loss:  0.5886967
Encoder Loss:  0.050945867  || Decoder Loss:  0.19280417 Validation Decoder Loss:  0.5889092
Encoder Loss:  0.05093167  || Decoder Loss:  0.19274132 Validation Decoder Loss:  0.58901316
Encoder Loss:  0.05092478  || Decoder Loss:  0.19267647 Validation Decoder Loss:  0.5890944
Encoder Loss:  0.05093003  || Decoder Loss:  0.19260627 Validation Decoder Loss:  0.5892926
Encoder Loss:  0.05091901  || Decoder Loss:  0.19254367 Validation Decoder Loss:  0.5894227
Encoder Loss:  0.050921753  || Decoder Loss:  0.19248804 Validation Decoder Loss:  0.5894252
Encoder Loss:  0.050918628  || Decoder Loss:  0.19242781 Validation Decoder Loss:  0.5893321
Encoder Loss:  0.05090248  || Decoder Loss:  0.19237435 Validation Decoder Loss:  0.58944273
Encoder Loss:  0.050905917  || Decoder Loss:  0.19231126 Validation Decoder Loss:  0.58937156
Encoder Loss:  0.05090492  || Decoder Loss:  0.19224916 Validation Decoder Loss:  0.5893424
Encoder Loss:  0.050911114  || Decoder Loss:  0.19219774 Validation Decoder Loss:  0.5894406
Model: bold_synthesis_net_lr_0.001 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5894406
NAS BO
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_13 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4631296
NAS BO
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_14 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 420, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.082353756  || Decoder Loss:  0.23723707 Validation Decoder Loss:  0.49991095
Encoder Loss:  0.08065606  || Decoder Loss:  0.23634246 Validation Decoder Loss:  0.5006295
Encoder Loss:  0.07917758  || Decoder Loss:  0.23584192 Validation Decoder Loss:  0.50164807
Encoder Loss:  0.07786809  || Decoder Loss:  0.23558918 Validation Decoder Loss:  0.50287735
Encoder Loss:  0.07669039  || Decoder Loss:  0.23552182 Validation Decoder Loss:  0.5042032
Encoder Loss:  0.0756427  || Decoder Loss:  0.23559336 Validation Decoder Loss:  0.50555426
Encoder Loss:  0.0746552  || Decoder Loss:  0.23574889 Validation Decoder Loss:  0.50700986
Encoder Loss:  0.07368316  || Decoder Loss:  0.2359914 Validation Decoder Loss:  0.50860804
Encoder Loss:  0.072716385  || Decoder Loss:  0.2362982 Validation Decoder Loss:  0.5103133
Encoder Loss:  0.07175626  || Decoder Loss:  0.23665965 Validation Decoder Loss:  0.5120971
Encoder Loss:  0.07079605  || Decoder Loss:  0.23708113 Validation Decoder Loss:  0.513935
Encoder Loss:  0.0698934  || Decoder Loss:  0.23753381 Validation Decoder Loss:  0.5156425
Encoder Loss:  0.06902428  || Decoder Loss:  0.23794885 Validation Decoder Loss:  0.51737976
Encoder Loss:  0.06818196  || Decoder Loss:  0.23835166 Validation Decoder Loss:  0.5191694
Encoder Loss:  0.06737328  || Decoder Loss:  0.23872764 Validation Decoder Loss:  0.5209118
Encoder Loss:  0.0666066  || Decoder Loss:  0.23905599 Validation Decoder Loss:  0.5224754
Encoder Loss:  0.0659012  || Decoder Loss:  0.23930052 Validation Decoder Loss:  0.52388704
Encoder Loss:  0.06523614  || Decoder Loss:  0.23948877 Validation Decoder Loss:  0.52503973
Encoder Loss:  0.06459946  || Decoder Loss:  0.2396164 Validation Decoder Loss:  0.5259726
Encoder Loss:  0.06396321  || Decoder Loss:  0.2396872 Validation Decoder Loss:  0.5268212
Encoder Loss:  0.06335163  || Decoder Loss:  0.23973234 Validation Decoder Loss:  0.52756095
Encoder Loss:  0.06276696  || Decoder Loss:  0.23976609 Validation Decoder Loss:  0.5280934
Encoder Loss:  0.062209822  || Decoder Loss:  0.23972937 Validation Decoder Loss:  0.52863824
Encoder Loss:  0.061634354  || Decoder Loss:  0.23967794 Validation Decoder Loss:  0.529444
Encoder Loss:  0.06109501  || Decoder Loss:  0.23963031 Validation Decoder Loss:  0.5306848
Encoder Loss:  0.06065167  || Decoder Loss:  0.23956175 Validation Decoder Loss:  0.5321528
Encoder Loss:  0.060308427  || Decoder Loss:  0.23949155 Validation Decoder Loss:  0.53366953
Encoder Loss:  0.060045302  || Decoder Loss:  0.23937044 Validation Decoder Loss:  0.53536874
Encoder Loss:  0.059868157  || Decoder Loss:  0.2392942 Validation Decoder Loss:  0.53690094
Encoder Loss:  0.059734534  || Decoder Loss:  0.23919275 Validation Decoder Loss:  0.538795
Encoder Loss:  0.05962311  || Decoder Loss:  0.23906526 Validation Decoder Loss:  0.54117566
Encoder Loss:  0.059517633  || Decoder Loss:  0.23891869 Validation Decoder Loss:  0.54375243
Encoder Loss:  0.059408776  || Decoder Loss:  0.23875865 Validation Decoder Loss:  0.54597497
Encoder Loss:  0.05929602  || Decoder Loss:  0.23856759 Validation Decoder Loss:  0.5478069
Encoder Loss:  0.059184514  || Decoder Loss:  0.2382296 Validation Decoder Loss:  0.55005324
Encoder Loss:  0.05907728  || Decoder Loss:  0.23777032 Validation Decoder Loss:  0.5526073
Encoder Loss:  0.058987755  || Decoder Loss:  0.23702586 Validation Decoder Loss:  0.5555737
Encoder Loss:  0.05890184  || Decoder Loss:  0.23599097 Validation Decoder Loss:  0.55954206
Encoder Loss:  0.05881214  || Decoder Loss:  0.23406771 Validation Decoder Loss:  0.5635459
Encoder Loss:  0.058728267  || Decoder Loss:  0.23098095 Validation Decoder Loss:  0.56448853
Model: bold_synthesis_net_lr_0.001 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.56448853
NAS BO
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_15 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.51594734
NAS BO
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_16 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49331418
NAS BO
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_17 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 420, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974373  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974374  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.07974373  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.51594734
NAS BO
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_18 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260207 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326185  || Decoder Loss:  0.23260204 Validation Decoder Loss:  0.51594734
Encoder Loss:  0.12326183  || Decoder Loss:  0.23260209 Validation Decoder Loss:  0.51594734
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.51594734
NAS BO
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_19 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799893 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4996342
NAS BO
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_20 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331415
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331415
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49331418
NAS BO
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 72, 10, 14, 1)     55        
_________________________________________________________________
reshape_21 (Reshape)         (None, 720, 14, 1)        0         
=================================================================
Total params: 55
Trainable params: 55
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 720, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 874, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1708748  || Decoder Loss:  0.22059457 Validation Decoder Loss:  0.5035374
Encoder Loss:  0.17023675  || Decoder Loss:  0.22035487 Validation Decoder Loss:  0.50339997
Encoder Loss:  0.16961625  || Decoder Loss:  0.22019 Validation Decoder Loss:  0.50319636
Encoder Loss:  0.16893883  || Decoder Loss:  0.22002152 Validation Decoder Loss:  0.50296617
Encoder Loss:  0.16820756  || Decoder Loss:  0.21985152 Validation Decoder Loss:  0.502695
Encoder Loss:  0.16742495  || Decoder Loss:  0.21967606 Validation Decoder Loss:  0.50240517
Encoder Loss:  0.16660044  || Decoder Loss:  0.21949771 Validation Decoder Loss:  0.50210243
Encoder Loss:  0.16574301  || Decoder Loss:  0.21931374 Validation Decoder Loss:  0.5017713
Encoder Loss:  0.164856  || Decoder Loss:  0.21912177 Validation Decoder Loss:  0.5014145
Encoder Loss:  0.1639433  || Decoder Loss:  0.21892104 Validation Decoder Loss:  0.5010202
Encoder Loss:  0.16301088  || Decoder Loss:  0.21871117 Validation Decoder Loss:  0.5005998
Encoder Loss:  0.1620642  || Decoder Loss:  0.21849279 Validation Decoder Loss:  0.50015527
Encoder Loss:  0.16111144  || Decoder Loss:  0.21826479 Validation Decoder Loss:  0.499648
Encoder Loss:  0.16015081  || Decoder Loss:  0.21802345 Validation Decoder Loss:  0.4990906
Encoder Loss:  0.1591893  || Decoder Loss:  0.2177757 Validation Decoder Loss:  0.4984966
Encoder Loss:  0.15823372  || Decoder Loss:  0.21753499 Validation Decoder Loss:  0.4978541
Encoder Loss:  0.15728089  || Decoder Loss:  0.21729179 Validation Decoder Loss:  0.497162
Encoder Loss:  0.15633819  || Decoder Loss:  0.21704361 Validation Decoder Loss:  0.49641383
Encoder Loss:  0.15541042  || Decoder Loss:  0.21680406 Validation Decoder Loss:  0.49565288
Encoder Loss:  0.1544943  || Decoder Loss:  0.21656851 Validation Decoder Loss:  0.4948407
Encoder Loss:  0.15358314  || Decoder Loss:  0.21632726 Validation Decoder Loss:  0.4940137
Encoder Loss:  0.15267603  || Decoder Loss:  0.21607856 Validation Decoder Loss:  0.4931861
Encoder Loss:  0.15178636  || Decoder Loss:  0.21583323 Validation Decoder Loss:  0.49233902
Encoder Loss:  0.15090525  || Decoder Loss:  0.21558633 Validation Decoder Loss:  0.49144715
Encoder Loss:  0.15002729  || Decoder Loss:  0.21533152 Validation Decoder Loss:  0.49059692
Encoder Loss:  0.14916337  || Decoder Loss:  0.21508682 Validation Decoder Loss:  0.48983574
Encoder Loss:  0.1483359  || Decoder Loss:  0.2148689 Validation Decoder Loss:  0.4891095
Encoder Loss:  0.14753725  || Decoder Loss:  0.21466923 Validation Decoder Loss:  0.48851737
Encoder Loss:  0.14678666  || Decoder Loss:  0.2144936 Validation Decoder Loss:  0.4879101
Encoder Loss:  0.1460626  || Decoder Loss:  0.21431163 Validation Decoder Loss:  0.48725137
Encoder Loss:  0.1453621  || Decoder Loss:  0.21414371 Validation Decoder Loss:  0.48661554
Encoder Loss:  0.14467631  || Decoder Loss:  0.2139813 Validation Decoder Loss:  0.48590854
Encoder Loss:  0.14401259  || Decoder Loss:  0.21382806 Validation Decoder Loss:  0.48515296
Encoder Loss:  0.14338292  || Decoder Loss:  0.21368471 Validation Decoder Loss:  0.48458838
Encoder Loss:  0.14281675  || Decoder Loss:  0.21360035 Validation Decoder Loss:  0.4840287
Encoder Loss:  0.14231052  || Decoder Loss:  0.21351996 Validation Decoder Loss:  0.48346135
Encoder Loss:  0.1418452  || Decoder Loss:  0.21344252 Validation Decoder Loss:  0.48301184
Encoder Loss:  0.1414054  || Decoder Loss:  0.21335924 Validation Decoder Loss:  0.48255944
Encoder Loss:  0.14096704  || Decoder Loss:  0.21320441 Validation Decoder Loss:  0.4822671
Encoder Loss:  0.14055467  || Decoder Loss:  0.21293218 Validation Decoder Loss:  0.4814632
Model: bold_synthesis_net_lr_0.0005406965315040052 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4814632
NAS BO
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 90, 8, 14, 1)      109       
_________________________________________________________________
reshape_22 (Reshape)         (None, 720, 14, 1)        0         
=================================================================
Total params: 109
Trainable params: 109
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 720, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 874, 14, 1)        156       
=================================================================
Total params: 156
Trainable params: 156
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1705819  || Decoder Loss:  0.22266276 Validation Decoder Loss:  0.523661
Encoder Loss:  0.16985044  || Decoder Loss:  0.22222106 Validation Decoder Loss:  0.5228285
Encoder Loss:  0.16911872  || Decoder Loss:  0.22183597 Validation Decoder Loss:  0.5219808
Encoder Loss:  0.16835967  || Decoder Loss:  0.22145967 Validation Decoder Loss:  0.52113456
Encoder Loss:  0.16757533  || Decoder Loss:  0.22110768 Validation Decoder Loss:  0.52023387
Encoder Loss:  0.16677219  || Decoder Loss:  0.22078104 Validation Decoder Loss:  0.5193457
Encoder Loss:  0.16596313  || Decoder Loss:  0.22049852 Validation Decoder Loss:  0.5184548
Encoder Loss:  0.1651431  || Decoder Loss:  0.22024158 Validation Decoder Loss:  0.51748896
Encoder Loss:  0.16430584  || Decoder Loss:  0.21998659 Validation Decoder Loss:  0.5164779
Encoder Loss:  0.16346379  || Decoder Loss:  0.21975927 Validation Decoder Loss:  0.51542085
Encoder Loss:  0.16270834  || Decoder Loss:  0.21974477 Validation Decoder Loss:  0.51426804
Encoder Loss:  0.1620876  || Decoder Loss:  0.22003749 Validation Decoder Loss:  0.5129968
Encoder Loss:  0.16159791  || Decoder Loss:  0.22062497 Validation Decoder Loss:  0.51170045
Encoder Loss:  0.16116688  || Decoder Loss:  0.22136883 Validation Decoder Loss:  0.5104837
Encoder Loss:  0.16084829  || Decoder Loss:  0.22235158 Validation Decoder Loss:  0.51014304
Encoder Loss:  0.16084823  || Decoder Loss:  0.223967 Validation Decoder Loss:  0.51143205
Encoder Loss:  0.16143283  || Decoder Loss:  0.22672853 Validation Decoder Loss:  0.5146003
Encoder Loss:  0.16227977  || Decoder Loss:  0.23003133 Validation Decoder Loss:  0.51952
Encoder Loss:  0.16308737  || Decoder Loss:  0.2332799 Validation Decoder Loss:  0.52510375
Encoder Loss:  0.16376108  || Decoder Loss:  0.23628628 Validation Decoder Loss:  0.532563
Encoder Loss:  0.16423431  || Decoder Loss:  0.23891687 Validation Decoder Loss:  0.53933966
Encoder Loss:  0.1645194  || Decoder Loss:  0.2411309 Validation Decoder Loss:  0.54464024
Encoder Loss:  0.16457424  || Decoder Loss:  0.24282017 Validation Decoder Loss:  0.5482967
Encoder Loss:  0.16436838  || Decoder Loss:  0.24396427 Validation Decoder Loss:  0.5503738
Encoder Loss:  0.16354322  || Decoder Loss:  0.24387598 Validation Decoder Loss:  0.5499069
Encoder Loss:  0.16166301  || Decoder Loss:  0.24166319 Validation Decoder Loss:  0.54679084
Encoder Loss:  0.15981258  || Decoder Loss:  0.239414 Validation Decoder Loss:  0.54226595
Encoder Loss:  0.15801165  || Decoder Loss:  0.23718531 Validation Decoder Loss:  0.53860354
Encoder Loss:  0.1563813  || Decoder Loss:  0.23520088 Validation Decoder Loss:  0.53553903
Encoder Loss:  0.15507191  || Decoder Loss:  0.233772 Validation Decoder Loss:  0.534147
Encoder Loss:  0.15412515  || Decoder Loss:  0.23292904 Validation Decoder Loss:  0.532938
Encoder Loss:  0.15347932  || Decoder Loss:  0.23246455 Validation Decoder Loss:  0.53188515
Encoder Loss:  0.15298167  || Decoder Loss:  0.23215425 Validation Decoder Loss:  0.53070104
Encoder Loss:  0.15258567  || Decoder Loss:  0.23192313 Validation Decoder Loss:  0.5293851
Encoder Loss:  0.1522833  || Decoder Loss:  0.23175707 Validation Decoder Loss:  0.52805686
Encoder Loss:  0.15201753  || Decoder Loss:  0.23163164 Validation Decoder Loss:  0.52680975
Encoder Loss:  0.15178303  || Decoder Loss:  0.23153427 Validation Decoder Loss:  0.5254483
Encoder Loss:  0.15157488  || Decoder Loss:  0.23147242 Validation Decoder Loss:  0.5243518
Encoder Loss:  0.15140536  || Decoder Loss:  0.23144364 Validation Decoder Loss:  0.52370244
Encoder Loss:  0.15123536  || Decoder Loss:  0.23140152 Validation Decoder Loss:  0.5237316
Model: bold_synthesis_net_lr_0.0005406796894592723 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5237316
NAS BO
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_23 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224594  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Encoder Loss:  0.13224596  || Decoder Loss:  0.21602681 Validation Decoder Loss:  0.4631296
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4631296
NAS BO
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 77, 10, 14, 1)     85        
_________________________________________________________________
reshape_24 (Reshape)         (None, 770, 14, 1)        0         
=================================================================
Total params: 85
Trainable params: 85
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 770, 14, 1)        106       
=================================================================
Total params: 106
Trainable params: 106
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 874, 14, 1)        106       
=================================================================
Total params: 106
Trainable params: 106
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18597442  || Decoder Loss:  0.2216531 Validation Decoder Loss:  0.5076405
Encoder Loss:  0.17569284  || Decoder Loss:  0.21819782 Validation Decoder Loss:  0.49041474
Encoder Loss:  0.16795783  || Decoder Loss:  0.21321279 Validation Decoder Loss:  0.52392054
Encoder Loss:  0.16667587  || Decoder Loss:  0.21250112 Validation Decoder Loss:  0.57657754
Encoder Loss:  0.16150865  || Decoder Loss:  0.2058933 Validation Decoder Loss:  0.592334
Encoder Loss:  0.15700196  || Decoder Loss:  0.19977246 Validation Decoder Loss:  0.5952224
Encoder Loss:  0.15482405  || Decoder Loss:  0.19679774 Validation Decoder Loss:  0.6009048
Encoder Loss:  0.15338783  || Decoder Loss:  0.19482681 Validation Decoder Loss:  0.6087403
Encoder Loss:  0.15250456  || Decoder Loss:  0.19361337 Validation Decoder Loss:  0.6153181
Encoder Loss:  0.15244225  || Decoder Loss:  0.19354081 Validation Decoder Loss:  0.6233839
Encoder Loss:  0.15221478  || Decoder Loss:  0.19323032 Validation Decoder Loss:  0.6276039
Encoder Loss:  0.15201841  || Decoder Loss:  0.19295496 Validation Decoder Loss:  0.62980986
Encoder Loss:  0.15158816  || Decoder Loss:  0.19236077 Validation Decoder Loss:  0.63196343
Encoder Loss:  0.15121837  || Decoder Loss:  0.191838 Validation Decoder Loss:  0.63336
Encoder Loss:  0.15089206  || Decoder Loss:  0.191393 Validation Decoder Loss:  0.632601
Encoder Loss:  0.15059274  || Decoder Loss:  0.1909725 Validation Decoder Loss:  0.6328749
Encoder Loss:  0.15031931  || Decoder Loss:  0.1905853 Validation Decoder Loss:  0.63211954
Encoder Loss:  0.14992188  || Decoder Loss:  0.19003326 Validation Decoder Loss:  0.6340197
Encoder Loss:  0.14972027  || Decoder Loss:  0.18975414 Validation Decoder Loss:  0.6347395
Encoder Loss:  0.14954512  || Decoder Loss:  0.18950614 Validation Decoder Loss:  0.63488907
Encoder Loss:  0.14937732  || Decoder Loss:  0.18927355 Validation Decoder Loss:  0.6348996
Encoder Loss:  0.1493136  || Decoder Loss:  0.18918468 Validation Decoder Loss:  0.6340856
Encoder Loss:  0.14921959  || Decoder Loss:  0.18905461 Validation Decoder Loss:  0.63382876
Encoder Loss:  0.14912236  || Decoder Loss:  0.18892111 Validation Decoder Loss:  0.63415277
Encoder Loss:  0.149025  || Decoder Loss:  0.18878247 Validation Decoder Loss:  0.6342236
Encoder Loss:  0.14899623  || Decoder Loss:  0.18874365 Validation Decoder Loss:  0.63396466
Encoder Loss:  0.14891778  || Decoder Loss:  0.18863364 Validation Decoder Loss:  0.633215
Encoder Loss:  0.14888166  || Decoder Loss:  0.18858188 Validation Decoder Loss:  0.632784
Encoder Loss:  0.14878023  || Decoder Loss:  0.18844193 Validation Decoder Loss:  0.6323594
Encoder Loss:  0.14875385  || Decoder Loss:  0.1884009 Validation Decoder Loss:  0.63304436
Encoder Loss:  0.14873679  || Decoder Loss:  0.18837284 Validation Decoder Loss:  0.63255143
Encoder Loss:  0.14868194  || Decoder Loss:  0.1883103 Validation Decoder Loss:  0.6322781
Encoder Loss:  0.14863719  || Decoder Loss:  0.18824305 Validation Decoder Loss:  0.6323374
Encoder Loss:  0.14861166  || Decoder Loss:  0.18820296 Validation Decoder Loss:  0.63140094
Encoder Loss:  0.14856452  || Decoder Loss:  0.18813853 Validation Decoder Loss:  0.6314826
Encoder Loss:  0.14852342  || Decoder Loss:  0.18808606 Validation Decoder Loss:  0.6325047
Encoder Loss:  0.14838532  || Decoder Loss:  0.18789129 Validation Decoder Loss:  0.63332593
Encoder Loss:  0.14831406  || Decoder Loss:  0.18778831 Validation Decoder Loss:  0.6333761
Encoder Loss:  0.14823937  || Decoder Loss:  0.18768866 Validation Decoder Loss:  0.63259363
Encoder Loss:  0.1482022  || Decoder Loss:  0.18763553 Validation Decoder Loss:  0.63218325
Model: bold_synthesis_net_lr_0.0006287449843590145 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.63218325
NAS BO
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 74, 5, 14, 1)      12        
_________________________________________________________________
reshape_25 (Reshape)         (None, 370, 14, 1)        0         
=================================================================
Total params: 12
Trainable params: 12
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 370, 14, 1)        506       
=================================================================
Total params: 506
Trainable params: 506
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 874, 14, 1)        137       
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13102846  || Decoder Loss:  0.24127242 Validation Decoder Loss:  0.49106547
Encoder Loss:  0.12919989  || Decoder Loss:  0.23712857 Validation Decoder Loss:  0.49097428
Encoder Loss:  0.12837665  || Decoder Loss:  0.23517218 Validation Decoder Loss:  0.49066612
Encoder Loss:  0.12758279  || Decoder Loss:  0.23419341 Validation Decoder Loss:  0.49022785
Encoder Loss:  0.12670751  || Decoder Loss:  0.23365037 Validation Decoder Loss:  0.4897722
Encoder Loss:  0.12572366  || Decoder Loss:  0.23318207 Validation Decoder Loss:  0.48935848
Encoder Loss:  0.124644555  || Decoder Loss:  0.23273745 Validation Decoder Loss:  0.48898277
Encoder Loss:  0.12345954  || Decoder Loss:  0.23230608 Validation Decoder Loss:  0.4886663
Encoder Loss:  0.12217392  || Decoder Loss:  0.23189871 Validation Decoder Loss:  0.48844585
Encoder Loss:  0.12078373  || Decoder Loss:  0.23149543 Validation Decoder Loss:  0.48839954
Encoder Loss:  0.119305074  || Decoder Loss:  0.2310638 Validation Decoder Loss:  0.4884773
Encoder Loss:  0.11774661  || Decoder Loss:  0.2306114 Validation Decoder Loss:  0.48872393
Encoder Loss:  0.11611929  || Decoder Loss:  0.23015389 Validation Decoder Loss:  0.48909378
Encoder Loss:  0.11443994  || Decoder Loss:  0.22970673 Validation Decoder Loss:  0.48970193
Encoder Loss:  0.11271852  || Decoder Loss:  0.22926894 Validation Decoder Loss:  0.49060538
Encoder Loss:  0.11099817  || Decoder Loss:  0.22890794 Validation Decoder Loss:  0.4916688
Encoder Loss:  0.10925336  || Decoder Loss:  0.22859588 Validation Decoder Loss:  0.49302277
Encoder Loss:  0.10748617  || Decoder Loss:  0.22820611 Validation Decoder Loss:  0.4946949
Encoder Loss:  0.105710484  || Decoder Loss:  0.2277422 Validation Decoder Loss:  0.49647728
Encoder Loss:  0.103926614  || Decoder Loss:  0.22726765 Validation Decoder Loss:  0.49832436
Encoder Loss:  0.10213278  || Decoder Loss:  0.22679046 Validation Decoder Loss:  0.50049967
Encoder Loss:  0.10032936  || Decoder Loss:  0.22630723 Validation Decoder Loss:  0.5028875
Encoder Loss:  0.0985129  || Decoder Loss:  0.22578244 Validation Decoder Loss:  0.50564164
Encoder Loss:  0.0966933  || Decoder Loss:  0.22527607 Validation Decoder Loss:  0.5084221
Encoder Loss:  0.09486072  || Decoder Loss:  0.2247734 Validation Decoder Loss:  0.511357
Encoder Loss:  0.09298883  || Decoder Loss:  0.22424316 Validation Decoder Loss:  0.5142776
Encoder Loss:  0.09107576  || Decoder Loss:  0.22367077 Validation Decoder Loss:  0.5165951
Encoder Loss:  0.08915042  || Decoder Loss:  0.2231493 Validation Decoder Loss:  0.5177653
Encoder Loss:  0.08720951  || Decoder Loss:  0.22267005 Validation Decoder Loss:  0.51841986
Encoder Loss:  0.0853258  || Decoder Loss:  0.22228488 Validation Decoder Loss:  0.51910925
Encoder Loss:  0.08348001  || Decoder Loss:  0.22204113 Validation Decoder Loss:  0.5199911
Encoder Loss:  0.0816709  || Decoder Loss:  0.2219327 Validation Decoder Loss:  0.5213278
Encoder Loss:  0.07992579  || Decoder Loss:  0.22184107 Validation Decoder Loss:  0.522838
Encoder Loss:  0.0782492  || Decoder Loss:  0.2217401 Validation Decoder Loss:  0.52458364
Encoder Loss:  0.07667773  || Decoder Loss:  0.2217226 Validation Decoder Loss:  0.52690804
Encoder Loss:  0.07521803  || Decoder Loss:  0.22168712 Validation Decoder Loss:  0.52910596
Encoder Loss:  0.07384679  || Decoder Loss:  0.22169118 Validation Decoder Loss:  0.5310027
Encoder Loss:  0.072596334  || Decoder Loss:  0.22177526 Validation Decoder Loss:  0.53302807
Encoder Loss:  0.07140207  || Decoder Loss:  0.22159891 Validation Decoder Loss:  0.5359216
Encoder Loss:  0.0703968  || Decoder Loss:  0.2211223 Validation Decoder Loss:  0.5403656
Model: bold_synthesis_net_lr_0.000994652677734217 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5403656
NAS BO
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 70, 6, 14, 1)      15        
_________________________________________________________________
reshape_26 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 15
Trainable params: 15
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 874, 14, 1)        37        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799893 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224594  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Encoder Loss:  0.13224596  || Decoder Loss:  0.23799892 Validation Decoder Loss:  0.4996342
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4996342
NAS BO
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_27 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326185  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.49331418
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Encoder Loss:  0.12326183  || Decoder Loss:  0.21864907 Validation Decoder Loss:  0.4933142
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4933142
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_28 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 420, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 874, 14, 1)        456       
=================================================================
Total params: 456
Trainable params: 456
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [1.00e-14 1.00e-04 1.00e+00 1.00e+00 1.00e+00 1.28e+02 4.20e+02]
Optimized Validation Decoder Loss: 0.46312960982322693











Optimizing at level  2
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_87 (Dropout)         (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_31 (Conv3DT (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_29 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 570, 14, 1)        306       
_________________________________________________________________
dropout_89 (Dropout)         (None, 570, 14, 1)        0         
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 420, 14, 1)        152       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 620, 14, 1)        202       
_________________________________________________________________
dropout_91 (Dropout)         (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_30 (Conv2DT (None, 874, 14, 1)        256       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19332366  || Decoder Loss:  0.2520185 Validation Decoder Loss:  0.49513355
Encoder Loss:  0.18668236  || Decoder Loss:  0.2427558 Validation Decoder Loss:  0.49399388
Encoder Loss:  0.18200943  || Decoder Loss:  0.23621304 Validation Decoder Loss:  0.4938613
Encoder Loss:  0.17869782  || Decoder Loss:  0.23153993 Validation Decoder Loss:  0.49414766
Encoder Loss:  0.17658105  || Decoder Loss:  0.22850078 Validation Decoder Loss:  0.49445558
Encoder Loss:  0.17500477  || Decoder Loss:  0.22628999 Validation Decoder Loss:  0.4947511
Encoder Loss:  0.17355442  || Decoder Loss:  0.22437774 Validation Decoder Loss:  0.49505836
Encoder Loss:  0.17230736  || Decoder Loss:  0.22292554 Validation Decoder Loss:  0.49514335
Encoder Loss:  0.17103837  || Decoder Loss:  0.22161539 Validation Decoder Loss:  0.49532288
Encoder Loss:  0.16970511  || Decoder Loss:  0.22037357 Validation Decoder Loss:  0.49551708
Encoder Loss:  0.16832595  || Decoder Loss:  0.21924469 Validation Decoder Loss:  0.495785
Encoder Loss:  0.16682565  || Decoder Loss:  0.21812166 Validation Decoder Loss:  0.49621427
Encoder Loss:  0.16520491  || Decoder Loss:  0.21699092 Validation Decoder Loss:  0.49682662
Encoder Loss:  0.16346434  || Decoder Loss:  0.21583857 Validation Decoder Loss:  0.49743465
Encoder Loss:  0.16154829  || Decoder Loss:  0.21462215 Validation Decoder Loss:  0.49817863
Encoder Loss:  0.15976594  || Decoder Loss:  0.21390337 Validation Decoder Loss:  0.4994134
Encoder Loss:  0.15797484  || Decoder Loss:  0.21330485 Validation Decoder Loss:  0.5008465
Encoder Loss:  0.15625252  || Decoder Loss:  0.21280923 Validation Decoder Loss:  0.5028469
Encoder Loss:  0.15472604  || Decoder Loss:  0.21258426 Validation Decoder Loss:  0.5049064
Encoder Loss:  0.15349501  || Decoder Loss:  0.2127467 Validation Decoder Loss:  0.50724757
Encoder Loss:  0.15258579  || Decoder Loss:  0.2132916 Validation Decoder Loss:  0.509836
Encoder Loss:  0.15200214  || Decoder Loss:  0.21416973 Validation Decoder Loss:  0.5119883
Encoder Loss:  0.15166795  || Decoder Loss:  0.21520533 Validation Decoder Loss:  0.5140411
Encoder Loss:  0.15153325  || Decoder Loss:  0.21638562 Validation Decoder Loss:  0.51609236
Encoder Loss:  0.15142885  || Decoder Loss:  0.21756364 Validation Decoder Loss:  0.51826483
Encoder Loss:  0.15137367  || Decoder Loss:  0.21875763 Validation Decoder Loss:  0.52047724
Encoder Loss:  0.1513052  || Decoder Loss:  0.219916 Validation Decoder Loss:  0.5220648
Encoder Loss:  0.15104106  || Decoder Loss:  0.22067617 Validation Decoder Loss:  0.522815
Encoder Loss:  0.15047187  || Decoder Loss:  0.22093213 Validation Decoder Loss:  0.5227547
Encoder Loss:  0.14995264  || Decoder Loss:  0.22124189 Validation Decoder Loss:  0.52310544
Encoder Loss:  0.1494285  || Decoder Loss:  0.22151276 Validation Decoder Loss:  0.5230703
Encoder Loss:  0.14879529  || Decoder Loss:  0.22152025 Validation Decoder Loss:  0.52259696
Encoder Loss:  0.1480472  || Decoder Loss:  0.22116855 Validation Decoder Loss:  0.5211287
Encoder Loss:  0.1471578  || Decoder Loss:  0.2202877 Validation Decoder Loss:  0.5188853
Encoder Loss:  0.14612196  || Decoder Loss:  0.21898809 Validation Decoder Loss:  0.5162447
Encoder Loss:  0.14506646  || Decoder Loss:  0.21760371 Validation Decoder Loss:  0.51371074
Encoder Loss:  0.14407636  || Decoder Loss:  0.21633185 Validation Decoder Loss:  0.51138294
Encoder Loss:  0.14313403  || Decoder Loss:  0.21512827 Validation Decoder Loss:  0.50953466
Encoder Loss:  0.1422321  || Decoder Loss:  0.21399559 Validation Decoder Loss:  0.5078406
Encoder Loss:  0.1412847  || Decoder Loss:  0.21275376 Validation Decoder Loss:  0.50812083
Model: bold_synthesis_net_lr_0.0001368496617742831 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50812083
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_93 (Dropout)         (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_34 (Conv3DT (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_30 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 490, 14, 1)        386       
_________________________________________________________________
dropout_95 (Dropout)         (None, 490, 14, 1)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 420, 14, 1)        72        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 830, 14, 1)        412       
_________________________________________________________________
dropout_97 (Dropout)         (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_32 (Conv2DT (None, 874, 14, 1)        46        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18479513  || Decoder Loss:  0.23520671 Validation Decoder Loss:  0.4937543
Encoder Loss:  0.1686267  || Decoder Loss:  0.21832633 Validation Decoder Loss:  0.48915553
Encoder Loss:  0.14997616  || Decoder Loss:  0.21299022 Validation Decoder Loss:  0.47884193
Encoder Loss:  0.14157622  || Decoder Loss:  0.21004376 Validation Decoder Loss:  0.47351506
Encoder Loss:  0.14033023  || Decoder Loss:  0.20831382 Validation Decoder Loss:  0.47083905
Encoder Loss:  0.13939191  || Decoder Loss:  0.2071161 Validation Decoder Loss:  0.46790543
Encoder Loss:  0.13832815  || Decoder Loss:  0.20570002 Validation Decoder Loss:  0.46420544
Encoder Loss:  0.13731696  || Decoder Loss:  0.20437826 Validation Decoder Loss:  0.46037126
Encoder Loss:  0.13680328  || Decoder Loss:  0.20388499 Validation Decoder Loss:  0.45893177
Encoder Loss:  0.1364764  || Decoder Loss:  0.20359872 Validation Decoder Loss:  0.457387
Encoder Loss:  0.13623808  || Decoder Loss:  0.20333646 Validation Decoder Loss:  0.45581296
Encoder Loss:  0.13596007  || Decoder Loss:  0.20297286 Validation Decoder Loss:  0.453924
Encoder Loss:  0.13556203  || Decoder Loss:  0.20237775 Validation Decoder Loss:  0.45118558
Encoder Loss:  0.13525674  || Decoder Loss:  0.20194863 Validation Decoder Loss:  0.44951558
Encoder Loss:  0.13519067  || Decoder Loss:  0.20194608 Validation Decoder Loss:  0.44837722
Encoder Loss:  0.13523069  || Decoder Loss:  0.20211692 Validation Decoder Loss:  0.44783208
Encoder Loss:  0.13532698  || Decoder Loss:  0.20238897 Validation Decoder Loss:  0.4466647
Encoder Loss:  0.13547528  || Decoder Loss:  0.20273432 Validation Decoder Loss:  0.44594115
Encoder Loss:  0.13535152  || Decoder Loss:  0.20256278 Validation Decoder Loss:  0.44759768
Encoder Loss:  0.13513364  || Decoder Loss:  0.20220633 Validation Decoder Loss:  0.44963828
Encoder Loss:  0.13494718  || Decoder Loss:  0.2019064 Validation Decoder Loss:  0.45133615
Encoder Loss:  0.13476667  || Decoder Loss:  0.20160928 Validation Decoder Loss:  0.4532448
Encoder Loss:  0.13456054  || Decoder Loss:  0.20126002 Validation Decoder Loss:  0.4557059
Encoder Loss:  0.13438858  || Decoder Loss:  0.20097464 Validation Decoder Loss:  0.45813373
Encoder Loss:  0.13421348  || Decoder Loss:  0.20067583 Validation Decoder Loss:  0.46078286
Encoder Loss:  0.13408716  || Decoder Loss:  0.20046449 Validation Decoder Loss:  0.46341982
Encoder Loss:  0.13401066  || Decoder Loss:  0.20033972 Validation Decoder Loss:  0.46591872
Encoder Loss:  0.133989  || Decoder Loss:  0.20031144 Validation Decoder Loss:  0.46839333
Encoder Loss:  0.13388894  || Decoder Loss:  0.20014188 Validation Decoder Loss:  0.4745827
Encoder Loss:  0.13324915  || Decoder Loss:  0.19900422 Validation Decoder Loss:  0.47794092
Encoder Loss:  0.13277401  || Decoder Loss:  0.19815607 Validation Decoder Loss:  0.47756386
Encoder Loss:  0.13266768  || Decoder Loss:  0.19797146 Validation Decoder Loss:  0.4804248
Encoder Loss:  0.13262112  || Decoder Loss:  0.19789399 Validation Decoder Loss:  0.4840783
Encoder Loss:  0.13260084  || Decoder Loss:  0.19786492 Validation Decoder Loss:  0.48803666
Encoder Loss:  0.1325756  || Decoder Loss:  0.19782417 Validation Decoder Loss:  0.49253723
Encoder Loss:  0.13252828  || Decoder Loss:  0.19774392 Validation Decoder Loss:  0.49687767
Encoder Loss:  0.13230191  || Decoder Loss:  0.19734108 Validation Decoder Loss:  0.52094656
Encoder Loss:  0.13177665  || Decoder Loss:  0.19639878 Validation Decoder Loss:  0.5370773
Encoder Loss:  0.13119143  || Decoder Loss:  0.19535081 Validation Decoder Loss:  0.54375756
Encoder Loss:  0.13046388  || Decoder Loss:  0.19404376 Validation Decoder Loss:  0.544952
Model: bold_synthesis_net_lr_0.0009045845725549529 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.544952
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_99 (Dropout)         (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_37 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_31 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 500, 14, 1)        376       
_________________________________________________________________
dropout_101 (Dropout)        (None, 500, 14, 1)        0         
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 420, 14, 1)        82        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 470, 14, 1)        52        
_________________________________________________________________
dropout_103 (Dropout)        (None, 470, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_34 (Conv2DT (None, 874, 14, 1)        406       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20429017  || Decoder Loss:  0.32592556 Validation Decoder Loss:  0.49472505
Encoder Loss:  0.16279308  || Decoder Loss:  0.2641236 Validation Decoder Loss:  0.45619544
Encoder Loss:  0.13917516  || Decoder Loss:  0.22806086 Validation Decoder Loss:  0.46719646
Encoder Loss:  0.124809146  || Decoder Loss:  0.21566814 Validation Decoder Loss:  0.47733602
Encoder Loss:  0.10916294  || Decoder Loss:  0.21258758 Validation Decoder Loss:  0.47731468
Encoder Loss:  0.08952479  || Decoder Loss:  0.2112677 Validation Decoder Loss:  0.47313
Encoder Loss:  0.07943256  || Decoder Loss:  0.20928007 Validation Decoder Loss:  0.4673518
Encoder Loss:  0.07818977  || Decoder Loss:  0.2077498 Validation Decoder Loss:  0.464139
Encoder Loss:  0.07756171  || Decoder Loss:  0.20667633 Validation Decoder Loss:  0.46186832
Encoder Loss:  0.077027194  || Decoder Loss:  0.20583871 Validation Decoder Loss:  0.46013176
Encoder Loss:  0.07660849  || Decoder Loss:  0.20519453 Validation Decoder Loss:  0.4595703
Encoder Loss:  0.076277584  || Decoder Loss:  0.20455065 Validation Decoder Loss:  0.45848054
Encoder Loss:  0.076027304  || Decoder Loss:  0.20400447 Validation Decoder Loss:  0.457275
Encoder Loss:  0.07582993  || Decoder Loss:  0.20349957 Validation Decoder Loss:  0.45683825
Encoder Loss:  0.07566895  || Decoder Loss:  0.20309524 Validation Decoder Loss:  0.45678875
Encoder Loss:  0.07551334  || Decoder Loss:  0.20269908 Validation Decoder Loss:  0.45915926
Encoder Loss:  0.07532825  || Decoder Loss:  0.20201911 Validation Decoder Loss:  0.46259522
Encoder Loss:  0.075131625  || Decoder Loss:  0.20124608 Validation Decoder Loss:  0.46451825
Encoder Loss:  0.07491536  || Decoder Loss:  0.20034432 Validation Decoder Loss:  0.46638802
Encoder Loss:  0.07466681  || Decoder Loss:  0.19914608 Validation Decoder Loss:  0.46599528
Encoder Loss:  0.07436702  || Decoder Loss:  0.19755067 Validation Decoder Loss:  0.4706776
Encoder Loss:  0.07399883  || Decoder Loss:  0.1954698 Validation Decoder Loss:  0.46411073
Encoder Loss:  0.07370509  || Decoder Loss:  0.19386281 Validation Decoder Loss:  0.46402207
Encoder Loss:  0.073569626  || Decoder Loss:  0.19331633 Validation Decoder Loss:  0.46489972
Encoder Loss:  0.073418476  || Decoder Loss:  0.19264776 Validation Decoder Loss:  0.46947503
Encoder Loss:  0.07328482  || Decoder Loss:  0.1920573 Validation Decoder Loss:  0.47205985
Encoder Loss:  0.07309856  || Decoder Loss:  0.19109866 Validation Decoder Loss:  0.47524834
Encoder Loss:  0.07282805  || Decoder Loss:  0.18955438 Validation Decoder Loss:  0.4801741
Encoder Loss:  0.0725786  || Decoder Loss:  0.18813583 Validation Decoder Loss:  0.4822645
Encoder Loss:  0.07242873  || Decoder Loss:  0.18736817 Validation Decoder Loss:  0.48285684
Encoder Loss:  0.0723033  || Decoder Loss:  0.18676285 Validation Decoder Loss:  0.48338607
Encoder Loss:  0.07219083  || Decoder Loss:  0.18623482 Validation Decoder Loss:  0.48459557
Encoder Loss:  0.072113946  || Decoder Loss:  0.185929 Validation Decoder Loss:  0.4858618
Encoder Loss:  0.07203982  || Decoder Loss:  0.185629 Validation Decoder Loss:  0.48787126
Encoder Loss:  0.07197306  || Decoder Loss:  0.18535586 Validation Decoder Loss:  0.49112213
Encoder Loss:  0.0719139  || Decoder Loss:  0.18511067 Validation Decoder Loss:  0.49470168
Encoder Loss:  0.07186385  || Decoder Loss:  0.18492284 Validation Decoder Loss:  0.49765
Encoder Loss:  0.07181446  || Decoder Loss:  0.18472846 Validation Decoder Loss:  0.4998173
Encoder Loss:  0.07177128  || Decoder Loss:  0.18456452 Validation Decoder Loss:  0.50225776
Encoder Loss:  0.07173325  || Decoder Loss:  0.18441378 Validation Decoder Loss:  0.50430304
Model: bold_synthesis_net_lr_0.0007369210999743378 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50430304
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_105 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_40 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_32 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_107 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_36 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_109 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_36 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22673346  || Decoder Loss:  0.32535285 Validation Decoder Loss:  0.49055892
Encoder Loss:  0.18032959  || Decoder Loss:  0.26051182 Validation Decoder Loss:  0.45505834
Encoder Loss:  0.15558608  || Decoder Loss:  0.22504114 Validation Decoder Loss:  0.46923515
Encoder Loss:  0.14499463  || Decoder Loss:  0.21341401 Validation Decoder Loss:  0.47880605
Encoder Loss:  0.1373834  || Decoder Loss:  0.21003622 Validation Decoder Loss:  0.48316312
Encoder Loss:  0.124660164  || Decoder Loss:  0.20858228 Validation Decoder Loss:  0.4850442
Encoder Loss:  0.1106758  || Decoder Loss:  0.2074776 Validation Decoder Loss:  0.48585805
Encoder Loss:  0.10453563  || Decoder Loss:  0.20647472 Validation Decoder Loss:  0.48356128
Encoder Loss:  0.1035262  || Decoder Loss:  0.20524897 Validation Decoder Loss:  0.48036152
Encoder Loss:  0.102615975  || Decoder Loss:  0.20396107 Validation Decoder Loss:  0.47797576
Encoder Loss:  0.10178587  || Decoder Loss:  0.20277959 Validation Decoder Loss:  0.4757295
Encoder Loss:  0.10119509  || Decoder Loss:  0.20211323 Validation Decoder Loss:  0.47596374
Encoder Loss:  0.10089952  || Decoder Loss:  0.20211405 Validation Decoder Loss:  0.47659066
Encoder Loss:  0.100667104  || Decoder Loss:  0.20208575 Validation Decoder Loss:  0.47686464
Encoder Loss:  0.100502975  || Decoder Loss:  0.20209521 Validation Decoder Loss:  0.47745255
Encoder Loss:  0.10036364  || Decoder Loss:  0.20201442 Validation Decoder Loss:  0.47715628
Encoder Loss:  0.100207545  || Decoder Loss:  0.20176655 Validation Decoder Loss:  0.4769147
Encoder Loss:  0.10004772  || Decoder Loss:  0.20146662 Validation Decoder Loss:  0.47639713
Encoder Loss:  0.09989421  || Decoder Loss:  0.20114605 Validation Decoder Loss:  0.47562924
Encoder Loss:  0.099744946  || Decoder Loss:  0.20082724 Validation Decoder Loss:  0.47476906
Encoder Loss:  0.09959256  || Decoder Loss:  0.2004858 Validation Decoder Loss:  0.4744838
Encoder Loss:  0.09927653  || Decoder Loss:  0.19961238 Validation Decoder Loss:  0.46968538
Encoder Loss:  0.09860053  || Decoder Loss:  0.1975901 Validation Decoder Loss:  0.4720398
Encoder Loss:  0.09812962  || Decoder Loss:  0.19622265 Validation Decoder Loss:  0.47198686
Encoder Loss:  0.09742256  || Decoder Loss:  0.19409281 Validation Decoder Loss:  0.4749387
Encoder Loss:  0.09671146  || Decoder Loss:  0.1919416 Validation Decoder Loss:  0.47059304
Encoder Loss:  0.09620145  || Decoder Loss:  0.1904138 Validation Decoder Loss:  0.47073475
Encoder Loss:  0.09575766  || Decoder Loss:  0.18908022 Validation Decoder Loss:  0.469644
Encoder Loss:  0.09538945  || Decoder Loss:  0.18797629 Validation Decoder Loss:  0.46674526
Encoder Loss:  0.09506655  || Decoder Loss:  0.18701364 Validation Decoder Loss:  0.4639394
Encoder Loss:  0.09475027  || Decoder Loss:  0.18607056 Validation Decoder Loss:  0.46134633
Encoder Loss:  0.094459645  || Decoder Loss:  0.1852063 Validation Decoder Loss:  0.4600336
Encoder Loss:  0.09425066  || Decoder Loss:  0.18459964 Validation Decoder Loss:  0.45911685
Encoder Loss:  0.09412936  || Decoder Loss:  0.18426682 Validation Decoder Loss:  0.45831817
Encoder Loss:  0.09402175  || Decoder Loss:  0.1839759 Validation Decoder Loss:  0.45781928
Encoder Loss:  0.09393024  || Decoder Loss:  0.18372884 Validation Decoder Loss:  0.4572994
Encoder Loss:  0.09384159  || Decoder Loss:  0.18350108 Validation Decoder Loss:  0.45624074
Encoder Loss:  0.093765125  || Decoder Loss:  0.18330583 Validation Decoder Loss:  0.45521393
Encoder Loss:  0.0936829  || Decoder Loss:  0.18310228 Validation Decoder Loss:  0.4542584
Encoder Loss:  0.09360647  || Decoder Loss:  0.1829011 Validation Decoder Loss:  0.45370835
Model: bold_synthesis_net_lr_0.0007754329495687829 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45370835
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 82, 5, 14, 1)      20        
_________________________________________________________________
dropout_111 (Dropout)        (None, 82, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_43 (Conv3DT (None, 84, 5, 14, 1)      4         
_________________________________________________________________
reshape_33 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 590, 14, 1)        286       
_________________________________________________________________
dropout_113 (Dropout)        (None, 590, 14, 1)        0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 420, 14, 1)        172       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 740, 14, 1)        322       
_________________________________________________________________
dropout_115 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_38 (Conv2DT (None, 874, 14, 1)        136       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13510135  || Decoder Loss:  0.26185876 Validation Decoder Loss:  0.5059431
Encoder Loss:  0.13249661  || Decoder Loss:  0.2558231 Validation Decoder Loss:  0.5030615
Encoder Loss:  0.13065805  || Decoder Loss:  0.2509624 Validation Decoder Loss:  0.5007389
Encoder Loss:  0.1290533  || Decoder Loss:  0.24666178 Validation Decoder Loss:  0.4988969
Encoder Loss:  0.1275928  || Decoder Loss:  0.24280167 Validation Decoder Loss:  0.49769843
Encoder Loss:  0.12641719  || Decoder Loss:  0.23949073 Validation Decoder Loss:  0.49699575
Encoder Loss:  0.12553908  || Decoder Loss:  0.23677145 Validation Decoder Loss:  0.49649483
Encoder Loss:  0.124939926  || Decoder Loss:  0.23464665 Validation Decoder Loss:  0.49607885
Encoder Loss:  0.12450736  || Decoder Loss:  0.23296152 Validation Decoder Loss:  0.49574214
Encoder Loss:  0.12414077  || Decoder Loss:  0.23152104 Validation Decoder Loss:  0.49544472
Encoder Loss:  0.123800255  || Decoder Loss:  0.23021035 Validation Decoder Loss:  0.49520788
Encoder Loss:  0.123494565  || Decoder Loss:  0.22908555 Validation Decoder Loss:  0.49495846
Encoder Loss:  0.123203546  || Decoder Loss:  0.22811466 Validation Decoder Loss:  0.49475628
Encoder Loss:  0.12289277  || Decoder Loss:  0.22718175 Validation Decoder Loss:  0.49464032
Encoder Loss:  0.12257801  || Decoder Loss:  0.22632109 Validation Decoder Loss:  0.4945382
Encoder Loss:  0.122247286  || Decoder Loss:  0.2255204 Validation Decoder Loss:  0.4944948
Encoder Loss:  0.12188861  || Decoder Loss:  0.22474003 Validation Decoder Loss:  0.49451798
Encoder Loss:  0.12149601  || Decoder Loss:  0.22397915 Validation Decoder Loss:  0.49458426
Encoder Loss:  0.12106553  || Decoder Loss:  0.2232419 Validation Decoder Loss:  0.49469945
Encoder Loss:  0.12059349  || Decoder Loss:  0.22254223 Validation Decoder Loss:  0.49485183
Encoder Loss:  0.12007694  || Decoder Loss:  0.22189292 Validation Decoder Loss:  0.49506867
Encoder Loss:  0.119514965  || Decoder Loss:  0.22128662 Validation Decoder Loss:  0.49530047
Encoder Loss:  0.118901856  || Decoder Loss:  0.22071488 Validation Decoder Loss:  0.4955515
Encoder Loss:  0.11823344  || Decoder Loss:  0.22014675 Validation Decoder Loss:  0.49586594
Encoder Loss:  0.11750795  || Decoder Loss:  0.21957867 Validation Decoder Loss:  0.49626517
Encoder Loss:  0.11674696  || Decoder Loss:  0.21906137 Validation Decoder Loss:  0.49661773
Encoder Loss:  0.11593011  || Decoder Loss:  0.21857396 Validation Decoder Loss:  0.4970155
Encoder Loss:  0.115057334  || Decoder Loss:  0.21811363 Validation Decoder Loss:  0.49743268
Encoder Loss:  0.11412493  || Decoder Loss:  0.21767654 Validation Decoder Loss:  0.49786115
Encoder Loss:  0.11312542  || Decoder Loss:  0.2172628 Validation Decoder Loss:  0.49827933
Encoder Loss:  0.11205513  || Decoder Loss:  0.21686901 Validation Decoder Loss:  0.49872902
Encoder Loss:  0.11092429  || Decoder Loss:  0.2164821 Validation Decoder Loss:  0.49923778
Encoder Loss:  0.10971169  || Decoder Loss:  0.21608704 Validation Decoder Loss:  0.49961898
Encoder Loss:  0.10840364  || Decoder Loss:  0.21557578 Validation Decoder Loss:  0.49967954
Encoder Loss:  0.10697382  || Decoder Loss:  0.21519828 Validation Decoder Loss:  0.50024885
Encoder Loss:  0.10545439  || Decoder Loss:  0.21491545 Validation Decoder Loss:  0.50089145
Encoder Loss:  0.10386147  || Decoder Loss:  0.21463633 Validation Decoder Loss:  0.50159645
Encoder Loss:  0.10224169  || Decoder Loss:  0.2143675 Validation Decoder Loss:  0.50234896
Encoder Loss:  0.10058684  || Decoder Loss:  0.2141655 Validation Decoder Loss:  0.5031751
Encoder Loss:  0.098915465  || Decoder Loss:  0.2140325 Validation Decoder Loss:  0.50421417
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: bold_synthesis_net_lr_0.00011731032771002977 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5042142
Started Optimization Process
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_117 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_46 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_34 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_119 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_121 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_40 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22653814  || Decoder Loss:  0.32520866 Validation Decoder Loss:  0.49011785
Encoder Loss:  0.17997858  || Decoder Loss:  0.26009017 Validation Decoder Loss:  0.45517236
Encoder Loss:  0.15533662  || Decoder Loss:  0.22481637 Validation Decoder Loss:  0.46943915
Encoder Loss:  0.1447997  || Decoder Loss:  0.2133265 Validation Decoder Loss:  0.4789351
Encoder Loss:  0.13708352  || Decoder Loss:  0.20999391 Validation Decoder Loss:  0.48325664
Encoder Loss:  0.1241052  || Decoder Loss:  0.2085401 Validation Decoder Loss:  0.48512763
Encoder Loss:  0.11018555  || Decoder Loss:  0.20735519 Validation Decoder Loss:  0.48526126
Encoder Loss:  0.1043067  || Decoder Loss:  0.20619482 Validation Decoder Loss:  0.4830162
Encoder Loss:  0.10337884  || Decoder Loss:  0.20512682 Validation Decoder Loss:  0.48045292
Encoder Loss:  0.10253567  || Decoder Loss:  0.20405386 Validation Decoder Loss:  0.47838828
Encoder Loss:  0.10175277  || Decoder Loss:  0.20301643 Validation Decoder Loss:  0.4762824
Encoder Loss:  0.10114395  || Decoder Loss:  0.20228189 Validation Decoder Loss:  0.47587106
Encoder Loss:  0.10081392  || Decoder Loss:  0.202158 Validation Decoder Loss:  0.476552
Encoder Loss:  0.1005886  || Decoder Loss:  0.20214531 Validation Decoder Loss:  0.47700605
Encoder Loss:  0.10041768  || Decoder Loss:  0.2021226 Validation Decoder Loss:  0.47703302
Encoder Loss:  0.10027861  || Decoder Loss:  0.20203272 Validation Decoder Loss:  0.4768171
Encoder Loss:  0.10012816  || Decoder Loss:  0.20179866 Validation Decoder Loss:  0.47683427
Encoder Loss:  0.099979766  || Decoder Loss:  0.20153089 Validation Decoder Loss:  0.4757391
Encoder Loss:  0.09983229  || Decoder Loss:  0.2012305 Validation Decoder Loss:  0.47486842
Encoder Loss:  0.099689245  || Decoder Loss:  0.20092891 Validation Decoder Loss:  0.47388762
Encoder Loss:  0.0995545  || Decoder Loss:  0.20064305 Validation Decoder Loss:  0.47264087
Encoder Loss:  0.09942168  || Decoder Loss:  0.20035318 Validation Decoder Loss:  0.4717004
Encoder Loss:  0.099277385  || Decoder Loss:  0.20002003 Validation Decoder Loss:  0.47140235
Encoder Loss:  0.09906587  || Decoder Loss:  0.19947176 Validation Decoder Loss:  0.47239494
Encoder Loss:  0.098428115  || Decoder Loss:  0.19755802 Validation Decoder Loss:  0.4759422
Encoder Loss:  0.09786703  || Decoder Loss:  0.19588004 Validation Decoder Loss:  0.47408855
Encoder Loss:  0.097119644  || Decoder Loss:  0.19359237 Validation Decoder Loss:  0.474711
Encoder Loss:  0.09667872  || Decoder Loss:  0.19226553 Validation Decoder Loss:  0.4727648
Encoder Loss:  0.09634037  || Decoder Loss:  0.19125997 Validation Decoder Loss:  0.47045767
Encoder Loss:  0.09601864  || Decoder Loss:  0.19029759 Validation Decoder Loss:  0.46704066
Encoder Loss:  0.095688805  || Decoder Loss:  0.18930644 Validation Decoder Loss:  0.4670537
Encoder Loss:  0.095451675  || Decoder Loss:  0.18860875 Validation Decoder Loss:  0.46612245
Encoder Loss:  0.095289394  || Decoder Loss:  0.18815151 Validation Decoder Loss:  0.4676519
Encoder Loss:  0.09504346  || Decoder Loss:  0.18742362 Validation Decoder Loss:  0.46629474
Encoder Loss:  0.09484191  || Decoder Loss:  0.18683016 Validation Decoder Loss:  0.4657801
Encoder Loss:  0.094684616  || Decoder Loss:  0.18637864 Validation Decoder Loss:  0.4629992
Encoder Loss:  0.09450348  || Decoder Loss:  0.18585238 Validation Decoder Loss:  0.46113002
Encoder Loss:  0.094314404  || Decoder Loss:  0.18530448 Validation Decoder Loss:  0.459766
Encoder Loss:  0.09414907  || Decoder Loss:  0.18482673 Validation Decoder Loss:  0.45995373
Encoder Loss:  0.09405  || Decoder Loss:  0.18455224 Validation Decoder Loss:  0.45885172
Model: bold_synthesis_net_lr_0.0007797101479568464 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45885172
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_123 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_49 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_35 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 760, 14, 1)        116       
_________________________________________________________________
dropout_125 (Dropout)        (None, 760, 14, 1)        0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 420, 14, 1)        342       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 710, 14, 1)        292       
_________________________________________________________________
dropout_127 (Dropout)        (None, 710, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_42 (Conv2DT (None, 874, 14, 1)        166       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35200065  || Decoder Loss:  0.39500278 Validation Decoder Loss:  0.6624807
Encoder Loss:  0.3049327  || Decoder Loss:  0.34973317 Validation Decoder Loss:  0.52894616
Encoder Loss:  0.24463122  || Decoder Loss:  0.28228337 Validation Decoder Loss:  0.44838288
Encoder Loss:  0.20248196  || Decoder Loss:  0.2329398 Validation Decoder Loss:  0.45355397
Encoder Loss:  0.1839388  || Decoder Loss:  0.21265066 Validation Decoder Loss:  0.4708079
Encoder Loss:  0.17769034  || Decoder Loss:  0.20700097 Validation Decoder Loss:  0.48110938
Encoder Loss:  0.1746902  || Decoder Loss:  0.20533316 Validation Decoder Loss:  0.4856649
Encoder Loss:  0.17213444  || Decoder Loss:  0.20528315 Validation Decoder Loss:  0.49133354
Encoder Loss:  0.16978204  || Decoder Loss:  0.20660469 Validation Decoder Loss:  0.4988538
Encoder Loss:  0.16954957  || Decoder Loss:  0.21082513 Validation Decoder Loss:  0.5092261
Encoder Loss:  0.17256056  || Decoder Loss:  0.21854101 Validation Decoder Loss:  0.5211719
Encoder Loss:  0.17561208  || Decoder Loss:  0.22539605 Validation Decoder Loss:  0.5305108
Encoder Loss:  0.17740437  || Decoder Loss:  0.229429 Validation Decoder Loss:  0.5354612
Encoder Loss:  0.17780387  || Decoder Loss:  0.23074375 Validation Decoder Loss:  0.53560203
Encoder Loss:  0.17676543  || Decoder Loss:  0.22956315 Validation Decoder Loss:  0.5338094
Encoder Loss:  0.17511147  || Decoder Loss:  0.22740404 Validation Decoder Loss:  0.53151953
Encoder Loss:  0.1731328  || Decoder Loss:  0.22475135 Validation Decoder Loss:  0.52808195
Encoder Loss:  0.17135276  || Decoder Loss:  0.22236665 Validation Decoder Loss:  0.524815
Encoder Loss:  0.16999575  || Decoder Loss:  0.22057036 Validation Decoder Loss:  0.52202433
Encoder Loss:  0.16868559  || Decoder Loss:  0.21882479 Validation Decoder Loss:  0.5188555
Encoder Loss:  0.16749994  || Decoder Loss:  0.21724889 Validation Decoder Loss:  0.51523644
Encoder Loss:  0.16637947  || Decoder Loss:  0.2157564 Validation Decoder Loss:  0.5112236
Encoder Loss:  0.1651983  || Decoder Loss:  0.21417065 Validation Decoder Loss:  0.50749534
Encoder Loss:  0.16407304  || Decoder Loss:  0.2126583 Validation Decoder Loss:  0.50425464
Encoder Loss:  0.163083  || Decoder Loss:  0.2113297 Validation Decoder Loss:  0.5010528
Encoder Loss:  0.16216435  || Decoder Loss:  0.21008661 Validation Decoder Loss:  0.49799073
Encoder Loss:  0.16133276  || Decoder Loss:  0.20895128 Validation Decoder Loss:  0.49468884
Encoder Loss:  0.15979442  || Decoder Loss:  0.20678577 Validation Decoder Loss:  0.4880518
Encoder Loss:  0.15723309  || Decoder Loss:  0.20314473 Validation Decoder Loss:  0.48529166
Encoder Loss:  0.15651646  || Decoder Loss:  0.20214613 Validation Decoder Loss:  0.48304912
Encoder Loss:  0.15599927  || Decoder Loss:  0.20143016 Validation Decoder Loss:  0.48086798
Encoder Loss:  0.15558659  || Decoder Loss:  0.20086063 Validation Decoder Loss:  0.47855204
Encoder Loss:  0.15524508  || Decoder Loss:  0.20039107 Validation Decoder Loss:  0.47644043
Encoder Loss:  0.15498368  || Decoder Loss:  0.20003387 Validation Decoder Loss:  0.47419006
Encoder Loss:  0.15477501  || Decoder Loss:  0.19975017 Validation Decoder Loss:  0.47204694
Encoder Loss:  0.15459107  || Decoder Loss:  0.1994996 Validation Decoder Loss:  0.4701695
Encoder Loss:  0.15447533  || Decoder Loss:  0.19934487 Validation Decoder Loss:  0.46856704
Encoder Loss:  0.15443917  || Decoder Loss:  0.19930294 Validation Decoder Loss:  0.46682072
Encoder Loss:  0.15456942  || Decoder Loss:  0.19949926 Validation Decoder Loss:  0.46466982
Encoder Loss:  0.1548131  || Decoder Loss:  0.1998569 Validation Decoder Loss:  0.46262047
Model: bold_synthesis_net_lr_0.0003066155064885558 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.46262047
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_129 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_52 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_36 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_131 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 710, 14, 1)        292       
_________________________________________________________________
dropout_133 (Dropout)        (None, 710, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_44 (Conv2DT (None, 874, 14, 1)        166       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40024945  || Decoder Loss:  0.4342189 Validation Decoder Loss:  0.9100926
Encoder Loss:  0.36969113  || Decoder Loss:  0.41441208 Validation Decoder Loss:  0.6628119
Encoder Loss:  0.23126413  || Decoder Loss:  0.27332264 Validation Decoder Loss:  0.47267064
Encoder Loss:  0.17043515  || Decoder Loss:  0.20230664 Validation Decoder Loss:  0.4917093
Encoder Loss:  0.17000602  || Decoder Loss:  0.20409809 Validation Decoder Loss:  0.5000455
Encoder Loss:  0.16977465  || Decoder Loss:  0.20746581 Validation Decoder Loss:  0.5059582
Encoder Loss:  0.16964935  || Decoder Loss:  0.21269909 Validation Decoder Loss:  0.51386774
Encoder Loss:  0.16807802  || Decoder Loss:  0.2165887 Validation Decoder Loss:  0.5380668
Encoder Loss:  0.17489395  || Decoder Loss:  0.23156539 Validation Decoder Loss:  0.5612487
Encoder Loss:  0.18687508  || Decoder Loss:  0.25273186 Validation Decoder Loss:  0.5820917
Encoder Loss:  0.19561662  || Decoder Loss:  0.2679235 Validation Decoder Loss:  0.58963454
Encoder Loss:  0.19608937  || Decoder Loss:  0.26986206 Validation Decoder Loss:  0.5879987
Encoder Loss:  0.19351105  || Decoder Loss:  0.26669717 Validation Decoder Loss:  0.58050966
Encoder Loss:  0.18947072  || Decoder Loss:  0.2609876 Validation Decoder Loss:  0.5747236
Encoder Loss:  0.18513185  || Decoder Loss:  0.25469887 Validation Decoder Loss:  0.57330436
Encoder Loss:  0.17784089  || Decoder Loss:  0.2438248 Validation Decoder Loss:  0.5691401
Encoder Loss:  0.17083418  || Decoder Loss:  0.2333423 Validation Decoder Loss:  0.57513493
Encoder Loss:  0.16446671  || Decoder Loss:  0.2238023 Validation Decoder Loss:  0.5640088
Encoder Loss:  0.16132244  || Decoder Loss:  0.21917054 Validation Decoder Loss:  0.56000006
Encoder Loss:  0.15956797  || Decoder Loss:  0.2166306 Validation Decoder Loss:  0.5603931
Encoder Loss:  0.1578996  || Decoder Loss:  0.21419722 Validation Decoder Loss:  0.5652041
Encoder Loss:  0.1561048  || Decoder Loss:  0.21154605 Validation Decoder Loss:  0.57047933
Encoder Loss:  0.15383062  || Decoder Loss:  0.20814012 Validation Decoder Loss:  0.57287806
Encoder Loss:  0.14966892  || Decoder Loss:  0.20182799 Validation Decoder Loss:  0.57080454
Encoder Loss:  0.14341807  || Decoder Loss:  0.19230583 Validation Decoder Loss:  0.5754759
Encoder Loss:  0.14091752  || Decoder Loss:  0.18851773 Validation Decoder Loss:  0.5710936
Encoder Loss:  0.14049017  || Decoder Loss:  0.18789789 Validation Decoder Loss:  0.5680012
Encoder Loss:  0.14022277  || Decoder Loss:  0.1875171 Validation Decoder Loss:  0.5655973
Encoder Loss:  0.14002702  || Decoder Loss:  0.18724088 Validation Decoder Loss:  0.56424785
Encoder Loss:  0.13986951  || Decoder Loss:  0.18701898 Validation Decoder Loss:  0.5630574
Encoder Loss:  0.1397466  || Decoder Loss:  0.18684483 Validation Decoder Loss:  0.5620283
Encoder Loss:  0.13966572  || Decoder Loss:  0.18673462 Validation Decoder Loss:  0.56095266
Encoder Loss:  0.13960606  || Decoder Loss:  0.18665639 Validation Decoder Loss:  0.5602486
Encoder Loss:  0.13959005  || Decoder Loss:  0.18664458 Validation Decoder Loss:  0.5595266
Encoder Loss:  0.13961247  || Decoder Loss:  0.18669052 Validation Decoder Loss:  0.5590479
Encoder Loss:  0.13963509  || Decoder Loss:  0.18673529 Validation Decoder Loss:  0.5586129
Encoder Loss:  0.13971195  || Decoder Loss:  0.18685988 Validation Decoder Loss:  0.55798256
Encoder Loss:  0.139818  || Decoder Loss:  0.18702836 Validation Decoder Loss:  0.5575137
Encoder Loss:  0.13997787  || Decoder Loss:  0.18727717 Validation Decoder Loss:  0.5571279
Encoder Loss:  0.14020157  || Decoder Loss:  0.18762398 Validation Decoder Loss:  0.55686045
Model: bold_synthesis_net_lr_0.0003860226694938087 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.55686045
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_135 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_55 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_37 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 760, 14, 1)        116       
_________________________________________________________________
dropout_137 (Dropout)        (None, 760, 14, 1)        0         
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 420, 14, 1)        342       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 710, 14, 1)        292       
_________________________________________________________________
dropout_139 (Dropout)        (None, 710, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_46 (Conv2DT (None, 874, 14, 1)        166       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35203883  || Decoder Loss:  0.39501753 Validation Decoder Loss:  0.66260374
Encoder Loss:  0.30503613  || Decoder Loss:  0.3498193 Validation Decoder Loss:  0.52921635
Encoder Loss:  0.24477299  || Decoder Loss:  0.28242525 Validation Decoder Loss:  0.44838724
Encoder Loss:  0.20251277  || Decoder Loss:  0.2329561 Validation Decoder Loss:  0.45354193
Encoder Loss:  0.18397589  || Decoder Loss:  0.21267161 Validation Decoder Loss:  0.47076064
Encoder Loss:  0.17772833  || Decoder Loss:  0.20702021 Validation Decoder Loss:  0.48105338
Encoder Loss:  0.17472526  || Decoder Loss:  0.20534167 Validation Decoder Loss:  0.4855934
Encoder Loss:  0.17216304  || Decoder Loss:  0.20527127 Validation Decoder Loss:  0.49121657
Encoder Loss:  0.16979888  || Decoder Loss:  0.20656283 Validation Decoder Loss:  0.49877438
Encoder Loss:  0.16955994  || Decoder Loss:  0.21077004 Validation Decoder Loss:  0.50911176
Encoder Loss:  0.17254367  || Decoder Loss:  0.21844995 Validation Decoder Loss:  0.5210138
Encoder Loss:  0.17559731  || Decoder Loss:  0.22531922 Validation Decoder Loss:  0.53037363
Encoder Loss:  0.177402  || Decoder Loss:  0.22937702 Validation Decoder Loss:  0.53536284
Encoder Loss:  0.17780876  || Decoder Loss:  0.23070584 Validation Decoder Loss:  0.5355148
Encoder Loss:  0.17677407  || Decoder Loss:  0.2295337 Validation Decoder Loss:  0.53372455
Encoder Loss:  0.17513119  || Decoder Loss:  0.22739172 Validation Decoder Loss:  0.53144556
Encoder Loss:  0.17315896  || Decoder Loss:  0.22474942 Validation Decoder Loss:  0.5280374
Encoder Loss:  0.17136522  || Decoder Loss:  0.22234486 Validation Decoder Loss:  0.52482545
Encoder Loss:  0.16999674  || Decoder Loss:  0.22053257 Validation Decoder Loss:  0.5220348
Encoder Loss:  0.16869235  || Decoder Loss:  0.21879517 Validation Decoder Loss:  0.51884645
Encoder Loss:  0.16752203  || Decoder Loss:  0.21724153 Validation Decoder Loss:  0.51526785
Encoder Loss:  0.16641112  || Decoder Loss:  0.21576339 Validation Decoder Loss:  0.5112884
Encoder Loss:  0.16522442  || Decoder Loss:  0.21416937 Validation Decoder Loss:  0.5073393
Encoder Loss:  0.16408373  || Decoder Loss:  0.21263498 Validation Decoder Loss:  0.50411135
Encoder Loss:  0.16308035  || Decoder Loss:  0.21128792 Validation Decoder Loss:  0.5009802
Encoder Loss:  0.16217391  || Decoder Loss:  0.21006373 Validation Decoder Loss:  0.498071
Encoder Loss:  0.1613534  || Decoder Loss:  0.20894466 Validation Decoder Loss:  0.4946009
Encoder Loss:  0.15981346  || Decoder Loss:  0.20677836 Validation Decoder Loss:  0.4881092
Encoder Loss:  0.1572535  || Decoder Loss:  0.20314002 Validation Decoder Loss:  0.48527795
Encoder Loss:  0.15653074  || Decoder Loss:  0.20213298 Validation Decoder Loss:  0.48298424
Encoder Loss:  0.15600747  || Decoder Loss:  0.20140895 Validation Decoder Loss:  0.48079908
Encoder Loss:  0.15559652  || Decoder Loss:  0.20084213 Validation Decoder Loss:  0.4784231
Encoder Loss:  0.15525801  || Decoder Loss:  0.20037688 Validation Decoder Loss:  0.47636443
Encoder Loss:  0.15500066  || Decoder Loss:  0.20002547 Validation Decoder Loss:  0.47412613
Encoder Loss:  0.1547982  || Decoder Loss:  0.1997507 Validation Decoder Loss:  0.47199544
Encoder Loss:  0.15462086  || Decoder Loss:  0.19950992 Validation Decoder Loss:  0.47008532
Encoder Loss:  0.15451053  || Decoder Loss:  0.19936298 Validation Decoder Loss:  0.4684209
Encoder Loss:  0.1544723  || Decoder Loss:  0.19931856 Validation Decoder Loss:  0.46675578
Encoder Loss:  0.15460122  || Decoder Loss:  0.19951247 Validation Decoder Loss:  0.4646102
Encoder Loss:  0.15488234  || Decoder Loss:  0.19992405 Validation Decoder Loss:  0.46231818
Model: bold_synthesis_net_lr_0.00030632450696668496 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.46231818
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_141 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_58 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_38 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_143 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_145 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_48 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36195233  || Decoder Loss:  0.4063214 Validation Decoder Loss:  0.76064324
Encoder Loss:  0.35900497  || Decoder Loss:  0.40414292 Validation Decoder Loss:  0.75188994
Encoder Loss:  0.3558567  || Decoder Loss:  0.40175164 Validation Decoder Loss:  0.74266106
Encoder Loss:  0.35254267  || Decoder Loss:  0.39916405 Validation Decoder Loss:  0.7328174
Encoder Loss:  0.34906414  || Decoder Loss:  0.39637223 Validation Decoder Loss:  0.72233355
Encoder Loss:  0.3454173  || Decoder Loss:  0.3933626 Validation Decoder Loss:  0.71120244
Encoder Loss:  0.34159726  || Decoder Loss:  0.390121 Validation Decoder Loss:  0.69942963
Encoder Loss:  0.3375992  || Decoder Loss:  0.38663262 Validation Decoder Loss:  0.6870354
Encoder Loss:  0.333417  || Decoder Loss:  0.38288084 Validation Decoder Loss:  0.67421854
Encoder Loss:  0.32904556  || Decoder Loss:  0.37884918 Validation Decoder Loss:  0.6615155
Encoder Loss:  0.32447812  || Decoder Loss:  0.37452397 Validation Decoder Loss:  0.648638
Encoder Loss:  0.3197071  || Decoder Loss:  0.3698881 Validation Decoder Loss:  0.6363187
Encoder Loss:  0.31472674  || Decoder Loss:  0.36492816 Validation Decoder Loss:  0.62490726
Encoder Loss:  0.3095334  || Decoder Loss:  0.3596319 Validation Decoder Loss:  0.61361533
Encoder Loss:  0.3041238  || Decoder Loss:  0.35399145 Validation Decoder Loss:  0.60226655
Encoder Loss:  0.29850012  || Decoder Loss:  0.34800643 Validation Decoder Loss:  0.5904904
Encoder Loss:  0.29267797  || Decoder Loss:  0.3416966 Validation Decoder Loss:  0.5782647
Encoder Loss:  0.2867161  || Decoder Loss:  0.3351473 Validation Decoder Loss:  0.5656077
Encoder Loss:  0.28062454  || Decoder Loss:  0.3283706 Validation Decoder Loss:  0.5525899
Encoder Loss:  0.2744207  || Decoder Loss:  0.32139102 Validation Decoder Loss:  0.53922117
Encoder Loss:  0.26811722  || Decoder Loss:  0.31422436 Validation Decoder Loss:  0.5259182
Encoder Loss:  0.26195455  || Decoder Loss:  0.30710784 Validation Decoder Loss:  0.51413244
Encoder Loss:  0.25637195  || Decoder Loss:  0.30051988 Validation Decoder Loss:  0.503725
Encoder Loss:  0.25098956  || Decoder Loss:  0.29416543 Validation Decoder Loss:  0.4937394
Encoder Loss:  0.24566212  || Decoder Loss:  0.28791228 Validation Decoder Loss:  0.48425418
Encoder Loss:  0.24040575  || Decoder Loss:  0.28177196 Validation Decoder Loss:  0.47570375
Encoder Loss:  0.23524997  || Decoder Loss:  0.27578166 Validation Decoder Loss:  0.4678221
Encoder Loss:  0.2301743  || Decoder Loss:  0.2699042 Validation Decoder Loss:  0.46091878
Encoder Loss:  0.22522774  || Decoder Loss:  0.26416734 Validation Decoder Loss:  0.45585185
Encoder Loss:  0.22067975  || Decoder Loss:  0.25882533 Validation Decoder Loss:  0.45244786
Encoder Loss:  0.21662363  || Decoder Loss:  0.25402036 Validation Decoder Loss:  0.4499132
Encoder Loss:  0.2129047  || Decoder Loss:  0.2495817 Validation Decoder Loss:  0.44806585
Encoder Loss:  0.20931749  || Decoder Loss:  0.24529205 Validation Decoder Loss:  0.4469217
Encoder Loss:  0.20575556  || Decoder Loss:  0.24104923 Validation Decoder Loss:  0.44643065
Encoder Loss:  0.20225288  || Decoder Loss:  0.236906 Validation Decoder Loss:  0.44656608
Encoder Loss:  0.19889279  || Decoder Loss:  0.23298314 Validation Decoder Loss:  0.44769672
Encoder Loss:  0.19570951  || Decoder Loss:  0.2293266 Validation Decoder Loss:  0.44934237
Encoder Loss:  0.1927477  || Decoder Loss:  0.22599563 Validation Decoder Loss:  0.45123756
Encoder Loss:  0.19012794  || Decoder Loss:  0.22310968 Validation Decoder Loss:  0.45332184
Encoder Loss:  0.18801503  || Decoder Loss:  0.22080047 Validation Decoder Loss:  0.45533508
Model: bold_synthesis_net_lr_2.9300993797155094e-05 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45533508
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_147 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_61 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_39 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 740, 14, 1)        136       
_________________________________________________________________
dropout_149 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 420, 14, 1)        322       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 720, 14, 1)        302       
_________________________________________________________________
dropout_151 (Dropout)        (None, 720, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_50 (Conv2DT (None, 874, 14, 1)        156       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42191848  || Decoder Loss:  0.43269703 Validation Decoder Loss:  0.8651787
Encoder Loss:  0.3589939  || Decoder Loss:  0.37332505 Validation Decoder Loss:  0.43581337
Encoder Loss:  0.19533493  || Decoder Loss:  0.20477092 Validation Decoder Loss:  0.49821746
Encoder Loss:  0.19545944  || Decoder Loss:  0.20582254 Validation Decoder Loss:  0.5119327
Encoder Loss:  0.19909464  || Decoder Loss:  0.21098247 Validation Decoder Loss:  0.5154478
Encoder Loss:  0.20420718  || Decoder Loss:  0.21835391 Validation Decoder Loss:  0.5351371
Encoder Loss:  0.2105351  || Decoder Loss:  0.22671375 Validation Decoder Loss:  0.5567623
Encoder Loss:  0.2238761  || Decoder Loss:  0.2423573 Validation Decoder Loss:  0.56377244
Encoder Loss:  0.22828752  || Decoder Loss:  0.24774688 Validation Decoder Loss:  0.56286365
Encoder Loss:  0.227703  || Decoder Loss:  0.24736391 Validation Decoder Loss:  0.5575942
Encoder Loss:  0.21748544  || Decoder Loss:  0.23610845 Validation Decoder Loss:  0.5586075
Encoder Loss:  0.20468454  || Decoder Loss:  0.22191302 Validation Decoder Loss:  0.56302434
Encoder Loss:  0.20255387  || Decoder Loss:  0.21959357 Validation Decoder Loss:  0.5620247
Encoder Loss:  0.20237166  || Decoder Loss:  0.2194402 Validation Decoder Loss:  0.5614899
Encoder Loss:  0.20221646  || Decoder Loss:  0.21931273 Validation Decoder Loss:  0.5623747
Encoder Loss:  0.20198745  || Decoder Loss:  0.21909705 Validation Decoder Loss:  0.5648108
Encoder Loss:  0.20171541  || Decoder Loss:  0.21882914 Validation Decoder Loss:  0.56544954
Encoder Loss:  0.20124356  || Decoder Loss:  0.21833387 Validation Decoder Loss:  0.5671079
Encoder Loss:  0.2005401  || Decoder Loss:  0.21757627 Validation Decoder Loss:  0.5681149
Encoder Loss:  0.19963868  || Decoder Loss:  0.21659468 Validation Decoder Loss:  0.5675242
Encoder Loss:  0.19856632  || Decoder Loss:  0.21541595 Validation Decoder Loss:  0.56591713
Encoder Loss:  0.19742748  || Decoder Loss:  0.21415815 Validation Decoder Loss:  0.5639212
Encoder Loss:  0.1958775  || Decoder Loss:  0.21243884 Validation Decoder Loss:  0.5622821
Encoder Loss:  0.19415124  || Decoder Loss:  0.21052149 Validation Decoder Loss:  0.5635636
Encoder Loss:  0.19178389  || Decoder Loss:  0.20788825 Validation Decoder Loss:  0.56483674
Encoder Loss:  0.18837336  || Decoder Loss:  0.20409116 Validation Decoder Loss:  0.560368
Encoder Loss:  0.1782977  || Decoder Loss:  0.19286321 Validation Decoder Loss:  0.54245055
Encoder Loss:  0.17184593  || Decoder Loss:  0.1856749 Validation Decoder Loss:  0.54059005
Encoder Loss:  0.17057595  || Decoder Loss:  0.18426323 Validation Decoder Loss:  0.5401718
Encoder Loss:  0.1696752  || Decoder Loss:  0.18326299 Validation Decoder Loss:  0.5402414
Encoder Loss:  0.16896491  || Decoder Loss:  0.18247464 Validation Decoder Loss:  0.5399746
Encoder Loss:  0.16838804  || Decoder Loss:  0.18183492 Validation Decoder Loss:  0.5395058
Encoder Loss:  0.16792072  || Decoder Loss:  0.18131775 Validation Decoder Loss:  0.5391819
Encoder Loss:  0.16750892  || Decoder Loss:  0.18086267 Validation Decoder Loss:  0.53927004
Encoder Loss:  0.16714829  || Decoder Loss:  0.18046412 Validation Decoder Loss:  0.5396833
Encoder Loss:  0.1667903  || Decoder Loss:  0.1800678 Validation Decoder Loss:  0.5395664
Encoder Loss:  0.16643514  || Decoder Loss:  0.17967564 Validation Decoder Loss:  0.5399206
Encoder Loss:  0.16608176  || Decoder Loss:  0.17928411 Validation Decoder Loss:  0.54036164
Encoder Loss:  0.16575193  || Decoder Loss:  0.178918 Validation Decoder Loss:  0.54056245
Encoder Loss:  0.16543913  || Decoder Loss:  0.17856985 Validation Decoder Loss:  0.5409766
Model: bold_synthesis_net_lr_0.000490130736218469 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5409766
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 70, 5, 14, 1)      8         
_________________________________________________________________
dropout_153 (Dropout)        (None, 70, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_64 (Conv3DT (None, 84, 5, 14, 1)      16        
_________________________________________________________________
reshape_40 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_155 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_157 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_52 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21336718  || Decoder Loss:  0.2947598 Validation Decoder Loss:  0.4894412
Encoder Loss:  0.19281499  || Decoder Loss:  0.26562217 Validation Decoder Loss:  0.46999112
Encoder Loss:  0.17825003  || Decoder Loss:  0.24471606 Validation Decoder Loss:  0.468801
Encoder Loss:  0.16875467  || Decoder Loss:  0.23180667 Validation Decoder Loss:  0.47255132
Encoder Loss:  0.1634009  || Decoder Loss:  0.22489 Validation Decoder Loss:  0.4770515
Encoder Loss:  0.15916419  || Decoder Loss:  0.21996097 Validation Decoder Loss:  0.48210838
Encoder Loss:  0.1561431  || Decoder Loss:  0.21708822 Validation Decoder Loss:  0.48520404
Encoder Loss:  0.15347877  || Decoder Loss:  0.21544956 Validation Decoder Loss:  0.4872121
Encoder Loss:  0.15029421  || Decoder Loss:  0.21420728 Validation Decoder Loss:  0.4886863
Encoder Loss:  0.14578477  || Decoder Loss:  0.2128492 Validation Decoder Loss:  0.48994797
Encoder Loss:  0.13979977  || Decoder Loss:  0.21200335 Validation Decoder Loss:  0.49195015
Encoder Loss:  0.13285314  || Decoder Loss:  0.21131594 Validation Decoder Loss:  0.49358937
Encoder Loss:  0.12659413  || Decoder Loss:  0.21092159 Validation Decoder Loss:  0.49519864
Encoder Loss:  0.12195085  || Decoder Loss:  0.21055752 Validation Decoder Loss:  0.49461138
Encoder Loss:  0.12039811  || Decoder Loss:  0.20965374 Validation Decoder Loss:  0.49244782
Encoder Loss:  0.11980341  || Decoder Loss:  0.2086715 Validation Decoder Loss:  0.4904457
Encoder Loss:  0.11924722  || Decoder Loss:  0.20779267 Validation Decoder Loss:  0.4886943
Encoder Loss:  0.11880458  || Decoder Loss:  0.20717761 Validation Decoder Loss:  0.48761228
Encoder Loss:  0.11844233  || Decoder Loss:  0.20674701 Validation Decoder Loss:  0.48676118
Encoder Loss:  0.118109524  || Decoder Loss:  0.20636131 Validation Decoder Loss:  0.4861446
Encoder Loss:  0.11776182  || Decoder Loss:  0.2059343 Validation Decoder Loss:  0.4856032
Encoder Loss:  0.1174207  || Decoder Loss:  0.20550883 Validation Decoder Loss:  0.48550224
Encoder Loss:  0.11710906  || Decoder Loss:  0.20515963 Validation Decoder Loss:  0.48512277
Encoder Loss:  0.11681733  || Decoder Loss:  0.20485084 Validation Decoder Loss:  0.4842758
Encoder Loss:  0.11653266  || Decoder Loss:  0.20454079 Validation Decoder Loss:  0.48348895
Encoder Loss:  0.116305046  || Decoder Loss:  0.20434205 Validation Decoder Loss:  0.48279595
Encoder Loss:  0.116043225  || Decoder Loss:  0.20399521 Validation Decoder Loss:  0.48226795
Encoder Loss:  0.115903735  || Decoder Loss:  0.20390776 Validation Decoder Loss:  0.4819269
Encoder Loss:  0.115786314  || Decoder Loss:  0.20383577 Validation Decoder Loss:  0.48156184
Encoder Loss:  0.11565054  || Decoder Loss:  0.20366879 Validation Decoder Loss:  0.4816632
Encoder Loss:  0.1154796  || Decoder Loss:  0.20338829 Validation Decoder Loss:  0.4817316
Encoder Loss:  0.11520261  || Decoder Loss:  0.20282741 Validation Decoder Loss:  0.48170194
Encoder Loss:  0.11484298  || Decoder Loss:  0.20204943 Validation Decoder Loss:  0.4817938
Encoder Loss:  0.11445577  || Decoder Loss:  0.20119844 Validation Decoder Loss:  0.48309478
Encoder Loss:  0.114013284  || Decoder Loss:  0.20020355 Validation Decoder Loss:  0.48281348
Encoder Loss:  0.11368205  || Decoder Loss:  0.19948378 Validation Decoder Loss:  0.48298755
Encoder Loss:  0.113476925  || Decoder Loss:  0.19907363 Validation Decoder Loss:  0.48267975
Encoder Loss:  0.11332126  || Decoder Loss:  0.19878168 Validation Decoder Loss:  0.48269358
Encoder Loss:  0.11318314  || Decoder Loss:  0.19853444 Validation Decoder Loss:  0.48291984
Encoder Loss:  0.11304382  || Decoder Loss:  0.19827846 Validation Decoder Loss:  0.4828734
Model: bold_synthesis_net_lr_0.00067168452374714 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4828734
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_159 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_67 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_41 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_161 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_163 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_54 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.40726885 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Encoder Loss:  0.36449948  || Decoder Loss:  0.4072689 Validation Decoder Loss:  0.7687953
Model: bold_synthesis_net_lr_1e-14 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.7687953
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_165 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_70 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_42 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_167 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_56 (Conv2D)           (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 710, 14, 1)        292       
_________________________________________________________________
dropout_169 (Dropout)        (None, 710, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_56 (Conv2DT (None, 874, 14, 1)        166       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3452192  || Decoder Loss:  0.38967538 Validation Decoder Loss:  0.6231642
Encoder Loss:  0.27665967  || Decoder Loss:  0.32012248 Validation Decoder Loss:  0.4651582
Encoder Loss:  0.20999423  || Decoder Loss:  0.24306731 Validation Decoder Loss:  0.45224434
Encoder Loss:  0.18185431  || Decoder Loss:  0.21186586 Validation Decoder Loss:  0.47481498
Encoder Loss:  0.17384204  || Decoder Loss:  0.20577541 Validation Decoder Loss:  0.4843137
Encoder Loss:  0.16806611  || Decoder Loss:  0.20501405 Validation Decoder Loss:  0.49040744
Encoder Loss:  0.16356914  || Decoder Loss:  0.20712827 Validation Decoder Loss:  0.4959966
Encoder Loss:  0.16275457  || Decoder Loss:  0.21014655 Validation Decoder Loss:  0.49810556
Encoder Loss:  0.16311003  || Decoder Loss:  0.21157628 Validation Decoder Loss:  0.49837917
Encoder Loss:  0.16330658  || Decoder Loss:  0.21223237 Validation Decoder Loss:  0.4989846
Encoder Loss:  0.16323774  || Decoder Loss:  0.21241029 Validation Decoder Loss:  0.4982292
Encoder Loss:  0.16294722  || Decoder Loss:  0.21219978 Validation Decoder Loss:  0.49743077
Encoder Loss:  0.16258337  || Decoder Loss:  0.21183616 Validation Decoder Loss:  0.49673262
Encoder Loss:  0.16216823  || Decoder Loss:  0.21137019 Validation Decoder Loss:  0.49619058
Encoder Loss:  0.16168964  || Decoder Loss:  0.2107858 Validation Decoder Loss:  0.49562877
Encoder Loss:  0.16108827  || Decoder Loss:  0.20999296 Validation Decoder Loss:  0.4962388
Encoder Loss:  0.16045739  || Decoder Loss:  0.20913416 Validation Decoder Loss:  0.49499443
Encoder Loss:  0.15985346  || Decoder Loss:  0.20830317 Validation Decoder Loss:  0.49282336
Encoder Loss:  0.15924942  || Decoder Loss:  0.20746428 Validation Decoder Loss:  0.49139932
Encoder Loss:  0.15856312  || Decoder Loss:  0.20650159 Validation Decoder Loss:  0.49110776
Encoder Loss:  0.15788588  || Decoder Loss:  0.20555034 Validation Decoder Loss:  0.48943788
Encoder Loss:  0.15746889  || Decoder Loss:  0.2049722 Validation Decoder Loss:  0.48852012
Encoder Loss:  0.15701813  || Decoder Loss:  0.20434219 Validation Decoder Loss:  0.48779243
Encoder Loss:  0.15662596  || Decoder Loss:  0.20379348 Validation Decoder Loss:  0.48678714
Encoder Loss:  0.15627502  || Decoder Loss:  0.20330426 Validation Decoder Loss:  0.4859494
Encoder Loss:  0.15593776  || Decoder Loss:  0.20283146 Validation Decoder Loss:  0.4852847
Encoder Loss:  0.15561171  || Decoder Loss:  0.20237394 Validation Decoder Loss:  0.48469082
Encoder Loss:  0.15524206  || Decoder Loss:  0.2018523 Validation Decoder Loss:  0.48404944
Encoder Loss:  0.15486838  || Decoder Loss:  0.20132312 Validation Decoder Loss:  0.48349527
Encoder Loss:  0.15446074  || Decoder Loss:  0.20074481 Validation Decoder Loss:  0.48314193
Encoder Loss:  0.15403429  || Decoder Loss:  0.20013857 Validation Decoder Loss:  0.48295087
Encoder Loss:  0.15361014  || Decoder Loss:  0.19953534 Validation Decoder Loss:  0.48275977
Encoder Loss:  0.15321499  || Decoder Loss:  0.19897307 Validation Decoder Loss:  0.48233455
Encoder Loss:  0.15285595  || Decoder Loss:  0.19846375 Validation Decoder Loss:  0.48375964
Encoder Loss:  0.15247338  || Decoder Loss:  0.19791809 Validation Decoder Loss:  0.48534596
Encoder Loss:  0.15215285  || Decoder Loss:  0.19746281 Validation Decoder Loss:  0.48412102
Encoder Loss:  0.15179454  || Decoder Loss:  0.1969515 Validation Decoder Loss:  0.4832033
Encoder Loss:  0.15134539  || Decoder Loss:  0.19630939 Validation Decoder Loss:  0.48228124
Encoder Loss:  0.15079726  || Decoder Loss:  0.19552174 Validation Decoder Loss:  0.4808615
Encoder Loss:  0.15019234  || Decoder Loss:  0.1946505 Validation Decoder Loss:  0.48013914
Model: bold_synthesis_net_lr_0.000775694611684193 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.48013914
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_171 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_73 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_43 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_173 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_175 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_58 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22597118  || Decoder Loss:  0.3250082 Validation Decoder Loss:  0.48954332
Encoder Loss:  0.17932232  || Decoder Loss:  0.2596072 Validation Decoder Loss:  0.4552915
Encoder Loss:  0.15488923  || Decoder Loss:  0.22463484 Validation Decoder Loss:  0.46949804
Encoder Loss:  0.14438409  || Decoder Loss:  0.2132499 Validation Decoder Loss:  0.4790515
Encoder Loss:  0.13650936  || Decoder Loss:  0.20996176 Validation Decoder Loss:  0.48333183
Encoder Loss:  0.12320954  || Decoder Loss:  0.20852853 Validation Decoder Loss:  0.4852483
Encoder Loss:  0.10936546  || Decoder Loss:  0.20734422 Validation Decoder Loss:  0.48519132
Encoder Loss:  0.103822865  || Decoder Loss:  0.20618817 Validation Decoder Loss:  0.48282838
Encoder Loss:  0.10290371  || Decoder Loss:  0.20507015 Validation Decoder Loss:  0.48029536
Encoder Loss:  0.10205591  || Decoder Loss:  0.20397288 Validation Decoder Loss:  0.47822902
Encoder Loss:  0.10126563  || Decoder Loss:  0.20290364 Validation Decoder Loss:  0.47602218
Encoder Loss:  0.10067431  || Decoder Loss:  0.20220351 Validation Decoder Loss:  0.4758767
Encoder Loss:  0.10036527  || Decoder Loss:  0.20213953 Validation Decoder Loss:  0.4765587
Encoder Loss:  0.10013686  || Decoder Loss:  0.20210236 Validation Decoder Loss:  0.47689393
Encoder Loss:  0.09996964  || Decoder Loss:  0.20208101 Validation Decoder Loss:  0.47723216
Encoder Loss:  0.09982701  || Decoder Loss:  0.20197614 Validation Decoder Loss:  0.47707766
Encoder Loss:  0.09967595  || Decoder Loss:  0.20173244 Validation Decoder Loss:  0.4769228
Encoder Loss:  0.09952429  || Decoder Loss:  0.20145139 Validation Decoder Loss:  0.4757118
Encoder Loss:  0.09937493  || Decoder Loss:  0.20113894 Validation Decoder Loss:  0.4751625
Encoder Loss:  0.09922904  || Decoder Loss:  0.20082991 Validation Decoder Loss:  0.47383446
Encoder Loss:  0.09909582  || Decoder Loss:  0.20054471 Validation Decoder Loss:  0.47263882
Encoder Loss:  0.09895415  || Decoder Loss:  0.20022245 Validation Decoder Loss:  0.4722053
Encoder Loss:  0.098807946  || Decoder Loss:  0.19988024 Validation Decoder Loss:  0.47235763
Encoder Loss:  0.09844299  || Decoder Loss:  0.19883898 Validation Decoder Loss:  0.4714556
Encoder Loss:  0.09709682  || Decoder Loss:  0.19463003 Validation Decoder Loss:  0.47643176
Encoder Loss:  0.09656631  || Decoder Loss:  0.19303514 Validation Decoder Loss:  0.47427562
Encoder Loss:  0.09623182  || Decoder Loss:  0.19205186 Validation Decoder Loss:  0.47201622
Encoder Loss:  0.095825195  || Decoder Loss:  0.19082326 Validation Decoder Loss:  0.4684747
Encoder Loss:  0.09539329  || Decoder Loss:  0.18950619 Validation Decoder Loss:  0.46819744
Encoder Loss:  0.09508564  || Decoder Loss:  0.1885787 Validation Decoder Loss:  0.46825963
Encoder Loss:  0.09482216  || Decoder Loss:  0.18779314 Validation Decoder Loss:  0.46686953
Encoder Loss:  0.094589286  || Decoder Loss:  0.1871036 Validation Decoder Loss:  0.46564543
Encoder Loss:  0.09439723  || Decoder Loss:  0.1865483 Validation Decoder Loss:  0.46243
Encoder Loss:  0.094162956  || Decoder Loss:  0.18584779 Validation Decoder Loss:  0.46081325
Encoder Loss:  0.09393311  || Decoder Loss:  0.18515833 Validation Decoder Loss:  0.46091512
Encoder Loss:  0.093748935  || Decoder Loss:  0.18461685 Validation Decoder Loss:  0.4601384
Encoder Loss:  0.09363654  || Decoder Loss:  0.18430738 Validation Decoder Loss:  0.45924976
Encoder Loss:  0.093556985  || Decoder Loss:  0.18410738 Validation Decoder Loss:  0.458724
Encoder Loss:  0.09348086  || Decoder Loss:  0.18390857 Validation Decoder Loss:  0.45836636
Encoder Loss:  0.09343063  || Decoder Loss:  0.18379386 Validation Decoder Loss:  0.45819962
Model: bold_synthesis_net_lr_0.0007844378490100179 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45819962
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_177 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_76 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_44 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 490, 14, 1)        386       
_________________________________________________________________
dropout_179 (Dropout)        (None, 490, 14, 1)        0         
_________________________________________________________________
conv2d_60 (Conv2D)           (None, 420, 14, 1)        72        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 470, 14, 1)        52        
_________________________________________________________________
dropout_181 (Dropout)        (None, 470, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_60 (Conv2DT (None, 874, 14, 1)        406       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23154244  || Decoder Loss:  0.3480342 Validation Decoder Loss:  0.57987744
Encoder Loss:  0.21506384  || Decoder Loss:  0.3284527 Validation Decoder Loss:  0.5401899
Encoder Loss:  0.20076534  || Decoder Loss:  0.30889982 Validation Decoder Loss:  0.50957865
Encoder Loss:  0.1885146  || Decoder Loss:  0.2906232 Validation Decoder Loss:  0.4845595
Encoder Loss:  0.17709595  || Decoder Loss:  0.27379262 Validation Decoder Loss:  0.46704414
Encoder Loss:  0.16825034  || Decoder Loss:  0.2601426 Validation Decoder Loss:  0.46045333
Encoder Loss:  0.16127042  || Decoder Loss:  0.24944897 Validation Decoder Loss:  0.456647
Encoder Loss:  0.15454656  || Decoder Loss:  0.23979445 Validation Decoder Loss:  0.45682925
Encoder Loss:  0.14815582  || Decoder Loss:  0.23180375 Validation Decoder Loss:  0.45980033
Encoder Loss:  0.14312722  || Decoder Loss:  0.22624439 Validation Decoder Loss:  0.4625849
Encoder Loss:  0.13913083  || Decoder Loss:  0.22269608 Validation Decoder Loss:  0.46575406
Encoder Loss:  0.1351436  || Decoder Loss:  0.22009644 Validation Decoder Loss:  0.46911716
Encoder Loss:  0.13104111  || Decoder Loss:  0.21809295 Validation Decoder Loss:  0.4719208
Encoder Loss:  0.12724328  || Decoder Loss:  0.21693097 Validation Decoder Loss:  0.4731868
Encoder Loss:  0.12370374  || Decoder Loss:  0.21636398 Validation Decoder Loss:  0.47347775
Encoder Loss:  0.1200699  || Decoder Loss:  0.21599455 Validation Decoder Loss:  0.47305176
Encoder Loss:  0.11629602  || Decoder Loss:  0.21545678 Validation Decoder Loss:  0.4721983
Encoder Loss:  0.112522535  || Decoder Loss:  0.21527776 Validation Decoder Loss:  0.4716457
Encoder Loss:  0.10877846  || Decoder Loss:  0.21509352 Validation Decoder Loss:  0.47102585
Encoder Loss:  0.1051989  || Decoder Loss:  0.21480705 Validation Decoder Loss:  0.46997428
Encoder Loss:  0.10198038  || Decoder Loss:  0.21440762 Validation Decoder Loss:  0.4683218
Encoder Loss:  0.09946994  || Decoder Loss:  0.21402822 Validation Decoder Loss:  0.466007
Encoder Loss:  0.09726194  || Decoder Loss:  0.21367007 Validation Decoder Loss:  0.46342033
Encoder Loss:  0.095124364  || Decoder Loss:  0.21324033 Validation Decoder Loss:  0.46098912
Encoder Loss:  0.093049474  || Decoder Loss:  0.2127455 Validation Decoder Loss:  0.45910606
Encoder Loss:  0.09111917  || Decoder Loss:  0.21237436 Validation Decoder Loss:  0.45748818
Encoder Loss:  0.08954094  || Decoder Loss:  0.21198365 Validation Decoder Loss:  0.4566051
Encoder Loss:  0.08878723  || Decoder Loss:  0.21153621 Validation Decoder Loss:  0.45661882
Encoder Loss:  0.08846364  || Decoder Loss:  0.21110977 Validation Decoder Loss:  0.45711616
Encoder Loss:  0.0882559  || Decoder Loss:  0.2107034 Validation Decoder Loss:  0.45799717
Encoder Loss:  0.08805718  || Decoder Loss:  0.21028768 Validation Decoder Loss:  0.459168
Encoder Loss:  0.08787445  || Decoder Loss:  0.20992018 Validation Decoder Loss:  0.46065825
Encoder Loss:  0.0876843  || Decoder Loss:  0.2094931 Validation Decoder Loss:  0.46434754
Encoder Loss:  0.08741524  || Decoder Loss:  0.20864443 Validation Decoder Loss:  0.48410425
Encoder Loss:  0.08726611  || Decoder Loss:  0.20838578 Validation Decoder Loss:  0.4838205
Encoder Loss:  0.087045975  || Decoder Loss:  0.20774527 Validation Decoder Loss:  0.49106997
Encoder Loss:  0.08698319  || Decoder Loss:  0.20786488 Validation Decoder Loss:  0.47977424
Encoder Loss:  0.086701736  || Decoder Loss:  0.20683706 Validation Decoder Loss:  0.4936447
Encoder Loss:  0.08677128  || Decoder Loss:  0.20755722 Validation Decoder Loss:  0.47708347
Encoder Loss:  0.08646634  || Decoder Loss:  0.20635484 Validation Decoder Loss:  0.4872349
Model: bold_synthesis_net_lr_0.0003723044886283927 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.48723495
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_183 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_79 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_45 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 760, 14, 1)        116       
_________________________________________________________________
dropout_185 (Dropout)        (None, 760, 14, 1)        0         
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 420, 14, 1)        342       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 700, 14, 1)        282       
_________________________________________________________________
dropout_187 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_62 (Conv2DT (None, 874, 14, 1)        176       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3721335  || Decoder Loss:  0.38291466 Validation Decoder Loss:  0.5813003
Encoder Loss:  0.27896553  || Decoder Loss:  0.2884655 Validation Decoder Loss:  0.44518933
Encoder Loss:  0.21027432  || Decoder Loss:  0.21743692 Validation Decoder Loss:  0.47368225
Encoder Loss:  0.19804834  || Decoder Loss:  0.20562367 Validation Decoder Loss:  0.4871402
Encoder Loss:  0.19642717  || Decoder Loss:  0.20556614 Validation Decoder Loss:  0.49780953
Encoder Loss:  0.20040555  || Decoder Loss:  0.21138655 Validation Decoder Loss:  0.50566065
Encoder Loss:  0.20315816  || Decoder Loss:  0.21491534 Validation Decoder Loss:  0.5065758
Encoder Loss:  0.20255226  || Decoder Loss:  0.21438108 Validation Decoder Loss:  0.5042688
Encoder Loss:  0.20127632  || Decoder Loss:  0.2130584 Validation Decoder Loss:  0.5015217
Encoder Loss:  0.19948891  || Decoder Loss:  0.21116851 Validation Decoder Loss:  0.50088525
Encoder Loss:  0.19772768  || Decoder Loss:  0.20929842 Validation Decoder Loss:  0.4994941
Encoder Loss:  0.19629136  || Decoder Loss:  0.20777449 Validation Decoder Loss:  0.49783906
Encoder Loss:  0.19516021  || Decoder Loss:  0.20657691 Validation Decoder Loss:  0.4957457
Encoder Loss:  0.19442894  || Decoder Loss:  0.20580797 Validation Decoder Loss:  0.4944211
Encoder Loss:  0.19382201  || Decoder Loss:  0.20516756 Validation Decoder Loss:  0.49304184
Encoder Loss:  0.19322845  || Decoder Loss:  0.20453602 Validation Decoder Loss:  0.4913687
Encoder Loss:  0.19267738  || Decoder Loss:  0.20394737 Validation Decoder Loss:  0.48995018
Encoder Loss:  0.19211279  || Decoder Loss:  0.20334294 Validation Decoder Loss:  0.48859107
Encoder Loss:  0.19149823  || Decoder Loss:  0.20268396 Validation Decoder Loss:  0.48775426
Encoder Loss:  0.19005322  || Decoder Loss:  0.20112647 Validation Decoder Loss:  0.4850098
Encoder Loss:  0.18697017  || Decoder Loss:  0.19779824 Validation Decoder Loss:  0.48449776
Encoder Loss:  0.18639836  || Decoder Loss:  0.19718328 Validation Decoder Loss:  0.48409805
Encoder Loss:  0.18603747  || Decoder Loss:  0.1967957 Validation Decoder Loss:  0.48411748
Encoder Loss:  0.18575528  || Decoder Loss:  0.19649269 Validation Decoder Loss:  0.48412177
Encoder Loss:  0.1854869  || Decoder Loss:  0.19620438 Validation Decoder Loss:  0.48398444
Encoder Loss:  0.18524559  || Decoder Loss:  0.19594528 Validation Decoder Loss:  0.4843346
Encoder Loss:  0.1850006  || Decoder Loss:  0.19568212 Validation Decoder Loss:  0.4863362
Encoder Loss:  0.18467991  || Decoder Loss:  0.1953368 Validation Decoder Loss:  0.48603275
Encoder Loss:  0.18434401  || Decoder Loss:  0.1949748 Validation Decoder Loss:  0.48549983
Encoder Loss:  0.18388408  || Decoder Loss:  0.1944787 Validation Decoder Loss:  0.4851375
Encoder Loss:  0.18329702  || Decoder Loss:  0.19384497 Validation Decoder Loss:  0.4849023
Encoder Loss:  0.1828313  || Decoder Loss:  0.19334233 Validation Decoder Loss:  0.4850555
Encoder Loss:  0.18241204  || Decoder Loss:  0.19288969 Validation Decoder Loss:  0.4858108
Encoder Loss:  0.18191531  || Decoder Loss:  0.19235341 Validation Decoder Loss:  0.48630905
Encoder Loss:  0.18135591  || Decoder Loss:  0.19174953 Validation Decoder Loss:  0.4870486
Encoder Loss:  0.18075323  || Decoder Loss:  0.19109857 Validation Decoder Loss:  0.48827052
Encoder Loss:  0.18011531  || Decoder Loss:  0.19040972 Validation Decoder Loss:  0.49017596
Encoder Loss:  0.17961633  || Decoder Loss:  0.18987097 Validation Decoder Loss:  0.49065942
Encoder Loss:  0.17914341  || Decoder Loss:  0.18936042 Validation Decoder Loss:  0.49164745
Encoder Loss:  0.17862132  || Decoder Loss:  0.18879656 Validation Decoder Loss:  0.49292928
Model: bold_synthesis_net_lr_0.000984970067043697 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49292928
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_189 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_82 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_46 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_191 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_64 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_193 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_64 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22643553  || Decoder Loss:  0.32520965 Validation Decoder Loss:  0.4901206
Encoder Loss:  0.17989624  || Decoder Loss:  0.26009253 Validation Decoder Loss:  0.45517197
Encoder Loss:  0.15526532  || Decoder Loss:  0.22481838 Validation Decoder Loss:  0.4694373
Encoder Loss:  0.14472911  || Decoder Loss:  0.21332777 Validation Decoder Loss:  0.47893405
Encoder Loss:  0.1370089  || Decoder Loss:  0.2099955 Validation Decoder Loss:  0.4832552
Encoder Loss:  0.12402017  || Decoder Loss:  0.20854294 Validation Decoder Loss:  0.48523846
Encoder Loss:  0.11012761  || Decoder Loss:  0.20748708 Validation Decoder Loss:  0.48598304
Encoder Loss:  0.10426786  || Decoder Loss:  0.20640995 Validation Decoder Loss:  0.48354423
Encoder Loss:  0.10328699  || Decoder Loss:  0.20517346 Validation Decoder Loss:  0.48011518
Encoder Loss:  0.1022971  || Decoder Loss:  0.20363048 Validation Decoder Loss:  0.476929
Encoder Loss:  0.10144541  || Decoder Loss:  0.20237236 Validation Decoder Loss:  0.47568417
Encoder Loss:  0.10096002  || Decoder Loss:  0.20203212 Validation Decoder Loss:  0.475949
Encoder Loss:  0.10069125  || Decoder Loss:  0.20210561 Validation Decoder Loss:  0.47613767
Encoder Loss:  0.10047414  || Decoder Loss:  0.20211747 Validation Decoder Loss:  0.47720596
Encoder Loss:  0.10029778  || Decoder Loss:  0.20207629 Validation Decoder Loss:  0.47810087
Encoder Loss:  0.10002662  || Decoder Loss:  0.20156609 Validation Decoder Loss:  0.47532454
Encoder Loss:  0.09923768  || Decoder Loss:  0.19929409 Validation Decoder Loss:  0.47450528
Encoder Loss:  0.09882657  || Decoder Loss:  0.19819395 Validation Decoder Loss:  0.47476766
Encoder Loss:  0.09840881  || Decoder Loss:  0.19702432 Validation Decoder Loss:  0.47347793
Encoder Loss:  0.097940885  || Decoder Loss:  0.19569011 Validation Decoder Loss:  0.47117954
Encoder Loss:  0.09746711  || Decoder Loss:  0.19432226 Validation Decoder Loss:  0.46854755
Encoder Loss:  0.09710011  || Decoder Loss:  0.19328547 Validation Decoder Loss:  0.4665333
Encoder Loss:  0.096689634  || Decoder Loss:  0.19210605 Validation Decoder Loss:  0.46337432
Encoder Loss:  0.09623278  || Decoder Loss:  0.19077514 Validation Decoder Loss:  0.46094474
Encoder Loss:  0.095885396  || Decoder Loss:  0.18977855 Validation Decoder Loss:  0.45980445
Encoder Loss:  0.095569454  || Decoder Loss:  0.18887956 Validation Decoder Loss:  0.46008822
Encoder Loss:  0.09492336  || Decoder Loss:  0.18691225 Validation Decoder Loss:  0.46368814
Encoder Loss:  0.09455984  || Decoder Loss:  0.18582726 Validation Decoder Loss:  0.46326736
Encoder Loss:  0.09435076  || Decoder Loss:  0.18523055 Validation Decoder Loss:  0.46150422
Encoder Loss:  0.09419356  || Decoder Loss:  0.18479344 Validation Decoder Loss:  0.4594511
Encoder Loss:  0.094070986  || Decoder Loss:  0.18445982 Validation Decoder Loss:  0.45776528
Encoder Loss:  0.09395838  || Decoder Loss:  0.18415773 Validation Decoder Loss:  0.45657817
Encoder Loss:  0.09385345  || Decoder Loss:  0.18388051 Validation Decoder Loss:  0.45553493
Encoder Loss:  0.09373707  || Decoder Loss:  0.1835655 Validation Decoder Loss:  0.4554041
Encoder Loss:  0.093624674  || Decoder Loss:  0.1832579 Validation Decoder Loss:  0.45470357
Encoder Loss:  0.09350616  || Decoder Loss:  0.18292713 Validation Decoder Loss:  0.4542653
Encoder Loss:  0.09337955  || Decoder Loss:  0.18257079 Validation Decoder Loss:  0.4532546
Encoder Loss:  0.09328297  || Decoder Loss:  0.18231861 Validation Decoder Loss:  0.45322502
Encoder Loss:  0.09321019  || Decoder Loss:  0.1821358 Validation Decoder Loss:  0.4533329
Encoder Loss:  0.09315328  || Decoder Loss:  0.18199559 Validation Decoder Loss:  0.45296627
Model: bold_synthesis_net_lr_0.0007796866721221822 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4529663
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_195 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_85 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_47 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_197 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_66 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_199 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_66 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22655849  || Decoder Loss:  0.32528263 Validation Decoder Loss:  0.49033058
Encoder Loss:  0.18006767  || Decoder Loss:  0.26026857 Validation Decoder Loss:  0.45513013
Encoder Loss:  0.15537499  || Decoder Loss:  0.22489162 Validation Decoder Loss:  0.46937707
Encoder Loss:  0.1448239  || Decoder Loss:  0.21335728 Validation Decoder Loss:  0.4789139
Encoder Loss:  0.13714783  || Decoder Loss:  0.21001811 Validation Decoder Loss:  0.48325387
Encoder Loss:  0.12427031  || Decoder Loss:  0.20858128 Validation Decoder Loss:  0.48513472
Encoder Loss:  0.11033096  || Decoder Loss:  0.20739125 Validation Decoder Loss:  0.48521617
Encoder Loss:  0.10429929  || Decoder Loss:  0.20622404 Validation Decoder Loss:  0.48305798
Encoder Loss:  0.10335726  || Decoder Loss:  0.20514801 Validation Decoder Loss:  0.48051894
Encoder Loss:  0.102517344  || Decoder Loss:  0.20407872 Validation Decoder Loss:  0.47840816
Encoder Loss:  0.101731114  || Decoder Loss:  0.20303158 Validation Decoder Loss:  0.47627717
Encoder Loss:  0.10112271  || Decoder Loss:  0.2022962 Validation Decoder Loss:  0.47585765
Encoder Loss:  0.100785516  || Decoder Loss:  0.2021546 Validation Decoder Loss:  0.47648257
Encoder Loss:  0.10055272  || Decoder Loss:  0.2021215 Validation Decoder Loss:  0.47689918
Encoder Loss:  0.10038171  || Decoder Loss:  0.20210542 Validation Decoder Loss:  0.47699285
Encoder Loss:  0.10024112  || Decoder Loss:  0.20201404 Validation Decoder Loss:  0.47675362
Encoder Loss:  0.1000926  || Decoder Loss:  0.20178601 Validation Decoder Loss:  0.47678158
Encoder Loss:  0.099940844  || Decoder Loss:  0.20151392 Validation Decoder Loss:  0.47579643
Encoder Loss:  0.09979608  || Decoder Loss:  0.20122117 Validation Decoder Loss:  0.47501987
Encoder Loss:  0.09964762  || Decoder Loss:  0.20090581 Validation Decoder Loss:  0.474193
Encoder Loss:  0.0995101  || Decoder Loss:  0.20061213 Validation Decoder Loss:  0.4728203
Encoder Loss:  0.09937419  || Decoder Loss:  0.2003114 Validation Decoder Loss:  0.4721226
Encoder Loss:  0.09922769  || Decoder Loss:  0.19996879 Validation Decoder Loss:  0.47184563
Encoder Loss:  0.098991595  || Decoder Loss:  0.19934523 Validation Decoder Loss:  0.47298312
Encoder Loss:  0.098096244  || Decoder Loss:  0.19661196 Validation Decoder Loss:  0.4741925
Encoder Loss:  0.09721169  || Decoder Loss:  0.19389969 Validation Decoder Loss:  0.4754545
Encoder Loss:  0.096777275  || Decoder Loss:  0.19260883 Validation Decoder Loss:  0.47349593
Encoder Loss:  0.096427225  || Decoder Loss:  0.19157103 Validation Decoder Loss:  0.47144306
Encoder Loss:  0.09606083  || Decoder Loss:  0.19047512 Validation Decoder Loss:  0.46798515
Encoder Loss:  0.09568403  || Decoder Loss:  0.18934041 Validation Decoder Loss:  0.4676343
Encoder Loss:  0.09542329  || Decoder Loss:  0.18856466 Validation Decoder Loss:  0.4680004
Encoder Loss:  0.09517885  || Decoder Loss:  0.18784636 Validation Decoder Loss:  0.46730164
Encoder Loss:  0.09495446  || Decoder Loss:  0.1871896 Validation Decoder Loss:  0.46654838
Encoder Loss:  0.09477005  || Decoder Loss:  0.18665352 Validation Decoder Loss:  0.464625
Encoder Loss:  0.094591625  || Decoder Loss:  0.18613762 Validation Decoder Loss:  0.46282396
Encoder Loss:  0.09438974  || Decoder Loss:  0.18554124 Validation Decoder Loss:  0.46153775
Encoder Loss:  0.0941972  || Decoder Loss:  0.18498017 Validation Decoder Loss:  0.4612431
Encoder Loss:  0.0940544  || Decoder Loss:  0.18457736 Validation Decoder Loss:  0.4607833
Encoder Loss:  0.09396432  || Decoder Loss:  0.18433794 Validation Decoder Loss:  0.45996284
Encoder Loss:  0.093902424  || Decoder Loss:  0.18418674 Validation Decoder Loss:  0.45911703
Model: bold_synthesis_net_lr_0.0007779650943318687 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45911703
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_201 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_88 (Conv3DT (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_48 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 480, 14, 1)        396       
_________________________________________________________________
dropout_203 (Dropout)        (None, 480, 14, 1)        0         
_________________________________________________________________
conv2d_68 (Conv2D)           (None, 420, 14, 1)        62        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 480, 14, 1)        62        
_________________________________________________________________
dropout_205 (Dropout)        (None, 480, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_68 (Conv2DT (None, 874, 14, 1)        396       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21014935  || Decoder Loss:  0.27810898 Validation Decoder Loss:  0.49805754
Encoder Loss:  0.20960177  || Decoder Loss:  0.2773634 Validation Decoder Loss:  0.49747333
Encoder Loss:  0.20905487  || Decoder Loss:  0.27661684 Validation Decoder Loss:  0.4968997
Encoder Loss:  0.20851384  || Decoder Loss:  0.27587715 Validation Decoder Loss:  0.49633187
Encoder Loss:  0.20797542  || Decoder Loss:  0.27514187 Validation Decoder Loss:  0.49576744
Encoder Loss:  0.20744032  || Decoder Loss:  0.2744123 Validation Decoder Loss:  0.49521023
Encoder Loss:  0.20690843  || Decoder Loss:  0.2736883 Validation Decoder Loss:  0.49466
Encoder Loss:  0.20638224  || Decoder Loss:  0.272972 Validation Decoder Loss:  0.49411792
Encoder Loss:  0.2058606  || Decoder Loss:  0.27226272 Validation Decoder Loss:  0.49358556
Encoder Loss:  0.20534317  || Decoder Loss:  0.27155948 Validation Decoder Loss:  0.49305946
Encoder Loss:  0.20483162  || Decoder Loss:  0.270865 Validation Decoder Loss:  0.49254054
Encoder Loss:  0.20432368  || Decoder Loss:  0.2701766 Validation Decoder Loss:  0.4920282
Encoder Loss:  0.20381872  || Decoder Loss:  0.26949322 Validation Decoder Loss:  0.4915259
Encoder Loss:  0.20331652  || Decoder Loss:  0.26881474 Validation Decoder Loss:  0.4910281
Encoder Loss:  0.20281726  || Decoder Loss:  0.2681408 Validation Decoder Loss:  0.49053174
Encoder Loss:  0.2023208  || Decoder Loss:  0.2674715 Validation Decoder Loss:  0.4900404
Encoder Loss:  0.20182739  || Decoder Loss:  0.2668075 Validation Decoder Loss:  0.48955363
Encoder Loss:  0.20133728  || Decoder Loss:  0.26614895 Validation Decoder Loss:  0.4890691
Encoder Loss:  0.20085059  || Decoder Loss:  0.2654964 Validation Decoder Loss:  0.48859146
Encoder Loss:  0.20036809  || Decoder Loss:  0.2648506 Validation Decoder Loss:  0.4881202
Encoder Loss:  0.1998889  || Decoder Loss:  0.26420963 Validation Decoder Loss:  0.48765832
Encoder Loss:  0.19941232  || Decoder Loss:  0.263573 Validation Decoder Loss:  0.48720738
Encoder Loss:  0.19893803  || Decoder Loss:  0.2629401 Validation Decoder Loss:  0.4867671
Encoder Loss:  0.19846596  || Decoder Loss:  0.26231062 Validation Decoder Loss:  0.48634478
Encoder Loss:  0.19799666  || Decoder Loss:  0.26168576 Validation Decoder Loss:  0.48592985
Encoder Loss:  0.19753024  || Decoder Loss:  0.26106563 Validation Decoder Loss:  0.48552364
Encoder Loss:  0.19706719  || Decoder Loss:  0.26045048 Validation Decoder Loss:  0.48512688
Encoder Loss:  0.19660635  || Decoder Loss:  0.2598389 Validation Decoder Loss:  0.484739
Encoder Loss:  0.19614828  || Decoder Loss:  0.2592321 Validation Decoder Loss:  0.4843627
Encoder Loss:  0.19569276  || Decoder Loss:  0.25862968 Validation Decoder Loss:  0.48399526
Encoder Loss:  0.19523974  || Decoder Loss:  0.25803152 Validation Decoder Loss:  0.48364055
Encoder Loss:  0.19478972  || Decoder Loss:  0.2574387 Validation Decoder Loss:  0.48330316
Encoder Loss:  0.19434214  || Decoder Loss:  0.25684986 Validation Decoder Loss:  0.4829814
Encoder Loss:  0.19389674  || Decoder Loss:  0.25626466 Validation Decoder Loss:  0.48267555
Encoder Loss:  0.19345413  || Decoder Loss:  0.2556841 Validation Decoder Loss:  0.48238167
Encoder Loss:  0.19301613  || Decoder Loss:  0.25510973 Validation Decoder Loss:  0.4821055
Encoder Loss:  0.192582  || Decoder Loss:  0.25454214 Validation Decoder Loss:  0.4818508
Encoder Loss:  0.19215098  || Decoder Loss:  0.25398037 Validation Decoder Loss:  0.48162553
Encoder Loss:  0.19172339  || Decoder Loss:  0.25342476 Validation Decoder Loss:  0.4814178
Encoder Loss:  0.19129995  || Decoder Loss:  0.25287703 Validation Decoder Loss:  0.48122683
Model: bold_synthesis_net_lr_1.6747753785577967e-05 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4812268
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_207 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_91 (Conv3DT (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_49 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_209 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_211 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_70 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22643705  || Decoder Loss:  0.32521793 Validation Decoder Loss:  0.49014428
Encoder Loss:  0.17990556  || Decoder Loss:  0.26011235 Validation Decoder Loss:  0.4551668
Encoder Loss:  0.15525988  || Decoder Loss:  0.22481355 Validation Decoder Loss:  0.4694345
Encoder Loss:  0.14473182  || Decoder Loss:  0.21333179 Validation Decoder Loss:  0.47892657
Encoder Loss:  0.13701715  || Decoder Loss:  0.2099958 Validation Decoder Loss:  0.4832455
Encoder Loss:  0.12403838  || Decoder Loss:  0.20853862 Validation Decoder Loss:  0.48510498
Encoder Loss:  0.11013855  || Decoder Loss:  0.2074625 Validation Decoder Loss:  0.4859129
Encoder Loss:  0.10426464  || Decoder Loss:  0.20641257 Validation Decoder Loss:  0.4835553
Encoder Loss:  0.10327703  || Decoder Loss:  0.20515676 Validation Decoder Loss:  0.47996348
Encoder Loss:  0.102244616  || Decoder Loss:  0.20347553 Validation Decoder Loss:  0.47663537
Encoder Loss:  0.10143393  || Decoder Loss:  0.20234837 Validation Decoder Loss:  0.47583455
Encoder Loss:  0.100991  || Decoder Loss:  0.20213889 Validation Decoder Loss:  0.47619474
Encoder Loss:  0.100711875  || Decoder Loss:  0.20218004 Validation Decoder Loss:  0.47640857
Encoder Loss:  0.10048818  || Decoder Loss:  0.20217289 Validation Decoder Loss:  0.47703972
Encoder Loss:  0.10031465  || Decoder Loss:  0.20214158 Validation Decoder Loss:  0.47730812
Encoder Loss:  0.10016042  || Decoder Loss:  0.20200765 Validation Decoder Loss:  0.47746876
Encoder Loss:  0.099933736  || Decoder Loss:  0.20153253 Validation Decoder Loss:  0.47660476
Encoder Loss:  0.09915804  || Decoder Loss:  0.19926226 Validation Decoder Loss:  0.47382587
Encoder Loss:  0.098722346  || Decoder Loss:  0.1980432 Validation Decoder Loss:  0.4744881
Encoder Loss:  0.09831417  || Decoder Loss:  0.1968962 Validation Decoder Loss:  0.4734894
Encoder Loss:  0.09788883  || Decoder Loss:  0.1956832 Validation Decoder Loss:  0.4707526
Encoder Loss:  0.09743994  || Decoder Loss:  0.19438373 Validation Decoder Loss:  0.4682514
Encoder Loss:  0.09707037  || Decoder Loss:  0.19333027 Validation Decoder Loss:  0.4656635
Encoder Loss:  0.0966749  || Decoder Loss:  0.19219758 Validation Decoder Loss:  0.46249667
Encoder Loss:  0.09624552  || Decoder Loss:  0.19094232 Validation Decoder Loss:  0.460946
Encoder Loss:  0.09592117  || Decoder Loss:  0.19001518 Validation Decoder Loss:  0.45915785
Encoder Loss:  0.09570566  || Decoder Loss:  0.18942073 Validation Decoder Loss:  0.45798743
Encoder Loss:  0.09555124  || Decoder Loss:  0.18900388 Validation Decoder Loss:  0.45687348
Encoder Loss:  0.09540289  || Decoder Loss:  0.18860078 Validation Decoder Loss:  0.45642254
Encoder Loss:  0.095068485  || Decoder Loss:  0.18759389 Validation Decoder Loss:  0.45814872
Encoder Loss:  0.09456155  || Decoder Loss:  0.1860356 Validation Decoder Loss:  0.4595284
Encoder Loss:  0.09429111  || Decoder Loss:  0.18523479 Validation Decoder Loss:  0.45867497
Encoder Loss:  0.094141155  || Decoder Loss:  0.1848137 Validation Decoder Loss:  0.45735168
Encoder Loss:  0.09403148  || Decoder Loss:  0.18451789 Validation Decoder Loss:  0.45568216
Encoder Loss:  0.093932524  || Decoder Loss:  0.18425208 Validation Decoder Loss:  0.45426372
Encoder Loss:  0.0938367  || Decoder Loss:  0.18399413 Validation Decoder Loss:  0.4528877
Encoder Loss:  0.093743764  || Decoder Loss:  0.18375348 Validation Decoder Loss:  0.45214534
Encoder Loss:  0.09363192  || Decoder Loss:  0.1834458 Validation Decoder Loss:  0.45162868
Encoder Loss:  0.09350659  || Decoder Loss:  0.1830941 Validation Decoder Loss:  0.4514885
Encoder Loss:  0.093390405  || Decoder Loss:  0.18276817 Validation Decoder Loss:  0.45083696
Model: bold_synthesis_net_lr_0.0007794928027116743 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45083696
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_213 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_94 (Conv3DT (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_50 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_215 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_72 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 750, 14, 1)        332       
_________________________________________________________________
dropout_217 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_72 (Conv2DT (None, 874, 14, 1)        126       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3002381  || Decoder Loss:  0.3880715 Validation Decoder Loss:  0.6133957
Encoder Loss:  0.22816256  || Decoder Loss:  0.31266585 Validation Decoder Loss:  0.4564383
Encoder Loss:  0.1721452  || Decoder Loss:  0.23604496 Validation Decoder Loss:  0.45658794
Encoder Loss:  0.15014485  || Decoder Loss:  0.21028303 Validation Decoder Loss:  0.47642776
Encoder Loss:  0.14048389  || Decoder Loss:  0.20546533 Validation Decoder Loss:  0.48143306
Encoder Loss:  0.12784895  || Decoder Loss:  0.20460972 Validation Decoder Loss:  0.48230144
Encoder Loss:  0.116016835  || Decoder Loss:  0.20336476 Validation Decoder Loss:  0.48299924
Encoder Loss:  0.11266113  || Decoder Loss:  0.20366171 Validation Decoder Loss:  0.48334903
Encoder Loss:  0.11258248  || Decoder Loss:  0.20498838 Validation Decoder Loss:  0.4839258
Encoder Loss:  0.11222699  || Decoder Loss:  0.20522863 Validation Decoder Loss:  0.4844537
Encoder Loss:  0.11199275  || Decoder Loss:  0.20546433 Validation Decoder Loss:  0.48455036
Encoder Loss:  0.11178804  || Decoder Loss:  0.205573 Validation Decoder Loss:  0.48384818
Encoder Loss:  0.11155024  || Decoder Loss:  0.20546079 Validation Decoder Loss:  0.48315924
Encoder Loss:  0.11131351  || Decoder Loss:  0.20525406 Validation Decoder Loss:  0.48232067
Encoder Loss:  0.11106062  || Decoder Loss:  0.20490149 Validation Decoder Loss:  0.4813179
Encoder Loss:  0.11081528  || Decoder Loss:  0.204502 Validation Decoder Loss:  0.4799122
Encoder Loss:  0.11058332  || Decoder Loss:  0.2040656 Validation Decoder Loss:  0.47941482
Encoder Loss:  0.1103475  || Decoder Loss:  0.20359904 Validation Decoder Loss:  0.47932607
Encoder Loss:  0.110083684  || Decoder Loss:  0.20305267 Validation Decoder Loss:  0.47823074
Encoder Loss:  0.10987001  || Decoder Loss:  0.20261182 Validation Decoder Loss:  0.47700664
Encoder Loss:  0.10967193  || Decoder Loss:  0.20220265 Validation Decoder Loss:  0.47576156
Encoder Loss:  0.10944128  || Decoder Loss:  0.20169838 Validation Decoder Loss:  0.47436863
Encoder Loss:  0.10911477  || Decoder Loss:  0.20092566 Validation Decoder Loss:  0.47805202
Encoder Loss:  0.10834972  || Decoder Loss:  0.19898507 Validation Decoder Loss:  0.47568864
Encoder Loss:  0.107967556  || Decoder Loss:  0.19803959 Validation Decoder Loss:  0.47341737
Encoder Loss:  0.107714064  || Decoder Loss:  0.19743173 Validation Decoder Loss:  0.47132644
Encoder Loss:  0.107506014  || Decoder Loss:  0.1969369 Validation Decoder Loss:  0.47011256
Encoder Loss:  0.10734953  || Decoder Loss:  0.19657718 Validation Decoder Loss:  0.46830133
Encoder Loss:  0.10713637  || Decoder Loss:  0.19606528 Validation Decoder Loss:  0.4665654
Encoder Loss:  0.10699746  || Decoder Loss:  0.19574086 Validation Decoder Loss:  0.4650064
Encoder Loss:  0.106914714  || Decoder Loss:  0.19555819 Validation Decoder Loss:  0.46322346
Encoder Loss:  0.106858395  || Decoder Loss:  0.19545837 Validation Decoder Loss:  0.46128875
Encoder Loss:  0.10682818  || Decoder Loss:  0.19541658 Validation Decoder Loss:  0.45938763
Encoder Loss:  0.10679054  || Decoder Loss:  0.19536458 Validation Decoder Loss:  0.45808387
Encoder Loss:  0.10676685  || Decoder Loss:  0.19534148 Validation Decoder Loss:  0.4565089
Encoder Loss:  0.106749065  || Decoder Loss:  0.1953305 Validation Decoder Loss:  0.4550347
Encoder Loss:  0.10670034  || Decoder Loss:  0.19524252 Validation Decoder Loss:  0.45325524
Encoder Loss:  0.10660616  || Decoder Loss:  0.19503205 Validation Decoder Loss:  0.45098525
Encoder Loss:  0.106437474  || Decoder Loss:  0.1946256 Validation Decoder Loss:  0.4499626
Encoder Loss:  0.106055826  || Decoder Loss:  0.19365427 Validation Decoder Loss:  0.45475674
Model: bold_synthesis_net_lr_0.0008224475414878241 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45475674
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_219 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_97 (Conv3DT (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_51 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 750, 14, 1)        126       
_________________________________________________________________
dropout_221 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_74 (Conv2D)           (None, 420, 14, 1)        332       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 700, 14, 1)        282       
_________________________________________________________________
dropout_223 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_74 (Conv2DT (None, 874, 14, 1)        176       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4038719  || Decoder Loss:  0.43751964 Validation Decoder Loss:  0.9629605
Encoder Loss:  0.40318176  || Decoder Loss:  0.43717209 Validation Decoder Loss:  0.9608324
Encoder Loss:  0.40245414  || Decoder Loss:  0.43680206 Validation Decoder Loss:  0.95853305
Encoder Loss:  0.40169528  || Decoder Loss:  0.43641263 Validation Decoder Loss:  0.9560595
Encoder Loss:  0.40090597  || Decoder Loss:  0.43600395 Validation Decoder Loss:  0.95340025
Encoder Loss:  0.40008646  || Decoder Loss:  0.43557495 Validation Decoder Loss:  0.9505402
Encoder Loss:  0.39923343  || Decoder Loss:  0.4351263 Validation Decoder Loss:  0.9474574
Encoder Loss:  0.3983452  || Decoder Loss:  0.43465498 Validation Decoder Loss:  0.94412774
Encoder Loss:  0.3974197  || Decoder Loss:  0.43416002 Validation Decoder Loss:  0.9405233
Encoder Loss:  0.39645308  || Decoder Loss:  0.43363917 Validation Decoder Loss:  0.93661356
Encoder Loss:  0.39544374  || Decoder Loss:  0.43309224 Validation Decoder Loss:  0.9323633
Encoder Loss:  0.3943876  || Decoder Loss:  0.43251568 Validation Decoder Loss:  0.92773265
Encoder Loss:  0.39328206  || Decoder Loss:  0.43190846 Validation Decoder Loss:  0.9226786
Encoder Loss:  0.39212447  || Decoder Loss:  0.43126708 Validation Decoder Loss:  0.9171536
Encoder Loss:  0.39091006  || Decoder Loss:  0.43059012 Validation Decoder Loss:  0.91110593
Encoder Loss:  0.38963544  || Decoder Loss:  0.42987323 Validation Decoder Loss:  0.90448225
Encoder Loss:  0.38829672  || Decoder Loss:  0.4291148 Validation Decoder Loss:  0.8972279
Encoder Loss:  0.386888  || Decoder Loss:  0.42830923 Validation Decoder Loss:  0.88928735
Encoder Loss:  0.38540483  || Decoder Loss:  0.42745358 Validation Decoder Loss:  0.8806097
Encoder Loss:  0.38384265  || Decoder Loss:  0.4265437 Validation Decoder Loss:  0.87115014
Encoder Loss:  0.38219455  || Decoder Loss:  0.42557436 Validation Decoder Loss:  0.8608741
Encoder Loss:  0.3804546  || Decoder Loss:  0.42453927 Validation Decoder Loss:  0.84976846
Encoder Loss:  0.37861648  || Decoder Loss:  0.4234324 Validation Decoder Loss:  0.83911014
Encoder Loss:  0.3766723  || Decoder Loss:  0.42224687 Validation Decoder Loss:  0.82915705
Encoder Loss:  0.37461475  || Decoder Loss:  0.4209748 Validation Decoder Loss:  0.819153
Encoder Loss:  0.37243602  || Decoder Loss:  0.41960606 Validation Decoder Loss:  0.8103328
Encoder Loss:  0.3701267  || Decoder Loss:  0.41813076 Validation Decoder Loss:  0.80359876
Encoder Loss:  0.367677  || Decoder Loss:  0.4165372 Validation Decoder Loss:  0.7972799
Encoder Loss:  0.36507714  || Decoder Loss:  0.41481113 Validation Decoder Loss:  0.79058313
Encoder Loss:  0.3623153  || Decoder Loss:  0.4129371 Validation Decoder Loss:  0.7832581
Encoder Loss:  0.35937893  || Decoder Loss:  0.41089463 Validation Decoder Loss:  0.7751211
Encoder Loss:  0.35625342  || Decoder Loss:  0.4086642 Validation Decoder Loss:  0.766041
Encoder Loss:  0.35292324  || Decoder Loss:  0.40622103 Validation Decoder Loss:  0.75592124
Encoder Loss:  0.34936872  || Decoder Loss:  0.40353426 Validation Decoder Loss:  0.74475634
Encoder Loss:  0.3455695  || Decoder Loss:  0.40057006 Validation Decoder Loss:  0.733529
Encoder Loss:  0.34150186  || Decoder Loss:  0.39728963 Validation Decoder Loss:  0.7214743
Encoder Loss:  0.33713734  || Decoder Loss:  0.39364704 Validation Decoder Loss:  0.70829004
Encoder Loss:  0.33244455  || Decoder Loss:  0.389588 Validation Decoder Loss:  0.6938732
Encoder Loss:  0.327388  || Decoder Loss:  0.38505423 Validation Decoder Loss:  0.67828345
Encoder Loss:  0.3219284  || Decoder Loss:  0.3799763 Validation Decoder Loss:  0.6617634
Model: bold_synthesis_net_lr_7.337515954471306e-06 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.6617634
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_225 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_100 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_52 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 780, 14, 1)        96        
_________________________________________________________________
dropout_227 (Dropout)        (None, 780, 14, 1)        0         
_________________________________________________________________
conv2d_76 (Conv2D)           (None, 420, 14, 1)        362       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_229 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_76 (Conv2DT (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22854865  || Decoder Loss:  0.32748133 Validation Decoder Loss:  0.4968689
Encoder Loss:  0.18359536  || Decoder Loss:  0.2651487 Validation Decoder Loss:  0.4545492
Encoder Loss:  0.15825683  || Decoder Loss:  0.22819123 Validation Decoder Loss:  0.46656272
Encoder Loss:  0.14705214  || Decoder Loss:  0.21514411 Validation Decoder Loss:  0.4767958
Encoder Loss:  0.14000556  || Decoder Loss:  0.21058312 Validation Decoder Loss:  0.4821399
Encoder Loss:  0.13020425  || Decoder Loss:  0.20911138 Validation Decoder Loss:  0.4843744
Encoder Loss:  0.11628656  || Decoder Loss:  0.20805281 Validation Decoder Loss:  0.4854118
Encoder Loss:  0.10651652  || Decoder Loss:  0.2067962 Validation Decoder Loss:  0.48383355
Encoder Loss:  0.10424728  || Decoder Loss:  0.2058996 Validation Decoder Loss:  0.4817458
Encoder Loss:  0.1034188  || Decoder Loss:  0.20481664 Validation Decoder Loss:  0.4795391
Encoder Loss:  0.10262366  || Decoder Loss:  0.20374687 Validation Decoder Loss:  0.47755337
Encoder Loss:  0.10187453  || Decoder Loss:  0.20270461 Validation Decoder Loss:  0.47553208
Encoder Loss:  0.101335876  || Decoder Loss:  0.20210882 Validation Decoder Loss:  0.47582862
Encoder Loss:  0.101060316  || Decoder Loss:  0.2021062 Validation Decoder Loss:  0.47652894
Encoder Loss:  0.100835  || Decoder Loss:  0.20205468 Validation Decoder Loss:  0.4765414
Encoder Loss:  0.10067706  || Decoder Loss:  0.2020574 Validation Decoder Loss:  0.47676328
Encoder Loss:  0.100544855  || Decoder Loss:  0.20199724 Validation Decoder Loss:  0.47659054
Encoder Loss:  0.10040278  || Decoder Loss:  0.20178615 Validation Decoder Loss:  0.47695982
Encoder Loss:  0.10025765  || Decoder Loss:  0.20152466 Validation Decoder Loss:  0.47599575
Encoder Loss:  0.100111075  || Decoder Loss:  0.20122577 Validation Decoder Loss:  0.47540334
Encoder Loss:  0.099969916  || Decoder Loss:  0.20092778 Validation Decoder Loss:  0.47492203
Encoder Loss:  0.09983059  || Decoder Loss:  0.20062476 Validation Decoder Loss:  0.47439483
Encoder Loss:  0.09968457  || Decoder Loss:  0.20028874 Validation Decoder Loss:  0.4740794
Encoder Loss:  0.0993078  || Decoder Loss:  0.19921675 Validation Decoder Loss:  0.4689049
Encoder Loss:  0.09868139  || Decoder Loss:  0.19736135 Validation Decoder Loss:  0.47129682
Encoder Loss:  0.09828911  || Decoder Loss:  0.19623187 Validation Decoder Loss:  0.4702898
Encoder Loss:  0.09783227  || Decoder Loss:  0.19489597 Validation Decoder Loss:  0.47172317
Encoder Loss:  0.096984655  || Decoder Loss:  0.1923074 Validation Decoder Loss:  0.47126073
Encoder Loss:  0.096540205  || Decoder Loss:  0.19097842 Validation Decoder Loss:  0.4700421
Encoder Loss:  0.09612555  || Decoder Loss:  0.1897358 Validation Decoder Loss:  0.46936035
Encoder Loss:  0.095799856  || Decoder Loss:  0.1887718 Validation Decoder Loss:  0.46676487
Encoder Loss:  0.09548028  || Decoder Loss:  0.1878137 Validation Decoder Loss:  0.46340877
Encoder Loss:  0.095155396  || Decoder Loss:  0.18684356 Validation Decoder Loss:  0.46111625
Encoder Loss:  0.09483913  || Decoder Loss:  0.18589832 Validation Decoder Loss:  0.45951968
Encoder Loss:  0.09459417  || Decoder Loss:  0.18517764 Validation Decoder Loss:  0.45846927
Encoder Loss:  0.09443582  || Decoder Loss:  0.1847243 Validation Decoder Loss:  0.4575367
Encoder Loss:  0.094319396  || Decoder Loss:  0.18440309 Validation Decoder Loss:  0.45686924
Encoder Loss:  0.09422391  || Decoder Loss:  0.18414989 Validation Decoder Loss:  0.45690033
Encoder Loss:  0.094148606  || Decoder Loss:  0.18395762 Validation Decoder Loss:  0.45647964
Encoder Loss:  0.094083585  || Decoder Loss:  0.18380395 Validation Decoder Loss:  0.4555046
Model: bold_synthesis_net_lr_0.0007238784741583709 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4555046
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_231 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_103 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_53 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 790, 14, 1)        86        
_________________________________________________________________
dropout_233 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_78 (Conv2D)           (None, 420, 14, 1)        372       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 740, 14, 1)        322       
_________________________________________________________________
dropout_235 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_78 (Conv2DT (None, 874, 14, 1)        136       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19868454  || Decoder Loss:  0.29689598 Validation Decoder Loss:  0.47553766
Encoder Loss:  0.12658542  || Decoder Loss:  0.20441912 Validation Decoder Loss:  0.49460986
Encoder Loss:  0.10080944  || Decoder Loss:  0.20453182 Validation Decoder Loss:  0.49859428
Encoder Loss:  0.0875693  || Decoder Loss:  0.21112306 Validation Decoder Loss:  0.5048897
Encoder Loss:  0.086819194  || Decoder Loss:  0.21442817 Validation Decoder Loss:  0.5080067
Encoder Loss:  0.08582699  || Decoder Loss:  0.21364434 Validation Decoder Loss:  0.50563675
Encoder Loss:  0.08461643  || Decoder Loss:  0.21058732 Validation Decoder Loss:  0.4978507
Encoder Loss:  0.08352136  || Decoder Loss:  0.20718709 Validation Decoder Loss:  0.48336858
Encoder Loss:  0.08289318  || Decoder Loss:  0.20514837 Validation Decoder Loss:  0.4628588
Encoder Loss:  0.08362902  || Decoder Loss:  0.20933074 Validation Decoder Loss:  0.44617996
Encoder Loss:  0.08556278  || Decoder Loss:  0.21911316 Validation Decoder Loss:  0.43540692
Encoder Loss:  0.08796949  || Decoder Loss:  0.23100804 Validation Decoder Loss:  0.44146112
Encoder Loss:  0.08840155  || Decoder Loss:  0.2332956 Validation Decoder Loss:  0.47103536
Encoder Loss:  0.08513061  || Decoder Loss:  0.21766272 Validation Decoder Loss:  0.58199364
Encoder Loss:  0.08105744  || Decoder Loss:  0.19813593 Validation Decoder Loss:  0.56807554
Encoder Loss:  0.07870642  || Decoder Loss:  0.18691349 Validation Decoder Loss:  0.5654542
Encoder Loss:  0.07834495  || Decoder Loss:  0.185274 Validation Decoder Loss:  0.5619185
Encoder Loss:  0.07794856  || Decoder Loss:  0.18341802 Validation Decoder Loss:  0.556472
Encoder Loss:  0.07774912  || Decoder Loss:  0.18251888 Validation Decoder Loss:  0.5543597
Encoder Loss:  0.077532254  || Decoder Loss:  0.18150784 Validation Decoder Loss:  0.55095804
Encoder Loss:  0.077258475  || Decoder Loss:  0.18025216 Validation Decoder Loss:  0.55063313
Encoder Loss:  0.07711073  || Decoder Loss:  0.17957702 Validation Decoder Loss:  0.5507507
Encoder Loss:  0.07702014  || Decoder Loss:  0.17916273 Validation Decoder Loss:  0.54896694
Encoder Loss:  0.07691315  || Decoder Loss:  0.17869064 Validation Decoder Loss:  0.54853934
Encoder Loss:  0.07683995  || Decoder Loss:  0.17830884 Validation Decoder Loss:  0.5465754
Encoder Loss:  0.076752976  || Decoder Loss:  0.17792 Validation Decoder Loss:  0.54555917
Encoder Loss:  0.07668751  || Decoder Loss:  0.177633 Validation Decoder Loss:  0.5436898
Encoder Loss:  0.076613955  || Decoder Loss:  0.17732552 Validation Decoder Loss:  0.54182136
Encoder Loss:  0.076519065  || Decoder Loss:  0.17692131 Validation Decoder Loss:  0.54099846
Encoder Loss:  0.07645882  || Decoder Loss:  0.17660189 Validation Decoder Loss:  0.5404876
Encoder Loss:  0.07637312  || Decoder Loss:  0.17626783 Validation Decoder Loss:  0.54053754
Encoder Loss:  0.076315634  || Decoder Loss:  0.17599103 Validation Decoder Loss:  0.54040754
Encoder Loss:  0.07625153  || Decoder Loss:  0.17573038 Validation Decoder Loss:  0.54082423
Encoder Loss:  0.076204784  || Decoder Loss:  0.17551121 Validation Decoder Loss:  0.5408113
Encoder Loss:  0.07617151  || Decoder Loss:  0.17536542 Validation Decoder Loss:  0.5398752
Encoder Loss:  0.07611983  || Decoder Loss:  0.1751656 Validation Decoder Loss:  0.53950393
Encoder Loss:  0.07606137  || Decoder Loss:  0.17493422 Validation Decoder Loss:  0.5388119
Encoder Loss:  0.07601335  || Decoder Loss:  0.17470816 Validation Decoder Loss:  0.5377976
Encoder Loss:  0.07595644  || Decoder Loss:  0.17446372 Validation Decoder Loss:  0.53735375
Encoder Loss:  0.07590966  || Decoder Loss:  0.17428677 Validation Decoder Loss:  0.5379171
Model: bold_synthesis_net_lr_0.000433125109053258 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5379171
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_237 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_106 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_54 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 430, 14, 1)        446       
_________________________________________________________________
dropout_239 (Dropout)        (None, 430, 14, 1)        0         
_________________________________________________________________
conv2d_80 (Conv2D)           (None, 420, 14, 1)        12        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 610, 14, 1)        192       
_________________________________________________________________
dropout_241 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_80 (Conv2DT (None, 874, 14, 1)        266       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19946967  || Decoder Loss:  0.24136856 Validation Decoder Loss:  0.49210322
Encoder Loss:  0.18686776  || Decoder Loss:  0.23001757 Validation Decoder Loss:  0.48446712
Encoder Loss:  0.17953348  || Decoder Loss:  0.22694653 Validation Decoder Loss:  0.47797692
Encoder Loss:  0.17326085  || Decoder Loss:  0.22538383 Validation Decoder Loss:  0.4753294
Encoder Loss:  0.1694198  || Decoder Loss:  0.22557744 Validation Decoder Loss:  0.48951572
Encoder Loss:  0.16688985  || Decoder Loss:  0.2232066 Validation Decoder Loss:  0.49584755
Encoder Loss:  0.16514505  || Decoder Loss:  0.22090042 Validation Decoder Loss:  0.49778935
Encoder Loss:  0.16376048  || Decoder Loss:  0.21914937 Validation Decoder Loss:  0.50271344
Encoder Loss:  0.16255558  || Decoder Loss:  0.21769331 Validation Decoder Loss:  0.50691897
Encoder Loss:  0.16160297  || Decoder Loss:  0.21670696 Validation Decoder Loss:  0.5094038
Encoder Loss:  0.16086116  || Decoder Loss:  0.21606572 Validation Decoder Loss:  0.5071242
Encoder Loss:  0.1602127  || Decoder Loss:  0.2152409 Validation Decoder Loss:  0.5073767
Encoder Loss:  0.15943365  || Decoder Loss:  0.21417283 Validation Decoder Loss:  0.5082991
Encoder Loss:  0.1583667  || Decoder Loss:  0.21264793 Validation Decoder Loss:  0.5158912
Encoder Loss:  0.15736245  || Decoder Loss:  0.2112023 Validation Decoder Loss:  0.5129328
Encoder Loss:  0.15621276  || Decoder Loss:  0.20952632 Validation Decoder Loss:  0.49947837
Encoder Loss:  0.15501864  || Decoder Loss:  0.20776843 Validation Decoder Loss:  0.4939746
Encoder Loss:  0.15418951  || Decoder Loss:  0.20655502 Validation Decoder Loss:  0.49078625
Encoder Loss:  0.15346582  || Decoder Loss:  0.20549352 Validation Decoder Loss:  0.4883566
Encoder Loss:  0.15290663  || Decoder Loss:  0.2046734 Validation Decoder Loss:  0.48548168
Encoder Loss:  0.15244569  || Decoder Loss:  0.20399986 Validation Decoder Loss:  0.4801326
Encoder Loss:  0.15189959  || Decoder Loss:  0.20319147 Validation Decoder Loss:  0.4786243
Encoder Loss:  0.15156911  || Decoder Loss:  0.2027032 Validation Decoder Loss:  0.4758197
Encoder Loss:  0.1512739  || Decoder Loss:  0.20226863 Validation Decoder Loss:  0.4747225
Encoder Loss:  0.15111053  || Decoder Loss:  0.2020278 Validation Decoder Loss:  0.47312433
Encoder Loss:  0.1506116  || Decoder Loss:  0.20128144 Validation Decoder Loss:  0.47217777
Encoder Loss:  0.1485742  || Decoder Loss:  0.19821829 Validation Decoder Loss:  0.46694866
Encoder Loss:  0.14752606  || Decoder Loss:  0.1966427 Validation Decoder Loss:  0.4658264
Encoder Loss:  0.14702657  || Decoder Loss:  0.19589499 Validation Decoder Loss:  0.4657583
Encoder Loss:  0.14672552  || Decoder Loss:  0.19544764 Validation Decoder Loss:  0.46595383
Encoder Loss:  0.14644371  || Decoder Loss:  0.19502741 Validation Decoder Loss:  0.46587455
Encoder Loss:  0.14587268  || Decoder Loss:  0.19416846 Validation Decoder Loss:  0.47102153
Encoder Loss:  0.14498684  || Decoder Loss:  0.19283667 Validation Decoder Loss:  0.46937025
Encoder Loss:  0.14458287  || Decoder Loss:  0.19222604 Validation Decoder Loss:  0.46894586
Encoder Loss:  0.14432839  || Decoder Loss:  0.19185157 Validation Decoder Loss:  0.46860027
Encoder Loss:  0.14416762  || Decoder Loss:  0.19160965 Validation Decoder Loss:  0.46765584
Encoder Loss:  0.14399746  || Decoder Loss:  0.19135746 Validation Decoder Loss:  0.46664125
Encoder Loss:  0.14386651  || Decoder Loss:  0.1911618 Validation Decoder Loss:  0.46605465
Encoder Loss:  0.14374688  || Decoder Loss:  0.19098476 Validation Decoder Loss:  0.4653082
Encoder Loss:  0.14361262  || Decoder Loss:  0.19078217 Validation Decoder Loss:  0.46678993
Model: bold_synthesis_net_lr_0.0004455032444611994 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.46678993
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_108 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_243 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_109 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_55 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 620, 14, 1)        256       
_________________________________________________________________
dropout_245 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_82 (Conv2D)           (None, 420, 14, 1)        202       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 870, 14, 1)        452       
_________________________________________________________________
dropout_247 (Dropout)        (None, 870, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_82 (Conv2DT (None, 874, 14, 1)        6         
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19292812  || Decoder Loss:  0.2244355 Validation Decoder Loss:  0.49940175
Encoder Loss:  0.17812456  || Decoder Loss:  0.2126495 Validation Decoder Loss:  0.5050684
Encoder Loss:  0.1621295  || Decoder Loss:  0.20665927 Validation Decoder Loss:  0.5535816
Encoder Loss:  0.15713322  || Decoder Loss:  0.20014514 Validation Decoder Loss:  0.589916
Encoder Loss:  0.15249024  || Decoder Loss:  0.19378348 Validation Decoder Loss:  0.5850721
Encoder Loss:  0.15120511  || Decoder Loss:  0.19210681 Validation Decoder Loss:  0.5814394
Encoder Loss:  0.15052144  || Decoder Loss:  0.19127059 Validation Decoder Loss:  0.58042145
Encoder Loss:  0.15012392  || Decoder Loss:  0.19081888 Validation Decoder Loss:  0.579432
Encoder Loss:  0.14971663  || Decoder Loss:  0.19034195 Validation Decoder Loss:  0.578144
Encoder Loss:  0.14936294  || Decoder Loss:  0.18993427 Validation Decoder Loss:  0.57761943
Encoder Loss:  0.14910062  || Decoder Loss:  0.18964799 Validation Decoder Loss:  0.57756716
Encoder Loss:  0.1489889  || Decoder Loss:  0.1895588 Validation Decoder Loss:  0.57795316
Encoder Loss:  0.14900076  || Decoder Loss:  0.18963106 Validation Decoder Loss:  0.5783569
Encoder Loss:  0.14930147  || Decoder Loss:  0.19009902 Validation Decoder Loss:  0.5789206
Encoder Loss:  0.1500989  || Decoder Loss:  0.19127809 Validation Decoder Loss:  0.57557845
Encoder Loss:  0.15149613  || Decoder Loss:  0.19330245 Validation Decoder Loss:  0.5793222
Encoder Loss:  0.15170923  || Decoder Loss:  0.19361699 Validation Decoder Loss:  0.5807583
Encoder Loss:  0.1508697  || Decoder Loss:  0.19244055 Validation Decoder Loss:  0.57661206
Encoder Loss:  0.14972498  || Decoder Loss:  0.19082826 Validation Decoder Loss:  0.57189894
Encoder Loss:  0.14856589  || Decoder Loss:  0.18919608 Validation Decoder Loss:  0.56859165
Encoder Loss:  0.14730881  || Decoder Loss:  0.18742545 Validation Decoder Loss:  0.56530005
Encoder Loss:  0.1464641  || Decoder Loss:  0.18623611 Validation Decoder Loss:  0.56576574
Encoder Loss:  0.14591321  || Decoder Loss:  0.18545963 Validation Decoder Loss:  0.5638673
Encoder Loss:  0.14551969  || Decoder Loss:  0.18491033 Validation Decoder Loss:  0.5626453
Encoder Loss:  0.14518884  || Decoder Loss:  0.18444373 Validation Decoder Loss:  0.56279624
Encoder Loss:  0.14493304  || Decoder Loss:  0.18408974 Validation Decoder Loss:  0.5625066
Encoder Loss:  0.14466532  || Decoder Loss:  0.18371262 Validation Decoder Loss:  0.5617937
Encoder Loss:  0.1444284  || Decoder Loss:  0.18338124 Validation Decoder Loss:  0.56199896
Encoder Loss:  0.14417142  || Decoder Loss:  0.18302166 Validation Decoder Loss:  0.5613887
Encoder Loss:  0.14396453  || Decoder Loss:  0.18273105 Validation Decoder Loss:  0.56222916
Encoder Loss:  0.14378172  || Decoder Loss:  0.18247402 Validation Decoder Loss:  0.56285995
Encoder Loss:  0.14360261  || Decoder Loss:  0.18222246 Validation Decoder Loss:  0.56314224
Encoder Loss:  0.14348057  || Decoder Loss:  0.18205394 Validation Decoder Loss:  0.56442934
Encoder Loss:  0.14334457  || Decoder Loss:  0.1818592 Validation Decoder Loss:  0.5632873
Encoder Loss:  0.14323226  || Decoder Loss:  0.18170163 Validation Decoder Loss:  0.56312513
Encoder Loss:  0.1431038  || Decoder Loss:  0.18152279 Validation Decoder Loss:  0.5635511
Encoder Loss:  0.14301024  || Decoder Loss:  0.18139127 Validation Decoder Loss:  0.56219345
Encoder Loss:  0.1428726  || Decoder Loss:  0.1811974 Validation Decoder Loss:  0.56258804
Encoder Loss:  0.14273615  || Decoder Loss:  0.18100508 Validation Decoder Loss:  0.56347936
Encoder Loss:  0.14258799  || Decoder Loss:  0.18079658 Validation Decoder Loss:  0.56369245
Model: bold_synthesis_net_lr_0.0009696330466227707 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.56369245
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_111 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_249 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_112 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_56 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 630, 14, 1)        246       
_________________________________________________________________
dropout_251 (Dropout)        (None, 630, 14, 1)        0         
_________________________________________________________________
conv2d_84 (Conv2D)           (None, 420, 14, 1)        212       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 790, 14, 1)        372       
_________________________________________________________________
dropout_253 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_84 (Conv2DT (None, 874, 14, 1)        86        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35056528  || Decoder Loss:  0.43705422 Validation Decoder Loss:  0.9588471
Encoder Loss:  0.34632117  || Decoder Loss:  0.43604836 Validation Decoder Loss:  0.952022
Encoder Loss:  0.3416632  || Decoder Loss:  0.43485957 Validation Decoder Loss:  0.9431746
Encoder Loss:  0.33638832  || Decoder Loss:  0.43340984 Validation Decoder Loss:  0.931196
Encoder Loss:  0.33027822  || Decoder Loss:  0.43159372 Validation Decoder Loss:  0.9141984
Encoder Loss:  0.32303095  || Decoder Loss:  0.42924723 Validation Decoder Loss:  0.8889467
Encoder Loss:  0.3141768  || Decoder Loss:  0.4260963 Validation Decoder Loss:  0.8504528
Encoder Loss:  0.30295366  || Decoder Loss:  0.42165047 Validation Decoder Loss:  0.80820566
Encoder Loss:  0.28819948  || Decoder Loss:  0.41497406 Validation Decoder Loss:  0.7768371
Encoder Loss:  0.26846224  || Decoder Loss:  0.40415907 Validation Decoder Loss:  0.7215155
Encoder Loss:  0.24288797  || Decoder Loss:  0.38549283 Validation Decoder Loss:  0.6387189
Encoder Loss:  0.21218514  || Decoder Loss:  0.35281903 Validation Decoder Loss:  0.5495744
Encoder Loss:  0.17905694  || Decoder Loss:  0.30313128 Validation Decoder Loss:  0.46148175
Encoder Loss:  0.15075462  || Decoder Loss:  0.2513464 Validation Decoder Loss:  0.43735123
Encoder Loss:  0.13143703  || Decoder Loss:  0.21635929 Validation Decoder Loss:  0.4558777
Encoder Loss:  0.1241894  || Decoder Loss:  0.20506808 Validation Decoder Loss:  0.47085452
Encoder Loss:  0.12293579  || Decoder Loss:  0.20439085 Validation Decoder Loss:  0.47780186
Encoder Loss:  0.12197673  || Decoder Loss:  0.2046386 Validation Decoder Loss:  0.4832438
Encoder Loss:  0.121035896  || Decoder Loss:  0.20530236 Validation Decoder Loss:  0.48852053
Encoder Loss:  0.120166704  || Decoder Loss:  0.20638438 Validation Decoder Loss:  0.4930378
Encoder Loss:  0.11930027  || Decoder Loss:  0.20751126 Validation Decoder Loss:  0.4971139
Encoder Loss:  0.118390284  || Decoder Loss:  0.20866537 Validation Decoder Loss:  0.5005301
Encoder Loss:  0.117416725  || Decoder Loss:  0.20958981 Validation Decoder Loss:  0.50268257
Encoder Loss:  0.11631169  || Decoder Loss:  0.21014981 Validation Decoder Loss:  0.50310004
Encoder Loss:  0.115080096  || Decoder Loss:  0.21025994 Validation Decoder Loss:  0.50141424
Encoder Loss:  0.11366749  || Decoder Loss:  0.21008644 Validation Decoder Loss:  0.49759105
Encoder Loss:  0.11204958  || Decoder Loss:  0.20975582 Validation Decoder Loss:  0.49295005
Encoder Loss:  0.11018573  || Decoder Loss:  0.2095404 Validation Decoder Loss:  0.48868442
Encoder Loss:  0.10819982  || Decoder Loss:  0.2098411 Validation Decoder Loss:  0.48418823
Encoder Loss:  0.106130004  || Decoder Loss:  0.21049015 Validation Decoder Loss:  0.4797561
Encoder Loss:  0.10399477  || Decoder Loss:  0.21116105 Validation Decoder Loss:  0.4745597
Encoder Loss:  0.10188725  || Decoder Loss:  0.2116859 Validation Decoder Loss:  0.4679287
Encoder Loss:  0.09977158  || Decoder Loss:  0.21150807 Validation Decoder Loss:  0.4601072
Encoder Loss:  0.09767995  || Decoder Loss:  0.21069297 Validation Decoder Loss:  0.45242187
Encoder Loss:  0.09584959  || Decoder Loss:  0.2106786 Validation Decoder Loss:  0.44729817
Encoder Loss:  0.09426846  || Decoder Loss:  0.21139137 Validation Decoder Loss:  0.44422582
Encoder Loss:  0.09288536  || Decoder Loss:  0.21259007 Validation Decoder Loss:  0.44218713
Encoder Loss:  0.091678366  || Decoder Loss:  0.21419963 Validation Decoder Loss:  0.43966112
Encoder Loss:  0.09060176  || Decoder Loss:  0.2159884 Validation Decoder Loss:  0.43704566
Encoder Loss:  0.0896183  || Decoder Loss:  0.21773398 Validation Decoder Loss:  0.43493125
Model: bold_synthesis_net_lr_0.0009553067013343265 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.43493125
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_114 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_255 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_115 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_57 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 420, 14, 1)        456       
_________________________________________________________________
dropout_257 (Dropout)        (None, 420, 14, 1)        0         
_________________________________________________________________
conv2d_86 (Conv2D)           (None, 420, 14, 1)        2         
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 600, 14, 1)        182       
_________________________________________________________________
dropout_259 (Dropout)        (None, 600, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_86 (Conv2DT (None, 874, 14, 1)        276       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16152094  || Decoder Loss:  0.25405285 Validation Decoder Loss:  0.49581107
Encoder Loss:  0.15725291  || Decoder Loss:  0.24660142 Validation Decoder Loss:  0.49439636
Encoder Loss:  0.15451786  || Decoder Loss:  0.2416617 Validation Decoder Loss:  0.49355
Encoder Loss:  0.15283135  || Decoder Loss:  0.23858689 Validation Decoder Loss:  0.49283108
Encoder Loss:  0.15157151  || Decoder Loss:  0.236488 Validation Decoder Loss:  0.49213424
Encoder Loss:  0.15052167  || Decoder Loss:  0.23507163 Validation Decoder Loss:  0.49135578
Encoder Loss:  0.14948486  || Decoder Loss:  0.23397087 Validation Decoder Loss:  0.49057496
Encoder Loss:  0.14841484  || Decoder Loss:  0.23302695 Validation Decoder Loss:  0.48975104
Encoder Loss:  0.14732634  || Decoder Loss:  0.23228197 Validation Decoder Loss:  0.4888705
Encoder Loss:  0.14618358  || Decoder Loss:  0.23164132 Validation Decoder Loss:  0.48796666
Encoder Loss:  0.14496912  || Decoder Loss:  0.23102973 Validation Decoder Loss:  0.48705682
Encoder Loss:  0.14369217  || Decoder Loss:  0.23045118 Validation Decoder Loss:  0.48611093
Encoder Loss:  0.1423619  || Decoder Loss:  0.22991635 Validation Decoder Loss:  0.48515987
Encoder Loss:  0.14098693  || Decoder Loss:  0.22941409 Validation Decoder Loss:  0.48419705
Encoder Loss:  0.13958575  || Decoder Loss:  0.22896853 Validation Decoder Loss:  0.4832141
Encoder Loss:  0.1381616  || Decoder Loss:  0.22855341 Validation Decoder Loss:  0.4822645
Encoder Loss:  0.13671842  || Decoder Loss:  0.22815497 Validation Decoder Loss:  0.4812957
Encoder Loss:  0.13528721  || Decoder Loss:  0.227815 Validation Decoder Loss:  0.48033535
Encoder Loss:  0.13383548  || Decoder Loss:  0.2274726 Validation Decoder Loss:  0.4796223
Encoder Loss:  0.13235238  || Decoder Loss:  0.22704391 Validation Decoder Loss:  0.47906289
Encoder Loss:  0.13084961  || Decoder Loss:  0.2265555 Validation Decoder Loss:  0.4786243
Encoder Loss:  0.12935358  || Decoder Loss:  0.22609419 Validation Decoder Loss:  0.47812676
Encoder Loss:  0.12784243  || Decoder Loss:  0.22559337 Validation Decoder Loss:  0.47727108
Encoder Loss:  0.12625077  || Decoder Loss:  0.22481163 Validation Decoder Loss:  0.47668868
Encoder Loss:  0.12473962  || Decoder Loss:  0.22432989 Validation Decoder Loss:  0.47640455
Encoder Loss:  0.12323208  || Decoder Loss:  0.22386454 Validation Decoder Loss:  0.4762186
Encoder Loss:  0.121719286  || Decoder Loss:  0.22340563 Validation Decoder Loss:  0.47604683
Encoder Loss:  0.12019502  || Decoder Loss:  0.22291411 Validation Decoder Loss:  0.47589448
Encoder Loss:  0.11868149  || Decoder Loss:  0.2224677 Validation Decoder Loss:  0.4758497
Encoder Loss:  0.117191665  || Decoder Loss:  0.22212504 Validation Decoder Loss:  0.47588238
Encoder Loss:  0.11569876  || Decoder Loss:  0.22179505 Validation Decoder Loss:  0.4760069
Encoder Loss:  0.114177495  || Decoder Loss:  0.22141348 Validation Decoder Loss:  0.4762776
Encoder Loss:  0.112642266  || Decoder Loss:  0.22097702 Validation Decoder Loss:  0.47664043
Encoder Loss:  0.11122169  || Decoder Loss:  0.220631 Validation Decoder Loss:  0.47668803
Encoder Loss:  0.10985359  || Decoder Loss:  0.22030231 Validation Decoder Loss:  0.47690773
Encoder Loss:  0.10863191  || Decoder Loss:  0.2202278 Validation Decoder Loss:  0.47757357
Encoder Loss:  0.10748131  || Decoder Loss:  0.21999925 Validation Decoder Loss:  0.476843
Encoder Loss:  0.10652504  || Decoder Loss:  0.219976 Validation Decoder Loss:  0.47694695
Encoder Loss:  0.10569719  || Decoder Loss:  0.219923 Validation Decoder Loss:  0.47718158
Encoder Loss:  0.10507025  || Decoder Loss:  0.21990678 Validation Decoder Loss:  0.47732908
Model: bold_synthesis_net_lr_0.0001807211974926264 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.47732908
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_117 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_261 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_118 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_58 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 510, 14, 1)        366       
_________________________________________________________________
dropout_263 (Dropout)        (None, 510, 14, 1)        0         
_________________________________________________________________
conv2d_88 (Conv2D)           (None, 420, 14, 1)        92        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 670, 14, 1)        252       
_________________________________________________________________
dropout_265 (Dropout)        (None, 670, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_88 (Conv2DT (None, 874, 14, 1)        206       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2527782  || Decoder Loss:  0.26436466 Validation Decoder Loss:  0.4945978
Encoder Loss:  0.25077188  || Decoder Loss:  0.26226243 Validation Decoder Loss:  0.4932913
Encoder Loss:  0.24881364  || Decoder Loss:  0.26021174 Validation Decoder Loss:  0.49222478
Encoder Loss:  0.2469181  || Decoder Loss:  0.25822845 Validation Decoder Loss:  0.49131492
Encoder Loss:  0.24510181  || Decoder Loss:  0.2563294 Validation Decoder Loss:  0.4905597
Encoder Loss:  0.24338211  || Decoder Loss:  0.25453103 Validation Decoder Loss:  0.4899337
Encoder Loss:  0.24176785  || Decoder Loss:  0.2528416 Validation Decoder Loss:  0.48944038
Encoder Loss:  0.24029192  || Decoder Loss:  0.2512945 Validation Decoder Loss:  0.4890642
Encoder Loss:  0.23891838  || Decoder Loss:  0.24985373 Validation Decoder Loss:  0.48875728
Encoder Loss:  0.23766091  || Decoder Loss:  0.24853306 Validation Decoder Loss:  0.48851466
Encoder Loss:  0.23650423  || Decoder Loss:  0.24731678 Validation Decoder Loss:  0.48830864
Encoder Loss:  0.23542185  || Decoder Loss:  0.24617812 Validation Decoder Loss:  0.48814845
Encoder Loss:  0.23440996  || Decoder Loss:  0.24511316 Validation Decoder Loss:  0.4880156
Encoder Loss:  0.2334479  || Decoder Loss:  0.24410054 Validation Decoder Loss:  0.4879101
Encoder Loss:  0.2325314  || Decoder Loss:  0.24313614 Validation Decoder Loss:  0.4878249
Encoder Loss:  0.23164302  || Decoder Loss:  0.24220166 Validation Decoder Loss:  0.48776296
Encoder Loss:  0.23078628  || Decoder Loss:  0.24130103 Validation Decoder Loss:  0.4877174
Encoder Loss:  0.22996399  || Decoder Loss:  0.24043663 Validation Decoder Loss:  0.4876846
Encoder Loss:  0.22917868  || Decoder Loss:  0.23961136 Validation Decoder Loss:  0.48766726
Encoder Loss:  0.22841994  || Decoder Loss:  0.23881431 Validation Decoder Loss:  0.48766112
Encoder Loss:  0.22768608  || Decoder Loss:  0.2380433 Validation Decoder Loss:  0.48767292
Encoder Loss:  0.22697522  || Decoder Loss:  0.2372973 Validation Decoder Loss:  0.48769328
Encoder Loss:  0.22627893  || Decoder Loss:  0.23656711 Validation Decoder Loss:  0.48772085
Encoder Loss:  0.2255994  || Decoder Loss:  0.23585483 Validation Decoder Loss:  0.48776054
Encoder Loss:  0.22493911  || Decoder Loss:  0.23516282 Validation Decoder Loss:  0.48780623
Encoder Loss:  0.22429961  || Decoder Loss:  0.2344927 Validation Decoder Loss:  0.487867
Encoder Loss:  0.22367397  || Decoder Loss:  0.2338377 Validation Decoder Loss:  0.4879486
Encoder Loss:  0.22306143  || Decoder Loss:  0.23319651 Validation Decoder Loss:  0.48804107
Encoder Loss:  0.2224692  || Decoder Loss:  0.23257732 Validation Decoder Loss:  0.48813716
Encoder Loss:  0.2218812  || Decoder Loss:  0.23196313 Validation Decoder Loss:  0.48825034
Encoder Loss:  0.22130847  || Decoder Loss:  0.23136543 Validation Decoder Loss:  0.48836908
Encoder Loss:  0.22077693  || Decoder Loss:  0.23080969 Validation Decoder Loss:  0.4884863
Encoder Loss:  0.22028476  || Decoder Loss:  0.2302952 Validation Decoder Loss:  0.48861614
Encoder Loss:  0.21980728  || Decoder Loss:  0.22979572 Validation Decoder Loss:  0.48876667
Encoder Loss:  0.21934234  || Decoder Loss:  0.22930954 Validation Decoder Loss:  0.4889338
Encoder Loss:  0.21890056  || Decoder Loss:  0.22884743 Validation Decoder Loss:  0.4891037
Encoder Loss:  0.21847852  || Decoder Loss:  0.22840594 Validation Decoder Loss:  0.48927894
Encoder Loss:  0.2180679  || Decoder Loss:  0.22797664 Validation Decoder Loss:  0.48945388
Encoder Loss:  0.21766934  || Decoder Loss:  0.22755937 Validation Decoder Loss:  0.48963532
Encoder Loss:  0.21728817  || Decoder Loss:  0.22716065 Validation Decoder Loss:  0.48981392
Model: bold_synthesis_net_lr_8.428462950054597e-06 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.48981392
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_120 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_267 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_121 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_59 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 840, 14, 1)        36        
_________________________________________________________________
dropout_269 (Dropout)        (None, 840, 14, 1)        0         
_________________________________________________________________
conv2d_90 (Conv2D)           (None, 420, 14, 1)        3         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 760, 14, 1)        342       
_________________________________________________________________
dropout_271 (Dropout)        (None, 760, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_90 (Conv2DT (None, 874, 14, 1)        116       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21608326  || Decoder Loss:  0.4048694 Validation Decoder Loss:  0.7528687
Encoder Loss:  0.2099844  || Decoder Loss:  0.40066352 Validation Decoder Loss:  0.7359903
Encoder Loss:  0.20388627  || Decoder Loss:  0.3958255 Validation Decoder Loss:  0.717042
Encoder Loss:  0.19776948  || Decoder Loss:  0.39029735 Validation Decoder Loss:  0.6959887
Encoder Loss:  0.19160773  || Decoder Loss:  0.3839918 Validation Decoder Loss:  0.6731212
Encoder Loss:  0.18537669  || Decoder Loss:  0.37681347 Validation Decoder Loss:  0.6499395
Encoder Loss:  0.17908186  || Decoder Loss:  0.3686816 Validation Decoder Loss:  0.6281025
Encoder Loss:  0.17267618  || Decoder Loss:  0.35950768 Validation Decoder Loss:  0.6073718
Encoder Loss:  0.16612972  || Decoder Loss:  0.34922513 Validation Decoder Loss:  0.58607423
Encoder Loss:  0.15948871  || Decoder Loss:  0.33792782 Validation Decoder Loss:  0.56363934
Encoder Loss:  0.1533763  || Decoder Loss:  0.3264664 Validation Decoder Loss:  0.54291844
Encoder Loss:  0.14793794  || Decoder Loss:  0.31559467 Validation Decoder Loss:  0.5221722
Encoder Loss:  0.14251631  || Decoder Loss:  0.30442482 Validation Decoder Loss:  0.5026933
Encoder Loss:  0.1377224  || Decoder Loss:  0.29398197 Validation Decoder Loss:  0.4878768
Encoder Loss:  0.13404486  || Decoder Loss:  0.28531945 Validation Decoder Loss:  0.47625676
Encoder Loss:  0.13074766  || Decoder Loss:  0.27761334 Validation Decoder Loss:  0.4656061
Encoder Loss:  0.12758638  || Decoder Loss:  0.2702818 Validation Decoder Loss:  0.45660886
Encoder Loss:  0.12478789  || Decoder Loss:  0.26351726 Validation Decoder Loss:  0.45026654
Encoder Loss:  0.122664824  || Decoder Loss:  0.2580113 Validation Decoder Loss:  0.4463006
Encoder Loss:  0.12105002  || Decoder Loss:  0.25360557 Validation Decoder Loss:  0.44372776
Encoder Loss:  0.119689375  || Decoder Loss:  0.24980067 Validation Decoder Loss:  0.44171542
Encoder Loss:  0.11834287  || Decoder Loss:  0.24601749 Validation Decoder Loss:  0.43996796
Encoder Loss:  0.11711239  || Decoder Loss:  0.2424597 Validation Decoder Loss:  0.43855226
Encoder Loss:  0.116065614  || Decoder Loss:  0.23935086 Validation Decoder Loss:  0.437536
Encoder Loss:  0.1152391  || Decoder Loss:  0.23685805 Validation Decoder Loss:  0.43676957
Encoder Loss:  0.11460624  || Decoder Loss:  0.23497851 Validation Decoder Loss:  0.43623364
Encoder Loss:  0.11409423  || Decoder Loss:  0.23356345 Validation Decoder Loss:  0.43577373
Encoder Loss:  0.113632746  || Decoder Loss:  0.23233461 Validation Decoder Loss:  0.4354553
Encoder Loss:  0.113264196  || Decoder Loss:  0.23144418 Validation Decoder Loss:  0.43518534
Encoder Loss:  0.11294989  || Decoder Loss:  0.2308069 Validation Decoder Loss:  0.4349997
Encoder Loss:  0.11263135  || Decoder Loss:  0.23017272 Validation Decoder Loss:  0.4348913
Encoder Loss:  0.112323605  || Decoder Loss:  0.22959262 Validation Decoder Loss:  0.43494338
Encoder Loss:  0.11205167  || Decoder Loss:  0.22918716 Validation Decoder Loss:  0.43503943
Encoder Loss:  0.11180691  || Decoder Loss:  0.22890672 Validation Decoder Loss:  0.43491456
Encoder Loss:  0.11156964  || Decoder Loss:  0.22868332 Validation Decoder Loss:  0.43464568
Encoder Loss:  0.11133554  || Decoder Loss:  0.22848779 Validation Decoder Loss:  0.43437225
Encoder Loss:  0.11109486  || Decoder Loss:  0.22827779 Validation Decoder Loss:  0.43406773
Encoder Loss:  0.110859595  || Decoder Loss:  0.22809978 Validation Decoder Loss:  0.43375397
Encoder Loss:  0.110626705  || Decoder Loss:  0.22794574 Validation Decoder Loss:  0.43346974
Encoder Loss:  0.110390104  || Decoder Loss:  0.22777838 Validation Decoder Loss:  0.433214
Model: bold_synthesis_net_lr_0.00019867009055412582 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.433214
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_123 (Conv3D (None, 82, 5, 14, 1)      20        
_________________________________________________________________
dropout_273 (Dropout)        (None, 82, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_124 (Conv3D (None, 84, 5, 14, 1)      4         
_________________________________________________________________
reshape_60 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 750, 14, 1)        126       
_________________________________________________________________
dropout_275 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_92 (Conv2D)           (None, 420, 14, 1)        332       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_277 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_92 (Conv2DT (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24218383  || Decoder Loss:  0.25248268 Validation Decoder Loss:  0.500546
Encoder Loss:  0.228327  || Decoder Loss:  0.23788841 Validation Decoder Loss:  0.49750197
Encoder Loss:  0.22182053  || Decoder Loss:  0.23099676 Validation Decoder Loss:  0.49549067
Encoder Loss:  0.21769382  || Decoder Loss:  0.22666296 Validation Decoder Loss:  0.4938613
Encoder Loss:  0.2144193  || Decoder Loss:  0.22330225 Validation Decoder Loss:  0.4931282
Encoder Loss:  0.21136504  || Decoder Loss:  0.22026567 Validation Decoder Loss:  0.4934594
Encoder Loss:  0.20843193  || Decoder Loss:  0.21747297 Validation Decoder Loss:  0.49428332
Encoder Loss:  0.20568384  || Decoder Loss:  0.21504027 Validation Decoder Loss:  0.49570084
Encoder Loss:  0.20311065  || Decoder Loss:  0.2129897 Validation Decoder Loss:  0.4993786
Encoder Loss:  0.20118508  || Decoder Loss:  0.21175407 Validation Decoder Loss:  0.5038255
Encoder Loss:  0.20028722  || Decoder Loss:  0.21157597 Validation Decoder Loss:  0.50754946
Encoder Loss:  0.20011625  || Decoder Loss:  0.21201849 Validation Decoder Loss:  0.50962836
Encoder Loss:  0.2001758  || Decoder Loss:  0.21252084 Validation Decoder Loss:  0.5113037
Encoder Loss:  0.20069668  || Decoder Loss:  0.2133378 Validation Decoder Loss:  0.5128186
Encoder Loss:  0.2011817  || Decoder Loss:  0.21401423 Validation Decoder Loss:  0.5129408
Encoder Loss:  0.20110105  || Decoder Loss:  0.21397638 Validation Decoder Loss:  0.51159215
Encoder Loss:  0.20071396  || Decoder Loss:  0.21358047 Validation Decoder Loss:  0.5103048
Encoder Loss:  0.20053165  || Decoder Loss:  0.21340407 Validation Decoder Loss:  0.51000524
Encoder Loss:  0.20055741  || Decoder Loss:  0.21345323 Validation Decoder Loss:  0.51033425
Encoder Loss:  0.2006356  || Decoder Loss:  0.21355839 Validation Decoder Loss:  0.51091105
Encoder Loss:  0.2007103  || Decoder Loss:  0.21365918 Validation Decoder Loss:  0.5112223
Encoder Loss:  0.20077068  || Decoder Loss:  0.21374339 Validation Decoder Loss:  0.51115495
Encoder Loss:  0.20072453  || Decoder Loss:  0.21370797 Validation Decoder Loss:  0.5109601
Encoder Loss:  0.2005614  || Decoder Loss:  0.21354286 Validation Decoder Loss:  0.5109804
Encoder Loss:  0.20029317  || Decoder Loss:  0.2132622 Validation Decoder Loss:  0.5117917
Encoder Loss:  0.20004493  || Decoder Loss:  0.21300195 Validation Decoder Loss:  0.51097333
Encoder Loss:  0.19971247  || Decoder Loss:  0.21264929 Validation Decoder Loss:  0.50420576
Encoder Loss:  0.19653106  || Decoder Loss:  0.20919429 Validation Decoder Loss:  0.5049194
Encoder Loss:  0.19584014  || Decoder Loss:  0.20844936 Validation Decoder Loss:  0.502804
Encoder Loss:  0.19552168  || Decoder Loss:  0.20810935 Validation Decoder Loss:  0.5020375
Encoder Loss:  0.1953087  || Decoder Loss:  0.2078827 Validation Decoder Loss:  0.50238574
Encoder Loss:  0.19517247  || Decoder Loss:  0.20773923 Validation Decoder Loss:  0.50247264
Encoder Loss:  0.19509141  || Decoder Loss:  0.20765433 Validation Decoder Loss:  0.5024727
Encoder Loss:  0.1950825  || Decoder Loss:  0.2076475 Validation Decoder Loss:  0.5024665
Encoder Loss:  0.19503272  || Decoder Loss:  0.20759606 Validation Decoder Loss:  0.50260496
Encoder Loss:  0.19494464  || Decoder Loss:  0.20750274 Validation Decoder Loss:  0.5026574
Encoder Loss:  0.19478838  || Decoder Loss:  0.2073352 Validation Decoder Loss:  0.5030568
Encoder Loss:  0.19470677  || Decoder Loss:  0.20724852 Validation Decoder Loss:  0.5035032
Encoder Loss:  0.19461858  || Decoder Loss:  0.20715454 Validation Decoder Loss:  0.50458264
Encoder Loss:  0.19452998  || Decoder Loss:  0.20705992 Validation Decoder Loss:  0.5057215
Model: bold_synthesis_net_lr_0.0004590016545022522 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5057215
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_126 (Conv3D (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_279 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_127 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_61 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 670, 14, 1)        206       
_________________________________________________________________
dropout_281 (Dropout)        (None, 670, 14, 1)        0         
_________________________________________________________________
conv2d_94 (Conv2D)           (None, 420, 14, 1)        252       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 820, 14, 1)        402       
_________________________________________________________________
dropout_283 (Dropout)        (None, 820, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_94 (Conv2DT (None, 874, 14, 1)        56        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24711516  || Decoder Loss:  0.26702747 Validation Decoder Loss:  0.47618508
Encoder Loss:  0.19252044  || Decoder Loss:  0.21057908 Validation Decoder Loss:  0.48184407
Encoder Loss:  0.18263301  || Decoder Loss:  0.20606391 Validation Decoder Loss:  0.47418392
Encoder Loss:  0.1801314  || Decoder Loss:  0.20434864 Validation Decoder Loss:  0.4725281
Encoder Loss:  0.17873247  || Decoder Loss:  0.20285396 Validation Decoder Loss:  0.46971348
Encoder Loss:  0.17753899  || Decoder Loss:  0.20159175 Validation Decoder Loss:  0.46929988
Encoder Loss:  0.17705013  || Decoder Loss:  0.20114012 Validation Decoder Loss:  0.46892
Encoder Loss:  0.17691149  || Decoder Loss:  0.20104025 Validation Decoder Loss:  0.4676413
Encoder Loss:  0.1767806  || Decoder Loss:  0.2009185 Validation Decoder Loss:  0.4663259
Encoder Loss:  0.17664014  || Decoder Loss:  0.20077662 Validation Decoder Loss:  0.46496007
Encoder Loss:  0.17652754  || Decoder Loss:  0.20066343 Validation Decoder Loss:  0.46397027
Encoder Loss:  0.17643763  || Decoder Loss:  0.2005734 Validation Decoder Loss:  0.46317178
Encoder Loss:  0.1764182  || Decoder Loss:  0.20056647 Validation Decoder Loss:  0.46200806
Encoder Loss:  0.17650871  || Decoder Loss:  0.20068584 Validation Decoder Loss:  0.46067634
Encoder Loss:  0.17664047  || Decoder Loss:  0.20085159 Validation Decoder Loss:  0.45940974
Encoder Loss:  0.1768831  || Decoder Loss:  0.20114884 Validation Decoder Loss:  0.45815635
Encoder Loss:  0.17725173  || Decoder Loss:  0.20159507 Validation Decoder Loss:  0.45686397
Encoder Loss:  0.17807075  || Decoder Loss:  0.20257838 Validation Decoder Loss:  0.45506638
Encoder Loss:  0.17993116  || Decoder Loss:  0.20480269 Validation Decoder Loss:  0.453714
Encoder Loss:  0.18426876  || Decoder Loss:  0.20998162 Validation Decoder Loss:  0.54213035
Encoder Loss:  0.17867512  || Decoder Loss:  0.20332003 Validation Decoder Loss:  0.58931696
Encoder Loss:  0.17129636  || Decoder Loss:  0.19453667 Validation Decoder Loss:  0.59642553
Encoder Loss:  0.16689003  || Decoder Loss:  0.18930553 Validation Decoder Loss:  0.59496135
Encoder Loss:  0.16912296  || Decoder Loss:  0.19200106 Validation Decoder Loss:  0.60228604
Encoder Loss:  0.17339514  || Decoder Loss:  0.19711095 Validation Decoder Loss:  0.6072124
Encoder Loss:  0.17143947  || Decoder Loss:  0.19478211 Validation Decoder Loss:  0.6103741
Encoder Loss:  0.17033567  || Decoder Loss:  0.19346622 Validation Decoder Loss:  0.61119914
Encoder Loss:  0.17037278  || Decoder Loss:  0.19351068 Validation Decoder Loss:  0.6031387
Encoder Loss:  0.16988648  || Decoder Loss:  0.19293347 Validation Decoder Loss:  0.62522006
Encoder Loss:  0.16912471  || Decoder Loss:  0.19202514 Validation Decoder Loss:  0.6218259
Encoder Loss:  0.17002441  || Decoder Loss:  0.19309932 Validation Decoder Loss:  0.6083305
Encoder Loss:  0.1698423  || Decoder Loss:  0.19288243 Validation Decoder Loss:  0.62902063
Encoder Loss:  0.16994898  || Decoder Loss:  0.19300963 Validation Decoder Loss:  0.62017256
Encoder Loss:  0.16979039  || Decoder Loss:  0.19282225 Validation Decoder Loss:  0.61999494
Encoder Loss:  0.16999404  || Decoder Loss:  0.1930651 Validation Decoder Loss:  0.61285543
Encoder Loss:  0.16907576  || Decoder Loss:  0.19197036 Validation Decoder Loss:  0.61906683
Encoder Loss:  0.17052892  || Decoder Loss:  0.19370311 Validation Decoder Loss:  0.63533765
Encoder Loss:  0.17046495  || Decoder Loss:  0.19362806 Validation Decoder Loss:  0.6077253
Encoder Loss:  0.17008065  || Decoder Loss:  0.19316944 Validation Decoder Loss:  0.61486334
Encoder Loss:  0.17072667  || Decoder Loss:  0.19394055 Validation Decoder Loss:  0.60536796
Model: bold_synthesis_net_lr_0.0007385486602750674 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.60536796
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_129 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_285 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_130 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_62 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 450, 14, 1)        426       
_________________________________________________________________
dropout_287 (Dropout)        (None, 450, 14, 1)        0         
_________________________________________________________________
conv2d_96 (Conv2D)           (None, 420, 14, 1)        32        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 640, 14, 1)        222       
_________________________________________________________________
dropout_289 (Dropout)        (None, 640, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_96 (Conv2DT (None, 874, 14, 1)        236       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24711247  || Decoder Loss:  0.24904068 Validation Decoder Loss:  0.49472702
Encoder Loss:  0.23331584  || Decoder Loss:  0.23513258 Validation Decoder Loss:  0.4947192
Encoder Loss:  0.2288396  || Decoder Loss:  0.23065214 Validation Decoder Loss:  0.49375683
Encoder Loss:  0.22693953  || Decoder Loss:  0.22879484 Validation Decoder Loss:  0.4921206
Encoder Loss:  0.22593245  || Decoder Loss:  0.22785443 Validation Decoder Loss:  0.48994312
Encoder Loss:  0.22522904  || Decoder Loss:  0.22723031 Validation Decoder Loss:  0.48752305
Encoder Loss:  0.22459228  || Decoder Loss:  0.22667909 Validation Decoder Loss:  0.48477978
Encoder Loss:  0.22393784  || Decoder Loss:  0.22611353 Validation Decoder Loss:  0.4825292
Encoder Loss:  0.223032  || Decoder Loss:  0.22529387 Validation Decoder Loss:  0.4811516
Encoder Loss:  0.22196326  || Decoder Loss:  0.22431129 Validation Decoder Loss:  0.48011124
Encoder Loss:  0.22037414  || Decoder Loss:  0.22281215 Validation Decoder Loss:  0.48039454
Encoder Loss:  0.21875517  || Decoder Loss:  0.22132072 Validation Decoder Loss:  0.47936082
Encoder Loss:  0.21701866  || Decoder Loss:  0.2195965 Validation Decoder Loss:  0.47755486
Encoder Loss:  0.21565177  || Decoder Loss:  0.21821085 Validation Decoder Loss:  0.47571197
Encoder Loss:  0.2149829  || Decoder Loss:  0.2175332 Validation Decoder Loss:  0.47426003
Encoder Loss:  0.21453068  || Decoder Loss:  0.21707559 Validation Decoder Loss:  0.47356555
Encoder Loss:  0.21405528  || Decoder Loss:  0.21659435 Validation Decoder Loss:  0.47787982
Encoder Loss:  0.21305507  || Decoder Loss:  0.21558002 Validation Decoder Loss:  0.535516
Encoder Loss:  0.21481854  || Decoder Loss:  0.21737419 Validation Decoder Loss:  0.48121613
Encoder Loss:  0.21333475  || Decoder Loss:  0.21586819 Validation Decoder Loss:  0.49191597
Encoder Loss:  0.21324757  || Decoder Loss:  0.21578185 Validation Decoder Loss:  0.5269965
Encoder Loss:  0.2128708  || Decoder Loss:  0.21540108 Validation Decoder Loss:  0.5401275
Encoder Loss:  0.21322286  || Decoder Loss:  0.21576092 Validation Decoder Loss:  0.54181695
Encoder Loss:  0.21305613  || Decoder Loss:  0.21559365 Validation Decoder Loss:  0.53950423
Encoder Loss:  0.21262251  || Decoder Loss:  0.21515518 Validation Decoder Loss:  0.55761033
Encoder Loss:  0.20712075  || Decoder Loss:  0.20956604 Validation Decoder Loss:  0.57236814
Encoder Loss:  0.19690222  || Decoder Loss:  0.19918329 Validation Decoder Loss:  0.5591075
Encoder Loss:  0.19251871  || Decoder Loss:  0.1947306 Validation Decoder Loss:  0.5548253
Encoder Loss:  0.18880506  || Decoder Loss:  0.19095844 Validation Decoder Loss:  0.5489908
Encoder Loss:  0.18747813  || Decoder Loss:  0.1896116 Validation Decoder Loss:  0.5470628
Encoder Loss:  0.18669225  || Decoder Loss:  0.1888145 Validation Decoder Loss:  0.5463627
Encoder Loss:  0.18600498  || Decoder Loss:  0.18811756 Validation Decoder Loss:  0.5451986
Encoder Loss:  0.18539025  || Decoder Loss:  0.18749394 Validation Decoder Loss:  0.54454345
Encoder Loss:  0.18483329  || Decoder Loss:  0.18692882 Validation Decoder Loss:  0.54473656
Encoder Loss:  0.18429929  || Decoder Loss:  0.18638697 Validation Decoder Loss:  0.54530406
Encoder Loss:  0.1837935  || Decoder Loss:  0.18587363 Validation Decoder Loss:  0.54568624
Encoder Loss:  0.1833505  || Decoder Loss:  0.1854241 Validation Decoder Loss:  0.5455783
Encoder Loss:  0.18294315  || Decoder Loss:  0.18501055 Validation Decoder Loss:  0.54601806
Encoder Loss:  0.18257232  || Decoder Loss:  0.18463436 Validation Decoder Loss:  0.5465357
Encoder Loss:  0.18221048  || Decoder Loss:  0.18426724 Validation Decoder Loss:  0.54668057
Model: bold_synthesis_net_lr_0.0007916255463190836 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.54668057
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_132 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_291 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_133 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_63 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 690, 14, 1)        186       
_________________________________________________________________
dropout_293 (Dropout)        (None, 690, 14, 1)        0         
_________________________________________________________________
conv2d_98 (Conv2D)           (None, 420, 14, 1)        272       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 680, 14, 1)        262       
_________________________________________________________________
dropout_295 (Dropout)        (None, 680, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_98 (Conv2DT (None, 874, 14, 1)        196       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21245079  || Decoder Loss:  0.22980386 Validation Decoder Loss:  0.4969612
Encoder Loss:  0.19622049  || Decoder Loss:  0.21277016 Validation Decoder Loss:  0.5022354
Encoder Loss:  0.18810889  || Decoder Loss:  0.21132055 Validation Decoder Loss:  0.50466746
Encoder Loss:  0.18659091  || Decoder Loss:  0.21090354 Validation Decoder Loss:  0.4917179
Encoder Loss:  0.18258964  || Decoder Loss:  0.20636132 Validation Decoder Loss:  0.4851367
Encoder Loss:  0.18087696  || Decoder Loss:  0.20449279 Validation Decoder Loss:  0.4852216
Encoder Loss:  0.17954601  || Decoder Loss:  0.20302717 Validation Decoder Loss:  0.48137695
Encoder Loss:  0.17771806  || Decoder Loss:  0.20094697 Validation Decoder Loss:  0.4875005
Encoder Loss:  0.17397279  || Decoder Loss:  0.19658558 Validation Decoder Loss:  0.48121944
Encoder Loss:  0.17050306  || Decoder Loss:  0.19253917 Validation Decoder Loss:  0.48478422
Encoder Loss:  0.1670056  || Decoder Loss:  0.18844584 Validation Decoder Loss:  0.48957616
Encoder Loss:  0.1654166  || Decoder Loss:  0.18660013 Validation Decoder Loss:  0.49022034
Encoder Loss:  0.16444078  || Decoder Loss:  0.18547554 Validation Decoder Loss:  0.48879093
Encoder Loss:  0.16426183  || Decoder Loss:  0.18528716 Validation Decoder Loss:  0.48531651
Encoder Loss:  0.16424286  || Decoder Loss:  0.18528737 Validation Decoder Loss:  0.48726165
Encoder Loss:  0.16097145  || Decoder Loss:  0.18142918 Validation Decoder Loss:  0.5098115
Encoder Loss:  0.15285857  || Decoder Loss:  0.17182752 Validation Decoder Loss:  0.5485985
Encoder Loss:  0.1467951  || Decoder Loss:  0.16464819 Validation Decoder Loss:  0.542121
Encoder Loss:  0.14532259  || Decoder Loss:  0.16290699 Validation Decoder Loss:  0.5402354
Encoder Loss:  0.1446108  || Decoder Loss:  0.16206609 Validation Decoder Loss:  0.53801644
Encoder Loss:  0.14401087  || Decoder Loss:  0.1613579 Validation Decoder Loss:  0.53777087
Encoder Loss:  0.14331754  || Decoder Loss:  0.16053753 Validation Decoder Loss:  0.5353426
Encoder Loss:  0.14232866  || Decoder Loss:  0.1593673 Validation Decoder Loss:  0.533762
Encoder Loss:  0.14098588  || Decoder Loss:  0.15777732 Validation Decoder Loss:  0.53637046
Encoder Loss:  0.13926402  || Decoder Loss:  0.1557387 Validation Decoder Loss:  0.54087335
Encoder Loss:  0.13781701  || Decoder Loss:  0.15402474 Validation Decoder Loss:  0.54358375
Encoder Loss:  0.1372225  || Decoder Loss:  0.1533227 Validation Decoder Loss:  0.5452394
Encoder Loss:  0.13678353  || Decoder Loss:  0.15280229 Validation Decoder Loss:  0.54736173
Encoder Loss:  0.1364296  || Decoder Loss:  0.15238428 Validation Decoder Loss:  0.5478416
Encoder Loss:  0.13624084  || Decoder Loss:  0.15216152 Validation Decoder Loss:  0.5485324
Encoder Loss:  0.1360883  || Decoder Loss:  0.15198135 Validation Decoder Loss:  0.5491605
Encoder Loss:  0.13595785  || Decoder Loss:  0.15182704 Validation Decoder Loss:  0.54980326
Encoder Loss:  0.13587928  || Decoder Loss:  0.1517338 Validation Decoder Loss:  0.5505621
Encoder Loss:  0.1357385  || Decoder Loss:  0.15156792 Validation Decoder Loss:  0.5506308
Encoder Loss:  0.13553792  || Decoder Loss:  0.15133095 Validation Decoder Loss:  0.5514088
Encoder Loss:  0.13530822  || Decoder Loss:  0.15105927 Validation Decoder Loss:  0.5524122
Encoder Loss:  0.13511641  || Decoder Loss:  0.15083233 Validation Decoder Loss:  0.5531812
Encoder Loss:  0.13490233  || Decoder Loss:  0.15057892 Validation Decoder Loss:  0.5533019
Encoder Loss:  0.13473792  || Decoder Loss:  0.15038519 Validation Decoder Loss:  0.55261797
Encoder Loss:  0.1345866  || Decoder Loss:  0.15020478 Validation Decoder Loss:  0.5518401
Model: bold_synthesis_net_lr_0.0008762384973529251 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5518401
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_135 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_297 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_136 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_64 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 630, 14, 1)        246       
_________________________________________________________________
dropout_299 (Dropout)        (None, 630, 14, 1)        0         
_________________________________________________________________
conv2d_100 (Conv2D)          (None, 420, 14, 1)        212       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 790, 14, 1)        372       
_________________________________________________________________
dropout_301 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_100 (Conv2D (None, 874, 14, 1)        86        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3505653  || Decoder Loss:  0.43705422 Validation Decoder Loss:  0.9588471
Encoder Loss:  0.34632117  || Decoder Loss:  0.43604836 Validation Decoder Loss:  0.952022
Encoder Loss:  0.3416632  || Decoder Loss:  0.43485957 Validation Decoder Loss:  0.9431746
Encoder Loss:  0.33638835  || Decoder Loss:  0.43340984 Validation Decoder Loss:  0.931196
Encoder Loss:  0.33027822  || Decoder Loss:  0.43159372 Validation Decoder Loss:  0.91419846
Encoder Loss:  0.32303095  || Decoder Loss:  0.42924723 Validation Decoder Loss:  0.8889467
Encoder Loss:  0.3141768  || Decoder Loss:  0.4260963 Validation Decoder Loss:  0.8504528
Encoder Loss:  0.30295366  || Decoder Loss:  0.42165047 Validation Decoder Loss:  0.80820566
Encoder Loss:  0.28819948  || Decoder Loss:  0.41497406 Validation Decoder Loss:  0.7768371
Encoder Loss:  0.26846224  || Decoder Loss:  0.40415907 Validation Decoder Loss:  0.7215156
Encoder Loss:  0.24288797  || Decoder Loss:  0.38549283 Validation Decoder Loss:  0.6387189
Encoder Loss:  0.21218514  || Decoder Loss:  0.352819 Validation Decoder Loss:  0.54957443
Encoder Loss:  0.17905694  || Decoder Loss:  0.30313128 Validation Decoder Loss:  0.46148175
Encoder Loss:  0.15075462  || Decoder Loss:  0.2513464 Validation Decoder Loss:  0.43735123
Encoder Loss:  0.13143703  || Decoder Loss:  0.21635929 Validation Decoder Loss:  0.4558777
Encoder Loss:  0.1241894  || Decoder Loss:  0.20506808 Validation Decoder Loss:  0.47085452
Encoder Loss:  0.12293579  || Decoder Loss:  0.20439085 Validation Decoder Loss:  0.47780186
Encoder Loss:  0.12197673  || Decoder Loss:  0.2046386 Validation Decoder Loss:  0.4832438
Encoder Loss:  0.121035896  || Decoder Loss:  0.20530236 Validation Decoder Loss:  0.48852053
Encoder Loss:  0.120166704  || Decoder Loss:  0.20638438 Validation Decoder Loss:  0.49303776
Encoder Loss:  0.11930027  || Decoder Loss:  0.20751123 Validation Decoder Loss:  0.49711394
Encoder Loss:  0.118390284  || Decoder Loss:  0.20866537 Validation Decoder Loss:  0.5005301
Encoder Loss:  0.117416725  || Decoder Loss:  0.20958984 Validation Decoder Loss:  0.50268257
Encoder Loss:  0.116311684  || Decoder Loss:  0.21014981 Validation Decoder Loss:  0.5031
Encoder Loss:  0.11508008  || Decoder Loss:  0.21025988 Validation Decoder Loss:  0.5014142
Encoder Loss:  0.11366751  || Decoder Loss:  0.21008661 Validation Decoder Loss:  0.49759147
Encoder Loss:  0.11204954  || Decoder Loss:  0.20975558 Validation Decoder Loss:  0.49294934
Encoder Loss:  0.110185646  || Decoder Loss:  0.20953982 Validation Decoder Loss:  0.48868224
Encoder Loss:  0.1081997  || Decoder Loss:  0.20984033 Validation Decoder Loss:  0.48418632
Encoder Loss:  0.10612985  || Decoder Loss:  0.21048915 Validation Decoder Loss:  0.479756
Encoder Loss:  0.1039948  || Decoder Loss:  0.21116114 Validation Decoder Loss:  0.474559
Encoder Loss:  0.101887204  || Decoder Loss:  0.21168551 Validation Decoder Loss:  0.4679266
Encoder Loss:  0.09977113  || Decoder Loss:  0.21150486 Validation Decoder Loss:  0.4601038
Encoder Loss:  0.09767945  || Decoder Loss:  0.21068951 Validation Decoder Loss:  0.4524244
Encoder Loss:  0.09584957  || Decoder Loss:  0.21067858 Validation Decoder Loss:  0.44730008
Encoder Loss:  0.094268635  || Decoder Loss:  0.21139248 Validation Decoder Loss:  0.44422472
Encoder Loss:  0.092885315  || Decoder Loss:  0.21258971 Validation Decoder Loss:  0.4421883
Encoder Loss:  0.091678366  || Decoder Loss:  0.21419966 Validation Decoder Loss:  0.43965814
Encoder Loss:  0.090601616  || Decoder Loss:  0.21598741 Validation Decoder Loss:  0.43704355
Encoder Loss:  0.08961825  || Decoder Loss:  0.21773367 Validation Decoder Loss:  0.43492642
Model: bold_synthesis_net_lr_0.0009553067013384381 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.43492642
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_138 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_303 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_139 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_65 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 490, 14, 1)        386       
_________________________________________________________________
dropout_305 (Dropout)        (None, 490, 14, 1)        0         
_________________________________________________________________
conv2d_102 (Conv2D)          (None, 420, 14, 1)        72        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 810, 14, 1)        392       
_________________________________________________________________
dropout_307 (Dropout)        (None, 810, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_102 (Conv2D (None, 874, 14, 1)        66        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21404931  || Decoder Loss:  0.22865464 Validation Decoder Loss:  0.4997262
Encoder Loss:  0.193155  || Decoder Loss:  0.21170545 Validation Decoder Loss:  0.48836
Encoder Loss:  0.18779306  || Decoder Loss:  0.20745096 Validation Decoder Loss:  0.48283178
Encoder Loss:  0.18472962  || Decoder Loss:  0.20402257 Validation Decoder Loss:  0.47566214
Encoder Loss:  0.18354215  || Decoder Loss:  0.20271595 Validation Decoder Loss:  0.47314018
Encoder Loss:  0.1827269  || Decoder Loss:  0.20182092 Validation Decoder Loss:  0.47113174
Encoder Loss:  0.18193108  || Decoder Loss:  0.2009455 Validation Decoder Loss:  0.46938252
Encoder Loss:  0.18113887  || Decoder Loss:  0.20006922 Validation Decoder Loss:  0.4680312
Encoder Loss:  0.17937209  || Decoder Loss:  0.19807445 Validation Decoder Loss:  0.47194478
Encoder Loss:  0.17879549  || Decoder Loss:  0.19744018 Validation Decoder Loss:  0.4692062
Encoder Loss:  0.1786684  || Decoder Loss:  0.19731537 Validation Decoder Loss:  0.46639332
Encoder Loss:  0.17866935  || Decoder Loss:  0.1973368 Validation Decoder Loss:  0.4633403
Encoder Loss:  0.17854688  || Decoder Loss:  0.19720705 Validation Decoder Loss:  0.46316448
Encoder Loss:  0.1780813  || Decoder Loss:  0.19668041 Validation Decoder Loss:  0.4667717
Encoder Loss:  0.17756717  || Decoder Loss:  0.19609739 Validation Decoder Loss:  0.47084266
Encoder Loss:  0.17718694  || Decoder Loss:  0.1956669 Validation Decoder Loss:  0.47405225
Encoder Loss:  0.17707567  || Decoder Loss:  0.19554344 Validation Decoder Loss:  0.47587734
Encoder Loss:  0.17696653  || Decoder Loss:  0.19542114 Validation Decoder Loss:  0.478046
Encoder Loss:  0.1769874  || Decoder Loss:  0.19544797 Validation Decoder Loss:  0.4802168
Encoder Loss:  0.1772672  || Decoder Loss:  0.19577046 Validation Decoder Loss:  0.4830922
Encoder Loss:  0.1767606  || Decoder Loss:  0.19519271 Validation Decoder Loss:  0.48643634
Encoder Loss:  0.17635322  || Decoder Loss:  0.19472753 Validation Decoder Loss:  0.4899015
Encoder Loss:  0.17643592  || Decoder Loss:  0.19482526 Validation Decoder Loss:  0.49398568
Encoder Loss:  0.17579228  || Decoder Loss:  0.1940898 Validation Decoder Loss:  0.4998912
Encoder Loss:  0.17376597  || Decoder Loss:  0.19176966 Validation Decoder Loss:  0.51015997
Encoder Loss:  0.17212228  || Decoder Loss:  0.18988687 Validation Decoder Loss:  0.5280525
Encoder Loss:  0.17016098  || Decoder Loss:  0.18764053 Validation Decoder Loss:  0.5353577
Encoder Loss:  0.16687265  || Decoder Loss:  0.18387334 Validation Decoder Loss:  0.557317
Encoder Loss:  0.16384658  || Decoder Loss:  0.18040697 Validation Decoder Loss:  0.5524374
Encoder Loss:  0.16256522  || Decoder Loss:  0.17894033 Validation Decoder Loss:  0.5529657
Encoder Loss:  0.16185987  || Decoder Loss:  0.17813231 Validation Decoder Loss:  0.55391186
Encoder Loss:  0.1613638  || Decoder Loss:  0.17756422 Validation Decoder Loss:  0.5537832
Encoder Loss:  0.16101433  || Decoder Loss:  0.17716476 Validation Decoder Loss:  0.5525961
Encoder Loss:  0.16073617  || Decoder Loss:  0.1768468 Validation Decoder Loss:  0.552032
Encoder Loss:  0.16047712  || Decoder Loss:  0.17654972 Validation Decoder Loss:  0.5517249
Encoder Loss:  0.16023944  || Decoder Loss:  0.17627871 Validation Decoder Loss:  0.5515646
Encoder Loss:  0.1600669  || Decoder Loss:  0.17608003 Validation Decoder Loss:  0.5512611
Encoder Loss:  0.15994862  || Decoder Loss:  0.17594543 Validation Decoder Loss:  0.5510437
Encoder Loss:  0.15979947  || Decoder Loss:  0.17577487 Validation Decoder Loss:  0.5512485
Encoder Loss:  0.15968771  || Decoder Loss:  0.17564748 Validation Decoder Loss:  0.5509527
Model: bold_synthesis_net_lr_0.0009478811435776669 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5509527
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_141 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_309 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_142 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_66 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 470, 14, 1)        406       
_________________________________________________________________
dropout_311 (Dropout)        (None, 470, 14, 1)        0         
_________________________________________________________________
conv2d_104 (Conv2D)          (None, 420, 14, 1)        52        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 700, 14, 1)        282       
_________________________________________________________________
dropout_313 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_104 (Conv2D (None, 874, 14, 1)        176       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11087493  || Decoder Loss:  0.22874539 Validation Decoder Loss:  0.49799547
Encoder Loss:  0.06366117  || Decoder Loss:  0.21510476 Validation Decoder Loss:  0.47755814
Encoder Loss:  0.055758227  || Decoder Loss:  0.20862798 Validation Decoder Loss:  0.4732497
Encoder Loss:  0.05479129  || Decoder Loss:  0.20461553 Validation Decoder Loss:  0.46885028
Encoder Loss:  0.054505464  || Decoder Loss:  0.20338297 Validation Decoder Loss:  0.46688682
Encoder Loss:  0.054325048  || Decoder Loss:  0.20266217 Validation Decoder Loss:  0.46485177
Encoder Loss:  0.054214045  || Decoder Loss:  0.20193931 Validation Decoder Loss:  0.46405333
Encoder Loss:  0.054110132  || Decoder Loss:  0.20123154 Validation Decoder Loss:  0.46441495
Encoder Loss:  0.05402354  || Decoder Loss:  0.19966339 Validation Decoder Loss:  0.4712684
Encoder Loss:  0.053961653  || Decoder Loss:  0.19853422 Validation Decoder Loss:  0.47446117
Encoder Loss:  0.05390844  || Decoder Loss:  0.1979658 Validation Decoder Loss:  0.47681096
Encoder Loss:  0.053867236  || Decoder Loss:  0.19761074 Validation Decoder Loss:  0.4806282
Encoder Loss:  0.05381857  || Decoder Loss:  0.19660392 Validation Decoder Loss:  0.4807295
Encoder Loss:  0.053763006  || Decoder Loss:  0.19513145 Validation Decoder Loss:  0.48837674
Encoder Loss:  0.053738862  || Decoder Loss:  0.1950299 Validation Decoder Loss:  0.49093175
Encoder Loss:  0.05371136  || Decoder Loss:  0.19476059 Validation Decoder Loss:  0.49018005
Encoder Loss:  0.05371024  || Decoder Loss:  0.19524902 Validation Decoder Loss:  0.4920916
Encoder Loss:  0.053712115  || Decoder Loss:  0.19578946 Validation Decoder Loss:  0.4924886
Encoder Loss:  0.053706404  || Decoder Loss:  0.19578484 Validation Decoder Loss:  0.49362123
Encoder Loss:  0.053689662  || Decoder Loss:  0.19572246 Validation Decoder Loss:  0.49431103
Encoder Loss:  0.053680036  || Decoder Loss:  0.19573282 Validation Decoder Loss:  0.4951619
Encoder Loss:  0.05367805  || Decoder Loss:  0.19579843 Validation Decoder Loss:  0.4963304
Encoder Loss:  0.053667903  || Decoder Loss:  0.1958412 Validation Decoder Loss:  0.49579227
Encoder Loss:  0.05363646  || Decoder Loss:  0.19466363 Validation Decoder Loss:  0.49516612
Encoder Loss:  0.053636324  || Decoder Loss:  0.19485444 Validation Decoder Loss:  0.49843588
Encoder Loss:  0.053617705  || Decoder Loss:  0.19429207 Validation Decoder Loss:  0.50381774
Encoder Loss:  0.053604577  || Decoder Loss:  0.19396538 Validation Decoder Loss:  0.50593954
Encoder Loss:  0.053588886  || Decoder Loss:  0.19364709 Validation Decoder Loss:  0.50351536
Encoder Loss:  0.053586446  || Decoder Loss:  0.193517 Validation Decoder Loss:  0.5049717
Encoder Loss:  0.053579338  || Decoder Loss:  0.19349 Validation Decoder Loss:  0.5043534
Encoder Loss:  0.053583782  || Decoder Loss:  0.193691 Validation Decoder Loss:  0.5048181
Encoder Loss:  0.053571794  || Decoder Loss:  0.19370075 Validation Decoder Loss:  0.50543875
Encoder Loss:  0.053576324  || Decoder Loss:  0.19364108 Validation Decoder Loss:  0.5048703
Encoder Loss:  0.053568415  || Decoder Loss:  0.19357745 Validation Decoder Loss:  0.5044548
Encoder Loss:  0.05356921  || Decoder Loss:  0.1935773 Validation Decoder Loss:  0.5031853
Encoder Loss:  0.05357441  || Decoder Loss:  0.19362138 Validation Decoder Loss:  0.5021742
Encoder Loss:  0.053565618  || Decoder Loss:  0.19359352 Validation Decoder Loss:  0.50156045
Encoder Loss:  0.053564858  || Decoder Loss:  0.19364046 Validation Decoder Loss:  0.5007984
Encoder Loss:  0.053565454  || Decoder Loss:  0.19368176 Validation Decoder Loss:  0.50113255
Encoder Loss:  0.05357279  || Decoder Loss:  0.1938458 Validation Decoder Loss:  0.5013062
Model: bold_synthesis_net_lr_0.0006327506070329298 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50130624
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_144 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_315 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_145 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_67 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 610, 14, 1)        266       
_________________________________________________________________
dropout_317 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_106 (Conv2D)          (None, 420, 14, 1)        192       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 510, 14, 1)        92        
_________________________________________________________________
dropout_319 (Dropout)        (None, 510, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_106 (Conv2D (None, 874, 14, 1)        366       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24499722  || Decoder Loss:  0.2530225 Validation Decoder Loss:  0.5044434
Encoder Loss:  0.2407352  || Decoder Loss:  0.24858487 Validation Decoder Loss:  0.5029226
Encoder Loss:  0.23711887  || Decoder Loss:  0.24482183 Validation Decoder Loss:  0.50171
Encoder Loss:  0.23402028  || Decoder Loss:  0.24159245 Validation Decoder Loss:  0.5009308
Encoder Loss:  0.23148258  || Decoder Loss:  0.23894008 Validation Decoder Loss:  0.5005888
Encoder Loss:  0.22951272  || Decoder Loss:  0.23687413 Validation Decoder Loss:  0.5004151
Encoder Loss:  0.22798681  || Decoder Loss:  0.23527232 Validation Decoder Loss:  0.50028807
Encoder Loss:  0.22670713  || Decoder Loss:  0.2339293 Validation Decoder Loss:  0.50016916
Encoder Loss:  0.2256343  || Decoder Loss:  0.23280425 Validation Decoder Loss:  0.5000185
Encoder Loss:  0.22477615  || Decoder Loss:  0.23190649 Validation Decoder Loss:  0.49986672
Encoder Loss:  0.22397098  || Decoder Loss:  0.23106639 Validation Decoder Loss:  0.499748
Encoder Loss:  0.22319612  || Decoder Loss:  0.23025933 Validation Decoder Loss:  0.4996585
Encoder Loss:  0.22248693  || Decoder Loss:  0.22952208 Validation Decoder Loss:  0.49957103
Encoder Loss:  0.22181189  || Decoder Loss:  0.22882266 Validation Decoder Loss:  0.49951398
Encoder Loss:  0.22113411  || Decoder Loss:  0.22812209 Validation Decoder Loss:  0.49950287
Encoder Loss:  0.22046752  || Decoder Loss:  0.22743519 Validation Decoder Loss:  0.49951118
Encoder Loss:  0.21983778  || Decoder Loss:  0.22678936 Validation Decoder Loss:  0.49954674
Encoder Loss:  0.2192311  || Decoder Loss:  0.22617038 Validation Decoder Loss:  0.4996087
Encoder Loss:  0.21866214  || Decoder Loss:  0.22559421 Validation Decoder Loss:  0.49969235
Encoder Loss:  0.2181102  || Decoder Loss:  0.22503881 Validation Decoder Loss:  0.49979675
Encoder Loss:  0.21758214  || Decoder Loss:  0.22451165 Validation Decoder Loss:  0.4999297
Encoder Loss:  0.21706803  || Decoder Loss:  0.22400232 Validation Decoder Loss:  0.50010324
Encoder Loss:  0.2165587  || Decoder Loss:  0.22350116 Validation Decoder Loss:  0.50031614
Encoder Loss:  0.21605392  || Decoder Loss:  0.2230076 Validation Decoder Loss:  0.5005762
Encoder Loss:  0.21557243  || Decoder Loss:  0.22254197 Validation Decoder Loss:  0.5008848
Encoder Loss:  0.21510224  || Decoder Loss:  0.22209144 Validation Decoder Loss:  0.50124395
Encoder Loss:  0.21464376  || Decoder Loss:  0.22165613 Validation Decoder Loss:  0.5016443
Encoder Loss:  0.21419993  || Decoder Loss:  0.2212394 Validation Decoder Loss:  0.5020773
Encoder Loss:  0.21376601  || Decoder Loss:  0.22083578 Validation Decoder Loss:  0.5025361
Encoder Loss:  0.21334133  || Decoder Loss:  0.22044535 Validation Decoder Loss:  0.5030637
Encoder Loss:  0.21291323  || Decoder Loss:  0.22005434 Validation Decoder Loss:  0.5036488
Encoder Loss:  0.21251564  || Decoder Loss:  0.219699 Validation Decoder Loss:  0.5042483
Encoder Loss:  0.21215653  || Decoder Loss:  0.21938737 Validation Decoder Loss:  0.50484
Encoder Loss:  0.21183002  || Decoder Loss:  0.2191128 Validation Decoder Loss:  0.5054306
Encoder Loss:  0.21153307  || Decoder Loss:  0.21887514 Validation Decoder Loss:  0.5060368
Encoder Loss:  0.21125188  || Decoder Loss:  0.21866047 Validation Decoder Loss:  0.5066804
Encoder Loss:  0.21097937  || Decoder Loss:  0.21846119 Validation Decoder Loss:  0.50737405
Encoder Loss:  0.21071407  || Decoder Loss:  0.21827514 Validation Decoder Loss:  0.5081273
Encoder Loss:  0.21048832  || Decoder Loss:  0.21814117 Validation Decoder Loss:  0.50874484
Encoder Loss:  0.2102462  || Decoder Loss:  0.21799767 Validation Decoder Loss:  0.50944144
Model: bold_synthesis_net_lr_0.0005723574117237935 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50944144
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_147 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_321 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_148 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_68 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_107 (Conv2D)          (None, 800, 14, 1)        76        
_________________________________________________________________
dropout_323 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_108 (Conv2D)          (None, 420, 14, 1)        382       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_107 (Conv2D (None, 540, 14, 1)        122       
_________________________________________________________________
dropout_325 (Dropout)        (None, 540, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_108 (Conv2D (None, 874, 14, 1)        336       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15835005  || Decoder Loss:  0.26060745 Validation Decoder Loss:  0.47954923
Encoder Loss:  0.14298458  || Decoder Loss:  0.23425171 Validation Decoder Loss:  0.4825769
Encoder Loss:  0.1367454  || Decoder Loss:  0.22412877 Validation Decoder Loss:  0.48729008
Encoder Loss:  0.13353325  || Decoder Loss:  0.22021855 Validation Decoder Loss:  0.4891408
Encoder Loss:  0.1301813  || Decoder Loss:  0.21786253 Validation Decoder Loss:  0.49028206
Encoder Loss:  0.12568872  || Decoder Loss:  0.21552609 Validation Decoder Loss:  0.4909159
Encoder Loss:  0.11932069  || Decoder Loss:  0.21366107 Validation Decoder Loss:  0.49190277
Encoder Loss:  0.1103484  || Decoder Loss:  0.21221006 Validation Decoder Loss:  0.49179536
Encoder Loss:  0.10008293  || Decoder Loss:  0.20964019 Validation Decoder Loss:  0.4925564
Encoder Loss:  0.09154147  || Decoder Loss:  0.20785923 Validation Decoder Loss:  0.4927777
Encoder Loss:  0.086631104  || Decoder Loss:  0.20717074 Validation Decoder Loss:  0.4925011
Encoder Loss:  0.08546851  || Decoder Loss:  0.207101 Validation Decoder Loss:  0.49408194
Encoder Loss:  0.08508986  || Decoder Loss:  0.20760909 Validation Decoder Loss:  0.4940072
Encoder Loss:  0.08482505  || Decoder Loss:  0.20848931 Validation Decoder Loss:  0.49333465
Encoder Loss:  0.08435834  || Decoder Loss:  0.20804566 Validation Decoder Loss:  0.49275815
Encoder Loss:  0.08386826  || Decoder Loss:  0.20734751 Validation Decoder Loss:  0.49171934
Encoder Loss:  0.0834595  || Decoder Loss:  0.20694046 Validation Decoder Loss:  0.4908226
Encoder Loss:  0.08308386  || Decoder Loss:  0.20661384 Validation Decoder Loss:  0.4899688
Encoder Loss:  0.0827099  || Decoder Loss:  0.20629023 Validation Decoder Loss:  0.48894823
Encoder Loss:  0.08234027  || Decoder Loss:  0.20594637 Validation Decoder Loss:  0.48834756
Encoder Loss:  0.08198918  || Decoder Loss:  0.20567183 Validation Decoder Loss:  0.48773885
Encoder Loss:  0.08166293  || Decoder Loss:  0.2054907 Validation Decoder Loss:  0.48756868
Encoder Loss:  0.08137771  || Decoder Loss:  0.2055066 Validation Decoder Loss:  0.48797026
Encoder Loss:  0.08109655  || Decoder Loss:  0.20552583 Validation Decoder Loss:  0.48846868
Encoder Loss:  0.080835044  || Decoder Loss:  0.20552683 Validation Decoder Loss:  0.4883592
Encoder Loss:  0.0806092  || Decoder Loss:  0.2054784 Validation Decoder Loss:  0.48840383
Encoder Loss:  0.08043643  || Decoder Loss:  0.20552367 Validation Decoder Loss:  0.4885065
Encoder Loss:  0.08029818  || Decoder Loss:  0.20545879 Validation Decoder Loss:  0.48840308
Encoder Loss:  0.08018032  || Decoder Loss:  0.20523664 Validation Decoder Loss:  0.48765922
Encoder Loss:  0.08004741  || Decoder Loss:  0.20487382 Validation Decoder Loss:  0.4868909
Encoder Loss:  0.07991705  || Decoder Loss:  0.20450439 Validation Decoder Loss:  0.48591587
Encoder Loss:  0.079788394  || Decoder Loss:  0.20410977 Validation Decoder Loss:  0.48500374
Encoder Loss:  0.079668984  || Decoder Loss:  0.2037188 Validation Decoder Loss:  0.48414567
Encoder Loss:  0.07954563  || Decoder Loss:  0.20328315 Validation Decoder Loss:  0.48384488
Encoder Loss:  0.07942206  || Decoder Loss:  0.20281807 Validation Decoder Loss:  0.48385704
Encoder Loss:  0.07924947  || Decoder Loss:  0.20204355 Validation Decoder Loss:  0.486083
Encoder Loss:  0.07896959  || Decoder Loss:  0.20066115 Validation Decoder Loss:  0.48845732
Encoder Loss:  0.078672655  || Decoder Loss:  0.19916901 Validation Decoder Loss:  0.48527625
Encoder Loss:  0.078485765  || Decoder Loss:  0.19829182 Validation Decoder Loss:  0.4836581
Encoder Loss:  0.078349754  || Decoder Loss:  0.19772589 Validation Decoder Loss:  0.48181283
Model: bold_synthesis_net_lr_0.0005974509382608023 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.48181283
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_150 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_327 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_151 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_69 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_109 (Conv2D)          (None, 670, 14, 1)        206       
_________________________________________________________________
dropout_329 (Dropout)        (None, 670, 14, 1)        0         
_________________________________________________________________
conv2d_110 (Conv2D)          (None, 420, 14, 1)        252       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_109 (Conv2D (None, 840, 14, 1)        3         
_________________________________________________________________
dropout_331 (Dropout)        (None, 840, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_110 (Conv2D (None, 874, 14, 1)        36        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32112315  || Decoder Loss:  0.3944574 Validation Decoder Loss:  0.56451505
Encoder Loss:  0.14820234  || Decoder Loss:  0.21693298 Validation Decoder Loss:  0.568779
Encoder Loss:  0.14307737  || Decoder Loss:  0.22568521 Validation Decoder Loss:  0.58777833
Encoder Loss:  0.12016568  || Decoder Loss:  0.20569827 Validation Decoder Loss:  0.5464217
Encoder Loss:  0.11025139  || Decoder Loss:  0.19460145 Validation Decoder Loss:  0.5324021
Encoder Loss:  0.10884368  || Decoder Loss:  0.19329523 Validation Decoder Loss:  0.52391624
Encoder Loss:  0.1082943  || Decoder Loss:  0.1932751 Validation Decoder Loss:  0.52229565
Encoder Loss:  0.107961595  || Decoder Loss:  0.19281515 Validation Decoder Loss:  0.5217961
Encoder Loss:  0.10778696  || Decoder Loss:  0.19268586 Validation Decoder Loss:  0.5222508
Encoder Loss:  0.107702285  || Decoder Loss:  0.19272214 Validation Decoder Loss:  0.52225184
Encoder Loss:  0.10761037  || Decoder Loss:  0.19273593 Validation Decoder Loss:  0.5222977
Encoder Loss:  0.10754828  || Decoder Loss:  0.19278985 Validation Decoder Loss:  0.5222636
Encoder Loss:  0.10748843  || Decoder Loss:  0.19285053 Validation Decoder Loss:  0.5224894
Encoder Loss:  0.107438356  || Decoder Loss:  0.19292751 Validation Decoder Loss:  0.5226862
Encoder Loss:  0.10739877  || Decoder Loss:  0.19302014 Validation Decoder Loss:  0.5231787
Encoder Loss:  0.10736267  || Decoder Loss:  0.19310427 Validation Decoder Loss:  0.5232072
Encoder Loss:  0.10731185  || Decoder Loss:  0.19316982 Validation Decoder Loss:  0.5233833
Encoder Loss:  0.10728483  || Decoder Loss:  0.19325146 Validation Decoder Loss:  0.523506
Encoder Loss:  0.10724469  || Decoder Loss:  0.19331184 Validation Decoder Loss:  0.5238459
Encoder Loss:  0.10721875  || Decoder Loss:  0.19339843 Validation Decoder Loss:  0.52393126
Encoder Loss:  0.10719907  || Decoder Loss:  0.19350287 Validation Decoder Loss:  0.5244894
Encoder Loss:  0.107150584  || Decoder Loss:  0.19355573 Validation Decoder Loss:  0.5247061
Encoder Loss:  0.10711006  || Decoder Loss:  0.19360736 Validation Decoder Loss:  0.524728
Encoder Loss:  0.1070389  || Decoder Loss:  0.19361591 Validation Decoder Loss:  0.5250843
Encoder Loss:  0.10694966  || Decoder Loss:  0.19364028 Validation Decoder Loss:  0.52543104
Encoder Loss:  0.10687368  || Decoder Loss:  0.19366327 Validation Decoder Loss:  0.5252374
Encoder Loss:  0.10681714  || Decoder Loss:  0.19372861 Validation Decoder Loss:  0.5247865
Encoder Loss:  0.10675121  || Decoder Loss:  0.19377574 Validation Decoder Loss:  0.52453256
Encoder Loss:  0.10663711  || Decoder Loss:  0.19369751 Validation Decoder Loss:  0.52421504
Encoder Loss:  0.10648318  || Decoder Loss:  0.1935239 Validation Decoder Loss:  0.523512
Encoder Loss:  0.106332704  || Decoder Loss:  0.19334313 Validation Decoder Loss:  0.52275705
Encoder Loss:  0.10618612  || Decoder Loss:  0.19318205 Validation Decoder Loss:  0.5224753
Encoder Loss:  0.10607053  || Decoder Loss:  0.19310151 Validation Decoder Loss:  0.5224054
Encoder Loss:  0.105981216  || Decoder Loss:  0.19309731 Validation Decoder Loss:  0.52211523
Encoder Loss:  0.1059011  || Decoder Loss:  0.19310144 Validation Decoder Loss:  0.5220787
Encoder Loss:  0.10581554  || Decoder Loss:  0.19312002 Validation Decoder Loss:  0.5215898
Encoder Loss:  0.10571685  || Decoder Loss:  0.19311304 Validation Decoder Loss:  0.5212208
Encoder Loss:  0.10562797  || Decoder Loss:  0.19312301 Validation Decoder Loss:  0.52097994
Encoder Loss:  0.105539285  || Decoder Loss:  0.19312842 Validation Decoder Loss:  0.5203481
Encoder Loss:  0.105448425  || Decoder Loss:  0.19310704 Validation Decoder Loss:  0.5199888
Model: bold_synthesis_net_lr_0.0005091556740240123 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5199888
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_153 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_333 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_154 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_70 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_111 (Conv2D)          (None, 600, 14, 1)        276       
_________________________________________________________________
dropout_335 (Dropout)        (None, 600, 14, 1)        0         
_________________________________________________________________
conv2d_112 (Conv2D)          (None, 420, 14, 1)        182       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_111 (Conv2D (None, 640, 14, 1)        222       
_________________________________________________________________
dropout_337 (Dropout)        (None, 640, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_112 (Conv2D (None, 874, 14, 1)        236       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1427907  || Decoder Loss:  0.26518935 Validation Decoder Loss:  0.49465355
Encoder Loss:  0.1417996  || Decoder Loss:  0.2632302 Validation Decoder Loss:  0.49345845
Encoder Loss:  0.14083236  || Decoder Loss:  0.26134306 Validation Decoder Loss:  0.49247745
Encoder Loss:  0.13988522  || Decoder Loss:  0.25951877 Validation Decoder Loss:  0.49164197
Encoder Loss:  0.13896923  || Decoder Loss:  0.2577706 Validation Decoder Loss:  0.49094418
Encoder Loss:  0.13809851  || Decoder Loss:  0.25609934 Validation Decoder Loss:  0.49036187
Encoder Loss:  0.13729033  || Decoder Loss:  0.25451988 Validation Decoder Loss:  0.48988277
Encoder Loss:  0.13654065  || Decoder Loss:  0.25303513 Validation Decoder Loss:  0.4895052
Encoder Loss:  0.13588275  || Decoder Loss:  0.2516641 Validation Decoder Loss:  0.48921588
Encoder Loss:  0.13528839  || Decoder Loss:  0.25040713 Validation Decoder Loss:  0.48897743
Encoder Loss:  0.13474455  || Decoder Loss:  0.24923277 Validation Decoder Loss:  0.48878244
Encoder Loss:  0.13423789  || Decoder Loss:  0.24812734 Validation Decoder Loss:  0.48862258
Encoder Loss:  0.13375244  || Decoder Loss:  0.24706557 Validation Decoder Loss:  0.48849708
Encoder Loss:  0.13330275  || Decoder Loss:  0.24606228 Validation Decoder Loss:  0.48839954
Encoder Loss:  0.13287094  || Decoder Loss:  0.24510029 Validation Decoder Loss:  0.4883281
Encoder Loss:  0.13244314  || Decoder Loss:  0.24416682 Validation Decoder Loss:  0.4882721
Encoder Loss:  0.13202949  || Decoder Loss:  0.24325863 Validation Decoder Loss:  0.4882407
Encoder Loss:  0.1316272  || Decoder Loss:  0.2423801 Validation Decoder Loss:  0.48822773
Encoder Loss:  0.13123637  || Decoder Loss:  0.24152724 Validation Decoder Loss:  0.4882318
Encoder Loss:  0.13085355  || Decoder Loss:  0.24069707 Validation Decoder Loss:  0.4882551
Encoder Loss:  0.13047881  || Decoder Loss:  0.23989077 Validation Decoder Loss:  0.4882916
Encoder Loss:  0.13010654  || Decoder Loss:  0.23910329 Validation Decoder Loss:  0.48834586
Encoder Loss:  0.12973788  || Decoder Loss:  0.23833168 Validation Decoder Loss:  0.48841652
Encoder Loss:  0.12937634  || Decoder Loss:  0.23758154 Validation Decoder Loss:  0.48849475
Encoder Loss:  0.12901594  || Decoder Loss:  0.23684534 Validation Decoder Loss:  0.48858872
Encoder Loss:  0.12866001  || Decoder Loss:  0.2361234 Validation Decoder Loss:  0.48870158
Encoder Loss:  0.12831509  || Decoder Loss:  0.23542306 Validation Decoder Loss:  0.48883113
Encoder Loss:  0.12796962  || Decoder Loss:  0.2347345 Validation Decoder Loss:  0.48897237
Encoder Loss:  0.12764809  || Decoder Loss:  0.23407915 Validation Decoder Loss:  0.48910835
Encoder Loss:  0.12735799  || Decoder Loss:  0.23347814 Validation Decoder Loss:  0.4892419
Encoder Loss:  0.12708503  || Decoder Loss:  0.23291185 Validation Decoder Loss:  0.48937535
Encoder Loss:  0.1268189  || Decoder Loss:  0.23236528 Validation Decoder Loss:  0.4895194
Encoder Loss:  0.12656191  || Decoder Loss:  0.23183668 Validation Decoder Loss:  0.48968613
Encoder Loss:  0.12631573  || Decoder Loss:  0.2313302 Validation Decoder Loss:  0.48986474
Encoder Loss:  0.12608658  || Decoder Loss:  0.2308522 Validation Decoder Loss:  0.49005264
Encoder Loss:  0.12587674  || Decoder Loss:  0.23041213 Validation Decoder Loss:  0.4902462
Encoder Loss:  0.12567547  || Decoder Loss:  0.22999454 Validation Decoder Loss:  0.4904495
Encoder Loss:  0.12548414  || Decoder Loss:  0.22959748 Validation Decoder Loss:  0.49063864
Encoder Loss:  0.12531304  || Decoder Loss:  0.22923751 Validation Decoder Loss:  0.49081048
Encoder Loss:  0.1251521  || Decoder Loss:  0.228905 Validation Decoder Loss:  0.4909786
Model: bold_synthesis_net_lr_0.0001745631380497432 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4909786
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_156 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_339 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_157 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_71 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_113 (Conv2D)          (None, 620, 14, 1)        256       
_________________________________________________________________
dropout_341 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_114 (Conv2D)          (None, 420, 14, 1)        202       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_113 (Conv2D (None, 700, 14, 1)        282       
_________________________________________________________________
dropout_343 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_114 (Conv2D (None, 874, 14, 1)        176       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32513613  || Decoder Loss:  0.40267023 Validation Decoder Loss:  0.733688
Encoder Loss:  0.3093715  || Decoder Loss:  0.39156067 Validation Decoder Loss:  0.6869624
Encoder Loss:  0.29107502  || Decoder Loss:  0.3761571 Validation Decoder Loss:  0.6337691
Encoder Loss:  0.27029335  || Decoder Loss:  0.35528755 Validation Decoder Loss:  0.5849779
Encoder Loss:  0.24742216  || Decoder Loss:  0.32883137 Validation Decoder Loss:  0.52924514
Encoder Loss:  0.22517182  || Decoder Loss:  0.30012223 Validation Decoder Loss:  0.4848215
Encoder Loss:  0.20655107  || Decoder Loss:  0.27521005 Validation Decoder Loss:  0.45588714
Encoder Loss:  0.19121966  || Decoder Loss:  0.25452852 Validation Decoder Loss:  0.44640505
Encoder Loss:  0.17964138  || Decoder Loss:  0.23874547 Validation Decoder Loss:  0.4457822
Encoder Loss:  0.16982596  || Decoder Loss:  0.22641513 Validation Decoder Loss:  0.45204076
Encoder Loss:  0.16324434  || Decoder Loss:  0.21902116 Validation Decoder Loss:  0.45844382
Encoder Loss:  0.15878184  || Decoder Loss:  0.21470296 Validation Decoder Loss:  0.46502778
Encoder Loss:  0.1555234  || Decoder Loss:  0.21232337 Validation Decoder Loss:  0.46983826
Encoder Loss:  0.15334435  || Decoder Loss:  0.21160208 Validation Decoder Loss:  0.47220927
Encoder Loss:  0.15155753  || Decoder Loss:  0.21177803 Validation Decoder Loss:  0.4763089
Encoder Loss:  0.14974341  || Decoder Loss:  0.21269007 Validation Decoder Loss:  0.48006082
Encoder Loss:  0.14739786  || Decoder Loss:  0.21328416 Validation Decoder Loss:  0.4820578
Encoder Loss:  0.14432472  || Decoder Loss:  0.21293092 Validation Decoder Loss:  0.48196414
Encoder Loss:  0.14133067  || Decoder Loss:  0.2119871 Validation Decoder Loss:  0.47959414
Encoder Loss:  0.13895288  || Decoder Loss:  0.21105891 Validation Decoder Loss:  0.47615448
Encoder Loss:  0.13704115  || Decoder Loss:  0.21052785 Validation Decoder Loss:  0.47245216
Encoder Loss:  0.1353627  || Decoder Loss:  0.21052988 Validation Decoder Loss:  0.46901482
Encoder Loss:  0.13383533  || Decoder Loss:  0.2108273 Validation Decoder Loss:  0.46573249
Encoder Loss:  0.13245106  || Decoder Loss:  0.21133415 Validation Decoder Loss:  0.46171573
Encoder Loss:  0.13075668  || Decoder Loss:  0.21083656 Validation Decoder Loss:  0.45918477
Encoder Loss:  0.12905923  || Decoder Loss:  0.20986106 Validation Decoder Loss:  0.45738727
Encoder Loss:  0.12768595  || Decoder Loss:  0.20901296 Validation Decoder Loss:  0.45644858
Encoder Loss:  0.1266816  || Decoder Loss:  0.2082867 Validation Decoder Loss:  0.45645028
Encoder Loss:  0.12598555  || Decoder Loss:  0.20770213 Validation Decoder Loss:  0.4573653
Encoder Loss:  0.1254216  || Decoder Loss:  0.20714444 Validation Decoder Loss:  0.4585077
Encoder Loss:  0.124979705  || Decoder Loss:  0.20666216 Validation Decoder Loss:  0.4592017
Encoder Loss:  0.124604926  || Decoder Loss:  0.20622186 Validation Decoder Loss:  0.45946494
Encoder Loss:  0.12427972  || Decoder Loss:  0.20583862 Validation Decoder Loss:  0.45976213
Encoder Loss:  0.123981595  || Decoder Loss:  0.20547155 Validation Decoder Loss:  0.45986184
Encoder Loss:  0.12370931  || Decoder Loss:  0.20513274 Validation Decoder Loss:  0.45993477
Encoder Loss:  0.12344695  || Decoder Loss:  0.2048049 Validation Decoder Loss:  0.45987657
Encoder Loss:  0.123199135  || Decoder Loss:  0.20450293 Validation Decoder Loss:  0.4598051
Encoder Loss:  0.12294304  || Decoder Loss:  0.20417006 Validation Decoder Loss:  0.4596709
Encoder Loss:  0.122711144  || Decoder Loss:  0.20388386 Validation Decoder Loss:  0.45953152
Encoder Loss:  0.12249353  || Decoder Loss:  0.20362012 Validation Decoder Loss:  0.45927086
Model: bold_synthesis_net_lr_0.00044015091323529803 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45927086
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_159 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_345 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_160 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_72 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_115 (Conv2D)          (None, 420, 14, 1)        37        
_________________________________________________________________
dropout_347 (Dropout)        (None, 420, 14, 1)        0         
_________________________________________________________________
conv2d_116 (Conv2D)          (None, 420, 14, 1)        2         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_115 (Conv2D (None, 770, 14, 1)        352       
_________________________________________________________________
dropout_349 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_116 (Conv2D (None, 874, 14, 1)        106       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12018739  || Decoder Loss:  0.25388193 Validation Decoder Loss:  0.5040244
Encoder Loss:  0.118084714  || Decoder Loss:  0.24975342 Validation Decoder Loss:  0.50199544
Encoder Loss:  0.116443045  || Decoder Loss:  0.24696323 Validation Decoder Loss:  0.5002944
Encoder Loss:  0.11499701  || Decoder Loss:  0.24470858 Validation Decoder Loss:  0.49876022
Encoder Loss:  0.113688506  || Decoder Loss:  0.24276501 Validation Decoder Loss:  0.49733952
Encoder Loss:  0.11248425  || Decoder Loss:  0.24098498 Validation Decoder Loss:  0.49602634
Encoder Loss:  0.111353666  || Decoder Loss:  0.23928519 Validation Decoder Loss:  0.49481255
Encoder Loss:  0.11027434  || Decoder Loss:  0.23764277 Validation Decoder Loss:  0.49375212
Encoder Loss:  0.10925042  || Decoder Loss:  0.23609664 Validation Decoder Loss:  0.49280387
Encoder Loss:  0.10825534  || Decoder Loss:  0.23461622 Validation Decoder Loss:  0.49199817
Encoder Loss:  0.10729716  || Decoder Loss:  0.23320036 Validation Decoder Loss:  0.49127758
Encoder Loss:  0.10638091  || Decoder Loss:  0.23188432 Validation Decoder Loss:  0.49063632
Encoder Loss:  0.10550211  || Decoder Loss:  0.23066936 Validation Decoder Loss:  0.4900562
Encoder Loss:  0.10465902  || Decoder Loss:  0.2295242 Validation Decoder Loss:  0.48953912
Encoder Loss:  0.10386053  || Decoder Loss:  0.22844276 Validation Decoder Loss:  0.48913273
Encoder Loss:  0.10309713  || Decoder Loss:  0.22737356 Validation Decoder Loss:  0.4888206
Encoder Loss:  0.102377266  || Decoder Loss:  0.2263627 Validation Decoder Loss:  0.4884833
Encoder Loss:  0.10169181  || Decoder Loss:  0.22544016 Validation Decoder Loss:  0.48813137
Encoder Loss:  0.101028554  || Decoder Loss:  0.22456971 Validation Decoder Loss:  0.4877659
Encoder Loss:  0.100403346  || Decoder Loss:  0.22378792 Validation Decoder Loss:  0.48730507
Encoder Loss:  0.09979649  || Decoder Loss:  0.22306056 Validation Decoder Loss:  0.48680073
Encoder Loss:  0.099202365  || Decoder Loss:  0.22235914 Validation Decoder Loss:  0.48626027
Encoder Loss:  0.098613866  || Decoder Loss:  0.2216653 Validation Decoder Loss:  0.48567706
Encoder Loss:  0.09803563  || Decoder Loss:  0.22103672 Validation Decoder Loss:  0.48500374
Encoder Loss:  0.09745767  || Decoder Loss:  0.22043781 Validation Decoder Loss:  0.48430827
Encoder Loss:  0.096886426  || Decoder Loss:  0.2198487 Validation Decoder Loss:  0.48358786
Encoder Loss:  0.096314  || Decoder Loss:  0.21925935 Validation Decoder Loss:  0.4828321
Encoder Loss:  0.09574623  || Decoder Loss:  0.21867195 Validation Decoder Loss:  0.48189446
Encoder Loss:  0.09517019  || Decoder Loss:  0.21805911 Validation Decoder Loss:  0.48079056
Encoder Loss:  0.09455147  || Decoder Loss:  0.21729255 Validation Decoder Loss:  0.4797656
Encoder Loss:  0.0939651  || Decoder Loss:  0.21675149 Validation Decoder Loss:  0.47910202
Encoder Loss:  0.09339196  || Decoder Loss:  0.21629804 Validation Decoder Loss:  0.47862417
Encoder Loss:  0.09282115  || Decoder Loss:  0.21587186 Validation Decoder Loss:  0.4780558
Encoder Loss:  0.09224761  || Decoder Loss:  0.21550277 Validation Decoder Loss:  0.4774031
Encoder Loss:  0.09167072  || Decoder Loss:  0.2151483 Validation Decoder Loss:  0.4767675
Encoder Loss:  0.0910772  || Decoder Loss:  0.21468233 Validation Decoder Loss:  0.47613153
Encoder Loss:  0.09047289  || Decoder Loss:  0.21423857 Validation Decoder Loss:  0.47569326
Encoder Loss:  0.08985412  || Decoder Loss:  0.2138119 Validation Decoder Loss:  0.47525477
Encoder Loss:  0.089226484  || Decoder Loss:  0.21337786 Validation Decoder Loss:  0.4748291
Encoder Loss:  0.08862872  || Decoder Loss:  0.21298109 Validation Decoder Loss:  0.4742437
Model: bold_synthesis_net_lr_0.00023474886389772883 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4742437
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_162 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_351 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_163 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_73 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_117 (Conv2D)          (None, 820, 14, 1)        56        
_________________________________________________________________
dropout_353 (Dropout)        (None, 820, 14, 1)        0         
_________________________________________________________________
conv2d_118 (Conv2D)          (None, 420, 14, 1)        402       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_117 (Conv2D (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_355 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_118 (Conv2D (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13440034  || Decoder Loss:  0.25262302 Validation Decoder Loss:  0.5049327
Encoder Loss:  0.13319798  || Decoder Loss:  0.24937494 Validation Decoder Loss:  0.5038759
Encoder Loss:  0.13216797  || Decoder Loss:  0.24666595 Validation Decoder Loss:  0.5029449
Encoder Loss:  0.1312376  || Decoder Loss:  0.24423936 Validation Decoder Loss:  0.50211966
Encoder Loss:  0.1305327  || Decoder Loss:  0.24220243 Validation Decoder Loss:  0.50147456
Encoder Loss:  0.1299616  || Decoder Loss:  0.24051008 Validation Decoder Loss:  0.5009566
Encoder Loss:  0.12944399  || Decoder Loss:  0.23898458 Validation Decoder Loss:  0.5005798
Encoder Loss:  0.12904029  || Decoder Loss:  0.2377706 Validation Decoder Loss:  0.5002389
Encoder Loss:  0.12869099  || Decoder Loss:  0.236817 Validation Decoder Loss:  0.4999258
Encoder Loss:  0.12834868  || Decoder Loss:  0.23594435 Validation Decoder Loss:  0.49963233
Encoder Loss:  0.12801461  || Decoder Loss:  0.23517847 Validation Decoder Loss:  0.49932414
Encoder Loss:  0.12767032  || Decoder Loss:  0.23446766 Validation Decoder Loss:  0.49904338
Encoder Loss:  0.12731174  || Decoder Loss:  0.23374367 Validation Decoder Loss:  0.49877578
Encoder Loss:  0.12694588  || Decoder Loss:  0.2330586 Validation Decoder Loss:  0.49850222
Encoder Loss:  0.1265743  || Decoder Loss:  0.2324415 Validation Decoder Loss:  0.49821794
Encoder Loss:  0.12619245  || Decoder Loss:  0.23187128 Validation Decoder Loss:  0.4979217
Encoder Loss:  0.12579444  || Decoder Loss:  0.23135245 Validation Decoder Loss:  0.4976309
Encoder Loss:  0.1253771  || Decoder Loss:  0.23085332 Validation Decoder Loss:  0.49734196
Encoder Loss:  0.124937996  || Decoder Loss:  0.23036468 Validation Decoder Loss:  0.49706525
Encoder Loss:  0.12447727  || Decoder Loss:  0.22987969 Validation Decoder Loss:  0.49679974
Encoder Loss:  0.12399276  || Decoder Loss:  0.22939484 Validation Decoder Loss:  0.49654365
Encoder Loss:  0.123484895  || Decoder Loss:  0.22891426 Validation Decoder Loss:  0.4963026
Encoder Loss:  0.12295008  || Decoder Loss:  0.22842352 Validation Decoder Loss:  0.49608508
Encoder Loss:  0.122393295  || Decoder Loss:  0.22792545 Validation Decoder Loss:  0.49588507
Encoder Loss:  0.12181623  || Decoder Loss:  0.22742052 Validation Decoder Loss:  0.49571505
Encoder Loss:  0.121217415  || Decoder Loss:  0.22690837 Validation Decoder Loss:  0.49558952
Encoder Loss:  0.1205919  || Decoder Loss:  0.22639692 Validation Decoder Loss:  0.49548465
Encoder Loss:  0.11993694  || Decoder Loss:  0.22589032 Validation Decoder Loss:  0.49539375
Encoder Loss:  0.11925055  || Decoder Loss:  0.22538133 Validation Decoder Loss:  0.49533242
Encoder Loss:  0.11853562  || Decoder Loss:  0.22487669 Validation Decoder Loss:  0.49530822
Encoder Loss:  0.117790475  || Decoder Loss:  0.2243739 Validation Decoder Loss:  0.49533853
Encoder Loss:  0.117014065  || Decoder Loss:  0.22388291 Validation Decoder Loss:  0.49540272
Encoder Loss:  0.11620967  || Decoder Loss:  0.2234019 Validation Decoder Loss:  0.4954954
Encoder Loss:  0.115375996  || Decoder Loss:  0.22293405 Validation Decoder Loss:  0.49559966
Encoder Loss:  0.11450879  || Decoder Loss:  0.22248694 Validation Decoder Loss:  0.4957169
Encoder Loss:  0.11360651  || Decoder Loss:  0.22206624 Validation Decoder Loss:  0.4958465
Encoder Loss:  0.11266985  || Decoder Loss:  0.22166498 Validation Decoder Loss:  0.49597687
Encoder Loss:  0.11170121  || Decoder Loss:  0.22129197 Validation Decoder Loss:  0.49611646
Encoder Loss:  0.11070585  || Decoder Loss:  0.22089863 Validation Decoder Loss:  0.4962788
Encoder Loss:  0.10968421  || Decoder Loss:  0.22052069 Validation Decoder Loss:  0.4964476
Model: bold_synthesis_net_lr_0.0002483352735216132 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4964476
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_165 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_357 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_166 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_74 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_119 (Conv2D)          (None, 830, 14, 1)        46        
_________________________________________________________________
dropout_359 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_120 (Conv2D)          (None, 420, 14, 1)        412       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_119 (Conv2D (None, 660, 14, 1)        242       
_________________________________________________________________
dropout_361 (Dropout)        (None, 660, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_120 (Conv2D (None, 874, 14, 1)        216       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3178347  || Decoder Loss:  0.4058454 Validation Decoder Loss:  0.76087564
Encoder Loss:  0.31378865  || Decoder Loss:  0.40358293 Validation Decoder Loss:  0.75176674
Encoder Loss:  0.30956453  || Decoder Loss:  0.40110618 Validation Decoder Loss:  0.74213266
Encoder Loss:  0.30518663  || Decoder Loss:  0.39841703 Validation Decoder Loss:  0.7318867
Encoder Loss:  0.3006676  || Decoder Loss:  0.39550358 Validation Decoder Loss:  0.72094154
Encoder Loss:  0.29600886  || Decoder Loss:  0.39234945 Validation Decoder Loss:  0.70926607
Encoder Loss:  0.2912127  || Decoder Loss:  0.38893703 Validation Decoder Loss:  0.69686043
Encoder Loss:  0.28628436  || Decoder Loss:  0.38524723 Validation Decoder Loss:  0.6837452
Encoder Loss:  0.28122956  || Decoder Loss:  0.381261 Validation Decoder Loss:  0.67046666
Encoder Loss:  0.27605394  || Decoder Loss:  0.37695894 Validation Decoder Loss:  0.65704316
Encoder Loss:  0.27076733  || Decoder Loss:  0.37232465 Validation Decoder Loss:  0.6435857
Encoder Loss:  0.26538154  || Decoder Loss:  0.36734205 Validation Decoder Loss:  0.63090575
Encoder Loss:  0.25990322  || Decoder Loss:  0.3619951 Validation Decoder Loss:  0.61883324
Encoder Loss:  0.25432885  || Decoder Loss:  0.3562723 Validation Decoder Loss:  0.607064
Encoder Loss:  0.24868163  || Decoder Loss:  0.35017043 Validation Decoder Loss:  0.59487456
Encoder Loss:  0.24296737  || Decoder Loss:  0.34369016 Validation Decoder Loss:  0.5822054
Encoder Loss:  0.23720744  || Decoder Loss:  0.3368855 Validation Decoder Loss:  0.56907797
Encoder Loss:  0.23144427  || Decoder Loss:  0.32988346 Validation Decoder Loss:  0.5555559
Encoder Loss:  0.22568138  || Decoder Loss:  0.32268712 Validation Decoder Loss:  0.5416536
Encoder Loss:  0.21990283  || Decoder Loss:  0.315245 Validation Decoder Loss:  0.5277238
Encoder Loss:  0.21467902  || Decoder Loss:  0.3080783 Validation Decoder Loss:  0.51622283
Encoder Loss:  0.21011174  || Decoder Loss:  0.30155453 Validation Decoder Loss:  0.5052923
Encoder Loss:  0.20559038  || Decoder Loss:  0.29508126 Validation Decoder Loss:  0.4949928
Encoder Loss:  0.2012002  || Decoder Loss:  0.28891072 Validation Decoder Loss:  0.48529908
Encoder Loss:  0.19691679  || Decoder Loss:  0.28299662 Validation Decoder Loss:  0.476544
Encoder Loss:  0.19269511  || Decoder Loss:  0.27719793 Validation Decoder Loss:  0.46888435
Encoder Loss:  0.18855181  || Decoder Loss:  0.27155575 Validation Decoder Loss:  0.46217972
Encoder Loss:  0.18448967  || Decoder Loss:  0.2660846 Validation Decoder Loss:  0.45656338
Encoder Loss:  0.18078655  || Decoder Loss:  0.26098847 Validation Decoder Loss:  0.4526032
Encoder Loss:  0.17760976  || Decoder Loss:  0.25648886 Validation Decoder Loss:  0.44994316
Encoder Loss:  0.1748788  || Decoder Loss:  0.2524739 Validation Decoder Loss:  0.44800967
Encoder Loss:  0.17231974  || Decoder Loss:  0.24872255 Validation Decoder Loss:  0.44639945
Encoder Loss:  0.16978376  || Decoder Loss:  0.24504611 Validation Decoder Loss:  0.44536033
Encoder Loss:  0.16728118  || Decoder Loss:  0.24146324 Validation Decoder Loss:  0.44484764
Encoder Loss:  0.16481157  || Decoder Loss:  0.2379873 Validation Decoder Loss:  0.44482216
Encoder Loss:  0.16237798  || Decoder Loss:  0.23463187 Validation Decoder Loss:  0.44537216
Encoder Loss:  0.16000073  || Decoder Loss:  0.23144336 Validation Decoder Loss:  0.44645023
Encoder Loss:  0.15770562  || Decoder Loss:  0.228469 Validation Decoder Loss:  0.44784537
Encoder Loss:  0.15552753  || Decoder Loss:  0.22576721 Validation Decoder Loss:  0.44944832
Encoder Loss:  0.15366684  || Decoder Loss:  0.22350867 Validation Decoder Loss:  0.45090255
Model: bold_synthesis_net_lr_0.0001103360563404918 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45090255
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_168 (Conv3D (None, 70, 5, 14, 1)      8         
_________________________________________________________________
dropout_363 (Dropout)        (None, 70, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_169 (Conv3D (None, 84, 5, 14, 1)      16        
_________________________________________________________________
reshape_75 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_121 (Conv2D)          (None, 720, 14, 1)        156       
_________________________________________________________________
dropout_365 (Dropout)        (None, 720, 14, 1)        0         
_________________________________________________________________
conv2d_122 (Conv2D)          (None, 420, 14, 1)        302       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_121 (Conv2D (None, 640, 14, 1)        222       
_________________________________________________________________
dropout_367 (Dropout)        (None, 640, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_122 (Conv2D (None, 874, 14, 1)        236       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20609397  || Decoder Loss:  0.22537641 Validation Decoder Loss:  0.47825027
Encoder Loss:  0.18625376  || Decoder Loss:  0.21087578 Validation Decoder Loss:  0.4633835
Encoder Loss:  0.18174557  || Decoder Loss:  0.20638804 Validation Decoder Loss:  0.45921704
Encoder Loss:  0.17911483  || Decoder Loss:  0.20350923 Validation Decoder Loss:  0.45242578
Encoder Loss:  0.17852367  || Decoder Loss:  0.20282431 Validation Decoder Loss:  0.44845164
Encoder Loss:  0.17826553  || Decoder Loss:  0.20251907 Validation Decoder Loss:  0.4493164
Encoder Loss:  0.1778272  || Decoder Loss:  0.2020068 Validation Decoder Loss:  0.4471727
Encoder Loss:  0.17800018  || Decoder Loss:  0.20221491 Validation Decoder Loss:  0.4448128
Encoder Loss:  0.17726389  || Decoder Loss:  0.2013426 Validation Decoder Loss:  0.47548053
Encoder Loss:  0.171641  || Decoder Loss:  0.19466066 Validation Decoder Loss:  0.5657806
Encoder Loss:  0.16533779  || Decoder Loss:  0.18716289 Validation Decoder Loss:  0.5642046
Encoder Loss:  0.16417874  || Decoder Loss:  0.18578658 Validation Decoder Loss:  0.5623519
Encoder Loss:  0.1634457  || Decoder Loss:  0.18492353 Validation Decoder Loss:  0.5617599
Encoder Loss:  0.16294166  || Decoder Loss:  0.18432148 Validation Decoder Loss:  0.5592638
Encoder Loss:  0.16242066  || Decoder Loss:  0.18370333 Validation Decoder Loss:  0.5572327
Encoder Loss:  0.16185607  || Decoder Loss:  0.1830393 Validation Decoder Loss:  0.5565652
Encoder Loss:  0.16139704  || Decoder Loss:  0.18249395 Validation Decoder Loss:  0.5557631
Encoder Loss:  0.16096394  || Decoder Loss:  0.18197843 Validation Decoder Loss:  0.55495256
Encoder Loss:  0.16044927  || Decoder Loss:  0.18136562 Validation Decoder Loss:  0.55662364
Encoder Loss:  0.16000062  || Decoder Loss:  0.18083636 Validation Decoder Loss:  0.55898845
Encoder Loss:  0.15971494  || Decoder Loss:  0.18049185 Validation Decoder Loss:  0.55948216
Encoder Loss:  0.15946594  || Decoder Loss:  0.1802013 Validation Decoder Loss:  0.56001925
Encoder Loss:  0.15928228  || Decoder Loss:  0.17998075 Validation Decoder Loss:  0.56077886
Encoder Loss:  0.15912436  || Decoder Loss:  0.17979199 Validation Decoder Loss:  0.5610396
Encoder Loss:  0.15893613  || Decoder Loss:  0.17957148 Validation Decoder Loss:  0.56128854
Encoder Loss:  0.15872572  || Decoder Loss:  0.17932265 Validation Decoder Loss:  0.56104785
Encoder Loss:  0.1585485  || Decoder Loss:  0.1791117 Validation Decoder Loss:  0.56180096
Encoder Loss:  0.15835825  || Decoder Loss:  0.178888 Validation Decoder Loss:  0.5629394
Encoder Loss:  0.15820545  || Decoder Loss:  0.17870712 Validation Decoder Loss:  0.5646879
Encoder Loss:  0.1580298  || Decoder Loss:  0.1784987 Validation Decoder Loss:  0.5667024
Encoder Loss:  0.15784948  || Decoder Loss:  0.17828596 Validation Decoder Loss:  0.569564
Encoder Loss:  0.15770663  || Decoder Loss:  0.17811693 Validation Decoder Loss:  0.5718635
Encoder Loss:  0.15754193  || Decoder Loss:  0.17792657 Validation Decoder Loss:  0.57333386
Encoder Loss:  0.15727511  || Decoder Loss:  0.17760815 Validation Decoder Loss:  0.57213455
Encoder Loss:  0.15702964  || Decoder Loss:  0.17731817 Validation Decoder Loss:  0.57232416
Encoder Loss:  0.15679538  || Decoder Loss:  0.17704123 Validation Decoder Loss:  0.5733689
Encoder Loss:  0.15656783  || Decoder Loss:  0.17677155 Validation Decoder Loss:  0.5740414
Encoder Loss:  0.15635009  || Decoder Loss:  0.1765128 Validation Decoder Loss:  0.57537466
Encoder Loss:  0.15622379  || Decoder Loss:  0.17635973 Validation Decoder Loss:  0.5749349
Encoder Loss:  0.15612248  || Decoder Loss:  0.17623997 Validation Decoder Loss:  0.5739138
Model: bold_synthesis_net_lr_0.0009830041228585122 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5739138
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_171 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_369 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_172 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_76 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_123 (Conv2D)          (None, 720, 14, 1)        156       
_________________________________________________________________
dropout_371 (Dropout)        (None, 720, 14, 1)        0         
_________________________________________________________________
conv2d_124 (Conv2D)          (None, 420, 14, 1)        302       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_123 (Conv2D (None, 730, 14, 1)        312       
_________________________________________________________________
dropout_373 (Dropout)        (None, 730, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_124 (Conv2D (None, 874, 14, 1)        146       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3814824  || Decoder Loss:  0.43751103 Validation Decoder Loss:  0.9640515
Encoder Loss:  0.38111967  || Decoder Loss:  0.43738237 Validation Decoder Loss:  0.96330434
Encoder Loss:  0.38075316  || Decoder Loss:  0.43725103 Validation Decoder Loss:  0.96253175
Encoder Loss:  0.38037974  || Decoder Loss:  0.43711615 Validation Decoder Loss:  0.9617317
Encoder Loss:  0.37999877  || Decoder Loss:  0.43697762 Validation Decoder Loss:  0.9609028
Encoder Loss:  0.37960985  || Decoder Loss:  0.4368353 Validation Decoder Loss:  0.96004397
Encoder Loss:  0.37921268  || Decoder Loss:  0.436689 Validation Decoder Loss:  0.95915353
Encoder Loss:  0.3788069  || Decoder Loss:  0.43653876 Validation Decoder Loss:  0.9582299
Encoder Loss:  0.378392  || Decoder Loss:  0.43638414 Validation Decoder Loss:  0.95727134
Encoder Loss:  0.37796783  || Decoder Loss:  0.43622532 Validation Decoder Loss:  0.95627576
Encoder Loss:  0.37753376  || Decoder Loss:  0.43606186 Validation Decoder Loss:  0.95524126
Encoder Loss:  0.37708953  || Decoder Loss:  0.4358936 Validation Decoder Loss:  0.9541654
Encoder Loss:  0.37663457  || Decoder Loss:  0.43572038 Validation Decoder Loss:  0.953046
Encoder Loss:  0.3761686  || Decoder Loss:  0.43554202 Validation Decoder Loss:  0.9518802
Encoder Loss:  0.3756911  || Decoder Loss:  0.4353583 Validation Decoder Loss:  0.9506654
Encoder Loss:  0.3752016  || Decoder Loss:  0.4351689 Validation Decoder Loss:  0.9493986
Encoder Loss:  0.37469953  || Decoder Loss:  0.43497372 Validation Decoder Loss:  0.9480763
Encoder Loss:  0.37418455  || Decoder Loss:  0.43477234 Validation Decoder Loss:  0.9466951
Encoder Loss:  0.3736561  || Decoder Loss:  0.43456444 Validation Decoder Loss:  0.94525117
Encoder Loss:  0.37311348  || Decoder Loss:  0.43434992 Validation Decoder Loss:  0.94374025
Encoder Loss:  0.3725562  || Decoder Loss:  0.43412822 Validation Decoder Loss:  0.9421578
Encoder Loss:  0.3719837  || Decoder Loss:  0.43389916 Validation Decoder Loss:  0.94049907
Encoder Loss:  0.37139535  || Decoder Loss:  0.4336624 Validation Decoder Loss:  0.9387587
Encoder Loss:  0.37079042  || Decoder Loss:  0.43341726 Validation Decoder Loss:  0.9369308
Encoder Loss:  0.37016824  || Decoder Loss:  0.43316364 Validation Decoder Loss:  0.93500924
Encoder Loss:  0.36952808  || Decoder Loss:  0.43290097 Validation Decoder Loss:  0.93298715
Encoder Loss:  0.3688691  || Decoder Loss:  0.43262872 Validation Decoder Loss:  0.93085706
Encoder Loss:  0.3681905  || Decoder Loss:  0.43234652 Validation Decoder Loss:  0.92861104
Encoder Loss:  0.36749157  || Decoder Loss:  0.43205366 Validation Decoder Loss:  0.9262406
Encoder Loss:  0.36677128  || Decoder Loss:  0.43174973 Validation Decoder Loss:  0.92373604
Encoder Loss:  0.3660285  || Decoder Loss:  0.43143398 Validation Decoder Loss:  0.9210873
Encoder Loss:  0.36526242  || Decoder Loss:  0.43110567 Validation Decoder Loss:  0.91828346
Encoder Loss:  0.36447176  || Decoder Loss:  0.4307642 Validation Decoder Loss:  0.9153126
Encoder Loss:  0.36365545  || Decoder Loss:  0.43040887 Validation Decoder Loss:  0.91216207
Encoder Loss:  0.36281216  || Decoder Loss:  0.4300385 Validation Decoder Loss:  0.90881836
Encoder Loss:  0.36194068  || Decoder Loss:  0.4296524 Validation Decoder Loss:  0.9052671
Encoder Loss:  0.36103937  || Decoder Loss:  0.4292496 Validation Decoder Loss:  0.9014928
Encoder Loss:  0.3601068  || Decoder Loss:  0.42882895 Validation Decoder Loss:  0.8974795
Encoder Loss:  0.35914135  || Decoder Loss:  0.4283893 Validation Decoder Loss:  0.89321005
Encoder Loss:  0.35814115  || Decoder Loss:  0.4279293 Validation Decoder Loss:  0.88866717
Model: bold_synthesis_net_lr_0.0001377538135431943 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.88866717
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_174 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_375 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_175 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_77 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_125 (Conv2D)          (None, 790, 14, 1)        86        
_________________________________________________________________
dropout_377 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_126 (Conv2D)          (None, 420, 14, 1)        372       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_125 (Conv2D (None, 790, 14, 1)        372       
_________________________________________________________________
dropout_379 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_126 (Conv2D (None, 874, 14, 1)        86        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25260103  || Decoder Loss:  0.30156088 Validation Decoder Loss:  0.47098312
Encoder Loss:  0.1670537  || Decoder Loss:  0.20505527 Validation Decoder Loss:  0.49367672
Encoder Loss:  0.15542354  || Decoder Loss:  0.2045881 Validation Decoder Loss:  0.4972575
Encoder Loss:  0.14967273  || Decoder Loss:  0.20958902 Validation Decoder Loss:  0.5038788
Encoder Loss:  0.15136394  || Decoder Loss:  0.21387959 Validation Decoder Loss:  0.5060623
Encoder Loss:  0.15107581  || Decoder Loss:  0.2141227 Validation Decoder Loss:  0.50616765
Encoder Loss:  0.14956573  || Decoder Loss:  0.21213102 Validation Decoder Loss:  0.5007663
Encoder Loss:  0.14749883  || Decoder Loss:  0.20909062 Validation Decoder Loss:  0.48906174
Encoder Loss:  0.14543109  || Decoder Loss:  0.2059053 Validation Decoder Loss:  0.4687222
Encoder Loss:  0.14628896  || Decoder Loss:  0.20743072 Validation Decoder Loss:  0.44729927
Encoder Loss:  0.15208712  || Decoder Loss:  0.21702006 Validation Decoder Loss:  0.4357906
Encoder Loss:  0.15829377  || Decoder Loss:  0.2272597 Validation Decoder Loss:  0.4474506
Encoder Loss:  0.16201693  || Decoder Loss:  0.23340122 Validation Decoder Loss:  0.45504913
Encoder Loss:  0.1666029  || Decoder Loss:  0.24095725 Validation Decoder Loss:  0.4708936
Encoder Loss:  0.17012528  || Decoder Loss:  0.24676497 Validation Decoder Loss:  0.48961186
Encoder Loss:  0.16859338  || Decoder Loss:  0.24427454 Validation Decoder Loss:  0.5365375
Encoder Loss:  0.1461694  || Decoder Loss:  0.20750166 Validation Decoder Loss:  0.5784978
Encoder Loss:  0.13891533  || Decoder Loss:  0.19561426 Validation Decoder Loss:  0.58710307
Encoder Loss:  0.13693345  || Decoder Loss:  0.19237597 Validation Decoder Loss:  0.588079
Encoder Loss:  0.13632245  || Decoder Loss:  0.19138019 Validation Decoder Loss:  0.58742476
Encoder Loss:  0.13582434  || Decoder Loss:  0.19057265 Validation Decoder Loss:  0.5875942
Encoder Loss:  0.13543098  || Decoder Loss:  0.18993431 Validation Decoder Loss:  0.5873882
Encoder Loss:  0.13507952  || Decoder Loss:  0.18935795 Validation Decoder Loss:  0.5867042
Encoder Loss:  0.13467361  || Decoder Loss:  0.18869768 Validation Decoder Loss:  0.58620715
Encoder Loss:  0.13429162  || Decoder Loss:  0.1880753 Validation Decoder Loss:  0.5866633
Encoder Loss:  0.13388805  || Decoder Loss:  0.18741946 Validation Decoder Loss:  0.5870118
Encoder Loss:  0.13353598  || Decoder Loss:  0.18684539 Validation Decoder Loss:  0.5863562
Encoder Loss:  0.13325661  || Decoder Loss:  0.18639366 Validation Decoder Loss:  0.5858646
Encoder Loss:  0.13301894  || Decoder Loss:  0.18600251 Validation Decoder Loss:  0.5852118
Encoder Loss:  0.13282475  || Decoder Loss:  0.18569136 Validation Decoder Loss:  0.582768
Encoder Loss:  0.1325665  || Decoder Loss:  0.18527158 Validation Decoder Loss:  0.57789254
Encoder Loss:  0.13194607  || Decoder Loss:  0.18425511 Validation Decoder Loss:  0.5701489
Encoder Loss:  0.12956531  || Decoder Loss:  0.18035579 Validation Decoder Loss:  0.5750178
Encoder Loss:  0.12901857  || Decoder Loss:  0.1794644 Validation Decoder Loss:  0.571779
Encoder Loss:  0.12859964  || Decoder Loss:  0.17878275 Validation Decoder Loss:  0.5674776
Encoder Loss:  0.1282101  || Decoder Loss:  0.1781488 Validation Decoder Loss:  0.5663746
Encoder Loss:  0.12789586  || Decoder Loss:  0.17763327 Validation Decoder Loss:  0.5647177
Encoder Loss:  0.1276095  || Decoder Loss:  0.17716716 Validation Decoder Loss:  0.56229556
Encoder Loss:  0.12738483  || Decoder Loss:  0.17680284 Validation Decoder Loss:  0.5600272
Encoder Loss:  0.12720016  || Decoder Loss:  0.17650719 Validation Decoder Loss:  0.56103784
Model: bold_synthesis_net_lr_0.000410980450443063 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.56103784
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_177 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_381 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_178 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_78 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_127 (Conv2D)          (None, 510, 14, 1)        366       
_________________________________________________________________
dropout_383 (Dropout)        (None, 510, 14, 1)        0         
_________________________________________________________________
conv2d_128 (Conv2D)          (None, 420, 14, 1)        92        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_127 (Conv2D (None, 620, 14, 1)        202       
_________________________________________________________________
dropout_385 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_128 (Conv2D (None, 874, 14, 1)        256       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22695754  || Decoder Loss:  0.24146697 Validation Decoder Loss:  0.49725473
Encoder Loss:  0.21237713  || Decoder Loss:  0.2257757 Validation Decoder Loss:  0.49700558
Encoder Loss:  0.20503391  || Decoder Loss:  0.218551 Validation Decoder Loss:  0.49731123
Encoder Loss:  0.19829401  || Decoder Loss:  0.21338694 Validation Decoder Loss:  0.5035871
Encoder Loss:  0.19420399  || Decoder Loss:  0.21214366 Validation Decoder Loss:  0.5098807
Encoder Loss:  0.19421026  || Decoder Loss:  0.21315905 Validation Decoder Loss:  0.50375485
Encoder Loss:  0.1920662  || Decoder Loss:  0.21082795 Validation Decoder Loss:  0.49632826
Encoder Loss:  0.18957442  || Decoder Loss:  0.20807573 Validation Decoder Loss:  0.4892702
Encoder Loss:  0.1875774  || Decoder Loss:  0.20586753 Validation Decoder Loss:  0.48488492
Encoder Loss:  0.18609634  || Decoder Loss:  0.20422974 Validation Decoder Loss:  0.48195487
Encoder Loss:  0.1852371  || Decoder Loss:  0.20328723 Validation Decoder Loss:  0.48169118
Encoder Loss:  0.18477607  || Decoder Loss:  0.20279174 Validation Decoder Loss:  0.48254624
Encoder Loss:  0.1843144  || Decoder Loss:  0.20229058 Validation Decoder Loss:  0.4827987
Encoder Loss:  0.1840082  || Decoder Loss:  0.20196234 Validation Decoder Loss:  0.4826505
Encoder Loss:  0.18399794  || Decoder Loss:  0.20196694 Validation Decoder Loss:  0.4828573
Encoder Loss:  0.18407741  || Decoder Loss:  0.20207211 Validation Decoder Loss:  0.4833243
Encoder Loss:  0.18416092  || Decoder Loss:  0.20218006 Validation Decoder Loss:  0.48550346
Encoder Loss:  0.18433498  || Decoder Loss:  0.20238927 Validation Decoder Loss:  0.48730385
Encoder Loss:  0.18444437  || Decoder Loss:  0.20252475 Validation Decoder Loss:  0.49001503
Encoder Loss:  0.18296859  || Decoder Loss:  0.20085897 Validation Decoder Loss:  0.49147877
Encoder Loss:  0.18085088  || Decoder Loss:  0.19846277 Validation Decoder Loss:  0.49240386
Encoder Loss:  0.18032539  || Decoder Loss:  0.19787438 Validation Decoder Loss:  0.49387035
Encoder Loss:  0.18026115  || Decoder Loss:  0.19780955 Validation Decoder Loss:  0.49487606
Encoder Loss:  0.18038118  || Decoder Loss:  0.19795287 Validation Decoder Loss:  0.49593854
Encoder Loss:  0.18056941  || Decoder Loss:  0.1981742 Validation Decoder Loss:  0.4979519
Encoder Loss:  0.18089484  || Decoder Loss:  0.19855084 Validation Decoder Loss:  0.49792504
Encoder Loss:  0.18114494  || Decoder Loss:  0.19884148 Validation Decoder Loss:  0.49875215
Encoder Loss:  0.1816724  || Decoder Loss:  0.19944629 Validation Decoder Loss:  0.50042933
Encoder Loss:  0.18225044  || Decoder Loss:  0.2001083 Validation Decoder Loss:  0.5022448
Encoder Loss:  0.18272477  || Decoder Loss:  0.20065191 Validation Decoder Loss:  0.5037256
Encoder Loss:  0.18334584  || Decoder Loss:  0.20136233 Validation Decoder Loss:  0.5049028
Encoder Loss:  0.18405312  || Decoder Loss:  0.20217071 Validation Decoder Loss:  0.50537515
Encoder Loss:  0.18471666  || Decoder Loss:  0.20292808 Validation Decoder Loss:  0.50607485
Encoder Loss:  0.18534228  || Decoder Loss:  0.20364177 Validation Decoder Loss:  0.50819945
Encoder Loss:  0.18611605  || Decoder Loss:  0.20452377 Validation Decoder Loss:  0.5086462
Encoder Loss:  0.18677463  || Decoder Loss:  0.20527449 Validation Decoder Loss:  0.50994664
Encoder Loss:  0.18733226  || Decoder Loss:  0.20591003 Validation Decoder Loss:  0.5121075
Encoder Loss:  0.1877897  || Decoder Loss:  0.20643167 Validation Decoder Loss:  0.5138688
Encoder Loss:  0.1882816  || Decoder Loss:  0.20699263 Validation Decoder Loss:  0.51511514
Encoder Loss:  0.18882842  || Decoder Loss:  0.20761594 Validation Decoder Loss:  0.5171354
Model: bold_synthesis_net_lr_0.0002105928136995799 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.51713544
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_180 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_387 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_181 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_79 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_129 (Conv2D)          (None, 660, 14, 1)        216       
_________________________________________________________________
dropout_389 (Dropout)        (None, 660, 14, 1)        0         
_________________________________________________________________
conv2d_130 (Conv2D)          (None, 420, 14, 1)        242       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_129 (Conv2D (None, 830, 14, 1)        412       
_________________________________________________________________
dropout_391 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_130 (Conv2D (None, 874, 14, 1)        46        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12834442  || Decoder Loss:  0.24394202 Validation Decoder Loss:  0.49936393
Encoder Loss:  0.12454721  || Decoder Loss:  0.2346507 Validation Decoder Loss:  0.49978748
Encoder Loss:  0.12315231  || Decoder Loss:  0.23074493 Validation Decoder Loss:  0.49941102
Encoder Loss:  0.12174659  || Decoder Loss:  0.22818421 Validation Decoder Loss:  0.49892238
Encoder Loss:  0.11986271  || Decoder Loss:  0.22588587 Validation Decoder Loss:  0.49819088
Encoder Loss:  0.11711262  || Decoder Loss:  0.223748 Validation Decoder Loss:  0.49717546
Encoder Loss:  0.11286705  || Decoder Loss:  0.22150609 Validation Decoder Loss:  0.49596298
Encoder Loss:  0.10613539  || Decoder Loss:  0.21901438 Validation Decoder Loss:  0.4944702
Encoder Loss:  0.09687679  || Decoder Loss:  0.21665464 Validation Decoder Loss:  0.49443698
Encoder Loss:  0.0868002  || Decoder Loss:  0.21568397 Validation Decoder Loss:  0.49375716
Encoder Loss:  0.07900366  || Decoder Loss:  0.2150693 Validation Decoder Loss:  0.48958337
Encoder Loss:  0.07315202  || Decoder Loss:  0.21427894 Validation Decoder Loss:  0.48543367
Encoder Loss:  0.06815778  || Decoder Loss:  0.21306792 Validation Decoder Loss:  0.48218554
Encoder Loss:  0.06451269  || Decoder Loss:  0.21195467 Validation Decoder Loss:  0.48097637
Encoder Loss:  0.062598564  || Decoder Loss:  0.21099885 Validation Decoder Loss:  0.4796278
Encoder Loss:  0.061796322  || Decoder Loss:  0.21015374 Validation Decoder Loss:  0.47861966
Encoder Loss:  0.061345298  || Decoder Loss:  0.20953557 Validation Decoder Loss:  0.47772962
Encoder Loss:  0.061038222  || Decoder Loss:  0.20902541 Validation Decoder Loss:  0.47677845
Encoder Loss:  0.060835525  || Decoder Loss:  0.20856693 Validation Decoder Loss:  0.47571126
Encoder Loss:  0.06068652  || Decoder Loss:  0.20816267 Validation Decoder Loss:  0.4746526
Encoder Loss:  0.060556304  || Decoder Loss:  0.20778644 Validation Decoder Loss:  0.47360423
Encoder Loss:  0.060441397  || Decoder Loss:  0.20746173 Validation Decoder Loss:  0.47258568
Encoder Loss:  0.06033507  || Decoder Loss:  0.20710419 Validation Decoder Loss:  0.47161126
Encoder Loss:  0.060246076  || Decoder Loss:  0.20676154 Validation Decoder Loss:  0.47055152
Encoder Loss:  0.060159598  || Decoder Loss:  0.20631583 Validation Decoder Loss:  0.46944427
Encoder Loss:  0.06007567  || Decoder Loss:  0.20572717 Validation Decoder Loss:  0.46808064
Encoder Loss:  0.059995126  || Decoder Loss:  0.20497279 Validation Decoder Loss:  0.4662568
Encoder Loss:  0.05992007  || Decoder Loss:  0.20424978 Validation Decoder Loss:  0.46511754
Encoder Loss:  0.059858136  || Decoder Loss:  0.20381959 Validation Decoder Loss:  0.46498096
Encoder Loss:  0.059803534  || Decoder Loss:  0.20349517 Validation Decoder Loss:  0.46538922
Encoder Loss:  0.059749167  || Decoder Loss:  0.20321923 Validation Decoder Loss:  0.4658827
Encoder Loss:  0.0596984  || Decoder Loss:  0.20291823 Validation Decoder Loss:  0.46673188
Encoder Loss:  0.059647884  || Decoder Loss:  0.2026115 Validation Decoder Loss:  0.46751457
Encoder Loss:  0.059599694  || Decoder Loss:  0.20229457 Validation Decoder Loss:  0.46853846
Encoder Loss:  0.059556153  || Decoder Loss:  0.20193903 Validation Decoder Loss:  0.46970642
Encoder Loss:  0.05951429  || Decoder Loss:  0.20145658 Validation Decoder Loss:  0.47176185
Encoder Loss:  0.059464544  || Decoder Loss:  0.20082468 Validation Decoder Loss:  0.47563142
Encoder Loss:  0.05941503  || Decoder Loss:  0.20021461 Validation Decoder Loss:  0.47808334
Encoder Loss:  0.059365574  || Decoder Loss:  0.1996296 Validation Decoder Loss:  0.480049
Encoder Loss:  0.05932728  || Decoder Loss:  0.19941026 Validation Decoder Loss:  0.4808538
Model: bold_synthesis_net_lr_0.000686047941839394 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4808538
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_183 (Conv3D (None, 82, 5, 14, 1)      20        
_________________________________________________________________
dropout_393 (Dropout)        (None, 82, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_184 (Conv3D (None, 84, 5, 14, 1)      4         
_________________________________________________________________
reshape_80 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_131 (Conv2D)          (None, 570, 14, 1)        306       
_________________________________________________________________
dropout_395 (Dropout)        (None, 570, 14, 1)        0         
_________________________________________________________________
conv2d_132 (Conv2D)          (None, 420, 14, 1)        152       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_131 (Conv2D (None, 680, 14, 1)        262       
_________________________________________________________________
dropout_397 (Dropout)        (None, 680, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_132 (Conv2D (None, 874, 14, 1)        196       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14143029  || Decoder Loss:  0.23422176 Validation Decoder Loss:  0.5002746
Encoder Loss:  0.112627335  || Decoder Loss:  0.21263845 Validation Decoder Loss:  0.5072036
Encoder Loss:  0.08874996  || Decoder Loss:  0.2100591 Validation Decoder Loss:  0.5015852
Encoder Loss:  0.08573914  || Decoder Loss:  0.20774673 Validation Decoder Loss:  0.4937662
Encoder Loss:  0.084374234  || Decoder Loss:  0.2050423 Validation Decoder Loss:  0.48770845
Encoder Loss:  0.08363769  || Decoder Loss:  0.20293489 Validation Decoder Loss:  0.49407688
Encoder Loss:  0.083357856  || Decoder Loss:  0.20268516 Validation Decoder Loss:  0.49526906
Encoder Loss:  0.08305146  || Decoder Loss:  0.20216721 Validation Decoder Loss:  0.49398842
Encoder Loss:  0.08287442  || Decoder Loss:  0.20196892 Validation Decoder Loss:  0.49403745
Encoder Loss:  0.08295084  || Decoder Loss:  0.20277669 Validation Decoder Loss:  0.49654168
Encoder Loss:  0.08307768  || Decoder Loss:  0.20371614 Validation Decoder Loss:  0.49802095
Encoder Loss:  0.083316974  || Decoder Loss:  0.20507193 Validation Decoder Loss:  0.500781
Encoder Loss:  0.08354235  || Decoder Loss:  0.20636453 Validation Decoder Loss:  0.50308645
Encoder Loss:  0.083699696  || Decoder Loss:  0.20728633 Validation Decoder Loss:  0.50339055
Encoder Loss:  0.08375833  || Decoder Loss:  0.2077789 Validation Decoder Loss:  0.51082504
Encoder Loss:  0.08372113  || Decoder Loss:  0.207807 Validation Decoder Loss:  0.5109868
Encoder Loss:  0.08362403  || Decoder Loss:  0.2075322 Validation Decoder Loss:  0.5117192
Encoder Loss:  0.083477564  || Decoder Loss:  0.20692012 Validation Decoder Loss:  0.50873584
Encoder Loss:  0.08335418  || Decoder Loss:  0.2063716 Validation Decoder Loss:  0.51024985
Encoder Loss:  0.08317244  || Decoder Loss:  0.20556414 Validation Decoder Loss:  0.49875966
Encoder Loss:  0.08302225  || Decoder Loss:  0.20484623 Validation Decoder Loss:  0.5063169
Encoder Loss:  0.08287235  || Decoder Loss:  0.20418417 Validation Decoder Loss:  0.50526154
Encoder Loss:  0.08272978  || Decoder Loss:  0.2035372 Validation Decoder Loss:  0.5017536
Encoder Loss:  0.0826109  || Decoder Loss:  0.20297022 Validation Decoder Loss:  0.5010703
Encoder Loss:  0.082471445  || Decoder Loss:  0.20234634 Validation Decoder Loss:  0.4985537
Encoder Loss:  0.08206763  || Decoder Loss:  0.20046581 Validation Decoder Loss:  0.49385965
Encoder Loss:  0.08146186  || Decoder Loss:  0.19763115 Validation Decoder Loss:  0.4903479
Encoder Loss:  0.08125664  || Decoder Loss:  0.19666941 Validation Decoder Loss:  0.48871547
Encoder Loss:  0.08113724  || Decoder Loss:  0.19613679 Validation Decoder Loss:  0.48805356
Encoder Loss:  0.08104394  || Decoder Loss:  0.19573212 Validation Decoder Loss:  0.48749515
Encoder Loss:  0.0809785  || Decoder Loss:  0.19544709 Validation Decoder Loss:  0.48688006
Encoder Loss:  0.08092097  || Decoder Loss:  0.19518237 Validation Decoder Loss:  0.48641795
Encoder Loss:  0.08086207  || Decoder Loss:  0.19493213 Validation Decoder Loss:  0.48507312
Encoder Loss:  0.080797255  || Decoder Loss:  0.19467989 Validation Decoder Loss:  0.4844165
Encoder Loss:  0.080740176  || Decoder Loss:  0.19443117 Validation Decoder Loss:  0.48348004
Encoder Loss:  0.0806878  || Decoder Loss:  0.19423164 Validation Decoder Loss:  0.48199725
Encoder Loss:  0.08064699  || Decoder Loss:  0.19407202 Validation Decoder Loss:  0.48109215
Encoder Loss:  0.080597796  || Decoder Loss:  0.19386783 Validation Decoder Loss:  0.4814766
Encoder Loss:  0.080557615  || Decoder Loss:  0.19371246 Validation Decoder Loss:  0.48048398
Encoder Loss:  0.08053762  || Decoder Loss:  0.19363467 Validation Decoder Loss:  0.4785491
Model: bold_synthesis_net_lr_0.0008172605422647792 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4785491
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_186 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_399 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_187 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_81 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_133 (Conv2D)          (None, 870, 14, 1)        6         
_________________________________________________________________
dropout_401 (Dropout)        (None, 870, 14, 1)        0         
_________________________________________________________________
conv2d_134 (Conv2D)          (None, 420, 14, 1)        452       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_133 (Conv2D (None, 720, 14, 1)        302       
_________________________________________________________________
dropout_403 (Dropout)        (None, 720, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_134 (Conv2D (None, 874, 14, 1)        156       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15383299  || Decoder Loss:  0.24142808 Validation Decoder Loss:  0.4956199
Encoder Loss:  0.1381783  || Decoder Loss:  0.22803478 Validation Decoder Loss:  0.49432552
Encoder Loss:  0.11589332  || Decoder Loss:  0.21927968 Validation Decoder Loss:  0.49505082
Encoder Loss:  0.095880866  || Decoder Loss:  0.212499 Validation Decoder Loss:  0.50162774
Encoder Loss:  0.08623948  || Decoder Loss:  0.21183224 Validation Decoder Loss:  0.5030681
Encoder Loss:  0.08431276  || Decoder Loss:  0.21082993 Validation Decoder Loss:  0.4952029
Encoder Loss:  0.08312358  || Decoder Loss:  0.20774235 Validation Decoder Loss:  0.48708245
Encoder Loss:  0.082014225  || Decoder Loss:  0.20433277 Validation Decoder Loss:  0.4803973
Encoder Loss:  0.08123652  || Decoder Loss:  0.20216702 Validation Decoder Loss:  0.47874096
Encoder Loss:  0.08073851  || Decoder Loss:  0.20115979 Validation Decoder Loss:  0.47751826
Encoder Loss:  0.080394  || Decoder Loss:  0.20061211 Validation Decoder Loss:  0.47658142
Encoder Loss:  0.08013802  || Decoder Loss:  0.20037544 Validation Decoder Loss:  0.47601524
Encoder Loss:  0.07976815  || Decoder Loss:  0.19943346 Validation Decoder Loss:  0.4731925
Encoder Loss:  0.07920264  || Decoder Loss:  0.19726856 Validation Decoder Loss:  0.47611806
Encoder Loss:  0.07881872  || Decoder Loss:  0.19600306 Validation Decoder Loss:  0.48502877
Encoder Loss:  0.078594156  || Decoder Loss:  0.19548337 Validation Decoder Loss:  0.48701283
Encoder Loss:  0.078471996  || Decoder Loss:  0.1954301 Validation Decoder Loss:  0.4880333
Encoder Loss:  0.078370556  || Decoder Loss:  0.1954159 Validation Decoder Loss:  0.4891777
Encoder Loss:  0.0783052  || Decoder Loss:  0.19546208 Validation Decoder Loss:  0.49057713
Encoder Loss:  0.0782588  || Decoder Loss:  0.19552691 Validation Decoder Loss:  0.4916763
Encoder Loss:  0.07822442  || Decoder Loss:  0.19562069 Validation Decoder Loss:  0.49202868
Encoder Loss:  0.078198165  || Decoder Loss:  0.19579476 Validation Decoder Loss:  0.49232522
Encoder Loss:  0.07815706  || Decoder Loss:  0.19582672 Validation Decoder Loss:  0.49187997
Encoder Loss:  0.07811718  || Decoder Loss:  0.19581144 Validation Decoder Loss:  0.49097556
Encoder Loss:  0.07807171  || Decoder Loss:  0.19573653 Validation Decoder Loss:  0.48972392
Encoder Loss:  0.07800968  || Decoder Loss:  0.19551565 Validation Decoder Loss:  0.48934838
Encoder Loss:  0.07794257  || Decoder Loss:  0.19522278 Validation Decoder Loss:  0.48925382
Encoder Loss:  0.07788243  || Decoder Loss:  0.19497266 Validation Decoder Loss:  0.48855668
Encoder Loss:  0.077807285  || Decoder Loss:  0.19462687 Validation Decoder Loss:  0.4886138
Encoder Loss:  0.07774276  || Decoder Loss:  0.1943431 Validation Decoder Loss:  0.49021012
Encoder Loss:  0.07767158  || Decoder Loss:  0.19403708 Validation Decoder Loss:  0.4921266
Encoder Loss:  0.077614024  || Decoder Loss:  0.19376484 Validation Decoder Loss:  0.49379784
Encoder Loss:  0.0775457  || Decoder Loss:  0.1934419 Validation Decoder Loss:  0.49541757
Encoder Loss:  0.07748479  || Decoder Loss:  0.19315475 Validation Decoder Loss:  0.4984274
Encoder Loss:  0.07740004  || Decoder Loss:  0.19275734 Validation Decoder Loss:  0.5022054
Encoder Loss:  0.077258065  || Decoder Loss:  0.19201621 Validation Decoder Loss:  0.5093674
Encoder Loss:  0.07694869  || Decoder Loss:  0.19038685 Validation Decoder Loss:  0.51677775
Encoder Loss:  0.07664115  || Decoder Loss:  0.18875387 Validation Decoder Loss:  0.52221954
Encoder Loss:  0.076441064  || Decoder Loss:  0.18769753 Validation Decoder Loss:  0.52506685
Encoder Loss:  0.07628853  || Decoder Loss:  0.18690892 Validation Decoder Loss:  0.5274902
Model: bold_synthesis_net_lr_0.0007138833356642309 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5274902
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_189 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_405 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_190 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_82 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_135 (Conv2D)          (None, 550, 14, 1)        326       
_________________________________________________________________
dropout_407 (Dropout)        (None, 550, 14, 1)        0         
_________________________________________________________________
conv2d_136 (Conv2D)          (None, 420, 14, 1)        132       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_135 (Conv2D (None, 700, 14, 1)        282       
_________________________________________________________________
dropout_409 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_136 (Conv2D (None, 874, 14, 1)        176       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39859796  || Decoder Loss:  0.40489793 Validation Decoder Loss:  0.7491411
Encoder Loss:  0.39292806  || Decoder Loss:  0.3994471 Validation Decoder Loss:  0.72729087
Encoder Loss:  0.386295  || Decoder Loss:  0.3930057 Validation Decoder Loss:  0.70207715
Encoder Loss:  0.37846  || Decoder Loss:  0.38532168 Validation Decoder Loss:  0.6735
Encoder Loss:  0.36920777  || Decoder Loss:  0.3761637 Validation Decoder Loss:  0.644097
Encoder Loss:  0.35833555  || Decoder Loss:  0.36531234 Validation Decoder Loss:  0.61731607
Encoder Loss:  0.3456909  || Decoder Loss:  0.3526009 Validation Decoder Loss:  0.59045196
Encoder Loss:  0.33136126  || Decoder Loss:  0.33811468 Validation Decoder Loss:  0.5611217
Encoder Loss:  0.3159048  || Decoder Loss:  0.322435 Validation Decoder Loss:  0.52981865
Encoder Loss:  0.29972193  || Decoder Loss:  0.3059603 Validation Decoder Loss:  0.50250226
Encoder Loss:  0.28504097  || Decoder Loss:  0.29097494 Validation Decoder Loss:  0.4811584
Encoder Loss:  0.2721197  || Decoder Loss:  0.27781433 Validation Decoder Loss:  0.46460658
Encoder Loss:  0.260127  || Decoder Loss:  0.265624 Validation Decoder Loss:  0.45391697
Encoder Loss:  0.24947946  || Decoder Loss:  0.25480092 Validation Decoder Loss:  0.44878486
Encoder Loss:  0.24076772  || Decoder Loss:  0.24597017 Validation Decoder Loss:  0.44627112
Encoder Loss:  0.2332983  || Decoder Loss:  0.23844853 Validation Decoder Loss:  0.4467309
Encoder Loss:  0.22690248  || Decoder Loss:  0.23207274 Validation Decoder Loss:  0.44917828
Encoder Loss:  0.22201046  || Decoder Loss:  0.22726433 Validation Decoder Loss:  0.4520325
Encoder Loss:  0.21875533  || Decoder Loss:  0.22413495 Validation Decoder Loss:  0.4548537
Encoder Loss:  0.21655253  || Decoder Loss:  0.22209425 Validation Decoder Loss:  0.4573566
Encoder Loss:  0.21523091  || Decoder Loss:  0.22094063 Validation Decoder Loss:  0.45911703
Encoder Loss:  0.21452284  || Decoder Loss:  0.22039089 Validation Decoder Loss:  0.4595894
Encoder Loss:  0.21388264  || Decoder Loss:  0.21989384 Validation Decoder Loss:  0.459565
Encoder Loss:  0.2135946  || Decoder Loss:  0.21975808 Validation Decoder Loss:  0.45965946
Encoder Loss:  0.21318975  || Decoder Loss:  0.21949136 Validation Decoder Loss:  0.45968994
Encoder Loss:  0.21266422  || Decoder Loss:  0.21908967 Validation Decoder Loss:  0.45987126
Encoder Loss:  0.21209721  || Decoder Loss:  0.21863146 Validation Decoder Loss:  0.46008426
Encoder Loss:  0.2115819  || Decoder Loss:  0.21821372 Validation Decoder Loss:  0.45970917
Encoder Loss:  0.21103752  || Decoder Loss:  0.21775079 Validation Decoder Loss:  0.4589614
Encoder Loss:  0.2104961  || Decoder Loss:  0.21728401 Validation Decoder Loss:  0.4581935
Encoder Loss:  0.20994997  || Decoder Loss:  0.21680777 Validation Decoder Loss:  0.45748103
Encoder Loss:  0.2094161  || Decoder Loss:  0.21634014 Validation Decoder Loss:  0.45683438
Encoder Loss:  0.20889373  || Decoder Loss:  0.21588051 Validation Decoder Loss:  0.45623645
Encoder Loss:  0.20837612  || Decoder Loss:  0.21542016 Validation Decoder Loss:  0.4556886
Encoder Loss:  0.20783797  || Decoder Loss:  0.21492556 Validation Decoder Loss:  0.45506772
Encoder Loss:  0.20727257  || Decoder Loss:  0.21438691 Validation Decoder Loss:  0.4544001
Encoder Loss:  0.20669878  || Decoder Loss:  0.21381983 Validation Decoder Loss:  0.45368928
Encoder Loss:  0.20612781  || Decoder Loss:  0.21324189 Validation Decoder Loss:  0.4529576
Encoder Loss:  0.20561214  || Decoder Loss:  0.21271308 Validation Decoder Loss:  0.4522591
Encoder Loss:  0.20511588  || Decoder Loss:  0.21220021 Validation Decoder Loss:  0.4515582
Model: bold_synthesis_net_lr_0.0008517081146194995 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4515582
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_192 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_411 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_193 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_83 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_137 (Conv2D)          (None, 440, 14, 1)        436       
_________________________________________________________________
dropout_413 (Dropout)        (None, 440, 14, 1)        0         
_________________________________________________________________
conv2d_138 (Conv2D)          (None, 420, 14, 1)        22        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_137 (Conv2D (None, 610, 14, 1)        192       
_________________________________________________________________
dropout_415 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_138 (Conv2D (None, 874, 14, 1)        266       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20260528  || Decoder Loss:  0.24646531 Validation Decoder Loss:  0.49629593
Encoder Loss:  0.19262785  || Decoder Loss:  0.23462817 Validation Decoder Loss:  0.49381924
Encoder Loss:  0.18774633  || Decoder Loss:  0.23023899 Validation Decoder Loss:  0.4908886
Encoder Loss:  0.183801  || Decoder Loss:  0.22778332 Validation Decoder Loss:  0.48772752
Encoder Loss:  0.18010242  || Decoder Loss:  0.2260918 Validation Decoder Loss:  0.48463327
Encoder Loss:  0.1763995  || Decoder Loss:  0.2245969 Validation Decoder Loss:  0.48197478
Encoder Loss:  0.1730479  || Decoder Loss:  0.22370145 Validation Decoder Loss:  0.48098746
Encoder Loss:  0.16993791  || Decoder Loss:  0.22316712 Validation Decoder Loss:  0.48040482
Encoder Loss:  0.16684608  || Decoder Loss:  0.22262222 Validation Decoder Loss:  0.47900367
Encoder Loss:  0.16502748  || Decoder Loss:  0.22309753 Validation Decoder Loss:  0.4746077
Encoder Loss:  0.16416872  || Decoder Loss:  0.22332726 Validation Decoder Loss:  0.47280708
Encoder Loss:  0.16291714  || Decoder Loss:  0.22183006 Validation Decoder Loss:  0.47317925
Encoder Loss:  0.16185828  || Decoder Loss:  0.2204936 Validation Decoder Loss:  0.47325552
Encoder Loss:  0.16109188  || Decoder Loss:  0.2196627 Validation Decoder Loss:  0.47277972
Encoder Loss:  0.16072102  || Decoder Loss:  0.21951526 Validation Decoder Loss:  0.47158805
Encoder Loss:  0.16089426  || Decoder Loss:  0.22014868 Validation Decoder Loss:  0.47024482
Encoder Loss:  0.16125803  || Decoder Loss:  0.22097763 Validation Decoder Loss:  0.47060147
Encoder Loss:  0.16147594  || Decoder Loss:  0.22151113 Validation Decoder Loss:  0.47240615
Encoder Loss:  0.16121542  || Decoder Loss:  0.22123562 Validation Decoder Loss:  0.47684997
Encoder Loss:  0.16045687  || Decoder Loss:  0.22012772 Validation Decoder Loss:  0.4888767
Encoder Loss:  0.1592731  || Decoder Loss:  0.21833308 Validation Decoder Loss:  0.5110491
Encoder Loss:  0.15821488  || Decoder Loss:  0.21672349 Validation Decoder Loss:  0.5193541
Encoder Loss:  0.1572085  || Decoder Loss:  0.2151894 Validation Decoder Loss:  0.521728
Encoder Loss:  0.15639837  || Decoder Loss:  0.2139537 Validation Decoder Loss:  0.52070004
Encoder Loss:  0.15569611  || Decoder Loss:  0.21288309 Validation Decoder Loss:  0.51952785
Encoder Loss:  0.15507801  || Decoder Loss:  0.2119408 Validation Decoder Loss:  0.5191436
Encoder Loss:  0.15453885  || Decoder Loss:  0.21112049 Validation Decoder Loss:  0.5187761
Encoder Loss:  0.15405734  || Decoder Loss:  0.21038707 Validation Decoder Loss:  0.51784205
Encoder Loss:  0.15364516  || Decoder Loss:  0.20976119 Validation Decoder Loss:  0.51654124
Encoder Loss:  0.15329298  || Decoder Loss:  0.20922619 Validation Decoder Loss:  0.5149287
Encoder Loss:  0.15297744  || Decoder Loss:  0.20874642 Validation Decoder Loss:  0.51395506
Encoder Loss:  0.15269703  || Decoder Loss:  0.2083219 Validation Decoder Loss:  0.5125022
Encoder Loss:  0.15243216  || Decoder Loss:  0.20791954 Validation Decoder Loss:  0.51094496
Encoder Loss:  0.152202  || Decoder Loss:  0.20757227 Validation Decoder Loss:  0.5094931
Encoder Loss:  0.15200736  || Decoder Loss:  0.20727806 Validation Decoder Loss:  0.50856096
Encoder Loss:  0.15183796  || Decoder Loss:  0.2070229 Validation Decoder Loss:  0.50762206
Encoder Loss:  0.1516598  || Decoder Loss:  0.20675464 Validation Decoder Loss:  0.50694555
Encoder Loss:  0.15149513  || Decoder Loss:  0.20650625 Validation Decoder Loss:  0.5060638
Encoder Loss:  0.15133369  || Decoder Loss:  0.2062633 Validation Decoder Loss:  0.5051998
Encoder Loss:  0.15118176  || Decoder Loss:  0.20603281 Validation Decoder Loss:  0.50458735
Model: bold_synthesis_net_lr_0.00011681965152589878 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50458735
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_195 (Conv3D (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_417 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_196 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_84 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_139 (Conv2D)          (None, 770, 14, 1)        106       
_________________________________________________________________
dropout_419 (Dropout)        (None, 770, 14, 1)        0         
_________________________________________________________________
conv2d_140 (Conv2D)          (None, 420, 14, 1)        352       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_139 (Conv2D (None, 630, 14, 1)        212       
_________________________________________________________________
dropout_421 (Dropout)        (None, 630, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_140 (Conv2D (None, 874, 14, 1)        246       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24818914  || Decoder Loss:  0.3107682 Validation Decoder Loss:  0.46238747
Encoder Loss:  0.18657543  || Decoder Loss:  0.23331232 Validation Decoder Loss:  0.46937004
Encoder Loss:  0.16837418  || Decoder Loss:  0.21180208 Validation Decoder Loss:  0.4825775
Encoder Loss:  0.1631477  || Decoder Loss:  0.20815879 Validation Decoder Loss:  0.4876161
Encoder Loss:  0.15664372  || Decoder Loss:  0.20675588 Validation Decoder Loss:  0.4904288
Encoder Loss:  0.14784366  || Decoder Loss:  0.20680876 Validation Decoder Loss:  0.49837485
Encoder Loss:  0.14388645  || Decoder Loss:  0.21126553 Validation Decoder Loss:  0.50246555
Encoder Loss:  0.14328286  || Decoder Loss:  0.21334822 Validation Decoder Loss:  0.4984514
Encoder Loss:  0.14265503  || Decoder Loss:  0.21303913 Validation Decoder Loss:  0.49852166
Encoder Loss:  0.14267686  || Decoder Loss:  0.2138249 Validation Decoder Loss:  0.49969062
Encoder Loss:  0.14250934  || Decoder Loss:  0.21412803 Validation Decoder Loss:  0.50108033
Encoder Loss:  0.14150093  || Decoder Loss:  0.21280117 Validation Decoder Loss:  0.50568265
Encoder Loss:  0.13957575  || Decoder Loss:  0.20970291 Validation Decoder Loss:  0.50564086
Encoder Loss:  0.13825333  || Decoder Loss:  0.2075814 Validation Decoder Loss:  0.50191635
Encoder Loss:  0.13704479  || Decoder Loss:  0.20559482 Validation Decoder Loss:  0.49726185
Encoder Loss:  0.13587764  || Decoder Loss:  0.20365544 Validation Decoder Loss:  0.49255806
Encoder Loss:  0.13477355  || Decoder Loss:  0.20180541 Validation Decoder Loss:  0.4881088
Encoder Loss:  0.13383539  || Decoder Loss:  0.20022714 Validation Decoder Loss:  0.48265895
Encoder Loss:  0.13305233  || Decoder Loss:  0.19890638 Validation Decoder Loss:  0.47689682
Encoder Loss:  0.1327256  || Decoder Loss:  0.19839062 Validation Decoder Loss:  0.47015885
Encoder Loss:  0.13293454  || Decoder Loss:  0.1988275 Validation Decoder Loss:  0.4646095
Encoder Loss:  0.13355671  || Decoder Loss:  0.19999848 Validation Decoder Loss:  0.45961323
Encoder Loss:  0.13439664  || Decoder Loss:  0.2015562 Validation Decoder Loss:  0.45567197
Encoder Loss:  0.13520296  || Decoder Loss:  0.20304762 Validation Decoder Loss:  0.45249566
Encoder Loss:  0.13590513  || Decoder Loss:  0.2043487 Validation Decoder Loss:  0.4500161
Encoder Loss:  0.13662647  || Decoder Loss:  0.20568056 Validation Decoder Loss:  0.44765922
Encoder Loss:  0.13741085  || Decoder Loss:  0.20712495 Validation Decoder Loss:  0.44519776
Encoder Loss:  0.13843675  || Decoder Loss:  0.20900352 Validation Decoder Loss:  0.4435594
Encoder Loss:  0.13966751  || Decoder Loss:  0.2112502 Validation Decoder Loss:  0.44617608
Encoder Loss:  0.14083163  || Decoder Loss:  0.21337356 Validation Decoder Loss:  0.44527125
Encoder Loss:  0.14189388  || Decoder Loss:  0.21531187 Validation Decoder Loss:  0.44480118
Encoder Loss:  0.14230573  || Decoder Loss:  0.21607395 Validation Decoder Loss:  0.44671094
Encoder Loss:  0.14285152  || Decoder Loss:  0.21707834 Validation Decoder Loss:  0.4466752
Encoder Loss:  0.143365  || Decoder Loss:  0.21802151 Validation Decoder Loss:  0.44818494
Encoder Loss:  0.14361769  || Decoder Loss:  0.21849263 Validation Decoder Loss:  0.46109122
Encoder Loss:  0.14199272  || Decoder Loss:  0.21557605 Validation Decoder Loss:  0.5017461
Encoder Loss:  0.13651057  || Decoder Loss:  0.20570174 Validation Decoder Loss:  0.549723
Encoder Loss:  0.13120224  || Decoder Loss:  0.19613856 Validation Decoder Loss:  0.55717516
Encoder Loss:  0.12968609  || Decoder Loss:  0.19341102 Validation Decoder Loss:  0.5559913
Encoder Loss:  0.12854171  || Decoder Loss:  0.19135402 Validation Decoder Loss:  0.5528884
Model: bold_synthesis_net_lr_0.00030578473951578224 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5528884
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_198 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_423 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_199 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_85 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_141 (Conv2D)          (None, 620, 14, 1)        256       
_________________________________________________________________
dropout_425 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_142 (Conv2D)          (None, 420, 14, 1)        202       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_141 (Conv2D (None, 610, 14, 1)        192       
_________________________________________________________________
dropout_427 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_142 (Conv2D (None, 874, 14, 1)        266       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20982648  || Decoder Loss:  0.23635128 Validation Decoder Loss:  0.49934074
Encoder Loss:  0.19695406  || Decoder Loss:  0.22117205 Validation Decoder Loss:  0.49773532
Encoder Loss:  0.18732978  || Decoder Loss:  0.21462093 Validation Decoder Loss:  0.49827477
Encoder Loss:  0.17714626  || Decoder Loss:  0.21234518 Validation Decoder Loss:  0.4939419
Encoder Loss:  0.17471726  || Decoder Loss:  0.21001437 Validation Decoder Loss:  0.4891449
Encoder Loss:  0.1730452  || Decoder Loss:  0.207941 Validation Decoder Loss:  0.48576835
Encoder Loss:  0.17163019  || Decoder Loss:  0.20618434 Validation Decoder Loss:  0.48320717
Encoder Loss:  0.17047329  || Decoder Loss:  0.20475516 Validation Decoder Loss:  0.48216644
Encoder Loss:  0.16881324  || Decoder Loss:  0.20267212 Validation Decoder Loss:  0.48206317
Encoder Loss:  0.16780414  || Decoder Loss:  0.20142883 Validation Decoder Loss:  0.48084936
Encoder Loss:  0.16750884  || Decoder Loss:  0.20110136 Validation Decoder Loss:  0.48085582
Encoder Loss:  0.16752775  || Decoder Loss:  0.20117489 Validation Decoder Loss:  0.48186684
Encoder Loss:  0.16758531  || Decoder Loss:  0.20129374 Validation Decoder Loss:  0.4824223
Encoder Loss:  0.16604303  || Decoder Loss:  0.1993387 Validation Decoder Loss:  0.48292124
Encoder Loss:  0.16291718  || Decoder Loss:  0.19533356 Validation Decoder Loss:  0.49001682
Encoder Loss:  0.1620815  || Decoder Loss:  0.19428733 Validation Decoder Loss:  0.4888618
Encoder Loss:  0.16135392  || Decoder Loss:  0.19337983 Validation Decoder Loss:  0.4899773
Encoder Loss:  0.16029033  || Decoder Loss:  0.19203363 Validation Decoder Loss:  0.4924633
Encoder Loss:  0.15946443  || Decoder Loss:  0.19099432 Validation Decoder Loss:  0.49254283
Encoder Loss:  0.15910566  || Decoder Loss:  0.19055408 Validation Decoder Loss:  0.49333125
Encoder Loss:  0.15879765  || Decoder Loss:  0.19017993 Validation Decoder Loss:  0.4924168
Encoder Loss:  0.1583892  || Decoder Loss:  0.18967332 Validation Decoder Loss:  0.48919457
Encoder Loss:  0.15787503  || Decoder Loss:  0.18903548 Validation Decoder Loss:  0.4819892
Encoder Loss:  0.15801999  || Decoder Loss:  0.18926887 Validation Decoder Loss:  0.47199136
Encoder Loss:  0.15771404  || Decoder Loss:  0.18890634 Validation Decoder Loss:  0.47169173
Encoder Loss:  0.15663353  || Decoder Loss:  0.18751918 Validation Decoder Loss:  0.4734846
Encoder Loss:  0.15563807  || Decoder Loss:  0.18623844 Validation Decoder Loss:  0.47692692
Encoder Loss:  0.15501995  || Decoder Loss:  0.18544139 Validation Decoder Loss:  0.47979504
Encoder Loss:  0.15451095  || Decoder Loss:  0.18478677 Validation Decoder Loss:  0.48218805
Encoder Loss:  0.15448351  || Decoder Loss:  0.18475333 Validation Decoder Loss:  0.4853273
Encoder Loss:  0.15460339  || Decoder Loss:  0.18491073 Validation Decoder Loss:  0.48761714
Encoder Loss:  0.15442833  || Decoder Loss:  0.18468596 Validation Decoder Loss:  0.48704532
Encoder Loss:  0.15374076  || Decoder Loss:  0.18380012 Validation Decoder Loss:  0.48808715
Encoder Loss:  0.15342194  || Decoder Loss:  0.18338898 Validation Decoder Loss:  0.48759422
Encoder Loss:  0.15345062  || Decoder Loss:  0.18342684 Validation Decoder Loss:  0.48943824
Encoder Loss:  0.15334049  || Decoder Loss:  0.18328798 Validation Decoder Loss:  0.4938774
Encoder Loss:  0.15262453  || Decoder Loss:  0.18236318 Validation Decoder Loss:  0.4977361
Encoder Loss:  0.14990704  || Decoder Loss:  0.17885362 Validation Decoder Loss:  0.5029295
Encoder Loss:  0.14494875  || Decoder Loss:  0.17244677 Validation Decoder Loss:  0.503825
Encoder Loss:  0.14357068  || Decoder Loss:  0.17066778 Validation Decoder Loss:  0.50452954
Model: bold_synthesis_net_lr_0.000998080573718116 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50452954
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_201 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_429 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_202 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_86 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_143 (Conv2D)          (None, 700, 14, 1)        176       
_________________________________________________________________
dropout_431 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_144 (Conv2D)          (None, 420, 14, 1)        282       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_143 (Conv2D (None, 640, 14, 1)        222       
_________________________________________________________________
dropout_433 (Dropout)        (None, 640, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_144 (Conv2D (None, 874, 14, 1)        236       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14731921  || Decoder Loss:  0.24801409 Validation Decoder Loss:  0.4980221
Encoder Loss:  0.1418855  || Decoder Loss:  0.23618849 Validation Decoder Loss:  0.49710143
Encoder Loss:  0.13961206  || Decoder Loss:  0.23046173 Validation Decoder Loss:  0.49659902
Encoder Loss:  0.13821167  || Decoder Loss:  0.22697824 Validation Decoder Loss:  0.49613595
Encoder Loss:  0.13683735  || Decoder Loss:  0.22428499 Validation Decoder Loss:  0.495921
Encoder Loss:  0.1351965  || Decoder Loss:  0.22194213 Validation Decoder Loss:  0.49581787
Encoder Loss:  0.13304667  || Decoder Loss:  0.21986903 Validation Decoder Loss:  0.49575242
Encoder Loss:  0.13019425  || Decoder Loss:  0.21782781 Validation Decoder Loss:  0.49527782
Encoder Loss:  0.12657331  || Decoder Loss:  0.21590891 Validation Decoder Loss:  0.49543548
Encoder Loss:  0.121951506  || Decoder Loss:  0.21457921 Validation Decoder Loss:  0.49634412
Encoder Loss:  0.11609272  || Decoder Loss:  0.21334748 Validation Decoder Loss:  0.4988313
Encoder Loss:  0.110476606  || Decoder Loss:  0.21243945 Validation Decoder Loss:  0.50302005
Encoder Loss:  0.10619784  || Decoder Loss:  0.21253502 Validation Decoder Loss:  0.5078621
Encoder Loss:  0.10309196  || Decoder Loss:  0.2136013 Validation Decoder Loss:  0.5115345
Encoder Loss:  0.100389354  || Decoder Loss:  0.21505171 Validation Decoder Loss:  0.5143193
Encoder Loss:  0.097425506  || Decoder Loss:  0.21641487 Validation Decoder Loss:  0.51596045
Encoder Loss:  0.09411394  || Decoder Loss:  0.21703514 Validation Decoder Loss:  0.5156682
Encoder Loss:  0.09114558  || Decoder Loss:  0.21640694 Validation Decoder Loss:  0.51252896
Encoder Loss:  0.0893911  || Decoder Loss:  0.21457414 Validation Decoder Loss:  0.5084868
Encoder Loss:  0.088290446  || Decoder Loss:  0.2129792 Validation Decoder Loss:  0.50464803
Encoder Loss:  0.087384656  || Decoder Loss:  0.21139653 Validation Decoder Loss:  0.5005201
Encoder Loss:  0.08660851  || Decoder Loss:  0.2101368 Validation Decoder Loss:  0.4974011
Encoder Loss:  0.085917175  || Decoder Loss:  0.20911722 Validation Decoder Loss:  0.49463817
Encoder Loss:  0.08509463  || Decoder Loss:  0.20716809 Validation Decoder Loss:  0.4936273
Encoder Loss:  0.08434648  || Decoder Loss:  0.20526955 Validation Decoder Loss:  0.49136066
Encoder Loss:  0.08343081  || Decoder Loss:  0.20233312 Validation Decoder Loss:  0.48318306
Encoder Loss:  0.08258922  || Decoder Loss:  0.19971576 Validation Decoder Loss:  0.4814794
Encoder Loss:  0.082123525  || Decoder Loss:  0.1989543 Validation Decoder Loss:  0.47883704
Encoder Loss:  0.081731424  || Decoder Loss:  0.19833174 Validation Decoder Loss:  0.47660553
Encoder Loss:  0.08136312  || Decoder Loss:  0.19759962 Validation Decoder Loss:  0.47325268
Encoder Loss:  0.08111315  || Decoder Loss:  0.197067 Validation Decoder Loss:  0.4713007
Encoder Loss:  0.08092619  || Decoder Loss:  0.19665298 Validation Decoder Loss:  0.46968633
Encoder Loss:  0.08077109  || Decoder Loss:  0.19632114 Validation Decoder Loss:  0.46835357
Encoder Loss:  0.08063424  || Decoder Loss:  0.19604334 Validation Decoder Loss:  0.46711868
Encoder Loss:  0.08051796  || Decoder Loss:  0.19580828 Validation Decoder Loss:  0.46622384
Encoder Loss:  0.0804194  || Decoder Loss:  0.19561648 Validation Decoder Loss:  0.4655529
Encoder Loss:  0.080337904  || Decoder Loss:  0.1954763 Validation Decoder Loss:  0.46502027
Encoder Loss:  0.0802642  || Decoder Loss:  0.19534235 Validation Decoder Loss:  0.4646492
Encoder Loss:  0.08019767  || Decoder Loss:  0.19523104 Validation Decoder Loss:  0.46433708
Encoder Loss:  0.08013358  || Decoder Loss:  0.19512193 Validation Decoder Loss:  0.46398118
Model: bold_synthesis_net_lr_0.00024391611948022517 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.46398118
Model: "sequential_319"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_204 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_435 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_205 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_87 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_145 (Conv2D)          (None, 590, 14, 1)        286       
_________________________________________________________________
dropout_437 (Dropout)        (None, 590, 14, 1)        0         
_________________________________________________________________
conv2d_146 (Conv2D)          (None, 420, 14, 1)        172       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_322"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_145 (Conv2D (None, 750, 14, 1)        332       
_________________________________________________________________
dropout_439 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_146 (Conv2D (None, 874, 14, 1)        126       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17538762  || Decoder Loss:  0.23499385 Validation Decoder Loss:  0.4946841
Encoder Loss:  0.16277772  || Decoder Loss:  0.21707906 Validation Decoder Loss:  0.49538368
Encoder Loss:  0.14958124  || Decoder Loss:  0.21067241 Validation Decoder Loss:  0.50666094
Encoder Loss:  0.13581574  || Decoder Loss:  0.2132529 Validation Decoder Loss:  0.50961995
Encoder Loss:  0.13172065  || Decoder Loss:  0.21282768 Validation Decoder Loss:  0.49876907
Encoder Loss:  0.12946074  || Decoder Loss:  0.20948765 Validation Decoder Loss:  0.49217233
Encoder Loss:  0.12780927  || Decoder Loss:  0.20702095 Validation Decoder Loss:  0.48753107
Encoder Loss:  0.12644696  || Decoder Loss:  0.20504561 Validation Decoder Loss:  0.4821758
Encoder Loss:  0.12524706  || Decoder Loss:  0.20327848 Validation Decoder Loss:  0.47550514
Encoder Loss:  0.12414692  || Decoder Loss:  0.20161529 Validation Decoder Loss:  0.4704714
Encoder Loss:  0.12327312  || Decoder Loss:  0.20027643 Validation Decoder Loss:  0.46688643
Encoder Loss:  0.122631446  || Decoder Loss:  0.19930181 Validation Decoder Loss:  0.46694487
Encoder Loss:  0.12243419  || Decoder Loss:  0.19919616 Validation Decoder Loss:  0.4696463
Encoder Loss:  0.12223034  || Decoder Loss:  0.1990194 Validation Decoder Loss:  0.4763337
Encoder Loss:  0.12206603  || Decoder Loss:  0.19889653 Validation Decoder Loss:  0.48032987
Encoder Loss:  0.12186065  || Decoder Loss:  0.1986536 Validation Decoder Loss:  0.481588
Encoder Loss:  0.12145205  || Decoder Loss:  0.19798295 Validation Decoder Loss:  0.47756976
Encoder Loss:  0.12118337  || Decoder Loss:  0.19760253 Validation Decoder Loss:  0.46692383
Encoder Loss:  0.121661685  || Decoder Loss:  0.19877248 Validation Decoder Loss:  0.45649308
Encoder Loss:  0.12163129  || Decoder Loss:  0.19880885 Validation Decoder Loss:  0.4541401
Encoder Loss:  0.12136569  || Decoder Loss:  0.19831088 Validation Decoder Loss:  0.45522293
Encoder Loss:  0.12093338  || Decoder Loss:  0.19744734 Validation Decoder Loss:  0.45685396
Encoder Loss:  0.12049766  || Decoder Loss:  0.19656475 Validation Decoder Loss:  0.4589867
Encoder Loss:  0.11997305  || Decoder Loss:  0.19549052 Validation Decoder Loss:  0.46113542
Encoder Loss:  0.11940949  || Decoder Loss:  0.19432712 Validation Decoder Loss:  0.4626247
Encoder Loss:  0.11878686  || Decoder Loss:  0.19304264 Validation Decoder Loss:  0.46550748
Encoder Loss:  0.11809829  || Decoder Loss:  0.19161612 Validation Decoder Loss:  0.46908143
Encoder Loss:  0.117245145  || Decoder Loss:  0.18984754 Validation Decoder Loss:  0.47677976
Encoder Loss:  0.11587384  || Decoder Loss:  0.18699855 Validation Decoder Loss:  0.48164153
Encoder Loss:  0.11498873  || Decoder Loss:  0.18516119 Validation Decoder Loss:  0.485987
Encoder Loss:  0.114297055  || Decoder Loss:  0.18372521 Validation Decoder Loss:  0.48970014
Encoder Loss:  0.11355963  || Decoder Loss:  0.18219653 Validation Decoder Loss:  0.49464962
Encoder Loss:  0.112820506  || Decoder Loss:  0.18066096 Validation Decoder Loss:  0.49917886
Encoder Loss:  0.11207338  || Decoder Loss:  0.17910847 Validation Decoder Loss:  0.50336796
Encoder Loss:  0.11128728  || Decoder Loss:  0.17747612 Validation Decoder Loss:  0.5063493
Encoder Loss:  0.11056243  || Decoder Loss:  0.17597067 Validation Decoder Loss:  0.5105544
Encoder Loss:  0.10956615  || Decoder Loss:  0.17390063 Validation Decoder Loss:  0.5283946
Encoder Loss:  0.107109815  || Decoder Loss:  0.16878827 Validation Decoder Loss:  0.53993136
Encoder Loss:  0.10560461  || Decoder Loss:  0.16565916 Validation Decoder Loss:  0.54366565
Encoder Loss:  0.10456523  || Decoder Loss:  0.16349748 Validation Decoder Loss:  0.5441952
Model: bold_synthesis_net_lr_0.0005566364339545217 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5441952
Model: "sequential_323"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_207 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_441 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_208 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_88 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_147 (Conv2D)          (None, 440, 14, 1)        436       
_________________________________________________________________
dropout_443 (Dropout)        (None, 440, 14, 1)        0         
_________________________________________________________________
conv2d_148 (Conv2D)          (None, 420, 14, 1)        22        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_326"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_147 (Conv2D (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_445 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_148 (Conv2D (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.42706144  || Decoder Loss:  0.43614188 Validation Decoder Loss:  0.947289
Encoder Loss:  0.42184573  || Decoder Loss:  0.43239394 Validation Decoder Loss:  0.9083923
Encoder Loss:  0.41213706  || Decoder Loss:  0.42505145 Validation Decoder Loss:  0.8094517
Encoder Loss:  0.38913676  || Decoder Loss:  0.40558064 Validation Decoder Loss:  0.6780407
Encoder Loss:  0.31712916  || Decoder Loss:  0.33460838 Validation Decoder Loss:  0.45338306
Encoder Loss:  0.21740226  || Decoder Loss:  0.22968936 Validation Decoder Loss:  0.45192784
Encoder Loss:  0.19604313  || Decoder Loss:  0.20715123 Validation Decoder Loss:  0.45999774
Encoder Loss:  0.1947214  || Decoder Loss:  0.20600139 Validation Decoder Loss:  0.46124154
Encoder Loss:  0.19385175  || Decoder Loss:  0.20538498 Validation Decoder Loss:  0.46148148
Encoder Loss:  0.19296204  || Decoder Loss:  0.20476343 Validation Decoder Loss:  0.4611306
Encoder Loss:  0.19227342  || Decoder Loss:  0.20437355 Validation Decoder Loss:  0.45983326
Encoder Loss:  0.19160944  || Decoder Loss:  0.20402366 Validation Decoder Loss:  0.4584705
Encoder Loss:  0.19117272  || Decoder Loss:  0.20392358 Validation Decoder Loss:  0.45704812
Encoder Loss:  0.1912909  || Decoder Loss:  0.20442963 Validation Decoder Loss:  0.45337632
Encoder Loss:  0.19237384  || Decoder Loss:  0.20600367 Validation Decoder Loss:  0.44781315
Encoder Loss:  0.19427368  || Decoder Loss:  0.2084848 Validation Decoder Loss:  0.44236457
Encoder Loss:  0.19678026  || Decoder Loss:  0.21163124 Validation Decoder Loss:  0.43605337
Encoder Loss:  0.1995703  || Decoder Loss:  0.2150822 Validation Decoder Loss:  0.42968163
Encoder Loss:  0.20253356  || Decoder Loss:  0.21870226 Validation Decoder Loss:  0.4252601
Encoder Loss:  0.2044184  || Decoder Loss:  0.22108486 Validation Decoder Loss:  0.42309055
Encoder Loss:  0.20476158  || Decoder Loss:  0.22167966 Validation Decoder Loss:  0.42401004
Encoder Loss:  0.20251918  || Decoder Loss:  0.21930417 Validation Decoder Loss:  0.42699906
Encoder Loss:  0.19920851  || Decoder Loss:  0.21567236 Validation Decoder Loss:  0.4317207
Encoder Loss:  0.19636445  || Decoder Loss:  0.21253768 Validation Decoder Loss:  0.4364878
Encoder Loss:  0.19415373  || Decoder Loss:  0.2101067 Validation Decoder Loss:  0.44051605
Encoder Loss:  0.19217929  || Decoder Loss:  0.20793669 Validation Decoder Loss:  0.4439145
Encoder Loss:  0.19063583  || Decoder Loss:  0.20624603 Validation Decoder Loss:  0.44661483
Encoder Loss:  0.18957326  || Decoder Loss:  0.20508862 Validation Decoder Loss:  0.44947544
Encoder Loss:  0.18849866  || Decoder Loss:  0.20391606 Validation Decoder Loss:  0.45111552
Encoder Loss:  0.18756658  || Decoder Loss:  0.2029024 Validation Decoder Loss:  0.45260957
Encoder Loss:  0.18689957  || Decoder Loss:  0.20218417 Validation Decoder Loss:  0.45520616
Encoder Loss:  0.18625456  || Decoder Loss:  0.2014899 Validation Decoder Loss:  0.45729202
Encoder Loss:  0.18589705  || Decoder Loss:  0.20111623 Validation Decoder Loss:  0.45859912
Encoder Loss:  0.18555462  || Decoder Loss:  0.20075876 Validation Decoder Loss:  0.4598709
Encoder Loss:  0.1855014  || Decoder Loss:  0.200724 Validation Decoder Loss:  0.46166798
Encoder Loss:  0.18510184  || Decoder Loss:  0.20030221 Validation Decoder Loss:  0.46249074
Encoder Loss:  0.18490526  || Decoder Loss:  0.20010553 Validation Decoder Loss:  0.46364647
Encoder Loss:  0.18480535  || Decoder Loss:  0.20001496 Validation Decoder Loss:  0.46518776
Encoder Loss:  0.1847766  || Decoder Loss:  0.20000336 Validation Decoder Loss:  0.4666422
Encoder Loss:  0.18476897  || Decoder Loss:  0.20001458 Validation Decoder Loss:  0.46790016
Model: bold_synthesis_net_lr_0.0003715401269516329 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4679002
Model: "sequential_327"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_210 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_447 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_211 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_89 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_329"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_149 (Conv2D)          (None, 830, 14, 1)        46        
_________________________________________________________________
dropout_449 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_150 (Conv2D)          (None, 420, 14, 1)        412       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_149 (Conv2D (None, 740, 14, 1)        322       
_________________________________________________________________
dropout_451 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_150 (Conv2D (None, 874, 14, 1)        136       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23730285  || Decoder Loss:  0.3013822 Validation Decoder Loss:  0.52939856
Encoder Loss:  0.13402873  || Decoder Loss:  0.20552209 Validation Decoder Loss:  0.5161149
Encoder Loss:  0.12412797  || Decoder Loss:  0.21140347 Validation Decoder Loss:  0.49563384
Encoder Loss:  0.120133474  || Decoder Loss:  0.20465153 Validation Decoder Loss:  0.4773087
Encoder Loss:  0.11770022  || Decoder Loss:  0.20049563 Validation Decoder Loss:  0.47946155
Encoder Loss:  0.11620474  || Decoder Loss:  0.19787662 Validation Decoder Loss:  0.48366767
Encoder Loss:  0.11522439  || Decoder Loss:  0.19591938 Validation Decoder Loss:  0.48109967
Encoder Loss:  0.11523031  || Decoder Loss:  0.19597334 Validation Decoder Loss:  0.4720003
Encoder Loss:  0.1156251  || Decoder Loss:  0.19686447 Validation Decoder Loss:  0.47547567
Encoder Loss:  0.11600586  || Decoder Loss:  0.19774199 Validation Decoder Loss:  0.47541887
Encoder Loss:  0.11577191  || Decoder Loss:  0.19721536 Validation Decoder Loss:  0.48666564
Encoder Loss:  0.114771225  || Decoder Loss:  0.19497024 Validation Decoder Loss:  0.49417794
Encoder Loss:  0.11489038  || Decoder Loss:  0.19525208 Validation Decoder Loss:  0.5002087
Encoder Loss:  0.11508506  || Decoder Loss:  0.19569232 Validation Decoder Loss:  0.5114648
Encoder Loss:  0.11433619  || Decoder Loss:  0.1940155 Validation Decoder Loss:  0.51263684
Encoder Loss:  0.11383818  || Decoder Loss:  0.19290863 Validation Decoder Loss:  0.51911783
Encoder Loss:  0.1132203  || Decoder Loss:  0.1915244 Validation Decoder Loss:  0.52552503
Encoder Loss:  0.112594984  || Decoder Loss:  0.19013077 Validation Decoder Loss:  0.5276279
Encoder Loss:  0.11263052  || Decoder Loss:  0.19023271 Validation Decoder Loss:  0.53359735
Encoder Loss:  0.11205938  || Decoder Loss:  0.18894415 Validation Decoder Loss:  0.53349
Encoder Loss:  0.11200835  || Decoder Loss:  0.1888347 Validation Decoder Loss:  0.5354938
Encoder Loss:  0.11189973  || Decoder Loss:  0.18862244 Validation Decoder Loss:  0.5369701
Encoder Loss:  0.11172709  || Decoder Loss:  0.18823624 Validation Decoder Loss:  0.5381878
Encoder Loss:  0.11152545  || Decoder Loss:  0.18778597 Validation Decoder Loss:  0.54046595
Encoder Loss:  0.111282006  || Decoder Loss:  0.18726116 Validation Decoder Loss:  0.5406659
Encoder Loss:  0.11105497  || Decoder Loss:  0.18677725 Validation Decoder Loss:  0.5440579
Encoder Loss:  0.11070969  || Decoder Loss:  0.186012 Validation Decoder Loss:  0.5423861
Encoder Loss:  0.110560976  || Decoder Loss:  0.18568878 Validation Decoder Loss:  0.5430461
Encoder Loss:  0.11028955  || Decoder Loss:  0.18508506 Validation Decoder Loss:  0.54317564
Encoder Loss:  0.11018731  || Decoder Loss:  0.18486245 Validation Decoder Loss:  0.54175544
Encoder Loss:  0.11012218  || Decoder Loss:  0.18470977 Validation Decoder Loss:  0.5401362
Encoder Loss:  0.10999945  || Decoder Loss:  0.1844472 Validation Decoder Loss:  0.5401709
Encoder Loss:  0.10989969  || Decoder Loss:  0.18422315 Validation Decoder Loss:  0.54001236
Encoder Loss:  0.10984217  || Decoder Loss:  0.18409483 Validation Decoder Loss:  0.5395573
Encoder Loss:  0.10972377  || Decoder Loss:  0.18384747 Validation Decoder Loss:  0.5374995
Encoder Loss:  0.109481834  || Decoder Loss:  0.18331245 Validation Decoder Loss:  0.5360967
Encoder Loss:  0.109046094  || Decoder Loss:  0.18233016 Validation Decoder Loss:  0.5364048
Encoder Loss:  0.10870317  || Decoder Loss:  0.18154289 Validation Decoder Loss:  0.53510886
Encoder Loss:  0.108753674  || Decoder Loss:  0.18166824 Validation Decoder Loss:  0.5340968
Encoder Loss:  0.10865245  || Decoder Loss:  0.18144406 Validation Decoder Loss:  0.5344647
Model: bold_synthesis_net_lr_0.0005972745414337494 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5344647
Model: "sequential_331"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_213 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_453 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_214 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_90 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_333"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_151 (Conv2D)          (None, 830, 14, 1)        46        
_________________________________________________________________
dropout_455 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_152 (Conv2D)          (None, 420, 14, 1)        412       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_151 (Conv2D (None, 530, 14, 1)        112       
_________________________________________________________________
dropout_457 (Dropout)        (None, 530, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_152 (Conv2D (None, 874, 14, 1)        346       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1391457  || Decoder Loss:  0.24382718 Validation Decoder Loss:  0.49745575
Encoder Loss:  0.13197403  || Decoder Loss:  0.23026802 Validation Decoder Loss:  0.49519733
Encoder Loss:  0.12442654  || Decoder Loss:  0.22357216 Validation Decoder Loss:  0.49409673
Encoder Loss:  0.11360588  || Decoder Loss:  0.21799888 Validation Decoder Loss:  0.49521953
Encoder Loss:  0.098922804  || Decoder Loss:  0.21414521 Validation Decoder Loss:  0.5003937
Encoder Loss:  0.08466872  || Decoder Loss:  0.21266577 Validation Decoder Loss:  0.508094
Encoder Loss:  0.07988073  || Decoder Loss:  0.21361737 Validation Decoder Loss:  0.50690204
Encoder Loss:  0.07900872  || Decoder Loss:  0.21246423 Validation Decoder Loss:  0.5016461
Encoder Loss:  0.07828818  || Decoder Loss:  0.21063052 Validation Decoder Loss:  0.49745312
Encoder Loss:  0.077634946  || Decoder Loss:  0.20902781 Validation Decoder Loss:  0.49385673
Encoder Loss:  0.07700397  || Decoder Loss:  0.20732865 Validation Decoder Loss:  0.4916739
Encoder Loss:  0.076565765  || Decoder Loss:  0.20665677 Validation Decoder Loss:  0.49245018
Encoder Loss:  0.07619801  || Decoder Loss:  0.20624378 Validation Decoder Loss:  0.49217212
Encoder Loss:  0.075867586  || Decoder Loss:  0.20576377 Validation Decoder Loss:  0.49287605
Encoder Loss:  0.07566032  || Decoder Loss:  0.2057918 Validation Decoder Loss:  0.49316397
Encoder Loss:  0.07554183  || Decoder Loss:  0.20604433 Validation Decoder Loss:  0.4936885
Encoder Loss:  0.07547667  || Decoder Loss:  0.20633566 Validation Decoder Loss:  0.49390653
Encoder Loss:  0.07543924  || Decoder Loss:  0.20672803 Validation Decoder Loss:  0.49425223
Encoder Loss:  0.07542255  || Decoder Loss:  0.20712578 Validation Decoder Loss:  0.49472716
Encoder Loss:  0.075398445  || Decoder Loss:  0.20742069 Validation Decoder Loss:  0.4952341
Encoder Loss:  0.07537154  || Decoder Loss:  0.20765007 Validation Decoder Loss:  0.49503842
Encoder Loss:  0.0753163  || Decoder Loss:  0.20771465 Validation Decoder Loss:  0.4955735
Encoder Loss:  0.075196035  || Decoder Loss:  0.2073482 Validation Decoder Loss:  0.4944893
Encoder Loss:  0.07493613  || Decoder Loss:  0.20598812 Validation Decoder Loss:  0.4952198
Encoder Loss:  0.074719004  || Decoder Loss:  0.20485795 Validation Decoder Loss:  0.4948087
Encoder Loss:  0.07462699  || Decoder Loss:  0.2044779 Validation Decoder Loss:  0.49185762
Encoder Loss:  0.074516304  || Decoder Loss:  0.20389628 Validation Decoder Loss:  0.49027064
Encoder Loss:  0.0744444  || Decoder Loss:  0.20356782 Validation Decoder Loss:  0.4896089
Encoder Loss:  0.07440922  || Decoder Loss:  0.20349388 Validation Decoder Loss:  0.48995736
Encoder Loss:  0.07438496  || Decoder Loss:  0.20344067 Validation Decoder Loss:  0.489617
Encoder Loss:  0.07436893  || Decoder Loss:  0.20342179 Validation Decoder Loss:  0.48964676
Encoder Loss:  0.07436192  || Decoder Loss:  0.20345542 Validation Decoder Loss:  0.49003452
Encoder Loss:  0.07435365  || Decoder Loss:  0.20349729 Validation Decoder Loss:  0.49373412
Encoder Loss:  0.07436105  || Decoder Loss:  0.20361672 Validation Decoder Loss:  0.49369508
Encoder Loss:  0.07435589  || Decoder Loss:  0.20366333 Validation Decoder Loss:  0.49300164
Encoder Loss:  0.07436268  || Decoder Loss:  0.2037838 Validation Decoder Loss:  0.49410304
Encoder Loss:  0.07437897  || Decoder Loss:  0.203966 Validation Decoder Loss:  0.49410897
Encoder Loss:  0.074384175  || Decoder Loss:  0.20408595 Validation Decoder Loss:  0.49477875
Encoder Loss:  0.0743938  || Decoder Loss:  0.20420091 Validation Decoder Loss:  0.49559486
Encoder Loss:  0.07440366  || Decoder Loss:  0.20430638 Validation Decoder Loss:  0.4953928
Model: bold_synthesis_net_lr_0.0005669353878289487 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49539283
Model: "sequential_335"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_216 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_459 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_217 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_91 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_337"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_153 (Conv2D)          (None, 750, 14, 1)        126       
_________________________________________________________________
dropout_461 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_154 (Conv2D)          (None, 420, 14, 1)        332       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_153 (Conv2D (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_463 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_154 (Conv2D (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1940458  || Decoder Loss:  0.23923624 Validation Decoder Loss:  0.48985463
Encoder Loss:  0.17499138  || Decoder Loss:  0.21798299 Validation Decoder Loss:  0.48836794
Encoder Loss:  0.15989022  || Decoder Loss:  0.21387133 Validation Decoder Loss:  0.47664586
Encoder Loss:  0.15019998  || Decoder Loss:  0.21042465 Validation Decoder Loss:  0.4733449
Encoder Loss:  0.14809437  || Decoder Loss:  0.2078133 Validation Decoder Loss:  0.47239363
Encoder Loss:  0.14682713  || Decoder Loss:  0.20626217 Validation Decoder Loss:  0.47088233
Encoder Loss:  0.14597256  || Decoder Loss:  0.20513889 Validation Decoder Loss:  0.46801305
Encoder Loss:  0.14514697  || Decoder Loss:  0.20398358 Validation Decoder Loss:  0.46434072
Encoder Loss:  0.14435261  || Decoder Loss:  0.2028999 Validation Decoder Loss:  0.46132043
Encoder Loss:  0.14402373  || Decoder Loss:  0.20261697 Validation Decoder Loss:  0.45869935
Encoder Loss:  0.1439848  || Decoder Loss:  0.20281881 Validation Decoder Loss:  0.45567134
Encoder Loss:  0.14395064  || Decoder Loss:  0.20297474 Validation Decoder Loss:  0.4538149
Encoder Loss:  0.14391524  || Decoder Loss:  0.20306532 Validation Decoder Loss:  0.45189354
Encoder Loss:  0.14398022  || Decoder Loss:  0.20327708 Validation Decoder Loss:  0.4498019
Encoder Loss:  0.14408593  || Decoder Loss:  0.20354481 Validation Decoder Loss:  0.4479891
Encoder Loss:  0.14439489  || Decoder Loss:  0.20412143 Validation Decoder Loss:  0.44552296
Encoder Loss:  0.14482918  || Decoder Loss:  0.20489256 Validation Decoder Loss:  0.44384503
Encoder Loss:  0.14516053  || Decoder Loss:  0.20548314 Validation Decoder Loss:  0.44293925
Encoder Loss:  0.14543281  || Decoder Loss:  0.20595558 Validation Decoder Loss:  0.4423635
Encoder Loss:  0.14560388  || Decoder Loss:  0.20627014 Validation Decoder Loss:  0.4420443
Encoder Loss:  0.14579776  || Decoder Loss:  0.20661895 Validation Decoder Loss:  0.4417621
Encoder Loss:  0.14601472  || Decoder Loss:  0.20700097 Validation Decoder Loss:  0.4425214
Encoder Loss:  0.1451679  || Decoder Loss:  0.20562457 Validation Decoder Loss:  0.44499537
Encoder Loss:  0.14394975  || Decoder Loss:  0.20362993 Validation Decoder Loss:  0.44211057
Encoder Loss:  0.14412123  || Decoder Loss:  0.20392084 Validation Decoder Loss:  0.44047192
Encoder Loss:  0.1444229  || Decoder Loss:  0.2044216 Validation Decoder Loss:  0.43948188
Encoder Loss:  0.14475568  || Decoder Loss:  0.20497556 Validation Decoder Loss:  0.4391729
Encoder Loss:  0.14499055  || Decoder Loss:  0.20536222 Validation Decoder Loss:  0.4392726
Encoder Loss:  0.14523691  || Decoder Loss:  0.20577228 Validation Decoder Loss:  0.44003323
Encoder Loss:  0.14550386  || Decoder Loss:  0.20621373 Validation Decoder Loss:  0.4407138
Encoder Loss:  0.14573295  || Decoder Loss:  0.20659591 Validation Decoder Loss:  0.44181457
Encoder Loss:  0.14585839  || Decoder Loss:  0.20680432 Validation Decoder Loss:  0.4431573
Encoder Loss:  0.14609037  || Decoder Loss:  0.20718955 Validation Decoder Loss:  0.44494385
Encoder Loss:  0.14653039  || Decoder Loss:  0.20792194 Validation Decoder Loss:  0.44802096
Encoder Loss:  0.14670542  || Decoder Loss:  0.20821059 Validation Decoder Loss:  0.45721602
Encoder Loss:  0.1465927  || Decoder Loss:  0.20803194 Validation Decoder Loss:  0.4758643
Encoder Loss:  0.14537175  || Decoder Loss:  0.2060307 Validation Decoder Loss:  0.5355544
Encoder Loss:  0.14321123  || Decoder Loss:  0.20248826 Validation Decoder Loss:  0.54162043
Encoder Loss:  0.14017724  || Decoder Loss:  0.19750914 Validation Decoder Loss:  0.5593232
Encoder Loss:  0.13854283  || Decoder Loss:  0.19482999 Validation Decoder Loss:  0.55560786
Model: bold_synthesis_net_lr_0.0009837088433490551 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.55560786
Model: "sequential_339"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_219 (Conv3D (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_465 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_220 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_92 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_155 (Conv2D)          (None, 740, 14, 1)        136       
_________________________________________________________________
dropout_467 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_156 (Conv2D)          (None, 420, 14, 1)        322       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_155 (Conv2D (None, 520, 14, 1)        102       
_________________________________________________________________
dropout_469 (Dropout)        (None, 520, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_156 (Conv2D (None, 874, 14, 1)        356       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2840245  || Decoder Loss:  0.33922493 Validation Decoder Loss:  0.53878814
Encoder Loss:  0.24739903  || Decoder Loss:  0.2968439 Validation Decoder Loss:  0.4781594
Encoder Loss:  0.21864958  || Decoder Loss:  0.26220265 Validation Decoder Loss:  0.45767537
Encoder Loss:  0.19873072  || Decoder Loss:  0.23844482 Validation Decoder Loss:  0.45976964
Encoder Loss:  0.18623352  || Decoder Loss:  0.22517437 Validation Decoder Loss:  0.46700066
Encoder Loss:  0.17917663  || Decoder Loss:  0.21939299 Validation Decoder Loss:  0.4729599
Encoder Loss:  0.17524871  || Decoder Loss:  0.21759838 Validation Decoder Loss:  0.4726202
Encoder Loss:  0.17165312  || Decoder Loss:  0.21665704 Validation Decoder Loss:  0.47136426
Encoder Loss:  0.16801037  || Decoder Loss:  0.21615203 Validation Decoder Loss:  0.46923554
Encoder Loss:  0.16451563  || Decoder Loss:  0.21546926 Validation Decoder Loss:  0.46531782
Encoder Loss:  0.16182114  || Decoder Loss:  0.21482213 Validation Decoder Loss:  0.46015266
Encoder Loss:  0.15945637  || Decoder Loss:  0.2143155 Validation Decoder Loss:  0.4551999
Encoder Loss:  0.15708394  || Decoder Loss:  0.21367471 Validation Decoder Loss:  0.45215312
Encoder Loss:  0.15510374  || Decoder Loss:  0.21264198 Validation Decoder Loss:  0.45110705
Encoder Loss:  0.15409096  || Decoder Loss:  0.21151996 Validation Decoder Loss:  0.45072877
Encoder Loss:  0.15322326  || Decoder Loss:  0.21034576 Validation Decoder Loss:  0.4502493
Encoder Loss:  0.15246208  || Decoder Loss:  0.20932786 Validation Decoder Loss:  0.4494672
Encoder Loss:  0.15181656  || Decoder Loss:  0.20848545 Validation Decoder Loss:  0.4484605
Encoder Loss:  0.15121694  || Decoder Loss:  0.20769346 Validation Decoder Loss:  0.447899
Encoder Loss:  0.15066856  || Decoder Loss:  0.20695138 Validation Decoder Loss:  0.45847988
Encoder Loss:  0.14823726  || Decoder Loss:  0.20318672 Validation Decoder Loss:  0.46098801
Encoder Loss:  0.14676198  || Decoder Loss:  0.20091167 Validation Decoder Loss:  0.46078026
Encoder Loss:  0.14611813  || Decoder Loss:  0.1999392 Validation Decoder Loss:  0.46014187
Encoder Loss:  0.14575848  || Decoder Loss:  0.19940639 Validation Decoder Loss:  0.45918393
Encoder Loss:  0.14549457  || Decoder Loss:  0.19902161 Validation Decoder Loss:  0.45835546
Encoder Loss:  0.1452691  || Decoder Loss:  0.19869286 Validation Decoder Loss:  0.45782372
Encoder Loss:  0.1448617  || Decoder Loss:  0.19807655 Validation Decoder Loss:  0.462509
Encoder Loss:  0.1440957  || Decoder Loss:  0.19689152 Validation Decoder Loss:  0.46109638
Encoder Loss:  0.14367232  || Decoder Loss:  0.19624564 Validation Decoder Loss:  0.46009845
Encoder Loss:  0.14343658  || Decoder Loss:  0.19589552 Validation Decoder Loss:  0.45994174
Encoder Loss:  0.14327037  || Decoder Loss:  0.1956525 Validation Decoder Loss:  0.45883918
Encoder Loss:  0.1431363  || Decoder Loss:  0.19545959 Validation Decoder Loss:  0.45722535
Encoder Loss:  0.14298856  || Decoder Loss:  0.19524463 Validation Decoder Loss:  0.45828307
Encoder Loss:  0.14259693  || Decoder Loss:  0.19464456 Validation Decoder Loss:  0.4619654
Encoder Loss:  0.142281  || Decoder Loss:  0.19416305 Validation Decoder Loss:  0.4632541
Encoder Loss:  0.14200267  || Decoder Loss:  0.19374056 Validation Decoder Loss:  0.46513298
Encoder Loss:  0.14153028  || Decoder Loss:  0.1930128 Validation Decoder Loss:  0.46535796
Encoder Loss:  0.14124927  || Decoder Loss:  0.19258663 Validation Decoder Loss:  0.46484596
Encoder Loss:  0.1411118  || Decoder Loss:  0.19238679 Validation Decoder Loss:  0.46426463
Encoder Loss:  0.14105491  || Decoder Loss:  0.1923145 Validation Decoder Loss:  0.4643079
Model: bold_synthesis_net_lr_0.00043590434637148513 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4643079
Model: "sequential_343"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_222 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_471 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_223 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_93 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_157 (Conv2D)          (None, 630, 14, 1)        246       
_________________________________________________________________
dropout_473 (Dropout)        (None, 630, 14, 1)        0         
_________________________________________________________________
conv2d_158 (Conv2D)          (None, 420, 14, 1)        212       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_157 (Conv2D (None, 560, 14, 1)        142       
_________________________________________________________________
dropout_475 (Dropout)        (None, 560, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_158 (Conv2D (None, 874, 14, 1)        316       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14594024  || Decoder Loss:  0.27925763 Validation Decoder Loss:  0.49884617
Encoder Loss:  0.14421578  || Decoder Loss:  0.2755656 Validation Decoder Loss:  0.49537674
Encoder Loss:  0.14254282  || Decoder Loss:  0.27205247 Validation Decoder Loss:  0.4922206
Encoder Loss:  0.14091215  || Decoder Loss:  0.26865426 Validation Decoder Loss:  0.4893045
Encoder Loss:  0.13932294  || Decoder Loss:  0.26537415 Validation Decoder Loss:  0.4866916
Encoder Loss:  0.13777566  || Decoder Loss:  0.26222605 Validation Decoder Loss:  0.48453483
Encoder Loss:  0.13626829  || Decoder Loss:  0.2592023 Validation Decoder Loss:  0.48283184
Encoder Loss:  0.1348038  || Decoder Loss:  0.2563132 Validation Decoder Loss:  0.48164558
Encoder Loss:  0.13341095  || Decoder Loss:  0.25358877 Validation Decoder Loss:  0.48092884
Encoder Loss:  0.1321287  || Decoder Loss:  0.25107735 Validation Decoder Loss:  0.4804843
Encoder Loss:  0.13102251  || Decoder Loss:  0.24883755 Validation Decoder Loss:  0.4802144
Encoder Loss:  0.1300915  || Decoder Loss:  0.24688645 Validation Decoder Loss:  0.48008057
Encoder Loss:  0.12925872  || Decoder Loss:  0.2451458 Validation Decoder Loss:  0.48005483
Encoder Loss:  0.12849905  || Decoder Loss:  0.2435663 Validation Decoder Loss:  0.48014298
Encoder Loss:  0.12777504  || Decoder Loss:  0.24210472 Validation Decoder Loss:  0.48028123
Encoder Loss:  0.12706488  || Decoder Loss:  0.24071193 Validation Decoder Loss:  0.48045242
Encoder Loss:  0.12638055  || Decoder Loss:  0.2394 Validation Decoder Loss:  0.48065728
Encoder Loss:  0.12570944  || Decoder Loss:  0.23816335 Validation Decoder Loss:  0.48087987
Encoder Loss:  0.12503828  || Decoder Loss:  0.2369978 Validation Decoder Loss:  0.48113814
Encoder Loss:  0.12435524  || Decoder Loss:  0.23588064 Validation Decoder Loss:  0.48141426
Encoder Loss:  0.12366487  || Decoder Loss:  0.23480558 Validation Decoder Loss:  0.48171148
Encoder Loss:  0.122967444  || Decoder Loss:  0.23378852 Validation Decoder Loss:  0.482047
Encoder Loss:  0.12227191  || Decoder Loss:  0.23283052 Validation Decoder Loss:  0.48241326
Encoder Loss:  0.12156501  || Decoder Loss:  0.23192096 Validation Decoder Loss:  0.48280084
Encoder Loss:  0.12088289  || Decoder Loss:  0.2310876 Validation Decoder Loss:  0.48317832
Encoder Loss:  0.120217815  || Decoder Loss:  0.23033433 Validation Decoder Loss:  0.4835465
Encoder Loss:  0.11957637  || Decoder Loss:  0.22964711 Validation Decoder Loss:  0.48390386
Encoder Loss:  0.11894299  || Decoder Loss:  0.2290248 Validation Decoder Loss:  0.4842588
Encoder Loss:  0.11830886  || Decoder Loss:  0.22845483 Validation Decoder Loss:  0.4846182
Encoder Loss:  0.11769968  || Decoder Loss:  0.22796762 Validation Decoder Loss:  0.48494655
Encoder Loss:  0.11709638  || Decoder Loss:  0.22755969 Validation Decoder Loss:  0.48524886
Encoder Loss:  0.11650541  || Decoder Loss:  0.22721668 Validation Decoder Loss:  0.48548126
Encoder Loss:  0.11591653  || Decoder Loss:  0.22693673 Validation Decoder Loss:  0.48567006
Encoder Loss:  0.115311906  || Decoder Loss:  0.22669935 Validation Decoder Loss:  0.4858176
Encoder Loss:  0.11466777  || Decoder Loss:  0.22647426 Validation Decoder Loss:  0.48598516
Encoder Loss:  0.11398846  || Decoder Loss:  0.22623818 Validation Decoder Loss:  0.48615882
Encoder Loss:  0.11328912  || Decoder Loss:  0.22601943 Validation Decoder Loss:  0.4863067
Encoder Loss:  0.11255916  || Decoder Loss:  0.22582111 Validation Decoder Loss:  0.48644614
Encoder Loss:  0.1117998  || Decoder Loss:  0.22563407 Validation Decoder Loss:  0.48657322
Encoder Loss:  0.111015335  || Decoder Loss:  0.2254589 Validation Decoder Loss:  0.4866853
Model: bold_synthesis_net_lr_0.00028409842319277796 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.4866853
Model: "sequential_347"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_225 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_477 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_226 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_94 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_159 (Conv2D)          (None, 750, 14, 1)        126       
_________________________________________________________________
dropout_479 (Dropout)        (None, 750, 14, 1)        0         
_________________________________________________________________
conv2d_160 (Conv2D)          (None, 420, 14, 1)        332       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_350"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_159 (Conv2D (None, 450, 14, 1)        32        
_________________________________________________________________
dropout_481 (Dropout)        (None, 450, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_160 (Conv2D (None, 874, 14, 1)        426       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18492441  || Decoder Loss:  0.2314151 Validation Decoder Loss:  0.5026572
Encoder Loss:  0.16658461  || Decoder Loss:  0.21516997 Validation Decoder Loss:  0.50384825
Encoder Loss:  0.15065098  || Decoder Loss:  0.21131775 Validation Decoder Loss:  0.51404047
Encoder Loss:  0.14964527  || Decoder Loss:  0.21348779 Validation Decoder Loss:  0.51156825
Encoder Loss:  0.14897287  || Decoder Loss:  0.21321867 Validation Decoder Loss:  0.5101087
Encoder Loss:  0.14648826  || Decoder Loss:  0.2096665 Validation Decoder Loss:  0.49904943
Encoder Loss:  0.14457057  || Decoder Loss:  0.20692164 Validation Decoder Loss:  0.49648234
Encoder Loss:  0.14365545  || Decoder Loss:  0.20569082 Validation Decoder Loss:  0.4950617
Encoder Loss:  0.14317183  || Decoder Loss:  0.20500362 Validation Decoder Loss:  0.4947488
Encoder Loss:  0.14292233  || Decoder Loss:  0.2046662 Validation Decoder Loss:  0.49554417
Encoder Loss:  0.14268254  || Decoder Loss:  0.20433588 Validation Decoder Loss:  0.49709088
Encoder Loss:  0.14242306  || Decoder Loss:  0.20396554 Validation Decoder Loss:  0.49778402
Encoder Loss:  0.14194275  || Decoder Loss:  0.20321965 Validation Decoder Loss:  0.49747804
Encoder Loss:  0.14138949  || Decoder Loss:  0.20234506 Validation Decoder Loss:  0.49643064
Encoder Loss:  0.14090142  || Decoder Loss:  0.20157929 Validation Decoder Loss:  0.49453053
Encoder Loss:  0.14035037  || Decoder Loss:  0.20069985 Validation Decoder Loss:  0.4914649
Encoder Loss:  0.13934848  || Decoder Loss:  0.19906294 Validation Decoder Loss:  0.49278337
Encoder Loss:  0.1375401  || Decoder Loss:  0.19607054 Validation Decoder Loss:  0.513026
Encoder Loss:  0.13560593  || Decoder Loss:  0.19286998 Validation Decoder Loss:  0.524592
Encoder Loss:  0.13458036  || Decoder Loss:  0.19117498 Validation Decoder Loss:  0.5242399
Encoder Loss:  0.13415672  || Decoder Loss:  0.1904821 Validation Decoder Loss:  0.52398574
Encoder Loss:  0.13388671  || Decoder Loss:  0.1900375 Validation Decoder Loss:  0.52474695
Encoder Loss:  0.13358821  || Decoder Loss:  0.1895437 Validation Decoder Loss:  0.5264629
Encoder Loss:  0.13330309  || Decoder Loss:  0.18907072 Validation Decoder Loss:  0.52828825
Encoder Loss:  0.13300386  || Decoder Loss:  0.18857643 Validation Decoder Loss:  0.5319339
Encoder Loss:  0.13250276  || Decoder Loss:  0.18774381 Validation Decoder Loss:  0.537793
Encoder Loss:  0.13180922  || Decoder Loss:  0.18659028 Validation Decoder Loss:  0.54535604
Encoder Loss:  0.13130721  || Decoder Loss:  0.18575716 Validation Decoder Loss:  0.54939944
Encoder Loss:  0.13116677  || Decoder Loss:  0.18553057 Validation Decoder Loss:  0.5522519
Encoder Loss:  0.13100578  || Decoder Loss:  0.18527815 Validation Decoder Loss:  0.55458325
Encoder Loss:  0.13078925  || Decoder Loss:  0.1849354 Validation Decoder Loss:  0.5562428
Encoder Loss:  0.13053046  || Decoder Loss:  0.1845217 Validation Decoder Loss:  0.55681366
Encoder Loss:  0.13022713  || Decoder Loss:  0.18403079 Validation Decoder Loss:  0.5559348
Encoder Loss:  0.1298749  || Decoder Loss:  0.18344876 Validation Decoder Loss:  0.555299
Encoder Loss:  0.12929021  || Decoder Loss:  0.18247965 Validation Decoder Loss:  0.5550757
Encoder Loss:  0.12800409  || Decoder Loss:  0.18033358 Validation Decoder Loss:  0.55856824
Encoder Loss:  0.12711214  || Decoder Loss:  0.17884664 Validation Decoder Loss:  0.5599607
Encoder Loss:  0.12672237  || Decoder Loss:  0.17820108 Validation Decoder Loss:  0.55955255
Encoder Loss:  0.12647006  || Decoder Loss:  0.17778546 Validation Decoder Loss:  0.5594799
Encoder Loss:  0.12630019  || Decoder Loss:  0.17750968 Validation Decoder Loss:  0.55868226
Model: bold_synthesis_net_lr_0.0007758237129952028 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.55868226
Model: "sequential_351"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_228 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_483 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_229 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_95 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_161 (Conv2D)          (None, 740, 14, 1)        136       
_________________________________________________________________
dropout_485 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_162 (Conv2D)          (None, 420, 14, 1)        322       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_354"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_161 (Conv2D (None, 480, 14, 1)        62        
_________________________________________________________________
dropout_487 (Dropout)        (None, 480, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_162 (Conv2D (None, 874, 14, 1)        396       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29233876  || Decoder Loss:  0.4022827 Validation Decoder Loss:  0.7262594
Encoder Loss:  0.2727065  || Decoder Loss:  0.3890487 Validation Decoder Loss:  0.67056155
Encoder Loss:  0.25071144  || Decoder Loss:  0.37009454 Validation Decoder Loss:  0.613667
Encoder Loss:  0.2273256  || Decoder Loss:  0.3442919 Validation Decoder Loss:  0.55692667
Encoder Loss:  0.20390321  || Decoder Loss:  0.3129328 Validation Decoder Loss:  0.5021518
Encoder Loss:  0.1847231  || Decoder Loss:  0.28362507 Validation Decoder Loss:  0.46448764
Encoder Loss:  0.16855699  || Decoder Loss:  0.25899735 Validation Decoder Loss:  0.45022854
Encoder Loss:  0.15680124  || Decoder Loss:  0.24002282 Validation Decoder Loss:  0.44858631
Encoder Loss:  0.14637639  || Decoder Loss:  0.22499126 Validation Decoder Loss:  0.45617855
Encoder Loss:  0.14007467  || Decoder Loss:  0.21698338 Validation Decoder Loss:  0.46418613
Encoder Loss:  0.13598132  || Decoder Loss:  0.21281941 Validation Decoder Loss:  0.4714031
Encoder Loss:  0.13334873  || Decoder Loss:  0.21064436 Validation Decoder Loss:  0.4765028
Encoder Loss:  0.13191546  || Decoder Loss:  0.2101349 Validation Decoder Loss:  0.4796279
Encoder Loss:  0.13056692  || Decoder Loss:  0.20991692 Validation Decoder Loss:  0.48276642
Encoder Loss:  0.12920673  || Decoder Loss:  0.2099729 Validation Decoder Loss:  0.48599118
Encoder Loss:  0.12777843  || Decoder Loss:  0.21028668 Validation Decoder Loss:  0.48949188
Encoder Loss:  0.12627643  || Decoder Loss:  0.21083692 Validation Decoder Loss:  0.49317348
Encoder Loss:  0.12465869  || Decoder Loss:  0.21145894 Validation Decoder Loss:  0.49656025
Encoder Loss:  0.12267577  || Decoder Loss:  0.21120302 Validation Decoder Loss:  0.4984702
Encoder Loss:  0.12042999  || Decoder Loss:  0.2107073 Validation Decoder Loss:  0.49843106
Encoder Loss:  0.11798853  || Decoder Loss:  0.21043044 Validation Decoder Loss:  0.49806046
Encoder Loss:  0.115394056  || Decoder Loss:  0.2103268 Validation Decoder Loss:  0.4988958
Encoder Loss:  0.112626195  || Decoder Loss:  0.21019605 Validation Decoder Loss:  0.5008142
Encoder Loss:  0.109740466  || Decoder Loss:  0.21002491 Validation Decoder Loss:  0.50255144
Encoder Loss:  0.10690214  || Decoder Loss:  0.20981607 Validation Decoder Loss:  0.50366354
Encoder Loss:  0.104378685  || Decoder Loss:  0.21003646 Validation Decoder Loss:  0.5055034
Encoder Loss:  0.102237575  || Decoder Loss:  0.21084954 Validation Decoder Loss:  0.5076879
Encoder Loss:  0.10050381  || Decoder Loss:  0.21194649 Validation Decoder Loss:  0.50981504
Encoder Loss:  0.09904878  || Decoder Loss:  0.21314834 Validation Decoder Loss:  0.5127229
Encoder Loss:  0.097848535  || Decoder Loss:  0.21458095 Validation Decoder Loss:  0.51544607
Encoder Loss:  0.096860886  || Decoder Loss:  0.21596162 Validation Decoder Loss:  0.5182226
Encoder Loss:  0.0960616  || Decoder Loss:  0.21725227 Validation Decoder Loss:  0.5205558
Encoder Loss:  0.095382966  || Decoder Loss:  0.21828707 Validation Decoder Loss:  0.52238566
Encoder Loss:  0.094841585  || Decoder Loss:  0.21915609 Validation Decoder Loss:  0.5235058
Encoder Loss:  0.09439598  || Decoder Loss:  0.21977478 Validation Decoder Loss:  0.5240216
Encoder Loss:  0.09396873  || Decoder Loss:  0.22011575 Validation Decoder Loss:  0.5240599
Encoder Loss:  0.09353383  || Decoder Loss:  0.22033653 Validation Decoder Loss:  0.5244129
Encoder Loss:  0.0931317  || Decoder Loss:  0.22052671 Validation Decoder Loss:  0.5244975
Encoder Loss:  0.09273386  || Decoder Loss:  0.22044617 Validation Decoder Loss:  0.5251105
Encoder Loss:  0.092320755  || Decoder Loss:  0.22016172 Validation Decoder Loss:  0.52587295
Model: bold_synthesis_net_lr_6.969075431982006e-05 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.52587295
Model: "sequential_355"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_231 (Conv3D (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_489 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_232 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_96 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_357"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_163 (Conv2D)          (None, 470, 14, 1)        406       
_________________________________________________________________
dropout_491 (Dropout)        (None, 470, 14, 1)        0         
_________________________________________________________________
conv2d_164 (Conv2D)          (None, 420, 14, 1)        52        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_163 (Conv2D (None, 540, 14, 1)        122       
_________________________________________________________________
dropout_493 (Dropout)        (None, 540, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_164 (Conv2D (None, 874, 14, 1)        336       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32725626  || Decoder Loss:  0.3527338 Validation Decoder Loss:  0.598572
Encoder Loss:  0.31565127  || Decoder Loss:  0.34083757 Validation Decoder Loss:  0.57405967
Encoder Loss:  0.30371398  || Decoder Loss:  0.32844532 Validation Decoder Loss:  0.54926515
Encoder Loss:  0.29194677  || Decoder Loss:  0.3160032 Validation Decoder Loss:  0.52784103
Encoder Loss:  0.28106436  || Decoder Loss:  0.3043646 Validation Decoder Loss:  0.5089876
Encoder Loss:  0.2705437  || Decoder Loss:  0.2931115 Validation Decoder Loss:  0.4934416
Encoder Loss:  0.2605505  || Decoder Loss:  0.28247184 Validation Decoder Loss:  0.47992286
Encoder Loss:  0.25147513  || Decoder Loss:  0.2728751 Validation Decoder Loss:  0.47055623
Encoder Loss:  0.24366832  || Decoder Loss:  0.26459175 Validation Decoder Loss:  0.46461704
Encoder Loss:  0.2372345  || Decoder Loss:  0.25781557 Validation Decoder Loss:  0.46092698
Encoder Loss:  0.23136778  || Decoder Loss:  0.25171122 Validation Decoder Loss:  0.4585912
Encoder Loss:  0.22579987  || Decoder Loss:  0.2459765 Validation Decoder Loss:  0.4575371
Encoder Loss:  0.22064893  || Decoder Loss:  0.24075241 Validation Decoder Loss:  0.45868284
Encoder Loss:  0.21613996  || Decoder Loss:  0.23626828 Validation Decoder Loss:  0.46037528
Encoder Loss:  0.2125973  || Decoder Loss:  0.23279986 Validation Decoder Loss:  0.46199262
Encoder Loss:  0.20988607  || Decoder Loss:  0.23022585 Validation Decoder Loss:  0.463601
Encoder Loss:  0.20767704  || Decoder Loss:  0.22822233 Validation Decoder Loss:  0.46527547
Encoder Loss:  0.20582402  || Decoder Loss:  0.22662644 Validation Decoder Loss:  0.46711972
Encoder Loss:  0.20422092  || Decoder Loss:  0.22531562 Validation Decoder Loss:  0.4688695
Encoder Loss:  0.20291725  || Decoder Loss:  0.22431426 Validation Decoder Loss:  0.47033054
Encoder Loss:  0.20191717  || Decoder Loss:  0.22361927 Validation Decoder Loss:  0.47137082
Encoder Loss:  0.20120707  || Decoder Loss:  0.22322126 Validation Decoder Loss:  0.47196016
Encoder Loss:  0.20069523  || Decoder Loss:  0.22304115 Validation Decoder Loss:  0.47221565
Encoder Loss:  0.20027292  || Decoder Loss:  0.22296762 Validation Decoder Loss:  0.4723268
Encoder Loss:  0.1998874  || Decoder Loss:  0.22294119 Validation Decoder Loss:  0.47236815
Encoder Loss:  0.19950937  || Decoder Loss:  0.22292697 Validation Decoder Loss:  0.47238037
Encoder Loss:  0.19912775  || Decoder Loss:  0.22290638 Validation Decoder Loss:  0.47233418
Encoder Loss:  0.1987272  || Decoder Loss:  0.22286269 Validation Decoder Loss:  0.47225803
Encoder Loss:  0.19830975  || Decoder Loss:  0.22280562 Validation Decoder Loss:  0.4721791
Encoder Loss:  0.19790071  || Decoder Loss:  0.22275726 Validation Decoder Loss:  0.4720612
Encoder Loss:  0.19749191  || Decoder Loss:  0.2226996 Validation Decoder Loss:  0.4718579
Encoder Loss:  0.19700603  || Decoder Loss:  0.22253916 Validation Decoder Loss:  0.4710037
Encoder Loss:  0.19632772  || Decoder Loss:  0.22213213 Validation Decoder Loss:  0.47044498
Encoder Loss:  0.1958648  || Decoder Loss:  0.22195587 Validation Decoder Loss:  0.4697535
Encoder Loss:  0.19543488  || Decoder Loss:  0.22178774 Validation Decoder Loss:  0.46883968
Encoder Loss:  0.1949881  || Decoder Loss:  0.22157478 Validation Decoder Loss:  0.46775487
Encoder Loss:  0.19458443  || Decoder Loss:  0.22138242 Validation Decoder Loss:  0.46676093
Encoder Loss:  0.19418801  || Decoder Loss:  0.22116943 Validation Decoder Loss:  0.46592233
Encoder Loss:  0.19385159  || Decoder Loss:  0.22099979 Validation Decoder Loss:  0.46534362
Encoder Loss:  0.19348733  || Decoder Loss:  0.22075792 Validation Decoder Loss:  0.46462986
Model: bold_synthesis_net_lr_0.0007937327816669019 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.46462986
Model: "sequential_359"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_234 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_495 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_235 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_97 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_361"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_165 (Conv2D)          (None, 530, 14, 1)        346       
_________________________________________________________________
dropout_497 (Dropout)        (None, 530, 14, 1)        0         
_________________________________________________________________
conv2d_166 (Conv2D)          (None, 420, 14, 1)        112       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_165 (Conv2D (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_499 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_166 (Conv2D (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14916568  || Decoder Loss:  0.24079907 Validation Decoder Loss:  0.49981344
Encoder Loss:  0.14143707  || Decoder Loss:  0.22716658 Validation Decoder Loss:  0.49978873
Encoder Loss:  0.13527954  || Decoder Loss:  0.2208165 Validation Decoder Loss:  0.5009066
Encoder Loss:  0.1258942  || Decoder Loss:  0.21553409 Validation Decoder Loss:  0.5043351
Encoder Loss:  0.112697504  || Decoder Loss:  0.21233861 Validation Decoder Loss:  0.50999534
Encoder Loss:  0.102109  || Decoder Loss:  0.21344326 Validation Decoder Loss:  0.5129351
Encoder Loss:  0.09496972  || Decoder Loss:  0.21395096 Validation Decoder Loss:  0.508567
Encoder Loss:  0.09273301  || Decoder Loss:  0.21186583 Validation Decoder Loss:  0.5027987
Encoder Loss:  0.09194959  || Decoder Loss:  0.2104552 Validation Decoder Loss:  0.49910596
Encoder Loss:  0.09139212  || Decoder Loss:  0.20962824 Validation Decoder Loss:  0.49736348
Encoder Loss:  0.09094218  || Decoder Loss:  0.20903762 Validation Decoder Loss:  0.49592933
Encoder Loss:  0.09055773  || Decoder Loss:  0.20852268 Validation Decoder Loss:  0.4946814
Encoder Loss:  0.09022072  || Decoder Loss:  0.20803106 Validation Decoder Loss:  0.49285543
Encoder Loss:  0.08989057  || Decoder Loss:  0.20746057 Validation Decoder Loss:  0.4931196
Encoder Loss:  0.08931707  || Decoder Loss:  0.20573561 Validation Decoder Loss:  0.49077457
Encoder Loss:  0.08898149  || Decoder Loss:  0.20497306 Validation Decoder Loss:  0.48930368
Encoder Loss:  0.08842204  || Decoder Loss:  0.20316719 Validation Decoder Loss:  0.48087314
Encoder Loss:  0.08761461  || Decoder Loss:  0.20022087 Validation Decoder Loss:  0.4813033
Encoder Loss:  0.08732189  || Decoder Loss:  0.19943252 Validation Decoder Loss:  0.4825687
Encoder Loss:  0.0870031  || Decoder Loss:  0.19845825 Validation Decoder Loss:  0.48452008
Encoder Loss:  0.08671387  || Decoder Loss:  0.19755296 Validation Decoder Loss:  0.48258957
Encoder Loss:  0.086455494  || Decoder Loss:  0.19675028 Validation Decoder Loss:  0.4819796
Encoder Loss:  0.08629896  || Decoder Loss:  0.1963547 Validation Decoder Loss:  0.48137587
Encoder Loss:  0.086165495  || Decoder Loss:  0.19604039 Validation Decoder Loss:  0.48137942
Encoder Loss:  0.08606917  || Decoder Loss:  0.19584905 Validation Decoder Loss:  0.4813621
Encoder Loss:  0.08598473  || Decoder Loss:  0.1957025 Validation Decoder Loss:  0.48118806
Encoder Loss:  0.08590936  || Decoder Loss:  0.19556908 Validation Decoder Loss:  0.48114493
Encoder Loss:  0.08584689  || Decoder Loss:  0.19548775 Validation Decoder Loss:  0.48116368
Encoder Loss:  0.08577152  || Decoder Loss:  0.19533871 Validation Decoder Loss:  0.48127759
Encoder Loss:  0.085715525  || Decoder Loss:  0.19525641 Validation Decoder Loss:  0.48140937
Encoder Loss:  0.085669495  || Decoder Loss:  0.1952028 Validation Decoder Loss:  0.48129097
Encoder Loss:  0.08563616  || Decoder Loss:  0.19519784 Validation Decoder Loss:  0.48200643
Encoder Loss:  0.085639834  || Decoder Loss:  0.1953395 Validation Decoder Loss:  0.48284194
Encoder Loss:  0.085660085  || Decoder Loss:  0.1955471 Validation Decoder Loss:  0.48395592
Encoder Loss:  0.08570275  || Decoder Loss:  0.19583827 Validation Decoder Loss:  0.4849896
Encoder Loss:  0.085757464  || Decoder Loss:  0.1961691 Validation Decoder Loss:  0.48595902
Encoder Loss:  0.085834086  || Decoder Loss:  0.19659795 Validation Decoder Loss:  0.48683304
Encoder Loss:  0.085924685  || Decoder Loss:  0.19707961 Validation Decoder Loss:  0.48791546
Encoder Loss:  0.086033605  || Decoder Loss:  0.19763726 Validation Decoder Loss:  0.4893112
Encoder Loss:  0.086158074  || Decoder Loss:  0.19825912 Validation Decoder Loss:  0.49112195
Model: bold_synthesis_net_lr_0.0008469530487299696 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49112195
Model: "sequential_363"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_237 (Conv3D (None, 82, 5, 14, 1)      20        
_________________________________________________________________
dropout_501 (Dropout)        (None, 82, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_238 (Conv3D (None, 84, 5, 14, 1)      4         
_________________________________________________________________
reshape_98 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_167 (Conv2D)          (None, 650, 14, 1)        226       
_________________________________________________________________
dropout_503 (Dropout)        (None, 650, 14, 1)        0         
_________________________________________________________________
conv2d_168 (Conv2D)          (None, 420, 14, 1)        232       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_167 (Conv2D (None, 500, 14, 1)        82        
_________________________________________________________________
dropout_505 (Dropout)        (None, 500, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_168 (Conv2D (None, 874, 14, 1)        376       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14283031  || Decoder Loss:  0.23869894 Validation Decoder Loss:  0.49503022
Encoder Loss:  0.13242912  || Decoder Loss:  0.21867144 Validation Decoder Loss:  0.4966119
Encoder Loss:  0.0996645  || Decoder Loss:  0.21121685 Validation Decoder Loss:  0.50493807
Encoder Loss:  0.08502376  || Decoder Loss:  0.21096845 Validation Decoder Loss:  0.5039421
Encoder Loss:  0.0835935  || Decoder Loss:  0.21036084 Validation Decoder Loss:  0.501165
Encoder Loss:  0.083426975  || Decoder Loss:  0.21001707 Validation Decoder Loss:  0.5001169
Encoder Loss:  0.083295844  || Decoder Loss:  0.20993726 Validation Decoder Loss:  0.5006108
Encoder Loss:  0.0832289  || Decoder Loss:  0.21031186 Validation Decoder Loss:  0.50185674
Encoder Loss:  0.083261274  || Decoder Loss:  0.21114291 Validation Decoder Loss:  0.5036597
Encoder Loss:  0.08329505  || Decoder Loss:  0.21193348 Validation Decoder Loss:  0.505105
Encoder Loss:  0.083262034  || Decoder Loss:  0.21233499 Validation Decoder Loss:  0.50536233
Encoder Loss:  0.083012655  || Decoder Loss:  0.21139194 Validation Decoder Loss:  0.50687814
Encoder Loss:  0.08250773  || Decoder Loss:  0.20908919 Validation Decoder Loss:  0.5008894
Encoder Loss:  0.08190733  || Decoder Loss:  0.20626836 Validation Decoder Loss:  0.50482583
Encoder Loss:  0.081676394  || Decoder Loss:  0.2053155 Validation Decoder Loss:  0.50818515
Encoder Loss:  0.08138744  || Decoder Loss:  0.20403773 Validation Decoder Loss:  0.50923157
Encoder Loss:  0.08124127  || Decoder Loss:  0.20346126 Validation Decoder Loss:  0.5093213
Encoder Loss:  0.08117968  || Decoder Loss:  0.20331213 Validation Decoder Loss:  0.5099899
Encoder Loss:  0.08115602  || Decoder Loss:  0.20334071 Validation Decoder Loss:  0.5104164
Encoder Loss:  0.08113026  || Decoder Loss:  0.20333718 Validation Decoder Loss:  0.5102293
Encoder Loss:  0.08105652  || Decoder Loss:  0.20308688 Validation Decoder Loss:  0.50894505
Encoder Loss:  0.08094802  || Decoder Loss:  0.2026439 Validation Decoder Loss:  0.50834817
Encoder Loss:  0.08081683  || Decoder Loss:  0.2020679 Validation Decoder Loss:  0.50828874
Encoder Loss:  0.08071654  || Decoder Loss:  0.20162156 Validation Decoder Loss:  0.507794
Encoder Loss:  0.08065586  || Decoder Loss:  0.20137106 Validation Decoder Loss:  0.5079174
Encoder Loss:  0.08061383  || Decoder Loss:  0.2012147 Validation Decoder Loss:  0.50775987
Encoder Loss:  0.080581345  || Decoder Loss:  0.20109984 Validation Decoder Loss:  0.50773436
Encoder Loss:  0.080559745  || Decoder Loss:  0.20103869 Validation Decoder Loss:  0.50785595
Encoder Loss:  0.080537416  || Decoder Loss:  0.20095795 Validation Decoder Loss:  0.5079713
Encoder Loss:  0.080520175  || Decoder Loss:  0.20090438 Validation Decoder Loss:  0.5081212
Encoder Loss:  0.08048952  || Decoder Loss:  0.20079961 Validation Decoder Loss:  0.50780964
Encoder Loss:  0.080458984  || Decoder Loss:  0.20067014 Validation Decoder Loss:  0.50773937
Encoder Loss:  0.080412194  || Decoder Loss:  0.20048359 Validation Decoder Loss:  0.50737286
Encoder Loss:  0.080362685  || Decoder Loss:  0.20027104 Validation Decoder Loss:  0.50681937
Encoder Loss:  0.08030587  || Decoder Loss:  0.20000681 Validation Decoder Loss:  0.50610495
Encoder Loss:  0.08022044  || Decoder Loss:  0.19961673 Validation Decoder Loss:  0.505665
Encoder Loss:  0.080116965  || Decoder Loss:  0.19915411 Validation Decoder Loss:  0.5048626
Encoder Loss:  0.08000088  || Decoder Loss:  0.19860774 Validation Decoder Loss:  0.503789
Encoder Loss:  0.079854116  || Decoder Loss:  0.19790576 Validation Decoder Loss:  0.5025115
Encoder Loss:  0.07971804  || Decoder Loss:  0.19725727 Validation Decoder Loss:  0.5012457
Model: bold_synthesis_net_lr_0.0006569488548944177 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5012457
Model: "sequential_367"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_240 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_507 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_241 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_99 (Reshape)         (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_169 (Conv2D)          (None, 580, 14, 1)        296       
_________________________________________________________________
dropout_509 (Dropout)        (None, 580, 14, 1)        0         
_________________________________________________________________
conv2d_170 (Conv2D)          (None, 420, 14, 1)        162       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_169 (Conv2D (None, 820, 14, 1)        402       
_________________________________________________________________
dropout_511 (Dropout)        (None, 820, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_170 (Conv2D (None, 874, 14, 1)        56        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19713476  || Decoder Loss:  0.24777114 Validation Decoder Loss:  0.50191426
Encoder Loss:  0.19062908  || Decoder Loss:  0.23902407 Validation Decoder Loss:  0.50140053
Encoder Loss:  0.18700215  || Decoder Loss:  0.23388453 Validation Decoder Loss:  0.50135785
Encoder Loss:  0.18502042  || Decoder Loss:  0.23094854 Validation Decoder Loss:  0.5009614
Encoder Loss:  0.18362539  || Decoder Loss:  0.22896843 Validation Decoder Loss:  0.5004297
Encoder Loss:  0.18239957  || Decoder Loss:  0.22734836 Validation Decoder Loss:  0.4999105
Encoder Loss:  0.18115573  || Decoder Loss:  0.22580495 Validation Decoder Loss:  0.49953625
Encoder Loss:  0.17985961  || Decoder Loss:  0.22430713 Validation Decoder Loss:  0.4991907
Encoder Loss:  0.17854312  || Decoder Loss:  0.22292209 Validation Decoder Loss:  0.49886116
Encoder Loss:  0.17713143  || Decoder Loss:  0.22156075 Validation Decoder Loss:  0.49880454
Encoder Loss:  0.17560625  || Decoder Loss:  0.22021136 Validation Decoder Loss:  0.49896467
Encoder Loss:  0.17396799  || Decoder Loss:  0.21893342 Validation Decoder Loss:  0.49936745
Encoder Loss:  0.17218141  || Decoder Loss:  0.21773073 Validation Decoder Loss:  0.5003117
Encoder Loss:  0.1702535  || Decoder Loss:  0.2166683 Validation Decoder Loss:  0.5017332
Encoder Loss:  0.16818948  || Decoder Loss:  0.21587881 Validation Decoder Loss:  0.5034092
Encoder Loss:  0.1660145  || Decoder Loss:  0.21532103 Validation Decoder Loss:  0.5053869
Encoder Loss:  0.1637564  || Decoder Loss:  0.21468362 Validation Decoder Loss:  0.5080357
Encoder Loss:  0.16199069  || Decoder Loss:  0.21465766 Validation Decoder Loss:  0.5111006
Encoder Loss:  0.16077304  || Decoder Loss:  0.21499547 Validation Decoder Loss:  0.5145205
Encoder Loss:  0.16016409  || Decoder Loss:  0.21584272 Validation Decoder Loss:  0.51749015
Encoder Loss:  0.15973099  || Decoder Loss:  0.21670046 Validation Decoder Loss:  0.5201618
Encoder Loss:  0.15939584  || Decoder Loss:  0.21750513 Validation Decoder Loss:  0.5222629
Encoder Loss:  0.15899934  || Decoder Loss:  0.21808097 Validation Decoder Loss:  0.52388567
Encoder Loss:  0.15872166  || Decoder Loss:  0.21886678 Validation Decoder Loss:  0.52540994
Encoder Loss:  0.15861537  || Decoder Loss:  0.21998267 Validation Decoder Loss:  0.5268124
Encoder Loss:  0.15838988  || Decoder Loss:  0.22094071 Validation Decoder Loss:  0.52763903
Encoder Loss:  0.1580229  || Decoder Loss:  0.22174759 Validation Decoder Loss:  0.5279727
Encoder Loss:  0.15754488  || Decoder Loss:  0.22242327 Validation Decoder Loss:  0.52799827
Encoder Loss:  0.15696476  || Decoder Loss:  0.22293107 Validation Decoder Loss:  0.52780443
Encoder Loss:  0.15637203  || Decoder Loss:  0.22320633 Validation Decoder Loss:  0.5268092
Encoder Loss:  0.15573266  || Decoder Loss:  0.223013 Validation Decoder Loss:  0.526281
Encoder Loss:  0.15511711  || Decoder Loss:  0.22258654 Validation Decoder Loss:  0.52635884
Encoder Loss:  0.15462206  || Decoder Loss:  0.22209303 Validation Decoder Loss:  0.526942
Encoder Loss:  0.15410224  || Decoder Loss:  0.22144003 Validation Decoder Loss:  0.5258027
Encoder Loss:  0.15369675  || Decoder Loss:  0.22094326 Validation Decoder Loss:  0.5249509
Encoder Loss:  0.15333022  || Decoder Loss:  0.22049765 Validation Decoder Loss:  0.52452385
Encoder Loss:  0.15298147  || Decoder Loss:  0.2200722 Validation Decoder Loss:  0.5242253
Encoder Loss:  0.15264651  || Decoder Loss:  0.21966112 Validation Decoder Loss:  0.523667
Encoder Loss:  0.15234333  || Decoder Loss:  0.21930544 Validation Decoder Loss:  0.5228529
Encoder Loss:  0.1520561  || Decoder Loss:  0.21897301 Validation Decoder Loss:  0.52237105
Model: bold_synthesis_net_lr_0.0008494285547816237 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.52237105
Model: "sequential_371"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_243 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_513 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_244 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_100 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_171 (Conv2D)          (None, 670, 14, 1)        206       
_________________________________________________________________
dropout_515 (Dropout)        (None, 670, 14, 1)        0         
_________________________________________________________________
conv2d_172 (Conv2D)          (None, 420, 14, 1)        252       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_374"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_171 (Conv2D (None, 530, 14, 1)        112       
_________________________________________________________________
dropout_517 (Dropout)        (None, 530, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_172 (Conv2D (None, 874, 14, 1)        346       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14293747  || Decoder Loss:  0.2553193 Validation Decoder Loss:  0.49795488
Encoder Loss:  0.1408256  || Decoder Loss:  0.2506126 Validation Decoder Loss:  0.49658257
Encoder Loss:  0.1390831  || Decoder Loss:  0.24664529 Validation Decoder Loss:  0.4956666
Encoder Loss:  0.13750777  || Decoder Loss:  0.24316442 Validation Decoder Loss:  0.4950275
Encoder Loss:  0.13606462  || Decoder Loss:  0.24005271 Validation Decoder Loss:  0.4946153
Encoder Loss:  0.13490486  || Decoder Loss:  0.23749071 Validation Decoder Loss:  0.4944045
Encoder Loss:  0.1339897  || Decoder Loss:  0.23538266 Validation Decoder Loss:  0.4944532
Encoder Loss:  0.13331509  || Decoder Loss:  0.23374048 Validation Decoder Loss:  0.49454507
Encoder Loss:  0.1328074  || Decoder Loss:  0.23247941 Validation Decoder Loss:  0.49464077
Encoder Loss:  0.13235222  || Decoder Loss:  0.2313983 Validation Decoder Loss:  0.494748
Encoder Loss:  0.13192065  || Decoder Loss:  0.23042536 Validation Decoder Loss:  0.49487984
Encoder Loss:  0.13150753  || Decoder Loss:  0.22954002 Validation Decoder Loss:  0.49499294
Encoder Loss:  0.1311341  || Decoder Loss:  0.22880818 Validation Decoder Loss:  0.4950527
Encoder Loss:  0.13075319  || Decoder Loss:  0.22813836 Validation Decoder Loss:  0.495134
Encoder Loss:  0.13037474  || Decoder Loss:  0.22751182 Validation Decoder Loss:  0.49520737
Encoder Loss:  0.12997907  || Decoder Loss:  0.22690754 Validation Decoder Loss:  0.49531054
Encoder Loss:  0.12955898  || Decoder Loss:  0.22630669 Validation Decoder Loss:  0.49545014
Encoder Loss:  0.12911083  || Decoder Loss:  0.22570996 Validation Decoder Loss:  0.4956262
Encoder Loss:  0.12863177  || Decoder Loss:  0.2251162 Validation Decoder Loss:  0.49582985
Encoder Loss:  0.12812658  || Decoder Loss:  0.22454265 Validation Decoder Loss:  0.49602494
Encoder Loss:  0.12759578  || Decoder Loss:  0.2240003 Validation Decoder Loss:  0.49623257
Encoder Loss:  0.12704073  || Decoder Loss:  0.22348462 Validation Decoder Loss:  0.49644765
Encoder Loss:  0.12645622  || Decoder Loss:  0.22299522 Validation Decoder Loss:  0.4966511
Encoder Loss:  0.12584823  || Decoder Loss:  0.22253558 Validation Decoder Loss:  0.49686557
Encoder Loss:  0.12520717  || Decoder Loss:  0.22209597 Validation Decoder Loss:  0.49711844
Encoder Loss:  0.12453274  || Decoder Loss:  0.22167614 Validation Decoder Loss:  0.4973939
Encoder Loss:  0.12382605  || Decoder Loss:  0.22127168 Validation Decoder Loss:  0.49768174
Encoder Loss:  0.12308045  || Decoder Loss:  0.22086552 Validation Decoder Loss:  0.49799854
Encoder Loss:  0.12229583  || Decoder Loss:  0.22046074 Validation Decoder Loss:  0.4983448
Encoder Loss:  0.12148215  || Decoder Loss:  0.22006623 Validation Decoder Loss:  0.4987049
Encoder Loss:  0.12062628  || Decoder Loss:  0.21969059 Validation Decoder Loss:  0.49905673
Encoder Loss:  0.119719364  || Decoder Loss:  0.21934061 Validation Decoder Loss:  0.49938133
Encoder Loss:  0.11874823  || Decoder Loss:  0.21901006 Validation Decoder Loss:  0.49971187
Encoder Loss:  0.11771673  || Decoder Loss:  0.21871595 Validation Decoder Loss:  0.50001216
Encoder Loss:  0.11661732  || Decoder Loss:  0.21844299 Validation Decoder Loss:  0.5002619
Encoder Loss:  0.11547278  || Decoder Loss:  0.21820186 Validation Decoder Loss:  0.50035787
Encoder Loss:  0.1142701  || Decoder Loss:  0.21797647 Validation Decoder Loss:  0.5003704
Encoder Loss:  0.11297878  || Decoder Loss:  0.2177632 Validation Decoder Loss:  0.5003745
Encoder Loss:  0.11161189  || Decoder Loss:  0.21756849 Validation Decoder Loss:  0.50032175
Encoder Loss:  0.11016707  || Decoder Loss:  0.21737787 Validation Decoder Loss:  0.50022215
Model: bold_synthesis_net_lr_0.00017256812699016993 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.50022215
Model: "sequential_375"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_246 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_519 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_247 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_101 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_377"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_173 (Conv2D)          (None, 610, 14, 1)        266       
_________________________________________________________________
dropout_521 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_174 (Conv2D)          (None, 420, 14, 1)        192       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_173 (Conv2D (None, 810, 14, 1)        392       
_________________________________________________________________
dropout_523 (Dropout)        (None, 810, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_174 (Conv2D (None, 874, 14, 1)        66        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22966126  || Decoder Loss:  0.27268007 Validation Decoder Loss:  0.5267963
Encoder Loss:  0.15507255  || Decoder Loss:  0.20865056 Validation Decoder Loss:  0.4849499
Encoder Loss:  0.1526197  || Decoder Loss:  0.20740408 Validation Decoder Loss:  0.49693757
Encoder Loss:  0.15495607  || Decoder Loss:  0.21184495 Validation Decoder Loss:  0.5004616
Encoder Loss:  0.15350264  || Decoder Loss:  0.20982671 Validation Decoder Loss:  0.48437795
Encoder Loss:  0.14929165  || Decoder Loss:  0.20340748 Validation Decoder Loss:  0.4739866
Encoder Loss:  0.14796808  || Decoder Loss:  0.2014154 Validation Decoder Loss:  0.46414688
Encoder Loss:  0.14877474  || Decoder Loss:  0.20270497 Validation Decoder Loss:  0.458425
Encoder Loss:  0.14919609  || Decoder Loss:  0.20339246 Validation Decoder Loss:  0.5832659
Encoder Loss:  0.14606914  || Decoder Loss:  0.19856086 Validation Decoder Loss:  0.57315624
Encoder Loss:  0.14140761  || Decoder Loss:  0.19135575 Validation Decoder Loss:  0.58573484
Encoder Loss:  0.1383062  || Decoder Loss:  0.1865616 Validation Decoder Loss:  0.5802865
Encoder Loss:  0.13781007  || Decoder Loss:  0.18580537 Validation Decoder Loss:  0.5774589
Encoder Loss:  0.13734052  || Decoder Loss:  0.18508334 Validation Decoder Loss:  0.5773949
Encoder Loss:  0.13787277  || Decoder Loss:  0.18595758 Validation Decoder Loss:  0.5768606
Encoder Loss:  0.14228897  || Decoder Loss:  0.19286677 Validation Decoder Loss:  0.5871662
Encoder Loss:  0.15812261  || Decoder Loss:  0.2174581 Validation Decoder Loss:  0.6158783
Encoder Loss:  0.20627607  || Decoder Loss:  0.29211727 Validation Decoder Loss:  0.9810549
Encoder Loss:  0.2800439  || Decoder Loss:  0.4064418 Validation Decoder Loss:  0.96267736
Encoder Loss:  0.2864386  || Decoder Loss:  0.4163524 Validation Decoder Loss:  0.9534854
Encoder Loss:  0.28427118  || Decoder Loss:  0.41299784 Validation Decoder Loss:  0.99666405
Encoder Loss:  0.28500888  || Decoder Loss:  0.4141467 Validation Decoder Loss:  0.9837812
Encoder Loss:  0.3031239  || Decoder Loss:  0.4422098 Validation Decoder Loss:  0.9963591
Encoder Loss:  0.3047876  || Decoder Loss:  0.4448025 Validation Decoder Loss:  0.99955064
Encoder Loss:  0.30460876  || Decoder Loss:  0.44451588 Validation Decoder Loss:  0.9963411
Encoder Loss:  0.30494878  || Decoder Loss:  0.44504654 Validation Decoder Loss:  0.99968743
Encoder Loss:  0.30505067  || Decoder Loss:  0.44519994 Validation Decoder Loss:  0.9998753
Encoder Loss:  0.30505624  || Decoder Loss:  0.4452198 Validation Decoder Loss:  0.9963096
Encoder Loss:  0.30397514  || Decoder Loss:  0.4435474 Validation Decoder Loss:  0.9985109
Encoder Loss:  0.3050147  || Decoder Loss:  0.4451496 Validation Decoder Loss:  0.999875
Encoder Loss:  0.30512592  || Decoder Loss:  0.4453297 Validation Decoder Loss:  0.9997657
Encoder Loss:  0.30512694  || Decoder Loss:  0.4453239 Validation Decoder Loss:  0.9998548
Encoder Loss:  0.30512333  || Decoder Loss:  0.44532427 Validation Decoder Loss:  0.99975866
Encoder Loss:  0.30512124  || Decoder Loss:  0.44532344 Validation Decoder Loss:  0.9998545
Encoder Loss:  0.30509484  || Decoder Loss:  0.44528672 Validation Decoder Loss:  0.9998307
Encoder Loss:  0.30511838  || Decoder Loss:  0.44531634 Validation Decoder Loss:  0.9998275
Encoder Loss:  0.30512503  || Decoder Loss:  0.44532657 Validation Decoder Loss:  0.99970055
Encoder Loss:  0.30491793  || Decoder Loss:  0.4450057 Validation Decoder Loss:  0.99978286
Encoder Loss:  0.304637  || Decoder Loss:  0.4445728 Validation Decoder Loss:  0.99380404
Encoder Loss:  0.30457336  || Decoder Loss:  0.44447607 Validation Decoder Loss:  0.9998753
Model: bold_synthesis_net_lr_0.0008836130779828716 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.9998753
Model: "sequential_379"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_249 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_525 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_250 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_102 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_381"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_175 (Conv2D)          (None, 790, 14, 1)        86        
_________________________________________________________________
dropout_527 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_176 (Conv2D)          (None, 420, 14, 1)        372       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_175 (Conv2D (None, 820, 14, 1)        402       
_________________________________________________________________
dropout_529 (Dropout)        (None, 820, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_176 (Conv2D (None, 874, 14, 1)        56        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19032675  || Decoder Loss:  0.23600864 Validation Decoder Loss:  0.49478847
Encoder Loss:  0.17728838  || Decoder Loss:  0.21880713 Validation Decoder Loss:  0.4933535
Encoder Loss:  0.16934611  || Decoder Loss:  0.21305208 Validation Decoder Loss:  0.49710342
Encoder Loss:  0.15940382  || Decoder Loss:  0.21006022 Validation Decoder Loss:  0.50937957
Encoder Loss:  0.15518185  || Decoder Loss:  0.21343665 Validation Decoder Loss:  0.52314425
Encoder Loss:  0.15704224  || Decoder Loss:  0.22133951 Validation Decoder Loss:  0.5349906
Encoder Loss:  0.15874287  || Decoder Loss:  0.22626784 Validation Decoder Loss:  0.53392315
Encoder Loss:  0.15809572  || Decoder Loss:  0.22568418 Validation Decoder Loss:  0.53371274
Encoder Loss:  0.15722969  || Decoder Loss:  0.22452815 Validation Decoder Loss:  0.5342998
Encoder Loss:  0.15659909  || Decoder Loss:  0.22366409 Validation Decoder Loss:  0.5331509
Encoder Loss:  0.15598775  || Decoder Loss:  0.2228031 Validation Decoder Loss:  0.53185815
Encoder Loss:  0.1552858  || Decoder Loss:  0.22177322 Validation Decoder Loss:  0.53171766
Encoder Loss:  0.15467115  || Decoder Loss:  0.22087085 Validation Decoder Loss:  0.5302694
Encoder Loss:  0.15398744  || Decoder Loss:  0.21983054 Validation Decoder Loss:  0.5310952
Encoder Loss:  0.1529055  || Decoder Loss:  0.21811973 Validation Decoder Loss:  0.53088576
Encoder Loss:  0.15225244  || Decoder Loss:  0.21709546 Validation Decoder Loss:  0.5305541
Encoder Loss:  0.15121743  || Decoder Loss:  0.21543698 Validation Decoder Loss:  0.52861863
Encoder Loss:  0.14966094  || Decoder Loss:  0.21291709 Validation Decoder Loss:  0.5211607
Encoder Loss:  0.14708263  || Decoder Loss:  0.20871595 Validation Decoder Loss:  0.52376103
Encoder Loss:  0.14442188  || Decoder Loss:  0.20437449 Validation Decoder Loss:  0.5512945
Encoder Loss:  0.14013252  || Decoder Loss:  0.19736226 Validation Decoder Loss:  0.5493971
Encoder Loss:  0.13782018  || Decoder Loss:  0.19358552 Validation Decoder Loss:  0.5450895
Encoder Loss:  0.13592255  || Decoder Loss:  0.19048658 Validation Decoder Loss:  0.5387973
Encoder Loss:  0.13468814  || Decoder Loss:  0.18847407 Validation Decoder Loss:  0.53456384
Encoder Loss:  0.13391553  || Decoder Loss:  0.18721654 Validation Decoder Loss:  0.5315979
Encoder Loss:  0.13314405  || Decoder Loss:  0.18595892 Validation Decoder Loss:  0.5291137
Encoder Loss:  0.13215493  || Decoder Loss:  0.18434538 Validation Decoder Loss:  0.52993524
Encoder Loss:  0.13134634  || Decoder Loss:  0.18302722 Validation Decoder Loss:  0.5313423
Encoder Loss:  0.13088125  || Decoder Loss:  0.18227123 Validation Decoder Loss:  0.53287363
Encoder Loss:  0.13049118  || Decoder Loss:  0.18163496 Validation Decoder Loss:  0.5363112
Encoder Loss:  0.1302241  || Decoder Loss:  0.18120065 Validation Decoder Loss:  0.5385805
Encoder Loss:  0.13003914  || Decoder Loss:  0.18090159 Validation Decoder Loss:  0.53933215
Encoder Loss:  0.12991557  || Decoder Loss:  0.1807032 Validation Decoder Loss:  0.54009724
Encoder Loss:  0.12982625  || Decoder Loss:  0.1805612 Validation Decoder Loss:  0.5403128
Encoder Loss:  0.12974642  || Decoder Loss:  0.18043363 Validation Decoder Loss:  0.5404697
Encoder Loss:  0.12967178  || Decoder Loss:  0.18031463 Validation Decoder Loss:  0.5404951
Encoder Loss:  0.12959585  || Decoder Loss:  0.1801939 Validation Decoder Loss:  0.54044706
Encoder Loss:  0.12952165  || Decoder Loss:  0.18007587 Validation Decoder Loss:  0.54028636
Encoder Loss:  0.12944885  || Decoder Loss:  0.17996046 Validation Decoder Loss:  0.54006577
Encoder Loss:  0.12938018  || Decoder Loss:  0.1798509 Validation Decoder Loss:  0.5398781
Model: bold_synthesis_net_lr_0.00032752391977333375 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5398781
Model: "sequential_383"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_252 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_531 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_253 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_103 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_385"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_177 (Conv2D)          (None, 500, 14, 1)        376       
_________________________________________________________________
dropout_533 (Dropout)        (None, 500, 14, 1)        0         
_________________________________________________________________
conv2d_178 (Conv2D)          (None, 420, 14, 1)        82        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_177 (Conv2D (None, 740, 14, 1)        322       
_________________________________________________________________
dropout_535 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_178 (Conv2D (None, 874, 14, 1)        136       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24989882  || Decoder Loss:  0.26696408 Validation Decoder Loss:  0.48078197
Encoder Loss:  0.22775996  || Decoder Loss:  0.24327853 Validation Decoder Loss:  0.48016602
Encoder Loss:  0.21676065  || Decoder Loss:  0.23153514 Validation Decoder Loss:  0.48264077
Encoder Loss:  0.21030818  || Decoder Loss:  0.22477399 Validation Decoder Loss:  0.4866131
Encoder Loss:  0.20670164  || Decoder Loss:  0.22112845 Validation Decoder Loss:  0.48900717
Encoder Loss:  0.20446342  || Decoder Loss:  0.21909663 Validation Decoder Loss:  0.49044713
Encoder Loss:  0.20240702  || Decoder Loss:  0.21749319 Validation Decoder Loss:  0.49159652
Encoder Loss:  0.2003554  || Decoder Loss:  0.21620116 Validation Decoder Loss:  0.49210545
Encoder Loss:  0.19812305  || Decoder Loss:  0.21500134 Validation Decoder Loss:  0.49107727
Encoder Loss:  0.19589612  || Decoder Loss:  0.21401098 Validation Decoder Loss:  0.4898785
Encoder Loss:  0.19381125  || Decoder Loss:  0.2133011 Validation Decoder Loss:  0.48844108
Encoder Loss:  0.19206138  || Decoder Loss:  0.21268225 Validation Decoder Loss:  0.48494595
Encoder Loss:  0.19075036  || Decoder Loss:  0.21151079 Validation Decoder Loss:  0.48163155
Encoder Loss:  0.18968047  || Decoder Loss:  0.21033658 Validation Decoder Loss:  0.47987533
Encoder Loss:  0.18892343  || Decoder Loss:  0.20950915 Validation Decoder Loss:  0.47827995
Encoder Loss:  0.1881893  || Decoder Loss:  0.20870659 Validation Decoder Loss:  0.47671956
Encoder Loss:  0.18750787  || Decoder Loss:  0.20796318 Validation Decoder Loss:  0.47543758
Encoder Loss:  0.18690568  || Decoder Loss:  0.20731133 Validation Decoder Loss:  0.47429165
Encoder Loss:  0.18634859  || Decoder Loss:  0.20671062 Validation Decoder Loss:  0.47308746
Encoder Loss:  0.18582499  || Decoder Loss:  0.20614928 Validation Decoder Loss:  0.4718297
Encoder Loss:  0.18535598  || Decoder Loss:  0.20565069 Validation Decoder Loss:  0.47060487
Encoder Loss:  0.18491076  || Decoder Loss:  0.2051793 Validation Decoder Loss:  0.46941647
Encoder Loss:  0.18444689  || Decoder Loss:  0.20468538 Validation Decoder Loss:  0.46817753
Encoder Loss:  0.18397926  || Decoder Loss:  0.20418671 Validation Decoder Loss:  0.4668948
Encoder Loss:  0.18354277  || Decoder Loss:  0.20372295 Validation Decoder Loss:  0.4655533
Encoder Loss:  0.1831323  || Decoder Loss:  0.20328708 Validation Decoder Loss:  0.464188
Encoder Loss:  0.18276975  || Decoder Loss:  0.2029034 Validation Decoder Loss:  0.46283764
Encoder Loss:  0.18244089  || Decoder Loss:  0.20255488 Validation Decoder Loss:  0.46149993
Encoder Loss:  0.18209742  || Decoder Loss:  0.20218393 Validation Decoder Loss:  0.4604796
Encoder Loss:  0.18181261  || Decoder Loss:  0.20187615 Validation Decoder Loss:  0.45947587
Encoder Loss:  0.18158127  || Decoder Loss:  0.201625 Validation Decoder Loss:  0.45842567
Encoder Loss:  0.18139444  || Decoder Loss:  0.20142323 Validation Decoder Loss:  0.45742476
Encoder Loss:  0.1812826  || Decoder Loss:  0.20130679 Validation Decoder Loss:  0.4565573
Encoder Loss:  0.18119954  || Decoder Loss:  0.20122169 Validation Decoder Loss:  0.45568454
Encoder Loss:  0.18114337  || Decoder Loss:  0.20116688 Validation Decoder Loss:  0.45485097
Encoder Loss:  0.18111575  || Decoder Loss:  0.20114449 Validation Decoder Loss:  0.45405266
Encoder Loss:  0.18112203  || Decoder Loss:  0.20116144 Validation Decoder Loss:  0.45331123
Encoder Loss:  0.18115485  || Decoder Loss:  0.20120832 Validation Decoder Loss:  0.45252013
Encoder Loss:  0.18119867  || Decoder Loss:  0.20126797 Validation Decoder Loss:  0.45178604
Encoder Loss:  0.18126315  || Decoder Loss:  0.20135139 Validation Decoder Loss:  0.45105198
Model: bold_synthesis_net_lr_0.0003880334871937685 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.45105198
Model: "sequential_387"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_255 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_537 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_256 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_104 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_389"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_179 (Conv2D)          (None, 420, 14, 1)        456       
_________________________________________________________________
dropout_539 (Dropout)        (None, 420, 14, 1)        0         
_________________________________________________________________
conv2d_180 (Conv2D)          (None, 420, 14, 1)        2         
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_179 (Conv2D (None, 620, 14, 1)        202       
_________________________________________________________________
dropout_541 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_180 (Conv2D (None, 874, 14, 1)        256       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15265365  || Decoder Loss:  0.24368405 Validation Decoder Loss:  0.48765418
Encoder Loss:  0.14192578  || Decoder Loss:  0.22965378 Validation Decoder Loss:  0.48240784
Encoder Loss:  0.1323287  || Decoder Loss:  0.226116 Validation Decoder Loss:  0.47525954
Encoder Loss:  0.121882856  || Decoder Loss:  0.22412902 Validation Decoder Loss:  0.47497994
Encoder Loss:  0.111297935  || Decoder Loss:  0.22203091 Validation Decoder Loss:  0.5266832
Encoder Loss:  0.103614956  || Decoder Loss:  0.22224817 Validation Decoder Loss:  0.51685435
Encoder Loss:  0.10072551  || Decoder Loss:  0.22125588 Validation Decoder Loss:  0.5297008
Encoder Loss:  0.09929898  || Decoder Loss:  0.21927613 Validation Decoder Loss:  0.54993594
Encoder Loss:  0.09766416  || Decoder Loss:  0.21526481 Validation Decoder Loss:  0.54332095
Encoder Loss:  0.094188325  || Decoder Loss:  0.20384158 Validation Decoder Loss:  0.5462042
Encoder Loss:  0.09233214  || Decoder Loss:  0.19840291 Validation Decoder Loss:  0.543953
Encoder Loss:  0.09046453  || Decoder Loss:  0.19271827 Validation Decoder Loss:  0.551473
Encoder Loss:  0.08951298  || Decoder Loss:  0.19042161 Validation Decoder Loss:  0.55411077
Encoder Loss:  0.08888399  || Decoder Loss:  0.18921061 Validation Decoder Loss:  0.5550333
Encoder Loss:  0.0884075  || Decoder Loss:  0.18833923 Validation Decoder Loss:  0.55616057
Encoder Loss:  0.08790306  || Decoder Loss:  0.18729106 Validation Decoder Loss:  0.5581297
Encoder Loss:  0.087371536  || Decoder Loss:  0.18611416 Validation Decoder Loss:  0.5595892
Encoder Loss:  0.08686169  || Decoder Loss:  0.18494926 Validation Decoder Loss:  0.5585546
Encoder Loss:  0.08636536  || Decoder Loss:  0.18374218 Validation Decoder Loss:  0.55346197
Encoder Loss:  0.08585383  || Decoder Loss:  0.18230304 Validation Decoder Loss:  0.54754615
Encoder Loss:  0.085417636  || Decoder Loss:  0.18101422 Validation Decoder Loss:  0.5438648
Encoder Loss:  0.0851072  || Decoder Loss:  0.18011461 Validation Decoder Loss:  0.5419803
Encoder Loss:  0.08488287  || Decoder Loss:  0.17947763 Validation Decoder Loss:  0.5407059
Encoder Loss:  0.08471791  || Decoder Loss:  0.1790326 Validation Decoder Loss:  0.5402098
Encoder Loss:  0.084580325  || Decoder Loss:  0.1786563 Validation Decoder Loss:  0.53954184
Encoder Loss:  0.08444008  || Decoder Loss:  0.17826787 Validation Decoder Loss:  0.5388076
Encoder Loss:  0.08430714  || Decoder Loss:  0.17787476 Validation Decoder Loss:  0.53830254
Encoder Loss:  0.0841864  || Decoder Loss:  0.17750907 Validation Decoder Loss:  0.5381618
Encoder Loss:  0.08408084  || Decoder Loss:  0.1771671 Validation Decoder Loss:  0.5385532
Encoder Loss:  0.08398923  || Decoder Loss:  0.17688394 Validation Decoder Loss:  0.5390833
Encoder Loss:  0.083907455  || Decoder Loss:  0.1766319 Validation Decoder Loss:  0.5392559
Encoder Loss:  0.08382267  || Decoder Loss:  0.17636096 Validation Decoder Loss:  0.5395508
Encoder Loss:  0.083736874  || Decoder Loss:  0.1760695 Validation Decoder Loss:  0.53981787
Encoder Loss:  0.08364409  || Decoder Loss:  0.1757788 Validation Decoder Loss:  0.5398196
Encoder Loss:  0.083545335  || Decoder Loss:  0.1754385 Validation Decoder Loss:  0.539834
Encoder Loss:  0.08340744  || Decoder Loss:  0.17490864 Validation Decoder Loss:  0.5409128
Encoder Loss:  0.08331792  || Decoder Loss:  0.1746018 Validation Decoder Loss:  0.54075074
Encoder Loss:  0.08324353  || Decoder Loss:  0.17436521 Validation Decoder Loss:  0.5403273
Encoder Loss:  0.08318374  || Decoder Loss:  0.17411716 Validation Decoder Loss:  0.53997785
Encoder Loss:  0.08311504  || Decoder Loss:  0.17387971 Validation Decoder Loss:  0.53951514
Model: bold_synthesis_net_lr_0.0007654370812736093 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.53951514
Model: "sequential_391"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_258 (Conv3D (None, 64, 5, 14, 1)      2         
_________________________________________________________________
dropout_543 (Dropout)        (None, 64, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_259 (Conv3D (None, 84, 5, 14, 1)      22        
_________________________________________________________________
reshape_105 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_393"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_181 (Conv2D)          (None, 580, 14, 1)        296       
_________________________________________________________________
dropout_545 (Dropout)        (None, 580, 14, 1)        0         
_________________________________________________________________
conv2d_182 (Conv2D)          (None, 420, 14, 1)        162       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_181 (Conv2D (None, 670, 14, 1)        252       
_________________________________________________________________
dropout_547 (Dropout)        (None, 670, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_182 (Conv2D (None, 874, 14, 1)        206       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31001088  || Decoder Loss:  0.42530972 Validation Decoder Loss:  0.7127871
Encoder Loss:  0.15275046  || Decoder Loss:  0.27204838 Validation Decoder Loss:  0.48816335
Encoder Loss:  0.10832214  || Decoder Loss:  0.2030489 Validation Decoder Loss:  0.5070398
Encoder Loss:  0.097314045  || Decoder Loss:  0.21271895 Validation Decoder Loss:  0.5271093
Encoder Loss:  0.079229  || Decoder Loss:  0.21215163 Validation Decoder Loss:  0.5062921
Encoder Loss:  0.06759466  || Decoder Loss:  0.21275234 Validation Decoder Loss:  0.5078131
Encoder Loss:  0.06404936  || Decoder Loss:  0.21309324 Validation Decoder Loss:  0.50215334
Encoder Loss:  0.062311675  || Decoder Loss:  0.2112948 Validation Decoder Loss:  0.4984714
Encoder Loss:  0.0610351  || Decoder Loss:  0.21039866 Validation Decoder Loss:  0.49629253
Encoder Loss:  0.05996792  || Decoder Loss:  0.20997474 Validation Decoder Loss:  0.4969668
Encoder Loss:  0.059046276  || Decoder Loss:  0.21136485 Validation Decoder Loss:  0.50474435
Encoder Loss:  0.0583311  || Decoder Loss:  0.21508935 Validation Decoder Loss:  0.5165801
Encoder Loss:  0.05779594  || Decoder Loss:  0.21911526 Validation Decoder Loss:  0.52459925
Encoder Loss:  0.05731771  || Decoder Loss:  0.2178547 Validation Decoder Loss:  0.5177219
Encoder Loss:  0.056895588  || Decoder Loss:  0.2136276 Validation Decoder Loss:  0.50338537
Encoder Loss:  0.056547303  || Decoder Loss:  0.20906568 Validation Decoder Loss:  0.48638305
Encoder Loss:  0.056300804  || Decoder Loss:  0.20582348 Validation Decoder Loss:  0.47555187
Encoder Loss:  0.056176525  || Decoder Loss:  0.20514917 Validation Decoder Loss:  0.46450892
Encoder Loss:  0.056168493  || Decoder Loss:  0.20716889 Validation Decoder Loss:  0.45475376
Encoder Loss:  0.056257814  || Decoder Loss:  0.2115219 Validation Decoder Loss:  0.44775525
Encoder Loss:  0.056378398  || Decoder Loss:  0.21651101 Validation Decoder Loss:  0.44213024
Encoder Loss:  0.05654845  || Decoder Loss:  0.22284053 Validation Decoder Loss:  0.4399614
Encoder Loss:  0.056756165  || Decoder Loss:  0.23011574 Validation Decoder Loss:  0.4418509
Encoder Loss:  0.056882977  || Decoder Loss:  0.23477069 Validation Decoder Loss:  0.4505459
Encoder Loss:  0.056839686  || Decoder Loss:  0.23424703 Validation Decoder Loss:  0.4645383
Encoder Loss:  0.05682436  || Decoder Loss:  0.23456882 Validation Decoder Loss:  0.47671697
Encoder Loss:  0.056894816  || Decoder Loss:  0.23745738 Validation Decoder Loss:  0.48949283
Encoder Loss:  0.05700695  || Decoder Loss:  0.24162458 Validation Decoder Loss:  0.50275964
Encoder Loss:  0.057028826  || Decoder Loss:  0.24296013 Validation Decoder Loss:  0.5242006
Encoder Loss:  0.05715408  || Decoder Loss:  0.24739587 Validation Decoder Loss:  0.5366599
Encoder Loss:  0.057319116  || Decoder Loss:  0.25293523 Validation Decoder Loss:  0.5507994
Encoder Loss:  0.057480346  || Decoder Loss:  0.25839043 Validation Decoder Loss:  0.5641018
Encoder Loss:  0.057597198  || Decoder Loss:  0.2624364 Validation Decoder Loss:  0.57578623
Encoder Loss:  0.05753879  || Decoder Loss:  0.26118088 Validation Decoder Loss:  0.5768704
Encoder Loss:  0.055871632  || Decoder Loss:  0.21140105 Validation Decoder Loss:  0.5950277
Encoder Loss:  0.05554466  || Decoder Loss:  0.20209067 Validation Decoder Loss:  0.5961014
Encoder Loss:  0.055473376  || Decoder Loss:  0.20058385 Validation Decoder Loss:  0.5951168
Encoder Loss:  0.05542365  || Decoder Loss:  0.19974491 Validation Decoder Loss:  0.59504503
Encoder Loss:  0.055385564  || Decoder Loss:  0.19927931 Validation Decoder Loss:  0.59647673
Encoder Loss:  0.05535125  || Decoder Loss:  0.19893475 Validation Decoder Loss:  0.5977518
Model: bold_synthesis_net_lr_0.00019665470593961963 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5977518
Model: "sequential_395"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_261 (Conv3D (None, 78, 5, 14, 1)      16        
_________________________________________________________________
dropout_549 (Dropout)        (None, 78, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_262 (Conv3D (None, 84, 5, 14, 1)      8         
_________________________________________________________________
reshape_106 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_397"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_183 (Conv2D)          (None, 700, 14, 1)        176       
_________________________________________________________________
dropout_551 (Dropout)        (None, 700, 14, 1)        0         
_________________________________________________________________
conv2d_184 (Conv2D)          (None, 420, 14, 1)        282       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_183 (Conv2D (None, 850, 14, 1)        13        
_________________________________________________________________
dropout_553 (Dropout)        (None, 850, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_184 (Conv2D (None, 874, 14, 1)        26        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17698501  || Decoder Loss:  0.26141384 Validation Decoder Loss:  0.5266132
Encoder Loss:  0.17509854  || Decoder Loss:  0.25867385 Validation Decoder Loss:  0.52568257
Encoder Loss:  0.17352238  || Decoder Loss:  0.25637692 Validation Decoder Loss:  0.52512306
Encoder Loss:  0.17210533  || Decoder Loss:  0.2543212 Validation Decoder Loss:  0.5248032
Encoder Loss:  0.1708451  || Decoder Loss:  0.25247395 Validation Decoder Loss:  0.52469647
Encoder Loss:  0.16985887  || Decoder Loss:  0.25097746 Validation Decoder Loss:  0.52471596
Encoder Loss:  0.16907255  || Decoder Loss:  0.24975434 Validation Decoder Loss:  0.52481025
Encoder Loss:  0.1684928  || Decoder Loss:  0.24880612 Validation Decoder Loss:  0.5249528
Encoder Loss:  0.16805598  || Decoder Loss:  0.24809198 Validation Decoder Loss:  0.52509904
Encoder Loss:  0.16766432  || Decoder Loss:  0.24746954 Validation Decoder Loss:  0.5252643
Encoder Loss:  0.16731216  || Decoder Loss:  0.24691777 Validation Decoder Loss:  0.52542824
Encoder Loss:  0.16699435  || Decoder Loss:  0.24644296 Validation Decoder Loss:  0.52559316
Encoder Loss:  0.16673526  || Decoder Loss:  0.24608846 Validation Decoder Loss:  0.5257576
Encoder Loss:  0.16649027  || Decoder Loss:  0.24578655 Validation Decoder Loss:  0.5259343
Encoder Loss:  0.1662359  || Decoder Loss:  0.24548256 Validation Decoder Loss:  0.5261248
Encoder Loss:  0.16597125  || Decoder Loss:  0.24517497 Validation Decoder Loss:  0.5263374
Encoder Loss:  0.16570982  || Decoder Loss:  0.2448873 Validation Decoder Loss:  0.52654356
Encoder Loss:  0.16545606  || Decoder Loss:  0.24463172 Validation Decoder Loss:  0.5267562
Encoder Loss:  0.16519085  || Decoder Loss:  0.24437578 Validation Decoder Loss:  0.52698636
Encoder Loss:  0.16491386  || Decoder Loss:  0.2441208 Validation Decoder Loss:  0.52722204
Encoder Loss:  0.1646311  || Decoder Loss:  0.24387977 Validation Decoder Loss:  0.52746046
Encoder Loss:  0.16434672  || Decoder Loss:  0.2436655 Validation Decoder Loss:  0.5276987
Encoder Loss:  0.16405644  || Decoder Loss:  0.24347535 Validation Decoder Loss:  0.5279445
Encoder Loss:  0.16375586  || Decoder Loss:  0.2433017 Validation Decoder Loss:  0.5282084
Encoder Loss:  0.16343872  || Decoder Loss:  0.2431293 Validation Decoder Loss:  0.5284938
Encoder Loss:  0.1631084  || Decoder Loss:  0.24296491 Validation Decoder Loss:  0.52880925
Encoder Loss:  0.1627632  || Decoder Loss:  0.24281046 Validation Decoder Loss:  0.52917
Encoder Loss:  0.16239865  || Decoder Loss:  0.24265607 Validation Decoder Loss:  0.5295887
Encoder Loss:  0.16201681  || Decoder Loss:  0.24250774 Validation Decoder Loss:  0.5300828
Encoder Loss:  0.16161783  || Decoder Loss:  0.24236915 Validation Decoder Loss:  0.5306121
Encoder Loss:  0.16119799  || Decoder Loss:  0.24223165 Validation Decoder Loss:  0.5312134
Encoder Loss:  0.16076007  || Decoder Loss:  0.24209492 Validation Decoder Loss:  0.5318904
Encoder Loss:  0.16030106  || Decoder Loss:  0.24194941 Validation Decoder Loss:  0.5326528
Encoder Loss:  0.15982406  || Decoder Loss:  0.24180225 Validation Decoder Loss:  0.533525
Encoder Loss:  0.15933093  || Decoder Loss:  0.24165547 Validation Decoder Loss:  0.5344736
Encoder Loss:  0.15881307  || Decoder Loss:  0.24150673 Validation Decoder Loss:  0.53551453
Encoder Loss:  0.1582683  || Decoder Loss:  0.24134755 Validation Decoder Loss:  0.5366896
Encoder Loss:  0.15770707  || Decoder Loss:  0.24119172 Validation Decoder Loss:  0.53807145
Encoder Loss:  0.15711412  || Decoder Loss:  0.24100494 Validation Decoder Loss:  0.5397349
Encoder Loss:  0.15648422  || Decoder Loss:  0.2407757 Validation Decoder Loss:  0.5416097
Model: bold_synthesis_net_lr_0.0002783236913313874 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.54160964
Model: "sequential_399"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_264 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_555 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_265 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_107 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_401"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_185 (Conv2D)          (None, 790, 14, 1)        86        
_________________________________________________________________
dropout_557 (Dropout)        (None, 790, 14, 1)        0         
_________________________________________________________________
conv2d_186 (Conv2D)          (None, 420, 14, 1)        372       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_185 (Conv2D (None, 530, 14, 1)        112       
_________________________________________________________________
dropout_559 (Dropout)        (None, 530, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_186 (Conv2D (None, 874, 14, 1)        346       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16242471  || Decoder Loss:  0.27561563 Validation Decoder Loss:  0.4936166
Encoder Loss:  0.096958004  || Decoder Loss:  0.20480552 Validation Decoder Loss:  0.50061536
Encoder Loss:  0.062140167  || Decoder Loss:  0.21007669 Validation Decoder Loss:  0.50489974
Encoder Loss:  0.058749266  || Decoder Loss:  0.21382928 Validation Decoder Loss:  0.5068766
Encoder Loss:  0.05761433  || Decoder Loss:  0.21191184 Validation Decoder Loss:  0.5015066
Encoder Loss:  0.056826558  || Decoder Loss:  0.2088971 Validation Decoder Loss:  0.49087703
Encoder Loss:  0.056408748  || Decoder Loss:  0.20589304 Validation Decoder Loss:  0.47627485
Encoder Loss:  0.056149323  || Decoder Loss:  0.20382687 Validation Decoder Loss:  0.45708767
Encoder Loss:  0.056178126  || Decoder Loss:  0.20812668 Validation Decoder Loss:  0.44104043
Encoder Loss:  0.056243982  || Decoder Loss:  0.2125285 Validation Decoder Loss:  0.575061
Encoder Loss:  0.05563688  || Decoder Loss:  0.19674936 Validation Decoder Loss:  0.5625728
Encoder Loss:  0.05547891  || Decoder Loss:  0.19358228 Validation Decoder Loss:  0.5559466
Encoder Loss:  0.055390168  || Decoder Loss:  0.19222933 Validation Decoder Loss:  0.552501
Encoder Loss:  0.05533157  || Decoder Loss:  0.19143035 Validation Decoder Loss:  0.55295265
Encoder Loss:  0.055272833  || Decoder Loss:  0.1908125 Validation Decoder Loss:  0.5520874
Encoder Loss:  0.055246856  || Decoder Loss:  0.19025971 Validation Decoder Loss:  0.5509072
Encoder Loss:  0.05521826  || Decoder Loss:  0.18966265 Validation Decoder Loss:  0.5502079
Encoder Loss:  0.05517842  || Decoder Loss:  0.18916865 Validation Decoder Loss:  0.5501331
Encoder Loss:  0.05517099  || Decoder Loss:  0.18882027 Validation Decoder Loss:  0.5491098
Encoder Loss:  0.05513662  || Decoder Loss:  0.18841691 Validation Decoder Loss:  0.54931307
Encoder Loss:  0.055116955  || Decoder Loss:  0.18805423 Validation Decoder Loss:  0.5489993
Encoder Loss:  0.055089086  || Decoder Loss:  0.18765004 Validation Decoder Loss:  0.5492768
Encoder Loss:  0.05506566  || Decoder Loss:  0.18727663 Validation Decoder Loss:  0.5487414
Encoder Loss:  0.05504931  || Decoder Loss:  0.18686727 Validation Decoder Loss:  0.54848033
Encoder Loss:  0.055026222  || Decoder Loss:  0.18635274 Validation Decoder Loss:  0.54841554
Encoder Loss:  0.054989167  || Decoder Loss:  0.18577376 Validation Decoder Loss:  0.54818875
Encoder Loss:  0.05495945  || Decoder Loss:  0.18527792 Validation Decoder Loss:  0.54825544
Encoder Loss:  0.054940674  || Decoder Loss:  0.18490072 Validation Decoder Loss:  0.5484328
Encoder Loss:  0.05492469  || Decoder Loss:  0.18456502 Validation Decoder Loss:  0.5493032
Encoder Loss:  0.054894585  || Decoder Loss:  0.18422067 Validation Decoder Loss:  0.54857856
Encoder Loss:  0.054879908  || Decoder Loss:  0.18388362 Validation Decoder Loss:  0.54891175
Encoder Loss:  0.054866724  || Decoder Loss:  0.18352267 Validation Decoder Loss:  0.5492035
Encoder Loss:  0.05484555  || Decoder Loss:  0.18327715 Validation Decoder Loss:  0.5492313
Encoder Loss:  0.054826915  || Decoder Loss:  0.1829386 Validation Decoder Loss:  0.54974824
Encoder Loss:  0.054806866  || Decoder Loss:  0.18257368 Validation Decoder Loss:  0.55160505
Encoder Loss:  0.054783937  || Decoder Loss:  0.18227464 Validation Decoder Loss:  0.5516113
Encoder Loss:  0.054773346  || Decoder Loss:  0.18192911 Validation Decoder Loss:  0.55244064
Encoder Loss:  0.05475199  || Decoder Loss:  0.18161605 Validation Decoder Loss:  0.55234355
Encoder Loss:  0.054736614  || Decoder Loss:  0.18128957 Validation Decoder Loss:  0.55335814
Encoder Loss:  0.0547255  || Decoder Loss:  0.18091653 Validation Decoder Loss:  0.5565527
Model: bold_synthesis_net_lr_0.0005700585961887497 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5565527
Model: "sequential_403"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_267 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_561 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_268 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_108 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_405"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_187 (Conv2D)          (None, 690, 14, 1)        186       
_________________________________________________________________
dropout_563 (Dropout)        (None, 690, 14, 1)        0         
_________________________________________________________________
conv2d_188 (Conv2D)          (None, 420, 14, 1)        272       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_187 (Conv2D (None, 850, 14, 1)        432       
_________________________________________________________________
dropout_565 (Dropout)        (None, 850, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_188 (Conv2D (None, 874, 14, 1)        26        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22914802  || Decoder Loss:  0.2319897 Validation Decoder Loss:  0.48773068
Encoder Loss:  0.20685025  || Decoder Loss:  0.20937946 Validation Decoder Loss:  0.4925258
Encoder Loss:  0.20299323  || Decoder Loss:  0.20619768 Validation Decoder Loss:  0.49351442
Encoder Loss:  0.19983302  || Decoder Loss:  0.20357454 Validation Decoder Loss:  0.49882716
Encoder Loss:  0.19949092  || Decoder Loss:  0.20330869 Validation Decoder Loss:  0.5101115
Encoder Loss:  0.19863732  || Decoder Loss:  0.20246953 Validation Decoder Loss:  0.56014335
Encoder Loss:  0.19565235  || Decoder Loss:  0.19941977 Validation Decoder Loss:  0.54546887
Encoder Loss:  0.1924783  || Decoder Loss:  0.19617243 Validation Decoder Loss:  0.5535384
Encoder Loss:  0.19109412  || Decoder Loss:  0.1947626 Validation Decoder Loss:  0.5587659
Encoder Loss:  0.1908467  || Decoder Loss:  0.19451961 Validation Decoder Loss:  0.5582442
Encoder Loss:  0.19070728  || Decoder Loss:  0.19438735 Validation Decoder Loss:  0.5573463
Encoder Loss:  0.18927923  || Decoder Loss:  0.19293135 Validation Decoder Loss:  0.5532918
Encoder Loss:  0.18706468  || Decoder Loss:  0.19066603 Validation Decoder Loss:  0.5600693
Encoder Loss:  0.18454714  || Decoder Loss:  0.1880875 Validation Decoder Loss:  0.5525816
Encoder Loss:  0.18370157  || Decoder Loss:  0.18722443 Validation Decoder Loss:  0.5541524
Encoder Loss:  0.18300234  || Decoder Loss:  0.18651125 Validation Decoder Loss:  0.5486367
Encoder Loss:  0.18025136  || Decoder Loss:  0.18369143 Validation Decoder Loss:  0.5449526
Encoder Loss:  0.17962822  || Decoder Loss:  0.18305482 Validation Decoder Loss:  0.5428615
Encoder Loss:  0.17940462  || Decoder Loss:  0.18282744 Validation Decoder Loss:  0.5420952
Encoder Loss:  0.17908438  || Decoder Loss:  0.18250054 Validation Decoder Loss:  0.54160446
Encoder Loss:  0.17869593  || Decoder Loss:  0.18210343 Validation Decoder Loss:  0.538776
Encoder Loss:  0.1780964  || Decoder Loss:  0.18148898 Validation Decoder Loss:  0.53746015
Encoder Loss:  0.1774162  || Decoder Loss:  0.18079177 Validation Decoder Loss:  0.53938687
Encoder Loss:  0.17644338  || Decoder Loss:  0.17979373 Validation Decoder Loss:  0.5384278
Encoder Loss:  0.17538585  || Decoder Loss:  0.17870861 Validation Decoder Loss:  0.5357138
Encoder Loss:  0.17429063  || Decoder Loss:  0.17758475 Validation Decoder Loss:  0.533672
Encoder Loss:  0.17348768  || Decoder Loss:  0.17676081 Validation Decoder Loss:  0.53322893
Encoder Loss:  0.17277093  || Decoder Loss:  0.17602527 Validation Decoder Loss:  0.5320465
Encoder Loss:  0.17222333  || Decoder Loss:  0.17546365 Validation Decoder Loss:  0.5317467
Encoder Loss:  0.17165038  || Decoder Loss:  0.17487563 Validation Decoder Loss:  0.5307873
Encoder Loss:  0.1711528  || Decoder Loss:  0.1743649 Validation Decoder Loss:  0.5297489
Encoder Loss:  0.17061417  || Decoder Loss:  0.17381248 Validation Decoder Loss:  0.528781
Encoder Loss:  0.1702047  || Decoder Loss:  0.17339212 Validation Decoder Loss:  0.5276883
Encoder Loss:  0.16979815  || Decoder Loss:  0.17297494 Validation Decoder Loss:  0.52675766
Encoder Loss:  0.16945137  || Decoder Loss:  0.17261912 Validation Decoder Loss:  0.52611303
Encoder Loss:  0.16915311  || Decoder Loss:  0.17231308 Validation Decoder Loss:  0.525499
Encoder Loss:  0.16885388  || Decoder Loss:  0.17200598 Validation Decoder Loss:  0.52468115
Encoder Loss:  0.16870578  || Decoder Loss:  0.17185393 Validation Decoder Loss:  0.52428555
Encoder Loss:  0.1685262  || Decoder Loss:  0.17166984 Validation Decoder Loss:  0.52439904
Encoder Loss:  0.16836117  || Decoder Loss:  0.17150046 Validation Decoder Loss:  0.5242077
Model: bold_synthesis_net_lr_0.000722059319567809 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5242077
Model: "sequential_407"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_270 (Conv3D (None, 82, 5, 14, 1)      20        
_________________________________________________________________
dropout_567 (Dropout)        (None, 82, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_271 (Conv3D (None, 84, 5, 14, 1)      4         
_________________________________________________________________
reshape_109 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_409"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_189 (Conv2D)          (None, 830, 14, 1)        46        
_________________________________________________________________
dropout_569 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_190 (Conv2D)          (None, 420, 14, 1)        412       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_189 (Conv2D (None, 830, 14, 1)        412       
_________________________________________________________________
dropout_571 (Dropout)        (None, 830, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_190 (Conv2D (None, 874, 14, 1)        46        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18973228  || Decoder Loss:  0.25831422 Validation Decoder Loss:  0.5026656
Encoder Loss:  0.18876894  || Decoder Loss:  0.25695547 Validation Decoder Loss:  0.5023623
Encoder Loss:  0.18790206  || Decoder Loss:  0.25570992 Validation Decoder Loss:  0.50211245
Encoder Loss:  0.1870781  || Decoder Loss:  0.25452507 Validation Decoder Loss:  0.50189316
Encoder Loss:  0.18627462  || Decoder Loss:  0.25337026 Validation Decoder Loss:  0.501682
Encoder Loss:  0.18551414  || Decoder Loss:  0.2522697 Validation Decoder Loss:  0.5014762
Encoder Loss:  0.1847935  || Decoder Loss:  0.25122023 Validation Decoder Loss:  0.5012706
Encoder Loss:  0.184102  || Decoder Loss:  0.25021607 Validation Decoder Loss:  0.50105876
Encoder Loss:  0.18342921  || Decoder Loss:  0.2492425 Validation Decoder Loss:  0.50084907
Encoder Loss:  0.18277095  || Decoder Loss:  0.24829726 Validation Decoder Loss:  0.50064135
Encoder Loss:  0.18212394  || Decoder Loss:  0.24737546 Validation Decoder Loss:  0.50044066
Encoder Loss:  0.18148977  || Decoder Loss:  0.2464772 Validation Decoder Loss:  0.5002426
Encoder Loss:  0.1808717  || Decoder Loss:  0.24560869 Validation Decoder Loss:  0.5000415
Encoder Loss:  0.18026827  || Decoder Loss:  0.24476364 Validation Decoder Loss:  0.49984854
Encoder Loss:  0.17968552  || Decoder Loss:  0.24395314 Validation Decoder Loss:  0.49965775
Encoder Loss:  0.17912278  || Decoder Loss:  0.2431734 Validation Decoder Loss:  0.4994744
Encoder Loss:  0.17858449  || Decoder Loss:  0.2424275 Validation Decoder Loss:  0.499308
Encoder Loss:  0.17811134  || Decoder Loss:  0.24176061 Validation Decoder Loss:  0.49915192
Encoder Loss:  0.17768413  || Decoder Loss:  0.24116036 Validation Decoder Loss:  0.4990153
Encoder Loss:  0.17727551  || Decoder Loss:  0.24059014 Validation Decoder Loss:  0.49888435
Encoder Loss:  0.17687884  || Decoder Loss:  0.24003823 Validation Decoder Loss:  0.4987624
Encoder Loss:  0.17649323  || Decoder Loss:  0.23950347 Validation Decoder Loss:  0.4986512
Encoder Loss:  0.17611484  || Decoder Loss:  0.23897867 Validation Decoder Loss:  0.4985629
Encoder Loss:  0.17574629  || Decoder Loss:  0.23846972 Validation Decoder Loss:  0.49848893
Encoder Loss:  0.17539486  || Decoder Loss:  0.23798409 Validation Decoder Loss:  0.49842346
Encoder Loss:  0.17506954  || Decoder Loss:  0.23753509 Validation Decoder Loss:  0.498364
Encoder Loss:  0.17477416  || Decoder Loss:  0.23713104 Validation Decoder Loss:  0.49830297
Encoder Loss:  0.17451116  || Decoder Loss:  0.23677917 Validation Decoder Loss:  0.49823952
Encoder Loss:  0.17426085  || Decoder Loss:  0.23645341 Validation Decoder Loss:  0.49818036
Encoder Loss:  0.17401148  || Decoder Loss:  0.23613146 Validation Decoder Loss:  0.4981251
Encoder Loss:  0.17376097  || Decoder Loss:  0.235809 Validation Decoder Loss:  0.4980797
Encoder Loss:  0.17351344  || Decoder Loss:  0.2354919 Validation Decoder Loss:  0.4980356
Encoder Loss:  0.1732808  || Decoder Loss:  0.23519997 Validation Decoder Loss:  0.49798843
Encoder Loss:  0.17306516  || Decoder Loss:  0.23494072 Validation Decoder Loss:  0.49793682
Encoder Loss:  0.17285249  || Decoder Loss:  0.23468971 Validation Decoder Loss:  0.49788457
Encoder Loss:  0.17263922  || Decoder Loss:  0.2344404 Validation Decoder Loss:  0.49783915
Encoder Loss:  0.172417  || Decoder Loss:  0.234177 Validation Decoder Loss:  0.4978022
Encoder Loss:  0.17219529  || Decoder Loss:  0.23391399 Validation Decoder Loss:  0.49776307
Encoder Loss:  0.17197588  || Decoder Loss:  0.23365691 Validation Decoder Loss:  0.497724
Encoder Loss:  0.17175719  || Decoder Loss:  0.23340301 Validation Decoder Loss:  0.49768376
Model: bold_synthesis_net_lr_0.00015215536953124288 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.49768376
Model: "sequential_411"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_273 (Conv3D (None, 80, 5, 14, 1)      18        
_________________________________________________________________
dropout_573 (Dropout)        (None, 80, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_274 (Conv3D (None, 84, 5, 14, 1)      6         
_________________________________________________________________
reshape_110 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_191 (Conv2D)          (None, 810, 14, 1)        66        
_________________________________________________________________
dropout_575 (Dropout)        (None, 810, 14, 1)        0         
_________________________________________________________________
conv2d_192 (Conv2D)          (None, 420, 14, 1)        392       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_191 (Conv2D (None, 620, 14, 1)        202       
_________________________________________________________________
dropout_577 (Dropout)        (None, 620, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_192 (Conv2D (None, 874, 14, 1)        256       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13754494  || Decoder Loss:  0.25428134 Validation Decoder Loss:  0.50272197
Encoder Loss:  0.13549647  || Decoder Loss:  0.24928932 Validation Decoder Loss:  0.50134647
Encoder Loss:  0.13373952  || Decoder Loss:  0.24512747 Validation Decoder Loss:  0.50052637
Encoder Loss:  0.13243309  || Decoder Loss:  0.24177293 Validation Decoder Loss:  0.5000031
Encoder Loss:  0.13142738  || Decoder Loss:  0.23915581 Validation Decoder Loss:  0.49966606
Encoder Loss:  0.13072184  || Decoder Loss:  0.23724374 Validation Decoder Loss:  0.4993943
Encoder Loss:  0.13012786  || Decoder Loss:  0.23584051 Validation Decoder Loss:  0.4991709
Encoder Loss:  0.12954216  || Decoder Loss:  0.23461011 Validation Decoder Loss:  0.4989862
Encoder Loss:  0.12899375  || Decoder Loss:  0.23359999 Validation Decoder Loss:  0.4987711
Encoder Loss:  0.12844364  || Decoder Loss:  0.23278423 Validation Decoder Loss:  0.49855727
Encoder Loss:  0.1278739  || Decoder Loss:  0.23202989 Validation Decoder Loss:  0.49835774
Encoder Loss:  0.12728372  || Decoder Loss:  0.23133299 Validation Decoder Loss:  0.49817234
Encoder Loss:  0.12666728  || Decoder Loss:  0.2306875 Validation Decoder Loss:  0.49800727
Encoder Loss:  0.12601528  || Decoder Loss:  0.23005858 Validation Decoder Loss:  0.49787062
Encoder Loss:  0.12532347  || Decoder Loss:  0.22944638 Validation Decoder Loss:  0.49776283
Encoder Loss:  0.12458819  || Decoder Loss:  0.22884586 Validation Decoder Loss:  0.49767798
Encoder Loss:  0.12380123  || Decoder Loss:  0.22825468 Validation Decoder Loss:  0.49762526
Encoder Loss:  0.12295537  || Decoder Loss:  0.22766015 Validation Decoder Loss:  0.49761742
Encoder Loss:  0.12204508  || Decoder Loss:  0.2270348 Validation Decoder Loss:  0.4976541
Encoder Loss:  0.1210646  || Decoder Loss:  0.2263956 Validation Decoder Loss:  0.4977441
Encoder Loss:  0.12000756  || Decoder Loss:  0.22573729 Validation Decoder Loss:  0.49790895
Encoder Loss:  0.118876144  || Decoder Loss:  0.22505847 Validation Decoder Loss:  0.49811837
Encoder Loss:  0.117672846  || Decoder Loss:  0.22437632 Validation Decoder Loss:  0.49839225
Encoder Loss:  0.11639057  || Decoder Loss:  0.22371283 Validation Decoder Loss:  0.4986937
Encoder Loss:  0.115026034  || Decoder Loss:  0.2230736 Validation Decoder Loss:  0.4990138
Encoder Loss:  0.11358552  || Decoder Loss:  0.22248621 Validation Decoder Loss:  0.4993044
Encoder Loss:  0.112067625  || Decoder Loss:  0.22194752 Validation Decoder Loss:  0.49958894
Encoder Loss:  0.11047518  || Decoder Loss:  0.22143865 Validation Decoder Loss:  0.49989486
Encoder Loss:  0.10882916  || Decoder Loss:  0.22095713 Validation Decoder Loss:  0.5002503
Encoder Loss:  0.1071253  || Decoder Loss:  0.2204738 Validation Decoder Loss:  0.5006657
Encoder Loss:  0.10537629  || Decoder Loss:  0.21999726 Validation Decoder Loss:  0.5010967
Encoder Loss:  0.103607856  || Decoder Loss:  0.21954341 Validation Decoder Loss:  0.50148606
Encoder Loss:  0.10181769  || Decoder Loss:  0.21911493 Validation Decoder Loss:  0.50189036
Encoder Loss:  0.100006625  || Decoder Loss:  0.21869056 Validation Decoder Loss:  0.5023411
Encoder Loss:  0.09818887  || Decoder Loss:  0.21827285 Validation Decoder Loss:  0.50282264
Encoder Loss:  0.09637474  || Decoder Loss:  0.21787079 Validation Decoder Loss:  0.503322
Encoder Loss:  0.094559  || Decoder Loss:  0.21747616 Validation Decoder Loss:  0.50385714
Encoder Loss:  0.09275635  || Decoder Loss:  0.21708806 Validation Decoder Loss:  0.5044405
Encoder Loss:  0.090989515  || Decoder Loss:  0.21674824 Validation Decoder Loss:  0.5049603
Encoder Loss:  0.08925009  || Decoder Loss:  0.21643977 Validation Decoder Loss:  0.5054117
Model: bold_synthesis_net_lr_0.0005990210384507605 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5054117
Model: "sequential_415"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_276 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_579 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_277 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_111 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_193 (Conv2D)          (None, 540, 14, 1)        336       
_________________________________________________________________
dropout_581 (Dropout)        (None, 540, 14, 1)        0         
_________________________________________________________________
conv2d_194 (Conv2D)          (None, 420, 14, 1)        122       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_193 (Conv2D (None, 740, 14, 1)        322       
_________________________________________________________________
dropout_583 (Dropout)        (None, 740, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_194 (Conv2D (None, 874, 14, 1)        136       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14700085  || Decoder Loss:  0.2499429 Validation Decoder Loss:  0.49467278
Encoder Loss:  0.14117002  || Decoder Loss:  0.23830982 Validation Decoder Loss:  0.49354443
Encoder Loss:  0.13750818  || Decoder Loss:  0.23119968 Validation Decoder Loss:  0.4939479
Encoder Loss:  0.13538036  || Decoder Loss:  0.22719175 Validation Decoder Loss:  0.49435875
Encoder Loss:  0.13358438  || Decoder Loss:  0.22440997 Validation Decoder Loss:  0.4947233
Encoder Loss:  0.13165522  || Decoder Loss:  0.2221302 Validation Decoder Loss:  0.49510825
Encoder Loss:  0.12946405  || Decoder Loss:  0.22018206 Validation Decoder Loss:  0.4955691
Encoder Loss:  0.12688805  || Decoder Loss:  0.21840402 Validation Decoder Loss:  0.49615428
Encoder Loss:  0.12385326  || Decoder Loss:  0.21667644 Validation Decoder Loss:  0.49664584
Encoder Loss:  0.12024811  || Decoder Loss:  0.21491282 Validation Decoder Loss:  0.49747586
Encoder Loss:  0.116112046  || Decoder Loss:  0.21387912 Validation Decoder Loss:  0.49865663
Encoder Loss:  0.111237414  || Decoder Loss:  0.21309687 Validation Decoder Loss:  0.5004055
Encoder Loss:  0.1059004  || Decoder Loss:  0.21253572 Validation Decoder Loss:  0.5026219
Encoder Loss:  0.10058855  || Decoder Loss:  0.21242961 Validation Decoder Loss:  0.5055257
Encoder Loss:  0.09566982  || Decoder Loss:  0.21299915 Validation Decoder Loss:  0.5081956
Encoder Loss:  0.091335334  || Decoder Loss:  0.21370944 Validation Decoder Loss:  0.5097195
Encoder Loss:  0.08767828  || Decoder Loss:  0.21418212 Validation Decoder Loss:  0.50967276
Encoder Loss:  0.0856108  || Decoder Loss:  0.21406849 Validation Decoder Loss:  0.5072067
Encoder Loss:  0.084786005  || Decoder Loss:  0.21328111 Validation Decoder Loss:  0.5043218
Encoder Loss:  0.0841848  || Decoder Loss:  0.21235423 Validation Decoder Loss:  0.5012956
Encoder Loss:  0.08361556  || Decoder Loss:  0.2114038 Validation Decoder Loss:  0.49814147
Encoder Loss:  0.08306861  || Decoder Loss:  0.21048184 Validation Decoder Loss:  0.4952572
Encoder Loss:  0.082558036  || Decoder Loss:  0.20965198 Validation Decoder Loss:  0.49248505
Encoder Loss:  0.08209133  || Decoder Loss:  0.20886455 Validation Decoder Loss:  0.49017698
Encoder Loss:  0.081685424  || Decoder Loss:  0.20812678 Validation Decoder Loss:  0.48834115
Encoder Loss:  0.08135753  || Decoder Loss:  0.2075218 Validation Decoder Loss:  0.48675293
Encoder Loss:  0.081078604  || Decoder Loss:  0.20696831 Validation Decoder Loss:  0.4851439
Encoder Loss:  0.080833055  || Decoder Loss:  0.20640476 Validation Decoder Loss:  0.4837631
Encoder Loss:  0.08062972  || Decoder Loss:  0.20593384 Validation Decoder Loss:  0.48260698
Encoder Loss:  0.080443054  || Decoder Loss:  0.20547517 Validation Decoder Loss:  0.48150757
Encoder Loss:  0.08027215  || Decoder Loss:  0.20502764 Validation Decoder Loss:  0.48042193
Encoder Loss:  0.08011745  || Decoder Loss:  0.20464699 Validation Decoder Loss:  0.47941437
Encoder Loss:  0.07997604  || Decoder Loss:  0.20431522 Validation Decoder Loss:  0.4786126
Encoder Loss:  0.07985148  || Decoder Loss:  0.20404033 Validation Decoder Loss:  0.4778458
Encoder Loss:  0.079733804  || Decoder Loss:  0.20376933 Validation Decoder Loss:  0.47734365
Encoder Loss:  0.079628244  || Decoder Loss:  0.20357819 Validation Decoder Loss:  0.47686327
Encoder Loss:  0.07952918  || Decoder Loss:  0.20340003 Validation Decoder Loss:  0.47631282
Encoder Loss:  0.0794266  || Decoder Loss:  0.20320399 Validation Decoder Loss:  0.47573003
Encoder Loss:  0.07932637  || Decoder Loss:  0.20301732 Validation Decoder Loss:  0.47509602
Encoder Loss:  0.07923406  || Decoder Loss:  0.20285764 Validation Decoder Loss:  0.47460192
Model: bold_synthesis_net_lr_0.00010963868205398437 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.47460192
Model: "sequential_419"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_279 (Conv3D (None, 68, 5, 14, 1)      6         
_________________________________________________________________
dropout_585 (Dropout)        (None, 68, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_280 (Conv3D (None, 84, 5, 14, 1)      18        
_________________________________________________________________
reshape_112 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_195 (Conv2D)          (None, 430, 14, 1)        17        
_________________________________________________________________
dropout_587 (Dropout)        (None, 430, 14, 1)        0         
_________________________________________________________________
conv2d_196 (Conv2D)          (None, 420, 14, 1)        12        
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_195 (Conv2D (None, 710, 14, 1)        292       
_________________________________________________________________
dropout_589 (Dropout)        (None, 710, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_196 (Conv2D (None, 874, 14, 1)        166       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26013753  || Decoder Loss:  0.35186607 Validation Decoder Loss:  0.59920645
Encoder Loss:  0.2503181  || Decoder Loss:  0.34005466 Validation Decoder Loss:  0.5748334
Encoder Loss:  0.24109802  || Decoder Loss:  0.32839757 Validation Decoder Loss:  0.55239916
Encoder Loss:  0.23254657  || Decoder Loss:  0.31719893 Validation Decoder Loss:  0.53118634
Encoder Loss:  0.2239376  || Decoder Loss:  0.30566984 Validation Decoder Loss:  0.51077276
Encoder Loss:  0.21556988  || Decoder Loss:  0.2943462 Validation Decoder Loss:  0.49363002
Encoder Loss:  0.20797834  || Decoder Loss:  0.28393358 Validation Decoder Loss:  0.48112443
Encoder Loss:  0.20204966  || Decoder Loss:  0.27566332 Validation Decoder Loss:  0.47197497
Encoder Loss:  0.19675337  || Decoder Loss:  0.26829833 Validation Decoder Loss:  0.4647094
Encoder Loss:  0.19167496  || Decoder Loss:  0.26125103 Validation Decoder Loss:  0.45875984
Encoder Loss:  0.1868775  || Decoder Loss:  0.25461128 Validation Decoder Loss:  0.45407647
Encoder Loss:  0.18255877  || Decoder Loss:  0.24863538 Validation Decoder Loss:  0.4513054
Encoder Loss:  0.17909853  || Decoder Loss:  0.24380255 Validation Decoder Loss:  0.4499621
Encoder Loss:  0.17633447  || Decoder Loss:  0.23991787 Validation Decoder Loss:  0.44951284
Encoder Loss:  0.17403394  || Decoder Loss:  0.23669007 Validation Decoder Loss:  0.4496997
Encoder Loss:  0.17200914  || Decoder Loss:  0.2338593 Validation Decoder Loss:  0.45015135
Encoder Loss:  0.17015879  || Decoder Loss:  0.23128924 Validation Decoder Loss:  0.4506242
Encoder Loss:  0.16864315  || Decoder Loss:  0.22920148 Validation Decoder Loss:  0.45092842
Encoder Loss:  0.16751648  || Decoder Loss:  0.22768874 Validation Decoder Loss:  0.45108193
Encoder Loss:  0.16658759  || Decoder Loss:  0.2264699 Validation Decoder Loss:  0.45099065
Encoder Loss:  0.16591203  || Decoder Loss:  0.2256389 Validation Decoder Loss:  0.45063287
Encoder Loss:  0.16534048  || Decoder Loss:  0.22498283 Validation Decoder Loss:  0.45020732
Encoder Loss:  0.1647958  || Decoder Loss:  0.22437409 Validation Decoder Loss:  0.44971192
Encoder Loss:  0.16425705  || Decoder Loss:  0.22377506 Validation Decoder Loss:  0.449135
Encoder Loss:  0.16372272  || Decoder Loss:  0.22317752 Validation Decoder Loss:  0.4482991
Encoder Loss:  0.16319951  || Decoder Loss:  0.22260873 Validation Decoder Loss:  0.44762117
Encoder Loss:  0.16271637  || Decoder Loss:  0.22211938 Validation Decoder Loss:  0.44706687
Encoder Loss:  0.16225725  || Decoder Loss:  0.22168088 Validation Decoder Loss:  0.4465558
Encoder Loss:  0.16180414  || Decoder Loss:  0.22126123 Validation Decoder Loss:  0.44603312
Encoder Loss:  0.16138336  || Decoder Loss:  0.22089903 Validation Decoder Loss:  0.44541028
Encoder Loss:  0.16097434  || Decoder Loss:  0.22056572 Validation Decoder Loss:  0.44471395
Encoder Loss:  0.16062038  || Decoder Loss:  0.22033644 Validation Decoder Loss:  0.4441046
Encoder Loss:  0.16029933  || Decoder Loss:  0.22017519 Validation Decoder Loss:  0.44348702
Encoder Loss:  0.15999874  || Decoder Loss:  0.22006047 Validation Decoder Loss:  0.44280675
Encoder Loss:  0.15974037  || Decoder Loss:  0.22002515 Validation Decoder Loss:  0.4420234
Encoder Loss:  0.15948515  || Decoder Loss:  0.22000782 Validation Decoder Loss:  0.4412031
Encoder Loss:  0.15919751  || Decoder Loss:  0.21995254 Validation Decoder Loss:  0.44045934
Encoder Loss:  0.15888003  || Decoder Loss:  0.21987052 Validation Decoder Loss:  0.4397016
Encoder Loss:  0.15855917  || Decoder Loss:  0.21979742 Validation Decoder Loss:  0.43888646
Encoder Loss:  0.1582417  || Decoder Loss:  0.21972632 Validation Decoder Loss:  0.438161
Model: bold_synthesis_net_lr_0.0004438584479666699 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.438161
Model: "sequential_423"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_282 (Conv3D (None, 66, 5, 14, 1)      4         
_________________________________________________________________
dropout_591 (Dropout)        (None, 66, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_283 (Conv3D (None, 84, 5, 14, 1)      20        
_________________________________________________________________
reshape_113 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_197 (Conv2D)          (None, 840, 14, 1)        36        
_________________________________________________________________
dropout_593 (Dropout)        (None, 840, 14, 1)        0         
_________________________________________________________________
conv2d_198 (Conv2D)          (None, 420, 14, 1)        422       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_197 (Conv2D (None, 530, 14, 1)        112       
_________________________________________________________________
dropout_595 (Dropout)        (None, 530, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_198 (Conv2D (None, 874, 14, 1)        346       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24672207  || Decoder Loss:  0.36999375 Validation Decoder Loss:  0.50946677
Encoder Loss:  0.15168813  || Decoder Loss:  0.2510514 Validation Decoder Loss:  0.45852548
Encoder Loss:  0.11962475  || Decoder Loss:  0.2105504 Validation Decoder Loss:  0.47917497
Encoder Loss:  0.10357008  || Decoder Loss:  0.2080927 Validation Decoder Loss:  0.4732245
Encoder Loss:  0.08443787  || Decoder Loss:  0.2032015 Validation Decoder Loss:  0.4692706
Encoder Loss:  0.08135965  || Decoder Loss:  0.20170148 Validation Decoder Loss:  0.46556908
Encoder Loss:  0.080774724  || Decoder Loss:  0.2012155 Validation Decoder Loss:  0.4643187
Encoder Loss:  0.08015925  || Decoder Loss:  0.20039666 Validation Decoder Loss:  0.46276674
Encoder Loss:  0.07939875  || Decoder Loss:  0.19852723 Validation Decoder Loss:  0.4606889
Encoder Loss:  0.07883281  || Decoder Loss:  0.19741759 Validation Decoder Loss:  0.4663067
Encoder Loss:  0.07841169  || Decoder Loss:  0.19681735 Validation Decoder Loss:  0.46264344
Encoder Loss:  0.078107424  || Decoder Loss:  0.19661689 Validation Decoder Loss:  0.4601828
Encoder Loss:  0.07787189  || Decoder Loss:  0.19649129 Validation Decoder Loss:  0.45899236
Encoder Loss:  0.07768554  || Decoder Loss:  0.19641763 Validation Decoder Loss:  0.45777407
Encoder Loss:  0.07753438  || Decoder Loss:  0.19642684 Validation Decoder Loss:  0.4556494
Encoder Loss:  0.07741805  || Decoder Loss:  0.19653317 Validation Decoder Loss:  0.4535533
Encoder Loss:  0.077378206  || Decoder Loss:  0.1968874 Validation Decoder Loss:  0.45074317
Encoder Loss:  0.077389665  || Decoder Loss:  0.19738448 Validation Decoder Loss:  0.44836384
Encoder Loss:  0.07741298  || Decoder Loss:  0.19797659 Validation Decoder Loss:  0.4454704
Encoder Loss:  0.07746101  || Decoder Loss:  0.1986322 Validation Decoder Loss:  0.4431501
Encoder Loss:  0.0775322  || Decoder Loss:  0.19931583 Validation Decoder Loss:  0.44434345
Encoder Loss:  0.07744029  || Decoder Loss:  0.19901416 Validation Decoder Loss:  0.44553277
Encoder Loss:  0.0773666  || Decoder Loss:  0.1987132 Validation Decoder Loss:  0.4482478
Encoder Loss:  0.077232465  || Decoder Loss:  0.19805229 Validation Decoder Loss:  0.44570023
Encoder Loss:  0.07721121  || Decoder Loss:  0.19802329 Validation Decoder Loss:  0.44609013
Encoder Loss:  0.077235594  || Decoder Loss:  0.19824322 Validation Decoder Loss:  0.44492054
Encoder Loss:  0.07730778  || Decoder Loss:  0.19873118 Validation Decoder Loss:  0.4420792
Encoder Loss:  0.077413045  || Decoder Loss:  0.19939485 Validation Decoder Loss:  0.44100615
Encoder Loss:  0.07764759  || Decoder Loss:  0.20076196 Validation Decoder Loss:  0.44139287
Encoder Loss:  0.07786563  || Decoder Loss:  0.20207332 Validation Decoder Loss:  0.44204727
Encoder Loss:  0.07813172  || Decoder Loss:  0.20365244 Validation Decoder Loss:  0.44449753
Encoder Loss:  0.0782265  || Decoder Loss:  0.204244 Validation Decoder Loss:  0.44862214
Encoder Loss:  0.078223266  || Decoder Loss:  0.20428948 Validation Decoder Loss:  0.4559225
Encoder Loss:  0.07811384  || Decoder Loss:  0.20371169 Validation Decoder Loss:  0.46257484
Encoder Loss:  0.0782676  || Decoder Loss:  0.20462957 Validation Decoder Loss:  0.47299424
Encoder Loss:  0.07639478  || Decoder Loss:  0.19408515 Validation Decoder Loss:  0.5465334
Encoder Loss:  0.074658394  || Decoder Loss:  0.18422006 Validation Decoder Loss:  0.541792
Encoder Loss:  0.074407846  || Decoder Loss:  0.18288492 Validation Decoder Loss:  0.53890234
Encoder Loss:  0.07426679  || Decoder Loss:  0.18214853 Validation Decoder Loss:  0.53687507
Encoder Loss:  0.074163824  || Decoder Loss:  0.18159002 Validation Decoder Loss:  0.53507257
Model: bold_synthesis_net_lr_0.0007044373599277869 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.53507257
Model: "sequential_427"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_285 (Conv3D (None, 72, 5, 14, 1)      10        
_________________________________________________________________
dropout_597 (Dropout)        (None, 72, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_286 (Conv3D (None, 84, 5, 14, 1)      14        
_________________________________________________________________
reshape_114 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_199 (Conv2D)          (None, 610, 14, 1)        266       
_________________________________________________________________
dropout_599 (Dropout)        (None, 610, 14, 1)        0         
_________________________________________________________________
conv2d_200 (Conv2D)          (None, 420, 14, 1)        192       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_199 (Conv2D (None, 800, 14, 1)        382       
_________________________________________________________________
dropout_601 (Dropout)        (None, 800, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_200 (Conv2D (None, 874, 14, 1)        76        
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18054718  || Decoder Loss:  0.2351335 Validation Decoder Loss:  0.49061975
Encoder Loss:  0.16385718  || Decoder Loss:  0.21359405 Validation Decoder Loss:  0.49398735
Encoder Loss:  0.14696473  || Decoder Loss:  0.20873259 Validation Decoder Loss:  0.48935863
Encoder Loss:  0.13510042  || Decoder Loss:  0.20687546 Validation Decoder Loss:  0.48825076
Encoder Loss:  0.1342941  || Decoder Loss:  0.20773655 Validation Decoder Loss:  0.48253682
Encoder Loss:  0.13348371  || Decoder Loss:  0.20768882 Validation Decoder Loss:  0.47745696
Encoder Loss:  0.13222517  || Decoder Loss:  0.20588094 Validation Decoder Loss:  0.47852948
Encoder Loss:  0.13128002  || Decoder Loss:  0.20442936 Validation Decoder Loss:  0.48069078
Encoder Loss:  0.13072205  || Decoder Loss:  0.20371962 Validation Decoder Loss:  0.48270932
Encoder Loss:  0.13057077  || Decoder Loss:  0.20380358 Validation Decoder Loss:  0.4864999
Encoder Loss:  0.13191292  || Decoder Loss:  0.20677032 Validation Decoder Loss:  0.4959901
Encoder Loss:  0.13442807  || Decoder Loss:  0.21198225 Validation Decoder Loss:  0.50956935
Encoder Loss:  0.13757154  || Decoder Loss:  0.21835288 Validation Decoder Loss:  0.5318742
Encoder Loss:  0.14178535  || Decoder Loss:  0.22672307 Validation Decoder Loss:  0.55092984
Encoder Loss:  0.14708638  || Decoder Loss:  0.23715498 Validation Decoder Loss:  0.56479037
Encoder Loss:  0.15125562  || Decoder Loss:  0.24535976 Validation Decoder Loss:  0.58947355
Encoder Loss:  0.14790961  || Decoder Loss:  0.2389926 Validation Decoder Loss:  0.58645517
Encoder Loss:  0.13144241  || Decoder Loss:  0.20720312 Validation Decoder Loss:  0.58376426
Encoder Loss:  0.1224584  || Decoder Loss:  0.1899157 Validation Decoder Loss:  0.5820876
Encoder Loss:  0.11988937  || Decoder Loss:  0.18501554 Validation Decoder Loss:  0.58869934
Encoder Loss:  0.11873277  || Decoder Loss:  0.18283163 Validation Decoder Loss:  0.5878203
Encoder Loss:  0.11799715  || Decoder Loss:  0.18144444 Validation Decoder Loss:  0.5868118
Encoder Loss:  0.1176249  || Decoder Loss:  0.18074471 Validation Decoder Loss:  0.5853675
Encoder Loss:  0.11737468  || Decoder Loss:  0.18029252 Validation Decoder Loss:  0.58366835
Encoder Loss:  0.11723515  || Decoder Loss:  0.18003054 Validation Decoder Loss:  0.5824023
Encoder Loss:  0.11715845  || Decoder Loss:  0.1798997 Validation Decoder Loss:  0.5818248
Encoder Loss:  0.117119156  || Decoder Loss:  0.17983176 Validation Decoder Loss:  0.581341
Encoder Loss:  0.1170923  || Decoder Loss:  0.1797945 Validation Decoder Loss:  0.580624
Encoder Loss:  0.11706549  || Decoder Loss:  0.17976376 Validation Decoder Loss:  0.5804248
Encoder Loss:  0.11703794  || Decoder Loss:  0.17972544 Validation Decoder Loss:  0.58011186
Encoder Loss:  0.11700901  || Decoder Loss:  0.17966978 Validation Decoder Loss:  0.5798266
Encoder Loss:  0.11697097  || Decoder Loss:  0.17960937 Validation Decoder Loss:  0.5794717
Encoder Loss:  0.116921335  || Decoder Loss:  0.17952709 Validation Decoder Loss:  0.57912356
Encoder Loss:  0.11687303  || Decoder Loss:  0.17944461 Validation Decoder Loss:  0.5785925
Encoder Loss:  0.116817765  || Decoder Loss:  0.17933933 Validation Decoder Loss:  0.5776839
Encoder Loss:  0.11677025  || Decoder Loss:  0.17926049 Validation Decoder Loss:  0.57704663
Encoder Loss:  0.11674104  || Decoder Loss:  0.17920929 Validation Decoder Loss:  0.576308
Encoder Loss:  0.11671213  || Decoder Loss:  0.17915644 Validation Decoder Loss:  0.5753079
Encoder Loss:  0.116686545  || Decoder Loss:  0.17911728 Validation Decoder Loss:  0.5743669
Encoder Loss:  0.11666268  || Decoder Loss:  0.17907603 Validation Decoder Loss:  0.5738875
Model: bold_synthesis_net_lr_0.0003740659826916636 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.5738875
Model: "sequential_431"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_288 (Conv3D (None, 74, 5, 14, 1)      12        
_________________________________________________________________
dropout_603 (Dropout)        (None, 74, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_289 (Conv3D (None, 84, 5, 14, 1)      12        
_________________________________________________________________
reshape_115 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_201 (Conv2D)          (None, 690, 14, 1)        186       
_________________________________________________________________
dropout_605 (Dropout)        (None, 690, 14, 1)        0         
_________________________________________________________________
conv2d_202 (Conv2D)          (None, 420, 14, 1)        272       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_201 (Conv2D (None, 520, 14, 1)        102       
_________________________________________________________________
dropout_607 (Dropout)        (None, 520, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_202 (Conv2D (None, 874, 14, 1)        356       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16430376  || Decoder Loss:  0.25374466 Validation Decoder Loss:  0.4890066
Encoder Loss:  0.15531774  || Decoder Loss:  0.23841484 Validation Decoder Loss:  0.4883593
Encoder Loss:  0.1503898  || Decoder Loss:  0.22988316 Validation Decoder Loss:  0.4902389
Encoder Loss:  0.14804378  || Decoder Loss:  0.2256277 Validation Decoder Loss:  0.49150562
Encoder Loss:  0.14644416  || Decoder Loss:  0.22305954 Validation Decoder Loss:  0.49211818
Encoder Loss:  0.14483842  || Decoder Loss:  0.22100152 Validation Decoder Loss:  0.49290016
Encoder Loss:  0.14291072  || Decoder Loss:  0.219063 Validation Decoder Loss:  0.49395356
Encoder Loss:  0.14053021  || Decoder Loss:  0.21725167 Validation Decoder Loss:  0.49515074
Encoder Loss:  0.13758798  || Decoder Loss:  0.21563883 Validation Decoder Loss:  0.49602845
Encoder Loss:  0.13397552  || Decoder Loss:  0.21443488 Validation Decoder Loss:  0.4983762
Encoder Loss:  0.12952384  || Decoder Loss:  0.21374905 Validation Decoder Loss:  0.49935925
Encoder Loss:  0.123402394  || Decoder Loss:  0.21185529 Validation Decoder Loss:  0.5010246
Encoder Loss:  0.11711525  || Decoder Loss:  0.21102652 Validation Decoder Loss:  0.5035245
Encoder Loss:  0.11145017  || Decoder Loss:  0.21082953 Validation Decoder Loss:  0.50464296
Encoder Loss:  0.10670628  || Decoder Loss:  0.21059673 Validation Decoder Loss:  0.5025226
Encoder Loss:  0.104580194  || Decoder Loss:  0.2099917 Validation Decoder Loss:  0.5002722
Encoder Loss:  0.10347052  || Decoder Loss:  0.2095676 Validation Decoder Loss:  0.4984121
Encoder Loss:  0.10260879  || Decoder Loss:  0.20932496 Validation Decoder Loss:  0.49613807
Encoder Loss:  0.10192495  || Decoder Loss:  0.20930904 Validation Decoder Loss:  0.4936076
Encoder Loss:  0.1013391  || Decoder Loss:  0.20929939 Validation Decoder Loss:  0.4910733
Encoder Loss:  0.10064684  || Decoder Loss:  0.20882139 Validation Decoder Loss:  0.48827007
Encoder Loss:  0.099927604  || Decoder Loss:  0.20815308 Validation Decoder Loss:  0.48522183
Encoder Loss:  0.09931783  || Decoder Loss:  0.2075821 Validation Decoder Loss:  0.48262843
Encoder Loss:  0.0987204  || Decoder Loss:  0.20674257 Validation Decoder Loss:  0.4821916
Encoder Loss:  0.09824924  || Decoder Loss:  0.2061906 Validation Decoder Loss:  0.4807786
Encoder Loss:  0.09788232  || Decoder Loss:  0.20580354 Validation Decoder Loss:  0.47863638
Encoder Loss:  0.097589724  || Decoder Loss:  0.20548171 Validation Decoder Loss:  0.4765844
Encoder Loss:  0.09737158  || Decoder Loss:  0.20525841 Validation Decoder Loss:  0.47487965
Encoder Loss:  0.09719745  || Decoder Loss:  0.20504974 Validation Decoder Loss:  0.47362736
Encoder Loss:  0.09705796  || Decoder Loss:  0.20489183 Validation Decoder Loss:  0.47240296
Encoder Loss:  0.09691815  || Decoder Loss:  0.20471333 Validation Decoder Loss:  0.47158718
Encoder Loss:  0.096777394  || Decoder Loss:  0.20452206 Validation Decoder Loss:  0.47071892
Encoder Loss:  0.09665609  || Decoder Loss:  0.20438948 Validation Decoder Loss:  0.47010052
Encoder Loss:  0.09652665  || Decoder Loss:  0.20420113 Validation Decoder Loss:  0.47009575
Encoder Loss:  0.096400745  || Decoder Loss:  0.20402537 Validation Decoder Loss:  0.47028226
Encoder Loss:  0.09626527  || Decoder Loss:  0.20382075 Validation Decoder Loss:  0.47114676
Encoder Loss:  0.09613601  || Decoder Loss:  0.20363729 Validation Decoder Loss:  0.47179523
Encoder Loss:  0.09599224  || Decoder Loss:  0.20339736 Validation Decoder Loss:  0.4721007
Encoder Loss:  0.09587122  || Decoder Loss:  0.20324354 Validation Decoder Loss:  0.47173867
Encoder Loss:  0.09575777  || Decoder Loss:  0.20311593 Validation Decoder Loss:  0.47148108
Model: bold_synthesis_net_lr_0.00040430993731579767 Train Intances: 2500 | Validation Instances: 100 | Validation Loss: 0.47148108
Model: "sequential_435"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_291 (Conv3D (None, 76, 5, 14, 1)      14        
_________________________________________________________________
dropout_609 (Dropout)        (None, 76, 5, 14, 1)      0         
_________________________________________________________________
conv3d_transpose_292 (Conv3D (None, 84, 5, 14, 1)      10        
_________________________________________________________________
reshape_116 (Reshape)        (None, 420, 14, 1)        0         
=================================================================
Total params: 24
Trainable params: 24
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_203 (Conv2D)          (None, 680, 14, 1)        196       
_________________________________________________________________
dropout_611 (Dropout)        (None, 680, 14, 1)        0         
_________________________________________________________________
conv2d_204 (Conv2D)          (None, 420, 14, 1)        262       
=================================================================
Total params: 458
Trainable params: 458
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_438"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_203 (Conv2D (None, 870, 14, 1)        33        
_________________________________________________________________
dropout_613 (Dropout)        (None, 870, 14, 1)        0         
_________________________________________________________________
conv2d_transpose_204 (Conv2D (None, 874, 14, 1)        6         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19714  || Decoder Loss:  0.24598621 Validation Decoder Loss:  0.5403101
Encoder Loss:  0.18715145  || Decoder Loss:  0.23614153 Validation Decoder Loss:  0.5574862
Encoder Loss:  0.16320047  || Decoder Loss:  0.22568394 Validation Decoder Loss:  0.6213434
Encoder Loss:  0.15365413  || Decoder Loss:  0.21509795 Validation Decoder Loss:  0.6048314
Encoder Loss:  0.15002526  || Decoder Loss:  0.20966482 Validation Decoder Loss:  0.5965352
