Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/32/export/20130410320002_Segmentation_bin.vhdr...
Setting channel info structure...
Reading 0 ... 162022  =      0.000 ...   648.088 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/35/export/20130424350002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 197234  =      0.000 ...   788.936 secs...
(32, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/36/export/20130425360002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 181949  =      0.000 ...   727.796 secs...
(48, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/37/export/20130426370002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 195159  =      0.000 ...   780.636 secs...
(64, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/38/export/20130105380002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 179384  =      0.000 ...   717.536 secs...
(80, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/39/export/20130501390002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 182129  =      0.000 ...   728.516 secs...
(96, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/40/export/20130510400002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 173914  =      0.000 ...   695.656 secs...
(112, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/42/export/20130523420002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 184909  =      0.000 ...   739.636 secs...
(128, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/43/export/20130529430002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 170594  =      0.000 ...   682.376 secs...
(144, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/44/export/20130605440002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 169854  =      0.000 ...   679.416 secs...
(160, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/45/export/20130627450002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 168099  =      0.000 ...   672.396 secs...
(16, 2607, 20)
Extracting parameters from /home/davidcalhas/eeg_to_fmri/datasets/01/EEG/46/export/20130703460002_Pulse_Artifact_Correction_bin.vhdr...
Setting channel info structure...
Reading 0 ... 172264  =      0.000 ...   689.056 secs...
2019-11-19 23:35:21.221059: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-19 23:35:21.224358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-19 23:35:21.224508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 23:35:21.225553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-19 23:35:21.226633: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-19 23:35:21.226838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-19 23:35:21.227836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-19 23:35:21.228355: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-19 23:35:21.230438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-19 23:35:21.231613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-19 23:35:21.231802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-11-19 23:35:21.259785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
2019-11-19 23:35:21.260811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb0508bf70 executing computations on platform Host. Devices:
2019-11-19 23:35:21.260842: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-19 23:35:21.261725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:65:00.0
2019-11-19 23:35:21.261761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 23:35:21.261772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-11-19 23:35:21.261781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-11-19 23:35:21.261791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-11-19 23:35:21.261800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-11-19 23:35:21.261809: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-11-19 23:35:21.261819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-19 23:35:21.263245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-19 23:35:21.263270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-11-19 23:35:21.335512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-19 23:35:21.335540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-19 23:35:21.335545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-19 23:35:21.337336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8064 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-11-19 23:35:21.338643: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb0938f880 executing computations on platform CUDA. Devices:
2019-11-19 23:35:21.338662: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-11-19 23:35:22.069498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
 /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
WARNING:tensorflow:From /home/davidcalhas/anaconda3/envs/fmri_eeg/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
(32, 2607, 20)
Finished Loading Data
Pairs Created
Optimizing at level  1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose (Conv3DTran (None, 70, 16, 20, 1)     57        
_________________________________________________________________
reshape (Reshape)            (None, 1120, 20, 1)       0         
=================================================================
Total params: 57
Trainable params: 57
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1120, 20, 1)       370       
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose (Conv2DTran (None, 2607, 20, 1)       1489      
=================================================================
Total params: 1,489
Trainable params: 1,489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41895688  || Decoder Loss:  0.5711034 Validation Decoder Loss:  1.5423224
Encoder Loss:  0.3081623  || Decoder Loss:  0.46796933 Validation Decoder Loss:  1.2225225
Encoder Loss:  0.27700207  || Decoder Loss:  0.44038174 Validation Decoder Loss:  0.6223116
Encoder Loss:  0.14248806  || Decoder Loss:  0.19040398 Validation Decoder Loss:  0.36405376
Encoder Loss:  0.058573812  || Decoder Loss:  0.028036 Validation Decoder Loss:  0.34562194
Encoder Loss:  0.06653814  || Decoder Loss:  0.050678354 Validation Decoder Loss:  0.34328777
Encoder Loss:  0.048216853  || Decoder Loss:  0.027051117 Validation Decoder Loss:  0.35820714
Encoder Loss:  0.042067505  || Decoder Loss:  0.028210146 Validation Decoder Loss:  0.34743872
Encoder Loss:  0.04052448  || Decoder Loss:  0.028806701 Validation Decoder Loss:  0.35301512
Encoder Loss:  0.04026513  || Decoder Loss:  0.027998624 Validation Decoder Loss:  0.3529389
Encoder Loss:  0.039782807  || Decoder Loss:  0.027768673 Validation Decoder Loss:  0.35459366
Encoder Loss:  0.040039305  || Decoder Loss:  0.027902687 Validation Decoder Loss:  0.35447568
Encoder Loss:  0.039976522  || Decoder Loss:  0.028185846 Validation Decoder Loss:  0.35648745
Encoder Loss:  0.040512763  || Decoder Loss:  0.028702063 Validation Decoder Loss:  0.34612024
Encoder Loss:  0.039628018  || Decoder Loss:  0.027990537 Validation Decoder Loss:  0.35008684
Encoder Loss:  0.039488927  || Decoder Loss:  0.027759306 Validation Decoder Loss:  0.35047686
Encoder Loss:  0.03948724  || Decoder Loss:  0.027847221 Validation Decoder Loss:  0.34885088
Encoder Loss:  0.03961762  || Decoder Loss:  0.028127199 Validation Decoder Loss:  0.35116494
Encoder Loss:  0.039955758  || Decoder Loss:  0.028609205 Validation Decoder Loss:  0.38844967
Encoder Loss:  0.040223937  || Decoder Loss:  0.028688047 Validation Decoder Loss:  0.34535855
Encoder Loss:  0.039512325  || Decoder Loss:  0.028412547 Validation Decoder Loss:  0.34421864
Encoder Loss:  0.03948108  || Decoder Loss:  0.02864751 Validation Decoder Loss:  0.34346402
Encoder Loss:  0.039594278  || Decoder Loss:  0.028740166 Validation Decoder Loss:  0.34298065
Encoder Loss:  0.040505074  || Decoder Loss:  0.03005438 Validation Decoder Loss:  0.33831272
Encoder Loss:  0.0399441  || Decoder Loss:  0.029175255 Validation Decoder Loss:  0.34059605
Encoder Loss:  0.040092155  || Decoder Loss:  0.029512437 Validation Decoder Loss:  0.37063056
Encoder Loss:  0.04921267  || Decoder Loss:  0.04552814 Validation Decoder Loss:  0.33697426
Encoder Loss:  0.043388043  || Decoder Loss:  0.0360465 Validation Decoder Loss:  0.33673614
Encoder Loss:  0.04124268  || Decoder Loss:  0.03238409 Validation Decoder Loss:  0.33672273
Encoder Loss:  0.040017094  || Decoder Loss:  0.029842928 Validation Decoder Loss:  0.33744812
Encoder Loss:  0.04428261  || Decoder Loss:  0.03743224 Validation Decoder Loss:  0.35768533
Encoder Loss:  0.04397352  || Decoder Loss:  0.036764286 Validation Decoder Loss:  0.3359836
Encoder Loss:  0.04306163  || Decoder Loss:  0.035337072 Validation Decoder Loss:  0.34450147
Encoder Loss:  0.07473434  || Decoder Loss:  0.08713498 Validation Decoder Loss:  0.3310122
Encoder Loss:  0.043401156  || Decoder Loss:  0.036671683 Validation Decoder Loss:  0.33296537
Encoder Loss:  0.04320366  || Decoder Loss:  0.036385436 Validation Decoder Loss:  0.33278164
Encoder Loss:  0.04310428  || Decoder Loss:  0.036193527 Validation Decoder Loss:  0.33274108
Encoder Loss:  0.042881314  || Decoder Loss:  0.035726655 Validation Decoder Loss:  0.33287454
Encoder Loss:  0.042862076  || Decoder Loss:  0.035628434 Validation Decoder Loss:  0.33306286
Encoder Loss:  0.0433281  || Decoder Loss:  0.036297623 Validation Decoder Loss:  0.33684665
Model: siamese_net_lr_0.4733248020438244 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33684665
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_1 (Conv3DTr (None, 395, 6, 20, 1)     539       
_________________________________________________________________
reshape_1 (Reshape)          (None, 2370, 20, 1)       0         
=================================================================
Total params: 539
Trainable params: 539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_1 (Conv2DTr (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23775256  || Decoder Loss:  0.45756745 Validation Decoder Loss:  1.1274331
Encoder Loss:  0.16710453  || Decoder Loss:  0.34085664 Validation Decoder Loss:  0.315417
Encoder Loss:  0.04631947  || Decoder Loss:  0.03811948 Validation Decoder Loss:  0.31180784
Encoder Loss:  0.045264482  || Decoder Loss:  0.036908146 Validation Decoder Loss:  0.3141061
Encoder Loss:  0.048735972  || Decoder Loss:  0.03916955 Validation Decoder Loss:  0.36776507
Encoder Loss:  0.045347497  || Decoder Loss:  0.036975373 Validation Decoder Loss:  0.3646992
Encoder Loss:  0.045680024  || Decoder Loss:  0.037069302 Validation Decoder Loss:  0.3669911
Encoder Loss:  0.045135498  || Decoder Loss:  0.036697585 Validation Decoder Loss:  0.3639543
Encoder Loss:  0.048674893  || Decoder Loss:  0.039085753 Validation Decoder Loss:  0.365439
Encoder Loss:  0.045046724  || Decoder Loss:  0.036779955 Validation Decoder Loss:  0.3166024
Encoder Loss:  0.04564444  || Decoder Loss:  0.03692797 Validation Decoder Loss:  0.31569323
Encoder Loss:  0.044874858  || Decoder Loss:  0.036376134 Validation Decoder Loss:  0.31849653
Encoder Loss:  0.04541584  || Decoder Loss:  0.03663104 Validation Decoder Loss:  0.31775403
Encoder Loss:  0.045758776  || Decoder Loss:  0.036711145 Validation Decoder Loss:  0.31821477
Encoder Loss:  0.047050457  || Decoder Loss:  0.037561454 Validation Decoder Loss:  0.31828833
Encoder Loss:  0.044771448  || Decoder Loss:  0.036127776 Validation Decoder Loss:  0.31946093
Encoder Loss:  0.044787124  || Decoder Loss:  0.03600353 Validation Decoder Loss:  0.32036167
Encoder Loss:  0.044988602  || Decoder Loss:  0.036142603 Validation Decoder Loss:  0.31959045
Encoder Loss:  0.046954136  || Decoder Loss:  0.036813814 Validation Decoder Loss:  0.34978047
Encoder Loss:  0.045079842  || Decoder Loss:  0.036358785 Validation Decoder Loss:  0.32195282
Encoder Loss:  0.044550072  || Decoder Loss:  0.035774514 Validation Decoder Loss:  0.32223654
Encoder Loss:  0.044690024  || Decoder Loss:  0.035769492 Validation Decoder Loss:  0.32230598
Encoder Loss:  0.047267314  || Decoder Loss:  0.036754157 Validation Decoder Loss:  0.32346988
Encoder Loss:  0.0445727  || Decoder Loss:  0.035696495 Validation Decoder Loss:  0.32365382
Encoder Loss:  0.044595663  || Decoder Loss:  0.035663806 Validation Decoder Loss:  0.3224259
Encoder Loss:  0.044966713  || Decoder Loss:  0.03578379 Validation Decoder Loss:  0.32419786
Encoder Loss:  0.04484326  || Decoder Loss:  0.035584725 Validation Decoder Loss:  0.32214236
Encoder Loss:  0.04469764  || Decoder Loss:  0.035638668 Validation Decoder Loss:  0.32540563
Encoder Loss:  0.04478176  || Decoder Loss:  0.035528667 Validation Decoder Loss:  0.32344076
Encoder Loss:  0.044904027  || Decoder Loss:  0.035695147 Validation Decoder Loss:  0.3253011
Encoder Loss:  0.04463695  || Decoder Loss:  0.03552583 Validation Decoder Loss:  0.32688773
Encoder Loss:  0.044492554  || Decoder Loss:  0.03543277 Validation Decoder Loss:  0.32756424
Encoder Loss:  0.044804968  || Decoder Loss:  0.035550028 Validation Decoder Loss:  0.32787052
Encoder Loss:  0.04447571  || Decoder Loss:  0.035395104 Validation Decoder Loss:  0.32822913
Encoder Loss:  0.044590913  || Decoder Loss:  0.035391655 Validation Decoder Loss:  0.32848153
Encoder Loss:  0.044693843  || Decoder Loss:  0.035394154 Validation Decoder Loss:  0.32940203
Encoder Loss:  0.04752317  || Decoder Loss:  0.036025017 Validation Decoder Loss:  0.32853281
Encoder Loss:  0.04436966  || Decoder Loss:  0.035360564 Validation Decoder Loss:  0.32883167
Encoder Loss:  0.04465295  || Decoder Loss:  0.035432905 Validation Decoder Loss:  0.3290112
Encoder Loss:  0.044367805  || Decoder Loss:  0.035344757 Validation Decoder Loss:  0.32941517
Model: siamese_net_lr_0.19456574118521525 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32941517
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_2 (Conv3DTr (None, 334, 5, 20, 1)     272       
_________________________________________________________________
reshape_2 (Reshape)          (None, 1670, 20, 1)       0         
=================================================================
Total params: 272
Trainable params: 272
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 1670, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_2 (Conv2DTr (None, 2607, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30029777  || Decoder Loss:  0.34543633 Validation Decoder Loss:  0.6212416
Encoder Loss:  0.14356668  || Decoder Loss:  0.16087797 Validation Decoder Loss:  0.36947775
Encoder Loss:  0.07759608  || Decoder Loss:  0.077162474 Validation Decoder Loss:  0.43817565
Encoder Loss:  0.06220097  || Decoder Loss:  0.061553497 Validation Decoder Loss:  0.32180974
Encoder Loss:  0.04970786  || Decoder Loss:  0.04762968 Validation Decoder Loss:  0.33738363
Encoder Loss:  0.04331516  || Decoder Loss:  0.040928494 Validation Decoder Loss:  0.34832293
Encoder Loss:  0.041437864  || Decoder Loss:  0.038724825 Validation Decoder Loss:  0.36881775
Encoder Loss:  0.042478066  || Decoder Loss:  0.039875213 Validation Decoder Loss:  0.33493483
Encoder Loss:  0.039506696  || Decoder Loss:  0.036206435 Validation Decoder Loss:  0.32284367
Encoder Loss:  0.04108273  || Decoder Loss:  0.038275022 Validation Decoder Loss:  0.37303618
Encoder Loss:  0.043034807  || Decoder Loss:  0.040465966 Validation Decoder Loss:  0.34002393
Encoder Loss:  0.039256465  || Decoder Loss:  0.03533443 Validation Decoder Loss:  0.32320815
Encoder Loss:  0.041046187  || Decoder Loss:  0.03806513 Validation Decoder Loss:  0.35182294
Encoder Loss:  0.039984018  || Decoder Loss:  0.03679376 Validation Decoder Loss:  0.32314712
Encoder Loss:  0.040033694  || Decoder Loss:  0.03692322 Validation Decoder Loss:  0.3504554
Encoder Loss:  0.03927201  || Decoder Loss:  0.03601481 Validation Decoder Loss:  0.32353035
Encoder Loss:  0.03971354  || Decoder Loss:  0.036550745 Validation Decoder Loss:  0.33031112
Encoder Loss:  0.03792352  || Decoder Loss:  0.0342318 Validation Decoder Loss:  0.323593
Encoder Loss:  0.039368458  || Decoder Loss:  0.036138747 Validation Decoder Loss:  0.36549285
Encoder Loss:  0.040911946  || Decoder Loss:  0.03795786 Validation Decoder Loss:  0.3653508
Encoder Loss:  0.041128226  || Decoder Loss:  0.03821513 Validation Decoder Loss:  0.34481436
Encoder Loss:  0.038830377  || Decoder Loss:  0.03542654 Validation Decoder Loss:  0.34975004
Encoder Loss:  0.03863004  || Decoder Loss:  0.035158064 Validation Decoder Loss:  0.3336904
Encoder Loss:  0.037651483  || Decoder Loss:  0.033802256 Validation Decoder Loss:  0.3302073
Encoder Loss:  0.03772969  || Decoder Loss:  0.033995643 Validation Decoder Loss:  0.32279778
Encoder Loss:  0.039633602  || Decoder Loss:  0.036385022 Validation Decoder Loss:  0.32395455
Encoder Loss:  0.040287517  || Decoder Loss:  0.03723631 Validation Decoder Loss:  0.35090607
Encoder Loss:  0.040425863  || Decoder Loss:  0.03665719 Validation Decoder Loss:  0.32403308
Encoder Loss:  0.044021912  || Decoder Loss:  0.039484054 Validation Decoder Loss:  0.32879585
Encoder Loss:  0.048434686  || Decoder Loss:  0.045405507 Validation Decoder Loss:  0.32030264
Encoder Loss:  0.046033908  || Decoder Loss:  0.043215394 Validation Decoder Loss:  0.3821302
Encoder Loss:  0.044731006  || Decoder Loss:  0.042317625 Validation Decoder Loss:  0.3843059
Encoder Loss:  0.04493835  || Decoder Loss:  0.042875253 Validation Decoder Loss:  0.3436501
Encoder Loss:  0.040044066  || Decoder Loss:  0.036672205 Validation Decoder Loss:  0.31971663
Encoder Loss:  0.04056807  || Decoder Loss:  0.03763885 Validation Decoder Loss:  0.3284453
Encoder Loss:  0.040718574  || Decoder Loss:  0.037890326 Validation Decoder Loss:  0.3597627
Encoder Loss:  0.041251376  || Decoder Loss:  0.038582526 Validation Decoder Loss:  0.35657275
Encoder Loss:  0.04042528  || Decoder Loss:  0.037532948 Validation Decoder Loss:  0.34450555
Encoder Loss:  0.039037097  || Decoder Loss:  0.035730008 Validation Decoder Loss:  0.347361
Encoder Loss:  0.038889114  || Decoder Loss:  0.035505213 Validation Decoder Loss:  0.34773868
Model: siamese_net_lr_0.27461387249708485 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34773868
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_3 (Conv3DTr (None, 484, 5, 20, 1)     359       
_________________________________________________________________
reshape_3 (Reshape)          (None, 2420, 20, 1)       0         
=================================================================
Total params: 359
Trainable params: 359
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_3 (Conv2DTr (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12541166  || Decoder Loss:  0.07038047 Validation Decoder Loss:  0.33211443
Encoder Loss:  0.08582516  || Decoder Loss:  0.07932595 Validation Decoder Loss:  0.28181916
Encoder Loss:  0.055546165  || Decoder Loss:  0.037049096 Validation Decoder Loss:  0.33293426
Encoder Loss:  0.048614636  || Decoder Loss:  0.0354138 Validation Decoder Loss:  0.3395699
Encoder Loss:  0.0480761  || Decoder Loss:  0.03536603 Validation Decoder Loss:  0.3370863
Encoder Loss:  0.04797295  || Decoder Loss:  0.03544291 Validation Decoder Loss:  0.33628654
Encoder Loss:  0.047477268  || Decoder Loss:  0.03534317 Validation Decoder Loss:  0.33821344
Encoder Loss:  0.048751548  || Decoder Loss:  0.03543173 Validation Decoder Loss:  0.34035355
Encoder Loss:  0.047664717  || Decoder Loss:  0.035532538 Validation Decoder Loss:  0.3223313
Encoder Loss:  0.048996996  || Decoder Loss:  0.035758402 Validation Decoder Loss:  0.3163396
Encoder Loss:  0.04813678  || Decoder Loss:  0.03594967 Validation Decoder Loss:  0.3160859
Encoder Loss:  0.04796914  || Decoder Loss:  0.035958264 Validation Decoder Loss:  0.3448146
Encoder Loss:  0.048059836  || Decoder Loss:  0.035937294 Validation Decoder Loss:  0.3374904
Encoder Loss:  0.04774695  || Decoder Loss:  0.035736643 Validation Decoder Loss:  0.32869482
Encoder Loss:  0.047966883  || Decoder Loss:  0.035908353 Validation Decoder Loss:  0.3424259
Encoder Loss:  0.049961742  || Decoder Loss:  0.036164977 Validation Decoder Loss:  0.36053914
Encoder Loss:  0.049664088  || Decoder Loss:  0.036314033 Validation Decoder Loss:  0.3180196
Encoder Loss:  0.048112653  || Decoder Loss:  0.036075756 Validation Decoder Loss:  0.34503233
Encoder Loss:  0.04747288  || Decoder Loss:  0.035670083 Validation Decoder Loss:  0.33417988
Encoder Loss:  0.04774227  || Decoder Loss:  0.03569566 Validation Decoder Loss:  0.3453694
Encoder Loss:  0.047661964  || Decoder Loss:  0.035699856 Validation Decoder Loss:  0.3452803
Encoder Loss:  0.04753946  || Decoder Loss:  0.03567604 Validation Decoder Loss:  0.33450878
Encoder Loss:  0.047515307  || Decoder Loss:  0.035650037 Validation Decoder Loss:  0.32362264
Encoder Loss:  0.048228607  || Decoder Loss:  0.03583701 Validation Decoder Loss:  0.3412478
Encoder Loss:  0.048202462  || Decoder Loss:  0.035752095 Validation Decoder Loss:  0.33701074
Encoder Loss:  0.049485683  || Decoder Loss:  0.03602517 Validation Decoder Loss:  0.3363716
Encoder Loss:  0.052262038  || Decoder Loss:  0.03737999 Validation Decoder Loss:  0.36357954
Encoder Loss:  0.047792163  || Decoder Loss:  0.0359265 Validation Decoder Loss:  0.335316
Encoder Loss:  0.047818292  || Decoder Loss:  0.035624757 Validation Decoder Loss:  0.3340031
Encoder Loss:  0.04825652  || Decoder Loss:  0.035824962 Validation Decoder Loss:  0.35044408
Encoder Loss:  0.047825642  || Decoder Loss:  0.035682905 Validation Decoder Loss:  0.3255886
Encoder Loss:  0.04752633  || Decoder Loss:  0.03564029 Validation Decoder Loss:  0.331998
Encoder Loss:  0.04751478  || Decoder Loss:  0.035631698 Validation Decoder Loss:  0.32493246
Encoder Loss:  0.048090678  || Decoder Loss:  0.035663445 Validation Decoder Loss:  0.3323077
Encoder Loss:  0.04759119  || Decoder Loss:  0.03566335 Validation Decoder Loss:  0.3232392
Encoder Loss:  0.0479338  || Decoder Loss:  0.035659377 Validation Decoder Loss:  0.35788247
Encoder Loss:  0.047954854  || Decoder Loss:  0.035802864 Validation Decoder Loss:  0.32197836
Encoder Loss:  0.04945919  || Decoder Loss:  0.036124617 Validation Decoder Loss:  0.3422367
Encoder Loss:  0.047636792  || Decoder Loss:  0.035624187 Validation Decoder Loss:  0.33457842
Encoder Loss:  0.04792459  || Decoder Loss:  0.03563736 Validation Decoder Loss:  0.34357512
Model: siamese_net_lr_0.16709019871685238 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34357512
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_4 (Conv3DTr (None, 257, 10, 20, 1)    11        
_________________________________________________________________
reshape_4 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_4 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19011502  || Decoder Loss:  0.12038801 Validation Decoder Loss:  1.6659051
Encoder Loss:  0.10546773  || Decoder Loss:  0.09925094 Validation Decoder Loss:  0.33230233
Encoder Loss:  0.056475  || Decoder Loss:  0.03894882 Validation Decoder Loss:  0.33298624
Encoder Loss:  0.05035045  || Decoder Loss:  0.03838421 Validation Decoder Loss:  0.33210862
Encoder Loss:  0.04661189  || Decoder Loss:  0.037658297 Validation Decoder Loss:  0.33222032
Encoder Loss:  0.04690423  || Decoder Loss:  0.037425328 Validation Decoder Loss:  0.33225864
Encoder Loss:  0.04652495  || Decoder Loss:  0.03724255 Validation Decoder Loss:  0.3320685
Encoder Loss:  0.049179163  || Decoder Loss:  0.037045296 Validation Decoder Loss:  0.33199584
Encoder Loss:  0.046482448  || Decoder Loss:  0.0368014 Validation Decoder Loss:  0.3319854
Encoder Loss:  0.04513041  || Decoder Loss:  0.03662082 Validation Decoder Loss:  0.3319133
Encoder Loss:  0.04485862  || Decoder Loss:  0.036403686 Validation Decoder Loss:  0.33185285
Encoder Loss:  0.044294845  || Decoder Loss:  0.036269367 Validation Decoder Loss:  0.331846
Encoder Loss:  0.04489086  || Decoder Loss:  0.036135174 Validation Decoder Loss:  0.33182552
Encoder Loss:  0.044174682  || Decoder Loss:  0.03602659 Validation Decoder Loss:  0.33180004
Encoder Loss:  0.043389793  || Decoder Loss:  0.035902336 Validation Decoder Loss:  0.33176547
Encoder Loss:  0.04423647  || Decoder Loss:  0.035849262 Validation Decoder Loss:  0.3317638
Encoder Loss:  0.043494042  || Decoder Loss:  0.035775922 Validation Decoder Loss:  0.3317502
Encoder Loss:  0.042944334  || Decoder Loss:  0.035698608 Validation Decoder Loss:  0.3317328
Encoder Loss:  0.043511085  || Decoder Loss:  0.035680197 Validation Decoder Loss:  0.3317238
Encoder Loss:  0.04434321  || Decoder Loss:  0.03565987 Validation Decoder Loss:  0.3317154
Encoder Loss:  0.042960323  || Decoder Loss:  0.035598088 Validation Decoder Loss:  0.33169574
Encoder Loss:  0.043030266  || Decoder Loss:  0.03557977 Validation Decoder Loss:  0.33168775
Encoder Loss:  0.042947974  || Decoder Loss:  0.0355551 Validation Decoder Loss:  0.33168063
Encoder Loss:  0.043086905  || Decoder Loss:  0.0355452 Validation Decoder Loss:  0.33167744
Encoder Loss:  0.043026198  || Decoder Loss:  0.035523012 Validation Decoder Loss:  0.33166707
Encoder Loss:  0.043254666  || Decoder Loss:  0.035521563 Validation Decoder Loss:  0.33167538
Encoder Loss:  0.042652637  || Decoder Loss:  0.03549992 Validation Decoder Loss:  0.33165333
Encoder Loss:  0.042855702  || Decoder Loss:  0.035487138 Validation Decoder Loss:  0.33165377
Encoder Loss:  0.04277061  || Decoder Loss:  0.035486955 Validation Decoder Loss:  0.33164477
Encoder Loss:  0.04388496  || Decoder Loss:  0.035482377 Validation Decoder Loss:  0.3316475
Encoder Loss:  0.042524956  || Decoder Loss:  0.035466827 Validation Decoder Loss:  0.33162606
Encoder Loss:  0.042767707  || Decoder Loss:  0.035457585 Validation Decoder Loss:  0.33162808
Encoder Loss:  0.04285002  || Decoder Loss:  0.035464305 Validation Decoder Loss:  0.33162025
Encoder Loss:  0.042556167  || Decoder Loss:  0.03544469 Validation Decoder Loss:  0.33162057
Encoder Loss:  0.04285959  || Decoder Loss:  0.035451308 Validation Decoder Loss:  0.33162585
Encoder Loss:  0.043438286  || Decoder Loss:  0.035449363 Validation Decoder Loss:  0.3316146
Encoder Loss:  0.04236041  || Decoder Loss:  0.03543175 Validation Decoder Loss:  0.33161366
Encoder Loss:  0.04257638  || Decoder Loss:  0.03542977 Validation Decoder Loss:  0.33161452
Encoder Loss:  0.042899676  || Decoder Loss:  0.035430018 Validation Decoder Loss:  0.33162057
Encoder Loss:  0.044421736  || Decoder Loss:  0.035442192 Validation Decoder Loss:  0.33160523
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.40306512529454236 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33160523
Started Optimization Process
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_5 (Conv3DTr (None, 395, 6, 20, 1)     413       
_________________________________________________________________
reshape_5 (Reshape)          (None, 2370, 20, 1)       0         
=================================================================
Total params: 413
Trainable params: 413
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_5 (Conv2DTr (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27992317  || Decoder Loss:  0.4526802 Validation Decoder Loss:  0.9666235
Encoder Loss:  0.22730905  || Decoder Loss:  0.40648383 Validation Decoder Loss:  0.31549996
Encoder Loss:  0.055133734  || Decoder Loss:  0.04866804 Validation Decoder Loss:  0.3157174
Encoder Loss:  0.049682952  || Decoder Loss:  0.046220303 Validation Decoder Loss:  0.3135017
Encoder Loss:  0.050552033  || Decoder Loss:  0.04925544 Validation Decoder Loss:  0.32657596
Encoder Loss:  0.04764191  || Decoder Loss:  0.043042306 Validation Decoder Loss:  0.32666373
Encoder Loss:  0.047492594  || Decoder Loss:  0.04384781 Validation Decoder Loss:  0.32916352
Encoder Loss:  0.048796862  || Decoder Loss:  0.045725137 Validation Decoder Loss:  0.33043134
Encoder Loss:  0.047170594  || Decoder Loss:  0.04347556 Validation Decoder Loss:  0.33294117
Encoder Loss:  0.04719099  || Decoder Loss:  0.04318864 Validation Decoder Loss:  0.33288038
Encoder Loss:  0.047277365  || Decoder Loss:  0.04339131 Validation Decoder Loss:  0.334794
Encoder Loss:  0.046694413  || Decoder Loss:  0.042406667 Validation Decoder Loss:  0.3362972
Encoder Loss:  0.049874574  || Decoder Loss:  0.047344565 Validation Decoder Loss:  0.33984756
Encoder Loss:  0.04809535  || Decoder Loss:  0.044760946 Validation Decoder Loss:  0.33820856
Encoder Loss:  0.04671633  || Decoder Loss:  0.042813595 Validation Decoder Loss:  0.33744013
Encoder Loss:  0.04607636  || Decoder Loss:  0.04123695 Validation Decoder Loss:  0.33937252
Encoder Loss:  0.046357833  || Decoder Loss:  0.041588858 Validation Decoder Loss:  0.33467996
Encoder Loss:  0.049868215  || Decoder Loss:  0.03748161 Validation Decoder Loss:  0.33605805
Encoder Loss:  0.04451488  || Decoder Loss:  0.038285386 Validation Decoder Loss:  0.33649698
Encoder Loss:  0.044549394  || Decoder Loss:  0.038338985 Validation Decoder Loss:  0.3367979
Encoder Loss:  0.044637572  || Decoder Loss:  0.03839454 Validation Decoder Loss:  0.337634
Encoder Loss:  0.04471548  || Decoder Loss:  0.038361266 Validation Decoder Loss:  0.3365007
Encoder Loss:  0.045142587  || Decoder Loss:  0.03875522 Validation Decoder Loss:  0.3376884
Encoder Loss:  0.04447189  || Decoder Loss:  0.038079742 Validation Decoder Loss:  0.33836275
Encoder Loss:  0.044523373  || Decoder Loss:  0.03793819 Validation Decoder Loss:  0.33730972
Encoder Loss:  0.04436609  || Decoder Loss:  0.037794713 Validation Decoder Loss:  0.33734873
Encoder Loss:  0.044236213  || Decoder Loss:  0.03757021 Validation Decoder Loss:  0.33728445
Encoder Loss:  0.044720534  || Decoder Loss:  0.037888754 Validation Decoder Loss:  0.33750367
Encoder Loss:  0.044785142  || Decoder Loss:  0.03799461 Validation Decoder Loss:  0.3364767
Encoder Loss:  0.044125307  || Decoder Loss:  0.037377685 Validation Decoder Loss:  0.33657697
Encoder Loss:  0.044131294  || Decoder Loss:  0.037181843 Validation Decoder Loss:  0.33851093
Encoder Loss:  0.044098496  || Decoder Loss:  0.03716539 Validation Decoder Loss:  0.335517
Encoder Loss:  0.04506571  || Decoder Loss:  0.03792936 Validation Decoder Loss:  0.33663023
Encoder Loss:  0.044034053  || Decoder Loss:  0.0372568 Validation Decoder Loss:  0.3360565
Encoder Loss:  0.044141527  || Decoder Loss:  0.03707589 Validation Decoder Loss:  0.33605015
Encoder Loss:  0.04405853  || Decoder Loss:  0.036994528 Validation Decoder Loss:  0.3362434
Encoder Loss:  0.04401794  || Decoder Loss:  0.037046168 Validation Decoder Loss:  0.3362969
Encoder Loss:  0.044093937  || Decoder Loss:  0.036807723 Validation Decoder Loss:  0.33578694
Encoder Loss:  0.044296518  || Decoder Loss:  0.037306655 Validation Decoder Loss:  0.33624238
Encoder Loss:  0.043792304  || Decoder Loss:  0.03660956 Validation Decoder Loss:  0.3365321
Model: siamese_net_lr_0.4225637864718905 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3365321
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_6 (Conv3DTr (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_6 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_6 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.05731504  || Decoder Loss:  0.04544785 Validation Decoder Loss:  0.33384585
Encoder Loss:  0.045396913  || Decoder Loss:  0.038264904 Validation Decoder Loss:  0.3154924
Encoder Loss:  0.044051513  || Decoder Loss:  0.037163284 Validation Decoder Loss:  0.31680888
Encoder Loss:  0.04426175  || Decoder Loss:  0.03706764 Validation Decoder Loss:  0.31657094
Encoder Loss:  0.044415046  || Decoder Loss:  0.03922969 Validation Decoder Loss:  0.33409047
Encoder Loss:  0.04456396  || Decoder Loss:  0.038846828 Validation Decoder Loss:  0.3730657
Encoder Loss:  0.04513131  || Decoder Loss:  0.03845801 Validation Decoder Loss:  0.37312624
Encoder Loss:  0.044630256  || Decoder Loss:  0.038028188 Validation Decoder Loss:  0.3747985
Encoder Loss:  0.043448225  || Decoder Loss:  0.03726366 Validation Decoder Loss:  0.3732087
Encoder Loss:  0.043077726  || Decoder Loss:  0.03692189 Validation Decoder Loss:  0.37239856
Encoder Loss:  0.043879386  || Decoder Loss:  0.03714946 Validation Decoder Loss:  0.37445414
Encoder Loss:  0.04306851  || Decoder Loss:  0.036700293 Validation Decoder Loss:  0.37416017
Encoder Loss:  0.044309024  || Decoder Loss:  0.037026197 Validation Decoder Loss:  0.37693918
Encoder Loss:  0.042485747  || Decoder Loss:  0.036156684 Validation Decoder Loss:  0.35601377
Encoder Loss:  0.042620916  || Decoder Loss:  0.03626388 Validation Decoder Loss:  0.35107028
Encoder Loss:  0.043427676  || Decoder Loss:  0.036680702 Validation Decoder Loss:  0.3121466
Encoder Loss:  0.042316437  || Decoder Loss:  0.03589775 Validation Decoder Loss:  0.344912
Encoder Loss:  0.042921677  || Decoder Loss:  0.036558107 Validation Decoder Loss:  0.3234858
Encoder Loss:  0.043811463  || Decoder Loss:  0.036373258 Validation Decoder Loss:  0.32276297
Encoder Loss:  0.042356506  || Decoder Loss:  0.03609427 Validation Decoder Loss:  0.32505915
Encoder Loss:  0.043017358  || Decoder Loss:  0.036171447 Validation Decoder Loss:  0.32453164
Encoder Loss:  0.042879067  || Decoder Loss:  0.036145207 Validation Decoder Loss:  0.32663488
Encoder Loss:  0.042236075  || Decoder Loss:  0.035988737 Validation Decoder Loss:  0.3267144
Encoder Loss:  0.042365205  || Decoder Loss:  0.03600116 Validation Decoder Loss:  0.32772
Encoder Loss:  0.043526627  || Decoder Loss:  0.03612925 Validation Decoder Loss:  0.32763165
Encoder Loss:  0.04226831  || Decoder Loss:  0.035952505 Validation Decoder Loss:  0.32832906
Encoder Loss:  0.042267963  || Decoder Loss:  0.03592705 Validation Decoder Loss:  0.32876036
Encoder Loss:  0.042289175  || Decoder Loss:  0.035909206 Validation Decoder Loss:  0.32932025
Encoder Loss:  0.042241942  || Decoder Loss:  0.035881802 Validation Decoder Loss:  0.32935864
Encoder Loss:  0.04270497  || Decoder Loss:  0.035922464 Validation Decoder Loss:  0.32969686
Encoder Loss:  0.042177696  || Decoder Loss:  0.035842966 Validation Decoder Loss:  0.33000275
Encoder Loss:  0.042394314  || Decoder Loss:  0.03586004 Validation Decoder Loss:  0.33016872
Encoder Loss:  0.042436246  || Decoder Loss:  0.03585482 Validation Decoder Loss:  0.33027315
Encoder Loss:  0.04214888  || Decoder Loss:  0.03580481 Validation Decoder Loss:  0.33052546
Encoder Loss:  0.042104326  || Decoder Loss:  0.035783295 Validation Decoder Loss:  0.33075255
Encoder Loss:  0.04241147  || Decoder Loss:  0.035802566 Validation Decoder Loss:  0.33089322
Encoder Loss:  0.042077217  || Decoder Loss:  0.035756826 Validation Decoder Loss:  0.33118743
Encoder Loss:  0.042154495  || Decoder Loss:  0.035751544 Validation Decoder Loss:  0.3312374
Encoder Loss:  0.042135533  || Decoder Loss:  0.03573674 Validation Decoder Loss:  0.3314017
Encoder Loss:  0.04212964  || Decoder Loss:  0.03572347 Validation Decoder Loss:  0.33167344
Model: siamese_net_lr_0.40885744733873836 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33167344
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_7 (Conv3DTr (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_7 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_7 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.058924176  || Decoder Loss:  0.041676782 Validation Decoder Loss:  0.35622257
Encoder Loss:  0.0440207  || Decoder Loss:  0.036910035 Validation Decoder Loss:  0.31142688
Encoder Loss:  0.043821063  || Decoder Loss:  0.036674425 Validation Decoder Loss:  0.31666303
Encoder Loss:  0.044072617  || Decoder Loss:  0.03674814 Validation Decoder Loss:  0.32136005
Encoder Loss:  0.04404558  || Decoder Loss:  0.0367837 Validation Decoder Loss:  0.31519017
Encoder Loss:  0.043263875  || Decoder Loss:  0.036334656 Validation Decoder Loss:  0.36699933
Encoder Loss:  0.046761192  || Decoder Loss:  0.03721684 Validation Decoder Loss:  0.35301057
Encoder Loss:  0.04469814  || Decoder Loss:  0.0394246 Validation Decoder Loss:  0.37491077
Encoder Loss:  0.04370058  || Decoder Loss:  0.03721833 Validation Decoder Loss:  0.3706882
Encoder Loss:  0.04361796  || Decoder Loss:  0.03700778 Validation Decoder Loss:  0.3744074
Encoder Loss:  0.043210387  || Decoder Loss:  0.036731206 Validation Decoder Loss:  0.37234503
Encoder Loss:  0.044287514  || Decoder Loss:  0.036978405 Validation Decoder Loss:  0.3773549
Encoder Loss:  0.042777743  || Decoder Loss:  0.036369048 Validation Decoder Loss:  0.376519
Encoder Loss:  0.04370918  || Decoder Loss:  0.036583416 Validation Decoder Loss:  0.37338313
Encoder Loss:  0.042640537  || Decoder Loss:  0.036111645 Validation Decoder Loss:  0.33912975
Encoder Loss:  0.04321233  || Decoder Loss:  0.036577225 Validation Decoder Loss:  0.31375635
Encoder Loss:  0.04285164  || Decoder Loss:  0.036250338 Validation Decoder Loss:  0.32114
Encoder Loss:  0.042690087  || Decoder Loss:  0.03613311 Validation Decoder Loss:  0.3210044
Encoder Loss:  0.043625727  || Decoder Loss:  0.03629778 Validation Decoder Loss:  0.32461262
Encoder Loss:  0.04255121  || Decoder Loss:  0.03605202 Validation Decoder Loss:  0.32605106
Encoder Loss:  0.0427  || Decoder Loss:  0.036055855 Validation Decoder Loss:  0.32672507
Encoder Loss:  0.043013178  || Decoder Loss:  0.03608526 Validation Decoder Loss:  0.32757664
Encoder Loss:  0.042530213  || Decoder Loss:  0.03596585 Validation Decoder Loss:  0.32798958
Encoder Loss:  0.042956952  || Decoder Loss:  0.03603061 Validation Decoder Loss:  0.32837284
Encoder Loss:  0.042390533  || Decoder Loss:  0.03590794 Validation Decoder Loss:  0.32849795
Encoder Loss:  0.04349093  || Decoder Loss:  0.036030468 Validation Decoder Loss:  0.3288865
Encoder Loss:  0.04239361  || Decoder Loss:  0.03588316 Validation Decoder Loss:  0.3291435
Encoder Loss:  0.043691363  || Decoder Loss:  0.036003936 Validation Decoder Loss:  0.32914063
Encoder Loss:  0.042364687  || Decoder Loss:  0.035859674 Validation Decoder Loss:  0.32958174
Encoder Loss:  0.042363472  || Decoder Loss:  0.035839748 Validation Decoder Loss:  0.32981724
Encoder Loss:  0.04307624  || Decoder Loss:  0.035899423 Validation Decoder Loss:  0.32997587
Encoder Loss:  0.042395268  || Decoder Loss:  0.035822205 Validation Decoder Loss:  0.3302076
Encoder Loss:  0.04240106  || Decoder Loss:  0.03580387 Validation Decoder Loss:  0.3306008
Encoder Loss:  0.042340375  || Decoder Loss:  0.03578235 Validation Decoder Loss:  0.33062667
Encoder Loss:  0.042391863  || Decoder Loss:  0.035771623 Validation Decoder Loss:  0.33081445
Encoder Loss:  0.042308293  || Decoder Loss:  0.035751276 Validation Decoder Loss:  0.33117223
Encoder Loss:  0.0425037  || Decoder Loss:  0.035752308 Validation Decoder Loss:  0.33125246
Encoder Loss:  0.042256404  || Decoder Loss:  0.03571925 Validation Decoder Loss:  0.331546
Encoder Loss:  0.042313002  || Decoder Loss:  0.035712015 Validation Decoder Loss:  0.33175677
Encoder Loss:  0.042342782  || Decoder Loss:  0.03569996 Validation Decoder Loss:  0.3319689
Model: siamese_net_lr_0.3900184145970053 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33196896
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_8 (Conv3DTr (None, 514, 5, 20, 1)     263       
_________________________________________________________________
reshape_8 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_8 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.034901097  || Decoder Loss:  0.034901097 Validation Decoder Loss:  0.32639158
Encoder Loss:  0.034757264  || Decoder Loss:  0.034757264 Validation Decoder Loss:  0.32643205
Encoder Loss:  0.034738887  || Decoder Loss:  0.034738887 Validation Decoder Loss:  0.3264335
Encoder Loss:  0.034732305  || Decoder Loss:  0.034732305 Validation Decoder Loss:  0.32645428
Encoder Loss:  0.03472985  || Decoder Loss:  0.03472985 Validation Decoder Loss:  0.3264961
Encoder Loss:  0.034728635  || Decoder Loss:  0.034728635 Validation Decoder Loss:  0.32655048
Encoder Loss:  0.03472763  || Decoder Loss:  0.03472763 Validation Decoder Loss:  0.32660973
Encoder Loss:  0.03472649  || Decoder Loss:  0.03472649 Validation Decoder Loss:  0.32666916
Encoder Loss:  0.03472519  || Decoder Loss:  0.03472519 Validation Decoder Loss:  0.32672656
Encoder Loss:  0.034723688  || Decoder Loss:  0.034723688 Validation Decoder Loss:  0.32678106
Encoder Loss:  0.03472216  || Decoder Loss:  0.03472216 Validation Decoder Loss:  0.32683256
Encoder Loss:  0.03472059  || Decoder Loss:  0.03472059 Validation Decoder Loss:  0.32688105
Encoder Loss:  0.034719028  || Decoder Loss:  0.034719028 Validation Decoder Loss:  0.32692683
Encoder Loss:  0.03471755  || Decoder Loss:  0.03471755 Validation Decoder Loss:  0.32696986
Encoder Loss:  0.034716126  || Decoder Loss:  0.034716126 Validation Decoder Loss:  0.32701048
Encoder Loss:  0.03471473  || Decoder Loss:  0.03471473 Validation Decoder Loss:  0.32704884
Encoder Loss:  0.034713443  || Decoder Loss:  0.034713443 Validation Decoder Loss:  0.32708502
Encoder Loss:  0.034712195  || Decoder Loss:  0.034712195 Validation Decoder Loss:  0.32711923
Encoder Loss:  0.034711037  || Decoder Loss:  0.034711037 Validation Decoder Loss:  0.3271515
Encoder Loss:  0.034709945  || Decoder Loss:  0.034709945 Validation Decoder Loss:  0.32718208
Encoder Loss:  0.03470892  || Decoder Loss:  0.03470892 Validation Decoder Loss:  0.32721102
Encoder Loss:  0.03470791  || Decoder Loss:  0.03470791 Validation Decoder Loss:  0.32723844
Encoder Loss:  0.034707  || Decoder Loss:  0.034707 Validation Decoder Loss:  0.32726443
Encoder Loss:  0.034706105  || Decoder Loss:  0.034706105 Validation Decoder Loss:  0.3272891
Encoder Loss:  0.034705304  || Decoder Loss:  0.034705304 Validation Decoder Loss:  0.32731253
Encoder Loss:  0.0347045  || Decoder Loss:  0.0347045 Validation Decoder Loss:  0.3273348
Encoder Loss:  0.034703746  || Decoder Loss:  0.034703746 Validation Decoder Loss:  0.32735598
Encoder Loss:  0.03470304  || Decoder Loss:  0.03470304 Validation Decoder Loss:  0.3273762
Encoder Loss:  0.034702364  || Decoder Loss:  0.034702364 Validation Decoder Loss:  0.32739544
Encoder Loss:  0.034701683  || Decoder Loss:  0.034701683 Validation Decoder Loss:  0.3274138
Encoder Loss:  0.034701087  || Decoder Loss:  0.034701087 Validation Decoder Loss:  0.32743132
Encoder Loss:  0.034700476  || Decoder Loss:  0.034700476 Validation Decoder Loss:  0.32744804
Encoder Loss:  0.034699902  || Decoder Loss:  0.034699902 Validation Decoder Loss:  0.32746404
Encoder Loss:  0.03469936  || Decoder Loss:  0.03469936 Validation Decoder Loss:  0.3274794
Encoder Loss:  0.03469887  || Decoder Loss:  0.03469887 Validation Decoder Loss:  0.32749406
Encoder Loss:  0.034698386  || Decoder Loss:  0.034698386 Validation Decoder Loss:  0.32750812
Encoder Loss:  0.03469788  || Decoder Loss:  0.03469788 Validation Decoder Loss:  0.32752162
Encoder Loss:  0.03469743  || Decoder Loss:  0.03469743 Validation Decoder Loss:  0.32753456
Encoder Loss:  0.03469695  || Decoder Loss:  0.03469695 Validation Decoder Loss:  0.32754698
Encoder Loss:  0.03469655  || Decoder Loss:  0.03469655 Validation Decoder Loss:  0.32755893
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32755893
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_9 (Conv3DTr (None, 257, 10, 20, 1)    31        
_________________________________________________________________
reshape_9 (Reshape)          (None, 2570, 20, 1)       0         
=================================================================
Total params: 31
Trainable params: 31
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_9 (Conv2DTr (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035006214  || Decoder Loss:  0.035006214 Validation Decoder Loss:  0.32916865
Encoder Loss:  0.034857515  || Decoder Loss:  0.034857515 Validation Decoder Loss:  0.32928464
Encoder Loss:  0.03481956  || Decoder Loss:  0.03481956 Validation Decoder Loss:  0.3293777
Encoder Loss:  0.034803394  || Decoder Loss:  0.034803394 Validation Decoder Loss:  0.32944703
Encoder Loss:  0.034796808  || Decoder Loss:  0.034796808 Validation Decoder Loss:  0.3294934
Encoder Loss:  0.03479443  || Decoder Loss:  0.03479443 Validation Decoder Loss:  0.3295283
Encoder Loss:  0.034793913  || Decoder Loss:  0.034793913 Validation Decoder Loss:  0.32955983
Encoder Loss:  0.034794167  || Decoder Loss:  0.034794167 Validation Decoder Loss:  0.3295919
Encoder Loss:  0.034794465  || Decoder Loss:  0.034794465 Validation Decoder Loss:  0.32962564
Encoder Loss:  0.03479458  || Decoder Loss:  0.03479458 Validation Decoder Loss:  0.32966083
Encoder Loss:  0.03479442  || Decoder Loss:  0.03479442 Validation Decoder Loss:  0.32969683
Encoder Loss:  0.034794047  || Decoder Loss:  0.034794047 Validation Decoder Loss:  0.32973292
Encoder Loss:  0.034793425  || Decoder Loss:  0.034793425 Validation Decoder Loss:  0.32976854
Encoder Loss:  0.03479265  || Decoder Loss:  0.03479265 Validation Decoder Loss:  0.32980326
Encoder Loss:  0.03479178  || Decoder Loss:  0.03479178 Validation Decoder Loss:  0.3298368
Encoder Loss:  0.03479084  || Decoder Loss:  0.03479084 Validation Decoder Loss:  0.32986894
Encoder Loss:  0.034789857  || Decoder Loss:  0.034789857 Validation Decoder Loss:  0.32989958
Encoder Loss:  0.0347889  || Decoder Loss:  0.0347889 Validation Decoder Loss:  0.3299287
Encoder Loss:  0.034787968  || Decoder Loss:  0.034787968 Validation Decoder Loss:  0.32995623
Encoder Loss:  0.034787025  || Decoder Loss:  0.034787025 Validation Decoder Loss:  0.3299823
Encoder Loss:  0.03478609  || Decoder Loss:  0.03478609 Validation Decoder Loss:  0.330007
Encoder Loss:  0.034785226  || Decoder Loss:  0.034785226 Validation Decoder Loss:  0.3300303
Encoder Loss:  0.034784388  || Decoder Loss:  0.034784388 Validation Decoder Loss:  0.3300524
Encoder Loss:  0.034783594  || Decoder Loss:  0.034783594 Validation Decoder Loss:  0.3300733
Encoder Loss:  0.03478281  || Decoder Loss:  0.03478281 Validation Decoder Loss:  0.33009315
Encoder Loss:  0.034782074  || Decoder Loss:  0.034782074 Validation Decoder Loss:  0.33011198
Encoder Loss:  0.0347814  || Decoder Loss:  0.0347814 Validation Decoder Loss:  0.33012986
Encoder Loss:  0.034780696  || Decoder Loss:  0.034780696 Validation Decoder Loss:  0.33014688
Encoder Loss:  0.03478002  || Decoder Loss:  0.03478002 Validation Decoder Loss:  0.3301631
Encoder Loss:  0.034779415  || Decoder Loss:  0.034779415 Validation Decoder Loss:  0.33017856
Encoder Loss:  0.03477881  || Decoder Loss:  0.03477881 Validation Decoder Loss:  0.33019334
Encoder Loss:  0.034778263  || Decoder Loss:  0.034778263 Validation Decoder Loss:  0.33020747
Encoder Loss:  0.034777712  || Decoder Loss:  0.034777712 Validation Decoder Loss:  0.33022097
Encoder Loss:  0.034777187  || Decoder Loss:  0.034777187 Validation Decoder Loss:  0.33023396
Encoder Loss:  0.03477667  || Decoder Loss:  0.03477667 Validation Decoder Loss:  0.3302464
Encoder Loss:  0.03477619  || Decoder Loss:  0.03477619 Validation Decoder Loss:  0.3302583
Encoder Loss:  0.03477573  || Decoder Loss:  0.03477573 Validation Decoder Loss:  0.33026978
Encoder Loss:  0.034775298  || Decoder Loss:  0.034775298 Validation Decoder Loss:  0.33028084
Encoder Loss:  0.034774873  || Decoder Loss:  0.034774873 Validation Decoder Loss:  0.33029145
Encoder Loss:  0.03477446  || Decoder Loss:  0.03477446 Validation Decoder Loss:  0.3303017
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3303017
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_10 (Conv3DT (None, 257, 10, 20, 1)    263       
_________________________________________________________________
reshape_10 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_10 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.034905277  || Decoder Loss:  0.034905277 Validation Decoder Loss:  0.32650518
Encoder Loss:  0.034772694  || Decoder Loss:  0.034772694 Validation Decoder Loss:  0.32653427
Encoder Loss:  0.03475559  || Decoder Loss:  0.03475559 Validation Decoder Loss:  0.32653978
Encoder Loss:  0.03474955  || Decoder Loss:  0.03474955 Validation Decoder Loss:  0.32656878
Encoder Loss:  0.034747258  || Decoder Loss:  0.034747258 Validation Decoder Loss:  0.32661638
Encoder Loss:  0.034746114  || Decoder Loss:  0.034746114 Validation Decoder Loss:  0.32667282
Encoder Loss:  0.034745093  || Decoder Loss:  0.034745093 Validation Decoder Loss:  0.32673126
Encoder Loss:  0.03474397  || Decoder Loss:  0.03474397 Validation Decoder Loss:  0.32678834
Encoder Loss:  0.03474264  || Decoder Loss:  0.03474264 Validation Decoder Loss:  0.32684278
Encoder Loss:  0.03474121  || Decoder Loss:  0.03474121 Validation Decoder Loss:  0.32689422
Encoder Loss:  0.034739695  || Decoder Loss:  0.034739695 Validation Decoder Loss:  0.32694283
Encoder Loss:  0.03473822  || Decoder Loss:  0.03473822 Validation Decoder Loss:  0.32698876
Encoder Loss:  0.03473673  || Decoder Loss:  0.03473673 Validation Decoder Loss:  0.3270322
Encoder Loss:  0.034735337  || Decoder Loss:  0.034735337 Validation Decoder Loss:  0.32707334
Encoder Loss:  0.03473398  || Decoder Loss:  0.03473398 Validation Decoder Loss:  0.3271123
Encoder Loss:  0.034732673  || Decoder Loss:  0.034732673 Validation Decoder Loss:  0.3271492
Encoder Loss:  0.034731437  || Decoder Loss:  0.034731437 Validation Decoder Loss:  0.3271842
Encoder Loss:  0.034730263  || Decoder Loss:  0.034730263 Validation Decoder Loss:  0.32721734
Encoder Loss:  0.034729227  || Decoder Loss:  0.034729227 Validation Decoder Loss:  0.32724878
Encoder Loss:  0.03472821  || Decoder Loss:  0.03472821 Validation Decoder Loss:  0.3272786
Encoder Loss:  0.034727223  || Decoder Loss:  0.034727223 Validation Decoder Loss:  0.32730693
Encoder Loss:  0.034726292  || Decoder Loss:  0.034726292 Validation Decoder Loss:  0.3273338
Encoder Loss:  0.034725424  || Decoder Loss:  0.034725424 Validation Decoder Loss:  0.32735938
Encoder Loss:  0.034724597  || Decoder Loss:  0.034724597 Validation Decoder Loss:  0.32738364
Encoder Loss:  0.034723822  || Decoder Loss:  0.034723822 Validation Decoder Loss:  0.32740682
Encoder Loss:  0.03472308  || Decoder Loss:  0.03472308 Validation Decoder Loss:  0.32742885
Encoder Loss:  0.03472239  || Decoder Loss:  0.03472239 Validation Decoder Loss:  0.32744986
Encoder Loss:  0.0347217  || Decoder Loss:  0.0347217 Validation Decoder Loss:  0.3274699
Encoder Loss:  0.03472106  || Decoder Loss:  0.03472106 Validation Decoder Loss:  0.32748902
Encoder Loss:  0.034720458  || Decoder Loss:  0.034720458 Validation Decoder Loss:  0.3275073
Encoder Loss:  0.034719866  || Decoder Loss:  0.034719866 Validation Decoder Loss:  0.32752472
Encoder Loss:  0.034719337  || Decoder Loss:  0.034719337 Validation Decoder Loss:  0.32754144
Encoder Loss:  0.034718774  || Decoder Loss:  0.034718774 Validation Decoder Loss:  0.32755744
Encoder Loss:  0.03471827  || Decoder Loss:  0.03471827 Validation Decoder Loss:  0.3275728
Encoder Loss:  0.034717776  || Decoder Loss:  0.034717776 Validation Decoder Loss:  0.3275875
Encoder Loss:  0.034717314  || Decoder Loss:  0.034717314 Validation Decoder Loss:  0.32760155
Encoder Loss:  0.034716874  || Decoder Loss:  0.034716874 Validation Decoder Loss:  0.32761508
Encoder Loss:  0.03471643  || Decoder Loss:  0.03471643 Validation Decoder Loss:  0.3276281
Encoder Loss:  0.03471602  || Decoder Loss:  0.03471602 Validation Decoder Loss:  0.3276406
Encoder Loss:  0.034715604  || Decoder Loss:  0.034715604 Validation Decoder Loss:  0.32765263
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32765263
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_11 (Conv3DT (None, 257, 10, 20, 1)    263       
_________________________________________________________________
reshape_11 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 263
Trainable params: 263
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_11 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13999075  || Decoder Loss:  0.19167499 Validation Decoder Loss:  0.32976216
Encoder Loss:  0.05324725  || Decoder Loss:  0.037849203 Validation Decoder Loss:  0.33082598
Encoder Loss:  0.052259345  || Decoder Loss:  0.037373427 Validation Decoder Loss:  0.33302516
Encoder Loss:  0.052560344  || Decoder Loss:  0.03719238 Validation Decoder Loss:  0.33049825
Encoder Loss:  0.051935207  || Decoder Loss:  0.037282865 Validation Decoder Loss:  0.33143318
Encoder Loss:  0.049092636  || Decoder Loss:  0.03669368 Validation Decoder Loss:  0.3300154
Encoder Loss:  0.058482546  || Decoder Loss:  0.037906207 Validation Decoder Loss:  0.33041447
Encoder Loss:  0.050497964  || Decoder Loss:  0.036804862 Validation Decoder Loss:  0.33137214
Encoder Loss:  0.049052108  || Decoder Loss:  0.03716962 Validation Decoder Loss:  0.33233863
Encoder Loss:  0.050157305  || Decoder Loss:  0.040166974 Validation Decoder Loss:  0.3332746
Encoder Loss:  0.050355192  || Decoder Loss:  0.03770294 Validation Decoder Loss:  0.33100957
Encoder Loss:  0.04962184  || Decoder Loss:  0.037495714 Validation Decoder Loss:  0.33104154
Encoder Loss:  0.05454554  || Decoder Loss:  0.03810894 Validation Decoder Loss:  0.33442998
Encoder Loss:  0.048895806  || Decoder Loss:  0.03654864 Validation Decoder Loss:  0.3339987
Encoder Loss:  0.050580993  || Decoder Loss:  0.03664653 Validation Decoder Loss:  0.33302101
Encoder Loss:  0.04931613  || Decoder Loss:  0.036291163 Validation Decoder Loss:  0.33264476
Encoder Loss:  0.04901355  || Decoder Loss:  0.036227375 Validation Decoder Loss:  0.33286434
Encoder Loss:  0.048933756  || Decoder Loss:  0.03613822 Validation Decoder Loss:  0.33152813
Encoder Loss:  0.049958184  || Decoder Loss:  0.036093 Validation Decoder Loss:  0.3315966
Encoder Loss:  0.048973817  || Decoder Loss:  0.03607158 Validation Decoder Loss:  0.3323967
Encoder Loss:  0.049361676  || Decoder Loss:  0.03600897 Validation Decoder Loss:  0.33167922
Encoder Loss:  0.04956877  || Decoder Loss:  0.036316637 Validation Decoder Loss:  0.33282295
Encoder Loss:  0.049977988  || Decoder Loss:  0.036101464 Validation Decoder Loss:  0.33241972
Encoder Loss:  0.050270204  || Decoder Loss:  0.035949048 Validation Decoder Loss:  0.33320856
Encoder Loss:  0.049152948  || Decoder Loss:  0.03592396 Validation Decoder Loss:  0.33201092
Encoder Loss:  0.04884168  || Decoder Loss:  0.03587642 Validation Decoder Loss:  0.3316561
Encoder Loss:  0.04906033  || Decoder Loss:  0.035911568 Validation Decoder Loss:  0.33188096
Encoder Loss:  0.048782557  || Decoder Loss:  0.0358583 Validation Decoder Loss:  0.33207458
Encoder Loss:  0.050803527  || Decoder Loss:  0.036068715 Validation Decoder Loss:  0.33269346
Encoder Loss:  0.048789036  || Decoder Loss:  0.03595146 Validation Decoder Loss:  0.33183554
Encoder Loss:  0.04891426  || Decoder Loss:  0.035900913 Validation Decoder Loss:  0.33152175
Encoder Loss:  0.051327504  || Decoder Loss:  0.035949208 Validation Decoder Loss:  0.3326057
Encoder Loss:  0.048784874  || Decoder Loss:  0.035809368 Validation Decoder Loss:  0.3320501
Encoder Loss:  0.049360085  || Decoder Loss:  0.035919458 Validation Decoder Loss:  0.33183506
Encoder Loss:  0.04883533  || Decoder Loss:  0.035824694 Validation Decoder Loss:  0.33238018
Encoder Loss:  0.051543422  || Decoder Loss:  0.036011573 Validation Decoder Loss:  0.3320384
Encoder Loss:  0.048755515  || Decoder Loss:  0.03586399 Validation Decoder Loss:  0.3319767
Encoder Loss:  0.04911212  || Decoder Loss:  0.035897706 Validation Decoder Loss:  0.3319018
Encoder Loss:  0.048770223  || Decoder Loss:  0.035880636 Validation Decoder Loss:  0.3319401
Encoder Loss:  0.049173173  || Decoder Loss:  0.035860296 Validation Decoder Loss:  0.33185172
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33185175
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_12 (Conv3DT (None, 514, 5, 20, 1)     74        
_________________________________________________________________
reshape_12 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_12 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.034801573  || Decoder Loss:  0.034801573 Validation Decoder Loss:  0.3285151
Encoder Loss:  0.034709245  || Decoder Loss:  0.034709245 Validation Decoder Loss:  0.32860708
Encoder Loss:  0.034693744  || Decoder Loss:  0.034693744 Validation Decoder Loss:  0.3286718
Encoder Loss:  0.034686435  || Decoder Loss:  0.034686435 Validation Decoder Loss:  0.32874298
Encoder Loss:  0.034681555  || Decoder Loss:  0.034681555 Validation Decoder Loss:  0.32881486
Encoder Loss:  0.034677703  || Decoder Loss:  0.034677703 Validation Decoder Loss:  0.32888395
Encoder Loss:  0.03467451  || Decoder Loss:  0.03467451 Validation Decoder Loss:  0.32894957
Encoder Loss:  0.034671694  || Decoder Loss:  0.034671694 Validation Decoder Loss:  0.32901168
Encoder Loss:  0.034669094  || Decoder Loss:  0.034669094 Validation Decoder Loss:  0.3290703
Encoder Loss:  0.0346667  || Decoder Loss:  0.0346667 Validation Decoder Loss:  0.3291255
Encoder Loss:  0.034664452  || Decoder Loss:  0.034664452 Validation Decoder Loss:  0.32917732
Encoder Loss:  0.03466237  || Decoder Loss:  0.03466237 Validation Decoder Loss:  0.3292258
Encoder Loss:  0.03466041  || Decoder Loss:  0.03466041 Validation Decoder Loss:  0.32927114
Encoder Loss:  0.034658596  || Decoder Loss:  0.034658596 Validation Decoder Loss:  0.32931337
Encoder Loss:  0.034656912  || Decoder Loss:  0.034656912 Validation Decoder Loss:  0.32935274
Encoder Loss:  0.03465534  || Decoder Loss:  0.03465534 Validation Decoder Loss:  0.3293894
Encoder Loss:  0.03465391  || Decoder Loss:  0.03465391 Validation Decoder Loss:  0.32942355
Encoder Loss:  0.034652557  || Decoder Loss:  0.034652557 Validation Decoder Loss:  0.32945544
Encoder Loss:  0.034651328  || Decoder Loss:  0.034651328 Validation Decoder Loss:  0.32948524
Encoder Loss:  0.03465015  || Decoder Loss:  0.03465015 Validation Decoder Loss:  0.32951313
Encoder Loss:  0.03464906  || Decoder Loss:  0.03464906 Validation Decoder Loss:  0.3295393
Encoder Loss:  0.034648016  || Decoder Loss:  0.034648016 Validation Decoder Loss:  0.32956386
Encoder Loss:  0.03464705  || Decoder Loss:  0.03464705 Validation Decoder Loss:  0.32958698
Encoder Loss:  0.03464613  || Decoder Loss:  0.03464613 Validation Decoder Loss:  0.32960886
Encoder Loss:  0.034645297  || Decoder Loss:  0.034645297 Validation Decoder Loss:  0.32962942
Encoder Loss:  0.034644485  || Decoder Loss:  0.034644485 Validation Decoder Loss:  0.32964894
Encoder Loss:  0.034643736  || Decoder Loss:  0.034643736 Validation Decoder Loss:  0.32966745
Encoder Loss:  0.034643006  || Decoder Loss:  0.034643006 Validation Decoder Loss:  0.329685
Encoder Loss:  0.034642335  || Decoder Loss:  0.034642335 Validation Decoder Loss:  0.32970172
Encoder Loss:  0.03464169  || Decoder Loss:  0.03464169 Validation Decoder Loss:  0.3297176
Encoder Loss:  0.03464105  || Decoder Loss:  0.03464105 Validation Decoder Loss:  0.32973278
Encoder Loss:  0.034640476  || Decoder Loss:  0.034640476 Validation Decoder Loss:  0.32974726
Encoder Loss:  0.03463993  || Decoder Loss:  0.03463993 Validation Decoder Loss:  0.3297611
Encoder Loss:  0.034639355  || Decoder Loss:  0.034639355 Validation Decoder Loss:  0.32977438
Encoder Loss:  0.034638833  || Decoder Loss:  0.034638833 Validation Decoder Loss:  0.32978708
Encoder Loss:  0.03463836  || Decoder Loss:  0.03463836 Validation Decoder Loss:  0.32979923
Encoder Loss:  0.03463788  || Decoder Loss:  0.03463788 Validation Decoder Loss:  0.32981098
Encoder Loss:  0.034637436  || Decoder Loss:  0.034637436 Validation Decoder Loss:  0.32982224
Encoder Loss:  0.034637004  || Decoder Loss:  0.034637004 Validation Decoder Loss:  0.3298331
Encoder Loss:  0.03463658  || Decoder Loss:  0.03463658 Validation Decoder Loss:  0.32984352
Model: siamese_net_lr_0.925478894229264 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32984352
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_13 (Conv3DT (None, 514, 5, 20, 1)     11        
_________________________________________________________________
reshape_13 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_13 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03499842  || Decoder Loss:  0.03499842 Validation Decoder Loss:  0.32849556
Encoder Loss:  0.034822296  || Decoder Loss:  0.034822296 Validation Decoder Loss:  0.32863167
Encoder Loss:  0.034784876  || Decoder Loss:  0.034784876 Validation Decoder Loss:  0.32872522
Encoder Loss:  0.034769163  || Decoder Loss:  0.034769163 Validation Decoder Loss:  0.328782
Encoder Loss:  0.034762815  || Decoder Loss:  0.034762815 Validation Decoder Loss:  0.32882336
Encoder Loss:  0.034760635  || Decoder Loss:  0.034760635 Validation Decoder Loss:  0.32886392
Encoder Loss:  0.034760248  || Decoder Loss:  0.034760248 Validation Decoder Loss:  0.32891
Encoder Loss:  0.03476028  || Decoder Loss:  0.03476028 Validation Decoder Loss:  0.32896164
Encoder Loss:  0.034760173  || Decoder Loss:  0.034760173 Validation Decoder Loss:  0.32901615
Encoder Loss:  0.034759704  || Decoder Loss:  0.034759704 Validation Decoder Loss:  0.32907087
Encoder Loss:  0.034758933  || Decoder Loss:  0.034758933 Validation Decoder Loss:  0.32912415
Encoder Loss:  0.034757867  || Decoder Loss:  0.034757867 Validation Decoder Loss:  0.32917497
Encoder Loss:  0.034756638  || Decoder Loss:  0.034756638 Validation Decoder Loss:  0.329223
Encoder Loss:  0.034755293  || Decoder Loss:  0.034755293 Validation Decoder Loss:  0.3292681
Encoder Loss:  0.034753922  || Decoder Loss:  0.034753922 Validation Decoder Loss:  0.3293103
Encoder Loss:  0.034752518  || Decoder Loss:  0.034752518 Validation Decoder Loss:  0.3293497
Encoder Loss:  0.034751184  || Decoder Loss:  0.034751184 Validation Decoder Loss:  0.3293864
Encoder Loss:  0.034749847  || Decoder Loss:  0.034749847 Validation Decoder Loss:  0.32942066
Encoder Loss:  0.03474859  || Decoder Loss:  0.03474859 Validation Decoder Loss:  0.32945257
Encoder Loss:  0.034747396  || Decoder Loss:  0.034747396 Validation Decoder Loss:  0.32948235
Encoder Loss:  0.034746267  || Decoder Loss:  0.034746267 Validation Decoder Loss:  0.32951018
Encoder Loss:  0.034745153  || Decoder Loss:  0.034745153 Validation Decoder Loss:  0.32953626
Encoder Loss:  0.03474416  || Decoder Loss:  0.03474416 Validation Decoder Loss:  0.32956064
Encoder Loss:  0.03474318  || Decoder Loss:  0.03474318 Validation Decoder Loss:  0.3295836
Encoder Loss:  0.034742247  || Decoder Loss:  0.034742247 Validation Decoder Loss:  0.3296052
Encoder Loss:  0.034741372  || Decoder Loss:  0.034741372 Validation Decoder Loss:  0.32962555
Encoder Loss:  0.034740537  || Decoder Loss:  0.034740537 Validation Decoder Loss:  0.32964477
Encoder Loss:  0.034739766  || Decoder Loss:  0.034739766 Validation Decoder Loss:  0.32966298
Encoder Loss:  0.03473902  || Decoder Loss:  0.03473902 Validation Decoder Loss:  0.3296802
Encoder Loss:  0.0347383  || Decoder Loss:  0.0347383 Validation Decoder Loss:  0.3296966
Encoder Loss:  0.034737602  || Decoder Loss:  0.034737602 Validation Decoder Loss:  0.32971215
Encoder Loss:  0.034736957  || Decoder Loss:  0.034736957 Validation Decoder Loss:  0.329727
Encoder Loss:  0.03473637  || Decoder Loss:  0.03473637 Validation Decoder Loss:  0.32974112
Encoder Loss:  0.03473576  || Decoder Loss:  0.03473576 Validation Decoder Loss:  0.3297546
Encoder Loss:  0.034735214  || Decoder Loss:  0.034735214 Validation Decoder Loss:  0.32976753
Encoder Loss:  0.03473468  || Decoder Loss:  0.03473468 Validation Decoder Loss:  0.32977986
Encoder Loss:  0.03473414  || Decoder Loss:  0.03473414 Validation Decoder Loss:  0.3297917
Encoder Loss:  0.03473365  || Decoder Loss:  0.03473365 Validation Decoder Loss:  0.32980305
Encoder Loss:  0.03473319  || Decoder Loss:  0.03473319 Validation Decoder Loss:  0.329814
Encoder Loss:  0.034732737  || Decoder Loss:  0.034732737 Validation Decoder Loss:  0.3298245
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3298245
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_14 (Conv3DT (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_14 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_14 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035018757  || Decoder Loss:  0.035018757 Validation Decoder Loss:  0.3266982
Encoder Loss:  0.034813426  || Decoder Loss:  0.034813426 Validation Decoder Loss:  0.3270458
Encoder Loss:  0.034776438  || Decoder Loss:  0.034776438 Validation Decoder Loss:  0.32713994
Encoder Loss:  0.034755703  || Decoder Loss:  0.034755703 Validation Decoder Loss:  0.32720357
Encoder Loss:  0.034741323  || Decoder Loss:  0.034741323 Validation Decoder Loss:  0.32725626
Encoder Loss:  0.03473049  || Decoder Loss:  0.03473049 Validation Decoder Loss:  0.32730278
Encoder Loss:  0.034721956  || Decoder Loss:  0.034721956 Validation Decoder Loss:  0.32734478
Encoder Loss:  0.034714986  || Decoder Loss:  0.034714986 Validation Decoder Loss:  0.32738292
Encoder Loss:  0.034709178  || Decoder Loss:  0.034709178 Validation Decoder Loss:  0.32741785
Encoder Loss:  0.03470422  || Decoder Loss:  0.03470422 Validation Decoder Loss:  0.32744986
Encoder Loss:  0.03469991  || Decoder Loss:  0.03469991 Validation Decoder Loss:  0.3274794
Encoder Loss:  0.034696154  || Decoder Loss:  0.034696154 Validation Decoder Loss:  0.32750654
Encoder Loss:  0.03469279  || Decoder Loss:  0.03469279 Validation Decoder Loss:  0.3275317
Encoder Loss:  0.03468975  || Decoder Loss:  0.03468975 Validation Decoder Loss:  0.3275549
Encoder Loss:  0.034687  || Decoder Loss:  0.034687 Validation Decoder Loss:  0.3275764
Encoder Loss:  0.034684528  || Decoder Loss:  0.034684528 Validation Decoder Loss:  0.32759637
Encoder Loss:  0.03468223  || Decoder Loss:  0.03468223 Validation Decoder Loss:  0.3276148
Encoder Loss:  0.03468013  || Decoder Loss:  0.03468013 Validation Decoder Loss:  0.32763195
Encoder Loss:  0.034678135  || Decoder Loss:  0.034678135 Validation Decoder Loss:  0.32764792
Encoder Loss:  0.03467632  || Decoder Loss:  0.03467632 Validation Decoder Loss:  0.32766277
Encoder Loss:  0.034674622  || Decoder Loss:  0.034674622 Validation Decoder Loss:  0.32767665
Encoder Loss:  0.03467302  || Decoder Loss:  0.03467302 Validation Decoder Loss:  0.32768965
Encoder Loss:  0.034671556  || Decoder Loss:  0.034671556 Validation Decoder Loss:  0.32770193
Encoder Loss:  0.034670185  || Decoder Loss:  0.034670185 Validation Decoder Loss:  0.32771343
Encoder Loss:  0.034668848  || Decoder Loss:  0.034668848 Validation Decoder Loss:  0.3277244
Encoder Loss:  0.034667607  || Decoder Loss:  0.034667607 Validation Decoder Loss:  0.32773483
Encoder Loss:  0.034666456  || Decoder Loss:  0.034666456 Validation Decoder Loss:  0.3277448
Encoder Loss:  0.034665342  || Decoder Loss:  0.034665342 Validation Decoder Loss:  0.32775432
Encoder Loss:  0.034664314  || Decoder Loss:  0.034664314 Validation Decoder Loss:  0.32776356
Encoder Loss:  0.034663323  || Decoder Loss:  0.034663323 Validation Decoder Loss:  0.32777238
Encoder Loss:  0.034662385  || Decoder Loss:  0.034662385 Validation Decoder Loss:  0.32778096
Encoder Loss:  0.0346615  || Decoder Loss:  0.0346615 Validation Decoder Loss:  0.32778925
Encoder Loss:  0.034660656  || Decoder Loss:  0.034660656 Validation Decoder Loss:  0.3277973
Encoder Loss:  0.03465985  || Decoder Loss:  0.03465985 Validation Decoder Loss:  0.3278051
Encoder Loss:  0.03465909  || Decoder Loss:  0.03465909 Validation Decoder Loss:  0.32781264
Encoder Loss:  0.03465837  || Decoder Loss:  0.03465837 Validation Decoder Loss:  0.32782
Encoder Loss:  0.034657672  || Decoder Loss:  0.034657672 Validation Decoder Loss:  0.32782716
Encoder Loss:  0.03465702  || Decoder Loss:  0.03465702 Validation Decoder Loss:  0.32783413
Encoder Loss:  0.03465638  || Decoder Loss:  0.03465638 Validation Decoder Loss:  0.32784095
Encoder Loss:  0.034655787  || Decoder Loss:  0.034655787 Validation Decoder Loss:  0.32784757
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32784754
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_15 (Conv3DT (None, 257, 10, 20, 1)    389       
_________________________________________________________________
reshape_15 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_15 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06016467  || Decoder Loss:  0.03538604 Validation Decoder Loss:  0.33480397
Encoder Loss:  0.0440551  || Decoder Loss:  0.03533287 Validation Decoder Loss:  0.3353548
Encoder Loss:  0.043245777  || Decoder Loss:  0.03533189 Validation Decoder Loss:  0.33479828
Encoder Loss:  0.043173328  || Decoder Loss:  0.03533524 Validation Decoder Loss:  0.33462793
Encoder Loss:  0.04291614  || Decoder Loss:  0.03574577 Validation Decoder Loss:  0.33453387
Encoder Loss:  0.04306747  || Decoder Loss:  0.03533853 Validation Decoder Loss:  0.3347978
Encoder Loss:  0.04328419  || Decoder Loss:  0.035398837 Validation Decoder Loss:  0.3343757
Encoder Loss:  0.0425945  || Decoder Loss:  0.035380594 Validation Decoder Loss:  0.33411294
Encoder Loss:  0.04310565  || Decoder Loss:  0.035400506 Validation Decoder Loss:  0.33483133
Encoder Loss:  0.042562164  || Decoder Loss:  0.035367817 Validation Decoder Loss:  0.33408427
Encoder Loss:  0.044637606  || Decoder Loss:  0.035433467 Validation Decoder Loss:  0.33481437
Encoder Loss:  0.04257495  || Decoder Loss:  0.03537262 Validation Decoder Loss:  0.33451658
Encoder Loss:  0.042559277  || Decoder Loss:  0.035361607 Validation Decoder Loss:  0.33437282
Encoder Loss:  0.042838186  || Decoder Loss:  0.03536573 Validation Decoder Loss:  0.33458272
Encoder Loss:  0.0426384  || Decoder Loss:  0.03535534 Validation Decoder Loss:  0.33458674
Encoder Loss:  0.042614967  || Decoder Loss:  0.035355274 Validation Decoder Loss:  0.33458817
Encoder Loss:  0.04333375  || Decoder Loss:  0.03536579 Validation Decoder Loss:  0.33467
Encoder Loss:  0.042782154  || Decoder Loss:  0.035354458 Validation Decoder Loss:  0.33468336
Encoder Loss:  0.04246804  || Decoder Loss:  0.035343874 Validation Decoder Loss:  0.33474955
Encoder Loss:  0.042596  || Decoder Loss:  0.03534836 Validation Decoder Loss:  0.33475175
Encoder Loss:  0.042574044  || Decoder Loss:  0.035346575 Validation Decoder Loss:  0.33469373
Encoder Loss:  0.042639937  || Decoder Loss:  0.035347313 Validation Decoder Loss:  0.3346256
Encoder Loss:  0.04264201  || Decoder Loss:  0.035344772 Validation Decoder Loss:  0.33475643
Encoder Loss:  0.0425044  || Decoder Loss:  0.035339676 Validation Decoder Loss:  0.3348235
Encoder Loss:  0.042757764  || Decoder Loss:  0.035344925 Validation Decoder Loss:  0.33484295
Encoder Loss:  0.042498156  || Decoder Loss:  0.03534026 Validation Decoder Loss:  0.33493835
Encoder Loss:  0.042731795  || Decoder Loss:  0.035340298 Validation Decoder Loss:  0.33488184
Encoder Loss:  0.04249501  || Decoder Loss:  0.035339125 Validation Decoder Loss:  0.33503553
Encoder Loss:  0.042774316  || Decoder Loss:  0.035340227 Validation Decoder Loss:  0.33503333
Encoder Loss:  0.04264469  || Decoder Loss:  0.035335958 Validation Decoder Loss:  0.33513921
Encoder Loss:  0.042502034  || Decoder Loss:  0.035335958 Validation Decoder Loss:  0.3352574
Encoder Loss:  0.04266185  || Decoder Loss:  0.035338692 Validation Decoder Loss:  0.3352967
Encoder Loss:  0.043226022  || Decoder Loss:  0.0353397 Validation Decoder Loss:  0.33511728
Encoder Loss:  0.042445984  || Decoder Loss:  0.035336327 Validation Decoder Loss:  0.33542365
Encoder Loss:  0.0425298  || Decoder Loss:  0.035336416 Validation Decoder Loss:  0.3355565
Encoder Loss:  0.0425085  || Decoder Loss:  0.035335153 Validation Decoder Loss:  0.3356272
Encoder Loss:  0.042623933  || Decoder Loss:  0.03533608 Validation Decoder Loss:  0.3356461
Encoder Loss:  0.04250923  || Decoder Loss:  0.03533487 Validation Decoder Loss:  0.3357194
Encoder Loss:  0.042741884  || Decoder Loss:  0.035335626 Validation Decoder Loss:  0.3357113
Encoder Loss:  0.042492367  || Decoder Loss:  0.035332642 Validation Decoder Loss:  0.33584124
Model: siamese_net_lr_0.043214035722113485 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33584124
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_16 (Conv3DT (None, 257, 10, 20, 1)    137       
_________________________________________________________________
reshape_16 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_16 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.03532417  || Decoder Loss:  0.03532417 Validation Decoder Loss:  0.32904503
Encoder Loss:  0.0347753  || Decoder Loss:  0.0347753 Validation Decoder Loss:  0.32952982
Encoder Loss:  0.03471829  || Decoder Loss:  0.03471829 Validation Decoder Loss:  0.3294446
Encoder Loss:  0.034688473  || Decoder Loss:  0.034688473 Validation Decoder Loss:  0.3293965
Encoder Loss:  0.03467155  || Decoder Loss:  0.03467155 Validation Decoder Loss:  0.32940707
Encoder Loss:  0.034657523  || Decoder Loss:  0.034657523 Validation Decoder Loss:  0.3294356
Encoder Loss:  0.0346459  || Decoder Loss:  0.0346459 Validation Decoder Loss:  0.32946092
Encoder Loss:  0.034636937  || Decoder Loss:  0.034636937 Validation Decoder Loss:  0.32948267
Encoder Loss:  0.03463  || Decoder Loss:  0.03463 Validation Decoder Loss:  0.32950112
Encoder Loss:  0.034624547  || Decoder Loss:  0.034624547 Validation Decoder Loss:  0.32951695
Encoder Loss:  0.034620203  || Decoder Loss:  0.034620203 Validation Decoder Loss:  0.32953072
Encoder Loss:  0.034616716  || Decoder Loss:  0.034616716 Validation Decoder Loss:  0.32954285
Encoder Loss:  0.034613844  || Decoder Loss:  0.034613844 Validation Decoder Loss:  0.32955363
Encoder Loss:  0.034611475  || Decoder Loss:  0.034611475 Validation Decoder Loss:  0.32956326
Encoder Loss:  0.034609474  || Decoder Loss:  0.034609474 Validation Decoder Loss:  0.32957196
Encoder Loss:  0.03460777  || Decoder Loss:  0.03460777 Validation Decoder Loss:  0.32957977
Encoder Loss:  0.03460632  || Decoder Loss:  0.03460632 Validation Decoder Loss:  0.3295869
Encoder Loss:  0.03460506  || Decoder Loss:  0.03460506 Validation Decoder Loss:  0.32959336
Encoder Loss:  0.03460395  || Decoder Loss:  0.03460395 Validation Decoder Loss:  0.32959926
Encoder Loss:  0.03460297  || Decoder Loss:  0.03460297 Validation Decoder Loss:  0.3296047
Encoder Loss:  0.034602106  || Decoder Loss:  0.034602106 Validation Decoder Loss:  0.32960966
Encoder Loss:  0.034601327  || Decoder Loss:  0.034601327 Validation Decoder Loss:  0.32961428
Encoder Loss:  0.034600627  || Decoder Loss:  0.034600627 Validation Decoder Loss:  0.3296185
Encoder Loss:  0.0346  || Decoder Loss:  0.0346 Validation Decoder Loss:  0.32962245
Encoder Loss:  0.034599416  || Decoder Loss:  0.034599416 Validation Decoder Loss:  0.32962614
Encoder Loss:  0.034598887  || Decoder Loss:  0.034598887 Validation Decoder Loss:  0.32962954
Encoder Loss:  0.0345984  || Decoder Loss:  0.0345984 Validation Decoder Loss:  0.32963276
Encoder Loss:  0.034597937  || Decoder Loss:  0.034597937 Validation Decoder Loss:  0.3296358
Encoder Loss:  0.034597527  || Decoder Loss:  0.034597527 Validation Decoder Loss:  0.3296386
Encoder Loss:  0.03459714  || Decoder Loss:  0.03459714 Validation Decoder Loss:  0.32964128
Encoder Loss:  0.034596767  || Decoder Loss:  0.034596767 Validation Decoder Loss:  0.32964388
Encoder Loss:  0.034596417  || Decoder Loss:  0.034596417 Validation Decoder Loss:  0.3296463
Encoder Loss:  0.034596097  || Decoder Loss:  0.034596097 Validation Decoder Loss:  0.3296486
Encoder Loss:  0.034595795  || Decoder Loss:  0.034595795 Validation Decoder Loss:  0.32965082
Encoder Loss:  0.034595493  || Decoder Loss:  0.034595493 Validation Decoder Loss:  0.329653
Encoder Loss:  0.03459522  || Decoder Loss:  0.03459522 Validation Decoder Loss:  0.32965505
Encoder Loss:  0.03459495  || Decoder Loss:  0.03459495 Validation Decoder Loss:  0.32965708
Encoder Loss:  0.03459469  || Decoder Loss:  0.03459469 Validation Decoder Loss:  0.32965901
Encoder Loss:  0.03459446  || Decoder Loss:  0.03459446 Validation Decoder Loss:  0.32966095
Encoder Loss:  0.034594215  || Decoder Loss:  0.034594215 Validation Decoder Loss:  0.3296628
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32966283
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_17 (Conv3DT (None, 257, 10, 20, 1)    787       
_________________________________________________________________
reshape_17 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 787
Trainable params: 787
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_17 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31570277  || Decoder Loss:  0.3928009 Validation Decoder Loss:  0.91203403
Encoder Loss:  0.3562926  || Decoder Loss:  0.4854983 Validation Decoder Loss:  1.0135443
Encoder Loss:  0.3340956  || Decoder Loss:  0.44577152 Validation Decoder Loss:  0.9139817
Encoder Loss:  0.34778428  || Decoder Loss:  0.47863582 Validation Decoder Loss:  0.89385045
Encoder Loss:  0.35629138  || Decoder Loss:  0.49151123 Validation Decoder Loss:  0.8668736
Encoder Loss:  0.3331453  || Decoder Loss:  0.45863706 Validation Decoder Loss:  0.8520972
Encoder Loss:  0.33041072  || Decoder Loss:  0.45428166 Validation Decoder Loss:  0.8155417
Encoder Loss:  0.33524215  || Decoder Loss:  0.46113628 Validation Decoder Loss:  0.83002365
Encoder Loss:  0.33313018  || Decoder Loss:  0.45905137 Validation Decoder Loss:  0.8135649
Encoder Loss:  0.33478147  || Decoder Loss:  0.4615601 Validation Decoder Loss:  0.77457464
Encoder Loss:  0.31915227  || Decoder Loss:  0.43913692 Validation Decoder Loss:  0.7533955
Encoder Loss:  0.24923259  || Decoder Loss:  0.33775708 Validation Decoder Loss:  0.47692764
Encoder Loss:  0.044850968  || Decoder Loss:  0.04202871 Validation Decoder Loss:  0.3309258
Encoder Loss:  0.04056425  || Decoder Loss:  0.035446092 Validation Decoder Loss:  0.33767086
Encoder Loss:  0.040147293  || Decoder Loss:  0.03539985 Validation Decoder Loss:  0.33814025
Encoder Loss:  0.040412463  || Decoder Loss:  0.03542442 Validation Decoder Loss:  0.33946726
Encoder Loss:  0.040515643  || Decoder Loss:  0.03545663 Validation Decoder Loss:  0.33905944
Encoder Loss:  0.04024035  || Decoder Loss:  0.03546574 Validation Decoder Loss:  0.334492
Encoder Loss:  0.040219773  || Decoder Loss:  0.035433363 Validation Decoder Loss:  0.33205667
Encoder Loss:  0.040176436  || Decoder Loss:  0.03542038 Validation Decoder Loss:  0.33013058
Encoder Loss:  0.04023066  || Decoder Loss:  0.035421096 Validation Decoder Loss:  0.32934687
Encoder Loss:  0.04030224  || Decoder Loss:  0.035428148 Validation Decoder Loss:  0.3304435
Encoder Loss:  0.040054593  || Decoder Loss:  0.03541134 Validation Decoder Loss:  0.3323234
Encoder Loss:  0.040190905  || Decoder Loss:  0.035403572 Validation Decoder Loss:  0.33431864
Encoder Loss:  0.040330082  || Decoder Loss:  0.035369556 Validation Decoder Loss:  0.3327731
Encoder Loss:  0.040289644  || Decoder Loss:  0.03541681 Validation Decoder Loss:  0.33142853
Encoder Loss:  0.04039334  || Decoder Loss:  0.0354257 Validation Decoder Loss:  0.3319304
Encoder Loss:  0.040092755  || Decoder Loss:  0.0354331 Validation Decoder Loss:  0.33423507
Encoder Loss:  0.040055208  || Decoder Loss:  0.035404067 Validation Decoder Loss:  0.3357458
Encoder Loss:  0.04014555  || Decoder Loss:  0.035411276 Validation Decoder Loss:  0.3346681
Encoder Loss:  0.040005807  || Decoder Loss:  0.035420727 Validation Decoder Loss:  0.33323693
Encoder Loss:  0.040048093  || Decoder Loss:  0.035433255 Validation Decoder Loss:  0.33271655
Encoder Loss:  0.040162057  || Decoder Loss:  0.03543332 Validation Decoder Loss:  0.33417875
Encoder Loss:  0.04009713  || Decoder Loss:  0.035397362 Validation Decoder Loss:  0.33630046
Encoder Loss:  0.040357426  || Decoder Loss:  0.035403 Validation Decoder Loss:  0.33565366
Encoder Loss:  0.040184278  || Decoder Loss:  0.03538644 Validation Decoder Loss:  0.33564264
Encoder Loss:  0.040272325  || Decoder Loss:  0.035371587 Validation Decoder Loss:  0.33753315
Encoder Loss:  0.040612053  || Decoder Loss:  0.03545882 Validation Decoder Loss:  0.33511105
Encoder Loss:  0.04071473  || Decoder Loss:  0.036212914 Validation Decoder Loss:  0.33926743
Encoder Loss:  0.04231853  || Decoder Loss:  0.038405575 Validation Decoder Loss:  0.34322304
Model: siamese_net_lr_0.9422771759318285 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34322304
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_18 (Conv3DT (None, 514, 5, 20, 1)     74        
_________________________________________________________________
reshape_18 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 74
Trainable params: 74
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_18 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035366036  || Decoder Loss:  0.035366036 Validation Decoder Loss:  0.3303234
Encoder Loss:  0.034842864  || Decoder Loss:  0.034842864 Validation Decoder Loss:  0.33018813
Encoder Loss:  0.03475972  || Decoder Loss:  0.03475972 Validation Decoder Loss:  0.3300908
Encoder Loss:  0.034724616  || Decoder Loss:  0.034724616 Validation Decoder Loss:  0.33003122
Encoder Loss:  0.03470657  || Decoder Loss:  0.03470657 Validation Decoder Loss:  0.3300459
Encoder Loss:  0.034692023  || Decoder Loss:  0.034692023 Validation Decoder Loss:  0.33008355
Encoder Loss:  0.03468014  || Decoder Loss:  0.03468014 Validation Decoder Loss:  0.3301167
Encoder Loss:  0.034670915  || Decoder Loss:  0.034670915 Validation Decoder Loss:  0.33014563
Encoder Loss:  0.034663726  || Decoder Loss:  0.034663726 Validation Decoder Loss:  0.33017117
Encoder Loss:  0.03465806  || Decoder Loss:  0.03465806 Validation Decoder Loss:  0.3301937
Encoder Loss:  0.034653533  || Decoder Loss:  0.034653533 Validation Decoder Loss:  0.33021355
Encoder Loss:  0.034649886  || Decoder Loss:  0.034649886 Validation Decoder Loss:  0.33023107
Encoder Loss:  0.03464688  || Decoder Loss:  0.03464688 Validation Decoder Loss:  0.3302465
Encoder Loss:  0.034644388  || Decoder Loss:  0.034644388 Validation Decoder Loss:  0.33026016
Encoder Loss:  0.034642275  || Decoder Loss:  0.034642275 Validation Decoder Loss:  0.33027223
Encoder Loss:  0.034640495  || Decoder Loss:  0.034640495 Validation Decoder Loss:  0.330283
Encoder Loss:  0.03463895  || Decoder Loss:  0.03463895 Validation Decoder Loss:  0.33029258
Encoder Loss:  0.034637608  || Decoder Loss:  0.034637608 Validation Decoder Loss:  0.33030123
Encoder Loss:  0.034636434  || Decoder Loss:  0.034636434 Validation Decoder Loss:  0.33030894
Encoder Loss:  0.034635406  || Decoder Loss:  0.034635406 Validation Decoder Loss:  0.33031598
Encoder Loss:  0.034634482  || Decoder Loss:  0.034634482 Validation Decoder Loss:  0.33032233
Encoder Loss:  0.03463366  || Decoder Loss:  0.03463366 Validation Decoder Loss:  0.33032817
Encoder Loss:  0.034632932  || Decoder Loss:  0.034632932 Validation Decoder Loss:  0.33033347
Encoder Loss:  0.034632247  || Decoder Loss:  0.034632247 Validation Decoder Loss:  0.33033836
Encoder Loss:  0.034631632  || Decoder Loss:  0.034631632 Validation Decoder Loss:  0.3303429
Encoder Loss:  0.03463107  || Decoder Loss:  0.03463107 Validation Decoder Loss:  0.33034706
Encoder Loss:  0.034630556  || Decoder Loss:  0.034630556 Validation Decoder Loss:  0.33035094
Encoder Loss:  0.03463009  || Decoder Loss:  0.03463009 Validation Decoder Loss:  0.3303545
Encoder Loss:  0.034629628  || Decoder Loss:  0.034629628 Validation Decoder Loss:  0.3303579
Encoder Loss:  0.03462923  || Decoder Loss:  0.03462923 Validation Decoder Loss:  0.33036107
Encoder Loss:  0.034628835  || Decoder Loss:  0.034628835 Validation Decoder Loss:  0.33036405
Encoder Loss:  0.034628466  || Decoder Loss:  0.034628466 Validation Decoder Loss:  0.33036682
Encoder Loss:  0.03462814  || Decoder Loss:  0.03462814 Validation Decoder Loss:  0.33036944
Encoder Loss:  0.034627806  || Decoder Loss:  0.034627806 Validation Decoder Loss:  0.33037198
Encoder Loss:  0.0346275  || Decoder Loss:  0.0346275 Validation Decoder Loss:  0.33037436
Encoder Loss:  0.034627214  || Decoder Loss:  0.034627214 Validation Decoder Loss:  0.33037663
Encoder Loss:  0.03462693  || Decoder Loss:  0.03462693 Validation Decoder Loss:  0.33037877
Encoder Loss:  0.034626663  || Decoder Loss:  0.034626663 Validation Decoder Loss:  0.3303808
Encoder Loss:  0.034626413  || Decoder Loss:  0.034626413 Validation Decoder Loss:  0.33038282
Encoder Loss:  0.03462616  || Decoder Loss:  0.03462616 Validation Decoder Loss:  0.3303848
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33038476
Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_19 (Conv3DT (None, 237, 10, 20, 1)    97        
_________________________________________________________________
reshape_19 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_19 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19419865  || Decoder Loss:  0.044532202 Validation Decoder Loss:  0.34444392
Encoder Loss:  0.2028258  || Decoder Loss:  0.09064127 Validation Decoder Loss:  0.39913017
Encoder Loss:  0.06561443  || Decoder Loss:  0.038022622 Validation Decoder Loss:  0.33066005
Encoder Loss:  0.056315724  || Decoder Loss:  0.034995142 Validation Decoder Loss:  0.33197135
Encoder Loss:  0.048659936  || Decoder Loss:  0.034846243 Validation Decoder Loss:  0.33331448
Encoder Loss:  0.04879869  || Decoder Loss:  0.034842256 Validation Decoder Loss:  0.3331286
Encoder Loss:  0.04969294  || Decoder Loss:  0.03501358 Validation Decoder Loss:  0.33188033
Encoder Loss:  0.049868774  || Decoder Loss:  0.035614647 Validation Decoder Loss:  0.33623683
Encoder Loss:  0.046326898  || Decoder Loss:  0.035452664 Validation Decoder Loss:  0.33356357
Encoder Loss:  0.047695562  || Decoder Loss:  0.03546779 Validation Decoder Loss:  0.33559805
Encoder Loss:  0.04583228  || Decoder Loss:  0.035267413 Validation Decoder Loss:  0.3360196
Encoder Loss:  0.04681839  || Decoder Loss:  0.035353422 Validation Decoder Loss:  0.3369454
Encoder Loss:  0.048345555  || Decoder Loss:  0.03539183 Validation Decoder Loss:  0.33370158
Encoder Loss:  0.046928436  || Decoder Loss:  0.035348702 Validation Decoder Loss:  0.3367391
Encoder Loss:  0.047050748  || Decoder Loss:  0.035452574 Validation Decoder Loss:  0.33219254
Encoder Loss:  0.048684668  || Decoder Loss:  0.035284106 Validation Decoder Loss:  0.33581954
Encoder Loss:  0.048256114  || Decoder Loss:  0.035379965 Validation Decoder Loss:  0.33398122
Encoder Loss:  0.045728434  || Decoder Loss:  0.035400096 Validation Decoder Loss:  0.33599317
Encoder Loss:  0.046575166  || Decoder Loss:  0.035135623 Validation Decoder Loss:  0.33817938
Encoder Loss:  0.044109255  || Decoder Loss:  0.035204116 Validation Decoder Loss:  0.3341222
Encoder Loss:  0.047148105  || Decoder Loss:  0.035235304 Validation Decoder Loss:  0.3377425
Encoder Loss:  0.043247253  || Decoder Loss:  0.03514988 Validation Decoder Loss:  0.33680207
Encoder Loss:  0.04640523  || Decoder Loss:  0.035265915 Validation Decoder Loss:  0.33476722
Encoder Loss:  0.04700497  || Decoder Loss:  0.035228536 Validation Decoder Loss:  0.33981392
Encoder Loss:  0.047304466  || Decoder Loss:  0.03529601 Validation Decoder Loss:  0.33499426
Encoder Loss:  0.0433677  || Decoder Loss:  0.035086602 Validation Decoder Loss:  0.33592832
Encoder Loss:  0.044499196  || Decoder Loss:  0.03513933 Validation Decoder Loss:  0.33408847
Encoder Loss:  0.046493936  || Decoder Loss:  0.03522733 Validation Decoder Loss:  0.3341437
Encoder Loss:  0.04643072  || Decoder Loss:  0.03516311 Validation Decoder Loss:  0.33808923
Encoder Loss:  0.045273446  || Decoder Loss:  0.03518992 Validation Decoder Loss:  0.33613184
Encoder Loss:  0.044133555  || Decoder Loss:  0.035068557 Validation Decoder Loss:  0.33630276
Encoder Loss:  0.04336596  || Decoder Loss:  0.035207275 Validation Decoder Loss:  0.33570403
Encoder Loss:  0.04130234  || Decoder Loss:  0.034982327 Validation Decoder Loss:  0.33406234
Encoder Loss:  0.04128396  || Decoder Loss:  0.03508889 Validation Decoder Loss:  0.33730143
Encoder Loss:  0.04124663  || Decoder Loss:  0.035070423 Validation Decoder Loss:  0.3358201
Encoder Loss:  0.04123533  || Decoder Loss:  0.03506607 Validation Decoder Loss:  0.3346784
Encoder Loss:  0.041218616  || Decoder Loss:  0.0350475 Validation Decoder Loss:  0.33521056
Encoder Loss:  0.041250736  || Decoder Loss:  0.035086337 Validation Decoder Loss:  0.33420634
Encoder Loss:  0.041247915  || Decoder Loss:  0.035072833 Validation Decoder Loss:  0.33409786
Encoder Loss:  0.041257598  || Decoder Loss:  0.03507622 Validation Decoder Loss:  0.3350169
Model: siamese_net_lr_0.17553793225053585 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3350169
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_20 (Conv3DT (None, 444, 5, 20, 1)     382       
_________________________________________________________________
reshape_20 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 382
Trainable params: 382
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_20 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28022158  || Decoder Loss:  0.34559464 Validation Decoder Loss:  1.4058353
Encoder Loss:  0.27503893  || Decoder Loss:  0.4920936 Validation Decoder Loss:  0.97895586
Encoder Loss:  0.26358688  || Decoder Loss:  0.43386626 Validation Decoder Loss:  1.2904711
Encoder Loss:  0.27107403  || Decoder Loss:  0.4961393 Validation Decoder Loss:  1.1953253
Encoder Loss:  0.26438737  || Decoder Loss:  0.48595536 Validation Decoder Loss:  1.1762892
Encoder Loss:  0.18590939  || Decoder Loss:  0.32606754 Validation Decoder Loss:  0.32540908
Encoder Loss:  0.06219965  || Decoder Loss:  0.07397941 Validation Decoder Loss:  0.39107066
Encoder Loss:  0.044590782  || Decoder Loss:  0.0380005 Validation Decoder Loss:  0.326583
Encoder Loss:  0.04317358  || Decoder Loss:  0.034753118 Validation Decoder Loss:  0.33654824
Encoder Loss:  0.045526333  || Decoder Loss:  0.03443896 Validation Decoder Loss:  0.33632585
Encoder Loss:  0.04414816  || Decoder Loss:  0.034232326 Validation Decoder Loss:  0.33773625
Encoder Loss:  0.043491617  || Decoder Loss:  0.034319296 Validation Decoder Loss:  0.33240005
Encoder Loss:  0.045603752  || Decoder Loss:  0.03491244 Validation Decoder Loss:  0.30623066
Encoder Loss:  0.044210088  || Decoder Loss:  0.036752902 Validation Decoder Loss:  0.3654601
Encoder Loss:  0.04340635  || Decoder Loss:  0.03543695 Validation Decoder Loss:  0.31524923
Encoder Loss:  0.043686498  || Decoder Loss:  0.035301883 Validation Decoder Loss:  0.32256916
Encoder Loss:  0.043326564  || Decoder Loss:  0.03527705 Validation Decoder Loss:  0.3219072
Encoder Loss:  0.043187942  || Decoder Loss:  0.03537352 Validation Decoder Loss:  0.31970596
Encoder Loss:  0.043213382  || Decoder Loss:  0.035265297 Validation Decoder Loss:  0.33412975
Encoder Loss:  0.042900987  || Decoder Loss:  0.03469197 Validation Decoder Loss:  0.31436777
Encoder Loss:  0.043243583  || Decoder Loss:  0.035694323 Validation Decoder Loss:  0.3357235
Encoder Loss:  0.042697612  || Decoder Loss:  0.034616366 Validation Decoder Loss:  0.3185742
Encoder Loss:  0.04340007  || Decoder Loss:  0.035328973 Validation Decoder Loss:  0.3269859
Encoder Loss:  0.042798128  || Decoder Loss:  0.035056103 Validation Decoder Loss:  0.3201114
Encoder Loss:  0.042951196  || Decoder Loss:  0.03518523 Validation Decoder Loss:  0.33731776
Encoder Loss:  0.043066286  || Decoder Loss:  0.034624305 Validation Decoder Loss:  0.31884253
Encoder Loss:  0.04326854  || Decoder Loss:  0.035443276 Validation Decoder Loss:  0.32342076
Encoder Loss:  0.04314859  || Decoder Loss:  0.035307147 Validation Decoder Loss:  0.3248965
Encoder Loss:  0.04298918  || Decoder Loss:  0.035151437 Validation Decoder Loss:  0.3280747
Encoder Loss:  0.04307948  || Decoder Loss:  0.035010528 Validation Decoder Loss:  0.3218494
Encoder Loss:  0.04333386  || Decoder Loss:  0.03538948 Validation Decoder Loss:  0.32889923
Encoder Loss:  0.042849217  || Decoder Loss:  0.03487703 Validation Decoder Loss:  0.32505205
Encoder Loss:  0.043192722  || Decoder Loss:  0.035137072 Validation Decoder Loss:  0.3254807
Encoder Loss:  0.042901177  || Decoder Loss:  0.03509426 Validation Decoder Loss:  0.3277861
Encoder Loss:  0.042746257  || Decoder Loss:  0.03488253 Validation Decoder Loss:  0.33226147
Encoder Loss:  0.044235755  || Decoder Loss:  0.034588255 Validation Decoder Loss:  0.32048345
Encoder Loss:  0.045612726  || Decoder Loss:  0.03504737 Validation Decoder Loss:  0.30583277
Encoder Loss:  0.047056455  || Decoder Loss:  0.037348732 Validation Decoder Loss:  0.2974193
Encoder Loss:  0.04440063  || Decoder Loss:  0.037216537 Validation Decoder Loss:  0.30265492
Encoder Loss:  0.04420778  || Decoder Loss:  0.03767563 Validation Decoder Loss:  0.34643507
Model: siamese_net_lr_0.10369540770133676 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34643507
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_21 (Conv3DT (None, 257, 10, 20, 1)    137       
_________________________________________________________________
reshape_21 (Reshape)         (None, 2570, 20, 1)       0         
=================================================================
Total params: 137
Trainable params: 137
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_21 (Conv2DT (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.45702848  || Decoder Loss:  0.49208435 Validation Decoder Loss:  0.33171993
Encoder Loss:  0.29139426  || Decoder Loss:  0.036537293 Validation Decoder Loss:  0.3311404
Encoder Loss:  0.29506087  || Decoder Loss:  0.14719424 Validation Decoder Loss:  0.46354058
Encoder Loss:  0.13656706  || Decoder Loss:  0.2271586 Validation Decoder Loss:  0.33078274
Encoder Loss:  0.054848522  || Decoder Loss:  0.03524704 Validation Decoder Loss:  0.3305831
Encoder Loss:  0.052329436  || Decoder Loss:  0.035232715 Validation Decoder Loss:  0.33073112
Encoder Loss:  0.0527333  || Decoder Loss:  0.03530479 Validation Decoder Loss:  0.3317328
Encoder Loss:  0.057702556  || Decoder Loss:  0.035614148 Validation Decoder Loss:  0.33177733
Encoder Loss:  0.054151718  || Decoder Loss:  0.03554741 Validation Decoder Loss:  0.3324828
Encoder Loss:  0.05356807  || Decoder Loss:  0.035623442 Validation Decoder Loss:  0.33229628
Encoder Loss:  0.05423861  || Decoder Loss:  0.035562042 Validation Decoder Loss:  0.3324641
Encoder Loss:  0.0535224  || Decoder Loss:  0.035675477 Validation Decoder Loss:  0.3331021
Encoder Loss:  0.05307515  || Decoder Loss:  0.03574296 Validation Decoder Loss:  0.33339334
Encoder Loss:  0.050924193  || Decoder Loss:  0.03563368 Validation Decoder Loss:  0.3328743
Encoder Loss:  0.05158589  || Decoder Loss:  0.035575192 Validation Decoder Loss:  0.33275974
Encoder Loss:  0.048771586  || Decoder Loss:  0.035651706 Validation Decoder Loss:  0.33182478
Encoder Loss:  0.054336306  || Decoder Loss:  0.03567301 Validation Decoder Loss:  0.3336591
Encoder Loss:  0.05116182  || Decoder Loss:  0.035547566 Validation Decoder Loss:  0.33402434
Encoder Loss:  0.05127393  || Decoder Loss:  0.03561829 Validation Decoder Loss:  0.33252954
Encoder Loss:  0.049619727  || Decoder Loss:  0.03560568 Validation Decoder Loss:  0.33200237
Encoder Loss:  0.050045732  || Decoder Loss:  0.035509743 Validation Decoder Loss:  0.33203188
Encoder Loss:  0.049777556  || Decoder Loss:  0.035514005 Validation Decoder Loss:  0.33488232
Encoder Loss:  0.053005084  || Decoder Loss:  0.0356792 Validation Decoder Loss:  0.33203834
Encoder Loss:  0.049205136  || Decoder Loss:  0.03550639 Validation Decoder Loss:  0.33282912
Encoder Loss:  0.048948303  || Decoder Loss:  0.035625115 Validation Decoder Loss:  0.33198997
Encoder Loss:  0.050023638  || Decoder Loss:  0.03548022 Validation Decoder Loss:  0.3319741
Encoder Loss:  0.049439803  || Decoder Loss:  0.035501633 Validation Decoder Loss:  0.33339787
Encoder Loss:  0.050173335  || Decoder Loss:  0.035624858 Validation Decoder Loss:  0.33230865
Encoder Loss:  0.04903376  || Decoder Loss:  0.035529863 Validation Decoder Loss:  0.33190846
Encoder Loss:  0.048676185  || Decoder Loss:  0.03550717 Validation Decoder Loss:  0.3337825
Encoder Loss:  0.05153115  || Decoder Loss:  0.035616856 Validation Decoder Loss:  0.3318628
Encoder Loss:  0.047178213  || Decoder Loss:  0.035465557 Validation Decoder Loss:  0.33308086
Encoder Loss:  0.053338517  || Decoder Loss:  0.035595477 Validation Decoder Loss:  0.33189264
Encoder Loss:  0.049955998  || Decoder Loss:  0.03549345 Validation Decoder Loss:  0.33268964
Encoder Loss:  0.04908608  || Decoder Loss:  0.035577033 Validation Decoder Loss:  0.33234814
Encoder Loss:  0.047719825  || Decoder Loss:  0.03547417 Validation Decoder Loss:  0.33269817
Encoder Loss:  0.05069954  || Decoder Loss:  0.035567142 Validation Decoder Loss:  0.33230603
Encoder Loss:  0.04627637  || Decoder Loss:  0.035514843 Validation Decoder Loss:  0.33174178
Encoder Loss:  0.049418677  || Decoder Loss:  0.03548322 Validation Decoder Loss:  0.33355334
Encoder Loss:  0.048447706  || Decoder Loss:  0.03547239 Validation Decoder Loss:  0.33184487
Model: siamese_net_lr_0.9712493704742694 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33184487
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_22 (Conv3DT (None, 252, 10, 20, 1)    379       
_________________________________________________________________
reshape_22 (Reshape)         (None, 2520, 20, 1)       0         
=================================================================
Total params: 379
Trainable params: 379
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 2520, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_22 (Conv2DT (None, 2607, 20, 1)       89        
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.341768  || Decoder Loss:  0.36341 Validation Decoder Loss:  1.1278844
Encoder Loss:  0.12938406  || Decoder Loss:  0.13567476 Validation Decoder Loss:  0.3259423
Encoder Loss:  0.048137113  || Decoder Loss:  0.044158556 Validation Decoder Loss:  0.30012736
Encoder Loss:  0.042493697  || Decoder Loss:  0.040523812 Validation Decoder Loss:  0.3796356
Encoder Loss:  0.044770923  || Decoder Loss:  0.04181978 Validation Decoder Loss:  0.3018406
Encoder Loss:  0.043779805  || Decoder Loss:  0.041251063 Validation Decoder Loss:  0.388529
Encoder Loss:  0.042329583  || Decoder Loss:  0.04027994 Validation Decoder Loss:  0.3036447
Encoder Loss:  0.04173911  || Decoder Loss:  0.039692584 Validation Decoder Loss:  0.38177916
Encoder Loss:  0.041124474  || Decoder Loss:  0.039161496 Validation Decoder Loss:  0.37691972
Encoder Loss:  0.040744975  || Decoder Loss:  0.03873007 Validation Decoder Loss:  0.30374116
Encoder Loss:  0.040604603  || Decoder Loss:  0.03859761 Validation Decoder Loss:  0.3040676
Encoder Loss:  0.041178  || Decoder Loss:  0.03909429 Validation Decoder Loss:  0.37835354
Encoder Loss:  0.04040536  || Decoder Loss:  0.0385146 Validation Decoder Loss:  0.37650907
Encoder Loss:  0.03980399  || Decoder Loss:  0.03808815 Validation Decoder Loss:  0.3768962
Encoder Loss:  0.039426222  || Decoder Loss:  0.037642952 Validation Decoder Loss:  0.30582348
Encoder Loss:  0.040932883  || Decoder Loss:  0.038669847 Validation Decoder Loss:  0.3037249
Encoder Loss:  0.040003832  || Decoder Loss:  0.038166296 Validation Decoder Loss:  0.37806627
Encoder Loss:  0.03923887  || Decoder Loss:  0.03761331 Validation Decoder Loss:  0.37232447
Encoder Loss:  0.04012889  || Decoder Loss:  0.0378938 Validation Decoder Loss:  0.3064446
Encoder Loss:  0.04022687  || Decoder Loss:  0.03817416 Validation Decoder Loss:  0.3795234
Encoder Loss:  0.040009424  || Decoder Loss:  0.03812304 Validation Decoder Loss:  0.37831336
Encoder Loss:  0.039952017  || Decoder Loss:  0.037855584 Validation Decoder Loss:  0.30491292
Encoder Loss:  0.04002232  || Decoder Loss:  0.03803321 Validation Decoder Loss:  0.37908974
Encoder Loss:  0.040206105  || Decoder Loss:  0.03811607 Validation Decoder Loss:  0.37903476
Encoder Loss:  0.03991241  || Decoder Loss:  0.037836444 Validation Decoder Loss:  0.3758667
Encoder Loss:  0.039436284  || Decoder Loss:  0.037577614 Validation Decoder Loss:  0.30523324
Encoder Loss:  0.039679673  || Decoder Loss:  0.03774244 Validation Decoder Loss:  0.3706021
Encoder Loss:  0.03959618  || Decoder Loss:  0.037570983 Validation Decoder Loss:  0.3733406
Encoder Loss:  0.039759025  || Decoder Loss:  0.03768541 Validation Decoder Loss:  0.3725199
Encoder Loss:  0.03895271  || Decoder Loss:  0.03738038 Validation Decoder Loss:  0.3719926
Encoder Loss:  0.03877183  || Decoder Loss:  0.037070483 Validation Decoder Loss:  0.30793667
Encoder Loss:  0.038888697  || Decoder Loss:  0.037015602 Validation Decoder Loss:  0.37637383
Encoder Loss:  0.039289173  || Decoder Loss:  0.037415 Validation Decoder Loss:  0.37183768
Encoder Loss:  0.039037824  || Decoder Loss:  0.03727711 Validation Decoder Loss:  0.37171417
Encoder Loss:  0.03913885  || Decoder Loss:  0.037116237 Validation Decoder Loss:  0.30606297
Encoder Loss:  0.039292075  || Decoder Loss:  0.0374137 Validation Decoder Loss:  0.37189883
Encoder Loss:  0.039163552  || Decoder Loss:  0.037143104 Validation Decoder Loss:  0.3048312
Encoder Loss:  0.039276015  || Decoder Loss:  0.037365913 Validation Decoder Loss:  0.30679938
Encoder Loss:  0.038960256  || Decoder Loss:  0.037127826 Validation Decoder Loss:  0.308011
Encoder Loss:  0.038717557  || Decoder Loss:  0.0369934 Validation Decoder Loss:  0.37179112
Model: siamese_net_lr_0.8567953347072726 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37179112
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_23 (Conv3DT (None, 79, 30, 20, 1)     225       
_________________________________________________________________
reshape_23 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 225
Trainable params: 225
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_70"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_71"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_23 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22319883  || Decoder Loss:  0.35500988 Validation Decoder Loss:  0.69152355
Encoder Loss:  0.11788256  || Decoder Loss:  0.26067555 Validation Decoder Loss:  0.32888836
Encoder Loss:  0.0782924  || Decoder Loss:  0.065944955 Validation Decoder Loss:  0.33175078
Encoder Loss:  0.06964147  || Decoder Loss:  0.04007241 Validation Decoder Loss:  0.32935527
Encoder Loss:  0.061446458  || Decoder Loss:  0.03894056 Validation Decoder Loss:  0.3317334
Encoder Loss:  0.062624395  || Decoder Loss:  0.038924698 Validation Decoder Loss:  0.3438738
Encoder Loss:  0.058646634  || Decoder Loss:  0.040021375 Validation Decoder Loss:  0.33501846
Encoder Loss:  0.05300581  || Decoder Loss:  0.03898828 Validation Decoder Loss:  0.3388734
Encoder Loss:  0.061280087  || Decoder Loss:  0.039694287 Validation Decoder Loss:  0.33457208
Encoder Loss:  0.052209213  || Decoder Loss:  0.039057147 Validation Decoder Loss:  0.3359385
Encoder Loss:  0.052646223  || Decoder Loss:  0.0388362 Validation Decoder Loss:  0.33809605
Encoder Loss:  0.052264616  || Decoder Loss:  0.03849575 Validation Decoder Loss:  0.33454248
Encoder Loss:  0.052260075  || Decoder Loss:  0.03825012 Validation Decoder Loss:  0.34229013
Encoder Loss:  0.05203755  || Decoder Loss:  0.0383317 Validation Decoder Loss:  0.3351997
Encoder Loss:  0.051757857  || Decoder Loss:  0.038012873 Validation Decoder Loss:  0.330137
Encoder Loss:  0.057291135  || Decoder Loss:  0.0382852 Validation Decoder Loss:  0.34002236
Encoder Loss:  0.058167323  || Decoder Loss:  0.039494324 Validation Decoder Loss:  0.33767366
Encoder Loss:  0.05050521  || Decoder Loss:  0.03852744 Validation Decoder Loss:  0.33617836
Encoder Loss:  0.05434193  || Decoder Loss:  0.038454887 Validation Decoder Loss:  0.33457208
Encoder Loss:  0.055844184  || Decoder Loss:  0.038428638 Validation Decoder Loss:  0.33520982
Encoder Loss:  0.053470396  || Decoder Loss:  0.03812516 Validation Decoder Loss:  0.33812657
Encoder Loss:  0.05037281  || Decoder Loss:  0.037714887 Validation Decoder Loss:  0.34217972
Encoder Loss:  0.050755  || Decoder Loss:  0.038223345 Validation Decoder Loss:  0.340895
Encoder Loss:  0.05109179  || Decoder Loss:  0.037896503 Validation Decoder Loss:  0.33668885
Encoder Loss:  0.049968254  || Decoder Loss:  0.03708878 Validation Decoder Loss:  0.33542272
Encoder Loss:  0.051766723  || Decoder Loss:  0.03752844 Validation Decoder Loss:  0.33742458
Encoder Loss:  0.0517066  || Decoder Loss:  0.03725577 Validation Decoder Loss:  0.33755493
Encoder Loss:  0.050184865  || Decoder Loss:  0.037548855 Validation Decoder Loss:  0.3354104
Encoder Loss:  0.046779346  || Decoder Loss:  0.03678488 Validation Decoder Loss:  0.33829582
Encoder Loss:  0.046445742  || Decoder Loss:  0.036597714 Validation Decoder Loss:  0.33909684
Encoder Loss:  0.04660136  || Decoder Loss:  0.03661667 Validation Decoder Loss:  0.33853632
Encoder Loss:  0.046618156  || Decoder Loss:  0.036413424 Validation Decoder Loss:  0.33723372
Encoder Loss:  0.046643917  || Decoder Loss:  0.036587942 Validation Decoder Loss:  0.33662242
Encoder Loss:  0.04646338  || Decoder Loss:  0.036558516 Validation Decoder Loss:  0.33766124
Encoder Loss:  0.04653462  || Decoder Loss:  0.036332395 Validation Decoder Loss:  0.3349844
Encoder Loss:  0.04630119  || Decoder Loss:  0.036243454 Validation Decoder Loss:  0.33779475
Encoder Loss:  0.046427317  || Decoder Loss:  0.036186386 Validation Decoder Loss:  0.33463615
Encoder Loss:  0.04642635  || Decoder Loss:  0.03623293 Validation Decoder Loss:  0.33571118
Encoder Loss:  0.046326857  || Decoder Loss:  0.03603687 Validation Decoder Loss:  0.33810043
Encoder Loss:  0.046289787  || Decoder Loss:  0.03611 Validation Decoder Loss:  0.33681834
Model: siamese_net_lr_0.35431890721287074 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3368183
Model: "sequential_72"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_24 (Conv3DT (None, 80, 29, 20, 1)     358       
_________________________________________________________________
reshape_24 (Reshape)         (None, 2320, 20, 1)       0         
=================================================================
Total params: 358
Trainable params: 358
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_73"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 2320, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_74"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_24 (Conv2DT (None, 2607, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.076502465  || Decoder Loss:  0.0877868 Validation Decoder Loss:  0.3327958
Encoder Loss:  0.05927362  || Decoder Loss:  0.04046733 Validation Decoder Loss:  0.33506835
Encoder Loss:  0.054955095  || Decoder Loss:  0.038711194 Validation Decoder Loss:  0.33259627
Encoder Loss:  0.049756125  || Decoder Loss:  0.036772583 Validation Decoder Loss:  0.3329645
Encoder Loss:  0.049807068  || Decoder Loss:  0.035818554 Validation Decoder Loss:  0.33479613
Encoder Loss:  0.049471773  || Decoder Loss:  0.03816405 Validation Decoder Loss:  0.33977124
Encoder Loss:  0.0497774  || Decoder Loss:  0.03666309 Validation Decoder Loss:  0.33851475
Encoder Loss:  0.04984213  || Decoder Loss:  0.03659141 Validation Decoder Loss:  0.33573273
Encoder Loss:  0.05291969  || Decoder Loss:  0.03613687 Validation Decoder Loss:  0.33504415
Encoder Loss:  0.048979882  || Decoder Loss:  0.035369955 Validation Decoder Loss:  0.3363179
Encoder Loss:  0.049062777  || Decoder Loss:  0.03551542 Validation Decoder Loss:  0.3339974
Encoder Loss:  0.050360855  || Decoder Loss:  0.035833437 Validation Decoder Loss:  0.33500355
Encoder Loss:  0.04894297  || Decoder Loss:  0.03536108 Validation Decoder Loss:  0.3354739
Encoder Loss:  0.049263284  || Decoder Loss:  0.03543764 Validation Decoder Loss:  0.33514765
Encoder Loss:  0.0522481  || Decoder Loss:  0.036088105 Validation Decoder Loss:  0.3303837
Encoder Loss:  0.051552992  || Decoder Loss:  0.03586415 Validation Decoder Loss:  0.33413792
Encoder Loss:  0.04884695  || Decoder Loss:  0.03537623 Validation Decoder Loss:  0.33398044
Encoder Loss:  0.04901884  || Decoder Loss:  0.035378605 Validation Decoder Loss:  0.3343737
Encoder Loss:  0.049388718  || Decoder Loss:  0.035118297 Validation Decoder Loss:  0.33458638
Encoder Loss:  0.050013065  || Decoder Loss:  0.035399884 Validation Decoder Loss:  0.33408827
Encoder Loss:  0.050153345  || Decoder Loss:  0.035423044 Validation Decoder Loss:  0.334601
Encoder Loss:  0.04897651  || Decoder Loss:  0.03536176 Validation Decoder Loss:  0.33422524
Encoder Loss:  0.049288683  || Decoder Loss:  0.03528408 Validation Decoder Loss:  0.3335427
Encoder Loss:  0.048961867  || Decoder Loss:  0.03521224 Validation Decoder Loss:  0.33590227
Encoder Loss:  0.04959876  || Decoder Loss:  0.03529959 Validation Decoder Loss:  0.33455387
Encoder Loss:  0.049665853  || Decoder Loss:  0.03551672 Validation Decoder Loss:  0.33290267
Encoder Loss:  0.049039274  || Decoder Loss:  0.03508873 Validation Decoder Loss:  0.333898
Encoder Loss:  0.04883493  || Decoder Loss:  0.035114497 Validation Decoder Loss:  0.33517107
Encoder Loss:  0.049591094  || Decoder Loss:  0.035439774 Validation Decoder Loss:  0.3327255
Encoder Loss:  0.04909902  || Decoder Loss:  0.035082072 Validation Decoder Loss:  0.3343161
Encoder Loss:  0.049546205  || Decoder Loss:  0.035212692 Validation Decoder Loss:  0.33318168
Encoder Loss:  0.04877279  || Decoder Loss:  0.0350275 Validation Decoder Loss:  0.33389813
Encoder Loss:  0.048893847  || Decoder Loss:  0.03523474 Validation Decoder Loss:  0.3340451
Encoder Loss:  0.04930441  || Decoder Loss:  0.03526541 Validation Decoder Loss:  0.33336216
Encoder Loss:  0.048929833  || Decoder Loss:  0.035243202 Validation Decoder Loss:  0.33313078
Encoder Loss:  0.0491487  || Decoder Loss:  0.03511369 Validation Decoder Loss:  0.33511868
Encoder Loss:  0.049062878  || Decoder Loss:  0.035160884 Validation Decoder Loss:  0.3329813
Encoder Loss:  0.048870735  || Decoder Loss:  0.035109166 Validation Decoder Loss:  0.33356318
Encoder Loss:  0.04968493  || Decoder Loss:  0.035037003 Validation Decoder Loss:  0.33297315
Encoder Loss:  0.048808817  || Decoder Loss:  0.035089538 Validation Decoder Loss:  0.33325857
Model: siamese_net_lr_0.08976404975886587 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33325857
Model: "sequential_75"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_25 (Conv3DT (None, 232, 10, 20, 1)    213       
_________________________________________________________________
reshape_25 (Reshape)         (None, 2320, 20, 1)       0         
=================================================================
Total params: 213
Trainable params: 213
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_76"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 2320, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_25 (Conv2DT (None, 2607, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1001581  || Decoder Loss:  0.060265318 Validation Decoder Loss:  0.3314995
Encoder Loss:  0.041889314  || Decoder Loss:  0.035982236 Validation Decoder Loss:  0.329794
Encoder Loss:  0.04010687  || Decoder Loss:  0.034624495 Validation Decoder Loss:  0.33114654
Encoder Loss:  0.040178794  || Decoder Loss:  0.034288924 Validation Decoder Loss:  0.33138078
Encoder Loss:  0.039488852  || Decoder Loss:  0.034173697 Validation Decoder Loss:  0.33130392
Encoder Loss:  0.039046273  || Decoder Loss:  0.034075726 Validation Decoder Loss:  0.3312439
Encoder Loss:  0.039271053  || Decoder Loss:  0.03402295 Validation Decoder Loss:  0.33114654
Encoder Loss:  0.039682426  || Decoder Loss:  0.033976454 Validation Decoder Loss:  0.33113542
Encoder Loss:  0.03968414  || Decoder Loss:  0.033920113 Validation Decoder Loss:  0.33086443
Encoder Loss:  0.039399397  || Decoder Loss:  0.033932135 Validation Decoder Loss:  0.33064324
Encoder Loss:  0.03871475  || Decoder Loss:  0.03386043 Validation Decoder Loss:  0.33102694
Encoder Loss:  0.038698934  || Decoder Loss:  0.033858445 Validation Decoder Loss:  0.3313201
Encoder Loss:  0.03916762  || Decoder Loss:  0.033883877 Validation Decoder Loss:  0.33093727
Encoder Loss:  0.039263777  || Decoder Loss:  0.033820294 Validation Decoder Loss:  0.33122113
Encoder Loss:  0.038702305  || Decoder Loss:  0.033807587 Validation Decoder Loss:  0.33072656
Encoder Loss:  0.039235502  || Decoder Loss:  0.0337751 Validation Decoder Loss:  0.33067456
Encoder Loss:  0.038913786  || Decoder Loss:  0.03376033 Validation Decoder Loss:  0.33146164
Encoder Loss:  0.039920464  || Decoder Loss:  0.03372296 Validation Decoder Loss:  0.3305569
Encoder Loss:  0.038873598  || Decoder Loss:  0.033644706 Validation Decoder Loss:  0.33008158
Encoder Loss:  0.038626477  || Decoder Loss:  0.03366725 Validation Decoder Loss:  0.33060002
Encoder Loss:  0.038758907  || Decoder Loss:  0.03364885 Validation Decoder Loss:  0.3332807
Encoder Loss:  0.038817395  || Decoder Loss:  0.03368852 Validation Decoder Loss:  0.33360916
Encoder Loss:  0.03882379  || Decoder Loss:  0.0337088 Validation Decoder Loss:  0.33408067
Encoder Loss:  0.038644794  || Decoder Loss:  0.033676974 Validation Decoder Loss:  0.3332094
Encoder Loss:  0.03865458  || Decoder Loss:  0.033663016 Validation Decoder Loss:  0.3322092
Encoder Loss:  0.038738113  || Decoder Loss:  0.033640023 Validation Decoder Loss:  0.33379123
Encoder Loss:  0.038832262  || Decoder Loss:  0.03362948 Validation Decoder Loss:  0.33337027
Encoder Loss:  0.03888988  || Decoder Loss:  0.033676196 Validation Decoder Loss:  0.33467817
Encoder Loss:  0.038709108  || Decoder Loss:  0.033586875 Validation Decoder Loss:  0.32949078
Encoder Loss:  0.03865682  || Decoder Loss:  0.033591446 Validation Decoder Loss:  0.32361656
Encoder Loss:  0.03934086  || Decoder Loss:  0.03478877 Validation Decoder Loss:  0.32866743
Encoder Loss:  0.038972065  || Decoder Loss:  0.033590905 Validation Decoder Loss:  0.33103004
Encoder Loss:  0.03853742  || Decoder Loss:  0.033578593 Validation Decoder Loss:  0.33122575
Encoder Loss:  0.03884861  || Decoder Loss:  0.033630356 Validation Decoder Loss:  0.3310354
Encoder Loss:  0.038793024  || Decoder Loss:  0.03356589 Validation Decoder Loss:  0.3308828
Encoder Loss:  0.038771857  || Decoder Loss:  0.033636667 Validation Decoder Loss:  0.33082825
Encoder Loss:  0.038754027  || Decoder Loss:  0.03361572 Validation Decoder Loss:  0.3308527
Encoder Loss:  0.038813323  || Decoder Loss:  0.033654824 Validation Decoder Loss:  0.33118016
Encoder Loss:  0.038617454  || Decoder Loss:  0.0336539 Validation Decoder Loss:  0.33080024
Encoder Loss:  0.038704228  || Decoder Loss:  0.03362068 Validation Decoder Loss:  0.3306877
Model: siamese_net_lr_0.020180723184592082 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3306877
Model: "sequential_78"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_26 (Conv3DT (None, 290, 8, 20, 1)     909       
_________________________________________________________________
reshape_26 (Reshape)         (None, 2320, 20, 1)       0         
=================================================================
Total params: 909
Trainable params: 909
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_79"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 2320, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_26 (Conv2DT (None, 2607, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2642873  || Decoder Loss:  0.44622585 Validation Decoder Loss:  1.2312629
Encoder Loss:  0.21068539  || Decoder Loss:  0.50633395 Validation Decoder Loss:  1.1613387
Encoder Loss:  0.20570835  || Decoder Loss:  0.5001506 Validation Decoder Loss:  1.1942817
Encoder Loss:  0.20515311  || Decoder Loss:  0.49647227 Validation Decoder Loss:  1.2276874
Encoder Loss:  0.20312206  || Decoder Loss:  0.4992984 Validation Decoder Loss:  1.2382355
Encoder Loss:  0.20588697  || Decoder Loss:  0.50015646 Validation Decoder Loss:  1.1574252
Encoder Loss:  0.2130653  || Decoder Loss:  0.49352494 Validation Decoder Loss:  1.1622977
Encoder Loss:  0.20028271  || Decoder Loss:  0.4914597 Validation Decoder Loss:  1.2082741
Encoder Loss:  0.19788526  || Decoder Loss:  0.48647374 Validation Decoder Loss:  0.94978774
Encoder Loss:  0.19905348  || Decoder Loss:  0.48050463 Validation Decoder Loss:  0.95318717
Encoder Loss:  0.19448769  || Decoder Loss:  0.47612923 Validation Decoder Loss:  0.8592393
Encoder Loss:  0.19514205  || Decoder Loss:  0.47066143 Validation Decoder Loss:  1.1688819
Encoder Loss:  0.18853189  || Decoder Loss:  0.45065677 Validation Decoder Loss:  0.77381897
Encoder Loss:  0.19129275  || Decoder Loss:  0.46412316 Validation Decoder Loss:  0.74114954
Encoder Loss:  0.19382247  || Decoder Loss:  0.47676453 Validation Decoder Loss:  1.2231901
Encoder Loss:  0.19995606  || Decoder Loss:  0.49240193 Validation Decoder Loss:  1.206749
Encoder Loss:  0.19551031  || Decoder Loss:  0.48927867 Validation Decoder Loss:  1.1989713
Encoder Loss:  0.18740825  || Decoder Loss:  0.45158422 Validation Decoder Loss:  0.7279639
Encoder Loss:  0.19728386  || Decoder Loss:  0.48882267 Validation Decoder Loss:  0.76540786
Encoder Loss:  0.19851042  || Decoder Loss:  0.49399576 Validation Decoder Loss:  0.79145074
Encoder Loss:  0.20102169  || Decoder Loss:  0.4957954 Validation Decoder Loss:  0.7468318
Encoder Loss:  0.20029758  || Decoder Loss:  0.4900619 Validation Decoder Loss:  0.7295445
Encoder Loss:  0.19803679  || Decoder Loss:  0.4886525 Validation Decoder Loss:  0.7530277
Encoder Loss:  0.18578346  || Decoder Loss:  0.46007255 Validation Decoder Loss:  1.1905699
Encoder Loss:  0.1789924  || Decoder Loss:  0.43646786 Validation Decoder Loss:  1.0049208
Encoder Loss:  0.18012853  || Decoder Loss:  0.43868285 Validation Decoder Loss:  0.92744565
Encoder Loss:  0.17703542  || Decoder Loss:  0.42696235 Validation Decoder Loss:  1.0054843
Encoder Loss:  0.17412792  || Decoder Loss:  0.4244235 Validation Decoder Loss:  0.76179016
Encoder Loss:  0.19123192  || Decoder Loss:  0.47343257 Validation Decoder Loss:  0.8269171
Encoder Loss:  0.17411761  || Decoder Loss:  0.41721845 Validation Decoder Loss:  0.45757908
Encoder Loss:  0.19800627  || Decoder Loss:  0.47237244 Validation Decoder Loss:  1.1563231
Encoder Loss:  0.19967653  || Decoder Loss:  0.48862442 Validation Decoder Loss:  1.1893125
Encoder Loss:  0.19938785  || Decoder Loss:  0.4910223 Validation Decoder Loss:  1.1698809
Encoder Loss:  0.19790454  || Decoder Loss:  0.48920578 Validation Decoder Loss:  1.1956161
Encoder Loss:  0.19717237  || Decoder Loss:  0.48955518 Validation Decoder Loss:  1.191213
Encoder Loss:  0.19602087  || Decoder Loss:  0.48521668 Validation Decoder Loss:  1.1763649
Encoder Loss:  0.19294447  || Decoder Loss:  0.47595826 Validation Decoder Loss:  1.0647588
Encoder Loss:  0.17245716  || Decoder Loss:  0.4164727 Validation Decoder Loss:  0.7581105
Encoder Loss:  0.19795635  || Decoder Loss:  0.48720235 Validation Decoder Loss:  0.77441067
Encoder Loss:  0.19632925  || Decoder Loss:  0.48844245 Validation Decoder Loss:  0.7618836
Model: siamese_net_lr_0.6503990876253714 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7618836
Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_27 (Conv3DT (None, 121, 20, 20, 1)    929       
_________________________________________________________________
reshape_27 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 929
Trainable params: 929
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_27 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.052462358 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246236 Validation Decoder Loss:  0.33955878
Encoder Loss:  0.43600163  || Decoder Loss:  0.05246237 Validation Decoder Loss:  0.33955878
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33955878
Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_28 (Conv3DT (None, 227, 10, 20, 1)    229       
_________________________________________________________________
reshape_28 (Reshape)         (None, 2270, 20, 1)       0         
=================================================================
Total params: 229
Trainable params: 229
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 2270, 20, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_28 (Conv2DT (None, 2607, 20, 1)       339       
=================================================================
Total params: 339
Trainable params: 339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114328  || Decoder Loss:  0.049114328 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114313  || Decoder Loss:  0.049114313 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114313  || Decoder Loss:  0.049114313 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114317  || Decoder Loss:  0.049114317 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114313  || Decoder Loss:  0.049114313 Validation Decoder Loss:  0.35759103
Encoder Loss:  0.049114324  || Decoder Loss:  0.049114324 Validation Decoder Loss:  0.35759103
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35759103
Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_29 (Conv3DT (None, 65, 18, 20, 1)     29        
_________________________________________________________________
reshape_29 (Reshape)         (None, 1170, 20, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 1170, 20, 1)       1439      
=================================================================
Total params: 1,439
Trainable params: 1,439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_29 (Conv2DT (None, 2607, 20, 1)       1439      
=================================================================
Total params: 1,439
Trainable params: 1,439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35663983  || Decoder Loss:  0.21032633 Validation Decoder Loss:  0.36262226
Encoder Loss:  0.27537397  || Decoder Loss:  0.47569954 Validation Decoder Loss:  0.4457034
Encoder Loss:  0.20928878  || Decoder Loss:  0.3874218 Validation Decoder Loss:  0.46352243
Encoder Loss:  0.17008755  || Decoder Loss:  0.35068965 Validation Decoder Loss:  0.5738934
Encoder Loss:  0.047760747  || Decoder Loss:  0.03160428 Validation Decoder Loss:  0.34362024
Encoder Loss:  0.046095133  || Decoder Loss:  0.028970852 Validation Decoder Loss:  0.34438315
Encoder Loss:  0.045934863  || Decoder Loss:  0.02932231 Validation Decoder Loss:  0.3455527
Encoder Loss:  0.04417579  || Decoder Loss:  0.02840742 Validation Decoder Loss:  0.34434178
Encoder Loss:  0.04440132  || Decoder Loss:  0.02885001 Validation Decoder Loss:  0.34509903
Encoder Loss:  0.04359059  || Decoder Loss:  0.028128793 Validation Decoder Loss:  0.34708512
Encoder Loss:  0.043500684  || Decoder Loss:  0.028159024 Validation Decoder Loss:  0.3439592
Encoder Loss:  0.04389865  || Decoder Loss:  0.028234709 Validation Decoder Loss:  0.34628087
Encoder Loss:  0.043234788  || Decoder Loss:  0.028088022 Validation Decoder Loss:  0.3483619
Encoder Loss:  0.045451075  || Decoder Loss:  0.032381974 Validation Decoder Loss:  0.34480554
Encoder Loss:  0.043036528  || Decoder Loss:  0.028048167 Validation Decoder Loss:  0.3491291
Encoder Loss:  0.04323134  || Decoder Loss:  0.028243933 Validation Decoder Loss:  0.34686014
Encoder Loss:  0.04372517  || Decoder Loss:  0.030330945 Validation Decoder Loss:  0.36572027
Encoder Loss:  0.045258913  || Decoder Loss:  0.030786881 Validation Decoder Loss:  0.34162778
Encoder Loss:  0.0439173  || Decoder Loss:  0.029287105 Validation Decoder Loss:  0.34121147
Encoder Loss:  0.06778161  || Decoder Loss:  0.07809519 Validation Decoder Loss:  1.2988807
Encoder Loss:  0.09655915  || Decoder Loss:  0.17359023 Validation Decoder Loss:  0.33946875
Encoder Loss:  0.04311938  || Decoder Loss:  0.029115235 Validation Decoder Loss:  0.34034914
Encoder Loss:  0.043219414  || Decoder Loss:  0.029253438 Validation Decoder Loss:  0.34004855
Encoder Loss:  0.043722138  || Decoder Loss:  0.030285126 Validation Decoder Loss:  0.33903325
Encoder Loss:  0.04365158  || Decoder Loss:  0.02987296 Validation Decoder Loss:  0.33939195
Encoder Loss:  0.04341994  || Decoder Loss:  0.029901605 Validation Decoder Loss:  0.33880934
Encoder Loss:  0.043605175  || Decoder Loss:  0.030228753 Validation Decoder Loss:  0.33952546
Encoder Loss:  0.04371071  || Decoder Loss:  0.030624086 Validation Decoder Loss:  0.34045222
Encoder Loss:  0.047323197  || Decoder Loss:  0.036206212 Validation Decoder Loss:  0.34702724
Encoder Loss:  0.04516994  || Decoder Loss:  0.031518616 Validation Decoder Loss:  0.3382587
Encoder Loss:  0.047612954  || Decoder Loss:  0.032235887 Validation Decoder Loss:  0.34039146
Encoder Loss:  0.052655373  || Decoder Loss:  0.034770712 Validation Decoder Loss:  0.33865476
Encoder Loss:  0.043517932  || Decoder Loss:  0.030451888 Validation Decoder Loss:  0.33849853
Encoder Loss:  0.043562952  || Decoder Loss:  0.030697003 Validation Decoder Loss:  0.33858842
Encoder Loss:  0.043629065  || Decoder Loss:  0.030899351 Validation Decoder Loss:  0.3382845
Encoder Loss:  0.04344586  || Decoder Loss:  0.030357923 Validation Decoder Loss:  0.33834514
Encoder Loss:  0.043966077  || Decoder Loss:  0.031786107 Validation Decoder Loss:  0.33816904
Encoder Loss:  0.043988876  || Decoder Loss:  0.031778257 Validation Decoder Loss:  0.3393744
Encoder Loss:  0.045747638  || Decoder Loss:  0.03309712 Validation Decoder Loss:  0.3395345
Encoder Loss:  0.045780893  || Decoder Loss:  0.03238276 Validation Decoder Loss:  0.3362019
Model: siamese_net_lr_0.334973353956914 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3362019
Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_30 (Conv3DT (None, 244, 5, 20, 1)     182       
_________________________________________________________________
reshape_30 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 182
Trainable params: 182
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 1220, 20, 1)       170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_30 (Conv2DT (None, 2607, 20, 1)       170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.130024  || Decoder Loss:  0.17522912 Validation Decoder Loss:  0.33174795
Encoder Loss:  0.07115884  || Decoder Loss:  0.0453408 Validation Decoder Loss:  0.33204526
Encoder Loss:  0.059490357  || Decoder Loss:  0.0423882 Validation Decoder Loss:  0.327164
Encoder Loss:  0.0470436  || Decoder Loss:  0.038575437 Validation Decoder Loss:  0.33081627
Encoder Loss:  0.046645235  || Decoder Loss:  0.03757377 Validation Decoder Loss:  0.3318345
Encoder Loss:  0.04671911  || Decoder Loss:  0.0371314 Validation Decoder Loss:  0.33056515
Encoder Loss:  0.04625473  || Decoder Loss:  0.036787845 Validation Decoder Loss:  0.32926887
Encoder Loss:  0.046308614  || Decoder Loss:  0.03670784 Validation Decoder Loss:  0.33031386
Encoder Loss:  0.04727976  || Decoder Loss:  0.03688576 Validation Decoder Loss:  0.3344639
Encoder Loss:  0.04836568  || Decoder Loss:  0.037486557 Validation Decoder Loss:  0.3307222
Encoder Loss:  0.046367507  || Decoder Loss:  0.036738772 Validation Decoder Loss:  0.3344558
Encoder Loss:  0.046139345  || Decoder Loss:  0.036445882 Validation Decoder Loss:  0.33156815
Encoder Loss:  0.048189074  || Decoder Loss:  0.03706494 Validation Decoder Loss:  0.3341242
Encoder Loss:  0.047798134  || Decoder Loss:  0.03727823 Validation Decoder Loss:  0.33392543
Encoder Loss:  0.046654962  || Decoder Loss:  0.036713976 Validation Decoder Loss:  0.3343519
Encoder Loss:  0.04625012  || Decoder Loss:  0.036377173 Validation Decoder Loss:  0.33160836
Encoder Loss:  0.04648704  || Decoder Loss:  0.036425706 Validation Decoder Loss:  0.33449462
Encoder Loss:  0.047591787  || Decoder Loss:  0.036620755 Validation Decoder Loss:  0.33442888
Encoder Loss:  0.050775602  || Decoder Loss:  0.03831702 Validation Decoder Loss:  0.3319316
Encoder Loss:  0.046354957  || Decoder Loss:  0.036763724 Validation Decoder Loss:  0.33350533
Encoder Loss:  0.04638713  || Decoder Loss:  0.036424782 Validation Decoder Loss:  0.33148554
Encoder Loss:  0.0462194  || Decoder Loss:  0.036228042 Validation Decoder Loss:  0.33628094
Encoder Loss:  0.046182968  || Decoder Loss:  0.036200162 Validation Decoder Loss:  0.3310202
Encoder Loss:  0.046348926  || Decoder Loss:  0.036212575 Validation Decoder Loss:  0.33699575
Encoder Loss:  0.046163563  || Decoder Loss:  0.03614038 Validation Decoder Loss:  0.33064273
Encoder Loss:  0.04717459  || Decoder Loss:  0.03638811 Validation Decoder Loss:  0.33435482
Encoder Loss:  0.048223928  || Decoder Loss:  0.037095442 Validation Decoder Loss:  0.3305388
Encoder Loss:  0.046166945  || Decoder Loss:  0.036184445 Validation Decoder Loss:  0.33379564
Encoder Loss:  0.04631565  || Decoder Loss:  0.036076814 Validation Decoder Loss:  0.33144328
Encoder Loss:  0.045938894  || Decoder Loss:  0.03588297 Validation Decoder Loss:  0.33484212
Encoder Loss:  0.046670407  || Decoder Loss:  0.0360427 Validation Decoder Loss:  0.33271962
Encoder Loss:  0.04725414  || Decoder Loss:  0.036511075 Validation Decoder Loss:  0.33408988
Encoder Loss:  0.04656627  || Decoder Loss:  0.0361375 Validation Decoder Loss:  0.3347467
Encoder Loss:  0.046273522  || Decoder Loss:  0.036032006 Validation Decoder Loss:  0.33523062
Encoder Loss:  0.046527334  || Decoder Loss:  0.03597379 Validation Decoder Loss:  0.33400685
Encoder Loss:  0.04623658  || Decoder Loss:  0.035987508 Validation Decoder Loss:  0.33541763
Encoder Loss:  0.04599009  || Decoder Loss:  0.035839144 Validation Decoder Loss:  0.33377516
Encoder Loss:  0.04622839  || Decoder Loss:  0.035825673 Validation Decoder Loss:  0.33446813
Encoder Loss:  0.045944043  || Decoder Loss:  0.035795063 Validation Decoder Loss:  0.33414456
Encoder Loss:  0.04632367  || Decoder Loss:  0.03578715 Validation Decoder Loss:  0.33410186
Model: siamese_net_lr_0.6743835533006033 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33410186
Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_31 (Conv3DT (None, 254, 5, 20, 1)     129       
_________________________________________________________________
reshape_31 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_31 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31745195  || Decoder Loss:  0.4681997 Validation Decoder Loss:  1.2216264
Encoder Loss:  0.28613985  || Decoder Loss:  0.40893048 Validation Decoder Loss:  0.60844445
Encoder Loss:  0.26543403  || Decoder Loss:  0.4165579 Validation Decoder Loss:  1.1436296
Encoder Loss:  0.14837804  || Decoder Loss:  0.21588194 Validation Decoder Loss:  0.36442745
Encoder Loss:  0.04478175  || Decoder Loss:  0.03643819 Validation Decoder Loss:  0.4024573
Encoder Loss:  0.045913134  || Decoder Loss:  0.03395479 Validation Decoder Loss:  0.33769768
Encoder Loss:  0.04237138  || Decoder Loss:  0.032314908 Validation Decoder Loss:  0.36417562
Encoder Loss:  0.04117525  || Decoder Loss:  0.031041935 Validation Decoder Loss:  0.38010046
Encoder Loss:  0.04175517  || Decoder Loss:  0.03198891 Validation Decoder Loss:  0.36034006
Encoder Loss:  0.041550912  || Decoder Loss:  0.03044687 Validation Decoder Loss:  0.3520617
Encoder Loss:  0.041601013  || Decoder Loss:  0.030775785 Validation Decoder Loss:  0.35828942
Encoder Loss:  0.03999369  || Decoder Loss:  0.029904597 Validation Decoder Loss:  0.3345692
Encoder Loss:  0.040723134  || Decoder Loss:  0.030464597 Validation Decoder Loss:  0.3653003
Encoder Loss:  0.041914374  || Decoder Loss:  0.030798877 Validation Decoder Loss:  0.36212742
Encoder Loss:  0.04111298  || Decoder Loss:  0.030321388 Validation Decoder Loss:  0.38535434
Encoder Loss:  0.03974807  || Decoder Loss:  0.029366717 Validation Decoder Loss:  0.3435328
Encoder Loss:  0.040491696  || Decoder Loss:  0.029186476 Validation Decoder Loss:  0.33929175
Encoder Loss:  0.042107884  || Decoder Loss:  0.031498834 Validation Decoder Loss:  0.34277797
Encoder Loss:  0.04010941  || Decoder Loss:  0.029465485 Validation Decoder Loss:  0.34753883
Encoder Loss:  0.041423507  || Decoder Loss:  0.029921249 Validation Decoder Loss:  0.37474808
Encoder Loss:  0.039897405  || Decoder Loss:  0.02948485 Validation Decoder Loss:  0.35201675
Encoder Loss:  0.04030672  || Decoder Loss:  0.029314628 Validation Decoder Loss:  0.3470307
Encoder Loss:  0.04005665  || Decoder Loss:  0.030159736 Validation Decoder Loss:  0.38198736
Encoder Loss:  0.039262153  || Decoder Loss:  0.028536635 Validation Decoder Loss:  0.34716627
Encoder Loss:  0.039117645  || Decoder Loss:  0.028490677 Validation Decoder Loss:  0.35587353
Encoder Loss:  0.03899922  || Decoder Loss:  0.028676415 Validation Decoder Loss:  0.344078
Encoder Loss:  0.038827896  || Decoder Loss:  0.028463196 Validation Decoder Loss:  0.34697795
Encoder Loss:  0.039038774  || Decoder Loss:  0.028811065 Validation Decoder Loss:  0.3447678
Encoder Loss:  0.03881649  || Decoder Loss:  0.02846615 Validation Decoder Loss:  0.3539522
Encoder Loss:  0.039284922  || Decoder Loss:  0.028757073 Validation Decoder Loss:  0.34479228
Encoder Loss:  0.039611265  || Decoder Loss:  0.028823402 Validation Decoder Loss:  0.3448862
Encoder Loss:  0.039310817  || Decoder Loss:  0.028966416 Validation Decoder Loss:  0.34866917
Encoder Loss:  0.038956814  || Decoder Loss:  0.028719315 Validation Decoder Loss:  0.34608606
Encoder Loss:  0.039985046  || Decoder Loss:  0.028869886 Validation Decoder Loss:  0.34550348
Encoder Loss:  0.039061915  || Decoder Loss:  0.028878272 Validation Decoder Loss:  0.34438148
Encoder Loss:  0.039287224  || Decoder Loss:  0.028898017 Validation Decoder Loss:  0.34479457
Encoder Loss:  0.039007194  || Decoder Loss:  0.028755551 Validation Decoder Loss:  0.34564298
Encoder Loss:  0.038882956  || Decoder Loss:  0.028692674 Validation Decoder Loss:  0.3411274
Encoder Loss:  0.038233243  || Decoder Loss:  0.028643437 Validation Decoder Loss:  0.33872056
Encoder Loss:  0.038661424  || Decoder Loss:  0.028657757 Validation Decoder Loss:  0.33899525
Model: siamese_net_lr_0.4211358839793098 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33899528
Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_32 (Conv3DT (None, 122, 10, 20, 1)    119       
_________________________________________________________________
reshape_32 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 1220, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_32 (Conv2DT (None, 2607, 20, 1)       170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14454478  || Decoder Loss:  0.068265006 Validation Decoder Loss:  0.33627784
Encoder Loss:  0.13121484  || Decoder Loss:  0.0497602 Validation Decoder Loss:  0.33660716
Encoder Loss:  0.3060622  || Decoder Loss:  0.33078572 Validation Decoder Loss:  0.7088027
Encoder Loss:  0.34695712  || Decoder Loss:  0.41197473 Validation Decoder Loss:  0.78996927
Encoder Loss:  0.1046593  || Decoder Loss:  0.104482956 Validation Decoder Loss:  0.3237272
Encoder Loss:  0.04848684  || Decoder Loss:  0.035680342 Validation Decoder Loss:  0.32857192
Encoder Loss:  0.04845942  || Decoder Loss:  0.03481952 Validation Decoder Loss:  0.32834446
Encoder Loss:  0.04966812  || Decoder Loss:  0.035032686 Validation Decoder Loss:  0.32700858
Encoder Loss:  0.048642248  || Decoder Loss:  0.035760276 Validation Decoder Loss:  0.33109054
Encoder Loss:  0.05197279  || Decoder Loss:  0.04056503 Validation Decoder Loss:  0.31594923
Encoder Loss:  0.0506092  || Decoder Loss:  0.038669795 Validation Decoder Loss:  0.3232079
Encoder Loss:  0.048688553  || Decoder Loss:  0.036978967 Validation Decoder Loss:  0.31196344
Encoder Loss:  0.049163464  || Decoder Loss:  0.03775978 Validation Decoder Loss:  0.35338545
Encoder Loss:  0.04861528  || Decoder Loss:  0.037370764 Validation Decoder Loss:  0.31582892
Encoder Loss:  0.051067952  || Decoder Loss:  0.037795834 Validation Decoder Loss:  0.3591815
Encoder Loss:  0.051215593  || Decoder Loss:  0.0383669 Validation Decoder Loss:  0.3123811
Encoder Loss:  0.04972746  || Decoder Loss:  0.03862362 Validation Decoder Loss:  0.35341007
Encoder Loss:  0.047457594  || Decoder Loss:  0.03598158 Validation Decoder Loss:  0.3334862
Encoder Loss:  0.04598537  || Decoder Loss:  0.035171606 Validation Decoder Loss:  0.33414644
Encoder Loss:  0.04513717  || Decoder Loss:  0.0352557 Validation Decoder Loss:  0.3360023
Encoder Loss:  0.044906124  || Decoder Loss:  0.03606761 Validation Decoder Loss:  0.3661429
Encoder Loss:  0.047571767  || Decoder Loss:  0.040061936 Validation Decoder Loss:  0.33780682
Encoder Loss:  0.045724016  || Decoder Loss:  0.04021229 Validation Decoder Loss:  0.33855924
Encoder Loss:  0.0449848  || Decoder Loss:  0.040182743 Validation Decoder Loss:  0.33638293
Encoder Loss:  0.04497136  || Decoder Loss:  0.038446397 Validation Decoder Loss:  0.3460121
Encoder Loss:  0.043573663  || Decoder Loss:  0.039637834 Validation Decoder Loss:  0.3450861
Encoder Loss:  0.041237723  || Decoder Loss:  0.037495516 Validation Decoder Loss:  0.3459135
Encoder Loss:  0.042058825  || Decoder Loss:  0.037271038 Validation Decoder Loss:  0.34456563
Encoder Loss:  0.045213643  || Decoder Loss:  0.039418157 Validation Decoder Loss:  0.34518793
Encoder Loss:  0.04458979  || Decoder Loss:  0.03932016 Validation Decoder Loss:  0.3437822
Encoder Loss:  0.044577967  || Decoder Loss:  0.039272975 Validation Decoder Loss:  0.3442942
Encoder Loss:  0.04203412  || Decoder Loss:  0.03828724 Validation Decoder Loss:  0.3423177
Encoder Loss:  0.04146821  || Decoder Loss:  0.037753657 Validation Decoder Loss:  0.34455073
Encoder Loss:  0.043692365  || Decoder Loss:  0.038050085 Validation Decoder Loss:  0.33910662
Encoder Loss:  0.04078072  || Decoder Loss:  0.037222248 Validation Decoder Loss:  0.34334737
Encoder Loss:  0.042648986  || Decoder Loss:  0.03786296 Validation Decoder Loss:  0.3413896
Encoder Loss:  0.043202627  || Decoder Loss:  0.03811171 Validation Decoder Loss:  0.34202835
Encoder Loss:  0.04256356  || Decoder Loss:  0.037474867 Validation Decoder Loss:  0.34658933
Encoder Loss:  0.04097463  || Decoder Loss:  0.03798751 Validation Decoder Loss:  0.34232998
Encoder Loss:  0.041380167  || Decoder Loss:  0.037218362 Validation Decoder Loss:  0.34425348
Model: siamese_net_lr_0.8318625908594353 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34425348
Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_33 (Conv3DT (None, 224, 5, 20, 1)     162       
_________________________________________________________________
reshape_33 (Reshape)         (None, 1120, 20, 1)       0         
=================================================================
Total params: 162
Trainable params: 162
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_100"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 1120, 20, 1)       370       
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_101"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_33 (Conv2DT (None, 2607, 20, 1)       1489      
=================================================================
Total params: 1,489
Trainable params: 1,489
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22492695  || Decoder Loss:  0.51634544 Validation Decoder Loss:  1.0259702
Encoder Loss:  0.18383707  || Decoder Loss:  0.5046605 Validation Decoder Loss:  1.0043974
Encoder Loss:  0.15953892  || Decoder Loss:  0.48739272 Validation Decoder Loss:  1.0320445
Encoder Loss:  0.16139022  || Decoder Loss:  0.48310393 Validation Decoder Loss:  0.97469634
Encoder Loss:  0.16153227  || Decoder Loss:  0.48208553 Validation Decoder Loss:  0.952023
Encoder Loss:  0.14964402  || Decoder Loss:  0.45349282 Validation Decoder Loss:  1.0611198
Encoder Loss:  0.16770968  || Decoder Loss:  0.49427685 Validation Decoder Loss:  1.0607405
Encoder Loss:  0.1585713  || Decoder Loss:  0.48319957 Validation Decoder Loss:  0.9313721
Encoder Loss:  0.15167639  || Decoder Loss:  0.4637809 Validation Decoder Loss:  0.631287
Encoder Loss:  0.13050811  || Decoder Loss:  0.38894036 Validation Decoder Loss:  0.5367125
Encoder Loss:  0.12687497  || Decoder Loss:  0.3751416 Validation Decoder Loss:  0.5285636
Encoder Loss:  0.10129872  || Decoder Loss:  0.26632196 Validation Decoder Loss:  0.9207896
Encoder Loss:  0.11784788  || Decoder Loss:  0.33553874 Validation Decoder Loss:  0.41619813
Encoder Loss:  0.08253935  || Decoder Loss:  0.18464969 Validation Decoder Loss:  0.531083
Encoder Loss:  0.06529766  || Decoder Loss:  0.11382062 Validation Decoder Loss:  0.34537512
Encoder Loss:  0.053157233  || Decoder Loss:  0.05264746 Validation Decoder Loss:  0.34077066
Encoder Loss:  0.04964922  || Decoder Loss:  0.04364652 Validation Decoder Loss:  0.33370718
Encoder Loss:  0.04822554  || Decoder Loss:  0.040785737 Validation Decoder Loss:  0.33456475
Encoder Loss:  0.047923073  || Decoder Loss:  0.03895142 Validation Decoder Loss:  0.3332054
Encoder Loss:  0.047318343  || Decoder Loss:  0.037604433 Validation Decoder Loss:  0.3326228
Encoder Loss:  0.047245655  || Decoder Loss:  0.03708267 Validation Decoder Loss:  0.33000138
Encoder Loss:  0.04793724  || Decoder Loss:  0.03696471 Validation Decoder Loss:  0.32772255
Encoder Loss:  0.04815424  || Decoder Loss:  0.03711805 Validation Decoder Loss:  0.3324342
Encoder Loss:  0.04879046  || Decoder Loss:  0.037320074 Validation Decoder Loss:  0.33258903
Encoder Loss:  0.050103784  || Decoder Loss:  0.037922103 Validation Decoder Loss:  0.3324438
Encoder Loss:  0.048115328  || Decoder Loss:  0.038278583 Validation Decoder Loss:  0.38236427
Encoder Loss:  0.047266368  || Decoder Loss:  0.037171632 Validation Decoder Loss:  0.33483705
Encoder Loss:  0.047158323  || Decoder Loss:  0.036997184 Validation Decoder Loss:  0.33865255
Encoder Loss:  0.04709138  || Decoder Loss:  0.036258038 Validation Decoder Loss:  0.33316576
Encoder Loss:  0.047484353  || Decoder Loss:  0.036591634 Validation Decoder Loss:  0.3360266
Encoder Loss:  0.047039088  || Decoder Loss:  0.036200467 Validation Decoder Loss:  0.33320734
Encoder Loss:  0.047211036  || Decoder Loss:  0.03587735 Validation Decoder Loss:  0.33268082
Encoder Loss:  0.046883203  || Decoder Loss:  0.0357743 Validation Decoder Loss:  0.33344147
Encoder Loss:  0.046834797  || Decoder Loss:  0.03556638 Validation Decoder Loss:  0.3318448
Encoder Loss:  0.047484297  || Decoder Loss:  0.03592739 Validation Decoder Loss:  0.33460563
Encoder Loss:  0.04707898  || Decoder Loss:  0.035855927 Validation Decoder Loss:  0.37248418
Encoder Loss:  0.047176994  || Decoder Loss:  0.036432385 Validation Decoder Loss:  0.3301334
Encoder Loss:  0.047070395  || Decoder Loss:  0.035964597 Validation Decoder Loss:  0.33133557
Encoder Loss:  0.048603307  || Decoder Loss:  0.036131248 Validation Decoder Loss:  0.37026
Encoder Loss:  0.04928798  || Decoder Loss:  0.03761539 Validation Decoder Loss:  0.377221
Model: siamese_net_lr_0.9590461097401826 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.377221
Model: "sequential_102"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_34 (Conv3DT (None, 107, 10, 20, 1)    89        
_________________________________________________________________
reshape_34 (Reshape)         (None, 1070, 20, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_103"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 1070, 20, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_104"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_34 (Conv2DT (None, 2607, 20, 1)       1539      
=================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30024034  || Decoder Loss:  0.35740948 Validation Decoder Loss:  0.5819962
Encoder Loss:  0.08029189  || Decoder Loss:  0.079462186 Validation Decoder Loss:  0.34531605
Encoder Loss:  0.04566308  || Decoder Loss:  0.03867949 Validation Decoder Loss:  0.34525225
Encoder Loss:  0.0430593  || Decoder Loss:  0.035520747 Validation Decoder Loss:  0.46651852
Encoder Loss:  0.046323773  || Decoder Loss:  0.04024735 Validation Decoder Loss:  0.34377936
Encoder Loss:  0.04168747  || Decoder Loss:  0.034448486 Validation Decoder Loss:  0.35047233
Encoder Loss:  0.037940066  || Decoder Loss:  0.02895982 Validation Decoder Loss:  0.3540374
Encoder Loss:  0.037986346  || Decoder Loss:  0.030514412 Validation Decoder Loss:  0.34852526
Encoder Loss:  0.0378031  || Decoder Loss:  0.029870993 Validation Decoder Loss:  0.34549373
Encoder Loss:  0.039841972  || Decoder Loss:  0.033443384 Validation Decoder Loss:  0.33987534
Encoder Loss:  0.037564393  || Decoder Loss:  0.030999567 Validation Decoder Loss:  0.3452157
Encoder Loss:  0.035885405  || Decoder Loss:  0.02836366 Validation Decoder Loss:  0.34086454
Encoder Loss:  0.03495095  || Decoder Loss:  0.027603498 Validation Decoder Loss:  0.3553308
Encoder Loss:  0.035196166  || Decoder Loss:  0.02772082 Validation Decoder Loss:  0.3415619
Encoder Loss:  0.035693806  || Decoder Loss:  0.028792491 Validation Decoder Loss:  0.3451479
Encoder Loss:  0.03646715  || Decoder Loss:  0.029843265 Validation Decoder Loss:  0.3407128
Encoder Loss:  0.03624865  || Decoder Loss:  0.029950297 Validation Decoder Loss:  0.33603007
Encoder Loss:  0.041303203  || Decoder Loss:  0.03696957 Validation Decoder Loss:  0.34726593
Encoder Loss:  0.039113823  || Decoder Loss:  0.03317071 Validation Decoder Loss:  0.33983836
Encoder Loss:  0.039255098  || Decoder Loss:  0.034139108 Validation Decoder Loss:  0.33399928
Encoder Loss:  0.037696257  || Decoder Loss:  0.032217976 Validation Decoder Loss:  0.33823794
Encoder Loss:  0.03928042  || Decoder Loss:  0.03423402 Validation Decoder Loss:  0.33437732
Encoder Loss:  0.03903526  || Decoder Loss:  0.03416057 Validation Decoder Loss:  0.33322516
Encoder Loss:  0.040002618  || Decoder Loss:  0.03538446 Validation Decoder Loss:  0.33471137
Encoder Loss:  0.040113244  || Decoder Loss:  0.035385545 Validation Decoder Loss:  0.3337575
Encoder Loss:  0.03934077  || Decoder Loss:  0.034622245 Validation Decoder Loss:  0.33438548
Encoder Loss:  0.03917028  || Decoder Loss:  0.03441883 Validation Decoder Loss:  0.33572704
Encoder Loss:  0.040075608  || Decoder Loss:  0.035350446 Validation Decoder Loss:  0.334929
Encoder Loss:  0.038978733  || Decoder Loss:  0.03418366 Validation Decoder Loss:  0.33370483
Encoder Loss:  0.039053198  || Decoder Loss:  0.034230825 Validation Decoder Loss:  0.33681473
Encoder Loss:  0.039617952  || Decoder Loss:  0.03485416 Validation Decoder Loss:  0.33702204
Encoder Loss:  0.039039858  || Decoder Loss:  0.0342394 Validation Decoder Loss:  0.33824253
Encoder Loss:  0.03922134  || Decoder Loss:  0.034417327 Validation Decoder Loss:  0.33514202
Encoder Loss:  0.039408416  || Decoder Loss:  0.034419984 Validation Decoder Loss:  0.33328494
Encoder Loss:  0.03882567  || Decoder Loss:  0.03394322 Validation Decoder Loss:  0.3365702
Encoder Loss:  0.038628154  || Decoder Loss:  0.033505198 Validation Decoder Loss:  0.33715415
Encoder Loss:  0.03873501  || Decoder Loss:  0.033765383 Validation Decoder Loss:  0.33574852
Encoder Loss:  0.038624275  || Decoder Loss:  0.03354565 Validation Decoder Loss:  0.33820975
Encoder Loss:  0.0384628  || Decoder Loss:  0.033422545 Validation Decoder Loss:  0.336493
Encoder Loss:  0.039480742  || Decoder Loss:  0.034102365 Validation Decoder Loss:  0.33941883
Model: siamese_net_lr_0.24598303793026058 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33941883
Model: "sequential_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_35 (Conv3DT (None, 165, 8, 20, 1)     157       
_________________________________________________________________
reshape_35 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 157
Trainable params: 157
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_106"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_107"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_35 (Conv2DT (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2786668  || Decoder Loss:  0.35040906 Validation Decoder Loss:  0.6215395
Encoder Loss:  0.07565429  || Decoder Loss:  0.06791581 Validation Decoder Loss:  0.33706906
Encoder Loss:  0.05277085  || Decoder Loss:  0.03372433 Validation Decoder Loss:  0.32924595
Encoder Loss:  0.04826335  || Decoder Loss:  0.037500486 Validation Decoder Loss:  0.3208757
Encoder Loss:  0.04506954  || Decoder Loss:  0.038138036 Validation Decoder Loss:  0.32284898
Encoder Loss:  0.04177025  || Decoder Loss:  0.033500392 Validation Decoder Loss:  0.3276785
Encoder Loss:  0.04205661  || Decoder Loss:  0.0341356 Validation Decoder Loss:  0.32803383
Encoder Loss:  0.04205224  || Decoder Loss:  0.03428015 Validation Decoder Loss:  0.32893366
Encoder Loss:  0.042325158  || Decoder Loss:  0.03473158 Validation Decoder Loss:  0.33040935
Encoder Loss:  0.04360018  || Decoder Loss:  0.03648186 Validation Decoder Loss:  0.33450326
Encoder Loss:  0.045537338  || Decoder Loss:  0.037035156 Validation Decoder Loss:  0.33450907
Encoder Loss:  0.042571694  || Decoder Loss:  0.035351288 Validation Decoder Loss:  0.3342408
Encoder Loss:  0.04253111  || Decoder Loss:  0.03489086 Validation Decoder Loss:  0.3365063
Encoder Loss:  0.042650413  || Decoder Loss:  0.03490245 Validation Decoder Loss:  0.3372509
Encoder Loss:  0.04295903  || Decoder Loss:  0.03518145 Validation Decoder Loss:  0.3367104
Encoder Loss:  0.043535426  || Decoder Loss:  0.035778463 Validation Decoder Loss:  0.3383893
Encoder Loss:  0.042291287  || Decoder Loss:  0.03480699 Validation Decoder Loss:  0.33915913
Encoder Loss:  0.042278152  || Decoder Loss:  0.034849487 Validation Decoder Loss:  0.3394003
Encoder Loss:  0.045330197  || Decoder Loss:  0.036045905 Validation Decoder Loss:  0.33516458
Encoder Loss:  0.047615394  || Decoder Loss:  0.03816861 Validation Decoder Loss:  0.33325443
Encoder Loss:  0.042777322  || Decoder Loss:  0.035772257 Validation Decoder Loss:  0.33569223
Encoder Loss:  0.04226432  || Decoder Loss:  0.034819614 Validation Decoder Loss:  0.3361036
Encoder Loss:  0.04236336  || Decoder Loss:  0.034847617 Validation Decoder Loss:  0.33634394
Encoder Loss:  0.042271543  || Decoder Loss:  0.034805063 Validation Decoder Loss:  0.3367335
Encoder Loss:  0.042286936  || Decoder Loss:  0.034749035 Validation Decoder Loss:  0.33707
Encoder Loss:  0.04216583  || Decoder Loss:  0.034508653 Validation Decoder Loss:  0.33805138
Encoder Loss:  0.042133268  || Decoder Loss:  0.0344927 Validation Decoder Loss:  0.3380647
Encoder Loss:  0.042834107  || Decoder Loss:  0.03528107 Validation Decoder Loss:  0.3381052
Encoder Loss:  0.04298874  || Decoder Loss:  0.03486851 Validation Decoder Loss:  0.3381129
Encoder Loss:  0.043681215  || Decoder Loss:  0.035584174 Validation Decoder Loss:  0.3367321
Encoder Loss:  0.042335156  || Decoder Loss:  0.03451856 Validation Decoder Loss:  0.33514574
Encoder Loss:  0.04305421  || Decoder Loss:  0.035403043 Validation Decoder Loss:  0.33637226
Encoder Loss:  0.04198182  || Decoder Loss:  0.034173436 Validation Decoder Loss:  0.33703882
Encoder Loss:  0.042241964  || Decoder Loss:  0.034655776 Validation Decoder Loss:  0.3368047
Encoder Loss:  0.042092975  || Decoder Loss:  0.034469824 Validation Decoder Loss:  0.33680776
Encoder Loss:  0.04274361  || Decoder Loss:  0.035128538 Validation Decoder Loss:  0.33366558
Encoder Loss:  0.043794185  || Decoder Loss:  0.035938054 Validation Decoder Loss:  0.33597302
Encoder Loss:  0.04276551  || Decoder Loss:  0.03493176 Validation Decoder Loss:  0.33533287
Encoder Loss:  0.04238938  || Decoder Loss:  0.034838602 Validation Decoder Loss:  0.33685365
Encoder Loss:  0.042680547  || Decoder Loss:  0.034689143 Validation Decoder Loss:  0.3356487
Model: siamese_net_lr_0.11338789229392945 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3356487
Model: "sequential_108"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_36 (Conv3DT (None, 137, 10, 20, 1)    23        
_________________________________________________________________
reshape_36 (Reshape)         (None, 1370, 20, 1)       0         
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_109"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 1370, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_110"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_36 (Conv2DT (None, 2607, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3316975  || Decoder Loss:  0.15481883 Validation Decoder Loss:  0.35702854
Encoder Loss:  0.2959994  || Decoder Loss:  0.060153976 Validation Decoder Loss:  0.36640435
Encoder Loss:  0.15543732  || Decoder Loss:  0.06948441 Validation Decoder Loss:  0.4213235
Encoder Loss:  0.20724839  || Decoder Loss:  0.47801113 Validation Decoder Loss:  0.88786554
Encoder Loss:  0.15173855  || Decoder Loss:  0.339075 Validation Decoder Loss:  0.34939882
Encoder Loss:  0.108615786  || Decoder Loss:  0.20998041 Validation Decoder Loss:  0.33818296
Encoder Loss:  0.044408437  || Decoder Loss:  0.03215692 Validation Decoder Loss:  0.33867276
Encoder Loss:  0.044740047  || Decoder Loss:  0.031865746 Validation Decoder Loss:  0.3393547
Encoder Loss:  0.04362183  || Decoder Loss:  0.031156983 Validation Decoder Loss:  0.34377402
Encoder Loss:  0.047916826  || Decoder Loss:  0.0346302 Validation Decoder Loss:  0.33847487
Encoder Loss:  0.043435145  || Decoder Loss:  0.030955764 Validation Decoder Loss:  0.34525162
Encoder Loss:  0.044917308  || Decoder Loss:  0.032454547 Validation Decoder Loss:  0.33730346
Encoder Loss:  0.047496796  || Decoder Loss:  0.032860734 Validation Decoder Loss:  0.3467418
Encoder Loss:  0.043783072  || Decoder Loss:  0.031284414 Validation Decoder Loss:  0.34651652
Encoder Loss:  0.04600253  || Decoder Loss:  0.034461692 Validation Decoder Loss:  0.3405714
Encoder Loss:  0.044275284  || Decoder Loss:  0.03203179 Validation Decoder Loss:  0.3462416
Encoder Loss:  0.04456758  || Decoder Loss:  0.03174628 Validation Decoder Loss:  0.33720335
Encoder Loss:  0.06631225  || Decoder Loss:  0.08610307 Validation Decoder Loss:  0.33861715
Encoder Loss:  0.04418243  || Decoder Loss:  0.03158972 Validation Decoder Loss:  0.34317285
Encoder Loss:  0.04538369  || Decoder Loss:  0.032346908 Validation Decoder Loss:  0.34194604
Encoder Loss:  0.0437074  || Decoder Loss:  0.031181643 Validation Decoder Loss:  0.33962333
Encoder Loss:  0.045651134  || Decoder Loss:  0.03312692 Validation Decoder Loss:  0.34483114
Encoder Loss:  0.04526005  || Decoder Loss:  0.0320647 Validation Decoder Loss:  0.33979797
Encoder Loss:  0.043920863  || Decoder Loss:  0.031405356 Validation Decoder Loss:  0.3370447
Encoder Loss:  0.04416502  || Decoder Loss:  0.032118496 Validation Decoder Loss:  0.3470334
Encoder Loss:  0.080894716  || Decoder Loss:  0.11908146 Validation Decoder Loss:  0.34547448
Encoder Loss:  0.043822378  || Decoder Loss:  0.03150387 Validation Decoder Loss:  0.33613586
Encoder Loss:  0.04345077  || Decoder Loss:  0.030995216 Validation Decoder Loss:  0.33732945
Encoder Loss:  0.04419444  || Decoder Loss:  0.03190326 Validation Decoder Loss:  0.34736514
Encoder Loss:  0.06899142  || Decoder Loss:  0.08315544 Validation Decoder Loss:  0.3374969
Encoder Loss:  0.047052935  || Decoder Loss:  0.032505617 Validation Decoder Loss:  0.34062922
Encoder Loss:  0.046757102  || Decoder Loss:  0.031892397 Validation Decoder Loss:  0.34362596
Encoder Loss:  0.043473054  || Decoder Loss:  0.03100263 Validation Decoder Loss:  0.341155
Encoder Loss:  0.043316554  || Decoder Loss:  0.030809572 Validation Decoder Loss:  0.34513092
Encoder Loss:  0.0451917  || Decoder Loss:  0.033508178 Validation Decoder Loss:  0.34135625
Encoder Loss:  0.043609478  || Decoder Loss:  0.031026945 Validation Decoder Loss:  0.3374197
Encoder Loss:  0.043361597  || Decoder Loss:  0.030718597 Validation Decoder Loss:  0.33704287
Encoder Loss:  0.08040421  || Decoder Loss:  0.12739141 Validation Decoder Loss:  0.8380033
Encoder Loss:  0.08866729  || Decoder Loss:  0.15551597 Validation Decoder Loss:  0.33844134
Encoder Loss:  0.043483227  || Decoder Loss:  0.030942587 Validation Decoder Loss:  0.34206563
Model: siamese_net_lr_0.3054127165318938 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34206563
Model: "sequential_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_37 (Conv3DT (None, 88, 15, 20, 1)     76        
_________________________________________________________________
reshape_37 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 76
Trainable params: 76
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_37 (Conv2DT (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3674618  || Decoder Loss:  0.23336716 Validation Decoder Loss:  0.38192457
Encoder Loss:  0.3373007  || Decoder Loss:  0.09339115 Validation Decoder Loss:  0.3722445
Encoder Loss:  0.33524624  || Decoder Loss:  0.08690252 Validation Decoder Loss:  0.36731672
Encoder Loss:  0.33318537  || Decoder Loss:  0.08052605 Validation Decoder Loss:  0.36311245
Encoder Loss:  0.33086836  || Decoder Loss:  0.07340752 Validation Decoder Loss:  0.35946906
Encoder Loss:  0.32818258  || Decoder Loss:  0.06520739 Validation Decoder Loss:  0.35713306
Encoder Loss:  0.3251256  || Decoder Loss:  0.055951357 Validation Decoder Loss:  0.35914665
Encoder Loss:  0.32255784  || Decoder Loss:  0.048421584 Validation Decoder Loss:  0.36698723
Encoder Loss:  0.32139733  || Decoder Loss:  0.04561424 Validation Decoder Loss:  0.3630023
Encoder Loss:  0.3203799  || Decoder Loss:  0.043653883 Validation Decoder Loss:  0.3600639
Encoder Loss:  0.31921422  || Decoder Loss:  0.04190484 Validation Decoder Loss:  0.35729334
Encoder Loss:  0.31765383  || Decoder Loss:  0.040393826 Validation Decoder Loss:  0.35463455
Encoder Loss:  0.31405187  || Decoder Loss:  0.0391524 Validation Decoder Loss:  0.35228214
Encoder Loss:  0.2979272  || Decoder Loss:  0.038201883 Validation Decoder Loss:  0.35044497
Encoder Loss:  0.3154221  || Decoder Loss:  0.037656043 Validation Decoder Loss:  0.3495648
Encoder Loss:  0.31230527  || Decoder Loss:  0.038145065 Validation Decoder Loss:  0.3513014
Encoder Loss:  0.29711863  || Decoder Loss:  0.16659221 Validation Decoder Loss:  1.2073243
Encoder Loss:  0.22487819  || Decoder Loss:  0.45128667 Validation Decoder Loss:  1.361295
Encoder Loss:  0.24516186  || Decoder Loss:  0.477134 Validation Decoder Loss:  1.1040859
Encoder Loss:  0.21851948  || Decoder Loss:  0.46210748 Validation Decoder Loss:  1.2851812
Encoder Loss:  0.22213174  || Decoder Loss:  0.45860904 Validation Decoder Loss:  1.0778372
Encoder Loss:  0.19259554  || Decoder Loss:  0.41768235 Validation Decoder Loss:  1.1220644
Encoder Loss:  0.18676919  || Decoder Loss:  0.39484668 Validation Decoder Loss:  0.98467946
Encoder Loss:  0.15421727  || Decoder Loss:  0.29939458 Validation Decoder Loss:  0.9047068
Encoder Loss:  0.13868195  || Decoder Loss:  0.25761858 Validation Decoder Loss:  0.81222403
Encoder Loss:  0.14929558  || Decoder Loss:  0.29740623 Validation Decoder Loss:  0.5467801
Encoder Loss:  0.10644006  || Decoder Loss:  0.16507775 Validation Decoder Loss:  0.5486579
Encoder Loss:  0.10541768  || Decoder Loss:  0.16507743 Validation Decoder Loss:  0.46451482
Encoder Loss:  0.06881904  || Decoder Loss:  0.06066169 Validation Decoder Loss:  0.34309965
Encoder Loss:  0.061672024  || Decoder Loss:  0.038867556 Validation Decoder Loss:  0.35195902
Encoder Loss:  0.05982139  || Decoder Loss:  0.038254503 Validation Decoder Loss:  0.34662604
Encoder Loss:  0.058901723  || Decoder Loss:  0.03819444 Validation Decoder Loss:  0.3583815
Encoder Loss:  0.05801526  || Decoder Loss:  0.038265735 Validation Decoder Loss:  0.37584049
Encoder Loss:  0.057877425  || Decoder Loss:  0.04040756 Validation Decoder Loss:  0.36559892
Encoder Loss:  0.058286954  || Decoder Loss:  0.041797552 Validation Decoder Loss:  0.34364182
Encoder Loss:  0.054395776  || Decoder Loss:  0.039011016 Validation Decoder Loss:  0.34436697
Encoder Loss:  0.054168757  || Decoder Loss:  0.04056766 Validation Decoder Loss:  0.32841575
Encoder Loss:  0.05434699  || Decoder Loss:  0.03892608 Validation Decoder Loss:  0.32620862
Encoder Loss:  0.052579794  || Decoder Loss:  0.037288327 Validation Decoder Loss:  0.37873477
Encoder Loss:  0.056034032  || Decoder Loss:  0.045687333 Validation Decoder Loss:  0.337675
Model: siamese_net_lr_0.43304813263976727 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33767498
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_38 (Conv3DT (None, 132, 10, 20, 1)    139       
_________________________________________________________________
reshape_38 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_38 (Conv2DT (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32795128  || Decoder Loss:  0.35202247 Validation Decoder Loss:  1.3153901
Encoder Loss:  0.38512403  || Decoder Loss:  0.46642 Validation Decoder Loss:  1.1149231
Encoder Loss:  0.2805843  || Decoder Loss:  0.34063846 Validation Decoder Loss:  0.6229881
Encoder Loss:  0.083295316  || Decoder Loss:  0.08104062 Validation Decoder Loss:  0.34157044
Encoder Loss:  0.04498129  || Decoder Loss:  0.029800637 Validation Decoder Loss:  0.33205938
Encoder Loss:  0.04400097  || Decoder Loss:  0.030719528 Validation Decoder Loss:  0.33300602
Encoder Loss:  0.044031717  || Decoder Loss:  0.029450513 Validation Decoder Loss:  0.3375141
Encoder Loss:  0.04347811  || Decoder Loss:  0.028921878 Validation Decoder Loss:  0.35217166
Encoder Loss:  0.043970942  || Decoder Loss:  0.030235164 Validation Decoder Loss:  0.3503001
Encoder Loss:  0.044165377  || Decoder Loss:  0.030129498 Validation Decoder Loss:  0.35453078
Encoder Loss:  0.051501893  || Decoder Loss:  0.034706756 Validation Decoder Loss:  0.37364778
Encoder Loss:  0.045081157  || Decoder Loss:  0.0331346 Validation Decoder Loss:  0.36126998
Encoder Loss:  0.04287767  || Decoder Loss:  0.03170349 Validation Decoder Loss:  0.33533347
Encoder Loss:  0.039954025  || Decoder Loss:  0.031060962 Validation Decoder Loss:  0.3168779
Encoder Loss:  0.037721623  || Decoder Loss:  0.03222783 Validation Decoder Loss:  0.35021198
Encoder Loss:  0.036038503  || Decoder Loss:  0.030955508 Validation Decoder Loss:  0.3421992
Encoder Loss:  0.036188025  || Decoder Loss:  0.03136186 Validation Decoder Loss:  0.34992936
Encoder Loss:  0.036068622  || Decoder Loss:  0.030954745 Validation Decoder Loss:  0.34944654
Encoder Loss:  0.035747122  || Decoder Loss:  0.030673986 Validation Decoder Loss:  0.34868997
Encoder Loss:  0.03584861  || Decoder Loss:  0.030842362 Validation Decoder Loss:  0.34842265
Encoder Loss:  0.03594055  || Decoder Loss:  0.030810919 Validation Decoder Loss:  0.34456056
Encoder Loss:  0.036383435  || Decoder Loss:  0.030915761 Validation Decoder Loss:  0.34739792
Encoder Loss:  0.03565376  || Decoder Loss:  0.03074485 Validation Decoder Loss:  0.34043062
Encoder Loss:  0.03588739  || Decoder Loss:  0.031013878 Validation Decoder Loss:  0.34616828
Encoder Loss:  0.036960624  || Decoder Loss:  0.031976134 Validation Decoder Loss:  0.3284531
Encoder Loss:  0.036830276  || Decoder Loss:  0.031030491 Validation Decoder Loss:  0.34866297
Encoder Loss:  0.035770737  || Decoder Loss:  0.030991595 Validation Decoder Loss:  0.34361285
Encoder Loss:  0.035836015  || Decoder Loss:  0.031092446 Validation Decoder Loss:  0.3437787
Encoder Loss:  0.036590684  || Decoder Loss:  0.031514347 Validation Decoder Loss:  0.34646827
Encoder Loss:  0.036120888  || Decoder Loss:  0.031125009 Validation Decoder Loss:  0.34123874
Encoder Loss:  0.03660638  || Decoder Loss:  0.03138565 Validation Decoder Loss:  0.34057367
Encoder Loss:  0.036398917  || Decoder Loss:  0.03168882 Validation Decoder Loss:  0.34080178
Encoder Loss:  0.037779953  || Decoder Loss:  0.032756243 Validation Decoder Loss:  0.34320092
Encoder Loss:  0.0368575  || Decoder Loss:  0.03179149 Validation Decoder Loss:  0.34558946
Encoder Loss:  0.036000613  || Decoder Loss:  0.031088324 Validation Decoder Loss:  0.3453958
Encoder Loss:  0.0363624  || Decoder Loss:  0.031258605 Validation Decoder Loss:  0.34062946
Encoder Loss:  0.036493193  || Decoder Loss:  0.031856686 Validation Decoder Loss:  0.34762
Encoder Loss:  0.03802544  || Decoder Loss:  0.031780325 Validation Decoder Loss:  0.35373187
Encoder Loss:  0.037118368  || Decoder Loss:  0.032272328 Validation Decoder Loss:  0.35443223
Encoder Loss:  0.036700517  || Decoder Loss:  0.03224961 Validation Decoder Loss:  0.34802902
Model: siamese_net_lr_0.26266941420418927 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34802902
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_39 (Conv3DT (None, 214, 5, 20, 1)     89        
_________________________________________________________________
reshape_39 (Reshape)         (None, 1070, 20, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 1070, 20, 1)       1539      
=================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_39 (Conv2DT (None, 2607, 20, 1)       1539      
=================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.08693563  || Decoder Loss:  0.08693563 Validation Decoder Loss:  0.36294192
Encoder Loss:  0.086935624  || Decoder Loss:  0.086935624 Validation Decoder Loss:  0.36294192
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36294192
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_40 (Conv3DT (None, 254, 5, 20, 1)     192       
_________________________________________________________________
reshape_40 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_40 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21304192  || Decoder Loss:  0.5510122 Validation Decoder Loss:  0.9531708
Encoder Loss:  0.0945714  || Decoder Loss:  0.4891716 Validation Decoder Loss:  0.99695766
Encoder Loss:  0.08320067  || Decoder Loss:  0.48462906 Validation Decoder Loss:  1.0161123
Encoder Loss:  0.07694242  || Decoder Loss:  0.48001027 Validation Decoder Loss:  1.0577701
Encoder Loss:  0.08382341  || Decoder Loss:  0.48115098 Validation Decoder Loss:  1.0448463
Encoder Loss:  0.08066227  || Decoder Loss:  0.47268122 Validation Decoder Loss:  1.0933656
Encoder Loss:  0.073580354  || Decoder Loss:  0.4713989 Validation Decoder Loss:  0.6965095
Encoder Loss:  0.07099635  || Decoder Loss:  0.4199055 Validation Decoder Loss:  0.9263793
Encoder Loss:  0.064628884  || Decoder Loss:  0.40302274 Validation Decoder Loss:  0.63315964
Encoder Loss:  0.072398245  || Decoder Loss:  0.363797 Validation Decoder Loss:  0.85782343
Encoder Loss:  0.072374344  || Decoder Loss:  0.36796555 Validation Decoder Loss:  0.7991638
Encoder Loss:  0.0740685  || Decoder Loss:  0.41148433 Validation Decoder Loss:  0.83487
Encoder Loss:  0.06837024  || Decoder Loss:  0.3710472 Validation Decoder Loss:  0.74205476
Encoder Loss:  0.06329566  || Decoder Loss:  0.16724487 Validation Decoder Loss:  0.6840776
Encoder Loss:  0.07597369  || Decoder Loss:  0.344985 Validation Decoder Loss:  0.79553664
Encoder Loss:  0.075678326  || Decoder Loss:  0.41939998 Validation Decoder Loss:  1.0053173
Encoder Loss:  0.064607136  || Decoder Loss:  0.4337532 Validation Decoder Loss:  0.5549456
Encoder Loss:  0.056018937  || Decoder Loss:  0.16841826 Validation Decoder Loss:  0.40128613
Encoder Loss:  0.05946336  || Decoder Loss:  0.07647964 Validation Decoder Loss:  0.40694135
Encoder Loss:  0.06533606  || Decoder Loss:  0.05917205 Validation Decoder Loss:  0.36906278
Encoder Loss:  0.07307243  || Decoder Loss:  0.053976245 Validation Decoder Loss:  0.40730432
Encoder Loss:  0.056766752  || Decoder Loss:  0.053716347 Validation Decoder Loss:  0.37490094
Encoder Loss:  0.059852622  || Decoder Loss:  0.051313568 Validation Decoder Loss:  0.3630206
Encoder Loss:  0.056577872  || Decoder Loss:  0.04832503 Validation Decoder Loss:  0.3550672
Encoder Loss:  0.06139088  || Decoder Loss:  0.043493114 Validation Decoder Loss:  0.36521345
Encoder Loss:  0.056681585  || Decoder Loss:  0.042851996 Validation Decoder Loss:  0.3445155
Encoder Loss:  0.054556765  || Decoder Loss:  0.042306606 Validation Decoder Loss:  0.3627991
Encoder Loss:  0.057963934  || Decoder Loss:  0.044245433 Validation Decoder Loss:  0.36495465
Encoder Loss:  0.058336247  || Decoder Loss:  0.044779982 Validation Decoder Loss:  0.3453989
Encoder Loss:  0.06686845  || Decoder Loss:  0.041295055 Validation Decoder Loss:  0.36334914
Encoder Loss:  0.060602125  || Decoder Loss:  0.045286227 Validation Decoder Loss:  0.37839347
Encoder Loss:  0.06571284  || Decoder Loss:  0.04717957 Validation Decoder Loss:  0.34547254
Encoder Loss:  0.059856478  || Decoder Loss:  0.04332241 Validation Decoder Loss:  0.33197367
Encoder Loss:  0.064608246  || Decoder Loss:  0.04498495 Validation Decoder Loss:  0.3814342
Encoder Loss:  0.05781264  || Decoder Loss:  0.041218575 Validation Decoder Loss:  0.37248957
Encoder Loss:  0.0546972  || Decoder Loss:  0.0440393 Validation Decoder Loss:  0.33524144
Encoder Loss:  0.052770104  || Decoder Loss:  0.0417484 Validation Decoder Loss:  0.36672935
Encoder Loss:  0.05762463  || Decoder Loss:  0.045471035 Validation Decoder Loss:  0.34834373
Encoder Loss:  0.05834858  || Decoder Loss:  0.04246557 Validation Decoder Loss:  0.37476373
Encoder Loss:  0.056158945  || Decoder Loss:  0.04308771 Validation Decoder Loss:  0.33374003
Model: siamese_net_lr_0.7227739585603535 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33374
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_41 (Conv3DT (None, 127, 10, 20, 1)    129       
_________________________________________________________________
reshape_41 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_41 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35535896  || Decoder Loss:  0.70351064 Validation Decoder Loss:  1.3505085
Encoder Loss:  0.15824834  || Decoder Loss:  0.49787453 Validation Decoder Loss:  1.2078924
Encoder Loss:  0.14266029  || Decoder Loss:  0.48682904 Validation Decoder Loss:  1.1806402
Encoder Loss:  0.14016077  || Decoder Loss:  0.48375878 Validation Decoder Loss:  1.1542752
Encoder Loss:  0.1390171  || Decoder Loss:  0.47831538 Validation Decoder Loss:  1.0910563
Encoder Loss:  0.13509193  || Decoder Loss:  0.4654823 Validation Decoder Loss:  1.0535586
Encoder Loss:  0.13624239  || Decoder Loss:  0.4903558 Validation Decoder Loss:  1.1309545
Encoder Loss:  0.12816662  || Decoder Loss:  0.43892026 Validation Decoder Loss:  0.91679657
Encoder Loss:  0.12906988  || Decoder Loss:  0.4716975 Validation Decoder Loss:  1.0075613
Encoder Loss:  0.12624402  || Decoder Loss:  0.4607367 Validation Decoder Loss:  0.9574957
Encoder Loss:  0.112695485  || Decoder Loss:  0.4463313 Validation Decoder Loss:  0.95516384
Encoder Loss:  0.099178225  || Decoder Loss:  0.3460478 Validation Decoder Loss:  0.68456686
Encoder Loss:  0.089595295  || Decoder Loss:  0.2884286 Validation Decoder Loss:  0.48720244
Encoder Loss:  0.07682463  || Decoder Loss:  0.18874685 Validation Decoder Loss:  0.5156938
Encoder Loss:  0.06343918  || Decoder Loss:  0.08635825 Validation Decoder Loss:  0.44235653
Encoder Loss:  0.062118866  || Decoder Loss:  0.054461848 Validation Decoder Loss:  0.39068222
Encoder Loss:  0.07458999  || Decoder Loss:  0.04459986 Validation Decoder Loss:  0.35656285
Encoder Loss:  0.0688593  || Decoder Loss:  0.04399531 Validation Decoder Loss:  0.40902603
Encoder Loss:  0.056953855  || Decoder Loss:  0.04094926 Validation Decoder Loss:  0.35194653
Encoder Loss:  0.05729983  || Decoder Loss:  0.03968654 Validation Decoder Loss:  0.40418676
Encoder Loss:  0.05874581  || Decoder Loss:  0.038475443 Validation Decoder Loss:  0.39646158
Encoder Loss:  0.056835596  || Decoder Loss:  0.037700515 Validation Decoder Loss:  0.39832872
Encoder Loss:  0.055222858  || Decoder Loss:  0.037319306 Validation Decoder Loss:  0.3622579
Encoder Loss:  0.0552863  || Decoder Loss:  0.036767416 Validation Decoder Loss:  0.35046044
Encoder Loss:  0.055495247  || Decoder Loss:  0.035385076 Validation Decoder Loss:  0.38134822
Encoder Loss:  0.05394035  || Decoder Loss:  0.03526609 Validation Decoder Loss:  0.34463227
Encoder Loss:  0.055262946  || Decoder Loss:  0.035739616 Validation Decoder Loss:  0.3440473
Encoder Loss:  0.057882305  || Decoder Loss:  0.0352505 Validation Decoder Loss:  0.3502106
Encoder Loss:  0.057138134  || Decoder Loss:  0.036199775 Validation Decoder Loss:  0.34724474
Encoder Loss:  0.053325523  || Decoder Loss:  0.034879193 Validation Decoder Loss:  0.34403482
Encoder Loss:  0.055588044  || Decoder Loss:  0.035017576 Validation Decoder Loss:  0.3469012
Encoder Loss:  0.05676264  || Decoder Loss:  0.03530466 Validation Decoder Loss:  0.35048375
Encoder Loss:  0.054435033  || Decoder Loss:  0.03446577 Validation Decoder Loss:  0.34480074
Encoder Loss:  0.054065973  || Decoder Loss:  0.034388337 Validation Decoder Loss:  0.3585781
Encoder Loss:  0.055523157  || Decoder Loss:  0.034739435 Validation Decoder Loss:  0.39880735
Encoder Loss:  0.063892394  || Decoder Loss:  0.03613107 Validation Decoder Loss:  0.35693204
Encoder Loss:  0.05327405  || Decoder Loss:  0.034477264 Validation Decoder Loss:  0.3448732
Encoder Loss:  0.05876486  || Decoder Loss:  0.03514141 Validation Decoder Loss:  0.3557642
Encoder Loss:  0.052864466  || Decoder Loss:  0.035058595 Validation Decoder Loss:  0.34401083
Encoder Loss:  0.05363105  || Decoder Loss:  0.034307 Validation Decoder Loss:  0.3560009
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3560009
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_42 (Conv3DT (None, 254, 5, 20, 1)     129       
_________________________________________________________________
reshape_42 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 1270, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_42 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.40122163  || Decoder Loss:  0.11335861 Validation Decoder Loss:  0.35663792
Encoder Loss:  0.4415601  || Decoder Loss:  0.0663323 Validation Decoder Loss:  0.3551444
Encoder Loss:  0.44108763  || Decoder Loss:  0.053375054 Validation Decoder Loss:  0.3602841
Encoder Loss:  0.44037652  || Decoder Loss:  0.044569593 Validation Decoder Loss:  0.373447
Encoder Loss:  0.4394094  || Decoder Loss:  0.043593768 Validation Decoder Loss:  0.36695075
Encoder Loss:  0.43805373  || Decoder Loss:  0.0434688 Validation Decoder Loss:  0.3669023
Encoder Loss:  0.43606734  || Decoder Loss:  0.04391052 Validation Decoder Loss:  0.36595172
Encoder Loss:  0.4328996  || Decoder Loss:  0.045228317 Validation Decoder Loss:  0.3663399
Encoder Loss:  0.42688578  || Decoder Loss:  0.048274864 Validation Decoder Loss:  0.3691671
Encoder Loss:  0.4077847  || Decoder Loss:  0.05783206 Validation Decoder Loss:  0.3949992
Encoder Loss:  0.20380479  || Decoder Loss:  0.41763386 Validation Decoder Loss:  1.3773992
Encoder Loss:  0.13410884  || Decoder Loss:  0.4866079 Validation Decoder Loss:  1.2234504
Encoder Loss:  0.10180503  || Decoder Loss:  0.4664743 Validation Decoder Loss:  1.2066902
Encoder Loss:  0.09904797  || Decoder Loss:  0.44432494 Validation Decoder Loss:  1.1313112
Encoder Loss:  0.09218978  || Decoder Loss:  0.4379943 Validation Decoder Loss:  1.2209017
Encoder Loss:  0.09591851  || Decoder Loss:  0.44206765 Validation Decoder Loss:  1.1717882
Encoder Loss:  0.09285637  || Decoder Loss:  0.43366823 Validation Decoder Loss:  1.1657839
Encoder Loss:  0.09213764  || Decoder Loss:  0.42588428 Validation Decoder Loss:  1.1430547
Encoder Loss:  0.0911793  || Decoder Loss:  0.40727824 Validation Decoder Loss:  1.0321629
Encoder Loss:  0.09105709  || Decoder Loss:  0.34707543 Validation Decoder Loss:  0.8882816
Encoder Loss:  0.092541724  || Decoder Loss:  0.43185875 Validation Decoder Loss:  0.7587633
Encoder Loss:  0.08777244  || Decoder Loss:  0.31448233 Validation Decoder Loss:  0.7501147
Encoder Loss:  0.08755841  || Decoder Loss:  0.34732807 Validation Decoder Loss:  0.7291088
Encoder Loss:  0.08491292  || Decoder Loss:  0.32727408 Validation Decoder Loss:  0.7178665
Encoder Loss:  0.08417961  || Decoder Loss:  0.19033015 Validation Decoder Loss:  0.68966377
Encoder Loss:  0.08823084  || Decoder Loss:  0.24349937 Validation Decoder Loss:  0.42676142
Encoder Loss:  0.078522824  || Decoder Loss:  0.13262099 Validation Decoder Loss:  0.424675
Encoder Loss:  0.07756107  || Decoder Loss:  0.06952676 Validation Decoder Loss:  0.3967916
Encoder Loss:  0.0781698  || Decoder Loss:  0.03966384 Validation Decoder Loss:  0.37534365
Encoder Loss:  0.07015789  || Decoder Loss:  0.03352003 Validation Decoder Loss:  0.3558508
Encoder Loss:  0.073446296  || Decoder Loss:  0.031030856 Validation Decoder Loss:  0.35355425
Encoder Loss:  0.06618959  || Decoder Loss:  0.030665386 Validation Decoder Loss:  0.35091344
Encoder Loss:  0.06491607  || Decoder Loss:  0.031256687 Validation Decoder Loss:  0.33960265
Encoder Loss:  0.067548566  || Decoder Loss:  0.034396652 Validation Decoder Loss:  0.34825996
Encoder Loss:  0.06591844  || Decoder Loss:  0.03976715 Validation Decoder Loss:  0.38540876
Encoder Loss:  0.060930233  || Decoder Loss:  0.04575351 Validation Decoder Loss:  0.33548218
Encoder Loss:  0.061012387  || Decoder Loss:  0.04273246 Validation Decoder Loss:  0.33460143
Encoder Loss:  0.058040515  || Decoder Loss:  0.04092748 Validation Decoder Loss:  0.36820385
Encoder Loss:  0.05828364  || Decoder Loss:  0.04405923 Validation Decoder Loss:  0.3428165
Encoder Loss:  0.06513673  || Decoder Loss:  0.04124589 Validation Decoder Loss:  0.3545472
Model: siamese_net_lr_0.9200650676699825 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3545472
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_43 (Conv3DT (None, 264, 5, 20, 1)     13        
_________________________________________________________________
reshape_43 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 13
Trainable params: 13
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_43 (Conv2DT (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.3657365
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Encoder Loss:  0.0899348  || Decoder Loss:  0.0899348 Validation Decoder Loss:  0.36573654
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36573654
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_44 (Conv3DT (None, 127, 10, 20, 1)    129       
_________________________________________________________________
reshape_44 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_44 (Conv2DT (None, 2607, 20, 1)       70        
=================================================================
Total params: 70
Trainable params: 70
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745907 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.037459083 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.037459075 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.037459083 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.037459083 Validation Decoder Loss:  0.32803452
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.32803446
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Encoder Loss:  0.21314101  || Decoder Loss:  0.03745908 Validation Decoder Loss:  0.3280345
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3280345
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_45 (Conv3DT (None, 234, 5, 20, 1)     172       
_________________________________________________________________
reshape_45 (Reshape)         (None, 1170, 20, 1)       0         
=================================================================
Total params: 172
Trainable params: 172
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 1170, 20, 1)       1439      
=================================================================
Total params: 1,439
Trainable params: 1,439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_45 (Conv2DT (None, 2607, 20, 1)       1439      
=================================================================
Total params: 1,439
Trainable params: 1,439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27621135  || Decoder Loss:  0.37499577 Validation Decoder Loss:  0.62680554
Encoder Loss:  0.0846006  || Decoder Loss:  0.09189715 Validation Decoder Loss:  0.34701517
Encoder Loss:  0.05153695  || Decoder Loss:  0.038701788 Validation Decoder Loss:  0.338341
Encoder Loss:  0.055601258  || Decoder Loss:  0.041701216 Validation Decoder Loss:  0.3535688
Encoder Loss:  0.045529097  || Decoder Loss:  0.040030006 Validation Decoder Loss:  0.33416164
Encoder Loss:  0.04227681  || Decoder Loss:  0.035429563 Validation Decoder Loss:  0.3323285
Encoder Loss:  0.041403726  || Decoder Loss:  0.034836173 Validation Decoder Loss:  0.33457962
Encoder Loss:  0.041769844  || Decoder Loss:  0.035384905 Validation Decoder Loss:  0.3418268
Encoder Loss:  0.04139686  || Decoder Loss:  0.03500121 Validation Decoder Loss:  0.34022948
Encoder Loss:  0.041546896  || Decoder Loss:  0.03517126 Validation Decoder Loss:  0.34796157
Encoder Loss:  0.04152623  || Decoder Loss:  0.034808844 Validation Decoder Loss:  0.33688194
Encoder Loss:  0.04116757  || Decoder Loss:  0.034548324 Validation Decoder Loss:  0.34391078
Encoder Loss:  0.041674394  || Decoder Loss:  0.034686018 Validation Decoder Loss:  0.33974832
Encoder Loss:  0.042217515  || Decoder Loss:  0.035196386 Validation Decoder Loss:  0.34062022
Encoder Loss:  0.04261955  || Decoder Loss:  0.035271596 Validation Decoder Loss:  0.3307828
Encoder Loss:  0.041123353  || Decoder Loss:  0.03430243 Validation Decoder Loss:  0.3275153
Encoder Loss:  0.04170917  || Decoder Loss:  0.03551103 Validation Decoder Loss:  0.33184874
Encoder Loss:  0.041058727  || Decoder Loss:  0.034482617 Validation Decoder Loss:  0.33227247
Encoder Loss:  0.04095965  || Decoder Loss:  0.03414812 Validation Decoder Loss:  0.34116605
Encoder Loss:  0.04101738  || Decoder Loss:  0.034176797 Validation Decoder Loss:  0.3356889
Encoder Loss:  0.04188948  || Decoder Loss:  0.034798585 Validation Decoder Loss:  0.34094644
Encoder Loss:  0.041380133  || Decoder Loss:  0.034380287 Validation Decoder Loss:  0.34345257
Encoder Loss:  0.042176455  || Decoder Loss:  0.03539156 Validation Decoder Loss:  0.33744907
Encoder Loss:  0.040850934  || Decoder Loss:  0.03414409 Validation Decoder Loss:  0.33320063
Encoder Loss:  0.040741786  || Decoder Loss:  0.033885483 Validation Decoder Loss:  0.33897978
Encoder Loss:  0.04083153  || Decoder Loss:  0.033946875 Validation Decoder Loss:  0.3320133
Encoder Loss:  0.041781805  || Decoder Loss:  0.034970425 Validation Decoder Loss:  0.34634453
Encoder Loss:  0.041062903  || Decoder Loss:  0.034230508 Validation Decoder Loss:  0.33481902
Encoder Loss:  0.04085232  || Decoder Loss:  0.034057803 Validation Decoder Loss:  0.3333714
Encoder Loss:  0.041231856  || Decoder Loss:  0.03409169 Validation Decoder Loss:  0.34792832
Encoder Loss:  0.04118759  || Decoder Loss:  0.034489512 Validation Decoder Loss:  0.33601704
Encoder Loss:  0.041164346  || Decoder Loss:  0.03420298 Validation Decoder Loss:  0.33462298
Encoder Loss:  0.040735845  || Decoder Loss:  0.03374192 Validation Decoder Loss:  0.34388018
Encoder Loss:  0.040983353  || Decoder Loss:  0.03405962 Validation Decoder Loss:  0.33207202
Encoder Loss:  0.040558144  || Decoder Loss:  0.03357513 Validation Decoder Loss:  0.33638525
Encoder Loss:  0.04126275  || Decoder Loss:  0.0344098 Validation Decoder Loss:  0.34595627
Encoder Loss:  0.04100308  || Decoder Loss:  0.03414659 Validation Decoder Loss:  0.33983263
Encoder Loss:  0.041434117  || Decoder Loss:  0.0335463 Validation Decoder Loss:  0.35599995
Encoder Loss:  0.041820627  || Decoder Loss:  0.035639804 Validation Decoder Loss:  0.3427843
Encoder Loss:  0.040710725  || Decoder Loss:  0.033559613 Validation Decoder Loss:  0.33788395
Model: siamese_net_lr_0.23572726767249605 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33788395
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_46 (Conv3DT (None, 170, 6, 20, 1)     215       
_________________________________________________________________
reshape_46 (Reshape)         (None, 1020, 20, 1)       0         
=================================================================
Total params: 215
Trainable params: 215
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 1020, 20, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_46 (Conv2DT (None, 2607, 20, 1)       570       
=================================================================
Total params: 570
Trainable params: 570
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27031386  || Decoder Loss:  0.48430157 Validation Decoder Loss:  1.070418
Encoder Loss:  0.13090292  || Decoder Loss:  0.21522751 Validation Decoder Loss:  0.32554686
Encoder Loss:  0.050165787  || Decoder Loss:  0.04296731 Validation Decoder Loss:  0.32727116
Encoder Loss:  0.047361337  || Decoder Loss:  0.04024814 Validation Decoder Loss:  0.32380316
Encoder Loss:  0.047496438  || Decoder Loss:  0.04013445 Validation Decoder Loss:  0.3260429
Encoder Loss:  0.046295147  || Decoder Loss:  0.03890431 Validation Decoder Loss:  0.32794738
Encoder Loss:  0.048689164  || Decoder Loss:  0.040049694 Validation Decoder Loss:  0.32515007
Encoder Loss:  0.046336576  || Decoder Loss:  0.04012002 Validation Decoder Loss:  0.33193696
Encoder Loss:  0.045862816  || Decoder Loss:  0.03902196 Validation Decoder Loss:  0.33258605
Encoder Loss:  0.04546349  || Decoder Loss:  0.03859342 Validation Decoder Loss:  0.3358314
Encoder Loss:  0.045605637  || Decoder Loss:  0.03812325 Validation Decoder Loss:  0.33280075
Encoder Loss:  0.04578822  || Decoder Loss:  0.038794998 Validation Decoder Loss:  0.33510613
Encoder Loss:  0.04458827  || Decoder Loss:  0.037115492 Validation Decoder Loss:  0.33308485
Encoder Loss:  0.04651001  || Decoder Loss:  0.039561003 Validation Decoder Loss:  0.3589132
Encoder Loss:  0.044651713  || Decoder Loss:  0.036812294 Validation Decoder Loss:  0.33431312
Encoder Loss:  0.04460131  || Decoder Loss:  0.037385512 Validation Decoder Loss:  0.33441785
Encoder Loss:  0.045563113  || Decoder Loss:  0.03799642 Validation Decoder Loss:  0.33167493
Encoder Loss:  0.0446713  || Decoder Loss:  0.037611026 Validation Decoder Loss:  0.33883563
Encoder Loss:  0.04473425  || Decoder Loss:  0.037399292 Validation Decoder Loss:  0.33918652
Encoder Loss:  0.044356555  || Decoder Loss:  0.036970254 Validation Decoder Loss:  0.3389489
Encoder Loss:  0.046354514  || Decoder Loss:  0.037271075 Validation Decoder Loss:  0.33720204
Encoder Loss:  0.04469659  || Decoder Loss:  0.036851376 Validation Decoder Loss:  0.33460766
Encoder Loss:  0.044479918  || Decoder Loss:  0.037590444 Validation Decoder Loss:  0.342249
Encoder Loss:  0.044562727  || Decoder Loss:  0.036903627 Validation Decoder Loss:  0.33522412
Encoder Loss:  0.04401209  || Decoder Loss:  0.036258876 Validation Decoder Loss:  0.33225113
Encoder Loss:  0.044667155  || Decoder Loss:  0.037200503 Validation Decoder Loss:  0.34885567
Encoder Loss:  0.044062063  || Decoder Loss:  0.036665097 Validation Decoder Loss:  0.3571276
Encoder Loss:  0.0443056  || Decoder Loss:  0.03666504 Validation Decoder Loss:  0.36337554
Encoder Loss:  0.044197965  || Decoder Loss:  0.036624894 Validation Decoder Loss:  0.3560963
Encoder Loss:  0.044008344  || Decoder Loss:  0.03631916 Validation Decoder Loss:  0.33445743
Encoder Loss:  0.043843526  || Decoder Loss:  0.03620558 Validation Decoder Loss:  0.34032091
Encoder Loss:  0.043971725  || Decoder Loss:  0.036350273 Validation Decoder Loss:  0.33269525
Encoder Loss:  0.043850955  || Decoder Loss:  0.03618558 Validation Decoder Loss:  0.35172725
Encoder Loss:  0.043783497  || Decoder Loss:  0.035852216 Validation Decoder Loss:  0.3570872
Encoder Loss:  0.044156555  || Decoder Loss:  0.036474623 Validation Decoder Loss:  0.3369926
Encoder Loss:  0.043787792  || Decoder Loss:  0.03609739 Validation Decoder Loss:  0.34859592
Encoder Loss:  0.043857478  || Decoder Loss:  0.036169257 Validation Decoder Loss:  0.35453954
Encoder Loss:  0.043937825  || Decoder Loss:  0.036127128 Validation Decoder Loss:  0.35565835
Encoder Loss:  0.043557987  || Decoder Loss:  0.035663273 Validation Decoder Loss:  0.35310996
Encoder Loss:  0.043975167  || Decoder Loss:  0.03617997 Validation Decoder Loss:  0.3388628
Model: siamese_net_lr_0.5596429251294072 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33886284
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_47 (Conv3DT (None, 170, 6, 20, 1)     215       
_________________________________________________________________
reshape_47 (Reshape)         (None, 1020, 20, 1)       0         
=================================================================
Total params: 215
Trainable params: 215
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_142"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 1020, 20, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_143"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_47 (Conv2DT (None, 2607, 20, 1)       1589      
=================================================================
Total params: 1,589
Trainable params: 1,589
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.506083  || Decoder Loss:  0.69499296 Validation Decoder Loss:  0.6373671
Encoder Loss:  0.31516713  || Decoder Loss:  0.0856807 Validation Decoder Loss:  0.3862316
Encoder Loss:  0.2620623  || Decoder Loss:  0.08124311 Validation Decoder Loss:  0.40425897
Encoder Loss:  0.23419926  || Decoder Loss:  0.33329532 Validation Decoder Loss:  1.2997801
Encoder Loss:  0.21256915  || Decoder Loss:  0.50750375 Validation Decoder Loss:  1.2159125
Encoder Loss:  0.20191841  || Decoder Loss:  0.52008605 Validation Decoder Loss:  1.1098065
Encoder Loss:  0.18630429  || Decoder Loss:  0.4788325 Validation Decoder Loss:  1.1384665
Encoder Loss:  0.18618426  || Decoder Loss:  0.47952285 Validation Decoder Loss:  1.116936
Encoder Loss:  0.18146823  || Decoder Loss:  0.46455002 Validation Decoder Loss:  1.1250159
Encoder Loss:  0.1815721  || Decoder Loss:  0.46477926 Validation Decoder Loss:  1.1271737
Encoder Loss:  0.18437877  || Decoder Loss:  0.47206658 Validation Decoder Loss:  1.1654387
Encoder Loss:  0.1831968  || Decoder Loss:  0.46739683 Validation Decoder Loss:  1.1727958
Encoder Loss:  0.1848526  || Decoder Loss:  0.47412083 Validation Decoder Loss:  1.1283352
Encoder Loss:  0.18863435  || Decoder Loss:  0.48568824 Validation Decoder Loss:  1.1345098
Encoder Loss:  0.18129328  || Decoder Loss:  0.46369454 Validation Decoder Loss:  1.155397
Encoder Loss:  0.17776476  || Decoder Loss:  0.45045128 Validation Decoder Loss:  1.1541445
Encoder Loss:  0.18065853  || Decoder Loss:  0.4511137 Validation Decoder Loss:  1.019398
Encoder Loss:  0.18724811  || Decoder Loss:  0.4814348 Validation Decoder Loss:  1.1923038
Encoder Loss:  0.18033811  || Decoder Loss:  0.45438686 Validation Decoder Loss:  1.3185272
Encoder Loss:  0.19143364  || Decoder Loss:  0.48791373 Validation Decoder Loss:  1.2245772
Encoder Loss:  0.20971641  || Decoder Loss:  0.5307774 Validation Decoder Loss:  1.1126735
Encoder Loss:  0.18273315  || Decoder Loss:  0.4672741 Validation Decoder Loss:  1.1244162
Encoder Loss:  0.1805126  || Decoder Loss:  0.46060035 Validation Decoder Loss:  1.1828134
Encoder Loss:  0.1636459  || Decoder Loss:  0.40381917 Validation Decoder Loss:  1.0933585
Encoder Loss:  0.18285471  || Decoder Loss:  0.461071 Validation Decoder Loss:  1.0188272
Encoder Loss:  0.19872113  || Decoder Loss:  0.51322985 Validation Decoder Loss:  1.0629047
Encoder Loss:  0.20038418  || Decoder Loss:  0.51782125 Validation Decoder Loss:  1.1600459
Encoder Loss:  0.19216222  || Decoder Loss:  0.49264666 Validation Decoder Loss:  1.0888985
Encoder Loss:  0.18530217  || Decoder Loss:  0.4766592 Validation Decoder Loss:  1.1140254
Encoder Loss:  0.18869904  || Decoder Loss:  0.4880144 Validation Decoder Loss:  1.1311955
Encoder Loss:  0.1874052  || Decoder Loss:  0.48340362 Validation Decoder Loss:  1.1362308
Encoder Loss:  0.19053188  || Decoder Loss:  0.4906244 Validation Decoder Loss:  1.0992966
Encoder Loss:  0.18815526  || Decoder Loss:  0.48428035 Validation Decoder Loss:  1.142426
Encoder Loss:  0.18865457  || Decoder Loss:  0.4852308 Validation Decoder Loss:  1.090664
Encoder Loss:  0.18865222  || Decoder Loss:  0.48724845 Validation Decoder Loss:  1.1228106
Encoder Loss:  0.18769409  || Decoder Loss:  0.48430604 Validation Decoder Loss:  1.1345778
Encoder Loss:  0.1849813  || Decoder Loss:  0.47638753 Validation Decoder Loss:  1.1560943
Encoder Loss:  0.18567944  || Decoder Loss:  0.47279954 Validation Decoder Loss:  1.3482147
Encoder Loss:  0.20194362  || Decoder Loss:  0.50417274 Validation Decoder Loss:  1.2489114
Encoder Loss:  0.17376293  || Decoder Loss:  0.43676463 Validation Decoder Loss:  0.9834044
Model: siamese_net_lr_0.9858244475110192 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9834044
Model: "sequential_144"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_48 (Conv3DT (None, 137, 10, 20, 1)    149       
_________________________________________________________________
reshape_48 (Reshape)         (None, 1370, 20, 1)       0         
=================================================================
Total params: 149
Trainable params: 149
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_145"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 1370, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_146"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_48 (Conv2DT (None, 2607, 20, 1)       1239      
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4368392  || Decoder Loss:  0.6374089 Validation Decoder Loss:  1.3331463
Encoder Loss:  0.20592415  || Decoder Loss:  0.5280221 Validation Decoder Loss:  1.0613217
Encoder Loss:  0.19597341  || Decoder Loss:  0.5125253 Validation Decoder Loss:  0.9880233
Encoder Loss:  0.19684777  || Decoder Loss:  0.5007495 Validation Decoder Loss:  0.98452276
Encoder Loss:  0.19497356  || Decoder Loss:  0.49722305 Validation Decoder Loss:  1.0134044
Encoder Loss:  0.1945903  || Decoder Loss:  0.5057119 Validation Decoder Loss:  0.99858546
Encoder Loss:  0.1971678  || Decoder Loss:  0.5102225 Validation Decoder Loss:  1.0663182
Encoder Loss:  0.19267625  || Decoder Loss:  0.5043077 Validation Decoder Loss:  1.116328
Encoder Loss:  0.19005276  || Decoder Loss:  0.50717604 Validation Decoder Loss:  1.0827754
Encoder Loss:  0.19208756  || Decoder Loss:  0.5140179 Validation Decoder Loss:  1.138443
Encoder Loss:  0.18625353  || Decoder Loss:  0.50097984 Validation Decoder Loss:  1.1542308
Encoder Loss:  0.1859742  || Decoder Loss:  0.50331724 Validation Decoder Loss:  1.2073655
Encoder Loss:  0.17844602  || Decoder Loss:  0.5020948 Validation Decoder Loss:  1.1932669
Encoder Loss:  0.1695534  || Decoder Loss:  0.48414943 Validation Decoder Loss:  1.0624537
Encoder Loss:  0.1625373  || Decoder Loss:  0.48268428 Validation Decoder Loss:  1.0607805
Encoder Loss:  0.15989493  || Decoder Loss:  0.47955796 Validation Decoder Loss:  1.0064487
Encoder Loss:  0.15758762  || Decoder Loss:  0.47354507 Validation Decoder Loss:  0.98031443
Encoder Loss:  0.16149868  || Decoder Loss:  0.4925708 Validation Decoder Loss:  1.0002139
Encoder Loss:  0.15194322  || Decoder Loss:  0.4510919 Validation Decoder Loss:  0.8841171
Encoder Loss:  0.15677625  || Decoder Loss:  0.4702072 Validation Decoder Loss:  0.9317764
Encoder Loss:  0.16243137  || Decoder Loss:  0.4934611 Validation Decoder Loss:  1.1404343
Encoder Loss:  0.15568495  || Decoder Loss:  0.46682423 Validation Decoder Loss:  0.98958117
Encoder Loss:  0.14476384  || Decoder Loss:  0.42320862 Validation Decoder Loss:  0.67155474
Encoder Loss:  0.13449  || Decoder Loss:  0.3858851 Validation Decoder Loss:  0.83401227
Encoder Loss:  0.112105936  || Decoder Loss:  0.29578817 Validation Decoder Loss:  0.64736694
Encoder Loss:  0.09779468  || Decoder Loss:  0.2377778 Validation Decoder Loss:  0.5409982
Encoder Loss:  0.07535187  || Decoder Loss:  0.14812715 Validation Decoder Loss:  0.4219972
Encoder Loss:  0.056862574  || Decoder Loss:  0.07260664 Validation Decoder Loss:  0.35910022
Encoder Loss:  0.049095523  || Decoder Loss:  0.044632744 Validation Decoder Loss:  0.40954375
Encoder Loss:  0.04863603  || Decoder Loss:  0.040817242 Validation Decoder Loss:  0.3521899
Encoder Loss:  0.04747014  || Decoder Loss:  0.03758323 Validation Decoder Loss:  0.37536973
Encoder Loss:  0.04785279  || Decoder Loss:  0.037451383 Validation Decoder Loss:  0.35766685
Encoder Loss:  0.04709538  || Decoder Loss:  0.036891147 Validation Decoder Loss:  0.3620968
Encoder Loss:  0.046656534  || Decoder Loss:  0.035365943 Validation Decoder Loss:  0.37947673
Encoder Loss:  0.04710841  || Decoder Loss:  0.037406992 Validation Decoder Loss:  0.3574395
Encoder Loss:  0.0465571  || Decoder Loss:  0.03534726 Validation Decoder Loss:  0.37213972
Encoder Loss:  0.04685136  || Decoder Loss:  0.035537817 Validation Decoder Loss:  0.3527714
Encoder Loss:  0.046914674  || Decoder Loss:  0.036024615 Validation Decoder Loss:  0.3517727
Encoder Loss:  0.04655417  || Decoder Loss:  0.03522266 Validation Decoder Loss:  0.37012443
Encoder Loss:  0.047111865  || Decoder Loss:  0.03574616 Validation Decoder Loss:  0.3573348
Model: siamese_net_lr_0.9193572802702061 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3573348
Model: "sequential_147"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_49 (Conv3DT (None, 444, 5, 20, 1)     256       
_________________________________________________________________
reshape_49 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 256
Trainable params: 256
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_148"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_149"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_49 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25686023  || Decoder Loss:  0.34946424 Validation Decoder Loss:  0.74202955
Encoder Loss:  0.24971063  || Decoder Loss:  0.3800526 Validation Decoder Loss:  0.8955833
Encoder Loss:  0.21515861  || Decoder Loss:  0.35759267 Validation Decoder Loss:  0.32949865
Encoder Loss:  0.072153576  || Decoder Loss:  0.08062157 Validation Decoder Loss:  0.3184591
Encoder Loss:  0.045903552  || Decoder Loss:  0.039913252 Validation Decoder Loss:  0.3997435
Encoder Loss:  0.04742594  || Decoder Loss:  0.041228954 Validation Decoder Loss:  0.30260497
Encoder Loss:  0.045753933  || Decoder Loss:  0.03494869 Validation Decoder Loss:  0.33223528
Encoder Loss:  0.046269283  || Decoder Loss:  0.034539774 Validation Decoder Loss:  0.30913585
Encoder Loss:  0.050812222  || Decoder Loss:  0.047430295 Validation Decoder Loss:  0.29306138
Encoder Loss:  0.048062075  || Decoder Loss:  0.043320693 Validation Decoder Loss:  0.29641858
Encoder Loss:  0.042999078  || Decoder Loss:  0.03510119 Validation Decoder Loss:  0.3347913
Encoder Loss:  0.042205404  || Decoder Loss:  0.034148633 Validation Decoder Loss:  0.32510358
Encoder Loss:  0.042659182  || Decoder Loss:  0.034229796 Validation Decoder Loss:  0.33597815
Encoder Loss:  0.044339877  || Decoder Loss:  0.03485067 Validation Decoder Loss:  0.31257877
Encoder Loss:  0.046010956  || Decoder Loss:  0.037565388 Validation Decoder Loss:  0.3608551
Encoder Loss:  0.043637667  || Decoder Loss:  0.03653892 Validation Decoder Loss:  0.32181808
Encoder Loss:  0.043961562  || Decoder Loss:  0.036424506 Validation Decoder Loss:  0.29929346
Encoder Loss:  0.045727275  || Decoder Loss:  0.03772824 Validation Decoder Loss:  0.37172306
Encoder Loss:  0.04459449  || Decoder Loss:  0.03806804 Validation Decoder Loss:  0.30651057
Encoder Loss:  0.043280717  || Decoder Loss:  0.036472008 Validation Decoder Loss:  0.37850666
Encoder Loss:  0.0437405  || Decoder Loss:  0.03739921 Validation Decoder Loss:  0.3605975
Encoder Loss:  0.043833118  || Decoder Loss:  0.036773637 Validation Decoder Loss:  0.30962032
Encoder Loss:  0.043405596  || Decoder Loss:  0.036256775 Validation Decoder Loss:  0.30915546
Encoder Loss:  0.042944703  || Decoder Loss:  0.03610356 Validation Decoder Loss:  0.30594033
Encoder Loss:  0.043182086  || Decoder Loss:  0.036335446 Validation Decoder Loss:  0.30913916
Encoder Loss:  0.043096248  || Decoder Loss:  0.035933726 Validation Decoder Loss:  0.366131
Encoder Loss:  0.043957524  || Decoder Loss:  0.03709006 Validation Decoder Loss:  0.31290627
Encoder Loss:  0.044947553  || Decoder Loss:  0.036801726 Validation Decoder Loss:  0.33125204
Encoder Loss:  0.04407973  || Decoder Loss:  0.037008125 Validation Decoder Loss:  0.3603222
Encoder Loss:  0.04425136  || Decoder Loss:  0.037221614 Validation Decoder Loss:  0.3028758
Encoder Loss:  0.0443229  || Decoder Loss:  0.03771757 Validation Decoder Loss:  0.37863114
Encoder Loss:  0.04433116  || Decoder Loss:  0.03798404 Validation Decoder Loss:  0.36810642
Encoder Loss:  0.04451697  || Decoder Loss:  0.037087336 Validation Decoder Loss:  0.31582886
Encoder Loss:  0.070987575  || Decoder Loss:  0.06260786 Validation Decoder Loss:  0.33997566
Encoder Loss:  0.05334812  || Decoder Loss:  0.05443782 Validation Decoder Loss:  0.4920181
Encoder Loss:  0.04879654  || Decoder Loss:  0.047428656 Validation Decoder Loss:  0.37307894
Encoder Loss:  0.042642996  || Decoder Loss:  0.035702422 Validation Decoder Loss:  0.33297998
Encoder Loss:  0.042320438  || Decoder Loss:  0.03507457 Validation Decoder Loss:  0.32647213
Encoder Loss:  0.042404037  || Decoder Loss:  0.03525878 Validation Decoder Loss:  0.31848094
Encoder Loss:  0.042626813  || Decoder Loss:  0.03568972 Validation Decoder Loss:  0.31686822
Model: siamese_net_lr_0.3739873162036017 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31686822
Model: "sequential_150"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_50 (Conv3DT (None, 222, 10, 20, 1)    319       
_________________________________________________________________
reshape_50 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 319
Trainable params: 319
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_151"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_152"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_50 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4037196  || Decoder Loss:  0.42309165 Validation Decoder Loss:  0.89355487
Encoder Loss:  0.45702904  || Decoder Loss:  0.4882699 Validation Decoder Loss:  1.097269
Encoder Loss:  0.45783955  || Decoder Loss:  0.4878372 Validation Decoder Loss:  0.79885375
Encoder Loss:  0.42881683  || Decoder Loss:  0.45756862 Validation Decoder Loss:  1.0436208
Encoder Loss:  0.43768212  || Decoder Loss:  0.46675 Validation Decoder Loss:  1.2169316
Encoder Loss:  0.46398342  || Decoder Loss:  0.49581394 Validation Decoder Loss:  1.2148395
Encoder Loss:  0.46462336  || Decoder Loss:  0.4964616 Validation Decoder Loss:  1.2002192
Encoder Loss:  0.46339235  || Decoder Loss:  0.4959132 Validation Decoder Loss:  1.1848509
Encoder Loss:  0.4628295  || Decoder Loss:  0.49486545 Validation Decoder Loss:  1.1553743
Encoder Loss:  0.447044  || Decoder Loss:  0.47800294 Validation Decoder Loss:  0.9583603
Encoder Loss:  0.43773532  || Decoder Loss:  0.4679535 Validation Decoder Loss:  1.136305
Encoder Loss:  0.46217468  || Decoder Loss:  0.49415725 Validation Decoder Loss:  1.1071054
Encoder Loss:  0.45864394  || Decoder Loss:  0.4898939 Validation Decoder Loss:  1.1909862
Encoder Loss:  0.42262238  || Decoder Loss:  0.45146042 Validation Decoder Loss:  0.49841213
Encoder Loss:  0.44063905  || Decoder Loss:  0.47108746 Validation Decoder Loss:  1.1350975
Encoder Loss:  0.45514834  || Decoder Loss:  0.48659575 Validation Decoder Loss:  1.1633215
Encoder Loss:  0.4534125  || Decoder Loss:  0.48511317 Validation Decoder Loss:  1.1794095
Encoder Loss:  0.3727421  || Decoder Loss:  0.3975831 Validation Decoder Loss:  0.5442496
Encoder Loss:  0.2552936  || Decoder Loss:  0.27080014 Validation Decoder Loss:  0.46157074
Encoder Loss:  0.18784434  || Decoder Loss:  0.1982232 Validation Decoder Loss:  0.4221869
Encoder Loss:  0.08834737  || Decoder Loss:  0.09037382 Validation Decoder Loss:  0.31979245
Encoder Loss:  0.042558502  || Decoder Loss:  0.04103162 Validation Decoder Loss:  0.33531487
Encoder Loss:  0.037909042  || Decoder Loss:  0.03640108 Validation Decoder Loss:  0.33272657
Encoder Loss:  0.037496477  || Decoder Loss:  0.035693165 Validation Decoder Loss:  0.33516884
Encoder Loss:  0.037868798  || Decoder Loss:  0.03632967 Validation Decoder Loss:  0.31685627
Encoder Loss:  0.038979813  || Decoder Loss:  0.03768491 Validation Decoder Loss:  0.36799818
Encoder Loss:  0.039473496  || Decoder Loss:  0.038321547 Validation Decoder Loss:  0.31475288
Encoder Loss:  0.03932694  || Decoder Loss:  0.038167506 Validation Decoder Loss:  0.31550735
Encoder Loss:  0.03873734  || Decoder Loss:  0.037798814 Validation Decoder Loss:  0.31503248
Encoder Loss:  0.038402226  || Decoder Loss:  0.03745316 Validation Decoder Loss:  0.31526092
Encoder Loss:  0.03822274  || Decoder Loss:  0.0372511 Validation Decoder Loss:  0.31529018
Encoder Loss:  0.0382185  || Decoder Loss:  0.03725592 Validation Decoder Loss:  0.31484303
Encoder Loss:  0.03812101  || Decoder Loss:  0.037150964 Validation Decoder Loss:  0.3151927
Encoder Loss:  0.038239885  || Decoder Loss:  0.037188627 Validation Decoder Loss:  0.31512725
Encoder Loss:  0.038073972  || Decoder Loss:  0.03708006 Validation Decoder Loss:  0.31523544
Encoder Loss:  0.037999112  || Decoder Loss:  0.037007593 Validation Decoder Loss:  0.3155244
Encoder Loss:  0.037902083  || Decoder Loss:  0.036906715 Validation Decoder Loss:  0.31555495
Encoder Loss:  0.037900962  || Decoder Loss:  0.036921125 Validation Decoder Loss:  0.3154982
Encoder Loss:  0.03783595  || Decoder Loss:  0.03685062 Validation Decoder Loss:  0.31561062
Encoder Loss:  0.037817556  || Decoder Loss:  0.03682006 Validation Decoder Loss:  0.31570756
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31570756
Model: "sequential_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_51 (Conv3DT (None, 65, 18, 20, 1)     29        
_________________________________________________________________
reshape_51 (Reshape)         (None, 1170, 20, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_154"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 1170, 20, 1)       270       
=================================================================
Total params: 270
Trainable params: 270
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_155"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_51 (Conv2DT (None, 2607, 20, 1)       270       
=================================================================
Total params: 270
Trainable params: 270
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41916952  || Decoder Loss:  0.07816365 Validation Decoder Loss:  0.35145074
Encoder Loss:  0.44271538  || Decoder Loss:  0.04263084 Validation Decoder Loss:  0.35143355
Encoder Loss:  0.44248664  || Decoder Loss:  0.042311173 Validation Decoder Loss:  0.3522099
Encoder Loss:  0.44198403  || Decoder Loss:  0.04207671 Validation Decoder Loss:  0.35231373
Encoder Loss:  0.441262  || Decoder Loss:  0.041842934 Validation Decoder Loss:  0.3517121
Encoder Loss:  0.44020203  || Decoder Loss:  0.041628886 Validation Decoder Loss:  0.3511333
Encoder Loss:  0.4384947  || Decoder Loss:  0.041504502 Validation Decoder Loss:  0.3515839
Encoder Loss:  0.43508697  || Decoder Loss:  0.0416281 Validation Decoder Loss:  0.35269085
Encoder Loss:  0.40500426  || Decoder Loss:  0.06558931 Validation Decoder Loss:  1.1062257
Encoder Loss:  0.36502323  || Decoder Loss:  0.6207206 Validation Decoder Loss:  1.6328721
Encoder Loss:  0.19862568  || Decoder Loss:  0.5405292 Validation Decoder Loss:  1.1893641
Encoder Loss:  0.11054169  || Decoder Loss:  0.50880617 Validation Decoder Loss:  0.48167455
Encoder Loss:  0.11701026  || Decoder Loss:  0.47552937 Validation Decoder Loss:  0.51124793
Encoder Loss:  0.10747985  || Decoder Loss:  0.46703035 Validation Decoder Loss:  0.5998397
Encoder Loss:  0.08988495  || Decoder Loss:  0.4957515 Validation Decoder Loss:  0.66618013
Encoder Loss:  0.09306898  || Decoder Loss:  0.46248665 Validation Decoder Loss:  0.86993474
Encoder Loss:  0.08103101  || Decoder Loss:  0.4881894 Validation Decoder Loss:  0.7988915
Encoder Loss:  0.077449135  || Decoder Loss:  0.49663103 Validation Decoder Loss:  0.6652907
Encoder Loss:  0.09048007  || Decoder Loss:  0.46121007 Validation Decoder Loss:  0.8706208
Encoder Loss:  0.07773317  || Decoder Loss:  0.4844597 Validation Decoder Loss:  0.7719393
Encoder Loss:  0.076499045  || Decoder Loss:  0.4803461 Validation Decoder Loss:  0.71379524
Encoder Loss:  0.085967004  || Decoder Loss:  0.43745664 Validation Decoder Loss:  0.6087465
Encoder Loss:  0.08634509  || Decoder Loss:  0.4556398 Validation Decoder Loss:  0.5650879
Encoder Loss:  0.08392752  || Decoder Loss:  0.44459015 Validation Decoder Loss:  0.60156846
Encoder Loss:  0.07910237  || Decoder Loss:  0.46847755 Validation Decoder Loss:  0.6749454
Encoder Loss:  0.08054472  || Decoder Loss:  0.41601032 Validation Decoder Loss:  0.7990417
Encoder Loss:  0.072713286  || Decoder Loss:  0.415108 Validation Decoder Loss:  0.5978087
Encoder Loss:  0.074983776  || Decoder Loss:  0.38885617 Validation Decoder Loss:  0.6048449
Encoder Loss:  0.076259695  || Decoder Loss:  0.28434506 Validation Decoder Loss:  0.4612308
Encoder Loss:  0.07520881  || Decoder Loss:  0.069411986 Validation Decoder Loss:  0.33460993
Encoder Loss:  0.07045401  || Decoder Loss:  0.03846117 Validation Decoder Loss:  0.33477974
Encoder Loss:  0.06946871  || Decoder Loss:  0.035740625 Validation Decoder Loss:  0.3319443
Encoder Loss:  0.061035722  || Decoder Loss:  0.035476595 Validation Decoder Loss:  0.3315581
Encoder Loss:  0.06380651  || Decoder Loss:  0.03546702 Validation Decoder Loss:  0.33168602
Encoder Loss:  0.06129515  || Decoder Loss:  0.035460398 Validation Decoder Loss:  0.33200336
Encoder Loss:  0.06422319  || Decoder Loss:  0.035412077 Validation Decoder Loss:  0.33215743
Encoder Loss:  0.06964047  || Decoder Loss:  0.03536739 Validation Decoder Loss:  0.33220673
Encoder Loss:  0.059091225  || Decoder Loss:  0.03533256 Validation Decoder Loss:  0.33236402
Encoder Loss:  0.058615554  || Decoder Loss:  0.035274997 Validation Decoder Loss:  0.33245993
Encoder Loss:  0.05887202  || Decoder Loss:  0.035221837 Validation Decoder Loss:  0.33241954
Model: siamese_net_lr_0.4243092095154798 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3324195
Model: "sequential_156"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_52 (Conv3DT (None, 185, 12, 20, 1)    977       
_________________________________________________________________
reshape_52 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 977
Trainable params: 977
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_157"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_158"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_52 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2787803  || Decoder Loss:  0.37141755 Validation Decoder Loss:  0.8095982
Encoder Loss:  0.25810668  || Decoder Loss:  0.48827827 Validation Decoder Loss:  0.8669801
Encoder Loss:  0.25340587  || Decoder Loss:  0.49448052 Validation Decoder Loss:  0.88017595
Encoder Loss:  0.2634152  || Decoder Loss:  0.49774554 Validation Decoder Loss:  0.8240546
Encoder Loss:  0.25394744  || Decoder Loss:  0.4888634 Validation Decoder Loss:  1.0343125
Encoder Loss:  0.24262893  || Decoder Loss:  0.4715022 Validation Decoder Loss:  0.8159644
Encoder Loss:  0.24729612  || Decoder Loss:  0.48353902 Validation Decoder Loss:  1.1967645
Encoder Loss:  0.2566806  || Decoder Loss:  0.5010374 Validation Decoder Loss:  1.1589682
Encoder Loss:  0.2564601  || Decoder Loss:  0.49811286 Validation Decoder Loss:  1.1825387
Encoder Loss:  0.25431335  || Decoder Loss:  0.4956962 Validation Decoder Loss:  1.2097075
Encoder Loss:  0.25454566  || Decoder Loss:  0.49785614 Validation Decoder Loss:  1.2259266
Encoder Loss:  0.25459558  || Decoder Loss:  0.49678773 Validation Decoder Loss:  1.2006079
Encoder Loss:  0.25503126  || Decoder Loss:  0.49830875 Validation Decoder Loss:  1.1924219
Encoder Loss:  0.25256446  || Decoder Loss:  0.49440184 Validation Decoder Loss:  1.2245336
Encoder Loss:  0.25064975  || Decoder Loss:  0.4939526 Validation Decoder Loss:  1.2303529
Encoder Loss:  0.2508517  || Decoder Loss:  0.49245155 Validation Decoder Loss:  1.2315354
Encoder Loss:  0.24763754  || Decoder Loss:  0.4852916 Validation Decoder Loss:  1.0695379
Encoder Loss:  0.24432456  || Decoder Loss:  0.47386178 Validation Decoder Loss:  0.7405416
Encoder Loss:  0.24456882  || Decoder Loss:  0.4757448 Validation Decoder Loss:  0.77955574
Encoder Loss:  0.24162558  || Decoder Loss:  0.4731351 Validation Decoder Loss:  1.1847267
Encoder Loss:  0.25200903  || Decoder Loss:  0.49266624 Validation Decoder Loss:  1.2029661
Encoder Loss:  0.2513932  || Decoder Loss:  0.49474403 Validation Decoder Loss:  1.2084606
Encoder Loss:  0.25034705  || Decoder Loss:  0.49334162 Validation Decoder Loss:  1.2082107
Encoder Loss:  0.25005585  || Decoder Loss:  0.49110276 Validation Decoder Loss:  1.2033114
Encoder Loss:  0.24844751  || Decoder Loss:  0.48552707 Validation Decoder Loss:  1.2237903
Encoder Loss:  0.23060262  || Decoder Loss:  0.44760653 Validation Decoder Loss:  0.85954285
Encoder Loss:  0.18440455  || Decoder Loss:  0.34475884 Validation Decoder Loss:  1.1295707
Encoder Loss:  0.17674778  || Decoder Loss:  0.3224565 Validation Decoder Loss:  1.1376125
Encoder Loss:  0.19287015  || Decoder Loss:  0.36436543 Validation Decoder Loss:  0.9296396
Encoder Loss:  0.06496463  || Decoder Loss:  0.07762867 Validation Decoder Loss:  0.3153442
Encoder Loss:  0.047718797  || Decoder Loss:  0.040572356 Validation Decoder Loss:  0.30885255
Encoder Loss:  0.04691918  || Decoder Loss:  0.039212044 Validation Decoder Loss:  0.3811254
Encoder Loss:  0.047238756  || Decoder Loss:  0.03852205 Validation Decoder Loss:  0.3801521
Encoder Loss:  0.047436915  || Decoder Loss:  0.038543187 Validation Decoder Loss:  0.37337935
Encoder Loss:  0.04638171  || Decoder Loss:  0.03787231 Validation Decoder Loss:  0.3783024
Encoder Loss:  0.045561932  || Decoder Loss:  0.037611924 Validation Decoder Loss:  0.31102738
Encoder Loss:  0.046083465  || Decoder Loss:  0.037654974 Validation Decoder Loss:  0.37596363
Encoder Loss:  0.04744186  || Decoder Loss:  0.03773149 Validation Decoder Loss:  0.30853927
Encoder Loss:  0.04649855  || Decoder Loss:  0.037636794 Validation Decoder Loss:  0.37460482
Encoder Loss:  0.046780184  || Decoder Loss:  0.037787244 Validation Decoder Loss:  0.37408197
Model: siamese_net_lr_0.4448086329052876 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37408197
Model: "sequential_159"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_53 (Conv3DT (None, 464, 5, 20, 1)     402       
_________________________________________________________________
reshape_53 (Reshape)         (None, 2320, 20, 1)       0         
=================================================================
Total params: 402
Trainable params: 402
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 2320, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_161"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_53 (Conv2DT (None, 2607, 20, 1)       289       
=================================================================
Total params: 289
Trainable params: 289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19227847  || Decoder Loss:  0.10399125 Validation Decoder Loss:  0.3307752
Encoder Loss:  0.06297165  || Decoder Loss:  0.04051147 Validation Decoder Loss:  0.33638632
Encoder Loss:  0.04531712  || Decoder Loss:  0.035304092 Validation Decoder Loss:  0.33643103
Encoder Loss:  0.044255085  || Decoder Loss:  0.034831278 Validation Decoder Loss:  0.34807688
Encoder Loss:  0.04361214  || Decoder Loss:  0.035332553 Validation Decoder Loss:  0.33692706
Encoder Loss:  0.043026756  || Decoder Loss:  0.034088787 Validation Decoder Loss:  0.33455682
Encoder Loss:  0.0432754  || Decoder Loss:  0.033990115 Validation Decoder Loss:  0.3371811
Encoder Loss:  0.043748513  || Decoder Loss:  0.03407827 Validation Decoder Loss:  0.33883846
Encoder Loss:  0.044474375  || Decoder Loss:  0.034137033 Validation Decoder Loss:  0.33744365
Encoder Loss:  0.043794  || Decoder Loss:  0.034353703 Validation Decoder Loss:  0.3376581
Encoder Loss:  0.04347413  || Decoder Loss:  0.03432096 Validation Decoder Loss:  0.33564973
Encoder Loss:  0.043118697  || Decoder Loss:  0.034286603 Validation Decoder Loss:  0.3364689
Encoder Loss:  0.04357864  || Decoder Loss:  0.03430367 Validation Decoder Loss:  0.3321622
Encoder Loss:  0.043274652  || Decoder Loss:  0.034382306 Validation Decoder Loss:  0.33313915
Encoder Loss:  0.04302636  || Decoder Loss:  0.03430031 Validation Decoder Loss:  0.33661017
Encoder Loss:  0.043403927  || Decoder Loss:  0.034305714 Validation Decoder Loss:  0.3360642
Encoder Loss:  0.04408179  || Decoder Loss:  0.03449548 Validation Decoder Loss:  0.3222073
Encoder Loss:  0.04326489  || Decoder Loss:  0.034455243 Validation Decoder Loss:  0.33202553
Encoder Loss:  0.043132644  || Decoder Loss:  0.034406804 Validation Decoder Loss:  0.33570927
Encoder Loss:  0.04305928  || Decoder Loss:  0.034456234 Validation Decoder Loss:  0.33560914
Encoder Loss:  0.04309052  || Decoder Loss:  0.034434915 Validation Decoder Loss:  0.33795035
Encoder Loss:  0.044581886  || Decoder Loss:  0.034644123 Validation Decoder Loss:  0.3240717
Encoder Loss:  0.04351121  || Decoder Loss:  0.03468736 Validation Decoder Loss:  0.32642263
Encoder Loss:  0.043297693  || Decoder Loss:  0.03472247 Validation Decoder Loss:  0.33176172
Encoder Loss:  0.043032106  || Decoder Loss:  0.03457733 Validation Decoder Loss:  0.3390712
Encoder Loss:  0.043150306  || Decoder Loss:  0.034598477 Validation Decoder Loss:  0.33919626
Encoder Loss:  0.04299215  || Decoder Loss:  0.034516007 Validation Decoder Loss:  0.33832097
Encoder Loss:  0.043072596  || Decoder Loss:  0.034576643 Validation Decoder Loss:  0.3382042
Encoder Loss:  0.04307485  || Decoder Loss:  0.034569167 Validation Decoder Loss:  0.33809617
Encoder Loss:  0.043225326  || Decoder Loss:  0.03458771 Validation Decoder Loss:  0.33505666
Encoder Loss:  0.04296878  || Decoder Loss:  0.034568164 Validation Decoder Loss:  0.33917806
Encoder Loss:  0.0431701  || Decoder Loss:  0.03458005 Validation Decoder Loss:  0.33840913
Encoder Loss:  0.043136064  || Decoder Loss:  0.03460813 Validation Decoder Loss:  0.33768713
Encoder Loss:  0.043182574  || Decoder Loss:  0.03463134 Validation Decoder Loss:  0.33769274
Encoder Loss:  0.043032918  || Decoder Loss:  0.03463532 Validation Decoder Loss:  0.3388425
Encoder Loss:  0.04297214  || Decoder Loss:  0.03460559 Validation Decoder Loss:  0.34008795
Encoder Loss:  0.042990975  || Decoder Loss:  0.03459081 Validation Decoder Loss:  0.3394528
Encoder Loss:  0.043075223  || Decoder Loss:  0.03460529 Validation Decoder Loss:  0.33886412
Encoder Loss:  0.043196198  || Decoder Loss:  0.034638926 Validation Decoder Loss:  0.3369575
Encoder Loss:  0.04310416  || Decoder Loss:  0.034670852 Validation Decoder Loss:  0.33886206
Model: siamese_net_lr_0.025578853530396194 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33886206
Model: "sequential_162"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_54 (Conv3DT (None, 167, 10, 20, 1)    209       
_________________________________________________________________
reshape_54 (Reshape)         (None, 1670, 20, 1)       0         
=================================================================
Total params: 209
Trainable params: 209
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_163"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 1670, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_164"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_54 (Conv2DT (None, 2607, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30729428  || Decoder Loss:  0.4439827 Validation Decoder Loss:  1.0424349
Encoder Loss:  0.3084088  || Decoder Loss:  0.49370426 Validation Decoder Loss:  0.923376
Encoder Loss:  0.2878603  || Decoder Loss:  0.47406822 Validation Decoder Loss:  0.9618948
Encoder Loss:  0.29984194  || Decoder Loss:  0.4868803 Validation Decoder Loss:  0.82607424
Encoder Loss:  0.27007732  || Decoder Loss:  0.45260072 Validation Decoder Loss:  0.8718268
Encoder Loss:  0.26869097  || Decoder Loss:  0.4552404 Validation Decoder Loss:  0.9634782
Encoder Loss:  0.26301804  || Decoder Loss:  0.4334289 Validation Decoder Loss:  0.87820125
Encoder Loss:  0.22624423  || Decoder Loss:  0.3670225 Validation Decoder Loss:  0.7672182
Encoder Loss:  0.2522351  || Decoder Loss:  0.41254476 Validation Decoder Loss:  0.6654502
Encoder Loss:  0.17485204  || Decoder Loss:  0.27111673 Validation Decoder Loss:  0.3992885
Encoder Loss:  0.15454262  || Decoder Loss:  0.2266806 Validation Decoder Loss:  0.61903965
Encoder Loss:  0.2200758  || Decoder Loss:  0.36225355 Validation Decoder Loss:  0.8605365
Encoder Loss:  0.14956336  || Decoder Loss:  0.23053564 Validation Decoder Loss:  0.9756818
Encoder Loss:  0.16323313  || Decoder Loss:  0.26188406 Validation Decoder Loss:  0.6398232
Encoder Loss:  0.15355927  || Decoder Loss:  0.24471676 Validation Decoder Loss:  0.34570798
Encoder Loss:  0.047992874  || Decoder Loss:  0.04574623 Validation Decoder Loss:  0.39117467
Encoder Loss:  0.04600591  || Decoder Loss:  0.04149826 Validation Decoder Loss:  0.33236378
Encoder Loss:  0.045030728  || Decoder Loss:  0.039731544 Validation Decoder Loss:  0.33239692
Encoder Loss:  0.044039298  || Decoder Loss:  0.038296387 Validation Decoder Loss:  0.33202124
Encoder Loss:  0.04377222  || Decoder Loss:  0.037778918 Validation Decoder Loss:  0.32810867
Encoder Loss:  0.043583546  || Decoder Loss:  0.03745406 Validation Decoder Loss:  0.32636434
Encoder Loss:  0.043759756  || Decoder Loss:  0.037399754 Validation Decoder Loss:  0.32063937
Encoder Loss:  0.0453162  || Decoder Loss:  0.038396046 Validation Decoder Loss:  0.3174483
Encoder Loss:  0.04928029  || Decoder Loss:  0.039189033 Validation Decoder Loss:  0.32563123
Encoder Loss:  0.046362277  || Decoder Loss:  0.040738247 Validation Decoder Loss:  0.33817118
Encoder Loss:  0.044234633  || Decoder Loss:  0.03869622 Validation Decoder Loss:  0.32487106
Encoder Loss:  0.044207063  || Decoder Loss:  0.03876703 Validation Decoder Loss:  0.3583262
Encoder Loss:  0.043792482  || Decoder Loss:  0.03799193 Validation Decoder Loss:  0.35990512
Encoder Loss:  0.043470267  || Decoder Loss:  0.03746546 Validation Decoder Loss:  0.31198376
Encoder Loss:  0.04390852  || Decoder Loss:  0.038168903 Validation Decoder Loss:  0.3144772
Encoder Loss:  0.043883413  || Decoder Loss:  0.037982114 Validation Decoder Loss:  0.31546336
Encoder Loss:  0.043536443  || Decoder Loss:  0.037203256 Validation Decoder Loss:  0.35717767
Encoder Loss:  0.043982606  || Decoder Loss:  0.037804946 Validation Decoder Loss:  0.32603294
Encoder Loss:  0.043142315  || Decoder Loss:  0.03670774 Validation Decoder Loss:  0.31406355
Encoder Loss:  0.04388573  || Decoder Loss:  0.037806906 Validation Decoder Loss:  0.37589985
Encoder Loss:  0.043951575  || Decoder Loss:  0.037735622 Validation Decoder Loss:  0.3682871
Encoder Loss:  0.043798994  || Decoder Loss:  0.038001373 Validation Decoder Loss:  0.34526455
Encoder Loss:  0.042833272  || Decoder Loss:  0.035955682 Validation Decoder Loss:  0.33487052
Encoder Loss:  0.042862114  || Decoder Loss:  0.036267415 Validation Decoder Loss:  0.32578278
Encoder Loss:  0.043854814  || Decoder Loss:  0.03777401 Validation Decoder Loss:  0.32191858
Model: siamese_net_lr_0.9192773437169485 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32191855
Model: "sequential_165"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_55 (Conv3DT (None, 334, 5, 20, 1)     272       
_________________________________________________________________
reshape_55 (Reshape)         (None, 1670, 20, 1)       0         
=================================================================
Total params: 272
Trainable params: 272
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_166"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_55 (Conv2D)           (None, 1670, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_55 (Conv2DT (None, 2607, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22922039  || Decoder Loss:  0.4107493 Validation Decoder Loss:  0.91459167
Encoder Loss:  0.21647714  || Decoder Loss:  0.50450385 Validation Decoder Loss:  1.2197227
Encoder Loss:  0.21391563  || Decoder Loss:  0.50098133 Validation Decoder Loss:  1.311238
Encoder Loss:  0.20651415  || Decoder Loss:  0.49408454 Validation Decoder Loss:  1.1684147
Encoder Loss:  0.20140977  || Decoder Loss:  0.48876983 Validation Decoder Loss:  1.1477398
Encoder Loss:  0.20716321  || Decoder Loss:  0.48978737 Validation Decoder Loss:  0.8760499
Encoder Loss:  0.20552199  || Decoder Loss:  0.5054642 Validation Decoder Loss:  0.93339014
Encoder Loss:  0.19953714  || Decoder Loss:  0.48092252 Validation Decoder Loss:  0.9503745
Encoder Loss:  0.18353096  || Decoder Loss:  0.44102547 Validation Decoder Loss:  1.1073034
Encoder Loss:  0.19441627  || Decoder Loss:  0.4563836 Validation Decoder Loss:  0.76569885
Encoder Loss:  0.16102749  || Decoder Loss:  0.36097094 Validation Decoder Loss:  0.52083933
Encoder Loss:  0.12267652  || Decoder Loss:  0.25221798 Validation Decoder Loss:  0.59162486
Encoder Loss:  0.07336006  || Decoder Loss:  0.09439502 Validation Decoder Loss:  0.41973835
Encoder Loss:  0.055033598  || Decoder Loss:  0.05601666 Validation Decoder Loss:  0.35229087
Encoder Loss:  0.05512254  || Decoder Loss:  0.0471967 Validation Decoder Loss:  0.39464563
Encoder Loss:  0.05407281  || Decoder Loss:  0.044046365 Validation Decoder Loss:  0.33202744
Encoder Loss:  0.052131545  || Decoder Loss:  0.04170184 Validation Decoder Loss:  0.33214775
Encoder Loss:  0.04968628  || Decoder Loss:  0.039820127 Validation Decoder Loss:  0.32339454
Encoder Loss:  0.049459796  || Decoder Loss:  0.038797043 Validation Decoder Loss:  0.35793883
Encoder Loss:  0.048293673  || Decoder Loss:  0.03817352 Validation Decoder Loss:  0.33976364
Encoder Loss:  0.05211868  || Decoder Loss:  0.038478225 Validation Decoder Loss:  0.3419456
Encoder Loss:  0.051438626  || Decoder Loss:  0.03866008 Validation Decoder Loss:  0.36839736
Encoder Loss:  0.05411269  || Decoder Loss:  0.03943898 Validation Decoder Loss:  0.31798095
Encoder Loss:  0.048992068  || Decoder Loss:  0.0383848 Validation Decoder Loss:  0.33503658
Encoder Loss:  0.051854257  || Decoder Loss:  0.038320236 Validation Decoder Loss:  0.37945288
Encoder Loss:  0.049148794  || Decoder Loss:  0.03775773 Validation Decoder Loss:  0.3704893
Encoder Loss:  0.048207827  || Decoder Loss:  0.037807204 Validation Decoder Loss:  0.3290593
Encoder Loss:  0.051582154  || Decoder Loss:  0.037808917 Validation Decoder Loss:  0.32374498
Encoder Loss:  0.050191708  || Decoder Loss:  0.03808266 Validation Decoder Loss:  0.37414944
Encoder Loss:  0.05115386  || Decoder Loss:  0.037975527 Validation Decoder Loss:  0.32041103
Encoder Loss:  0.048993956  || Decoder Loss:  0.03749925 Validation Decoder Loss:  0.35939547
Encoder Loss:  0.050639328  || Decoder Loss:  0.037681982 Validation Decoder Loss:  0.33208236
Encoder Loss:  0.052104253  || Decoder Loss:  0.038110677 Validation Decoder Loss:  0.3518542
Encoder Loss:  0.0473658  || Decoder Loss:  0.037399836 Validation Decoder Loss:  0.32515237
Encoder Loss:  0.047975466  || Decoder Loss:  0.036938824 Validation Decoder Loss:  0.37061453
Encoder Loss:  0.047429398  || Decoder Loss:  0.036597446 Validation Decoder Loss:  0.33489317
Encoder Loss:  0.04991771  || Decoder Loss:  0.037208196 Validation Decoder Loss:  0.32686156
Encoder Loss:  0.048103336  || Decoder Loss:  0.036990885 Validation Decoder Loss:  0.36883312
Encoder Loss:  0.04836176  || Decoder Loss:  0.036738534 Validation Decoder Loss:  0.32905206
Encoder Loss:  0.049992394  || Decoder Loss:  0.03720416 Validation Decoder Loss:  0.31985587
Model: siamese_net_lr_0.7281377925779795 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.31985587
Model: "sequential_168"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_56 (Conv3DT (None, 167, 10, 20, 1)    83        
_________________________________________________________________
reshape_56 (Reshape)         (None, 1670, 20, 1)       0         
=================================================================
Total params: 83
Trainable params: 83
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_169"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 1670, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_170"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_56 (Conv2DT (None, 2607, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.035669107  || Decoder Loss:  0.035669107 Validation Decoder Loss:  0.3502945
Encoder Loss:  0.03037687  || Decoder Loss:  0.03037687 Validation Decoder Loss:  0.3432879
Encoder Loss:  0.030520592  || Decoder Loss:  0.030520592 Validation Decoder Loss:  0.37261754
Encoder Loss:  0.030158773  || Decoder Loss:  0.030158773 Validation Decoder Loss:  0.36999914
Encoder Loss:  0.029942384  || Decoder Loss:  0.029942384 Validation Decoder Loss:  0.36953646
Encoder Loss:  0.02976679  || Decoder Loss:  0.02976679 Validation Decoder Loss:  0.36925805
Encoder Loss:  0.02960544  || Decoder Loss:  0.02960544 Validation Decoder Loss:  0.36867756
Encoder Loss:  0.029455282  || Decoder Loss:  0.029455282 Validation Decoder Loss:  0.36824313
Encoder Loss:  0.029317593  || Decoder Loss:  0.029317593 Validation Decoder Loss:  0.368046
Encoder Loss:  0.02919221  || Decoder Loss:  0.02919221 Validation Decoder Loss:  0.36794788
Encoder Loss:  0.02907786  || Decoder Loss:  0.02907786 Validation Decoder Loss:  0.36790115
Encoder Loss:  0.028973429  || Decoder Loss:  0.028973429 Validation Decoder Loss:  0.36788324
Encoder Loss:  0.028877735  || Decoder Loss:  0.028877735 Validation Decoder Loss:  0.36788246
Encoder Loss:  0.0287898  || Decoder Loss:  0.0287898 Validation Decoder Loss:  0.36789173
Encoder Loss:  0.028708821  || Decoder Loss:  0.028708821 Validation Decoder Loss:  0.36790723
Encoder Loss:  0.028633986  || Decoder Loss:  0.028633986 Validation Decoder Loss:  0.36792585
Encoder Loss:  0.028564658  || Decoder Loss:  0.028564658 Validation Decoder Loss:  0.36794573
Encoder Loss:  0.028500244  || Decoder Loss:  0.028500244 Validation Decoder Loss:  0.36796552
Encoder Loss:  0.028440231  || Decoder Loss:  0.028440231 Validation Decoder Loss:  0.36798418
Encoder Loss:  0.028384224  || Decoder Loss:  0.028384224 Validation Decoder Loss:  0.36800086
Encoder Loss:  0.028331691  || Decoder Loss:  0.028331691 Validation Decoder Loss:  0.36801532
Encoder Loss:  0.028282419  || Decoder Loss:  0.028282419 Validation Decoder Loss:  0.36802715
Encoder Loss:  0.028236048  || Decoder Loss:  0.028236048 Validation Decoder Loss:  0.368036
Encoder Loss:  0.028192291  || Decoder Loss:  0.028192291 Validation Decoder Loss:  0.36804214
Encoder Loss:  0.028150916  || Decoder Loss:  0.028150916 Validation Decoder Loss:  0.3680453
Encoder Loss:  0.028111765  || Decoder Loss:  0.028111765 Validation Decoder Loss:  0.3680456
Encoder Loss:  0.028074574  || Decoder Loss:  0.028074574 Validation Decoder Loss:  0.3680433
Encoder Loss:  0.028039217  || Decoder Loss:  0.028039217 Validation Decoder Loss:  0.36803818
Encoder Loss:  0.028005546  || Decoder Loss:  0.028005546 Validation Decoder Loss:  0.36803052
Encoder Loss:  0.027973438  || Decoder Loss:  0.027973438 Validation Decoder Loss:  0.36802047
Encoder Loss:  0.027942736  || Decoder Loss:  0.027942736 Validation Decoder Loss:  0.3680081
Encoder Loss:  0.027913375  || Decoder Loss:  0.027913375 Validation Decoder Loss:  0.3679936
Encoder Loss:  0.027885273  || Decoder Loss:  0.027885273 Validation Decoder Loss:  0.367977
Encoder Loss:  0.02785828  || Decoder Loss:  0.02785828 Validation Decoder Loss:  0.3679586
Encoder Loss:  0.02783238  || Decoder Loss:  0.02783238 Validation Decoder Loss:  0.36793828
Encoder Loss:  0.027807483  || Decoder Loss:  0.027807483 Validation Decoder Loss:  0.3679164
Encoder Loss:  0.027783494  || Decoder Loss:  0.027783494 Validation Decoder Loss:  0.36789292
Encoder Loss:  0.02776041  || Decoder Loss:  0.02776041 Validation Decoder Loss:  0.36786798
Encoder Loss:  0.027738145  || Decoder Loss:  0.027738145 Validation Decoder Loss:  0.36784157
Encoder Loss:  0.027716668  || Decoder Loss:  0.027716668 Validation Decoder Loss:  0.36781383
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36781383
Model: "sequential_171"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_57 (Conv3DT (None, 121, 20, 20, 1)    697       
_________________________________________________________________
reshape_57 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 697
Trainable params: 697
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_172"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_57 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_173"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_57 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2315045  || Decoder Loss:  0.46036762 Validation Decoder Loss:  1.2098302
Encoder Loss:  0.17032942  || Decoder Loss:  0.358857 Validation Decoder Loss:  0.3411318
Encoder Loss:  0.05310731  || Decoder Loss:  0.04965188 Validation Decoder Loss:  0.34730935
Encoder Loss:  0.05080422  || Decoder Loss:  0.046513602 Validation Decoder Loss:  0.32885033
Encoder Loss:  0.048619498  || Decoder Loss:  0.043209735 Validation Decoder Loss:  0.34920537
Encoder Loss:  0.050213803  || Decoder Loss:  0.046611357 Validation Decoder Loss:  0.34008116
Encoder Loss:  0.048168916  || Decoder Loss:  0.04295378 Validation Decoder Loss:  0.33475542
Encoder Loss:  0.04853198  || Decoder Loss:  0.045202065 Validation Decoder Loss:  0.34233022
Encoder Loss:  0.048848998  || Decoder Loss:  0.044946283 Validation Decoder Loss:  0.34326953
Encoder Loss:  0.048687216  || Decoder Loss:  0.044835016 Validation Decoder Loss:  0.3418099
Encoder Loss:  0.048172507  || Decoder Loss:  0.041190144 Validation Decoder Loss:  0.33391887
Encoder Loss:  0.04832649  || Decoder Loss:  0.04446362 Validation Decoder Loss:  0.34095395
Encoder Loss:  0.047912974  || Decoder Loss:  0.04297109 Validation Decoder Loss:  0.3361384
Encoder Loss:  0.047710773  || Decoder Loss:  0.042237584 Validation Decoder Loss:  0.33646244
Encoder Loss:  0.04721854  || Decoder Loss:  0.04119131 Validation Decoder Loss:  0.33570427
Encoder Loss:  0.048125643  || Decoder Loss:  0.04316704 Validation Decoder Loss:  0.34040362
Encoder Loss:  0.04758773  || Decoder Loss:  0.04266976 Validation Decoder Loss:  0.33571208
Encoder Loss:  0.04688265  || Decoder Loss:  0.040661793 Validation Decoder Loss:  0.33520395
Encoder Loss:  0.047675792  || Decoder Loss:  0.041267194 Validation Decoder Loss:  0.33515906
Encoder Loss:  0.046618354  || Decoder Loss:  0.040275525 Validation Decoder Loss:  0.3347472
Encoder Loss:  0.046955615  || Decoder Loss:  0.040440816 Validation Decoder Loss:  0.33454174
Encoder Loss:  0.046483055  || Decoder Loss:  0.03991297 Validation Decoder Loss:  0.33525658
Encoder Loss:  0.046710063  || Decoder Loss:  0.040053297 Validation Decoder Loss:  0.33416688
Encoder Loss:  0.04653636  || Decoder Loss:  0.039962567 Validation Decoder Loss:  0.33531192
Encoder Loss:  0.047474276  || Decoder Loss:  0.04054699 Validation Decoder Loss:  0.33373845
Encoder Loss:  0.046435323  || Decoder Loss:  0.03982134 Validation Decoder Loss:  0.335356
Encoder Loss:  0.046458937  || Decoder Loss:  0.039720304 Validation Decoder Loss:  0.33349976
Encoder Loss:  0.046663553  || Decoder Loss:  0.039774645 Validation Decoder Loss:  0.33537772
Encoder Loss:  0.046397284  || Decoder Loss:  0.03979171 Validation Decoder Loss:  0.33351415
Encoder Loss:  0.04694489  || Decoder Loss:  0.039865788 Validation Decoder Loss:  0.3346095
Encoder Loss:  0.04621844  || Decoder Loss:  0.039356954 Validation Decoder Loss:  0.33376238
Encoder Loss:  0.046195574  || Decoder Loss:  0.039135225 Validation Decoder Loss:  0.33442444
Encoder Loss:  0.046168808  || Decoder Loss:  0.03898253 Validation Decoder Loss:  0.33410764
Encoder Loss:  0.046932727  || Decoder Loss:  0.039534338 Validation Decoder Loss:  0.3330953
Encoder Loss:  0.046295743  || Decoder Loss:  0.03936952 Validation Decoder Loss:  0.33453482
Encoder Loss:  0.0462038  || Decoder Loss:  0.039079294 Validation Decoder Loss:  0.33340803
Encoder Loss:  0.0462532  || Decoder Loss:  0.03922166 Validation Decoder Loss:  0.33450505
Encoder Loss:  0.0460978  || Decoder Loss:  0.03895389 Validation Decoder Loss:  0.33347857
Encoder Loss:  0.046152435  || Decoder Loss:  0.039099082 Validation Decoder Loss:  0.33430654
Encoder Loss:  0.04606141  || Decoder Loss:  0.03885536 Validation Decoder Loss:  0.333758
Model: siamese_net_lr_0.6380354441041168 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.333758
Model: "sequential_174"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_58 (Conv3DT (None, 474, 5, 20, 1)     97        
_________________________________________________________________
reshape_58 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_175"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_58 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_58 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20396817  || Decoder Loss:  0.06623529 Validation Decoder Loss:  0.35163853
Encoder Loss:  0.20699619  || Decoder Loss:  0.04206353 Validation Decoder Loss:  0.35141784
Encoder Loss:  0.20658724  || Decoder Loss:  0.042570077 Validation Decoder Loss:  0.351592
Encoder Loss:  0.20538738  || Decoder Loss:  0.04481665 Validation Decoder Loss:  0.35396296
Encoder Loss:  0.26947275  || Decoder Loss:  0.21372971 Validation Decoder Loss:  1.0641837
Encoder Loss:  0.3457443  || Decoder Loss:  0.5112576 Validation Decoder Loss:  0.8742848
Encoder Loss:  0.34165058  || Decoder Loss:  0.5086047 Validation Decoder Loss:  0.8033629
Encoder Loss:  0.3244998  || Decoder Loss:  0.47753596 Validation Decoder Loss:  0.7474282
Encoder Loss:  0.33209708  || Decoder Loss:  0.4957827 Validation Decoder Loss:  0.7636579
Encoder Loss:  0.25793248  || Decoder Loss:  0.38587174 Validation Decoder Loss:  0.50059247
Encoder Loss:  0.2113011  || Decoder Loss:  0.31859457 Validation Decoder Loss:  0.9094261
Encoder Loss:  0.122256756  || Decoder Loss:  0.17012343 Validation Decoder Loss:  0.33405566
Encoder Loss:  0.048095398  || Decoder Loss:  0.04470173 Validation Decoder Loss:  0.33083808
Encoder Loss:  0.04207267  || Decoder Loss:  0.03495821 Validation Decoder Loss:  0.32851326
Encoder Loss:  0.041490067  || Decoder Loss:  0.03446117 Validation Decoder Loss:  0.32957703
Encoder Loss:  0.042720165  || Decoder Loss:  0.034408856 Validation Decoder Loss:  0.32940423
Encoder Loss:  0.042039342  || Decoder Loss:  0.034380183 Validation Decoder Loss:  0.32942355
Encoder Loss:  0.04134987  || Decoder Loss:  0.034373224 Validation Decoder Loss:  0.329598
Encoder Loss:  0.04149152  || Decoder Loss:  0.03436103 Validation Decoder Loss:  0.3294254
Encoder Loss:  0.042522144  || Decoder Loss:  0.03433845 Validation Decoder Loss:  0.32918862
Encoder Loss:  0.0423126  || Decoder Loss:  0.034351174 Validation Decoder Loss:  0.3298148
Encoder Loss:  0.04216346  || Decoder Loss:  0.034331735 Validation Decoder Loss:  0.32924604
Encoder Loss:  0.0426373  || Decoder Loss:  0.034336027 Validation Decoder Loss:  0.32904798
Encoder Loss:  0.04126641  || Decoder Loss:  0.03432243 Validation Decoder Loss:  0.32946652
Encoder Loss:  0.041472744  || Decoder Loss:  0.03430028 Validation Decoder Loss:  0.32937643
Encoder Loss:  0.04101677  || Decoder Loss:  0.03429404 Validation Decoder Loss:  0.32951742
Encoder Loss:  0.041672878  || Decoder Loss:  0.03428144 Validation Decoder Loss:  0.32943803
Encoder Loss:  0.041497782  || Decoder Loss:  0.03427508 Validation Decoder Loss:  0.3294132
Encoder Loss:  0.042180575  || Decoder Loss:  0.03427409 Validation Decoder Loss:  0.3292787
Encoder Loss:  0.041562535  || Decoder Loss:  0.034262113 Validation Decoder Loss:  0.32935995
Encoder Loss:  0.04141496  || Decoder Loss:  0.034260925 Validation Decoder Loss:  0.32948095
Encoder Loss:  0.04123702  || Decoder Loss:  0.03425167 Validation Decoder Loss:  0.32959414
Encoder Loss:  0.04150971  || Decoder Loss:  0.03424303 Validation Decoder Loss:  0.329535
Encoder Loss:  0.041521125  || Decoder Loss:  0.034243725 Validation Decoder Loss:  0.32928014
Encoder Loss:  0.04232757  || Decoder Loss:  0.034229886 Validation Decoder Loss:  0.32933724
Encoder Loss:  0.04130371  || Decoder Loss:  0.03424107 Validation Decoder Loss:  0.32937682
Encoder Loss:  0.041240226  || Decoder Loss:  0.03422338 Validation Decoder Loss:  0.3294332
Encoder Loss:  0.041319866  || Decoder Loss:  0.034218736 Validation Decoder Loss:  0.3293056
Encoder Loss:  0.041543588  || Decoder Loss:  0.034197666 Validation Decoder Loss:  0.3295086
Encoder Loss:  0.040963665  || Decoder Loss:  0.034215517 Validation Decoder Loss:  0.32957834
Model: siamese_net_lr_0.2650611658527664 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32957834
Model: "sequential_177"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_59 (Conv3DT (None, 244, 5, 20, 1)     119       
_________________________________________________________________
reshape_59 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_178"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_59 (Conv2D)           (None, 1220, 20, 1)       170       
=================================================================
Total params: 170
Trainable params: 170
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_179"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_59 (Conv2DT (None, 2607, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.34465492  || Decoder Loss:  0.35310805 Validation Decoder Loss:  0.68198115
Encoder Loss:  0.2818369  || Decoder Loss:  0.29470208 Validation Decoder Loss:  0.37952408
Encoder Loss:  0.031889353  || Decoder Loss:  0.030385029 Validation Decoder Loss:  0.37084857
Encoder Loss:  0.032707788  || Decoder Loss:  0.030595658 Validation Decoder Loss:  0.39257616
Encoder Loss:  0.030208819  || Decoder Loss:  0.02884949 Validation Decoder Loss:  0.35960054
Encoder Loss:  0.028686624  || Decoder Loss:  0.027300177 Validation Decoder Loss:  0.36386153
Encoder Loss:  0.029441373  || Decoder Loss:  0.028006373 Validation Decoder Loss:  0.3614599
Encoder Loss:  0.030134246  || Decoder Loss:  0.0286512 Validation Decoder Loss:  0.36281163
Encoder Loss:  0.028724756  || Decoder Loss:  0.02723108 Validation Decoder Loss:  0.37034136
Encoder Loss:  0.02924379  || Decoder Loss:  0.027796514 Validation Decoder Loss:  0.3630768
Encoder Loss:  0.028493294  || Decoder Loss:  0.027179377 Validation Decoder Loss:  0.36035043
Encoder Loss:  0.028867356  || Decoder Loss:  0.027536998 Validation Decoder Loss:  0.37251955
Encoder Loss:  0.03096032  || Decoder Loss:  0.029703798 Validation Decoder Loss:  0.36576167
Encoder Loss:  0.029499222  || Decoder Loss:  0.028234653 Validation Decoder Loss:  0.3795973
Encoder Loss:  0.029525729  || Decoder Loss:  0.028216973 Validation Decoder Loss:  0.39047217
Encoder Loss:  0.030362966  || Decoder Loss:  0.029126644 Validation Decoder Loss:  0.37841153
Encoder Loss:  0.03287948  || Decoder Loss:  0.031676203 Validation Decoder Loss:  0.35859382
Encoder Loss:  0.03636825  || Decoder Loss:  0.0351217 Validation Decoder Loss:  0.36843196
Encoder Loss:  0.029748388  || Decoder Loss:  0.028509615 Validation Decoder Loss:  0.37414134
Encoder Loss:  0.030606559  || Decoder Loss:  0.029427974 Validation Decoder Loss:  0.38006753
Encoder Loss:  0.030904861  || Decoder Loss:  0.029732935 Validation Decoder Loss:  0.37206715
Encoder Loss:  0.030759018  || Decoder Loss:  0.029596863 Validation Decoder Loss:  0.37312365
Encoder Loss:  0.03172095  || Decoder Loss:  0.030541666 Validation Decoder Loss:  0.38284102
Encoder Loss:  0.03262376  || Decoder Loss:  0.031515572 Validation Decoder Loss:  0.37213022
Encoder Loss:  0.03169867  || Decoder Loss:  0.030582437 Validation Decoder Loss:  0.36684632
Encoder Loss:  0.03043253  || Decoder Loss:  0.02924912 Validation Decoder Loss:  0.37098762
Encoder Loss:  0.03219843  || Decoder Loss:  0.031120583 Validation Decoder Loss:  0.36356375
Encoder Loss:  0.031319316  || Decoder Loss:  0.030167488 Validation Decoder Loss:  0.362951
Encoder Loss:  0.032195635  || Decoder Loss:  0.031114848 Validation Decoder Loss:  0.36312702
Encoder Loss:  0.032094795  || Decoder Loss:  0.03099027 Validation Decoder Loss:  0.3653833
Encoder Loss:  0.03261485  || Decoder Loss:  0.031553682 Validation Decoder Loss:  0.3686257
Encoder Loss:  0.032648478  || Decoder Loss:  0.031545486 Validation Decoder Loss:  0.37302703
Encoder Loss:  0.033475243  || Decoder Loss:  0.032477852 Validation Decoder Loss:  0.35859782
Encoder Loss:  0.033052374  || Decoder Loss:  0.031994984 Validation Decoder Loss:  0.35958278
Encoder Loss:  0.03289291  || Decoder Loss:  0.031843774 Validation Decoder Loss:  0.36629897
Encoder Loss:  0.035495907  || Decoder Loss:  0.034505755 Validation Decoder Loss:  0.35506925
Encoder Loss:  0.035336252  || Decoder Loss:  0.03432033 Validation Decoder Loss:  0.35170552
Encoder Loss:  0.034214072  || Decoder Loss:  0.03324579 Validation Decoder Loss:  0.3471604
Encoder Loss:  0.033967406  || Decoder Loss:  0.032938566 Validation Decoder Loss:  0.35108116
Encoder Loss:  0.03910053  || Decoder Loss:  0.038018987 Validation Decoder Loss:  0.3419808
Model: siamese_net_lr_0.5045010164209001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34198081
Model: "sequential_180"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_60 (Conv3DT (None, 74, 30, 20, 1)     111       
_________________________________________________________________
reshape_60 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_60 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_182"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_60 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054371785  || Decoder Loss:  0.053439803 Validation Decoder Loss:  0.36116803
Encoder Loss:  0.11471453  || Decoder Loss:  0.11404136 Validation Decoder Loss:  0.36673644
Encoder Loss:  0.41487867  || Decoder Loss:  0.41552636 Validation Decoder Loss:  1.4389988
Encoder Loss:  0.48349145  || Decoder Loss:  0.48442796 Validation Decoder Loss:  0.6432495
Encoder Loss:  0.46655917  || Decoder Loss:  0.46748996 Validation Decoder Loss:  1.1687009
Encoder Loss:  0.50033575  || Decoder Loss:  0.5013565 Validation Decoder Loss:  0.69467056
Encoder Loss:  0.46893042  || Decoder Loss:  0.46987855 Validation Decoder Loss:  1.1525333
Encoder Loss:  0.49303383  || Decoder Loss:  0.49404278 Validation Decoder Loss:  1.1431081
Encoder Loss:  0.4656933  || Decoder Loss:  0.46663123 Validation Decoder Loss:  0.9006916
Encoder Loss:  0.4484668  || Decoder Loss:  0.44936645 Validation Decoder Loss:  1.0617164
Encoder Loss:  0.3397027  || Decoder Loss:  0.34034795 Validation Decoder Loss:  0.3249817
Encoder Loss:  0.04407934  || Decoder Loss:  0.04402014 Validation Decoder Loss:  0.35067058
Encoder Loss:  0.039722335  || Decoder Loss:  0.039666023 Validation Decoder Loss:  0.34767988
Encoder Loss:  0.039063357  || Decoder Loss:  0.039010134 Validation Decoder Loss:  0.3432886
Encoder Loss:  0.0391521  || Decoder Loss:  0.03909515 Validation Decoder Loss:  0.3318482
Encoder Loss:  0.03857729  || Decoder Loss:  0.038519625 Validation Decoder Loss:  0.33806038
Encoder Loss:  0.038623855  || Decoder Loss:  0.03856878 Validation Decoder Loss:  0.3434893
Encoder Loss:  0.038110174  || Decoder Loss:  0.03804937 Validation Decoder Loss:  0.33604735
Encoder Loss:  0.03832946  || Decoder Loss:  0.038272914 Validation Decoder Loss:  0.34081584
Encoder Loss:  0.03795384  || Decoder Loss:  0.037897345 Validation Decoder Loss:  0.33809587
Encoder Loss:  0.037572395  || Decoder Loss:  0.037521273 Validation Decoder Loss:  0.33691728
Encoder Loss:  0.03754726  || Decoder Loss:  0.03749378 Validation Decoder Loss:  0.33288535
Encoder Loss:  0.03728811  || Decoder Loss:  0.03722969 Validation Decoder Loss:  0.3440488
Encoder Loss:  0.037405204  || Decoder Loss:  0.037352055 Validation Decoder Loss:  0.33910748
Encoder Loss:  0.037172746  || Decoder Loss:  0.03711603 Validation Decoder Loss:  0.3337853
Encoder Loss:  0.036998525  || Decoder Loss:  0.03694491 Validation Decoder Loss:  0.33168012
Encoder Loss:  0.036878124  || Decoder Loss:  0.036820386 Validation Decoder Loss:  0.34060037
Encoder Loss:  0.03687516  || Decoder Loss:  0.036816113 Validation Decoder Loss:  0.3410558
Encoder Loss:  0.03667781  || Decoder Loss:  0.036622327 Validation Decoder Loss:  0.3346768
Encoder Loss:  0.036782082  || Decoder Loss:  0.03672044 Validation Decoder Loss:  0.3380815
Encoder Loss:  0.03656615  || Decoder Loss:  0.03650776 Validation Decoder Loss:  0.33909208
Encoder Loss:  0.036500063  || Decoder Loss:  0.036444232 Validation Decoder Loss:  0.3314611
Encoder Loss:  0.036453545  || Decoder Loss:  0.036400888 Validation Decoder Loss:  0.33247626
Encoder Loss:  0.03642774  || Decoder Loss:  0.036362287 Validation Decoder Loss:  0.3310581
Encoder Loss:  0.036422625  || Decoder Loss:  0.03636781 Validation Decoder Loss:  0.3343302
Encoder Loss:  0.036181103  || Decoder Loss:  0.0361261 Validation Decoder Loss:  0.33974946
Encoder Loss:  0.036323503  || Decoder Loss:  0.036264624 Validation Decoder Loss:  0.33084017
Encoder Loss:  0.036268245  || Decoder Loss:  0.036206555 Validation Decoder Loss:  0.34087262
Encoder Loss:  0.036234792  || Decoder Loss:  0.0361804 Validation Decoder Loss:  0.33302832
Encoder Loss:  0.036086  || Decoder Loss:  0.036031425 Validation Decoder Loss:  0.33338946
Model: siamese_net_lr_0.9300230206696404 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33338946
Model: "sequential_183"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_61 (Conv3DT (None, 214, 5, 20, 1)     152       
_________________________________________________________________
reshape_61 (Reshape)         (None, 1070, 20, 1)       0         
=================================================================
Total params: 152
Trainable params: 152
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_184"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 1070, 20, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_185"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_61 (Conv2DT (None, 2607, 20, 1)       470       
=================================================================
Total params: 470
Trainable params: 470
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16847712  || Decoder Loss:  0.21430072 Validation Decoder Loss:  0.3874973
Encoder Loss:  0.07587615  || Decoder Loss:  0.03854838 Validation Decoder Loss:  0.3371112
Encoder Loss:  0.060495123  || Decoder Loss:  0.038903568 Validation Decoder Loss:  0.32004607
Encoder Loss:  0.058259793  || Decoder Loss:  0.03950153 Validation Decoder Loss:  0.35760236
Encoder Loss:  0.049697947  || Decoder Loss:  0.038204715 Validation Decoder Loss:  0.36056933
Encoder Loss:  0.0527773  || Decoder Loss:  0.038054608 Validation Decoder Loss:  0.35371223
Encoder Loss:  0.05498486  || Decoder Loss:  0.03802943 Validation Decoder Loss:  0.37851048
Encoder Loss:  0.052962285  || Decoder Loss:  0.037961394 Validation Decoder Loss:  0.34801728
Encoder Loss:  0.054453168  || Decoder Loss:  0.03823584 Validation Decoder Loss:  0.36392373
Encoder Loss:  0.049570818  || Decoder Loss:  0.03688159 Validation Decoder Loss:  0.31149966
Encoder Loss:  0.052852813  || Decoder Loss:  0.03736663 Validation Decoder Loss:  0.35036284
Encoder Loss:  0.05229459  || Decoder Loss:  0.03717219 Validation Decoder Loss:  0.3636014
Encoder Loss:  0.05356081  || Decoder Loss:  0.03753887 Validation Decoder Loss:  0.35566375
Encoder Loss:  0.049527537  || Decoder Loss:  0.036691636 Validation Decoder Loss:  0.36933303
Encoder Loss:  0.050721236  || Decoder Loss:  0.036826625 Validation Decoder Loss:  0.36157924
Encoder Loss:  0.05136992  || Decoder Loss:  0.036793232 Validation Decoder Loss:  0.34600705
Encoder Loss:  0.051600546  || Decoder Loss:  0.036771823 Validation Decoder Loss:  0.32945484
Encoder Loss:  0.052152503  || Decoder Loss:  0.036962718 Validation Decoder Loss:  0.31665063
Encoder Loss:  0.049035754  || Decoder Loss:  0.03651989 Validation Decoder Loss:  0.36291605
Encoder Loss:  0.04847882  || Decoder Loss:  0.036102954 Validation Decoder Loss:  0.31425032
Encoder Loss:  0.050640292  || Decoder Loss:  0.0366935 Validation Decoder Loss:  0.31652784
Encoder Loss:  0.04985147  || Decoder Loss:  0.03619807 Validation Decoder Loss:  0.35879967
Encoder Loss:  0.050646674  || Decoder Loss:  0.036532745 Validation Decoder Loss:  0.3725739
Encoder Loss:  0.047922384  || Decoder Loss:  0.03619823 Validation Decoder Loss:  0.33225805
Encoder Loss:  0.04786588  || Decoder Loss:  0.035722934 Validation Decoder Loss:  0.34171203
Encoder Loss:  0.04648067  || Decoder Loss:  0.036022674 Validation Decoder Loss:  0.3706389
Encoder Loss:  0.045058727  || Decoder Loss:  0.03561838 Validation Decoder Loss:  0.35889933
Encoder Loss:  0.045443453  || Decoder Loss:  0.03543672 Validation Decoder Loss:  0.3398172
Encoder Loss:  0.045887124  || Decoder Loss:  0.035484515 Validation Decoder Loss:  0.35871008
Encoder Loss:  0.048238624  || Decoder Loss:  0.035904087 Validation Decoder Loss:  0.36790484
Encoder Loss:  0.044975206  || Decoder Loss:  0.03561727 Validation Decoder Loss:  0.32642063
Encoder Loss:  0.044736404  || Decoder Loss:  0.035345424 Validation Decoder Loss:  0.35887522
Encoder Loss:  0.044760447  || Decoder Loss:  0.035285946 Validation Decoder Loss:  0.35249165
Encoder Loss:  0.044769753  || Decoder Loss:  0.035253514 Validation Decoder Loss:  0.3496489
Encoder Loss:  0.044948626  || Decoder Loss:  0.03530703 Validation Decoder Loss:  0.35561478
Encoder Loss:  0.04470657  || Decoder Loss:  0.03521595 Validation Decoder Loss:  0.34532863
Encoder Loss:  0.045160413  || Decoder Loss:  0.035267018 Validation Decoder Loss:  0.3521058
Encoder Loss:  0.044669833  || Decoder Loss:  0.035167344 Validation Decoder Loss:  0.3455324
Encoder Loss:  0.04479353  || Decoder Loss:  0.03524978 Validation Decoder Loss:  0.35455787
Encoder Loss:  0.044703193  || Decoder Loss:  0.03519584 Validation Decoder Loss:  0.34675613
Model: siamese_net_lr_0.3444056803209583 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34675616
Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_62 (Conv3DT (None, 110, 22, 20, 1)    659       
_________________________________________________________________
reshape_62 (Reshape)         (None, 2420, 20, 1)       0         
=================================================================
Total params: 659
Trainable params: 659
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_187"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_62 (Conv2D)           (None, 2420, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_188"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_62 (Conv2DT (None, 2607, 20, 1)       189       
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.335849  || Decoder Loss:  0.42659906 Validation Decoder Loss:  0.71504974
Encoder Loss:  0.20543261  || Decoder Loss:  0.50128585 Validation Decoder Loss:  0.95436
Encoder Loss:  0.19699337  || Decoder Loss:  0.52297354 Validation Decoder Loss:  1.0342836
Encoder Loss:  0.18884538  || Decoder Loss:  0.5292551 Validation Decoder Loss:  0.99062794
Encoder Loss:  0.19180688  || Decoder Loss:  0.5174398 Validation Decoder Loss:  0.9944557
Encoder Loss:  0.1869018  || Decoder Loss:  0.51312464 Validation Decoder Loss:  0.97128147
Encoder Loss:  0.18258286  || Decoder Loss:  0.5006938 Validation Decoder Loss:  0.9494636
Encoder Loss:  0.17067003  || Decoder Loss:  0.45491883 Validation Decoder Loss:  0.86606735
Encoder Loss:  0.13863188  || Decoder Loss:  0.3434012 Validation Decoder Loss:  0.53103775
Encoder Loss:  0.077086665  || Decoder Loss:  0.11386806 Validation Decoder Loss:  0.3845025
Encoder Loss:  0.055411085  || Decoder Loss:  0.040923532 Validation Decoder Loss:  0.3315684
Encoder Loss:  0.056588247  || Decoder Loss:  0.035181627 Validation Decoder Loss:  0.33370948
Encoder Loss:  0.06353494  || Decoder Loss:  0.04269653 Validation Decoder Loss:  0.4023949
Encoder Loss:  0.066995315  || Decoder Loss:  0.09391294 Validation Decoder Loss:  0.39661068
Encoder Loss:  0.053563133  || Decoder Loss:  0.04464786 Validation Decoder Loss:  0.3359306
Encoder Loss:  0.05206648  || Decoder Loss:  0.037834145 Validation Decoder Loss:  0.34356728
Encoder Loss:  0.05117871  || Decoder Loss:  0.040606078 Validation Decoder Loss:  0.34283864
Encoder Loss:  0.051776193  || Decoder Loss:  0.041266274 Validation Decoder Loss:  0.3448774
Encoder Loss:  0.057170462  || Decoder Loss:  0.04158582 Validation Decoder Loss:  0.31399733
Encoder Loss:  0.057280127  || Decoder Loss:  0.043720502 Validation Decoder Loss:  0.3556751
Encoder Loss:  0.054917842  || Decoder Loss:  0.04805103 Validation Decoder Loss:  0.35674572
Encoder Loss:  0.05195625  || Decoder Loss:  0.044324063 Validation Decoder Loss:  0.34537485
Encoder Loss:  0.050178565  || Decoder Loss:  0.04227526 Validation Decoder Loss:  0.34514573
Encoder Loss:  0.049469076  || Decoder Loss:  0.041058 Validation Decoder Loss:  0.34492862
Encoder Loss:  0.050769858  || Decoder Loss:  0.04051255 Validation Decoder Loss:  0.34291708
Encoder Loss:  0.05405837  || Decoder Loss:  0.041796904 Validation Decoder Loss:  0.34442252
Encoder Loss:  0.05666721  || Decoder Loss:  0.042861406 Validation Decoder Loss:  0.33357352
Encoder Loss:  0.051757194  || Decoder Loss:  0.04311523 Validation Decoder Loss:  0.35151103
Encoder Loss:  0.05235375  || Decoder Loss:  0.042107042 Validation Decoder Loss:  0.3520609
Encoder Loss:  0.050646372  || Decoder Loss:  0.041924063 Validation Decoder Loss:  0.34884828
Encoder Loss:  0.05296089  || Decoder Loss:  0.04170191 Validation Decoder Loss:  0.34298354
Encoder Loss:  0.053842414  || Decoder Loss:  0.042103484 Validation Decoder Loss:  0.34927884
Encoder Loss:  0.05312959  || Decoder Loss:  0.042432133 Validation Decoder Loss:  0.35779324
Encoder Loss:  0.053846046  || Decoder Loss:  0.0425905 Validation Decoder Loss:  0.35127982
Encoder Loss:  0.049639747  || Decoder Loss:  0.042111397 Validation Decoder Loss:  0.34782737
Encoder Loss:  0.0538004  || Decoder Loss:  0.041549686 Validation Decoder Loss:  0.33893657
Encoder Loss:  0.04989737  || Decoder Loss:  0.041052297 Validation Decoder Loss:  0.34843367
Encoder Loss:  0.050255414  || Decoder Loss:  0.040842537 Validation Decoder Loss:  0.34309176
Encoder Loss:  0.051858284  || Decoder Loss:  0.04113703 Validation Decoder Loss:  0.34358847
Encoder Loss:  0.05249957  || Decoder Loss:  0.040977944 Validation Decoder Loss:  0.34700727
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34700727
Model: "sequential_189"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_63 (Conv3DT (None, 344, 5, 20, 1)     219       
_________________________________________________________________
reshape_63 (Reshape)         (None, 1720, 20, 1)       0         
=================================================================
Total params: 219
Trainable params: 219
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_190"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_63 (Conv2D)           (None, 1720, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_191"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_63 (Conv2DT (None, 2607, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439186 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439186 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439186 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.36131823
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439186 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439186 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.36131817
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439188 Validation Decoder Loss:  0.3613182
Encoder Loss:  0.44666922  || Decoder Loss:  0.08439187 Validation Decoder Loss:  0.3613182
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3613182
Model: "sequential_192"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_64 (Conv3DT (None, 111, 20, 20, 1)    385       
_________________________________________________________________
reshape_64 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 385
Trainable params: 385
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_193"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_64 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_194"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_64 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.049498767  || Decoder Loss:  0.049498767 Validation Decoder Loss:  0.3496322
Encoder Loss:  0.048967086  || Decoder Loss:  0.048967086 Validation Decoder Loss:  0.35302866
Encoder Loss:  0.05440766  || Decoder Loss:  0.05440766 Validation Decoder Loss:  0.35635728
Encoder Loss:  0.05395292  || Decoder Loss:  0.05395292 Validation Decoder Loss:  0.35713145
Encoder Loss:  0.052878905  || Decoder Loss:  0.052878905 Validation Decoder Loss:  0.35700834
Encoder Loss:  0.05068866  || Decoder Loss:  0.05068866 Validation Decoder Loss:  0.35382453
Encoder Loss:  0.039818082  || Decoder Loss:  0.039818082 Validation Decoder Loss:  0.34594145
Encoder Loss:  0.03308719  || Decoder Loss:  0.03308719 Validation Decoder Loss:  0.34236717
Encoder Loss:  0.032868277  || Decoder Loss:  0.032868277 Validation Decoder Loss:  0.3425825
Encoder Loss:  0.032783087  || Decoder Loss:  0.032783087 Validation Decoder Loss:  0.34248692
Encoder Loss:  0.032716423  || Decoder Loss:  0.032716423 Validation Decoder Loss:  0.3424216
Encoder Loss:  0.032658767  || Decoder Loss:  0.032658767 Validation Decoder Loss:  0.34232536
Encoder Loss:  0.03260723  || Decoder Loss:  0.03260723 Validation Decoder Loss:  0.3421479
Encoder Loss:  0.03256229  || Decoder Loss:  0.03256229 Validation Decoder Loss:  0.34193897
Encoder Loss:  0.032524362  || Decoder Loss:  0.032524362 Validation Decoder Loss:  0.34151858
Encoder Loss:  0.03248922  || Decoder Loss:  0.03248922 Validation Decoder Loss:  0.3413337
Encoder Loss:  0.032470968  || Decoder Loss:  0.032470968 Validation Decoder Loss:  0.34146172
Encoder Loss:  0.032478187  || Decoder Loss:  0.032478187 Validation Decoder Loss:  0.34171146
Encoder Loss:  0.032492924  || Decoder Loss:  0.032492924 Validation Decoder Loss:  0.3423616
Encoder Loss:  0.032491144  || Decoder Loss:  0.032491144 Validation Decoder Loss:  0.342718
Encoder Loss:  0.03241311  || Decoder Loss:  0.03241311 Validation Decoder Loss:  0.3442676
Encoder Loss:  0.032270957  || Decoder Loss:  0.032270957 Validation Decoder Loss:  0.34369722
Encoder Loss:  0.03218005  || Decoder Loss:  0.03218005 Validation Decoder Loss:  0.34335935
Encoder Loss:  0.032115452  || Decoder Loss:  0.032115452 Validation Decoder Loss:  0.34339908
Encoder Loss:  0.032051813  || Decoder Loss:  0.032051813 Validation Decoder Loss:  0.3435381
Encoder Loss:  0.03199088  || Decoder Loss:  0.03199088 Validation Decoder Loss:  0.343221
Encoder Loss:  0.03194913  || Decoder Loss:  0.03194913 Validation Decoder Loss:  0.3418696
Encoder Loss:  0.04362949  || Decoder Loss:  0.04362949 Validation Decoder Loss:  0.3557589
Encoder Loss:  0.050475933  || Decoder Loss:  0.050475933 Validation Decoder Loss:  0.3522318
Encoder Loss:  0.035556406  || Decoder Loss:  0.035556406 Validation Decoder Loss:  0.3420012
Encoder Loss:  0.032264214  || Decoder Loss:  0.032264214 Validation Decoder Loss:  0.3424545
Encoder Loss:  0.032186385  || Decoder Loss:  0.032186385 Validation Decoder Loss:  0.342474
Encoder Loss:  0.032142278  || Decoder Loss:  0.032142278 Validation Decoder Loss:  0.3422928
Encoder Loss:  0.032106888  || Decoder Loss:  0.032106888 Validation Decoder Loss:  0.34202695
Encoder Loss:  0.032083888  || Decoder Loss:  0.032083888 Validation Decoder Loss:  0.34158945
Encoder Loss:  0.032067567  || Decoder Loss:  0.032067567 Validation Decoder Loss:  0.34111106
Encoder Loss:  0.032064732  || Decoder Loss:  0.032064732 Validation Decoder Loss:  0.3412197
Encoder Loss:  0.03211745  || Decoder Loss:  0.03211745 Validation Decoder Loss:  0.3410203
Encoder Loss:  0.032163847  || Decoder Loss:  0.032163847 Validation Decoder Loss:  0.34058273
Encoder Loss:  0.032238014  || Decoder Loss:  0.032238014 Validation Decoder Loss:  0.34056416
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34056416
Model: "sequential_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_65 (Conv3DT (None, 162, 10, 20, 1)    199       
_________________________________________________________________
reshape_65 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 199
Trainable params: 199
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_196"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_65 (Conv2D)           (None, 1620, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_197"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_65 (Conv2DT (None, 2607, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310488
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310488
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310494
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.3631049
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310488
Encoder Loss:  0.44677222  || Decoder Loss:  0.08863061 Validation Decoder Loss:  0.36310488
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36310494
Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_66 (Conv3DT (None, 217, 10, 20, 1)    925       
_________________________________________________________________
reshape_66 (Reshape)         (None, 2170, 20, 1)       0         
=================================================================
Total params: 925
Trainable params: 925
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_199"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 2170, 20, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_200"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_66 (Conv2DT (None, 2607, 20, 1)       439       
=================================================================
Total params: 439
Trainable params: 439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.06674276 Validation Decoder Loss:  0.3591619
Encoder Loss:  0.43510693  || Decoder Loss:  0.066742755 Validation Decoder Loss:  0.3591619
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3591619
Model: "sequential_201"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_67 (Conv3DT (None, 71, 20, 20, 1)     65        
_________________________________________________________________
reshape_67 (Reshape)         (None, 1420, 20, 1)       0         
=================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_202"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_67 (Conv2D)           (None, 1420, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_67 (Conv2DT (None, 2607, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.25469026  || Decoder Loss:  0.45970672 Validation Decoder Loss:  0.9354955
Encoder Loss:  0.15215695  || Decoder Loss:  0.4072759 Validation Decoder Loss:  0.35753503
Encoder Loss:  0.049379483  || Decoder Loss:  0.03364623 Validation Decoder Loss:  0.3371518
Encoder Loss:  0.049089976  || Decoder Loss:  0.036782686 Validation Decoder Loss:  0.339602
Encoder Loss:  0.047901  || Decoder Loss:  0.036556445 Validation Decoder Loss:  0.36133754
Encoder Loss:  0.057488173  || Decoder Loss:  0.060342144 Validation Decoder Loss:  0.33693254
Encoder Loss:  0.04862816  || Decoder Loss:  0.039160416 Validation Decoder Loss:  0.34082228
Encoder Loss:  0.04872875  || Decoder Loss:  0.03883382 Validation Decoder Loss:  0.33719972
Encoder Loss:  0.047728397  || Decoder Loss:  0.037736002 Validation Decoder Loss:  0.33558634
Encoder Loss:  0.048249796  || Decoder Loss:  0.038192898 Validation Decoder Loss:  0.33610827
Encoder Loss:  0.04778373  || Decoder Loss:  0.037640106 Validation Decoder Loss:  0.33648065
Encoder Loss:  0.052062344  || Decoder Loss:  0.03770019 Validation Decoder Loss:  0.33388945
Encoder Loss:  0.04659017  || Decoder Loss:  0.036567196 Validation Decoder Loss:  0.3349569
Encoder Loss:  0.04671092  || Decoder Loss:  0.0369274 Validation Decoder Loss:  0.32728714
Encoder Loss:  0.056910858  || Decoder Loss:  0.037232652 Validation Decoder Loss:  0.33548653
Encoder Loss:  0.046385225  || Decoder Loss:  0.036065225 Validation Decoder Loss:  0.33766735
Encoder Loss:  0.04705542  || Decoder Loss:  0.036249243 Validation Decoder Loss:  0.35035938
Encoder Loss:  0.049289666  || Decoder Loss:  0.037691716 Validation Decoder Loss:  0.33361965
Encoder Loss:  0.046766184  || Decoder Loss:  0.03646163 Validation Decoder Loss:  0.3344729
Encoder Loss:  0.046372276  || Decoder Loss:  0.035962734 Validation Decoder Loss:  0.33314234
Encoder Loss:  0.046907645  || Decoder Loss:  0.035843078 Validation Decoder Loss:  0.33118403
Encoder Loss:  0.04660611  || Decoder Loss:  0.035820708 Validation Decoder Loss:  0.33469653
Encoder Loss:  0.04630632  || Decoder Loss:  0.03569174 Validation Decoder Loss:  0.33432588
Encoder Loss:  0.046301138  || Decoder Loss:  0.035686053 Validation Decoder Loss:  0.33386517
Encoder Loss:  0.04834258  || Decoder Loss:  0.035559226 Validation Decoder Loss:  0.33486873
Encoder Loss:  0.0462459  || Decoder Loss:  0.035220675 Validation Decoder Loss:  0.3339399
Encoder Loss:  0.04633324  || Decoder Loss:  0.03535391 Validation Decoder Loss:  0.3363762
Encoder Loss:  0.04852889  || Decoder Loss:  0.0354209 Validation Decoder Loss:  0.33389953
Encoder Loss:  0.04599968  || Decoder Loss:  0.035029657 Validation Decoder Loss:  0.33286983
Encoder Loss:  0.047156226  || Decoder Loss:  0.035137184 Validation Decoder Loss:  0.33439547
Encoder Loss:  0.04602896  || Decoder Loss:  0.03504589 Validation Decoder Loss:  0.33407015
Encoder Loss:  0.046422016  || Decoder Loss:  0.03531444 Validation Decoder Loss:  0.33395588
Encoder Loss:  0.045906555  || Decoder Loss:  0.035072893 Validation Decoder Loss:  0.33152682
Encoder Loss:  0.05028185  || Decoder Loss:  0.035351384 Validation Decoder Loss:  0.3347714
Encoder Loss:  0.045805823  || Decoder Loss:  0.034654997 Validation Decoder Loss:  0.33936295
Encoder Loss:  0.04826601  || Decoder Loss:  0.040337313 Validation Decoder Loss:  0.33200794
Encoder Loss:  0.046160623  || Decoder Loss:  0.035749637 Validation Decoder Loss:  0.33458415
Encoder Loss:  0.04623977  || Decoder Loss:  0.035636134 Validation Decoder Loss:  0.33254224
Encoder Loss:  0.04842497  || Decoder Loss:  0.035835788 Validation Decoder Loss:  0.33529884
Encoder Loss:  0.045928326  || Decoder Loss:  0.03468863 Validation Decoder Loss:  0.33805075
Model: siamese_net_lr_0.15183618189445094 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33805072
Model: "sequential_204"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_68 (Conv3DT (None, 284, 5, 20, 1)     96        
_________________________________________________________________
reshape_68 (Reshape)         (None, 1420, 20, 1)       0         
=================================================================
Total params: 96
Trainable params: 96
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_205"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_68 (Conv2D)           (None, 1420, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_206"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_68 (Conv2DT (None, 2607, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2627683  || Decoder Loss:  0.43130562 Validation Decoder Loss:  0.8016889
Encoder Loss:  0.1738098  || Decoder Loss:  0.43886143 Validation Decoder Loss:  1.0690475
Encoder Loss:  0.13152744  || Decoder Loss:  0.43875062 Validation Decoder Loss:  1.1600025
Encoder Loss:  0.12672353  || Decoder Loss:  0.3984566 Validation Decoder Loss:  0.72012055
Encoder Loss:  0.0982306  || Decoder Loss:  0.16223866 Validation Decoder Loss:  0.38207927
Encoder Loss:  0.08653048  || Decoder Loss:  0.040433984 Validation Decoder Loss:  0.344514
Encoder Loss:  0.08742039  || Decoder Loss:  0.042828254 Validation Decoder Loss:  0.400596
Encoder Loss:  0.08014443  || Decoder Loss:  0.043681145 Validation Decoder Loss:  0.3576948
Encoder Loss:  0.067340404  || Decoder Loss:  0.03732645 Validation Decoder Loss:  0.35033256
Encoder Loss:  0.061287507  || Decoder Loss:  0.03648812 Validation Decoder Loss:  0.35461348
Encoder Loss:  0.06063904  || Decoder Loss:  0.039032847 Validation Decoder Loss:  0.35405028
Encoder Loss:  0.056824457  || Decoder Loss:  0.03879801 Validation Decoder Loss:  0.35638073
Encoder Loss:  0.054391928  || Decoder Loss:  0.03744643 Validation Decoder Loss:  0.3411479
Encoder Loss:  0.05485358  || Decoder Loss:  0.04149529 Validation Decoder Loss:  0.34330457
Encoder Loss:  0.07087174  || Decoder Loss:  0.053329803 Validation Decoder Loss:  0.35039222
Encoder Loss:  0.056541786  || Decoder Loss:  0.04158233 Validation Decoder Loss:  0.345519
Encoder Loss:  0.0620082  || Decoder Loss:  0.039652377 Validation Decoder Loss:  0.33723116
Encoder Loss:  0.0594794  || Decoder Loss:  0.039731737 Validation Decoder Loss:  0.34180218
Encoder Loss:  0.060175605  || Decoder Loss:  0.041026115 Validation Decoder Loss:  0.35659686
Encoder Loss:  0.062514566  || Decoder Loss:  0.041636534 Validation Decoder Loss:  0.3421954
Encoder Loss:  0.05780602  || Decoder Loss:  0.040486373 Validation Decoder Loss:  0.3392492
Encoder Loss:  0.054844607  || Decoder Loss:  0.039901406 Validation Decoder Loss:  0.33632916
Encoder Loss:  0.059134837  || Decoder Loss:  0.039390136 Validation Decoder Loss:  0.34751254
Encoder Loss:  0.05719798  || Decoder Loss:  0.03987642 Validation Decoder Loss:  0.34842724
Encoder Loss:  0.05396877  || Decoder Loss:  0.039913505 Validation Decoder Loss:  0.34773672
Encoder Loss:  0.05660732  || Decoder Loss:  0.037992608 Validation Decoder Loss:  0.3420928
Encoder Loss:  0.05429321  || Decoder Loss:  0.03772656 Validation Decoder Loss:  0.34802678
Encoder Loss:  0.05419731  || Decoder Loss:  0.03859464 Validation Decoder Loss:  0.3473102
Encoder Loss:  0.05777299  || Decoder Loss:  0.038836077 Validation Decoder Loss:  0.3413915
Encoder Loss:  0.052866448  || Decoder Loss:  0.03834019 Validation Decoder Loss:  0.3371174
Encoder Loss:  0.053948678  || Decoder Loss:  0.03669973 Validation Decoder Loss:  0.3498441
Encoder Loss:  0.05694791  || Decoder Loss:  0.037906386 Validation Decoder Loss:  0.35011166
Encoder Loss:  0.053994264  || Decoder Loss:  0.037747037 Validation Decoder Loss:  0.34781334
Encoder Loss:  0.057265963  || Decoder Loss:  0.037637245 Validation Decoder Loss:  0.34654456
Encoder Loss:  0.052609053  || Decoder Loss:  0.038581844 Validation Decoder Loss:  0.3447402
Encoder Loss:  0.049898215  || Decoder Loss:  0.03635969 Validation Decoder Loss:  0.34633845
Encoder Loss:  0.049037594  || Decoder Loss:  0.03774452 Validation Decoder Loss:  0.34617367
Encoder Loss:  0.048696842  || Decoder Loss:  0.036501266 Validation Decoder Loss:  0.34437025
Encoder Loss:  0.048667837  || Decoder Loss:  0.036395907 Validation Decoder Loss:  0.34287563
Encoder Loss:  0.048598576  || Decoder Loss:  0.035854995 Validation Decoder Loss:  0.34544986
Model: siamese_net_lr_0.48272843204135896 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34544986
Model: "sequential_207"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_69 (Conv3DT (None, 142, 10, 20, 1)    159       
_________________________________________________________________
reshape_69 (Reshape)         (None, 1420, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_208"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_69 (Conv2D)           (None, 1420, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_209"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_69 (Conv2DT (None, 2607, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28844646  || Decoder Loss:  0.27342775 Validation Decoder Loss:  0.9521164
Encoder Loss:  0.40409198  || Decoder Loss:  0.44990766 Validation Decoder Loss:  1.1818987
Encoder Loss:  0.41881454  || Decoder Loss:  0.46641853 Validation Decoder Loss:  1.2120285
Encoder Loss:  0.41512185  || Decoder Loss:  0.46318617 Validation Decoder Loss:  1.2004962
Encoder Loss:  0.41284108  || Decoder Loss:  0.46076104 Validation Decoder Loss:  1.1592548
Encoder Loss:  0.40045998  || Decoder Loss:  0.44692543 Validation Decoder Loss:  1.1916459
Encoder Loss:  0.4175587  || Decoder Loss:  0.4684193 Validation Decoder Loss:  1.1443052
Encoder Loss:  0.40238494  || Decoder Loss:  0.45271876 Validation Decoder Loss:  1.1492374
Encoder Loss:  0.3810562  || Decoder Loss:  0.4296483 Validation Decoder Loss:  1.011801
Encoder Loss:  0.38389683  || Decoder Loss:  0.43359646 Validation Decoder Loss:  0.98326164
Encoder Loss:  0.32833266  || Decoder Loss:  0.3691513 Validation Decoder Loss:  0.8664849
Encoder Loss:  0.23452078  || Decoder Loss:  0.26181138 Validation Decoder Loss:  0.49123502
Encoder Loss:  0.05393342  || Decoder Loss:  0.053839494 Validation Decoder Loss:  0.36360517
Encoder Loss:  0.035289727  || Decoder Loss:  0.03276862 Validation Decoder Loss:  0.3664228
Encoder Loss:  0.034244608  || Decoder Loss:  0.03110591 Validation Decoder Loss:  0.3522738
Encoder Loss:  0.033161532  || Decoder Loss:  0.030346444 Validation Decoder Loss:  0.3730084
Encoder Loss:  0.032829463  || Decoder Loss:  0.030098671 Validation Decoder Loss:  0.35421556
Encoder Loss:  0.032880656  || Decoder Loss:  0.029878972 Validation Decoder Loss:  0.3620721
Encoder Loss:  0.033005044  || Decoder Loss:  0.030067673 Validation Decoder Loss:  0.3576702
Encoder Loss:  0.033275537  || Decoder Loss:  0.03014361 Validation Decoder Loss:  0.35432827
Encoder Loss:  0.032905746  || Decoder Loss:  0.03003365 Validation Decoder Loss:  0.35071522
Encoder Loss:  0.03236506  || Decoder Loss:  0.029492881 Validation Decoder Loss:  0.3617844
Encoder Loss:  0.033028647  || Decoder Loss:  0.030252697 Validation Decoder Loss:  0.33787328
Encoder Loss:  0.032976534  || Decoder Loss:  0.030164313 Validation Decoder Loss:  0.3365653
Encoder Loss:  0.033545148  || Decoder Loss:  0.030358493 Validation Decoder Loss:  0.33820623
Encoder Loss:  0.03332617  || Decoder Loss:  0.030272432 Validation Decoder Loss:  0.3373025
Encoder Loss:  0.033008  || Decoder Loss:  0.03013413 Validation Decoder Loss:  0.37094033
Encoder Loss:  0.03349163  || Decoder Loss:  0.030681407 Validation Decoder Loss:  0.33528924
Encoder Loss:  0.032902814  || Decoder Loss:  0.030045798 Validation Decoder Loss:  0.34566632
Encoder Loss:  0.03299144  || Decoder Loss:  0.03013066 Validation Decoder Loss:  0.33890334
Encoder Loss:  0.033332758  || Decoder Loss:  0.030558078 Validation Decoder Loss:  0.3524731
Encoder Loss:  0.032998413  || Decoder Loss:  0.030177262 Validation Decoder Loss:  0.3629548
Encoder Loss:  0.033345323  || Decoder Loss:  0.030620975 Validation Decoder Loss:  0.3407541
Encoder Loss:  0.033073813  || Decoder Loss:  0.030411592 Validation Decoder Loss:  0.34608537
Encoder Loss:  0.033215605  || Decoder Loss:  0.030507358 Validation Decoder Loss:  0.33386075
Encoder Loss:  0.033872373  || Decoder Loss:  0.031154422 Validation Decoder Loss:  0.33927128
Encoder Loss:  0.033131704  || Decoder Loss:  0.03046424 Validation Decoder Loss:  0.35006547
Encoder Loss:  0.03317715  || Decoder Loss:  0.030483602 Validation Decoder Loss:  0.33663496
Encoder Loss:  0.034000862  || Decoder Loss:  0.03100597 Validation Decoder Loss:  0.33936232
Encoder Loss:  0.033475254  || Decoder Loss:  0.030786032 Validation Decoder Loss:  0.3591989
Model: siamese_net_lr_0.8050366125993561 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3591989
Model: "sequential_210"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_70 (Conv3DT (None, 71, 20, 20, 1)     129       
_________________________________________________________________
reshape_70 (Reshape)         (None, 1420, 20, 1)       0         
=================================================================
Total params: 129
Trainable params: 129
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_211"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_70 (Conv2D)           (None, 1420, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_212"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_70 (Conv2DT (None, 2607, 20, 1)       1189      
=================================================================
Total params: 1,189
Trainable params: 1,189
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36835578  || Decoder Loss:  0.39223918 Validation Decoder Loss:  1.5564535
Encoder Loss:  0.21084954  || Decoder Loss:  0.5048296 Validation Decoder Loss:  0.86175025
Encoder Loss:  0.15506423  || Decoder Loss:  0.46681908 Validation Decoder Loss:  0.5831963
Encoder Loss:  0.1469911  || Decoder Loss:  0.44882488 Validation Decoder Loss:  0.6165802
Encoder Loss:  0.14333664  || Decoder Loss:  0.44475484 Validation Decoder Loss:  0.7186421
Encoder Loss:  0.13322711  || Decoder Loss:  0.42468536 Validation Decoder Loss:  0.5810665
Encoder Loss:  0.13227631  || Decoder Loss:  0.40481815 Validation Decoder Loss:  0.46517283
Encoder Loss:  0.13044469  || Decoder Loss:  0.3855171 Validation Decoder Loss:  0.70613956
Encoder Loss:  0.13614595  || Decoder Loss:  0.42556602 Validation Decoder Loss:  0.93178105
Encoder Loss:  0.098156646  || Decoder Loss:  0.27338123 Validation Decoder Loss:  0.7682041
Encoder Loss:  0.07561033  || Decoder Loss:  0.12900424 Validation Decoder Loss:  0.4061514
Encoder Loss:  0.067425855  || Decoder Loss:  0.073928855 Validation Decoder Loss:  0.3920809
Encoder Loss:  0.0597013  || Decoder Loss:  0.046735838 Validation Decoder Loss:  0.3501015
Encoder Loss:  0.068277985  || Decoder Loss:  0.038359247 Validation Decoder Loss:  0.33558518
Encoder Loss:  0.05461614  || Decoder Loss:  0.036785785 Validation Decoder Loss:  0.34604597
Encoder Loss:  0.05985259  || Decoder Loss:  0.036993165 Validation Decoder Loss:  0.34723648
Encoder Loss:  0.05732761  || Decoder Loss:  0.037594195 Validation Decoder Loss:  0.3393906
Encoder Loss:  0.062883094  || Decoder Loss:  0.035008863 Validation Decoder Loss:  0.3398453
Encoder Loss:  0.05858886  || Decoder Loss:  0.037749365 Validation Decoder Loss:  0.35885677
Encoder Loss:  0.05385024  || Decoder Loss:  0.040955067 Validation Decoder Loss:  0.34738684
Encoder Loss:  0.05490692  || Decoder Loss:  0.03787802 Validation Decoder Loss:  0.34766287
Encoder Loss:  0.06107153  || Decoder Loss:  0.03958285 Validation Decoder Loss:  0.35290065
Encoder Loss:  0.0533171  || Decoder Loss:  0.038297445 Validation Decoder Loss:  0.33949897
Encoder Loss:  0.051835123  || Decoder Loss:  0.03542845 Validation Decoder Loss:  0.3364141
Encoder Loss:  0.05536245  || Decoder Loss:  0.034218673 Validation Decoder Loss:  0.34075725
Encoder Loss:  0.054591898  || Decoder Loss:  0.03717248 Validation Decoder Loss:  0.33979172
Encoder Loss:  0.05819739  || Decoder Loss:  0.037348025 Validation Decoder Loss:  0.3353845
Encoder Loss:  0.05344038  || Decoder Loss:  0.035534028 Validation Decoder Loss:  0.33865413
Encoder Loss:  0.05118617  || Decoder Loss:  0.035844028 Validation Decoder Loss:  0.34781307
Encoder Loss:  0.056198444  || Decoder Loss:  0.038355723 Validation Decoder Loss:  0.3433566
Encoder Loss:  0.063532054  || Decoder Loss:  0.037306856 Validation Decoder Loss:  0.3400634
Encoder Loss:  0.05548268  || Decoder Loss:  0.037206784 Validation Decoder Loss:  0.34422368
Encoder Loss:  0.052530207  || Decoder Loss:  0.03668307 Validation Decoder Loss:  0.351803
Encoder Loss:  0.05356032  || Decoder Loss:  0.0383705 Validation Decoder Loss:  0.3397406
Encoder Loss:  0.052250553  || Decoder Loss:  0.03710113 Validation Decoder Loss:  0.34085107
Encoder Loss:  0.051400997  || Decoder Loss:  0.036394764 Validation Decoder Loss:  0.33521706
Encoder Loss:  0.051064417  || Decoder Loss:  0.033357438 Validation Decoder Loss:  0.33660674
Encoder Loss:  0.056829397  || Decoder Loss:  0.03577897 Validation Decoder Loss:  0.33578372
Encoder Loss:  0.051191773  || Decoder Loss:  0.033132244 Validation Decoder Loss:  0.34873444
Encoder Loss:  0.051600717  || Decoder Loss:  0.037608102 Validation Decoder Loss:  0.34525433
Model: siamese_net_lr_0.41375434921518944 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34525433
Model: "sequential_213"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_71 (Conv3DT (None, 147, 10, 20, 1)    169       
_________________________________________________________________
reshape_71 (Reshape)         (None, 1470, 20, 1)       0         
=================================================================
Total params: 169
Trainable params: 169
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_214"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_71 (Conv2D)           (None, 1470, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_215"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_71 (Conv2DT (None, 2607, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.44697303  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287381 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.44697312  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.44697312  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.44697303  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287381 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.092873834 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.092873834 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287381 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.4469731  || Decoder Loss:  0.092873834 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.44697303  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.36663446
Encoder Loss:  0.4469731  || Decoder Loss:  0.09287382 Validation Decoder Loss:  0.3666345
Encoder Loss:  0.4469731  || Decoder Loss:  0.092873834 Validation Decoder Loss:  0.3666345
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3666345
Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_72 (Conv3DT (None, 79, 30, 20, 1)     161       
_________________________________________________________________
reshape_72 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 161
Trainable params: 161
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_217"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_72 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_218"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_72 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956926 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.35050592
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.35050592
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956937 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956933 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956937 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.042956937 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Encoder Loss:  0.4484828  || Decoder Loss:  0.04295693 Validation Decoder Loss:  0.3505059
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3505059
Model: "sequential_219"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_73 (Conv3DT (None, 122, 10, 20, 1)    355       
_________________________________________________________________
reshape_73 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 355
Trainable params: 355
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_220"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_73 (Conv2D)           (None, 1220, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_221"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_73 (Conv2DT (None, 2607, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618765  || Decoder Loss:  0.09618765 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618765  || Decoder Loss:  0.09618765 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.37040943
Encoder Loss:  0.09618766  || Decoder Loss:  0.09618766 Validation Decoder Loss:  0.3704094
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37040943
Model: "sequential_222"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_74 (Conv3DT (None, 194, 5, 20, 1)     132       
_________________________________________________________________
reshape_74 (Reshape)         (None, 970, 20, 1)        0         
=================================================================
Total params: 132
Trainable params: 132
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_223"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_74 (Conv2D)           (None, 970, 20, 1)        670       
=================================================================
Total params: 670
Trainable params: 670
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_224"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_74 (Conv2DT (None, 2607, 20, 1)       670       
=================================================================
Total params: 670
Trainable params: 670
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190744  || Decoder Loss:  0.07190744 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190744  || Decoder Loss:  0.07190744 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190742  || Decoder Loss:  0.07190742 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.36132213
Encoder Loss:  0.07190743  || Decoder Loss:  0.07190743 Validation Decoder Loss:  0.3613221
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36132213
Model: "sequential_225"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_75 (Conv3DT (None, 95, 26, 20, 1)     449       
_________________________________________________________________
reshape_75 (Reshape)         (None, 2470, 20, 1)       0         
=================================================================
Total params: 449
Trainable params: 449
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_226"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_75 (Conv2D)           (None, 2470, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_227"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_75 (Conv2DT (None, 2607, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3141787  || Decoder Loss:  0.07855228 Validation Decoder Loss:  0.33503395
Encoder Loss:  0.31207085  || Decoder Loss:  0.040983688 Validation Decoder Loss:  0.33264017
Encoder Loss:  0.310639  || Decoder Loss:  0.042802878 Validation Decoder Loss:  0.32988107
Encoder Loss:  0.30739167  || Decoder Loss:  0.04559241 Validation Decoder Loss:  0.3267449
Encoder Loss:  0.29374844  || Decoder Loss:  0.050050613 Validation Decoder Loss:  0.32002655
Encoder Loss:  0.2878889  || Decoder Loss:  0.46865478 Validation Decoder Loss:  0.827148
Encoder Loss:  0.19501854  || Decoder Loss:  0.46512622 Validation Decoder Loss:  0.93809944
Encoder Loss:  0.19527408  || Decoder Loss:  0.48382074 Validation Decoder Loss:  0.6112718
Encoder Loss:  0.18616474  || Decoder Loss:  0.4568306 Validation Decoder Loss:  0.88080835
Encoder Loss:  0.18601765  || Decoder Loss:  0.45637426 Validation Decoder Loss:  0.9085476
Encoder Loss:  0.18965396  || Decoder Loss:  0.46454394 Validation Decoder Loss:  0.8644099
Encoder Loss:  0.16814312  || Decoder Loss:  0.4000669 Validation Decoder Loss:  0.88000786
Encoder Loss:  0.18566234  || Decoder Loss:  0.43881893 Validation Decoder Loss:  0.9733112
Encoder Loss:  0.19966282  || Decoder Loss:  0.4852687 Validation Decoder Loss:  0.97651523
Encoder Loss:  0.19758667  || Decoder Loss:  0.48530838 Validation Decoder Loss:  0.9748768
Encoder Loss:  0.19416516  || Decoder Loss:  0.48308122 Validation Decoder Loss:  0.9698343
Encoder Loss:  0.19344066  || Decoder Loss:  0.479189 Validation Decoder Loss:  0.96076155
Encoder Loss:  0.19201376  || Decoder Loss:  0.46715283 Validation Decoder Loss:  0.90624
Encoder Loss:  0.15665652  || Decoder Loss:  0.36419633 Validation Decoder Loss:  0.9300655
Encoder Loss:  0.15831289  || Decoder Loss:  0.3715888 Validation Decoder Loss:  0.49226764
Encoder Loss:  0.12275741  || Decoder Loss:  0.2641959 Validation Decoder Loss:  0.75216365
Encoder Loss:  0.12454039  || Decoder Loss:  0.26899332 Validation Decoder Loss:  0.73180664
Encoder Loss:  0.08616051  || Decoder Loss:  0.14901215 Validation Decoder Loss:  0.45010322
Encoder Loss:  0.067268655  || Decoder Loss:  0.0966206 Validation Decoder Loss:  0.35333392
Encoder Loss:  0.05440382  || Decoder Loss:  0.05729367 Validation Decoder Loss:  0.3397012
Encoder Loss:  0.048455432  || Decoder Loss:  0.037865814 Validation Decoder Loss:  0.3416766
Encoder Loss:  0.048249155  || Decoder Loss:  0.037796296 Validation Decoder Loss:  0.3510846
Encoder Loss:  0.05211047  || Decoder Loss:  0.041458476 Validation Decoder Loss:  0.34079033
Encoder Loss:  0.050528675  || Decoder Loss:  0.038267255 Validation Decoder Loss:  0.3462184
Encoder Loss:  0.05038234  || Decoder Loss:  0.040714882 Validation Decoder Loss:  0.34378442
Encoder Loss:  0.048685655  || Decoder Loss:  0.038572222 Validation Decoder Loss:  0.35162905
Encoder Loss:  0.0519684  || Decoder Loss:  0.042374812 Validation Decoder Loss:  0.3492595
Encoder Loss:  0.050974652  || Decoder Loss:  0.040784683 Validation Decoder Loss:  0.33631733
Encoder Loss:  0.049024887  || Decoder Loss:  0.037282895 Validation Decoder Loss:  0.34362203
Encoder Loss:  0.048239112  || Decoder Loss:  0.038698673 Validation Decoder Loss:  0.34724438
Encoder Loss:  0.04885444  || Decoder Loss:  0.041280966 Validation Decoder Loss:  0.33960128
Encoder Loss:  0.049316477  || Decoder Loss:  0.038445078 Validation Decoder Loss:  0.34712768
Encoder Loss:  0.053322174  || Decoder Loss:  0.040103383 Validation Decoder Loss:  0.3455351
Encoder Loss:  0.048092876  || Decoder Loss:  0.03974247 Validation Decoder Loss:  0.3421216
Encoder Loss:  0.049851183  || Decoder Loss:  0.038818344 Validation Decoder Loss:  0.33807427
Model: siamese_net_lr_0.8692939193230352 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33807427
Model: "sequential_228"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_76 (Conv3DT (None, 237, 10, 20, 1)    97        
_________________________________________________________________
reshape_76 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_229"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_76 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_230"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_76 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5857684  || Decoder Loss:  0.624992 Validation Decoder Loss:  0.35895866
Encoder Loss:  0.12498286  || Decoder Loss:  0.06757282 Validation Decoder Loss:  0.6969042
Encoder Loss:  0.43539578  || Decoder Loss:  0.48527282 Validation Decoder Loss:  0.61842036
Encoder Loss:  0.37352246  || Decoder Loss:  0.42361766 Validation Decoder Loss:  1.1639637
Encoder Loss:  0.40374887  || Decoder Loss:  0.45969754 Validation Decoder Loss:  1.1463946
Encoder Loss:  0.37342304  || Decoder Loss:  0.42354664 Validation Decoder Loss:  0.7151904
Encoder Loss:  0.23671703  || Decoder Loss:  0.26086372 Validation Decoder Loss:  0.63817036
Encoder Loss:  0.08627078  || Decoder Loss:  0.08011666 Validation Decoder Loss:  0.34243315
Encoder Loss:  0.051591735  || Decoder Loss:  0.037849218 Validation Decoder Loss:  0.33037922
Encoder Loss:  0.04784375  || Decoder Loss:  0.03482946 Validation Decoder Loss:  0.3295251
Encoder Loss:  0.04796118  || Decoder Loss:  0.03452259 Validation Decoder Loss:  0.3291723
Encoder Loss:  0.04769362  || Decoder Loss:  0.0344598 Validation Decoder Loss:  0.32899064
Encoder Loss:  0.049512297  || Decoder Loss:  0.034428068 Validation Decoder Loss:  0.32905585
Encoder Loss:  0.04626064  || Decoder Loss:  0.03443117 Validation Decoder Loss:  0.32841396
Encoder Loss:  0.04742641  || Decoder Loss:  0.034455046 Validation Decoder Loss:  0.32865977
Encoder Loss:  0.04628771  || Decoder Loss:  0.03532649 Validation Decoder Loss:  0.32957208
Encoder Loss:  0.04809369  || Decoder Loss:  0.037363578 Validation Decoder Loss:  0.3344298
Encoder Loss:  0.05172624  || Decoder Loss:  0.04190979 Validation Decoder Loss:  0.33532318
Encoder Loss:  0.050594147  || Decoder Loss:  0.04132371 Validation Decoder Loss:  0.33168048
Encoder Loss:  0.04557983  || Decoder Loss:  0.035458468 Validation Decoder Loss:  0.32645866
Encoder Loss:  0.04461321  || Decoder Loss:  0.035037912 Validation Decoder Loss:  0.32763582
Encoder Loss:  0.0437432  || Decoder Loss:  0.034442525 Validation Decoder Loss:  0.3284074
Encoder Loss:  0.043360453  || Decoder Loss:  0.034403406 Validation Decoder Loss:  0.32860112
Encoder Loss:  0.043011222  || Decoder Loss:  0.03439444 Validation Decoder Loss:  0.32888997
Encoder Loss:  0.042603392  || Decoder Loss:  0.034391686 Validation Decoder Loss:  0.32882422
Encoder Loss:  0.042430688  || Decoder Loss:  0.034441877 Validation Decoder Loss:  0.32856017
Encoder Loss:  0.042339057  || Decoder Loss:  0.034525715 Validation Decoder Loss:  0.33059347
Encoder Loss:  0.042589698  || Decoder Loss:  0.035468422 Validation Decoder Loss:  0.33099824
Encoder Loss:  0.04501222  || Decoder Loss:  0.03854325 Validation Decoder Loss:  0.3376116
Encoder Loss:  0.046850618  || Decoder Loss:  0.041218232 Validation Decoder Loss:  0.32793516
Encoder Loss:  0.043697614  || Decoder Loss:  0.03774063 Validation Decoder Loss:  0.33632937
Encoder Loss:  0.04356171  || Decoder Loss:  0.037733916 Validation Decoder Loss:  0.3356859
Encoder Loss:  0.043438803  || Decoder Loss:  0.03786917 Validation Decoder Loss:  0.33358136
Encoder Loss:  0.042056836  || Decoder Loss:  0.03652245 Validation Decoder Loss:  0.3281986
Encoder Loss:  0.04206519  || Decoder Loss:  0.03684151 Validation Decoder Loss:  0.32959992
Encoder Loss:  0.042431373  || Decoder Loss:  0.037238017 Validation Decoder Loss:  0.33297074
Encoder Loss:  0.04194988  || Decoder Loss:  0.037080865 Validation Decoder Loss:  0.3309099
Encoder Loss:  0.042324062  || Decoder Loss:  0.037591536 Validation Decoder Loss:  0.34170175
Encoder Loss:  0.04322476  || Decoder Loss:  0.03908179 Validation Decoder Loss:  0.3312239
Encoder Loss:  0.04242055  || Decoder Loss:  0.038116068 Validation Decoder Loss:  0.3284527
Model: siamese_net_lr_0.5365748527980966 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32845274
Model: "sequential_231"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_77 (Conv3DT (None, 220, 6, 20, 1)     63        
_________________________________________________________________
reshape_77 (Reshape)         (None, 1320, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_232"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_77 (Conv2D)           (None, 1320, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_233"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_77 (Conv2DT (None, 2607, 20, 1)       1289      
=================================================================
Total params: 1,289
Trainable params: 1,289
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.053100776  || Decoder Loss:  0.050704684 Validation Decoder Loss:  0.3456197
Encoder Loss:  0.033873104  || Decoder Loss:  0.031366765 Validation Decoder Loss:  0.33970183
Encoder Loss:  0.5120797  || Decoder Loss:  0.5130959 Validation Decoder Loss:  1.4766855
Encoder Loss:  0.5056595  || Decoder Loss:  0.50803053 Validation Decoder Loss:  1.016417
Encoder Loss:  0.5217821  || Decoder Loss:  0.5245747 Validation Decoder Loss:  0.95042187
Encoder Loss:  0.49564135  || Decoder Loss:  0.49828106 Validation Decoder Loss:  1.0644302
Encoder Loss:  0.49924713  || Decoder Loss:  0.50189984 Validation Decoder Loss:  0.91339767
Encoder Loss:  0.49735805  || Decoder Loss:  0.4999995 Validation Decoder Loss:  1.1384981
Encoder Loss:  0.50491923  || Decoder Loss:  0.50753057 Validation Decoder Loss:  0.9963368
Encoder Loss:  0.49678814  || Decoder Loss:  0.49941728 Validation Decoder Loss:  0.9363129
Encoder Loss:  0.49915478  || Decoder Loss:  0.50180054 Validation Decoder Loss:  1.1007345
Encoder Loss:  0.4970645  || Decoder Loss:  0.4996738 Validation Decoder Loss:  0.95126814
Encoder Loss:  0.4888603  || Decoder Loss:  0.49148074 Validation Decoder Loss:  1.042123
Encoder Loss:  0.4907869  || Decoder Loss:  0.4933755 Validation Decoder Loss:  0.9910731
Encoder Loss:  0.47611636  || Decoder Loss:  0.47863826 Validation Decoder Loss:  1.2517374
Encoder Loss:  0.49095798  || Decoder Loss:  0.49353004 Validation Decoder Loss:  1.0756407
Encoder Loss:  0.46723568  || Decoder Loss:  0.46970943 Validation Decoder Loss:  0.98316824
Encoder Loss:  0.44859946  || Decoder Loss:  0.45096952 Validation Decoder Loss:  0.84848636
Encoder Loss:  0.43523273  || Decoder Loss:  0.43751353 Validation Decoder Loss:  1.0579547
Encoder Loss:  0.30815026  || Decoder Loss:  0.3096884 Validation Decoder Loss:  0.74485207
Encoder Loss:  0.11563246  || Decoder Loss:  0.11599411 Validation Decoder Loss:  0.45214385
Encoder Loss:  0.06306772  || Decoder Loss:  0.06309275 Validation Decoder Loss:  0.38447297
Encoder Loss:  0.047438726  || Decoder Loss:  0.047386207 Validation Decoder Loss:  0.3548712
Encoder Loss:  0.043441154  || Decoder Loss:  0.0433517 Validation Decoder Loss:  0.35999742
Encoder Loss:  0.036742043  || Decoder Loss:  0.03662393 Validation Decoder Loss:  0.34573033
Encoder Loss:  0.036765918  || Decoder Loss:  0.036641154 Validation Decoder Loss:  0.35353985
Encoder Loss:  0.035343397  || Decoder Loss:  0.035198115 Validation Decoder Loss:  0.34898943
Encoder Loss:  0.035900705  || Decoder Loss:  0.035743527 Validation Decoder Loss:  0.34707907
Encoder Loss:  0.035192158  || Decoder Loss:  0.035053343 Validation Decoder Loss:  0.349158
Encoder Loss:  0.035188064  || Decoder Loss:  0.03503193 Validation Decoder Loss:  0.34451243
Encoder Loss:  0.03486838  || Decoder Loss:  0.03471867 Validation Decoder Loss:  0.34699404
Encoder Loss:  0.03464397  || Decoder Loss:  0.03451889 Validation Decoder Loss:  0.3465361
Encoder Loss:  0.034797266  || Decoder Loss:  0.034662493 Validation Decoder Loss:  0.34437656
Encoder Loss:  0.034633588  || Decoder Loss:  0.034476414 Validation Decoder Loss:  0.3468235
Encoder Loss:  0.034492776  || Decoder Loss:  0.034337386 Validation Decoder Loss:  0.34516418
Encoder Loss:  0.033738643  || Decoder Loss:  0.033616055 Validation Decoder Loss:  0.34043556
Encoder Loss:  0.034174945  || Decoder Loss:  0.034028754 Validation Decoder Loss:  0.35310787
Encoder Loss:  0.035070915  || Decoder Loss:  0.03493729 Validation Decoder Loss:  0.35069588
Encoder Loss:  0.03422175  || Decoder Loss:  0.03406685 Validation Decoder Loss:  0.3445732
Encoder Loss:  0.033449564  || Decoder Loss:  0.033323776 Validation Decoder Loss:  0.34248435
Model: siamese_net_lr_0.9362829157816581 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34248435
Model: "sequential_234"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_78 (Conv3DT (None, 65, 38, 20, 1)     29        
_________________________________________________________________
reshape_78 (Reshape)         (None, 2470, 20, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_235"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_78 (Conv2D)           (None, 2470, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_236"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_78 (Conv2DT (None, 2607, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43541047  || Decoder Loss:  0.11653811 Validation Decoder Loss:  0.34250855
Encoder Loss:  0.44756508  || Decoder Loss:  0.0385606 Validation Decoder Loss:  0.34217435
Encoder Loss:  0.4466196  || Decoder Loss:  0.03851416 Validation Decoder Loss:  0.3420095
Encoder Loss:  0.42080146  || Decoder Loss:  0.038479373 Validation Decoder Loss:  0.34183833
Encoder Loss:  0.4129046  || Decoder Loss:  0.038434636 Validation Decoder Loss:  0.3416695
Encoder Loss:  0.440708  || Decoder Loss:  0.03842208 Validation Decoder Loss:  0.34161112
Encoder Loss:  0.43925777  || Decoder Loss:  0.03848684 Validation Decoder Loss:  0.34165496
Encoder Loss:  0.43295163  || Decoder Loss:  0.038616106 Validation Decoder Loss:  0.3418465
Encoder Loss:  0.28936967  || Decoder Loss:  0.0388407 Validation Decoder Loss:  0.34213328
Encoder Loss:  0.08376707  || Decoder Loss:  0.03887894 Validation Decoder Loss:  0.34214836
Encoder Loss:  0.12622814  || Decoder Loss:  0.038808025 Validation Decoder Loss:  0.34220076
Encoder Loss:  0.11329725  || Decoder Loss:  0.03879638 Validation Decoder Loss:  0.34229153
Encoder Loss:  0.07788872  || Decoder Loss:  0.03875861 Validation Decoder Loss:  0.3423397
Encoder Loss:  0.06849964  || Decoder Loss:  0.03864366 Validation Decoder Loss:  0.34230912
Encoder Loss:  0.0737351  || Decoder Loss:  0.038542386 Validation Decoder Loss:  0.34232664
Encoder Loss:  0.07113996  || Decoder Loss:  0.038454484 Validation Decoder Loss:  0.3423342
Encoder Loss:  0.06625369  || Decoder Loss:  0.038355276 Validation Decoder Loss:  0.34230986
Encoder Loss:  0.06768294  || Decoder Loss:  0.038250435 Validation Decoder Loss:  0.34228295
Encoder Loss:  0.06642306  || Decoder Loss:  0.038153037 Validation Decoder Loss:  0.34226194
Encoder Loss:  0.08126723  || Decoder Loss:  0.03808968 Validation Decoder Loss:  0.34228843
Encoder Loss:  0.06859296  || Decoder Loss:  0.038020086 Validation Decoder Loss:  0.34226424
Encoder Loss:  0.081323765  || Decoder Loss:  0.037957884 Validation Decoder Loss:  0.3423056
Encoder Loss:  0.08963909  || Decoder Loss:  0.037974477 Validation Decoder Loss:  0.34244442
Encoder Loss:  0.06569097  || Decoder Loss:  0.037962787 Validation Decoder Loss:  0.34247518
Encoder Loss:  0.08985305  || Decoder Loss:  0.03797473 Validation Decoder Loss:  0.34263763
Encoder Loss:  0.065304786  || Decoder Loss:  0.038029578 Validation Decoder Loss:  0.34271994
Encoder Loss:  0.06532831  || Decoder Loss:  0.037997175 Validation Decoder Loss:  0.34272844
Encoder Loss:  0.07460126  || Decoder Loss:  0.037972104 Validation Decoder Loss:  0.34278017
Encoder Loss:  0.0742857  || Decoder Loss:  0.03800656 Validation Decoder Loss:  0.34288007
Encoder Loss:  0.08271368  || Decoder Loss:  0.038164232 Validation Decoder Loss:  0.3431734
Encoder Loss:  0.08106218  || Decoder Loss:  0.038434327 Validation Decoder Loss:  0.343802
Encoder Loss:  0.07672948  || Decoder Loss:  0.038914595 Validation Decoder Loss:  0.3448957
Encoder Loss:  0.07003811  || Decoder Loss:  0.039511226 Validation Decoder Loss:  0.34638375
Encoder Loss:  0.07000872  || Decoder Loss:  0.04317973 Validation Decoder Loss:  0.360201
Encoder Loss:  0.061973456  || Decoder Loss:  0.08046296 Validation Decoder Loss:  0.35458148
Encoder Loss:  0.058470696  || Decoder Loss:  0.09705639 Validation Decoder Loss:  0.38798594
Encoder Loss:  0.05512684  || Decoder Loss:  0.5245151 Validation Decoder Loss:  1.3388461
Encoder Loss:  0.050947253  || Decoder Loss:  0.27428973 Validation Decoder Loss:  0.42095858
Encoder Loss:  0.05091419  || Decoder Loss:  0.056081742 Validation Decoder Loss:  0.33681625
Encoder Loss:  0.051120926  || Decoder Loss:  0.035650354 Validation Decoder Loss:  0.33194268
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33194268
Model: "sequential_237"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_79 (Conv3DT (None, 494, 5, 20, 1)     117       
_________________________________________________________________
reshape_79 (Reshape)         (None, 2470, 20, 1)       0         
=================================================================
Total params: 117
Trainable params: 117
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_238"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_79 (Conv2D)           (None, 2470, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_239"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_79 (Conv2DT (None, 2607, 20, 1)       139       
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23313653  || Decoder Loss:  0.32265922 Validation Decoder Loss:  0.34630117
Encoder Loss:  0.04597883  || Decoder Loss:  0.04065648 Validation Decoder Loss:  0.33698127
Encoder Loss:  0.045466587  || Decoder Loss:  0.03833689 Validation Decoder Loss:  0.33243775
Encoder Loss:  0.044918895  || Decoder Loss:  0.040547416 Validation Decoder Loss:  0.33705896
Encoder Loss:  0.04484253  || Decoder Loss:  0.039600436 Validation Decoder Loss:  0.3309906
Encoder Loss:  0.043719206  || Decoder Loss:  0.03839402 Validation Decoder Loss:  0.3354656
Encoder Loss:  0.043096323  || Decoder Loss:  0.037398152 Validation Decoder Loss:  0.34005904
Encoder Loss:  0.04422709  || Decoder Loss:  0.038309895 Validation Decoder Loss:  0.33348483
Encoder Loss:  0.04258418  || Decoder Loss:  0.036977988 Validation Decoder Loss:  0.33497792
Encoder Loss:  0.042392895  || Decoder Loss:  0.03682003 Validation Decoder Loss:  0.33452797
Encoder Loss:  0.043175645  || Decoder Loss:  0.036850967 Validation Decoder Loss:  0.33316556
Encoder Loss:  0.043874428  || Decoder Loss:  0.037161928 Validation Decoder Loss:  0.33488953
Encoder Loss:  0.042172667  || Decoder Loss:  0.036449548 Validation Decoder Loss:  0.33320457
Encoder Loss:  0.04453116  || Decoder Loss:  0.037040576 Validation Decoder Loss:  0.3340283
Encoder Loss:  0.04188904  || Decoder Loss:  0.03626261 Validation Decoder Loss:  0.33168292
Encoder Loss:  0.041899867  || Decoder Loss:  0.036221635 Validation Decoder Loss:  0.3325575
Encoder Loss:  0.042100478  || Decoder Loss:  0.036234543 Validation Decoder Loss:  0.3314712
Encoder Loss:  0.042118203  || Decoder Loss:  0.03614703 Validation Decoder Loss:  0.33292064
Encoder Loss:  0.042741414  || Decoder Loss:  0.036239065 Validation Decoder Loss:  0.3315063
Encoder Loss:  0.041533604  || Decoder Loss:  0.036020156 Validation Decoder Loss:  0.33312893
Encoder Loss:  0.041752744  || Decoder Loss:  0.03597296 Validation Decoder Loss:  0.33269587
Encoder Loss:  0.041490678  || Decoder Loss:  0.035837397 Validation Decoder Loss:  0.33347154
Encoder Loss:  0.04324964  || Decoder Loss:  0.036247507 Validation Decoder Loss:  0.33333027
Encoder Loss:  0.041549258  || Decoder Loss:  0.03600309 Validation Decoder Loss:  0.33301333
Encoder Loss:  0.041878935  || Decoder Loss:  0.035865042 Validation Decoder Loss:  0.33319348
Encoder Loss:  0.041547626  || Decoder Loss:  0.03599217 Validation Decoder Loss:  0.33317447
Encoder Loss:  0.041536566  || Decoder Loss:  0.035936445 Validation Decoder Loss:  0.33279115
Encoder Loss:  0.04170926  || Decoder Loss:  0.035938464 Validation Decoder Loss:  0.33286342
Encoder Loss:  0.04291762  || Decoder Loss:  0.03814696 Validation Decoder Loss:  0.33364215
Encoder Loss:  0.04286284  || Decoder Loss:  0.03766854 Validation Decoder Loss:  0.33307594
Encoder Loss:  0.04187336  || Decoder Loss:  0.03639829 Validation Decoder Loss:  0.33384937
Encoder Loss:  0.042819165  || Decoder Loss:  0.036973976 Validation Decoder Loss:  0.332996
Encoder Loss:  0.041890655  || Decoder Loss:  0.036513954 Validation Decoder Loss:  0.33323252
Encoder Loss:  0.042394463  || Decoder Loss:  0.036762062 Validation Decoder Loss:  0.33245358
Encoder Loss:  0.041856814  || Decoder Loss:  0.036444537 Validation Decoder Loss:  0.3329093
Encoder Loss:  0.04184251  || Decoder Loss:  0.03638213 Validation Decoder Loss:  0.33265927
Encoder Loss:  0.042146325  || Decoder Loss:  0.036541983 Validation Decoder Loss:  0.33202162
Encoder Loss:  0.041730925  || Decoder Loss:  0.036270503 Validation Decoder Loss:  0.33145583
Encoder Loss:  0.042814422  || Decoder Loss:  0.036614183 Validation Decoder Loss:  0.3321308
Encoder Loss:  0.041645713  || Decoder Loss:  0.036184717 Validation Decoder Loss:  0.33271328
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33271328
Model: "sequential_240"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_80 (Conv3DT (None, 254, 5, 20, 1)     192       
_________________________________________________________________
reshape_80 (Reshape)         (None, 1270, 20, 1)       0         
=================================================================
Total params: 192
Trainable params: 192
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_241"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_80 (Conv2D)           (None, 1270, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_242"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_80 (Conv2DT (None, 2607, 20, 1)       1339      
=================================================================
Total params: 1,339
Trainable params: 1,339
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.09326177  || Decoder Loss:  0.09326177 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.09326177  || Decoder Loss:  0.09326177 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.093261786  || Decoder Loss:  0.093261786 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.09326177  || Decoder Loss:  0.09326177 Validation Decoder Loss:  0.36832404
Encoder Loss:  0.09326177  || Decoder Loss:  0.09326177 Validation Decoder Loss:  0.36832404
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36832404
Model: "sequential_243"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_81 (Conv3DT (None, 147, 10, 20, 1)    505       
_________________________________________________________________
reshape_81 (Reshape)         (None, 1470, 20, 1)       0         
=================================================================
Total params: 505
Trainable params: 505
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_244"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_81 (Conv2D)           (None, 1470, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_245"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_81 (Conv2DT (None, 2607, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3236905  || Decoder Loss:  0.49417076 Validation Decoder Loss:  1.116701
Encoder Loss:  0.24367897  || Decoder Loss:  0.45281342 Validation Decoder Loss:  1.1032932
Encoder Loss:  0.23998837  || Decoder Loss:  0.46302307 Validation Decoder Loss:  1.0936255
Encoder Loss:  0.2388437  || Decoder Loss:  0.46139386 Validation Decoder Loss:  1.1267157
Encoder Loss:  0.23959467  || Decoder Loss:  0.46746078 Validation Decoder Loss:  1.1937332
Encoder Loss:  0.23395558  || Decoder Loss:  0.47524193 Validation Decoder Loss:  1.1861436
Encoder Loss:  0.24055833  || Decoder Loss:  0.5065289 Validation Decoder Loss:  1.0528145
Encoder Loss:  0.22416443  || Decoder Loss:  0.469961 Validation Decoder Loss:  1.0535232
Encoder Loss:  0.22115338  || Decoder Loss:  0.46216744 Validation Decoder Loss:  1.0271125
Encoder Loss:  0.21514945  || Decoder Loss:  0.44786304 Validation Decoder Loss:  1.0156813
Encoder Loss:  0.22117467  || Decoder Loss:  0.46146694 Validation Decoder Loss:  1.0213666
Encoder Loss:  0.22061689  || Decoder Loss:  0.45840675 Validation Decoder Loss:  1.0846868
Encoder Loss:  0.19179691  || Decoder Loss:  0.38629344 Validation Decoder Loss:  1.1568664
Encoder Loss:  0.2680441  || Decoder Loss:  0.5682311 Validation Decoder Loss:  1.2131089
Encoder Loss:  0.24550842  || Decoder Loss:  0.5201087 Validation Decoder Loss:  1.1308111
Encoder Loss:  0.23169887  || Decoder Loss:  0.48664838 Validation Decoder Loss:  1.1269658
Encoder Loss:  0.22687171  || Decoder Loss:  0.47657132 Validation Decoder Loss:  1.0956733
Encoder Loss:  0.22158569  || Decoder Loss:  0.46440464 Validation Decoder Loss:  1.0806601
Encoder Loss:  0.21041918  || Decoder Loss:  0.43737522 Validation Decoder Loss:  0.93627435
Encoder Loss:  0.18849128  || Decoder Loss:  0.3841446 Validation Decoder Loss:  0.8493098
Encoder Loss:  0.17779821  || Decoder Loss:  0.35866708 Validation Decoder Loss:  0.7167578
Encoder Loss:  0.10299265  || Decoder Loss:  0.17669564 Validation Decoder Loss:  0.4349225
Encoder Loss:  0.06318405  || Decoder Loss:  0.07954564 Validation Decoder Loss:  0.3306308
Encoder Loss:  0.051413924  || Decoder Loss:  0.04642109 Validation Decoder Loss:  0.32795927
Encoder Loss:  0.045067504  || Decoder Loss:  0.03456946 Validation Decoder Loss:  0.33715057
Encoder Loss:  0.04626052  || Decoder Loss:  0.033766173 Validation Decoder Loss:  0.31767884
Encoder Loss:  0.04733004  || Decoder Loss:  0.039094575 Validation Decoder Loss:  0.31439662
Encoder Loss:  0.046295382  || Decoder Loss:  0.034532 Validation Decoder Loss:  0.33014452
Encoder Loss:  0.04678686  || Decoder Loss:  0.033380423 Validation Decoder Loss:  0.3338099
Encoder Loss:  0.04602222  || Decoder Loss:  0.03489153 Validation Decoder Loss:  0.35710475
Encoder Loss:  0.04522048  || Decoder Loss:  0.03710142 Validation Decoder Loss:  0.32997364
Encoder Loss:  0.04391624  || Decoder Loss:  0.03331254 Validation Decoder Loss:  0.3271262
Encoder Loss:  0.043224227  || Decoder Loss:  0.032820456 Validation Decoder Loss:  0.318237
Encoder Loss:  0.044160172  || Decoder Loss:  0.03541475 Validation Decoder Loss:  0.3270061
Encoder Loss:  0.04346738  || Decoder Loss:  0.03311635 Validation Decoder Loss:  0.3368504
Encoder Loss:  0.04323968  || Decoder Loss:  0.03287591 Validation Decoder Loss:  0.33896995
Encoder Loss:  0.043876644  || Decoder Loss:  0.032906104 Validation Decoder Loss:  0.34075207
Encoder Loss:  0.045084644  || Decoder Loss:  0.034865856 Validation Decoder Loss:  0.31273508
Encoder Loss:  0.045256514  || Decoder Loss:  0.033709906 Validation Decoder Loss:  0.32073268
Encoder Loss:  0.046198405  || Decoder Loss:  0.03273443 Validation Decoder Loss:  0.33291715
Model: siamese_net_lr_0.42141659689979993 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33291715
Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_82 (Conv3DT (None, 80, 19, 20, 1)     188       
_________________________________________________________________
reshape_82 (Reshape)         (None, 1520, 20, 1)       0         
=================================================================
Total params: 188
Trainable params: 188
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_247"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_82 (Conv2D)           (None, 1520, 20, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_82 (Conv2DT (None, 2607, 20, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33285058  || Decoder Loss:  0.47296295 Validation Decoder Loss:  0.72110283
Encoder Loss:  0.3038025  || Decoder Loss:  0.48615128 Validation Decoder Loss:  1.0871053
Encoder Loss:  0.26085177  || Decoder Loss:  0.41797966 Validation Decoder Loss:  0.6693789
Encoder Loss:  0.26430726  || Decoder Loss:  0.43760622 Validation Decoder Loss:  1.1375036
Encoder Loss:  0.28318098  || Decoder Loss:  0.48589098 Validation Decoder Loss:  1.0616429
Encoder Loss:  0.2799303  || Decoder Loss:  0.48565277 Validation Decoder Loss:  1.0145162
Encoder Loss:  0.27151302  || Decoder Loss:  0.4701718 Validation Decoder Loss:  1.037149
Encoder Loss:  0.2616555  || Decoder Loss:  0.45136505 Validation Decoder Loss:  1.1308529
Encoder Loss:  0.28408232  || Decoder Loss:  0.49335098 Validation Decoder Loss:  1.1345183
Encoder Loss:  0.2788537  || Decoder Loss:  0.4809554 Validation Decoder Loss:  1.0163354
Encoder Loss:  0.2826586  || Decoder Loss:  0.49054378 Validation Decoder Loss:  0.9964434
Encoder Loss:  0.24958956  || Decoder Loss:  0.427946 Validation Decoder Loss:  1.1641089
Encoder Loss:  0.23624605  || Decoder Loss:  0.40255466 Validation Decoder Loss:  0.8730031
Encoder Loss:  0.1999477  || Decoder Loss:  0.3327115 Validation Decoder Loss:  0.4864866
Encoder Loss:  0.18448018  || Decoder Loss:  0.3019376 Validation Decoder Loss:  0.8059
Encoder Loss:  0.17515692  || Decoder Loss:  0.2866468 Validation Decoder Loss:  0.50510895
Encoder Loss:  0.15055268  || Decoder Loss:  0.23949444 Validation Decoder Loss:  1.0252116
Encoder Loss:  0.14302611  || Decoder Loss:  0.2229381 Validation Decoder Loss:  0.5642932
Encoder Loss:  0.077919014  || Decoder Loss:  0.10180025 Validation Decoder Loss:  0.37380415
Encoder Loss:  0.046363637  || Decoder Loss:  0.042551234 Validation Decoder Loss:  0.3633886
Encoder Loss:  0.045681972  || Decoder Loss:  0.040494572 Validation Decoder Loss:  0.34234658
Encoder Loss:  0.042103786  || Decoder Loss:  0.034252882 Validation Decoder Loss:  0.35513097
Encoder Loss:  0.044738866  || Decoder Loss:  0.039063584 Validation Decoder Loss:  0.3559247
Encoder Loss:  0.043165393  || Decoder Loss:  0.03615067 Validation Decoder Loss:  0.3464977
Encoder Loss:  0.043945212  || Decoder Loss:  0.03723093 Validation Decoder Loss:  0.3488647
Encoder Loss:  0.041925147  || Decoder Loss:  0.034226667 Validation Decoder Loss:  0.33544555
Encoder Loss:  0.040605053  || Decoder Loss:  0.032012682 Validation Decoder Loss:  0.33765173
Encoder Loss:  0.040755063  || Decoder Loss:  0.032303996 Validation Decoder Loss:  0.3368643
Encoder Loss:  0.041232195  || Decoder Loss:  0.033066824 Validation Decoder Loss:  0.35092524
Encoder Loss:  0.043417506  || Decoder Loss:  0.03716366 Validation Decoder Loss:  0.35052365
Encoder Loss:  0.042778965  || Decoder Loss:  0.035659276 Validation Decoder Loss:  0.3390597
Encoder Loss:  0.04142067  || Decoder Loss:  0.033600092 Validation Decoder Loss:  0.34126487
Encoder Loss:  0.04139174  || Decoder Loss:  0.033457994 Validation Decoder Loss:  0.34452492
Encoder Loss:  0.04206749  || Decoder Loss:  0.034390908 Validation Decoder Loss:  0.36254197
Encoder Loss:  0.04542541  || Decoder Loss:  0.03986852 Validation Decoder Loss:  0.33320653
Encoder Loss:  0.0419879  || Decoder Loss:  0.034123424 Validation Decoder Loss:  0.33442393
Encoder Loss:  0.04132154  || Decoder Loss:  0.03338766 Validation Decoder Loss:  0.3486503
Encoder Loss:  0.04372224  || Decoder Loss:  0.037807178 Validation Decoder Loss:  0.36099368
Encoder Loss:  0.047051415  || Decoder Loss:  0.041523878 Validation Decoder Loss:  0.34196413
Encoder Loss:  0.044889946  || Decoder Loss:  0.038701955 Validation Decoder Loss:  0.3435858
Model: siamese_net_lr_0.5950232328833027 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3435858
Model: "sequential_249"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_83 (Conv3DT (None, 314, 5, 20, 1)     63        
_________________________________________________________________
reshape_83 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 63
Trainable params: 63
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_250"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_83 (Conv2D)           (None, 1570, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_251"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_83 (Conv2DT (None, 2607, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19924931  || Decoder Loss:  0.12158136 Validation Decoder Loss:  0.36205268
Encoder Loss:  0.16742606  || Decoder Loss:  0.08678379 Validation Decoder Loss:  0.36363423
Encoder Loss:  0.41165328  || Decoder Loss:  0.49585152 Validation Decoder Loss:  0.72896236
Encoder Loss:  0.35740665  || Decoder Loss:  0.44672576 Validation Decoder Loss:  0.7856941
Encoder Loss:  0.38821098  || Decoder Loss:  0.4909232 Validation Decoder Loss:  0.6315175
Encoder Loss:  0.3779562  || Decoder Loss:  0.47791314 Validation Decoder Loss:  0.64429355
Encoder Loss:  0.3737961  || Decoder Loss:  0.473643 Validation Decoder Loss:  0.6130323
Encoder Loss:  0.3596246  || Decoder Loss:  0.45545065 Validation Decoder Loss:  0.56582826
Encoder Loss:  0.30517542  || Decoder Loss:  0.38263285 Validation Decoder Loss:  1.162056
Encoder Loss:  0.31226447  || Decoder Loss:  0.39146405 Validation Decoder Loss:  0.9403739
Encoder Loss:  0.28748924  || Decoder Loss:  0.36252037 Validation Decoder Loss:  0.9065691
Encoder Loss:  0.2355444  || Decoder Loss:  0.2920987 Validation Decoder Loss:  0.8800857
Encoder Loss:  0.22738397  || Decoder Loss:  0.28172553 Validation Decoder Loss:  0.58463454
Encoder Loss:  0.09994073  || Decoder Loss:  0.11120937 Validation Decoder Loss:  0.38376087
Encoder Loss:  0.087263174  || Decoder Loss:  0.096406415 Validation Decoder Loss:  0.43427855
Encoder Loss:  0.060368195  || Decoder Loss:  0.061047945 Validation Decoder Loss:  0.36232716
Encoder Loss:  0.04524143  || Decoder Loss:  0.03788069 Validation Decoder Loss:  0.405128
Encoder Loss:  0.04805585  || Decoder Loss:  0.041608434 Validation Decoder Loss:  0.3597939
Encoder Loss:  0.04177303  || Decoder Loss:  0.035341155 Validation Decoder Loss:  0.34387183
Encoder Loss:  0.04446878  || Decoder Loss:  0.03883175 Validation Decoder Loss:  0.3529821
Encoder Loss:  0.049171273  || Decoder Loss:  0.046362914 Validation Decoder Loss:  0.34444043
Encoder Loss:  0.043697346  || Decoder Loss:  0.038933143 Validation Decoder Loss:  0.34657446
Encoder Loss:  0.047539692  || Decoder Loss:  0.043267954 Validation Decoder Loss:  0.35059547
Encoder Loss:  0.046358988  || Decoder Loss:  0.041773282 Validation Decoder Loss:  0.35410404
Encoder Loss:  0.04483397  || Decoder Loss:  0.04041827 Validation Decoder Loss:  0.34288698
Encoder Loss:  0.04401623  || Decoder Loss:  0.039184097 Validation Decoder Loss:  0.3372693
Encoder Loss:  0.045702938  || Decoder Loss:  0.041614894 Validation Decoder Loss:  0.3489638
Encoder Loss:  0.048354883  || Decoder Loss:  0.04328643 Validation Decoder Loss:  0.35932356
Encoder Loss:  0.04771631  || Decoder Loss:  0.04325095 Validation Decoder Loss:  0.34689897
Encoder Loss:  0.046679616  || Decoder Loss:  0.038760167 Validation Decoder Loss:  0.3379868
Encoder Loss:  0.045056034  || Decoder Loss:  0.039460972 Validation Decoder Loss:  0.3434164
Encoder Loss:  0.043475218  || Decoder Loss:  0.039328277 Validation Decoder Loss:  0.34844536
Encoder Loss:  0.045053408  || Decoder Loss:  0.042107653 Validation Decoder Loss:  0.34034073
Encoder Loss:  0.042544704  || Decoder Loss:  0.03682559 Validation Decoder Loss:  0.34681374
Encoder Loss:  0.041196316  || Decoder Loss:  0.03706563 Validation Decoder Loss:  0.34698394
Encoder Loss:  0.0428295  || Decoder Loss:  0.038621403 Validation Decoder Loss:  0.35293296
Encoder Loss:  0.046659876  || Decoder Loss:  0.04152906 Validation Decoder Loss:  0.34255683
Encoder Loss:  0.043448735  || Decoder Loss:  0.03743978 Validation Decoder Loss:  0.34452945
Encoder Loss:  0.04252038  || Decoder Loss:  0.03820556 Validation Decoder Loss:  0.33768672
Encoder Loss:  0.042184032  || Decoder Loss:  0.03705768 Validation Decoder Loss:  0.3371647
Model: siamese_net_lr_0.6650127658364839 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33716467
Model: "sequential_252"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_84 (Conv3DT (None, 314, 5, 20, 1)     189       
_________________________________________________________________
reshape_84 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_84 (Conv2D)           (None, 1570, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_254"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_84 (Conv2DT (None, 2607, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23144267  || Decoder Loss:  0.20877844 Validation Decoder Loss:  1.1157644
Encoder Loss:  0.3826725  || Decoder Loss:  0.45624942 Validation Decoder Loss:  1.0743355
Encoder Loss:  0.39033097  || Decoder Loss:  0.47073135 Validation Decoder Loss:  1.0581949
Encoder Loss:  0.37618157  || Decoder Loss:  0.45480064 Validation Decoder Loss:  1.0151181
Encoder Loss:  0.3620326  || Decoder Loss:  0.4384798 Validation Decoder Loss:  0.971594
Encoder Loss:  0.29783073  || Decoder Loss:  0.3584204 Validation Decoder Loss:  0.7620921
Encoder Loss:  0.3804434  || Decoder Loss:  0.46047834 Validation Decoder Loss:  1.1483445
Encoder Loss:  0.39284438  || Decoder Loss:  0.47720334 Validation Decoder Loss:  1.0841906
Encoder Loss:  0.38527644  || Decoder Loss:  0.4728245 Validation Decoder Loss:  0.96662915
Encoder Loss:  0.32094318  || Decoder Loss:  0.39174706 Validation Decoder Loss:  0.47860128
Encoder Loss:  0.3443723  || Decoder Loss:  0.41566792 Validation Decoder Loss:  0.80452335
Encoder Loss:  0.33528242  || Decoder Loss:  0.4040221 Validation Decoder Loss:  0.8928408
Encoder Loss:  0.25186452  || Decoder Loss:  0.3049182 Validation Decoder Loss:  0.85333943
Encoder Loss:  0.19492501  || Decoder Loss:  0.23161821 Validation Decoder Loss:  0.65504885
Encoder Loss:  0.16948074  || Decoder Loss:  0.19772017 Validation Decoder Loss:  0.4346972
Encoder Loss:  0.05884263  || Decoder Loss:  0.05323422 Validation Decoder Loss:  0.46662048
Encoder Loss:  0.04996313  || Decoder Loss:  0.04823235 Validation Decoder Loss:  0.40840387
Encoder Loss:  0.044147678  || Decoder Loss:  0.041003466 Validation Decoder Loss:  0.39247146
Encoder Loss:  0.0429086  || Decoder Loss:  0.038676847 Validation Decoder Loss:  0.33726072
Encoder Loss:  0.04439848  || Decoder Loss:  0.039109062 Validation Decoder Loss:  0.38229126
Encoder Loss:  0.042071365  || Decoder Loss:  0.03813046 Validation Decoder Loss:  0.33949184
Encoder Loss:  0.04183262  || Decoder Loss:  0.038052965 Validation Decoder Loss:  0.33265156
Encoder Loss:  0.044276558  || Decoder Loss:  0.03729404 Validation Decoder Loss:  0.32995322
Encoder Loss:  0.046324644  || Decoder Loss:  0.04038754 Validation Decoder Loss:  0.39293045
Encoder Loss:  0.0455768  || Decoder Loss:  0.039972387 Validation Decoder Loss:  0.40246826
Encoder Loss:  0.042273596  || Decoder Loss:  0.03867545 Validation Decoder Loss:  0.39612785
Encoder Loss:  0.04187231  || Decoder Loss:  0.038268927 Validation Decoder Loss:  0.33611864
Encoder Loss:  0.04214196  || Decoder Loss:  0.037210982 Validation Decoder Loss:  0.3378315
Encoder Loss:  0.041784573  || Decoder Loss:  0.037373908 Validation Decoder Loss:  0.36163613
Encoder Loss:  0.040608093  || Decoder Loss:  0.037074342 Validation Decoder Loss:  0.32795984
Encoder Loss:  0.04418024  || Decoder Loss:  0.03809328 Validation Decoder Loss:  0.342311
Encoder Loss:  0.041547474  || Decoder Loss:  0.037304193 Validation Decoder Loss:  0.3986721
Encoder Loss:  0.043372653  || Decoder Loss:  0.03884841 Validation Decoder Loss:  0.34056127
Encoder Loss:  0.042765997  || Decoder Loss:  0.037494686 Validation Decoder Loss:  0.32862842
Encoder Loss:  0.043754786  || Decoder Loss:  0.03798987 Validation Decoder Loss:  0.3577505
Encoder Loss:  0.041439828  || Decoder Loss:  0.0377382 Validation Decoder Loss:  0.37415147
Encoder Loss:  0.041411713  || Decoder Loss:  0.03760724 Validation Decoder Loss:  0.33903426
Encoder Loss:  0.040439844  || Decoder Loss:  0.036372308 Validation Decoder Loss:  0.3275987
Encoder Loss:  0.04161663  || Decoder Loss:  0.03709486 Validation Decoder Loss:  0.34469286
Encoder Loss:  0.041146472  || Decoder Loss:  0.036528192 Validation Decoder Loss:  0.328135
Model: siamese_net_lr_0.5742551572976783 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.328135
Model: "sequential_255"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_85 (Conv3DT (None, 304, 5, 20, 1)     116       
_________________________________________________________________
reshape_85 (Reshape)         (None, 1520, 20, 1)       0         
=================================================================
Total params: 116
Trainable params: 116
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_256"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_85 (Conv2D)           (None, 1520, 20, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_257"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_85 (Conv2DT (None, 2607, 20, 1)       1089      
=================================================================
Total params: 1,089
Trainable params: 1,089
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.3642525
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Encoder Loss:  0.4043263  || Decoder Loss:  0.08975161 Validation Decoder Loss:  0.36425248
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36425248
Model: "sequential_258"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_86 (Conv3DT (None, 314, 5, 20, 1)     126       
_________________________________________________________________
reshape_86 (Reshape)         (None, 1570, 20, 1)       0         
=================================================================
Total params: 126
Trainable params: 126
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_259"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_86 (Conv2D)           (None, 1570, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_260"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_86 (Conv2DT (None, 2607, 20, 1)       1039      
=================================================================
Total params: 1,039
Trainable params: 1,039
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.036131427  || Decoder Loss:  0.036131427 Validation Decoder Loss:  0.34415084
Encoder Loss:  0.029369561  || Decoder Loss:  0.029369561 Validation Decoder Loss:  0.3444355
Encoder Loss:  0.028679892  || Decoder Loss:  0.028679892 Validation Decoder Loss:  0.34266517
Encoder Loss:  0.028551342  || Decoder Loss:  0.028551342 Validation Decoder Loss:  0.3404377
Encoder Loss:  0.028890627  || Decoder Loss:  0.028890627 Validation Decoder Loss:  0.33958924
Encoder Loss:  0.028213674  || Decoder Loss:  0.028213674 Validation Decoder Loss:  0.33815607
Encoder Loss:  0.027868584  || Decoder Loss:  0.027868584 Validation Decoder Loss:  0.33996886
Encoder Loss:  0.028884724  || Decoder Loss:  0.028884724 Validation Decoder Loss:  0.37972045
Encoder Loss:  0.028573928  || Decoder Loss:  0.028573928 Validation Decoder Loss:  0.364973
Encoder Loss:  0.028271345  || Decoder Loss:  0.028271345 Validation Decoder Loss:  0.36412543
Encoder Loss:  0.028154358  || Decoder Loss:  0.028154358 Validation Decoder Loss:  0.36332723
Encoder Loss:  0.028052384  || Decoder Loss:  0.028052384 Validation Decoder Loss:  0.362884
Encoder Loss:  0.02795096  || Decoder Loss:  0.02795096 Validation Decoder Loss:  0.36219168
Encoder Loss:  0.027851593  || Decoder Loss:  0.027851593 Validation Decoder Loss:  0.36188775
Encoder Loss:  0.02775792  || Decoder Loss:  0.02775792 Validation Decoder Loss:  0.361825
Encoder Loss:  0.027670478  || Decoder Loss:  0.027670478 Validation Decoder Loss:  0.36184835
Encoder Loss:  0.02758886  || Decoder Loss:  0.02758886 Validation Decoder Loss:  0.36190313
Encoder Loss:  0.027512528  || Decoder Loss:  0.027512528 Validation Decoder Loss:  0.36197
Encoder Loss:  0.02744099  || Decoder Loss:  0.02744099 Validation Decoder Loss:  0.362041
Encoder Loss:  0.02737386  || Decoder Loss:  0.02737386 Validation Decoder Loss:  0.36211205
Encoder Loss:  0.027310692  || Decoder Loss:  0.027310692 Validation Decoder Loss:  0.36218047
Encoder Loss:  0.02725122  || Decoder Loss:  0.02725122 Validation Decoder Loss:  0.36224476
Encoder Loss:  0.027195103  || Decoder Loss:  0.027195103 Validation Decoder Loss:  0.36230364
Encoder Loss:  0.027142048  || Decoder Loss:  0.027142048 Validation Decoder Loss:  0.3623566
Encoder Loss:  0.027091779  || Decoder Loss:  0.027091779 Validation Decoder Loss:  0.36240315
Encoder Loss:  0.027044106  || Decoder Loss:  0.027044106 Validation Decoder Loss:  0.3624431
Encoder Loss:  0.026998807  || Decoder Loss:  0.026998807 Validation Decoder Loss:  0.3624763
Encoder Loss:  0.026955716  || Decoder Loss:  0.026955716 Validation Decoder Loss:  0.36250266
Encoder Loss:  0.026914602  || Decoder Loss:  0.026914602 Validation Decoder Loss:  0.3625223
Encoder Loss:  0.02687537  || Decoder Loss:  0.02687537 Validation Decoder Loss:  0.36253527
Encoder Loss:  0.026837863  || Decoder Loss:  0.026837863 Validation Decoder Loss:  0.36254182
Encoder Loss:  0.026801992  || Decoder Loss:  0.026801992 Validation Decoder Loss:  0.36254236
Encoder Loss:  0.026767561  || Decoder Loss:  0.026767561 Validation Decoder Loss:  0.3625372
Encoder Loss:  0.026734523  || Decoder Loss:  0.026734523 Validation Decoder Loss:  0.36252734
Encoder Loss:  0.026702784  || Decoder Loss:  0.026702784 Validation Decoder Loss:  0.36251372
Encoder Loss:  0.026672298  || Decoder Loss:  0.026672298 Validation Decoder Loss:  0.36249793
Encoder Loss:  0.026642937  || Decoder Loss:  0.026642937 Validation Decoder Loss:  0.36248165
Encoder Loss:  0.026614606  || Decoder Loss:  0.026614606 Validation Decoder Loss:  0.36246663
Encoder Loss:  0.02658736  || Decoder Loss:  0.02658736 Validation Decoder Loss:  0.36245474
Encoder Loss:  0.02656098  || Decoder Loss:  0.02656098 Validation Decoder Loss:  0.3624474
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3624474
Model: "sequential_261"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_87 (Conv3DT (None, 130, 9, 20, 1)     21        
_________________________________________________________________
reshape_87 (Reshape)         (None, 1170, 20, 1)       0         
=================================================================
Total params: 21
Trainable params: 21
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_262"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_87 (Conv2D)           (None, 1170, 20, 1)       270       
=================================================================
Total params: 270
Trainable params: 270
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_263"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_87 (Conv2DT (None, 2607, 20, 1)       1439      
=================================================================
Total params: 1,439
Trainable params: 1,439
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3910026  || Decoder Loss:  0.37049598 Validation Decoder Loss:  0.41394705
Encoder Loss:  0.37720582  || Decoder Loss:  0.10784532 Validation Decoder Loss:  0.37737828
Encoder Loss:  0.37827426  || Decoder Loss:  0.09383079 Validation Decoder Loss:  0.3685159
Encoder Loss:  0.32914656  || Decoder Loss:  0.087383434 Validation Decoder Loss:  0.3634166
Encoder Loss:  0.21571475  || Decoder Loss:  0.08206692 Validation Decoder Loss:  0.35951978
Encoder Loss:  0.20820644  || Decoder Loss:  0.07702288 Validation Decoder Loss:  0.35611188
Encoder Loss:  0.14876954  || Decoder Loss:  0.072093055 Validation Decoder Loss:  0.3531344
Encoder Loss:  0.09079106  || Decoder Loss:  0.06716881 Validation Decoder Loss:  0.35070252
Encoder Loss:  0.1213476  || Decoder Loss:  0.062191255 Validation Decoder Loss:  0.34893566
Encoder Loss:  0.11280719  || Decoder Loss:  0.057438605 Validation Decoder Loss:  0.3481351
Encoder Loss:  0.070610374  || Decoder Loss:  0.05306187 Validation Decoder Loss:  0.34886968
Encoder Loss:  0.077946134  || Decoder Loss:  0.049283043 Validation Decoder Loss:  0.35148376
Encoder Loss:  0.0842171  || Decoder Loss:  0.047081888 Validation Decoder Loss:  0.35518962
Encoder Loss:  0.087026834  || Decoder Loss:  0.046546575 Validation Decoder Loss:  0.35770196
Encoder Loss:  0.10876356  || Decoder Loss:  0.047368843 Validation Decoder Loss:  0.35763702
Encoder Loss:  0.11788054  || Decoder Loss:  0.051175173 Validation Decoder Loss:  0.3564948
Encoder Loss:  0.062820785  || Decoder Loss:  0.05914773 Validation Decoder Loss:  0.35659975
Encoder Loss:  0.07706533  || Decoder Loss:  0.07079477 Validation Decoder Loss:  0.35718185
Encoder Loss:  0.077072434  || Decoder Loss:  0.10698667 Validation Decoder Loss:  0.3656084
Encoder Loss:  0.07666634  || Decoder Loss:  0.16787936 Validation Decoder Loss:  0.37844813
Encoder Loss:  0.074356236  || Decoder Loss:  0.16953865 Validation Decoder Loss:  0.38438457
Encoder Loss:  0.070549734  || Decoder Loss:  0.14769337 Validation Decoder Loss:  0.37214017
Encoder Loss:  0.065913916  || Decoder Loss:  0.12990566 Validation Decoder Loss:  0.36766306
Encoder Loss:  0.06276407  || Decoder Loss:  0.109353185 Validation Decoder Loss:  0.36584204
Encoder Loss:  0.060333293  || Decoder Loss:  0.09281059 Validation Decoder Loss:  0.36396724
Encoder Loss:  0.06381245  || Decoder Loss:  0.08626333 Validation Decoder Loss:  0.36383772
Encoder Loss:  0.059621368  || Decoder Loss:  0.086177506 Validation Decoder Loss:  0.3630435
Encoder Loss:  0.059645467  || Decoder Loss:  0.08115835 Validation Decoder Loss:  0.36204207
Encoder Loss:  0.06805152  || Decoder Loss:  0.08285396 Validation Decoder Loss:  0.36337024
Encoder Loss:  0.073153436  || Decoder Loss:  0.113275655 Validation Decoder Loss:  0.3781414
Encoder Loss:  0.0744392  || Decoder Loss:  0.1534352 Validation Decoder Loss:  0.39266044
Encoder Loss:  0.0721362  || Decoder Loss:  0.16009484 Validation Decoder Loss:  0.37769228
Encoder Loss:  0.06734978  || Decoder Loss:  0.11961829 Validation Decoder Loss:  0.37364423
Encoder Loss:  0.072532706  || Decoder Loss:  0.12311204 Validation Decoder Loss:  0.39434558
Encoder Loss:  0.069179066  || Decoder Loss:  0.13733673 Validation Decoder Loss:  0.39667243
Encoder Loss:  0.065977775  || Decoder Loss:  0.12598242 Validation Decoder Loss:  0.38084352
Encoder Loss:  0.06480518  || Decoder Loss:  0.10006248 Validation Decoder Loss:  0.3779896
Encoder Loss:  0.069121115  || Decoder Loss:  0.10362073 Validation Decoder Loss:  0.40015733
Encoder Loss:  0.063019425  || Decoder Loss:  0.10015841 Validation Decoder Loss:  0.42651623
Encoder Loss:  0.060712714  || Decoder Loss:  0.07966865 Validation Decoder Loss:  0.32698032
Model: siamese_net_lr_0.37492525908706364 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32698032
Model: "sequential_264"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_88 (Conv3DT (None, 112, 10, 20, 1)    295       
_________________________________________________________________
reshape_88 (Reshape)         (None, 1120, 20, 1)       0         
=================================================================
Total params: 295
Trainable params: 295
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_265"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_88 (Conv2D)           (None, 1120, 20, 1)       370       
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_266"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_88 (Conv2DT (None, 2607, 20, 1)       370       
=================================================================
Total params: 370
Trainable params: 370
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36131737  || Decoder Loss:  0.5724467 Validation Decoder Loss:  0.9679905
Encoder Loss:  0.26836306  || Decoder Loss:  0.5043059 Validation Decoder Loss:  0.9381857
Encoder Loss:  0.28390655  || Decoder Loss:  0.50924164 Validation Decoder Loss:  0.978288
Encoder Loss:  0.26291528  || Decoder Loss:  0.50150406 Validation Decoder Loss:  0.9833871
Encoder Loss:  0.25814793  || Decoder Loss:  0.5010588 Validation Decoder Loss:  0.9867723
Encoder Loss:  0.26025063  || Decoder Loss:  0.5003233 Validation Decoder Loss:  0.9940014
Encoder Loss:  0.25529188  || Decoder Loss:  0.49838212 Validation Decoder Loss:  0.99972063
Encoder Loss:  0.25332412  || Decoder Loss:  0.49648428 Validation Decoder Loss:  1.0035064
Encoder Loss:  0.24878775  || Decoder Loss:  0.49354193 Validation Decoder Loss:  1.0156609
Encoder Loss:  0.2505094  || Decoder Loss:  0.49102533 Validation Decoder Loss:  1.0147995
Encoder Loss:  0.24733022  || Decoder Loss:  0.4862786 Validation Decoder Loss:  1.019523
Encoder Loss:  0.24622472  || Decoder Loss:  0.48363212 Validation Decoder Loss:  1.0199826
Encoder Loss:  0.24443254  || Decoder Loss:  0.47792023 Validation Decoder Loss:  0.9997997
Encoder Loss:  0.2383196  || Decoder Loss:  0.47550923 Validation Decoder Loss:  1.0286663
Encoder Loss:  0.23964797  || Decoder Loss:  0.47423947 Validation Decoder Loss:  1.0283866
Encoder Loss:  0.23921992  || Decoder Loss:  0.47344378 Validation Decoder Loss:  1.0206254
Encoder Loss:  0.23683508  || Decoder Loss:  0.46987584 Validation Decoder Loss:  1.0235777
Encoder Loss:  0.23667423  || Decoder Loss:  0.46992844 Validation Decoder Loss:  1.0197203
Encoder Loss:  0.23458928  || Decoder Loss:  0.4653104 Validation Decoder Loss:  1.008996
Encoder Loss:  0.22845362  || Decoder Loss:  0.45270398 Validation Decoder Loss:  0.9895762
Encoder Loss:  0.2543258  || Decoder Loss:  0.5216146 Validation Decoder Loss:  0.9857986
Encoder Loss:  0.2517641  || Decoder Loss:  0.51422304 Validation Decoder Loss:  0.9894943
Encoder Loss:  0.25123602  || Decoder Loss:  0.51223016 Validation Decoder Loss:  0.9998759
Encoder Loss:  0.24938112  || Decoder Loss:  0.51018643 Validation Decoder Loss:  1.0089068
Encoder Loss:  0.24781169  || Decoder Loss:  0.5103746 Validation Decoder Loss:  0.99703336
Encoder Loss:  0.24677254  || Decoder Loss:  0.5060888 Validation Decoder Loss:  0.99746436
Encoder Loss:  0.24232866  || Decoder Loss:  0.49433565 Validation Decoder Loss:  0.9938633
Encoder Loss:  0.23014934  || Decoder Loss:  0.46100548 Validation Decoder Loss:  0.9765204
Encoder Loss:  0.22346649  || Decoder Loss:  0.44454017 Validation Decoder Loss:  0.97913754
Encoder Loss:  0.21906458  || Decoder Loss:  0.43264338 Validation Decoder Loss:  0.93287295
Encoder Loss:  0.2192135  || Decoder Loss:  0.43352386 Validation Decoder Loss:  0.9505984
Encoder Loss:  0.22954299  || Decoder Loss:  0.46237656 Validation Decoder Loss:  0.96457607
Encoder Loss:  0.23045804  || Decoder Loss:  0.4662774 Validation Decoder Loss:  0.95926505
Encoder Loss:  0.22887208  || Decoder Loss:  0.4648822 Validation Decoder Loss:  0.9633159
Encoder Loss:  0.22640418  || Decoder Loss:  0.45796424 Validation Decoder Loss:  0.9566096
Encoder Loss:  0.22164422  || Decoder Loss:  0.4445793 Validation Decoder Loss:  0.9160839
Encoder Loss:  0.24121624  || Decoder Loss:  0.4991133 Validation Decoder Loss:  0.98512304
Encoder Loss:  0.23165403  || Decoder Loss:  0.47439325 Validation Decoder Loss:  0.91942257
Encoder Loss:  0.17070279  || Decoder Loss:  0.30973879 Validation Decoder Loss:  0.6062391
Encoder Loss:  0.18060818  || Decoder Loss:  0.33413145 Validation Decoder Loss:  0.90017796
Model: siamese_net_lr_0.9168370869969841 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.90017796
Model: "sequential_267"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_89 (Conv3DT (None, 122, 10, 20, 1)    355       
_________________________________________________________________
reshape_89 (Reshape)         (None, 1220, 20, 1)       0         
=================================================================
Total params: 355
Trainable params: 355
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_268"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_89 (Conv2D)           (None, 1220, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_269"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_89 (Conv2DT (None, 2607, 20, 1)       1389      
=================================================================
Total params: 1,389
Trainable params: 1,389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2711833  || Decoder Loss:  0.36848724 Validation Decoder Loss:  1.5337803
Encoder Loss:  0.2687627  || Decoder Loss:  0.50530297 Validation Decoder Loss:  1.3063707
Encoder Loss:  0.24490592  || Decoder Loss:  0.5334398 Validation Decoder Loss:  1.1801302
Encoder Loss:  0.21957424  || Decoder Loss:  0.48431376 Validation Decoder Loss:  1.2559116
Encoder Loss:  0.23067258  || Decoder Loss:  0.47946423 Validation Decoder Loss:  1.2213615
Encoder Loss:  0.23362462  || Decoder Loss:  0.48436886 Validation Decoder Loss:  1.1447132
Encoder Loss:  0.21270601  || Decoder Loss:  0.47049654 Validation Decoder Loss:  1.2181504
Encoder Loss:  0.21682692  || Decoder Loss:  0.46402857 Validation Decoder Loss:  1.2477131
Encoder Loss:  0.22606204  || Decoder Loss:  0.48432153 Validation Decoder Loss:  1.1841193
Encoder Loss:  0.2110154  || Decoder Loss:  0.46524483 Validation Decoder Loss:  1.2566155
Encoder Loss:  0.21699092  || Decoder Loss:  0.4711201 Validation Decoder Loss:  1.2814546
Encoder Loss:  0.21122599  || Decoder Loss:  0.46058586 Validation Decoder Loss:  1.2877378
Encoder Loss:  0.21129131  || Decoder Loss:  0.4622231 Validation Decoder Loss:  1.2750735
Encoder Loss:  0.20280446  || Decoder Loss:  0.44153783 Validation Decoder Loss:  1.2821951
Encoder Loss:  0.21930745  || Decoder Loss:  0.48051506 Validation Decoder Loss:  1.1814069
Encoder Loss:  0.19575192  || Decoder Loss:  0.42959532 Validation Decoder Loss:  1.2977402
Encoder Loss:  0.20483175  || Decoder Loss:  0.44145617 Validation Decoder Loss:  1.2013502
Encoder Loss:  0.19564022  || Decoder Loss:  0.42534164 Validation Decoder Loss:  1.2264886
Encoder Loss:  0.19735536  || Decoder Loss:  0.4268999 Validation Decoder Loss:  1.1951971
Encoder Loss:  0.19213709  || Decoder Loss:  0.4163316 Validation Decoder Loss:  1.1802268
Encoder Loss:  0.19526058  || Decoder Loss:  0.42155308 Validation Decoder Loss:  1.1836989
Encoder Loss:  0.19387355  || Decoder Loss:  0.42190564 Validation Decoder Loss:  1.1339278
Encoder Loss:  0.19873296  || Decoder Loss:  0.44938055 Validation Decoder Loss:  1.167556
Encoder Loss:  0.19164656  || Decoder Loss:  0.4689838 Validation Decoder Loss:  1.0420368
Encoder Loss:  0.1634344  || Decoder Loss:  0.39424402 Validation Decoder Loss:  1.0673505
Encoder Loss:  0.16384512  || Decoder Loss:  0.3877317 Validation Decoder Loss:  1.057396
Encoder Loss:  0.1535651  || Decoder Loss:  0.35931957 Validation Decoder Loss:  1.0469382
Encoder Loss:  0.15549596  || Decoder Loss:  0.3904851 Validation Decoder Loss:  1.0020757
Encoder Loss:  0.14580528  || Decoder Loss:  0.36331448 Validation Decoder Loss:  0.9806846
Encoder Loss:  0.14067687  || Decoder Loss:  0.34833577 Validation Decoder Loss:  0.9449133
Encoder Loss:  0.1370941  || Decoder Loss:  0.32797426 Validation Decoder Loss:  0.9132774
Encoder Loss:  0.1333166  || Decoder Loss:  0.30047297 Validation Decoder Loss:  0.85247064
Encoder Loss:  0.14729697  || Decoder Loss:  0.3628794 Validation Decoder Loss:  0.7941942
Encoder Loss:  0.12118416  || Decoder Loss:  0.2753766 Validation Decoder Loss:  0.88434875
Encoder Loss:  0.10433508  || Decoder Loss:  0.22344798 Validation Decoder Loss:  0.71370745
Encoder Loss:  0.092887454  || Decoder Loss:  0.17906004 Validation Decoder Loss:  0.6334325
Encoder Loss:  0.083574176  || Decoder Loss:  0.14455885 Validation Decoder Loss:  0.46055254
Encoder Loss:  0.06516394  || Decoder Loss:  0.090425685 Validation Decoder Loss:  0.39303398
Encoder Loss:  0.059511945  || Decoder Loss:  0.06971546 Validation Decoder Loss:  0.38027173
Encoder Loss:  0.056398656  || Decoder Loss:  0.05947113 Validation Decoder Loss:  0.37688768
Model: siamese_net_lr_0.5542464003546944 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37688765
Model: "sequential_270"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_90 (Conv3DT (None, 237, 10, 20, 1)    97        
_________________________________________________________________
reshape_90 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_271"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_90 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_272"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_90 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06868972  || Decoder Loss:  0.045737747 Validation Decoder Loss:  0.3502105
Encoder Loss:  0.06992317  || Decoder Loss:  0.042374015 Validation Decoder Loss:  0.3503828
Encoder Loss:  0.069897614  || Decoder Loss:  0.04232871 Validation Decoder Loss:  0.3503579
Encoder Loss:  0.06986313  || Decoder Loss:  0.04229111 Validation Decoder Loss:  0.35027972
Encoder Loss:  0.06982742  || Decoder Loss:  0.04225311 Validation Decoder Loss:  0.35018033
Encoder Loss:  0.069790244  || Decoder Loss:  0.042213753 Validation Decoder Loss:  0.35007095
Encoder Loss:  0.06975193  || Decoder Loss:  0.04217329 Validation Decoder Loss:  0.34995624
Encoder Loss:  0.06971295  || Decoder Loss:  0.042132184 Validation Decoder Loss:  0.34983838
Encoder Loss:  0.06967375  || Decoder Loss:  0.042090908 Validation Decoder Loss:  0.3497184
Encoder Loss:  0.06963468  || Decoder Loss:  0.042049866 Validation Decoder Loss:  0.34959668
Encoder Loss:  0.06959608  || Decoder Loss:  0.04200939 Validation Decoder Loss:  0.34947336
Encoder Loss:  0.069558196  || Decoder Loss:  0.04196976 Validation Decoder Loss:  0.34934822
Encoder Loss:  0.06952124  || Decoder Loss:  0.041931204 Validation Decoder Loss:  0.3492211
Encoder Loss:  0.06948545  || Decoder Loss:  0.041893966 Validation Decoder Loss:  0.34909177
Encoder Loss:  0.06945096  || Decoder Loss:  0.041858237 Validation Decoder Loss:  0.34895992
Encoder Loss:  0.069418006  || Decoder Loss:  0.041824237 Validation Decoder Loss:  0.34882554
Encoder Loss:  0.06938677  || Decoder Loss:  0.041792173 Validation Decoder Loss:  0.3486886
Encoder Loss:  0.06935745  || Decoder Loss:  0.041762266 Validation Decoder Loss:  0.3485496
Encoder Loss:  0.06933023  || Decoder Loss:  0.0417347 Validation Decoder Loss:  0.34840924
Encoder Loss:  0.06930523  || Decoder Loss:  0.041709647 Validation Decoder Loss:  0.3482688
Encoder Loss:  0.06928256  || Decoder Loss:  0.041687213 Validation Decoder Loss:  0.3481304
Encoder Loss:  0.069262244  || Decoder Loss:  0.0416674 Validation Decoder Loss:  0.34799665
Encoder Loss:  0.06924412  || Decoder Loss:  0.041650098 Validation Decoder Loss:  0.34787107
Encoder Loss:  0.069227986  || Decoder Loss:  0.041635063 Validation Decoder Loss:  0.34775746
Encoder Loss:  0.06921356  || Decoder Loss:  0.041621998 Validation Decoder Loss:  0.34765935
Encoder Loss:  0.06920059  || Decoder Loss:  0.041610643 Validation Decoder Loss:  0.34757924
Encoder Loss:  0.06918891  || Decoder Loss:  0.041600846 Validation Decoder Loss:  0.3475178
Encoder Loss:  0.06917858  || Decoder Loss:  0.041592658 Validation Decoder Loss:  0.34747294
Encoder Loss:  0.069169834  || Decoder Loss:  0.041586373 Validation Decoder Loss:  0.34744066
Encoder Loss:  0.069163136  || Decoder Loss:  0.04158246 Validation Decoder Loss:  0.34741575
Encoder Loss:  0.06915898  || Decoder Loss:  0.041581497 Validation Decoder Loss:  0.34739313
Encoder Loss:  0.06915789  || Decoder Loss:  0.041584034 Validation Decoder Loss:  0.34736893
Encoder Loss:  0.06916014  || Decoder Loss:  0.041590407 Validation Decoder Loss:  0.34734
Encoder Loss:  0.06916569  || Decoder Loss:  0.04160057 Validation Decoder Loss:  0.34730315
Encoder Loss:  0.069174066  || Decoder Loss:  0.04161405 Validation Decoder Loss:  0.3472548
Encoder Loss:  0.069184475  || Decoder Loss:  0.04162999 Validation Decoder Loss:  0.34719217
Encoder Loss:  0.069196045  || Decoder Loss:  0.041647494 Validation Decoder Loss:  0.3471151
Encoder Loss:  0.06920813  || Decoder Loss:  0.04166588 Validation Decoder Loss:  0.34702763
Encoder Loss:  0.069220416  || Decoder Loss:  0.041684873 Validation Decoder Loss:  0.34693596
Encoder Loss:  0.069233  || Decoder Loss:  0.0417046 Validation Decoder Loss:  0.34684658
Model: siamese_net_lr_0.7254821565364785 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34684658
Model: "sequential_273"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_91 (Conv3DT (None, 334, 5, 20, 1)     83        
_________________________________________________________________
reshape_91 (Reshape)         (None, 1670, 20, 1)       0         
=================================================================
Total params: 83
Trainable params: 83
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_274"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_91 (Conv2D)           (None, 1670, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_275"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_91 (Conv2DT (None, 2607, 20, 1)       939       
=================================================================
Total params: 939
Trainable params: 939
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24546926  || Decoder Loss:  0.20396401 Validation Decoder Loss:  1.4575837
Encoder Loss:  0.45547068  || Decoder Loss:  0.5385806 Validation Decoder Loss:  0.69631326
Encoder Loss:  0.32072628  || Decoder Loss:  0.39071772 Validation Decoder Loss:  0.606513
Encoder Loss:  0.327384  || Decoder Loss:  0.39882007 Validation Decoder Loss:  0.5462814
Encoder Loss:  0.3323731  || Decoder Loss:  0.40659112 Validation Decoder Loss:  0.8520341
Encoder Loss:  0.4004065  || Decoder Loss:  0.49818164 Validation Decoder Loss:  0.81703913
Encoder Loss:  0.37802318  || Decoder Loss:  0.4698177 Validation Decoder Loss:  0.84469026
Encoder Loss:  0.38942912  || Decoder Loss:  0.48503575 Validation Decoder Loss:  0.93522215
Encoder Loss:  0.3979773  || Decoder Loss:  0.4980446 Validation Decoder Loss:  0.75521183
Encoder Loss:  0.38223422  || Decoder Loss:  0.47740632 Validation Decoder Loss:  0.7707984
Encoder Loss:  0.35543016  || Decoder Loss:  0.44252974 Validation Decoder Loss:  0.5450846
Encoder Loss:  0.25509146  || Decoder Loss:  0.31046593 Validation Decoder Loss:  1.266859
Encoder Loss:  0.39055258  || Decoder Loss:  0.48510695 Validation Decoder Loss:  1.003554
Encoder Loss:  0.3415311  || Decoder Loss:  0.42456505 Validation Decoder Loss:  1.2964594
Encoder Loss:  0.41037968  || Decoder Loss:  0.51402813 Validation Decoder Loss:  0.92565054
Encoder Loss:  0.17004639  || Decoder Loss:  0.20224927 Validation Decoder Loss:  0.34765503
Encoder Loss:  0.071867175  || Decoder Loss:  0.07579165 Validation Decoder Loss:  0.4859922
Encoder Loss:  0.053237226  || Decoder Loss:  0.049326323 Validation Decoder Loss:  0.3759964
Encoder Loss:  0.043590307  || Decoder Loss:  0.037871256 Validation Decoder Loss:  0.3416766
Encoder Loss:  0.042342052  || Decoder Loss:  0.03428111 Validation Decoder Loss:  0.33274984
Encoder Loss:  0.04037005  || Decoder Loss:  0.033339605 Validation Decoder Loss:  0.33965665
Encoder Loss:  0.04076868  || Decoder Loss:  0.0326676 Validation Decoder Loss:  0.33339795
Encoder Loss:  0.039125282  || Decoder Loss:  0.032416094 Validation Decoder Loss:  0.33486867
Encoder Loss:  0.038686637  || Decoder Loss:  0.032106493 Validation Decoder Loss:  0.33770394
Encoder Loss:  0.039549954  || Decoder Loss:  0.032282256 Validation Decoder Loss:  0.3361006
Encoder Loss:  0.038364764  || Decoder Loss:  0.031978194 Validation Decoder Loss:  0.33936995
Encoder Loss:  0.037453137  || Decoder Loss:  0.032080803 Validation Decoder Loss:  0.33524126
Encoder Loss:  0.03704173  || Decoder Loss:  0.03197033 Validation Decoder Loss:  0.3368774
Encoder Loss:  0.03708432  || Decoder Loss:  0.031899355 Validation Decoder Loss:  0.33653957
Encoder Loss:  0.036992725  || Decoder Loss:  0.031879935 Validation Decoder Loss:  0.33695543
Encoder Loss:  0.036837928  || Decoder Loss:  0.031833712 Validation Decoder Loss:  0.33644646
Encoder Loss:  0.03691467  || Decoder Loss:  0.03191624 Validation Decoder Loss:  0.336021
Encoder Loss:  0.037215505  || Decoder Loss:  0.03193834 Validation Decoder Loss:  0.33665887
Encoder Loss:  0.036932405  || Decoder Loss:  0.03162166 Validation Decoder Loss:  0.3372288
Encoder Loss:  0.037175737  || Decoder Loss:  0.032076426 Validation Decoder Loss:  0.33938295
Encoder Loss:  0.03715437  || Decoder Loss:  0.031660296 Validation Decoder Loss:  0.3348683
Encoder Loss:  0.03688224  || Decoder Loss:  0.031802483 Validation Decoder Loss:  0.33671224
Encoder Loss:  0.036957588  || Decoder Loss:  0.03171025 Validation Decoder Loss:  0.33560997
Encoder Loss:  0.03666852  || Decoder Loss:  0.031802278 Validation Decoder Loss:  0.33669832
Encoder Loss:  0.03689365  || Decoder Loss:  0.031761028 Validation Decoder Loss:  0.33694077
Model: siamese_net_lr_0.37187883680003253 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33694077
Model: "sequential_276"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_92 (Conv3DT (None, 108, 15, 20, 1)    496       
_________________________________________________________________
reshape_92 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 496
Trainable params: 496
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_277"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_92 (Conv2D)           (None, 1620, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_278"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_92 (Conv2DT (None, 2607, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36695054  || Decoder Loss:  0.4344793 Validation Decoder Loss:  1.3877105
Encoder Loss:  0.34556872  || Decoder Loss:  0.48716575 Validation Decoder Loss:  1.1544745
Encoder Loss:  0.35631126  || Decoder Loss:  0.52875054 Validation Decoder Loss:  0.85786754
Encoder Loss:  0.34388572  || Decoder Loss:  0.5073769 Validation Decoder Loss:  0.95273066
Encoder Loss:  0.35243347  || Decoder Loss:  0.5249989 Validation Decoder Loss:  0.8784997
Encoder Loss:  0.34158576  || Decoder Loss:  0.5072666 Validation Decoder Loss:  1.0013152
Encoder Loss:  0.34929737  || Decoder Loss:  0.5260748 Validation Decoder Loss:  0.8105666
Encoder Loss:  0.31607005  || Decoder Loss:  0.46952948 Validation Decoder Loss:  0.9904208
Encoder Loss:  0.3349188  || Decoder Loss:  0.50317836 Validation Decoder Loss:  0.8064269
Encoder Loss:  0.31608012  || Decoder Loss:  0.4688602 Validation Decoder Loss:  0.70856065
Encoder Loss:  0.30631325  || Decoder Loss:  0.45443514 Validation Decoder Loss:  0.85776985
Encoder Loss:  0.28811526  || Decoder Loss:  0.42794248 Validation Decoder Loss:  0.42713037
Encoder Loss:  0.32260874  || Decoder Loss:  0.47917715 Validation Decoder Loss:  1.0371821
Encoder Loss:  0.3229054  || Decoder Loss:  0.49019435 Validation Decoder Loss:  0.92634684
Encoder Loss:  0.28960377  || Decoder Loss:  0.43480486 Validation Decoder Loss:  0.9619826
Encoder Loss:  0.34210175  || Decoder Loss:  0.51335955 Validation Decoder Loss:  0.84051543
Encoder Loss:  0.3115419  || Decoder Loss:  0.45654023 Validation Decoder Loss:  0.8006586
Encoder Loss:  0.2937821  || Decoder Loss:  0.43460876 Validation Decoder Loss:  1.0214379
Encoder Loss:  0.3140203  || Decoder Loss:  0.47389895 Validation Decoder Loss:  0.97302794
Encoder Loss:  0.3244499  || Decoder Loss:  0.48733962 Validation Decoder Loss:  0.9554306
Encoder Loss:  0.318248  || Decoder Loss:  0.4811343 Validation Decoder Loss:  0.9803908
Encoder Loss:  0.32036108  || Decoder Loss:  0.48463088 Validation Decoder Loss:  0.9859469
Encoder Loss:  0.31918925  || Decoder Loss:  0.47988373 Validation Decoder Loss:  1.0126928
Encoder Loss:  0.31917208  || Decoder Loss:  0.48069814 Validation Decoder Loss:  0.99677634
Encoder Loss:  0.3189122  || Decoder Loss:  0.47883475 Validation Decoder Loss:  0.9465922
Encoder Loss:  0.31285512  || Decoder Loss:  0.47130987 Validation Decoder Loss:  0.9371308
Encoder Loss:  0.31049755  || Decoder Loss:  0.46536 Validation Decoder Loss:  1.032264
Encoder Loss:  0.29981682  || Decoder Loss:  0.44887543 Validation Decoder Loss:  0.8284055
Encoder Loss:  0.21367265  || Decoder Loss:  0.30893707 Validation Decoder Loss:  0.6879026
Encoder Loss:  0.17275742  || Decoder Loss:  0.24315535 Validation Decoder Loss:  0.46678942
Encoder Loss:  0.16977069  || Decoder Loss:  0.24104539 Validation Decoder Loss:  0.37132603
Encoder Loss:  0.111722976  || Decoder Loss:  0.14289983 Validation Decoder Loss:  0.6624845
Encoder Loss:  0.16617146  || Decoder Loss:  0.23301683 Validation Decoder Loss:  0.36775726
Encoder Loss:  0.11251407  || Decoder Loss:  0.1484223 Validation Decoder Loss:  0.53452283
Encoder Loss:  0.100726075  || Decoder Loss:  0.13012014 Validation Decoder Loss:  0.5230905
Encoder Loss:  0.12142511  || Decoder Loss:  0.16382837 Validation Decoder Loss:  0.5470464
Encoder Loss:  0.1330845  || Decoder Loss:  0.18157093 Validation Decoder Loss:  0.43529356
Encoder Loss:  0.09399985  || Decoder Loss:  0.119390115 Validation Decoder Loss:  0.45407403
Encoder Loss:  0.07933705  || Decoder Loss:  0.09518954 Validation Decoder Loss:  0.4061557
Encoder Loss:  0.060296595  || Decoder Loss:  0.06466215 Validation Decoder Loss:  0.35458457
Model: siamese_net_lr_0.3991417821718377 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35458457
Model: "sequential_279"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_93 (Conv3DT (None, 86, 20, 20, 1)     369       
_________________________________________________________________
reshape_93 (Reshape)         (None, 1720, 20, 1)       0         
=================================================================
Total params: 369
Trainable params: 369
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_280"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_93 (Conv2D)           (None, 1720, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_281"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_93 (Conv2DT (None, 2607, 20, 1)       889       
=================================================================
Total params: 889
Trainable params: 889
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3256919  || Decoder Loss:  0.49665213 Validation Decoder Loss:  1.5160463
Encoder Loss:  0.223636  || Decoder Loss:  0.59569454 Validation Decoder Loss:  1.160109
Encoder Loss:  0.1763956  || Decoder Loss:  0.4696558 Validation Decoder Loss:  0.67448807
Encoder Loss:  0.17598575  || Decoder Loss:  0.4747145 Validation Decoder Loss:  0.99257
Encoder Loss:  0.17393216  || Decoder Loss:  0.50976473 Validation Decoder Loss:  0.79694396
Encoder Loss:  0.17352843  || Decoder Loss:  0.49006563 Validation Decoder Loss:  0.7205782
Encoder Loss:  0.1639782  || Decoder Loss:  0.46737295 Validation Decoder Loss:  0.56534123
Encoder Loss:  0.16482228  || Decoder Loss:  0.4556181 Validation Decoder Loss:  1.1060486
Encoder Loss:  0.15384549  || Decoder Loss:  0.4487939 Validation Decoder Loss:  0.64610684
Encoder Loss:  0.15999287  || Decoder Loss:  0.48344296 Validation Decoder Loss:  0.95876026
Encoder Loss:  0.1624429  || Decoder Loss:  0.4960523 Validation Decoder Loss:  0.97818094
Encoder Loss:  0.16425993  || Decoder Loss:  0.4954592 Validation Decoder Loss:  0.90281236
Encoder Loss:  0.17170128  || Decoder Loss:  0.5039589 Validation Decoder Loss:  0.84994
Encoder Loss:  0.17840114  || Decoder Loss:  0.4936082 Validation Decoder Loss:  1.0259829
Encoder Loss:  0.16762654  || Decoder Loss:  0.50258374 Validation Decoder Loss:  1.0713578
Encoder Loss:  0.17220695  || Decoder Loss:  0.50235593 Validation Decoder Loss:  0.8972689
Encoder Loss:  0.16884595  || Decoder Loss:  0.498694 Validation Decoder Loss:  0.96454525
Encoder Loss:  0.16185458  || Decoder Loss:  0.4948273 Validation Decoder Loss:  0.94995594
Encoder Loss:  0.1692439  || Decoder Loss:  0.50020814 Validation Decoder Loss:  0.92970043
Encoder Loss:  0.1651788  || Decoder Loss:  0.4856849 Validation Decoder Loss:  0.9808254
Encoder Loss:  0.16418804  || Decoder Loss:  0.48605645 Validation Decoder Loss:  1.0839723
Encoder Loss:  0.16591437  || Decoder Loss:  0.49889776 Validation Decoder Loss:  1.0479774
Encoder Loss:  0.15540335  || Decoder Loss:  0.45943096 Validation Decoder Loss:  1.0697163
Encoder Loss:  0.15802756  || Decoder Loss:  0.45763266 Validation Decoder Loss:  0.95555866
Encoder Loss:  0.16601174  || Decoder Loss:  0.49296203 Validation Decoder Loss:  0.9515867
Encoder Loss:  0.1660044  || Decoder Loss:  0.4806409 Validation Decoder Loss:  0.94068754
Encoder Loss:  0.15117475  || Decoder Loss:  0.44228327 Validation Decoder Loss:  0.7992338
Encoder Loss:  0.1401402  || Decoder Loss:  0.4153161 Validation Decoder Loss:  0.8762711
Encoder Loss:  0.14020601  || Decoder Loss:  0.41305655 Validation Decoder Loss:  0.9693441
Encoder Loss:  0.1597417  || Decoder Loss:  0.4875789 Validation Decoder Loss:  0.9693484
Encoder Loss:  0.16060308  || Decoder Loss:  0.48963773 Validation Decoder Loss:  0.9695369
Encoder Loss:  0.16195318  || Decoder Loss:  0.49009147 Validation Decoder Loss:  0.97785574
Encoder Loss:  0.15694353  || Decoder Loss:  0.4893319 Validation Decoder Loss:  0.9726044
Encoder Loss:  0.15618327  || Decoder Loss:  0.4880192 Validation Decoder Loss:  0.9717461
Encoder Loss:  0.15577863  || Decoder Loss:  0.4871914 Validation Decoder Loss:  0.97117984
Encoder Loss:  0.15528043  || Decoder Loss:  0.48556226 Validation Decoder Loss:  0.96402425
Encoder Loss:  0.15392119  || Decoder Loss:  0.47984716 Validation Decoder Loss:  0.95205534
Encoder Loss:  0.15036596  || Decoder Loss:  0.46488476 Validation Decoder Loss:  0.87228006
Encoder Loss:  0.14113425  || Decoder Loss:  0.42576554 Validation Decoder Loss:  0.96947217
Encoder Loss:  0.15343846  || Decoder Loss:  0.47789624 Validation Decoder Loss:  0.9722366
Model: siamese_net_lr_0.3843930459621142 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9722366
Model: "sequential_282"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_94 (Conv3DT (None, 79, 30, 20, 1)     353       
_________________________________________________________________
reshape_94 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 353
Trainable params: 353
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_283"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_94 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_284"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_94 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.04513647  || Decoder Loss:  0.04513647 Validation Decoder Loss:  0.3524223
Encoder Loss:  0.04441421  || Decoder Loss:  0.04441421 Validation Decoder Loss:  0.35249943
Encoder Loss:  0.04419739  || Decoder Loss:  0.04419739 Validation Decoder Loss:  0.35254848
Encoder Loss:  0.04392895  || Decoder Loss:  0.04392895 Validation Decoder Loss:  0.3519947
Encoder Loss:  0.043589484  || Decoder Loss:  0.043589484 Validation Decoder Loss:  0.35067993
Encoder Loss:  0.043114945  || Decoder Loss:  0.043114945 Validation Decoder Loss:  0.34828985
Encoder Loss:  0.042291574  || Decoder Loss:  0.042291574 Validation Decoder Loss:  0.3432592
Encoder Loss:  0.03972585  || Decoder Loss:  0.03972585 Validation Decoder Loss:  0.3411451
Encoder Loss:  0.034532696  || Decoder Loss:  0.034532696 Validation Decoder Loss:  0.33369163
Encoder Loss:  0.033736773  || Decoder Loss:  0.033736773 Validation Decoder Loss:  0.3350575
Encoder Loss:  0.033637024  || Decoder Loss:  0.033637024 Validation Decoder Loss:  0.33554554
Encoder Loss:  0.033575784  || Decoder Loss:  0.033575784 Validation Decoder Loss:  0.33555686
Encoder Loss:  0.033527102  || Decoder Loss:  0.033527102 Validation Decoder Loss:  0.33557522
Encoder Loss:  0.033482507  || Decoder Loss:  0.033482507 Validation Decoder Loss:  0.33574504
Encoder Loss:  0.033440553  || Decoder Loss:  0.033440553 Validation Decoder Loss:  0.33597293
Encoder Loss:  0.033400387  || Decoder Loss:  0.033400387 Validation Decoder Loss:  0.33613878
Encoder Loss:  0.033361815  || Decoder Loss:  0.033361815 Validation Decoder Loss:  0.33645815
Encoder Loss:  0.03332341  || Decoder Loss:  0.03332341 Validation Decoder Loss:  0.3362411
Encoder Loss:  0.03328273  || Decoder Loss:  0.03328273 Validation Decoder Loss:  0.33579662
Encoder Loss:  0.03324904  || Decoder Loss:  0.03324904 Validation Decoder Loss:  0.33747816
Encoder Loss:  0.033236507  || Decoder Loss:  0.033236507 Validation Decoder Loss:  0.33626065
Encoder Loss:  0.033198036  || Decoder Loss:  0.033198036 Validation Decoder Loss:  0.34322074
Encoder Loss:  0.040447146  || Decoder Loss:  0.040447146 Validation Decoder Loss:  0.35273603
Encoder Loss:  0.04432414  || Decoder Loss:  0.04432414 Validation Decoder Loss:  0.3531356
Encoder Loss:  0.04435217  || Decoder Loss:  0.04435217 Validation Decoder Loss:  0.35311562
Encoder Loss:  0.044325504  || Decoder Loss:  0.044325504 Validation Decoder Loss:  0.35307258
Encoder Loss:  0.04429483  || Decoder Loss:  0.04429483 Validation Decoder Loss:  0.353027
Encoder Loss:  0.0442632  || Decoder Loss:  0.0442632 Validation Decoder Loss:  0.3529803
Encoder Loss:  0.04423079  || Decoder Loss:  0.04423079 Validation Decoder Loss:  0.3529326
Encoder Loss:  0.044197615  || Decoder Loss:  0.044197615 Validation Decoder Loss:  0.35288393
Encoder Loss:  0.04416365  || Decoder Loss:  0.04416365 Validation Decoder Loss:  0.3528342
Encoder Loss:  0.04412886  || Decoder Loss:  0.04412886 Validation Decoder Loss:  0.3527834
Encoder Loss:  0.044093236  || Decoder Loss:  0.044093236 Validation Decoder Loss:  0.3527315
Encoder Loss:  0.04405673  || Decoder Loss:  0.04405673 Validation Decoder Loss:  0.35267842
Encoder Loss:  0.044019308  || Decoder Loss:  0.044019308 Validation Decoder Loss:  0.35262418
Encoder Loss:  0.043980937  || Decoder Loss:  0.043980937 Validation Decoder Loss:  0.3525687
Encoder Loss:  0.04394158  || Decoder Loss:  0.04394158 Validation Decoder Loss:  0.35251182
Encoder Loss:  0.043901153  || Decoder Loss:  0.043901153 Validation Decoder Loss:  0.35245362
Encoder Loss:  0.043859635  || Decoder Loss:  0.043859635 Validation Decoder Loss:  0.3523939
Encoder Loss:  0.043816943  || Decoder Loss:  0.043816943 Validation Decoder Loss:  0.35233268
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35233265
Model: "sequential_285"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_95 (Conv3DT (None, 324, 5, 20, 1)     10        
_________________________________________________________________
reshape_95 (Reshape)         (None, 1620, 20, 1)       0         
=================================================================
Total params: 10
Trainable params: 10
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_286"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_95 (Conv2D)           (None, 1620, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_287"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_95 (Conv2DT (None, 2607, 20, 1)       989       
=================================================================
Total params: 989
Trainable params: 989
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.060366154  || Decoder Loss:  0.060366154 Validation Decoder Loss:  0.33885515
Encoder Loss:  0.04888986  || Decoder Loss:  0.04888986 Validation Decoder Loss:  0.3470905
Encoder Loss:  0.063641764  || Decoder Loss:  0.063641764 Validation Decoder Loss:  0.3529584
Encoder Loss:  0.06371008  || Decoder Loss:  0.06371008 Validation Decoder Loss:  0.34550512
Encoder Loss:  0.05668468  || Decoder Loss:  0.05668468 Validation Decoder Loss:  0.34119216
Encoder Loss:  0.05282068  || Decoder Loss:  0.05282068 Validation Decoder Loss:  0.33822486
Encoder Loss:  0.045862738  || Decoder Loss:  0.045862738 Validation Decoder Loss:  0.34104067
Encoder Loss:  0.035130627  || Decoder Loss:  0.035130627 Validation Decoder Loss:  0.34589583
Encoder Loss:  0.03070901  || Decoder Loss:  0.03070901 Validation Decoder Loss:  0.35246876
Encoder Loss:  0.030083217  || Decoder Loss:  0.030083217 Validation Decoder Loss:  0.3440503
Encoder Loss:  0.029820485  || Decoder Loss:  0.029820485 Validation Decoder Loss:  0.3510915
Encoder Loss:  0.029712534  || Decoder Loss:  0.029712534 Validation Decoder Loss:  0.35114914
Encoder Loss:  0.029677572  || Decoder Loss:  0.029677572 Validation Decoder Loss:  0.3506628
Encoder Loss:  0.029607274  || Decoder Loss:  0.029607274 Validation Decoder Loss:  0.3545654
Encoder Loss:  0.029662525  || Decoder Loss:  0.029662525 Validation Decoder Loss:  0.33058357
Encoder Loss:  0.06923197  || Decoder Loss:  0.06923197 Validation Decoder Loss:  0.35260838
Encoder Loss:  0.0751226  || Decoder Loss:  0.0751226 Validation Decoder Loss:  0.3536245
Encoder Loss:  0.073303744  || Decoder Loss:  0.073303744 Validation Decoder Loss:  0.35375464
Encoder Loss:  0.07147694  || Decoder Loss:  0.07147694 Validation Decoder Loss:  0.35333616
Encoder Loss:  0.06966595  || Decoder Loss:  0.06966595 Validation Decoder Loss:  0.35247067
Encoder Loss:  0.06783663  || Decoder Loss:  0.06783663 Validation Decoder Loss:  0.35122734
Encoder Loss:  0.0659591  || Decoder Loss:  0.0659591 Validation Decoder Loss:  0.34966433
Encoder Loss:  0.06401561  || Decoder Loss:  0.06401561 Validation Decoder Loss:  0.347849
Encoder Loss:  0.062015504  || Decoder Loss:  0.062015504 Validation Decoder Loss:  0.34589413
Encoder Loss:  0.060029563  || Decoder Loss:  0.060029563 Validation Decoder Loss:  0.34401265
Encoder Loss:  0.058235068  || Decoder Loss:  0.058235068 Validation Decoder Loss:  0.34251606
Encoder Loss:  0.056852702  || Decoder Loss:  0.056852702 Validation Decoder Loss:  0.34151208
Encoder Loss:  0.05582983  || Decoder Loss:  0.05582983 Validation Decoder Loss:  0.34066302
Encoder Loss:  0.05482859  || Decoder Loss:  0.05482859 Validation Decoder Loss:  0.33984607
Encoder Loss:  0.05367006  || Decoder Loss:  0.05367006 Validation Decoder Loss:  0.3390446
Encoder Loss:  0.052277878  || Decoder Loss:  0.052277878 Validation Decoder Loss:  0.33815965
Encoder Loss:  0.050531674  || Decoder Loss:  0.050531674 Validation Decoder Loss:  0.33722568
Encoder Loss:  0.048214555  || Decoder Loss:  0.048214555 Validation Decoder Loss:  0.33634415
Encoder Loss:  0.044915687  || Decoder Loss:  0.044915687 Validation Decoder Loss:  0.33588487
Encoder Loss:  0.039949425  || Decoder Loss:  0.039949425 Validation Decoder Loss:  0.33707282
Encoder Loss:  0.03428161  || Decoder Loss:  0.03428161 Validation Decoder Loss:  0.34127533
Encoder Loss:  0.031499222  || Decoder Loss:  0.031499222 Validation Decoder Loss:  0.34310114
Encoder Loss:  0.030465879  || Decoder Loss:  0.030465879 Validation Decoder Loss:  0.34286976
Encoder Loss:  0.030074526  || Decoder Loss:  0.030074526 Validation Decoder Loss:  0.34260172
Encoder Loss:  0.02991597  || Decoder Loss:  0.02991597 Validation Decoder Loss:  0.3426032
Model: siamese_net_lr_0.4128551723163871 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3426032
Model: "sequential_288"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_96 (Conv3DT (None, 158, 15, 20, 1)    286       
_________________________________________________________________
reshape_96 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 286
Trainable params: 286
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_289"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_96 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_290"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_96 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.34558624
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.04526179 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.34558624
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.34558624
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Encoder Loss:  0.44633332  || Decoder Loss:  0.045261785 Validation Decoder Loss:  0.3455862
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3455862
Model: "sequential_291"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_97 (Conv3DT (None, 158, 15, 20, 1)    97        
_________________________________________________________________
reshape_97 (Reshape)         (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_292"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_97 (Conv2D)           (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_293"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_97 (Conv2DT (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021365
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021365
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.04232487  || Decoder Loss:  0.04232487 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021365
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021365
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.04232488  || Decoder Loss:  0.04232488 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.3502137
Encoder Loss:  0.042324882  || Decoder Loss:  0.042324882 Validation Decoder Loss:  0.35021368
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3502137
Model: "sequential_294"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_98 (Conv3DT (None, 70, 21, 20, 1)     120       
_________________________________________________________________
reshape_98 (Reshape)         (None, 1470, 20, 1)       0         
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_295"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_98 (Conv2D)           (None, 1470, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_296"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_98 (Conv2DT (None, 2607, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.5765073  || Decoder Loss:  0.788108 Validation Decoder Loss:  1.6029146
Encoder Loss:  0.4952928  || Decoder Loss:  0.5633299 Validation Decoder Loss:  0.36878225
Encoder Loss:  0.28090522  || Decoder Loss:  0.069890626 Validation Decoder Loss:  0.35910723
Encoder Loss:  0.27964914  || Decoder Loss:  0.07081179 Validation Decoder Loss:  0.35821956
Encoder Loss:  0.2751081  || Decoder Loss:  0.069499075 Validation Decoder Loss:  0.35787684
Encoder Loss:  0.24509089  || Decoder Loss:  0.07004704 Validation Decoder Loss:  1.3402683
Encoder Loss:  0.28142738  || Decoder Loss:  0.5129769 Validation Decoder Loss:  0.9521109
Encoder Loss:  0.23828746  || Decoder Loss:  0.45176134 Validation Decoder Loss:  1.3917346
Encoder Loss:  0.25180662  || Decoder Loss:  0.49050996 Validation Decoder Loss:  1.2767291
Encoder Loss:  0.24791773  || Decoder Loss:  0.4788971 Validation Decoder Loss:  0.9945934
Encoder Loss:  0.25325435  || Decoder Loss:  0.4936198 Validation Decoder Loss:  1.082231
Encoder Loss:  0.24600014  || Decoder Loss:  0.48123306 Validation Decoder Loss:  1.0755514
Encoder Loss:  0.23709397  || Decoder Loss:  0.4635698 Validation Decoder Loss:  1.0584872
Encoder Loss:  0.25705275  || Decoder Loss:  0.499411 Validation Decoder Loss:  1.0734713
Encoder Loss:  0.25236753  || Decoder Loss:  0.5009887 Validation Decoder Loss:  1.0315819
Encoder Loss:  0.24423009  || Decoder Loss:  0.48672822 Validation Decoder Loss:  0.9995179
Encoder Loss:  0.2428748  || Decoder Loss:  0.48679352 Validation Decoder Loss:  0.9223285
Encoder Loss:  0.24429007  || Decoder Loss:  0.48374104 Validation Decoder Loss:  1.1565024
Encoder Loss:  0.25631315  || Decoder Loss:  0.49575055 Validation Decoder Loss:  1.3732061
Encoder Loss:  0.26822355  || Decoder Loss:  0.5091016 Validation Decoder Loss:  1.1045742
Encoder Loss:  0.25909352  || Decoder Loss:  0.49144593 Validation Decoder Loss:  1.0582124
Encoder Loss:  0.25087118  || Decoder Loss:  0.487904 Validation Decoder Loss:  0.9749238
Encoder Loss:  0.2438849  || Decoder Loss:  0.4847257 Validation Decoder Loss:  0.98589325
Encoder Loss:  0.23945297  || Decoder Loss:  0.47485718 Validation Decoder Loss:  0.96610475
Encoder Loss:  0.22453491  || Decoder Loss:  0.44281158 Validation Decoder Loss:  0.8791471
Encoder Loss:  0.21770047  || Decoder Loss:  0.4187311 Validation Decoder Loss:  0.9270916
Encoder Loss:  0.24924852  || Decoder Loss:  0.4853456 Validation Decoder Loss:  1.1182835
Encoder Loss:  0.24553306  || Decoder Loss:  0.48582137 Validation Decoder Loss:  0.9341724
Encoder Loss:  0.22522347  || Decoder Loss:  0.4452583 Validation Decoder Loss:  0.8390856
Encoder Loss:  0.20515579  || Decoder Loss:  0.3965172 Validation Decoder Loss:  0.8771428
Encoder Loss:  0.22756565  || Decoder Loss:  0.45277613 Validation Decoder Loss:  0.98813105
Encoder Loss:  0.2452107  || Decoder Loss:  0.48731345 Validation Decoder Loss:  0.9916321
Encoder Loss:  0.2451856  || Decoder Loss:  0.48743877 Validation Decoder Loss:  0.9782475
Encoder Loss:  0.24394907  || Decoder Loss:  0.4865492 Validation Decoder Loss:  0.97418225
Encoder Loss:  0.24244088  || Decoder Loss:  0.48580658 Validation Decoder Loss:  0.9840181
Encoder Loss:  0.2403642  || Decoder Loss:  0.48429683 Validation Decoder Loss:  0.98118854
Encoder Loss:  0.24067312  || Decoder Loss:  0.48151776 Validation Decoder Loss:  0.98339105
Encoder Loss:  0.2392029  || Decoder Loss:  0.47151607 Validation Decoder Loss:  0.9085053
Encoder Loss:  0.19840391  || Decoder Loss:  0.37659386 Validation Decoder Loss:  0.60816765
Encoder Loss:  0.20860483  || Decoder Loss:  0.40397713 Validation Decoder Loss:  0.92445034
Model: siamese_net_lr_0.5650308390235482 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.92445034
Model: "sequential_297"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_99 (Conv3DT (None, 111, 20, 20, 1)    577       
_________________________________________________________________
reshape_99 (Reshape)         (None, 2220, 20, 1)       0         
=================================================================
Total params: 577
Trainable params: 577
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_298"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_99 (Conv2D)           (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_299"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_99 (Conv2DT (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.054866653  || Decoder Loss:  0.054866653 Validation Decoder Loss:  0.35259104
Encoder Loss:  0.052148324  || Decoder Loss:  0.052148324 Validation Decoder Loss:  0.35004476
Encoder Loss:  0.056980673  || Decoder Loss:  0.056980673 Validation Decoder Loss:  0.35338166
Encoder Loss:  0.052542638  || Decoder Loss:  0.052542638 Validation Decoder Loss:  0.34693384
Encoder Loss:  0.034346428  || Decoder Loss:  0.034346428 Validation Decoder Loss:  0.34209508
Encoder Loss:  0.03294058  || Decoder Loss:  0.03294058 Validation Decoder Loss:  0.34236914
Encoder Loss:  0.032831587  || Decoder Loss:  0.032831587 Validation Decoder Loss:  0.34249216
Encoder Loss:  0.032751538  || Decoder Loss:  0.032751538 Validation Decoder Loss:  0.34265107
Encoder Loss:  0.032683726  || Decoder Loss:  0.032683726 Validation Decoder Loss:  0.3428514
Encoder Loss:  0.032624803  || Decoder Loss:  0.032624803 Validation Decoder Loss:  0.3435657
Encoder Loss:  0.032573536  || Decoder Loss:  0.032573536 Validation Decoder Loss:  0.34607148
Encoder Loss:  0.03251976  || Decoder Loss:  0.03251976 Validation Decoder Loss:  0.3479515
Encoder Loss:  0.032458514  || Decoder Loss:  0.032458514 Validation Decoder Loss:  0.349249
Encoder Loss:  0.03240122  || Decoder Loss:  0.03240122 Validation Decoder Loss:  0.34675407
Encoder Loss:  0.032318305  || Decoder Loss:  0.032318305 Validation Decoder Loss:  0.34290728
Encoder Loss:  0.03226588  || Decoder Loss:  0.03226588 Validation Decoder Loss:  0.3455375
Encoder Loss:  0.049295887  || Decoder Loss:  0.049295887 Validation Decoder Loss:  0.34743264
Encoder Loss:  0.033820957  || Decoder Loss:  0.033820957 Validation Decoder Loss:  0.34206778
Encoder Loss:  0.032401755  || Decoder Loss:  0.032401755 Validation Decoder Loss:  0.34254414
Encoder Loss:  0.03234552  || Decoder Loss:  0.03234552 Validation Decoder Loss:  0.34264237
Encoder Loss:  0.03229787  || Decoder Loss:  0.03229787 Validation Decoder Loss:  0.34276465
Encoder Loss:  0.032254472  || Decoder Loss:  0.032254472 Validation Decoder Loss:  0.34295964
Encoder Loss:  0.032220155  || Decoder Loss:  0.032220155 Validation Decoder Loss:  0.34429193
Encoder Loss:  0.032183617  || Decoder Loss:  0.032183617 Validation Decoder Loss:  0.34786165
Encoder Loss:  0.032135185  || Decoder Loss:  0.032135185 Validation Decoder Loss:  0.34955797
Encoder Loss:  0.03208531  || Decoder Loss:  0.03208531 Validation Decoder Loss:  0.34692958
Encoder Loss:  0.03201054  || Decoder Loss:  0.03201054 Validation Decoder Loss:  0.3425547
Encoder Loss:  0.03449976  || Decoder Loss:  0.03449976 Validation Decoder Loss:  0.35081467
Encoder Loss:  0.049329337  || Decoder Loss:  0.049329337 Validation Decoder Loss:  0.3563649
Encoder Loss:  0.032332428  || Decoder Loss:  0.032332428 Validation Decoder Loss:  0.3424654
Encoder Loss:  0.032163803  || Decoder Loss:  0.032163803 Validation Decoder Loss:  0.34267282
Encoder Loss:  0.032102782  || Decoder Loss:  0.032102782 Validation Decoder Loss:  0.34278613
Encoder Loss:  0.032054942  || Decoder Loss:  0.032054942 Validation Decoder Loss:  0.343232
Encoder Loss:  0.032022692  || Decoder Loss:  0.032022692 Validation Decoder Loss:  0.34717393
Encoder Loss:  0.031977445  || Decoder Loss:  0.031977445 Validation Decoder Loss:  0.34960467
Encoder Loss:  0.031918827  || Decoder Loss:  0.031918827 Validation Decoder Loss:  0.34744608
Encoder Loss:  0.03185152  || Decoder Loss:  0.03185152 Validation Decoder Loss:  0.34235168
Encoder Loss:  0.036696825  || Decoder Loss:  0.036696825 Validation Decoder Loss:  0.35121045
Encoder Loss:  0.041913208  || Decoder Loss:  0.041913208 Validation Decoder Loss:  0.34361106
Encoder Loss:  0.032087162  || Decoder Loss:  0.032087162 Validation Decoder Loss:  0.3426516
Model: siamese_net_lr_1.0 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34265164
Model: "sequential_300"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_100 (Conv3D (None, 245, 6, 20, 1)     365       
_________________________________________________________________
reshape_100 (Reshape)        (None, 1470, 20, 1)       0         
=================================================================
Total params: 365
Trainable params: 365
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_301"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_100 (Conv2D)          (None, 1470, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_302"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_100 (Conv2D (None, 2607, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43098804  || Decoder Loss:  0.48096207 Validation Decoder Loss:  0.761966
Encoder Loss:  0.32876903  || Decoder Loss:  0.39450696 Validation Decoder Loss:  1.1314373
Encoder Loss:  0.42066514  || Decoder Loss:  0.5196062 Validation Decoder Loss:  1.1047418
Encoder Loss:  0.40340197  || Decoder Loss:  0.49743024 Validation Decoder Loss:  1.1916174
Encoder Loss:  0.40258875  || Decoder Loss:  0.498699 Validation Decoder Loss:  1.2060506
Encoder Loss:  0.39636353  || Decoder Loss:  0.49015373 Validation Decoder Loss:  1.2851646
Encoder Loss:  0.3979615  || Decoder Loss:  0.49268773 Validation Decoder Loss:  1.1593804
Encoder Loss:  0.39579117  || Decoder Loss:  0.4894213 Validation Decoder Loss:  1.1803972
Encoder Loss:  0.39681926  || Decoder Loss:  0.4906457 Validation Decoder Loss:  1.1931846
Encoder Loss:  0.39885244  || Decoder Loss:  0.49331367 Validation Decoder Loss:  1.2112565
Encoder Loss:  0.3988361  || Decoder Loss:  0.4941168 Validation Decoder Loss:  1.2424769
Encoder Loss:  0.39131168  || Decoder Loss:  0.48559815 Validation Decoder Loss:  1.2228969
Encoder Loss:  0.39816  || Decoder Loss:  0.49523667 Validation Decoder Loss:  1.192872
Encoder Loss:  0.38812026  || Decoder Loss:  0.4821811 Validation Decoder Loss:  1.1208781
Encoder Loss:  0.36638093  || Decoder Loss:  0.45456398 Validation Decoder Loss:  1.100079
Encoder Loss:  0.3113869  || Decoder Loss:  0.384052 Validation Decoder Loss:  0.82603043
Encoder Loss:  0.27279338  || Decoder Loss:  0.33493817 Validation Decoder Loss:  1.0621332
Encoder Loss:  0.37629056  || Decoder Loss:  0.46743748 Validation Decoder Loss:  1.158829
Encoder Loss:  0.37884307  || Decoder Loss:  0.4707306 Validation Decoder Loss:  1.1436684
Encoder Loss:  0.32660103  || Decoder Loss:  0.4038403 Validation Decoder Loss:  0.49159628
Encoder Loss:  0.2325507  || Decoder Loss:  0.28341684 Validation Decoder Loss:  0.923898
Encoder Loss:  0.17123337  || Decoder Loss:  0.20491166 Validation Decoder Loss:  0.52794397
Encoder Loss:  0.107052796  || Decoder Loss:  0.12289736 Validation Decoder Loss:  0.35217524
Encoder Loss:  0.07534169  || Decoder Loss:  0.082279176 Validation Decoder Loss:  0.34669757
Encoder Loss:  0.04351429  || Decoder Loss:  0.041494425 Validation Decoder Loss:  0.34207612
Encoder Loss:  0.038583122  || Decoder Loss:  0.035107967 Validation Decoder Loss:  0.3383551
Encoder Loss:  0.037908643  || Decoder Loss:  0.03430992 Validation Decoder Loss:  0.33485222
Encoder Loss:  0.037799183  || Decoder Loss:  0.03426831 Validation Decoder Loss:  0.3343549
Encoder Loss:  0.037766248  || Decoder Loss:  0.034280293 Validation Decoder Loss:  0.3337487
Encoder Loss:  0.037909046  || Decoder Loss:  0.03438888 Validation Decoder Loss:  0.33370212
Encoder Loss:  0.037991248  || Decoder Loss:  0.034412526 Validation Decoder Loss:  0.3337105
Encoder Loss:  0.03796552  || Decoder Loss:  0.03440186 Validation Decoder Loss:  0.33352357
Encoder Loss:  0.038004752  || Decoder Loss:  0.03443959 Validation Decoder Loss:  0.33317515
Encoder Loss:  0.037899185  || Decoder Loss:  0.034383297 Validation Decoder Loss:  0.3330555
Encoder Loss:  0.03784722  || Decoder Loss:  0.034314245 Validation Decoder Loss:  0.3328892
Encoder Loss:  0.0378358  || Decoder Loss:  0.03424369 Validation Decoder Loss:  0.33244532
Encoder Loss:  0.037764464  || Decoder Loss:  0.034200415 Validation Decoder Loss:  0.33245298
Encoder Loss:  0.037846796  || Decoder Loss:  0.03420105 Validation Decoder Loss:  0.33278757
Encoder Loss:  0.037753772  || Decoder Loss:  0.03423569 Validation Decoder Loss:  0.33380187
Encoder Loss:  0.03771369  || Decoder Loss:  0.034121986 Validation Decoder Loss:  0.33351767
Model: siamese_net_lr_0.37727896529058746 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33351767
Model: "sequential_303"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_101 (Conv3D (None, 98, 15, 20, 1)     386       
_________________________________________________________________
reshape_101 (Reshape)        (None, 1470, 20, 1)       0         
=================================================================
Total params: 386
Trainable params: 386
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_304"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_101 (Conv2D)          (None, 1470, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_305"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_101 (Conv2D (None, 2607, 20, 1)       1139      
=================================================================
Total params: 1,139
Trainable params: 1,139
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2268159  || Decoder Loss:  0.37059686 Validation Decoder Loss:  1.1663792
Encoder Loss:  0.19419385  || Decoder Loss:  0.36533538 Validation Decoder Loss:  0.6490641
Encoder Loss:  0.1173265  || Decoder Loss:  0.19808958 Validation Decoder Loss:  0.5374194
Encoder Loss:  0.09279248  || Decoder Loss:  0.12545818 Validation Decoder Loss:  0.32836133
Encoder Loss:  0.06786417  || Decoder Loss:  0.056956615 Validation Decoder Loss:  0.33506566
Encoder Loss:  0.050294165  || Decoder Loss:  0.037558924 Validation Decoder Loss:  0.34028703
Encoder Loss:  0.06566097  || Decoder Loss:  0.043553323 Validation Decoder Loss:  0.39837378
Encoder Loss:  0.07814432  || Decoder Loss:  0.06400365 Validation Decoder Loss:  0.34928876
Encoder Loss:  0.061008602  || Decoder Loss:  0.048989598 Validation Decoder Loss:  0.38652906
Encoder Loss:  0.06162017  || Decoder Loss:  0.052084617 Validation Decoder Loss:  0.34015745
Encoder Loss:  0.053078696  || Decoder Loss:  0.04560748 Validation Decoder Loss:  0.35200253
Encoder Loss:  0.0564902  || Decoder Loss:  0.047664534 Validation Decoder Loss:  0.33583325
Encoder Loss:  0.05716641  || Decoder Loss:  0.04720128 Validation Decoder Loss:  0.36353233
Encoder Loss:  0.051472526  || Decoder Loss:  0.044662625 Validation Decoder Loss:  0.3363706
Encoder Loss:  0.053351603  || Decoder Loss:  0.04369105 Validation Decoder Loss:  0.33758944
Encoder Loss:  0.048845578  || Decoder Loss:  0.041606974 Validation Decoder Loss:  0.3478629
Encoder Loss:  0.04853982  || Decoder Loss:  0.042062763 Validation Decoder Loss:  0.34753722
Encoder Loss:  0.048077554  || Decoder Loss:  0.04314946 Validation Decoder Loss:  0.34543887
Encoder Loss:  0.048292447  || Decoder Loss:  0.042132594 Validation Decoder Loss:  0.34787077
Encoder Loss:  0.04768401  || Decoder Loss:  0.04131563 Validation Decoder Loss:  0.3438632
Encoder Loss:  0.04606852  || Decoder Loss:  0.03820739 Validation Decoder Loss:  0.33915383
Encoder Loss:  0.047415514  || Decoder Loss:  0.04140637 Validation Decoder Loss:  0.34237552
Encoder Loss:  0.046044663  || Decoder Loss:  0.03869309 Validation Decoder Loss:  0.34216088
Encoder Loss:  0.04637415  || Decoder Loss:  0.039786786 Validation Decoder Loss:  0.3406973
Encoder Loss:  0.045212727  || Decoder Loss:  0.0372171 Validation Decoder Loss:  0.34742236
Encoder Loss:  0.04604423  || Decoder Loss:  0.039549213 Validation Decoder Loss:  0.34496552
Encoder Loss:  0.04579287  || Decoder Loss:  0.03887046 Validation Decoder Loss:  0.3466792
Encoder Loss:  0.046232626  || Decoder Loss:  0.039944112 Validation Decoder Loss:  0.34280026
Encoder Loss:  0.045686826  || Decoder Loss:  0.038423833 Validation Decoder Loss:  0.3482673
Encoder Loss:  0.046436593  || Decoder Loss:  0.040056586 Validation Decoder Loss:  0.33619428
Encoder Loss:  0.044686373  || Decoder Loss:  0.035341136 Validation Decoder Loss:  0.34089714
Encoder Loss:  0.045806896  || Decoder Loss:  0.038039155 Validation Decoder Loss:  0.33932203
Encoder Loss:  0.045755833  || Decoder Loss:  0.037055932 Validation Decoder Loss:  0.3350585
Encoder Loss:  0.047647625  || Decoder Loss:  0.037193026 Validation Decoder Loss:  0.3422454
Encoder Loss:  0.04683943  || Decoder Loss:  0.039056033 Validation Decoder Loss:  0.33891255
Encoder Loss:  0.04596852  || Decoder Loss:  0.03759154 Validation Decoder Loss:  0.34096918
Encoder Loss:  0.046351757  || Decoder Loss:  0.03920053 Validation Decoder Loss:  0.34714144
Encoder Loss:  0.046518255  || Decoder Loss:  0.03973469 Validation Decoder Loss:  0.34263977
Encoder Loss:  0.046155468  || Decoder Loss:  0.03925393 Validation Decoder Loss:  0.33638632
Encoder Loss:  0.04483529  || Decoder Loss:  0.03618722 Validation Decoder Loss:  0.3326689
Model: siamese_net_lr_0.3083366947931375 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3326689
Model: "sequential_306"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_102 (Conv3D (None, 514, 5, 20, 1)     326       
_________________________________________________________________
reshape_102 (Reshape)        (None, 2570, 20, 1)       0         
=================================================================
Total params: 326
Trainable params: 326
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_307"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_102 (Conv2D)          (None, 2570, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_308"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_102 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2066344  || Decoder Loss:  0.2651028 Validation Decoder Loss:  0.33907393
Encoder Loss:  0.054732986  || Decoder Loss:  0.046487093 Validation Decoder Loss:  0.31537372
Encoder Loss:  0.043558255  || Decoder Loss:  0.03814174 Validation Decoder Loss:  0.340173
Encoder Loss:  0.04371427  || Decoder Loss:  0.03877254 Validation Decoder Loss:  0.3398803
Encoder Loss:  0.048988353  || Decoder Loss:  0.042196926 Validation Decoder Loss:  0.33624053
Encoder Loss:  0.044789616  || Decoder Loss:  0.04042311 Validation Decoder Loss:  0.32475728
Encoder Loss:  0.04554623  || Decoder Loss:  0.039592747 Validation Decoder Loss:  0.33190954
Encoder Loss:  0.044660103  || Decoder Loss:  0.039803363 Validation Decoder Loss:  0.37637338
Encoder Loss:  0.04543807  || Decoder Loss:  0.039236106 Validation Decoder Loss:  0.3351791
Encoder Loss:  0.04330781  || Decoder Loss:  0.038413003 Validation Decoder Loss:  0.32398203
Encoder Loss:  0.043346677  || Decoder Loss:  0.03849126 Validation Decoder Loss:  0.3277321
Encoder Loss:  0.044826716  || Decoder Loss:  0.039259776 Validation Decoder Loss:  0.33355844
Encoder Loss:  0.043540187  || Decoder Loss:  0.039113473 Validation Decoder Loss:  0.3343954
Encoder Loss:  0.04380223  || Decoder Loss:  0.03912252 Validation Decoder Loss:  0.33729684
Encoder Loss:  0.043937057  || Decoder Loss:  0.039402004 Validation Decoder Loss:  0.33623642
Encoder Loss:  0.043455686  || Decoder Loss:  0.038919188 Validation Decoder Loss:  0.3375841
Encoder Loss:  0.043211933  || Decoder Loss:  0.03860037 Validation Decoder Loss:  0.33552283
Encoder Loss:  0.043118704  || Decoder Loss:  0.038459353 Validation Decoder Loss:  0.33776802
Encoder Loss:  0.0431978  || Decoder Loss:  0.0384907 Validation Decoder Loss:  0.33574855
Encoder Loss:  0.044118144  || Decoder Loss:  0.03914262 Validation Decoder Loss:  0.33665067
Encoder Loss:  0.042796955  || Decoder Loss:  0.038085934 Validation Decoder Loss:  0.33544996
Encoder Loss:  0.043020044  || Decoder Loss:  0.038263723 Validation Decoder Loss:  0.33591774
Encoder Loss:  0.042863473  || Decoder Loss:  0.03802795 Validation Decoder Loss:  0.33468074
Encoder Loss:  0.042718694  || Decoder Loss:  0.037818786 Validation Decoder Loss:  0.3358602
Encoder Loss:  0.044232674  || Decoder Loss:  0.038722243 Validation Decoder Loss:  0.33569175
Encoder Loss:  0.042707518  || Decoder Loss:  0.03782839 Validation Decoder Loss:  0.33554792
Encoder Loss:  0.042438094  || Decoder Loss:  0.037593167 Validation Decoder Loss:  0.3350293
Encoder Loss:  0.042649955  || Decoder Loss:  0.037647292 Validation Decoder Loss:  0.33507138
Encoder Loss:  0.042910825  || Decoder Loss:  0.03782837 Validation Decoder Loss:  0.3355142
Encoder Loss:  0.04200346  || Decoder Loss:  0.03681556 Validation Decoder Loss:  0.3386612
Encoder Loss:  0.042756688  || Decoder Loss:  0.037868407 Validation Decoder Loss:  0.337649
Encoder Loss:  0.042357467  || Decoder Loss:  0.037408683 Validation Decoder Loss:  0.33472523
Encoder Loss:  0.04233593  || Decoder Loss:  0.03727046 Validation Decoder Loss:  0.33524904
Encoder Loss:  0.04265795  || Decoder Loss:  0.037470262 Validation Decoder Loss:  0.3357206
Encoder Loss:  0.042231884  || Decoder Loss:  0.037180014 Validation Decoder Loss:  0.33491784
Encoder Loss:  0.04231887  || Decoder Loss:  0.03719648 Validation Decoder Loss:  0.3356041
Encoder Loss:  0.042282805  || Decoder Loss:  0.03715963 Validation Decoder Loss:  0.3351824
Encoder Loss:  0.042082366  || Decoder Loss:  0.0369814 Validation Decoder Loss:  0.33566323
Encoder Loss:  0.042267118  || Decoder Loss:  0.03711939 Validation Decoder Loss:  0.33558893
Encoder Loss:  0.042173807  || Decoder Loss:  0.037001908 Validation Decoder Loss:  0.33503208
Model: siamese_net_lr_0.9612103656814881 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33503208
Model: "sequential_309"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_103 (Conv3D (None, 474, 5, 20, 1)     97        
_________________________________________________________________
reshape_103 (Reshape)        (None, 2370, 20, 1)       0         
=================================================================
Total params: 97
Trainable params: 97
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_103 (Conv2D)          (None, 2370, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_311"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_103 (Conv2D (None, 2607, 20, 1)       239       
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.75139976  || Decoder Loss:  0.79158866 Validation Decoder Loss:  1.6456282
Encoder Loss:  0.90150017  || Decoder Loss:  0.9544251 Validation Decoder Loss:  1.6464797
Encoder Loss:  0.90107036  || Decoder Loss:  0.9539789 Validation Decoder Loss:  1.646894
Encoder Loss:  0.9000256  || Decoder Loss:  0.952918 Validation Decoder Loss:  1.647769
Encoder Loss:  0.896426  || Decoder Loss:  0.9491217 Validation Decoder Loss:  1.647318
Encoder Loss:  0.21556015  || Decoder Loss:  0.1903761 Validation Decoder Loss:  0.35290292
Encoder Loss:  0.084850185  || Decoder Loss:  0.045892976 Validation Decoder Loss:  0.35301337
Encoder Loss:  0.090335295  || Decoder Loss:  0.050332174 Validation Decoder Loss:  0.36471844
Encoder Loss:  0.7788353  || Decoder Loss:  0.82091767 Validation Decoder Loss:  1.6454952
Encoder Loss:  0.9041472  || Decoder Loss:  0.95790696 Validation Decoder Loss:  1.6453841
Encoder Loss:  0.9037437  || Decoder Loss:  0.95758176 Validation Decoder Loss:  1.6450169
Encoder Loss:  0.9030966  || Decoder Loss:  0.9570575 Validation Decoder Loss:  1.6444609
Encoder Loss:  0.9020577  || Decoder Loss:  0.95620745 Validation Decoder Loss:  1.6434772
Encoder Loss:  0.8999064  || Decoder Loss:  0.95440847 Validation Decoder Loss:  1.640695
Encoder Loss:  0.88159776  || Decoder Loss:  0.9371908 Validation Decoder Loss:  1.5593942
Encoder Loss:  0.5179959  || Decoder Loss:  0.5501265 Validation Decoder Loss:  0.66156054
Encoder Loss:  0.42507884  || Decoder Loss:  0.4609507 Validation Decoder Loss:  1.0942822
Encoder Loss:  0.4259991  || Decoder Loss:  0.46377718 Validation Decoder Loss:  1.1473595
Encoder Loss:  0.44206983  || Decoder Loss:  0.48101726 Validation Decoder Loss:  1.132355
Encoder Loss:  0.4351694  || Decoder Loss:  0.4735633 Validation Decoder Loss:  1.2273306
Encoder Loss:  0.42733228  || Decoder Loss:  0.46531555 Validation Decoder Loss:  1.1513629
Encoder Loss:  0.42574632  || Decoder Loss:  0.46406972 Validation Decoder Loss:  1.1366221
Encoder Loss:  0.42966157  || Decoder Loss:  0.46885204 Validation Decoder Loss:  1.1782923
Encoder Loss:  0.42269218  || Decoder Loss:  0.46118733 Validation Decoder Loss:  1.2403063
Encoder Loss:  0.4469732  || Decoder Loss:  0.48783058 Validation Decoder Loss:  1.1325347
Encoder Loss:  0.41665775  || Decoder Loss:  0.4553664 Validation Decoder Loss:  1.1875875
Encoder Loss:  0.4505422  || Decoder Loss:  0.49430293 Validation Decoder Loss:  1.2670873
Encoder Loss:  0.40840638  || Decoder Loss:  0.44856605 Validation Decoder Loss:  0.88131154
Encoder Loss:  0.29166165  || Decoder Loss:  0.31917733 Validation Decoder Loss:  0.6071186
Encoder Loss:  0.17089337  || Decoder Loss:  0.18450278 Validation Decoder Loss:  0.5885285
Encoder Loss:  0.1031997  || Decoder Loss:  0.10920386 Validation Decoder Loss:  0.40510038
Encoder Loss:  0.06973231  || Decoder Loss:  0.07185817 Validation Decoder Loss:  0.34758988
Encoder Loss:  0.042808402  || Decoder Loss:  0.04181022 Validation Decoder Loss:  0.32732105
Encoder Loss:  0.036356103  || Decoder Loss:  0.03455975 Validation Decoder Loss:  0.3285605
Encoder Loss:  0.036261264  || Decoder Loss:  0.034515392 Validation Decoder Loss:  0.32881927
Encoder Loss:  0.036350407  || Decoder Loss:  0.03467294 Validation Decoder Loss:  0.32831806
Encoder Loss:  0.036795553  || Decoder Loss:  0.035198525 Validation Decoder Loss:  0.32910967
Encoder Loss:  0.039040998  || Decoder Loss:  0.03770072 Validation Decoder Loss:  0.3281402
Encoder Loss:  0.037221026  || Decoder Loss:  0.035672653 Validation Decoder Loss:  0.32548046
Encoder Loss:  0.04044504  || Decoder Loss:  0.039273374 Validation Decoder Loss:  0.32672447
Model: siamese_net_lr_0.31178898004262834 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.32672447
Model: "sequential_312"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_104 (Conv3D (None, 444, 5, 20, 1)     193       
_________________________________________________________________
reshape_104 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_104 (Conv2D)          (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_314"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_104 (Conv2D (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1740886  || Decoder Loss:  0.066008955 Validation Decoder Loss:  0.3516288
Encoder Loss:  0.18130384  || Decoder Loss:  0.059375625 Validation Decoder Loss:  0.35300037
Encoder Loss:  0.18480138  || Decoder Loss:  0.07202689 Validation Decoder Loss:  0.3775547
Encoder Loss:  0.35602742  || Decoder Loss:  0.4501542 Validation Decoder Loss:  0.9651375
Encoder Loss:  0.33541748  || Decoder Loss:  0.4454967 Validation Decoder Loss:  1.0039859
Encoder Loss:  0.33839  || Decoder Loss:  0.44669285 Validation Decoder Loss:  0.8476379
Encoder Loss:  0.33186793  || Decoder Loss:  0.44467896 Validation Decoder Loss:  0.9330909
Encoder Loss:  0.32012057  || Decoder Loss:  0.42458552 Validation Decoder Loss:  0.98097837
Encoder Loss:  0.3502226  || Decoder Loss:  0.46588317 Validation Decoder Loss:  1.0016747
Encoder Loss:  0.34430063  || Decoder Loss:  0.4592462 Validation Decoder Loss:  0.9438042
Encoder Loss:  0.20264661  || Decoder Loss:  0.25367236 Validation Decoder Loss:  0.69959986
Encoder Loss:  0.18377216  || Decoder Loss:  0.22728156 Validation Decoder Loss:  0.3702366
Encoder Loss:  0.06315089  || Decoder Loss:  0.05566273 Validation Decoder Loss:  0.36404127
Encoder Loss:  0.04925252  || Decoder Loss:  0.035095707 Validation Decoder Loss:  0.32251942
Encoder Loss:  0.049219593  || Decoder Loss:  0.03627821 Validation Decoder Loss:  0.3307099
Encoder Loss:  0.05204766  || Decoder Loss:  0.04153758 Validation Decoder Loss:  0.32373682
Encoder Loss:  0.053970274  || Decoder Loss:  0.04560542 Validation Decoder Loss:  0.35769644
Encoder Loss:  0.052749705  || Decoder Loss:  0.045883827 Validation Decoder Loss:  0.33180162
Encoder Loss:  0.04972304  || Decoder Loss:  0.041213818 Validation Decoder Loss:  0.34507436
Encoder Loss:  0.049788307  || Decoder Loss:  0.042339507 Validation Decoder Loss:  0.34711206
Encoder Loss:  0.047276698  || Decoder Loss:  0.042689458 Validation Decoder Loss:  0.33697665
Encoder Loss:  0.046131182  || Decoder Loss:  0.041395377 Validation Decoder Loss:  0.34010613
Encoder Loss:  0.045219403  || Decoder Loss:  0.040610265 Validation Decoder Loss:  0.33859873
Encoder Loss:  0.048155237  || Decoder Loss:  0.039925564 Validation Decoder Loss:  0.31347233
Encoder Loss:  0.044698533  || Decoder Loss:  0.040227614 Validation Decoder Loss:  0.3461129
Encoder Loss:  0.047484323  || Decoder Loss:  0.040595826 Validation Decoder Loss:  0.3571096
Encoder Loss:  0.04406364  || Decoder Loss:  0.039956633 Validation Decoder Loss:  0.34167588
Encoder Loss:  0.04445461  || Decoder Loss:  0.039422054 Validation Decoder Loss:  0.34564513
Encoder Loss:  0.044753745  || Decoder Loss:  0.03878004 Validation Decoder Loss:  0.3469054
Encoder Loss:  0.04594588  || Decoder Loss:  0.04022178 Validation Decoder Loss:  0.32445347
Encoder Loss:  0.043315694  || Decoder Loss:  0.038491093 Validation Decoder Loss:  0.3432206
Encoder Loss:  0.04295748  || Decoder Loss:  0.038788423 Validation Decoder Loss:  0.33958137
Encoder Loss:  0.04202557  || Decoder Loss:  0.038138703 Validation Decoder Loss:  0.34097493
Encoder Loss:  0.042162567  || Decoder Loss:  0.038406197 Validation Decoder Loss:  0.3445348
Encoder Loss:  0.04201864  || Decoder Loss:  0.03818258 Validation Decoder Loss:  0.33784664
Encoder Loss:  0.0409485  || Decoder Loss:  0.03661727 Validation Decoder Loss:  0.33907068
Encoder Loss:  0.041154847  || Decoder Loss:  0.03690792 Validation Decoder Loss:  0.3423531
Encoder Loss:  0.04145341  || Decoder Loss:  0.037358694 Validation Decoder Loss:  0.34014022
Encoder Loss:  0.041339267  || Decoder Loss:  0.037184905 Validation Decoder Loss:  0.3397771
Encoder Loss:  0.0410561  || Decoder Loss:  0.03677734 Validation Decoder Loss:  0.33901086
Model: siamese_net_lr_0.5834877742347048 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33901086
Model: "sequential_315"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_105 (Conv3D (None, 74, 30, 20, 1)     155       
_________________________________________________________________
reshape_105 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 155
Trainable params: 155
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_316"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_105 (Conv2D)          (None, 2220, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_317"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_105 (Conv2D (None, 2607, 20, 1)       389       
=================================================================
Total params: 389
Trainable params: 389
Non-trainable params: 0
_________________________________________________________________
None
Optimized Parameters: [1.00000000e+00 9.67793438e-01 5.19090525e-01 2.83590197e-01
 7.39544317e-02 1.60000000e+01 2.22000000e+03]
Optimized Validation Decoder Loss: 0.31570756435394287











Optimizing at level  2
Model: "sequential_318"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_107 (Conv3D (None, 66, 10, 20, 1)     19        
_________________________________________________________________
dropout_318 (Dropout)        (None, 66, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_108 (Conv3D (None, 74, 30, 20, 1)     28        
_________________________________________________________________
reshape_106 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 47
Trainable params: 47
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_320"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_106 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_320 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_107 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_321"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_106 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_322 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_107 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.37188712  || Decoder Loss:  0.50070006 Validation Decoder Loss:  0.9695794
Encoder Loss:  0.37117782  || Decoder Loss:  0.5019955 Validation Decoder Loss:  1.0058875
Encoder Loss:  0.36754885  || Decoder Loss:  0.49978402 Validation Decoder Loss:  1.0009443
Encoder Loss:  0.28061482  || Decoder Loss:  0.37664863 Validation Decoder Loss:  0.5398793
Encoder Loss:  0.08827435  || Decoder Loss:  0.10421115 Validation Decoder Loss:  0.5599754
Encoder Loss:  0.221764  || Decoder Loss:  0.29328912 Validation Decoder Loss:  0.9735709
Encoder Loss:  0.08240161  || Decoder Loss:  0.09589249 Validation Decoder Loss:  0.3758849
Encoder Loss:  0.03963494  || Decoder Loss:  0.0353161 Validation Decoder Loss:  0.36129364
Encoder Loss:  0.1034475  || Decoder Loss:  0.12562424 Validation Decoder Loss:  0.43762836
Encoder Loss:  0.3619503  || Decoder Loss:  0.49185312 Validation Decoder Loss:  0.9950379
Encoder Loss:  0.3657712  || Decoder Loss:  0.4972657 Validation Decoder Loss:  0.99652827
Encoder Loss:  0.36531526  || Decoder Loss:  0.49661887 Validation Decoder Loss:  0.9946747
Encoder Loss:  0.36525762  || Decoder Loss:  0.49653602 Validation Decoder Loss:  0.9926013
Encoder Loss:  0.3661064  || Decoder Loss:  0.4975539 Validation Decoder Loss:  0.98535097
Encoder Loss:  0.3737104  || Decoder Loss:  0.50851005 Validation Decoder Loss:  0.99627435
Encoder Loss:  0.30028817  || Decoder Loss:  0.40451404 Validation Decoder Loss:  0.37892658
Encoder Loss:  0.06555906  || Decoder Loss:  0.07203646 Validation Decoder Loss:  0.38638324
Encoder Loss:  0.06704224  || Decoder Loss:  0.07413628 Validation Decoder Loss:  1.6199414
Encoder Loss:  0.2657099  || Decoder Loss:  0.3555341 Validation Decoder Loss:  1.0259488
Encoder Loss:  0.34464946  || Decoder Loss:  0.46734458 Validation Decoder Loss:  0.3486638
Encoder Loss:  0.38599983  || Decoder Loss:  0.5259085 Validation Decoder Loss:  1.0042999
Encoder Loss:  0.367316  || Decoder Loss:  0.49944973 Validation Decoder Loss:  0.9915923
Encoder Loss:  0.3669755  || Decoder Loss:  0.49896768 Validation Decoder Loss:  0.9819548
Encoder Loss:  0.20256363  || Decoder Loss:  0.26541618 Validation Decoder Loss:  0.3822224
Encoder Loss:  0.06502793  || Decoder Loss:  0.071284376 Validation Decoder Loss:  0.39067698
Encoder Loss:  0.06493955  || Decoder Loss:  0.07115927 Validation Decoder Loss:  0.3921362
Encoder Loss:  0.06356277  || Decoder Loss:  0.069208674 Validation Decoder Loss:  0.39829573
Encoder Loss:  0.060254987  || Decoder Loss:  0.06452301 Validation Decoder Loss:  0.40360695
Encoder Loss:  0.062044024  || Decoder Loss:  0.0670578 Validation Decoder Loss:  0.36911428
Encoder Loss:  0.12097903  || Decoder Loss:  0.15053459 Validation Decoder Loss:  0.4132511
Encoder Loss:  0.3457421  || Decoder Loss:  0.46889478 Validation Decoder Loss:  0.9639518
Encoder Loss:  0.36843464  || Decoder Loss:  0.5010367 Validation Decoder Loss:  1.0112633
Encoder Loss:  0.3658332  || Decoder Loss:  0.4973515 Validation Decoder Loss:  1.0028886
Encoder Loss:  0.36625654  || Decoder Loss:  0.49794957 Validation Decoder Loss:  0.99274385
Encoder Loss:  0.36327985  || Decoder Loss:  0.49373344 Validation Decoder Loss:  0.75287783
Encoder Loss:  0.3720209  || Decoder Loss:  0.5047187 Validation Decoder Loss:  1.0025253
Encoder Loss:  0.36601397  || Decoder Loss:  0.49761093 Validation Decoder Loss:  0.9983345
Encoder Loss:  0.3279771  || Decoder Loss:  0.44373462 Validation Decoder Loss:  0.37855846
Encoder Loss:  0.06844225  || Decoder Loss:  0.07612171 Validation Decoder Loss:  0.3797957
Encoder Loss:  0.06647325  || Decoder Loss:  0.07333268 Validation Decoder Loss:  0.3927865
Model: siamese_net_lr_0.5877416849995665 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3927865
Model: "sequential_323"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_108 (Conv2D)          (None, 2480, 20, 1)       129       
_________________________________________________________________
dropout_324 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_109 (Conv2D)          (None, 2220, 20, 1)       262       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_324"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_108 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_326 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_109 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_325"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_110 (Conv3D (None, 66, 20, 20, 1)     49        
_________________________________________________________________
dropout_328 (Dropout)        (None, 66, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_111 (Conv3D (None, 74, 30, 20, 1)     100       
_________________________________________________________________
reshape_107 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 149
Trainable params: 149
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_327"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_110 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_330 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_111 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_328"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_110 (Conv2D (None, 2550, 20, 1)       332       
_________________________________________________________________
dropout_332 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_111 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22029772  || Decoder Loss:  0.112136126 Validation Decoder Loss:  0.39783806
Encoder Loss:  0.21891963  || Decoder Loss:  0.1510969 Validation Decoder Loss:  1.5655005
Encoder Loss:  0.6721172  || Decoder Loss:  0.9320803 Validation Decoder Loss:  1.5827421
Encoder Loss:  0.42684284  || Decoder Loss:  0.63440776 Validation Decoder Loss:  0.3672978
Encoder Loss:  0.06262055  || Decoder Loss:  0.071454436 Validation Decoder Loss:  0.37208116
Encoder Loss:  0.06204942  || Decoder Loss:  0.070512645 Validation Decoder Loss:  0.37607586
Encoder Loss:  0.061618418  || Decoder Loss:  0.06977517 Validation Decoder Loss:  0.37964207
Encoder Loss:  0.061243292  || Decoder Loss:  0.06914757 Validation Decoder Loss:  0.38286722
Encoder Loss:  0.060906816  || Decoder Loss:  0.06858413 Validation Decoder Loss:  0.3857757
Encoder Loss:  0.060577847  || Decoder Loss:  0.068037204 Validation Decoder Loss:  0.38826066
Encoder Loss:  0.060272545  || Decoder Loss:  0.06745874 Validation Decoder Loss:  0.39041543
Encoder Loss:  0.059853043  || Decoder Loss:  0.066779345 Validation Decoder Loss:  0.3923114
Encoder Loss:  0.059291944  || Decoder Loss:  0.06586 Validation Decoder Loss:  0.39298147
Encoder Loss:  0.058509387  || Decoder Loss:  0.06427144 Validation Decoder Loss:  0.39079714
Encoder Loss:  0.05689478  || Decoder Loss:  0.06167403 Validation Decoder Loss:  0.3797216
Encoder Loss:  0.056691125  || Decoder Loss:  0.061202675 Validation Decoder Loss:  0.3787743
Encoder Loss:  0.05688839  || Decoder Loss:  0.061174218 Validation Decoder Loss:  0.3779463
Encoder Loss:  0.056576904  || Decoder Loss:  0.06121023 Validation Decoder Loss:  0.37754256
Encoder Loss:  0.05689713  || Decoder Loss:  0.06120208 Validation Decoder Loss:  0.37705413
Encoder Loss:  0.059088208  || Decoder Loss:  0.061199006 Validation Decoder Loss:  0.37710032
Encoder Loss:  0.056555428  || Decoder Loss:  0.061208863 Validation Decoder Loss:  0.37667865
Encoder Loss:  0.05614659  || Decoder Loss:  0.060517266 Validation Decoder Loss:  0.36477876
Encoder Loss:  0.054435477  || Decoder Loss:  0.057584744 Validation Decoder Loss:  0.35973272
Encoder Loss:  0.053956106  || Decoder Loss:  0.056766976 Validation Decoder Loss:  0.35980123
Encoder Loss:  0.05383553  || Decoder Loss:  0.05655548 Validation Decoder Loss:  0.3602497
Encoder Loss:  0.054293748  || Decoder Loss:  0.056422126 Validation Decoder Loss:  0.36168933
Encoder Loss:  0.055841006  || Decoder Loss:  0.056947216 Validation Decoder Loss:  0.36469337
Encoder Loss:  0.053941127  || Decoder Loss:  0.056721963 Validation Decoder Loss:  0.3648571
Encoder Loss:  0.053865775  || Decoder Loss:  0.056597665 Validation Decoder Loss:  0.36457387
Encoder Loss:  0.05413297  || Decoder Loss:  0.056552943 Validation Decoder Loss:  0.366647
Encoder Loss:  0.053910002  || Decoder Loss:  0.056579545 Validation Decoder Loss:  0.3666467
Encoder Loss:  0.0544493  || Decoder Loss:  0.056743752 Validation Decoder Loss:  0.36929095
Encoder Loss:  0.33793044  || Decoder Loss:  0.5430642 Validation Decoder Loss:  0.8767974
Encoder Loss:  0.0867976  || Decoder Loss:  0.11312049 Validation Decoder Loss:  0.32474613
Encoder Loss:  0.066310145  || Decoder Loss:  0.07787756 Validation Decoder Loss:  0.34026125
Encoder Loss:  0.06511888  || Decoder Loss:  0.07587999 Validation Decoder Loss:  0.3480749
Encoder Loss:  0.064399  || Decoder Loss:  0.07464065 Validation Decoder Loss:  0.3516683
Encoder Loss:  0.06418009  || Decoder Loss:  0.07428462 Validation Decoder Loss:  0.35453296
Encoder Loss:  0.063633494  || Decoder Loss:  0.07336202 Validation Decoder Loss:  0.3582071
Encoder Loss:  0.06464934  || Decoder Loss:  0.07505035 Validation Decoder Loss:  0.34520143
Model: siamese_net_lr_0.744932216017456 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34520143
Model: "sequential_330"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_112 (Conv2D)          (None, 2400, 20, 1)       209       
_________________________________________________________________
dropout_334 (Dropout)        (None, 2400, 20, 1)       0         
_________________________________________________________________
conv2d_113 (Conv2D)          (None, 2220, 20, 1)       182       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_331"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_112 (Conv2D (None, 2470, 20, 1)       252       
_________________________________________________________________
dropout_336 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_113 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_332"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_113 (Conv3D (None, 70, 29, 20, 1)     64        
_________________________________________________________________
dropout_338 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_114 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_108 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 75
Trainable params: 75
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_334"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_114 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_340 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_115 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_335"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_114 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_342 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_115 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10215807  || Decoder Loss:  0.0770608 Validation Decoder Loss:  0.42291498
Encoder Loss:  0.05513862  || Decoder Loss:  0.059588555 Validation Decoder Loss:  0.41271585
Encoder Loss:  0.054191038  || Decoder Loss:  0.05819042 Validation Decoder Loss:  0.40559366
Encoder Loss:  0.053241912  || Decoder Loss:  0.05669863 Validation Decoder Loss:  0.40084055
Encoder Loss:  0.05284898  || Decoder Loss:  0.05573191 Validation Decoder Loss:  0.39692
Encoder Loss:  0.05272991  || Decoder Loss:  0.055403117 Validation Decoder Loss:  0.39312822
Encoder Loss:  0.053832587  || Decoder Loss:  0.05451173 Validation Decoder Loss:  0.389432
Encoder Loss:  0.0520228  || Decoder Loss:  0.05417565 Validation Decoder Loss:  0.38620704
Encoder Loss:  0.051864747  || Decoder Loss:  0.053813487 Validation Decoder Loss:  0.3833031
Encoder Loss:  0.062673934  || Decoder Loss:  0.053567458 Validation Decoder Loss:  0.38546407
Encoder Loss:  0.052651286  || Decoder Loss:  0.054482795 Validation Decoder Loss:  0.38292366
Encoder Loss:  0.051815942  || Decoder Loss:  0.05383789 Validation Decoder Loss:  0.38003778
Encoder Loss:  0.051978983  || Decoder Loss:  0.054277964 Validation Decoder Loss:  0.37703723
Encoder Loss:  0.05145976  || Decoder Loss:  0.05311879 Validation Decoder Loss:  0.39187646
Encoder Loss:  0.05135678  || Decoder Loss:  0.052919373 Validation Decoder Loss:  0.37456316
Encoder Loss:  0.051439673  || Decoder Loss:  0.053143516 Validation Decoder Loss:  0.37033677
Encoder Loss:  0.05200346  || Decoder Loss:  0.054470643 Validation Decoder Loss:  0.38620695
Encoder Loss:  0.055318933  || Decoder Loss:  0.06212165 Validation Decoder Loss:  0.39706057
Encoder Loss:  0.05285239  || Decoder Loss:  0.056339912 Validation Decoder Loss:  0.36857152
Encoder Loss:  0.05127093  || Decoder Loss:  0.052718524 Validation Decoder Loss:  0.36791632
Encoder Loss:  0.050854553  || Decoder Loss:  0.051902223 Validation Decoder Loss:  0.3643983
Encoder Loss:  0.050712906  || Decoder Loss:  0.051534556 Validation Decoder Loss:  0.3621013
Encoder Loss:  0.050651267  || Decoder Loss:  0.051071033 Validation Decoder Loss:  0.3602028
Encoder Loss:  0.050824877  || Decoder Loss:  0.051097937 Validation Decoder Loss:  0.36277753
Encoder Loss:  0.05053117  || Decoder Loss:  0.051022973 Validation Decoder Loss:  0.3646059
Encoder Loss:  0.051201228  || Decoder Loss:  0.05221384 Validation Decoder Loss:  0.36082965
Encoder Loss:  0.05054132  || Decoder Loss:  0.050833378 Validation Decoder Loss:  0.36291248
Encoder Loss:  0.05056539  || Decoder Loss:  0.05070831 Validation Decoder Loss:  0.3597675
Encoder Loss:  0.050739985  || Decoder Loss:  0.050991982 Validation Decoder Loss:  0.36113364
Encoder Loss:  0.05130383  || Decoder Loss:  0.052398086 Validation Decoder Loss:  0.36122105
Encoder Loss:  0.06824339  || Decoder Loss:  0.07323009 Validation Decoder Loss:  0.38161772
Encoder Loss:  0.054988004  || Decoder Loss:  0.061192024 Validation Decoder Loss:  0.38510907
Encoder Loss:  0.053375535  || Decoder Loss:  0.057701107 Validation Decoder Loss:  0.36711332
Encoder Loss:  0.051830802  || Decoder Loss:  0.05414832 Validation Decoder Loss:  0.36183456
Encoder Loss:  0.05124363  || Decoder Loss:  0.05280004 Validation Decoder Loss:  0.35684
Encoder Loss:  0.050907306  || Decoder Loss:  0.05201093 Validation Decoder Loss:  0.35641524
Encoder Loss:  0.050793704  || Decoder Loss:  0.051765565 Validation Decoder Loss:  0.35704565
Encoder Loss:  0.05066299  || Decoder Loss:  0.051445056 Validation Decoder Loss:  0.35858905
Encoder Loss:  0.050526895  || Decoder Loss:  0.051014673 Validation Decoder Loss:  0.35594958
Encoder Loss:  0.050351772  || Decoder Loss:  0.050732702 Validation Decoder Loss:  0.35576138
reconstraining parameters GP_regression.rbf
reconstraining parameters GP_regression.Gaussian_noise.variance
Model: siamese_net_lr_0.19712457354738525 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35576138
Started Optimization Process
Model: "sequential_336"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_116 (Conv3D (None, 68, 30, 20, 1)     31        
_________________________________________________________________
dropout_344 (Dropout)        (None, 68, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_117 (Conv3D (None, 74, 30, 20, 1)     8         
_________________________________________________________________
reshape_109 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_338"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_346 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 2220, 20, 1)       372       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_339"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_116 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_348 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_117 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12679957  || Decoder Loss:  0.08152961 Validation Decoder Loss:  0.3753944
Encoder Loss:  0.22923973  || Decoder Loss:  0.06293253 Validation Decoder Loss:  0.35563153
Encoder Loss:  0.06942307  || Decoder Loss:  0.16861866 Validation Decoder Loss:  0.5315007
Encoder Loss:  0.051172566  || Decoder Loss:  0.07576551 Validation Decoder Loss:  0.46094364
Encoder Loss:  0.069988005  || Decoder Loss:  0.85691863 Validation Decoder Loss:  1.5579307
Encoder Loss:  0.06252487  || Decoder Loss:  0.40362185 Validation Decoder Loss:  0.5034347
Encoder Loss:  0.05082263  || Decoder Loss:  0.0755011 Validation Decoder Loss:  0.46698114
Encoder Loss:  0.050517734  || Decoder Loss:  0.07029746 Validation Decoder Loss:  0.44619355
Encoder Loss:  0.051316336  || Decoder Loss:  0.067614205 Validation Decoder Loss:  0.43784618
Encoder Loss:  0.06297086  || Decoder Loss:  0.4038793 Validation Decoder Loss:  0.308427
Encoder Loss:  0.052121624  || Decoder Loss:  0.13746329 Validation Decoder Loss:  0.3164853
Encoder Loss:  0.054376803  || Decoder Loss:  0.30203834 Validation Decoder Loss:  1.0466795
Encoder Loss:  0.05508183  || Decoder Loss:  0.3517862 Validation Decoder Loss:  1.1273308
Encoder Loss:  0.054448377  || Decoder Loss:  0.31873664 Validation Decoder Loss:  1.0209553
Encoder Loss:  0.055097923  || Decoder Loss:  0.3697059 Validation Decoder Loss:  0.66964227
Encoder Loss:  0.059690103  || Decoder Loss:  0.53423625 Validation Decoder Loss:  1.1373796
Encoder Loss:  0.055120345  || Decoder Loss:  0.38664317 Validation Decoder Loss:  1.0630519
Encoder Loss:  0.05687304  || Decoder Loss:  0.5043859 Validation Decoder Loss:  1.5076015
Encoder Loss:  0.05663311  || Decoder Loss:  0.4888118 Validation Decoder Loss:  1.264533
Encoder Loss:  0.05770342  || Decoder Loss:  0.49050382 Validation Decoder Loss:  1.6119477
Encoder Loss:  0.11894499  || Decoder Loss:  0.48326653 Validation Decoder Loss:  1.2092627
Encoder Loss:  0.055689517  || Decoder Loss:  0.43540806 Validation Decoder Loss:  1.2220285
Encoder Loss:  0.055528436  || Decoder Loss:  0.4249969 Validation Decoder Loss:  1.242316
Encoder Loss:  0.055315074  || Decoder Loss:  0.40927708 Validation Decoder Loss:  1.2317224
Encoder Loss:  0.055156693  || Decoder Loss:  0.3979233 Validation Decoder Loss:  1.2146187
Encoder Loss:  0.055146  || Decoder Loss:  0.3957007 Validation Decoder Loss:  1.2202783
Encoder Loss:  0.055961903  || Decoder Loss:  0.451631 Validation Decoder Loss:  0.76518214
Encoder Loss:  0.055869583  || Decoder Loss:  0.44777092 Validation Decoder Loss:  0.7705256
Encoder Loss:  0.05594299  || Decoder Loss:  0.45044005 Validation Decoder Loss:  0.80704534
Encoder Loss:  0.056026712  || Decoder Loss:  0.4494761 Validation Decoder Loss:  0.6477189
Encoder Loss:  0.056995507  || Decoder Loss:  0.48203 Validation Decoder Loss:  0.6784636
Encoder Loss:  0.056258418  || Decoder Loss:  0.46692035 Validation Decoder Loss:  1.1892154
Encoder Loss:  0.056276776  || Decoder Loss:  0.46727565 Validation Decoder Loss:  1.2210126
Encoder Loss:  0.057218216  || Decoder Loss:  0.50345004 Validation Decoder Loss:  1.2152716
Encoder Loss:  0.056141477  || Decoder Loss:  0.46162146 Validation Decoder Loss:  1.2170979
Encoder Loss:  0.059573893  || Decoder Loss:  0.50557923 Validation Decoder Loss:  0.93244916
Encoder Loss:  0.055741254  || Decoder Loss:  0.4383116 Validation Decoder Loss:  0.7188672
Encoder Loss:  0.055685192  || Decoder Loss:  0.43652818 Validation Decoder Loss:  0.69624484
Encoder Loss:  0.055553623  || Decoder Loss:  0.4239306 Validation Decoder Loss:  0.68816686
Encoder Loss:  0.055687144  || Decoder Loss:  0.43142608 Validation Decoder Loss:  0.7561507
Model: siamese_net_lr_0.6179386238539456 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.7561507
Model: "sequential_341"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_118 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_350 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_342"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_118 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_352 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_119 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_343"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_119 (Conv3D (None, 66, 10, 20, 1)     7         
_________________________________________________________________
dropout_354 (Dropout)        (None, 66, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_120 (Conv3D (None, 74, 30, 20, 1)     190       
_________________________________________________________________
reshape_110 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 197
Trainable params: 197
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_345"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_120 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_356 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_121 (Conv2D)          (None, 2220, 20, 1)       272       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_346"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_120 (Conv2D (None, 2470, 20, 1)       252       
_________________________________________________________________
dropout_358 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_121 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43863332  || Decoder Loss:  0.49137977 Validation Decoder Loss:  1.0171225
Encoder Loss:  0.441779  || Decoder Loss:  0.4949934 Validation Decoder Loss:  1.0154824
Encoder Loss:  0.44271988  || Decoder Loss:  0.49615952 Validation Decoder Loss:  0.9825736
Encoder Loss:  0.44159538  || Decoder Loss:  0.49597254 Validation Decoder Loss:  1.0516982
Encoder Loss:  0.44268858  || Decoder Loss:  0.49699956 Validation Decoder Loss:  1.012398
Encoder Loss:  0.43969995  || Decoder Loss:  0.4939512 Validation Decoder Loss:  1.011764
Encoder Loss:  0.44052753  || Decoder Loss:  0.49519002 Validation Decoder Loss:  1.0193428
Encoder Loss:  0.44017693  || Decoder Loss:  0.49449766 Validation Decoder Loss:  1.01394
Encoder Loss:  0.4395441  || Decoder Loss:  0.493951 Validation Decoder Loss:  1.0114133
Encoder Loss:  0.43921733  || Decoder Loss:  0.49368432 Validation Decoder Loss:  1.0121549
Encoder Loss:  0.4381673  || Decoder Loss:  0.4933959 Validation Decoder Loss:  1.0099043
Encoder Loss:  0.43779764  || Decoder Loss:  0.49298885 Validation Decoder Loss:  1.0076362
Encoder Loss:  0.43728963  || Decoder Loss:  0.49240893 Validation Decoder Loss:  1.0048473
Encoder Loss:  0.4370903  || Decoder Loss:  0.4921816 Validation Decoder Loss:  1.0047665
Encoder Loss:  0.4367683  || Decoder Loss:  0.49181357 Validation Decoder Loss:  1.0045888
Encoder Loss:  0.43587607  || Decoder Loss:  0.49079445 Validation Decoder Loss:  1.0052593
Encoder Loss:  0.4353888  || Decoder Loss:  0.49023807 Validation Decoder Loss:  1.0051961
Encoder Loss:  0.4350832  || Decoder Loss:  0.48988837 Validation Decoder Loss:  1.0056603
Encoder Loss:  0.4335743  || Decoder Loss:  0.48816514 Validation Decoder Loss:  1.0048547
Encoder Loss:  0.4037596  || Decoder Loss:  0.45410702 Validation Decoder Loss:  1.0188419
Encoder Loss:  0.43920872  || Decoder Loss:  0.4946017 Validation Decoder Loss:  1.0161514
Encoder Loss:  0.4384736  || Decoder Loss:  0.49376172 Validation Decoder Loss:  1.0170734
Encoder Loss:  0.4380439  || Decoder Loss:  0.49327075 Validation Decoder Loss:  1.003773
Encoder Loss:  0.42691505  || Decoder Loss:  0.48055804 Validation Decoder Loss:  0.76859605
Encoder Loss:  0.39957267  || Decoder Loss:  0.4493242 Validation Decoder Loss:  1.0084023
Encoder Loss:  0.4398951  || Decoder Loss:  0.4953854 Validation Decoder Loss:  1.0126096
Encoder Loss:  0.43612134  || Decoder Loss:  0.49107474 Validation Decoder Loss:  1.0026499
Encoder Loss:  0.38710612  || Decoder Loss:  0.4350834 Validation Decoder Loss:  0.4788972
Encoder Loss:  0.396853  || Decoder Loss:  0.4462173 Validation Decoder Loss:  1.0102375
Encoder Loss:  0.4214769  || Decoder Loss:  0.4743459 Validation Decoder Loss:  1.0116286
Encoder Loss:  0.43842584  || Decoder Loss:  0.49370706 Validation Decoder Loss:  1.0056018
Encoder Loss:  0.44149932  || Decoder Loss:  0.49721777 Validation Decoder Loss:  0.97987497
Encoder Loss:  0.44439968  || Decoder Loss:  0.5005302 Validation Decoder Loss:  0.9784385
Encoder Loss:  0.4099278  || Decoder Loss:  0.46115127 Validation Decoder Loss:  1.001979
Encoder Loss:  0.44153324  || Decoder Loss:  0.49725655 Validation Decoder Loss:  0.9992812
Encoder Loss:  0.4414786  || Decoder Loss:  0.49719405 Validation Decoder Loss:  0.9992533
Encoder Loss:  0.44065255  || Decoder Loss:  0.4962506 Validation Decoder Loss:  0.99970233
Encoder Loss:  0.43965995  || Decoder Loss:  0.49511677 Validation Decoder Loss:  1.0024376
Encoder Loss:  0.43955514  || Decoder Loss:  0.4949969 Validation Decoder Loss:  1.0049993
Encoder Loss:  0.43855655  || Decoder Loss:  0.49385503 Validation Decoder Loss:  1.0004423
Model: siamese_net_lr_0.6866068128722836 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0004423
Model: "sequential_348"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_122 (Conv2D)          (None, 2220, 20, 1)       389       
_________________________________________________________________
dropout_360 (Dropout)        (None, 2220, 20, 1)       0         
_________________________________________________________________
conv2d_123 (Conv2D)          (None, 2220, 20, 1)       2         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_349"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_122 (Conv2D (None, 2550, 20, 1)       332       
_________________________________________________________________
dropout_362 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_123 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_351"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_124 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_364 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_125 (Conv2D)          (None, 2220, 20, 1)       302       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_352"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_124 (Conv2D (None, 2370, 20, 1)       152       
_________________________________________________________________
dropout_366 (Dropout)        (None, 2370, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_125 (Conv2D (None, 2607, 20, 1)       239       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_353"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_122 (Conv3D (None, 70, 29, 20, 1)     92        
_________________________________________________________________
dropout_368 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_123 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_111 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 103
Trainable params: 103
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_355"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_126 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_370 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_127 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_126 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_372 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_127 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1660924  || Decoder Loss:  0.13653144 Validation Decoder Loss:  1.5908468
Encoder Loss:  0.40246093  || Decoder Loss:  0.43710697 Validation Decoder Loss:  0.3487167
Encoder Loss:  0.041117  || Decoder Loss:  0.03993926 Validation Decoder Loss:  0.34877044
Encoder Loss:  0.04531207  || Decoder Loss:  0.044666227 Validation Decoder Loss:  0.35043794
Encoder Loss:  0.040869962  || Decoder Loss:  0.039641775 Validation Decoder Loss:  0.3495999
Encoder Loss:  0.04096707  || Decoder Loss:  0.039729893 Validation Decoder Loss:  0.3490349
Encoder Loss:  0.040676214  || Decoder Loss:  0.0394342 Validation Decoder Loss:  0.3484888
Encoder Loss:  0.040834576  || Decoder Loss:  0.03961017 Validation Decoder Loss:  0.34773016
Encoder Loss:  0.04085912  || Decoder Loss:  0.03963671 Validation Decoder Loss:  0.34885678
Encoder Loss:  0.09888565  || Decoder Loss:  0.105065495 Validation Decoder Loss:  0.34882468
Encoder Loss:  0.0404567  || Decoder Loss:  0.039183345 Validation Decoder Loss:  0.348096
Encoder Loss:  0.040425997  || Decoder Loss:  0.039144885 Validation Decoder Loss:  0.34725243
Encoder Loss:  0.04034999  || Decoder Loss:  0.039067235 Validation Decoder Loss:  0.3468783
Encoder Loss:  0.04209136  || Decoder Loss:  0.041027766 Validation Decoder Loss:  0.34826207
Encoder Loss:  0.06860525  || Decoder Loss:  0.070967056 Validation Decoder Loss:  0.9687561
Encoder Loss:  0.44489822  || Decoder Loss:  0.49572432 Validation Decoder Loss:  0.9931124
Encoder Loss:  0.11182496  || Decoder Loss:  0.1197587 Validation Decoder Loss:  0.3478912
Encoder Loss:  0.04079597  || Decoder Loss:  0.03956075 Validation Decoder Loss:  0.34655526
Encoder Loss:  0.047119975  || Decoder Loss:  0.046668496 Validation Decoder Loss:  0.3476198
Encoder Loss:  0.040978465  || Decoder Loss:  0.039790977 Validation Decoder Loss:  0.34696022
Encoder Loss:  0.0408611  || Decoder Loss:  0.0396578 Validation Decoder Loss:  0.34721446
Encoder Loss:  0.04062944  || Decoder Loss:  0.039402243 Validation Decoder Loss:  0.34662235
Encoder Loss:  0.29845732  || Decoder Loss:  0.33038676 Validation Decoder Loss:  0.9718101
Encoder Loss:  0.4390669  || Decoder Loss:  0.48913863 Validation Decoder Loss:  1.002252
Encoder Loss:  0.4395241  || Decoder Loss:  0.48969334 Validation Decoder Loss:  0.9987737
Encoder Loss:  0.44644365  || Decoder Loss:  0.49748322 Validation Decoder Loss:  1.0277568
Encoder Loss:  0.44919017  || Decoder Loss:  0.5005326 Validation Decoder Loss:  0.99248457
Encoder Loss:  0.4441881  || Decoder Loss:  0.4949635 Validation Decoder Loss:  0.99431247
Encoder Loss:  0.4436268  || Decoder Loss:  0.49432865 Validation Decoder Loss:  0.97811437
Encoder Loss:  0.4453914  || Decoder Loss:  0.4963038 Validation Decoder Loss:  0.99697447
Encoder Loss:  0.44227734  || Decoder Loss:  0.49281284 Validation Decoder Loss:  0.9717877
Encoder Loss:  0.07461302  || Decoder Loss:  0.07778375 Validation Decoder Loss:  0.39894336
Encoder Loss:  0.10691967  || Decoder Loss:  0.114252396 Validation Decoder Loss:  0.9884727
Encoder Loss:  0.44006306  || Decoder Loss:  0.49031338 Validation Decoder Loss:  0.9756721
Encoder Loss:  0.16207677  || Decoder Loss:  0.17651515 Validation Decoder Loss:  0.39617318
Encoder Loss:  0.05176275  || Decoder Loss:  0.051989764 Validation Decoder Loss:  0.3890949
Encoder Loss:  0.051043294  || Decoder Loss:  0.051177643 Validation Decoder Loss:  0.38727516
Encoder Loss:  0.04568748  || Decoder Loss:  0.04513185 Validation Decoder Loss:  0.34997422
Encoder Loss:  0.038824603  || Decoder Loss:  0.037384775 Validation Decoder Loss:  0.35103035
Encoder Loss:  0.038879078  || Decoder Loss:  0.03744627 Validation Decoder Loss:  0.34877336
Model: siamese_net_lr_0.6355969846814596 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34877333
Model: "sequential_358"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_128 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_374 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_129 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_359"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_128 (Conv2D (None, 2300, 20, 1)       82        
_________________________________________________________________
dropout_376 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_129 (Conv2D (None, 2607, 20, 1)       309       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_360"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_125 (Conv3D (None, 64, 10, 20, 1)     3         
_________________________________________________________________
dropout_378 (Dropout)        (None, 64, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_126 (Conv3D (None, 74, 30, 20, 1)     133       
_________________________________________________________________
reshape_112 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 136
Trainable params: 136
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_362"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_130 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_380 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_131 (Conv2D)          (None, 2220, 20, 1)       282       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_363"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_130 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_382 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_131 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.69941324  || Decoder Loss:  0.71919775 Validation Decoder Loss:  1.6237352
Encoder Loss:  0.5063759  || Decoder Loss:  0.5254834 Validation Decoder Loss:  1.0080192
Encoder Loss:  0.48019254  || Decoder Loss:  0.49820483 Validation Decoder Loss:  1.0252211
Encoder Loss:  0.4272458  || Decoder Loss:  0.4430922 Validation Decoder Loss:  0.4506948
Encoder Loss:  0.07682851  || Decoder Loss:  0.077965155 Validation Decoder Loss:  0.386067
Encoder Loss:  0.07580576  || Decoder Loss:  0.07689966 Validation Decoder Loss:  0.38666075
Encoder Loss:  0.075770386  || Decoder Loss:  0.076862834 Validation Decoder Loss:  0.3869771
Encoder Loss:  0.07571416  || Decoder Loss:  0.07680426 Validation Decoder Loss:  0.38768727
Encoder Loss:  0.07563715  || Decoder Loss:  0.07672399 Validation Decoder Loss:  0.38852966
Encoder Loss:  0.075549826  || Decoder Loss:  0.076632954 Validation Decoder Loss:  0.38941127
Encoder Loss:  0.07544659  || Decoder Loss:  0.07652535 Validation Decoder Loss:  0.39021307
Encoder Loss:  0.07533026  || Decoder Loss:  0.076404095 Validation Decoder Loss:  0.39081568
Encoder Loss:  0.07519757  || Decoder Loss:  0.076265804 Validation Decoder Loss:  0.39161444
Encoder Loss:  0.07503497  || Decoder Loss:  0.07609628 Validation Decoder Loss:  0.3922878
Encoder Loss:  0.07483625  || Decoder Loss:  0.07588913 Validation Decoder Loss:  0.3928935
Encoder Loss:  0.074571155  || Decoder Loss:  0.07561283 Validation Decoder Loss:  0.3930934
Encoder Loss:  0.07418726  || Decoder Loss:  0.07521263 Validation Decoder Loss:  0.39322752
Encoder Loss:  0.073517546  || Decoder Loss:  0.07451455 Validation Decoder Loss:  0.39222255
Encoder Loss:  0.07194132  || Decoder Loss:  0.07287149 Validation Decoder Loss:  0.38416088
Encoder Loss:  0.07066509  || Decoder Loss:  0.07154113 Validation Decoder Loss:  0.37742198
Encoder Loss:  0.07018233  || Decoder Loss:  0.07103795 Validation Decoder Loss:  0.37591726
Encoder Loss:  0.06969211  || Decoder Loss:  0.070526905 Validation Decoder Loss:  0.37469223
Encoder Loss:  0.06907415  || Decoder Loss:  0.06988271 Validation Decoder Loss:  0.37206405
Encoder Loss:  0.06806597  || Decoder Loss:  0.06883177 Validation Decoder Loss:  0.36808467
Encoder Loss:  0.06586582  || Decoder Loss:  0.06653839 Validation Decoder Loss:  0.36941916
Encoder Loss:  0.064519696  || Decoder Loss:  0.065135196 Validation Decoder Loss:  0.36842865
Encoder Loss:  0.063981764  || Decoder Loss:  0.06457445 Validation Decoder Loss:  0.3611161
Encoder Loss:  0.06536661  || Decoder Loss:  0.066017866 Validation Decoder Loss:  0.3967185
Encoder Loss:  0.06656756  || Decoder Loss:  0.06726976 Validation Decoder Loss:  0.38887888
Encoder Loss:  0.06936219  || Decoder Loss:  0.070182875 Validation Decoder Loss:  0.38431078
Encoder Loss:  0.07588569  || Decoder Loss:  0.076983064 Validation Decoder Loss:  0.39093918
Encoder Loss:  0.07397142  || Decoder Loss:  0.07498765 Validation Decoder Loss:  0.3917391
Encoder Loss:  0.06625867  || Decoder Loss:  0.06694785 Validation Decoder Loss:  0.36309677
Encoder Loss:  0.06270732  || Decoder Loss:  0.063246 Validation Decoder Loss:  0.35920244
Encoder Loss:  0.06723148  || Decoder Loss:  0.067961924 Validation Decoder Loss:  0.38702855
Encoder Loss:  0.07575557  || Decoder Loss:  0.07684727 Validation Decoder Loss:  0.3942088
Encoder Loss:  0.066721134  || Decoder Loss:  0.06742985 Validation Decoder Loss:  0.36920008
Encoder Loss:  0.07319078  || Decoder Loss:  0.07417374 Validation Decoder Loss:  0.38879135
Encoder Loss:  0.07918295  || Decoder Loss:  0.08042004 Validation Decoder Loss:  0.38993114
Encoder Loss:  0.07919265  || Decoder Loss:  0.080430165 Validation Decoder Loss:  0.39464825
Model: siamese_net_lr_0.8688764520914118 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.39464825
Model: "sequential_365"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_132 (Conv2D)          (None, 2240, 20, 1)       369       
_________________________________________________________________
dropout_384 (Dropout)        (None, 2240, 20, 1)       0         
_________________________________________________________________
conv2d_133 (Conv2D)          (None, 2220, 20, 1)       22        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_366"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_132 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_386 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_133 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_368"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_134 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_388 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_135 (Conv2D)          (None, 2220, 20, 1)       282       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_369"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_134 (Conv2D (None, 2310, 20, 1)       92        
_________________________________________________________________
dropout_390 (Dropout)        (None, 2310, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_135 (Conv2D (None, 2607, 20, 1)       299       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_370"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_128 (Conv3D (None, 70, 19, 20, 1)     106       
_________________________________________________________________
dropout_392 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_129 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_113 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 167
Trainable params: 167
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_372"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_136 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_394 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_137 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_373"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_136 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_396 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_137 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16905047  || Decoder Loss:  0.17583565 Validation Decoder Loss:  0.37372836
Encoder Loss:  0.37022454  || Decoder Loss:  0.62982416 Validation Decoder Loss:  1.5367588
Encoder Loss:  0.31046796  || Decoder Loss:  0.5242643 Validation Decoder Loss:  1.0048472
Encoder Loss:  0.28730103  || Decoder Loss:  0.48207796 Validation Decoder Loss:  0.9859056
Encoder Loss:  0.2703248  || Decoder Loss:  0.45114574 Validation Decoder Loss:  0.31176692
Encoder Loss:  0.13883136  || Decoder Loss:  0.21169081 Validation Decoder Loss:  0.32716745
Encoder Loss:  0.10908651  || Decoder Loss:  0.15754513 Validation Decoder Loss:  0.321512
Encoder Loss:  0.19086693  || Decoder Loss:  0.30646932 Validation Decoder Loss:  0.34763342
Encoder Loss:  0.114893034  || Decoder Loss:  0.16813028 Validation Decoder Loss:  0.38351974
Encoder Loss:  0.20705129  || Decoder Loss:  0.33587283 Validation Decoder Loss:  1.6272993
Encoder Loss:  0.30442393  || Decoder Loss:  0.51317084 Validation Decoder Loss:  1.0184878
Encoder Loss:  0.29665336  || Decoder Loss:  0.4990376 Validation Decoder Loss:  1.0230956
Encoder Loss:  0.29511496  || Decoder Loss:  0.49624196 Validation Decoder Loss:  1.0201987
Encoder Loss:  0.29508936  || Decoder Loss:  0.49620044 Validation Decoder Loss:  1.0165775
Encoder Loss:  0.2941927  || Decoder Loss:  0.49455297 Validation Decoder Loss:  1.0147369
Encoder Loss:  0.29293525  || Decoder Loss:  0.49227124 Validation Decoder Loss:  1.0060325
Encoder Loss:  0.29045343  || Decoder Loss:  0.48774803 Validation Decoder Loss:  0.98679227
Encoder Loss:  0.2489009  || Decoder Loss:  0.41208726 Validation Decoder Loss:  0.44765663
Encoder Loss:  0.16815002  || Decoder Loss:  0.26504683 Validation Decoder Loss:  0.31348357
Encoder Loss:  0.19014697  || Decoder Loss:  0.30493528 Validation Decoder Loss:  1.0017772
Encoder Loss:  0.16356575  || Decoder Loss:  0.25661314 Validation Decoder Loss:  0.3140931
Encoder Loss:  0.07297604  || Decoder Loss:  0.09176877 Validation Decoder Loss:  0.39911374
Encoder Loss:  0.13256466  || Decoder Loss:  0.20028362 Validation Decoder Loss:  0.29509252
Encoder Loss:  0.095610864  || Decoder Loss:  0.13296276 Validation Decoder Loss:  0.3089381
Encoder Loss:  0.12840915  || Decoder Loss:  0.19267023 Validation Decoder Loss:  0.29800978
Encoder Loss:  0.22523828  || Decoder Loss:  0.36898285 Validation Decoder Loss:  1.5116317
Encoder Loss:  0.26602998  || Decoder Loss:  0.443141 Validation Decoder Loss:  0.36284888
Encoder Loss:  0.23695715  || Decoder Loss:  0.39034432 Validation Decoder Loss:  0.30809683
Encoder Loss:  0.15280189  || Decoder Loss:  0.23711742 Validation Decoder Loss:  1.0823929
Encoder Loss:  0.21725404  || Decoder Loss:  0.35431153 Validation Decoder Loss:  1.2192396
Encoder Loss:  0.222048  || Decoder Loss:  0.36319637 Validation Decoder Loss:  0.34237385
Encoder Loss:  0.12471661  || Decoder Loss:  0.18593693 Validation Decoder Loss:  0.3604622
Encoder Loss:  0.052443374  || Decoder Loss:  0.054397587 Validation Decoder Loss:  0.36127383
Encoder Loss:  0.053338155  || Decoder Loss:  0.055992264 Validation Decoder Loss:  0.36437765
Encoder Loss:  0.052878533  || Decoder Loss:  0.055151593 Validation Decoder Loss:  0.36209774
Encoder Loss:  0.2540858  || Decoder Loss:  0.42153203 Validation Decoder Loss:  0.7946695
Encoder Loss:  0.21099311  || Decoder Loss:  0.34308136 Validation Decoder Loss:  0.31843206
Encoder Loss:  0.052131522  || Decoder Loss:  0.05380793 Validation Decoder Loss:  0.36030063
Encoder Loss:  0.051402636  || Decoder Loss:  0.05246444 Validation Decoder Loss:  0.3550787
Encoder Loss:  0.052064832  || Decoder Loss:  0.05368968 Validation Decoder Loss:  0.365732
Model: siamese_net_lr_0.878799428906036 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.365732
Model: "sequential_375"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_138 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_398 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_139 (Conv2D)          (None, 2220, 20, 1)       312       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_376"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_138 (Conv2D (None, 2420, 20, 1)       202       
_________________________________________________________________
dropout_400 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_139 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_378"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_140 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_402 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_141 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_379"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_140 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_404 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_141 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_380"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_131 (Conv3D (None, 68, 10, 20, 1)     31        
_________________________________________________________________
dropout_406 (Dropout)        (None, 68, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_132 (Conv3D (None, 74, 30, 20, 1)     22        
_________________________________________________________________
reshape_114 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 53
Trainable params: 53
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_382"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_142 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_408 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_143 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_383"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_142 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_410 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_143 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2750927  || Decoder Loss:  0.06277576 Validation Decoder Loss:  0.3848015
Encoder Loss:  0.12999372  || Decoder Loss:  0.095995635 Validation Decoder Loss:  0.35483208
Encoder Loss:  0.046038337  || Decoder Loss:  0.03992397 Validation Decoder Loss:  0.3278646
Encoder Loss:  0.04367636  || Decoder Loss:  0.034306046 Validation Decoder Loss:  0.32867587
Encoder Loss:  0.04357123  || Decoder Loss:  0.034086827 Validation Decoder Loss:  0.3294056
Encoder Loss:  0.04346125  || Decoder Loss:  0.03392536 Validation Decoder Loss:  0.3301703
Encoder Loss:  0.04342013  || Decoder Loss:  0.03377611 Validation Decoder Loss:  0.33094895
Encoder Loss:  0.043339238  || Decoder Loss:  0.033635747 Validation Decoder Loss:  0.3317239
Encoder Loss:  0.043275617  || Decoder Loss:  0.033506922 Validation Decoder Loss:  0.33247864
Encoder Loss:  0.043213796  || Decoder Loss:  0.033392597 Validation Decoder Loss:  0.3332649
Encoder Loss:  0.043183032  || Decoder Loss:  0.03330501 Validation Decoder Loss:  0.33386326
Encoder Loss:  0.043121424  || Decoder Loss:  0.033214465 Validation Decoder Loss:  0.3345107
Encoder Loss:  0.043108977  || Decoder Loss:  0.03314457 Validation Decoder Loss:  0.33531743
Encoder Loss:  0.04307445  || Decoder Loss:  0.033114478 Validation Decoder Loss:  0.3359377
Encoder Loss:  0.04303254  || Decoder Loss:  0.033036217 Validation Decoder Loss:  0.33640894
Encoder Loss:  0.043011375  || Decoder Loss:  0.032991223 Validation Decoder Loss:  0.3365426
Encoder Loss:  0.04298367  || Decoder Loss:  0.03292802 Validation Decoder Loss:  0.33687162
Encoder Loss:  0.042964462  || Decoder Loss:  0.03287821 Validation Decoder Loss:  0.3369674
Encoder Loss:  0.042940225  || Decoder Loss:  0.032820567 Validation Decoder Loss:  0.33712852
Encoder Loss:  0.042912092  || Decoder Loss:  0.03275934 Validation Decoder Loss:  0.3373877
Encoder Loss:  0.04288702  || Decoder Loss:  0.032699063 Validation Decoder Loss:  0.33747834
Encoder Loss:  0.04285911  || Decoder Loss:  0.03263047 Validation Decoder Loss:  0.33758622
Encoder Loss:  0.042835098  || Decoder Loss:  0.032567214 Validation Decoder Loss:  0.33764434
Encoder Loss:  0.042802706  || Decoder Loss:  0.032498684 Validation Decoder Loss:  0.33769095
Encoder Loss:  0.04277902  || Decoder Loss:  0.032442667 Validation Decoder Loss:  0.33777863
Encoder Loss:  0.04274872  || Decoder Loss:  0.0323579 Validation Decoder Loss:  0.33805147
Encoder Loss:  0.04271238  || Decoder Loss:  0.032281775 Validation Decoder Loss:  0.3380822
Encoder Loss:  0.0426814  || Decoder Loss:  0.03220876 Validation Decoder Loss:  0.33726245
Encoder Loss:  0.042695977  || Decoder Loss:  0.032235615 Validation Decoder Loss:  0.33791256
Encoder Loss:  0.04266078  || Decoder Loss:  0.032156065 Validation Decoder Loss:  0.34176922
Encoder Loss:  0.042628787  || Decoder Loss:  0.03208374 Validation Decoder Loss:  0.34488636
Encoder Loss:  0.042610526  || Decoder Loss:  0.032033592 Validation Decoder Loss:  0.3452802
Encoder Loss:  0.04259612  || Decoder Loss:  0.031998824 Validation Decoder Loss:  0.3450018
Encoder Loss:  0.042582102  || Decoder Loss:  0.031964898 Validation Decoder Loss:  0.3447848
Encoder Loss:  0.042567786  || Decoder Loss:  0.03194394 Validation Decoder Loss:  0.34485698
Encoder Loss:  0.04256685  || Decoder Loss:  0.03192027 Validation Decoder Loss:  0.34472585
Encoder Loss:  0.042548593  || Decoder Loss:  0.03190072 Validation Decoder Loss:  0.3446994
Encoder Loss:  0.04253977  || Decoder Loss:  0.031874653 Validation Decoder Loss:  0.3442106
Encoder Loss:  0.042622447  || Decoder Loss:  0.031834457 Validation Decoder Loss:  0.34281284
Encoder Loss:  0.042522356  || Decoder Loss:  0.031834465 Validation Decoder Loss:  0.34326303
Model: siamese_net_lr_0.00190104093190001 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34326303
Model: "sequential_384"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_134 (Conv3D (None, 70, 19, 20, 1)     50        
_________________________________________________________________
dropout_412 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_135 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_115 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_144 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_414 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_145 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_387"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_144 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_416 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_145 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23412521  || Decoder Loss:  0.16173303 Validation Decoder Loss:  0.3693641
Encoder Loss:  0.2970371  || Decoder Loss:  0.44880202 Validation Decoder Loss:  0.36137885
Encoder Loss:  0.2867139  || Decoder Loss:  0.4419925 Validation Decoder Loss:  1.6150582
Encoder Loss:  0.33158824  || Decoder Loss:  0.5336984 Validation Decoder Loss:  0.40953976
Encoder Loss:  0.3004526  || Decoder Loss:  0.5010477 Validation Decoder Loss:  0.8099077
Encoder Loss:  0.30306414  || Decoder Loss:  0.5049954 Validation Decoder Loss:  0.978113
Encoder Loss:  0.29644358  || Decoder Loss:  0.49590385 Validation Decoder Loss:  1.0066404
Encoder Loss:  0.29537427  || Decoder Loss:  0.4955825 Validation Decoder Loss:  0.99728024
Encoder Loss:  0.29439005  || Decoder Loss:  0.494584 Validation Decoder Loss:  0.99592996
Encoder Loss:  0.29351476  || Decoder Loss:  0.4933587 Validation Decoder Loss:  0.9966831
Encoder Loss:  0.29176182  || Decoder Loss:  0.49012306 Validation Decoder Loss:  1.0028855
Encoder Loss:  0.2903375  || Decoder Loss:  0.48753142 Validation Decoder Loss:  1.0129173
Encoder Loss:  0.28931618  || Decoder Loss:  0.48565698 Validation Decoder Loss:  1.0124462
Encoder Loss:  0.25260258  || Decoder Loss:  0.41877377 Validation Decoder Loss:  0.93136215
Encoder Loss:  0.09868236  || Decoder Loss:  0.13856126 Validation Decoder Loss:  0.33239165
Encoder Loss:  0.04232926  || Decoder Loss:  0.03594642 Validation Decoder Loss:  0.33239287
Encoder Loss:  0.042289067  || Decoder Loss:  0.03587935 Validation Decoder Loss:  0.33245736
Encoder Loss:  0.042274833  || Decoder Loss:  0.035846997 Validation Decoder Loss:  0.3325388
Encoder Loss:  0.042312916  || Decoder Loss:  0.035837475 Validation Decoder Loss:  0.3326706
Encoder Loss:  0.042245477  || Decoder Loss:  0.035806186 Validation Decoder Loss:  0.33237892
Encoder Loss:  0.0422422  || Decoder Loss:  0.035794612 Validation Decoder Loss:  0.33227032
Encoder Loss:  0.042283583  || Decoder Loss:  0.035808414 Validation Decoder Loss:  0.33240372
Encoder Loss:  0.042254522  || Decoder Loss:  0.0357959 Validation Decoder Loss:  0.33331212
Encoder Loss:  0.042311072  || Decoder Loss:  0.035827164 Validation Decoder Loss:  0.33257204
Encoder Loss:  0.04223287  || Decoder Loss:  0.03574906 Validation Decoder Loss:  0.33240625
Encoder Loss:  0.042252216  || Decoder Loss:  0.035761643 Validation Decoder Loss:  0.33271408
Encoder Loss:  0.04220459  || Decoder Loss:  0.035713125 Validation Decoder Loss:  0.33267197
Encoder Loss:  0.042213608  || Decoder Loss:  0.035718206 Validation Decoder Loss:  0.3324058
Encoder Loss:  0.042308554  || Decoder Loss:  0.035782453 Validation Decoder Loss:  0.33179933
Encoder Loss:  0.042259738  || Decoder Loss:  0.03577938 Validation Decoder Loss:  0.33254474
Encoder Loss:  0.042219304  || Decoder Loss:  0.035694897 Validation Decoder Loss:  0.3327071
Encoder Loss:  0.04244254  || Decoder Loss:  0.03599464 Validation Decoder Loss:  0.32935295
Encoder Loss:  0.042644683  || Decoder Loss:  0.035937883 Validation Decoder Loss:  0.3346998
Encoder Loss:  0.042215634  || Decoder Loss:  0.035630163 Validation Decoder Loss:  0.33117807
Encoder Loss:  0.04213217  || Decoder Loss:  0.035571143 Validation Decoder Loss:  0.33134183
Encoder Loss:  0.04216068  || Decoder Loss:  0.035599865 Validation Decoder Loss:  0.33417934
Encoder Loss:  0.042621594  || Decoder Loss:  0.036236554 Validation Decoder Loss:  0.3317992
Encoder Loss:  0.04231152  || Decoder Loss:  0.035788942 Validation Decoder Loss:  0.333259
Encoder Loss:  0.042223517  || Decoder Loss:  0.0356628 Validation Decoder Loss:  0.33136758
Encoder Loss:  0.042232867  || Decoder Loss:  0.035743877 Validation Decoder Loss:  0.33173913
Model: siamese_net_lr_0.8787873363410368 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33173916
Model: "sequential_388"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_137 (Conv3D (None, 67, 10, 20, 1)     25        
_________________________________________________________________
dropout_418 (Dropout)        (None, 67, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_138 (Conv3D (None, 74, 30, 20, 1)     97        
_________________________________________________________________
reshape_116 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 122
Trainable params: 122
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_390"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_146 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_420 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_147 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_391"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_146 (Conv2D (None, 2470, 20, 1)       252       
_________________________________________________________________
dropout_422 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_147 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.071923904  || Decoder Loss:  0.07686674 Validation Decoder Loss:  0.36969107
Encoder Loss:  0.053275246  || Decoder Loss:  0.056804787 Validation Decoder Loss:  0.35990867
Encoder Loss:  0.20142351  || Decoder Loss:  0.4671952 Validation Decoder Loss:  1.0011537
Encoder Loss:  0.19017167  || Decoder Loss:  0.49456677 Validation Decoder Loss:  1.0010169
Encoder Loss:  0.19140686  || Decoder Loss:  0.49602574 Validation Decoder Loss:  1.0005751
Encoder Loss:  0.18971415  || Decoder Loss:  0.49631664 Validation Decoder Loss:  1.0003376
Encoder Loss:  0.18360442  || Decoder Loss:  0.477746 Validation Decoder Loss:  0.92160445
Encoder Loss:  0.1892682  || Decoder Loss:  0.49588016 Validation Decoder Loss:  0.9907057
Encoder Loss:  0.19071148  || Decoder Loss:  0.50051713 Validation Decoder Loss:  1.0035422
Encoder Loss:  0.18275923  || Decoder Loss:  0.47497976 Validation Decoder Loss:  1.0050764
Encoder Loss:  0.19036952  || Decoder Loss:  0.49943855 Validation Decoder Loss:  1.0033611
Encoder Loss:  0.19037613  || Decoder Loss:  0.49946672 Validation Decoder Loss:  1.0032445
Encoder Loss:  0.19028385  || Decoder Loss:  0.4991673 Validation Decoder Loss:  1.0006522
Encoder Loss:  0.19041073  || Decoder Loss:  0.49956676 Validation Decoder Loss:  1.0000405
Encoder Loss:  0.17375235  || Decoder Loss:  0.44622394 Validation Decoder Loss:  1.0053945
Encoder Loss:  0.19106454  || Decoder Loss:  0.5018914 Validation Decoder Loss:  1.2131727
Encoder Loss:  0.2112236  || Decoder Loss:  0.5102742 Validation Decoder Loss:  0.9974125
Encoder Loss:  0.1930287  || Decoder Loss:  0.50066096 Validation Decoder Loss:  0.99630576
Encoder Loss:  0.19241008  || Decoder Loss:  0.50057024 Validation Decoder Loss:  0.99573493
Encoder Loss:  0.19205143  || Decoder Loss:  0.50020415 Validation Decoder Loss:  0.9987748
Encoder Loss:  0.18999135  || Decoder Loss:  0.49774104 Validation Decoder Loss:  0.9980049
Encoder Loss:  0.18888335  || Decoder Loss:  0.49432015 Validation Decoder Loss:  1.0002298
Encoder Loss:  0.18809617  || Decoder Loss:  0.49165192 Validation Decoder Loss:  1.0210152
Encoder Loss:  0.18911384  || Decoder Loss:  0.49337676 Validation Decoder Loss:  0.9903243
Encoder Loss:  0.18778534  || Decoder Loss:  0.49049613 Validation Decoder Loss:  0.97459996
Encoder Loss:  0.18944946  || Decoder Loss:  0.49435803 Validation Decoder Loss:  1.0137705
Encoder Loss:  0.18606941  || Decoder Loss:  0.48516142 Validation Decoder Loss:  1.0030515
Encoder Loss:  0.17966327  || Decoder Loss:  0.46450627 Validation Decoder Loss:  0.8121518
Encoder Loss:  0.1866972  || Decoder Loss:  0.4873088 Validation Decoder Loss:  1.0033231
Encoder Loss:  0.18919685  || Decoder Loss:  0.49539104 Validation Decoder Loss:  0.99999964
Encoder Loss:  0.18878837  || Decoder Loss:  0.494363 Validation Decoder Loss:  0.99995553
Encoder Loss:  0.18641716  || Decoder Loss:  0.48651773 Validation Decoder Loss:  0.99100953
Encoder Loss:  0.18547453  || Decoder Loss:  0.4837389 Validation Decoder Loss:  0.79106367
Encoder Loss:  0.19071755  || Decoder Loss:  0.50016373 Validation Decoder Loss:  0.9960463
Encoder Loss:  0.18936251  || Decoder Loss:  0.49611205 Validation Decoder Loss:  1.0432773
Encoder Loss:  0.1908895  || Decoder Loss:  0.4997152 Validation Decoder Loss:  1.0000081
Encoder Loss:  0.18882617  || Decoder Loss:  0.49451274 Validation Decoder Loss:  0.9997997
Encoder Loss:  0.18878928  || Decoder Loss:  0.49429893 Validation Decoder Loss:  1.0013205
Encoder Loss:  0.18919632  || Decoder Loss:  0.4953074 Validation Decoder Loss:  1.0000887
Encoder Loss:  0.18873769  || Decoder Loss:  0.4942184 Validation Decoder Loss:  0.99956495
Model: siamese_net_lr_0.6572266005342624 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99956495
Model: "sequential_392"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_140 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_424 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_141 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_117 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_394"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_148 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_426 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_149 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_395"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_148 (Conv2D (None, 2590, 20, 1)       372       
_________________________________________________________________
dropout_428 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_149 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30163735  || Decoder Loss:  0.30265066 Validation Decoder Loss:  1.5616707
Encoder Loss:  0.49742314  || Decoder Loss:  0.51371473 Validation Decoder Loss:  1.014485
Encoder Loss:  0.47720703  || Decoder Loss:  0.4930869 Validation Decoder Loss:  1.0141542
Encoder Loss:  0.47429734  || Decoder Loss:  0.4900635 Validation Decoder Loss:  1.0180283
Encoder Loss:  0.46989492  || Decoder Loss:  0.48549816 Validation Decoder Loss:  1.0329239
Encoder Loss:  0.47106767  || Decoder Loss:  0.48671195 Validation Decoder Loss:  1.0086524
Encoder Loss:  0.4738667  || Decoder Loss:  0.4896131 Validation Decoder Loss:  1.062427
Encoder Loss:  0.48340404  || Decoder Loss:  0.49933192 Validation Decoder Loss:  1.0176692
Encoder Loss:  0.4730204  || Decoder Loss:  0.48874682 Validation Decoder Loss:  1.019546
Encoder Loss:  0.46612176  || Decoder Loss:  0.48158252 Validation Decoder Loss:  1.030622
Encoder Loss:  0.47159427  || Decoder Loss:  0.48726085 Validation Decoder Loss:  1.0033798
Encoder Loss:  0.4731433  || Decoder Loss:  0.48886585 Validation Decoder Loss:  1.2851294
Encoder Loss:  0.5342081  || Decoder Loss:  0.550744 Validation Decoder Loss:  1.0219378
Encoder Loss:  0.47595054  || Decoder Loss:  0.49178612 Validation Decoder Loss:  1.0715057
Encoder Loss:  0.4762058  || Decoder Loss:  0.49204886 Validation Decoder Loss:  0.99824893
Encoder Loss:  0.47020137  || Decoder Loss:  0.48579758 Validation Decoder Loss:  1.0489534
Encoder Loss:  0.4696513  || Decoder Loss:  0.48524997 Validation Decoder Loss:  1.0180798
Encoder Loss:  0.47331107  || Decoder Loss:  0.48904023 Validation Decoder Loss:  1.0969641
Encoder Loss:  0.47221076  || Decoder Loss:  0.4878176 Validation Decoder Loss:  1.02088
Encoder Loss:  0.46415475  || Decoder Loss:  0.47955182 Validation Decoder Loss:  1.0038644
Encoder Loss:  0.4717437  || Decoder Loss:  0.48742005 Validation Decoder Loss:  1.0149734
Encoder Loss:  0.46827915  || Decoder Loss:  0.48382804 Validation Decoder Loss:  0.64379954
Encoder Loss:  0.47059608  || Decoder Loss:  0.48619583 Validation Decoder Loss:  1.0158473
Encoder Loss:  0.4626196  || Decoder Loss:  0.47796097 Validation Decoder Loss:  1.0127802
Encoder Loss:  0.45893788  || Decoder Loss:  0.4741414 Validation Decoder Loss:  0.99980235
Encoder Loss:  0.47313827  || Decoder Loss:  0.4888671 Validation Decoder Loss:  1.0151612
Encoder Loss:  0.47207925  || Decoder Loss:  0.48776984 Validation Decoder Loss:  1.0291796
Encoder Loss:  0.46051365  || Decoder Loss:  0.47577643 Validation Decoder Loss:  1.0150769
Encoder Loss:  0.45879745  || Decoder Loss:  0.47399634 Validation Decoder Loss:  1.0328083
Encoder Loss:  0.4594055  || Decoder Loss:  0.47462705 Validation Decoder Loss:  1.0104873
Encoder Loss:  0.46503457  || Decoder Loss:  0.48046592 Validation Decoder Loss:  0.9737289
Encoder Loss:  0.45763057  || Decoder Loss:  0.47278687 Validation Decoder Loss:  1.0056583
Encoder Loss:  0.47411984  || Decoder Loss:  0.48988885 Validation Decoder Loss:  0.9786308
Encoder Loss:  0.46055707  || Decoder Loss:  0.47582152 Validation Decoder Loss:  0.98876464
Encoder Loss:  0.4703106  || Decoder Loss:  0.4859381 Validation Decoder Loss:  1.0112176
Encoder Loss:  0.47129458  || Decoder Loss:  0.4869527 Validation Decoder Loss:  1.0201066
Encoder Loss:  0.4762912  || Decoder Loss:  0.49214104 Validation Decoder Loss:  1.0274701
Encoder Loss:  0.46072003  || Decoder Loss:  0.47599116 Validation Decoder Loss:  1.034344
Encoder Loss:  0.45854673  || Decoder Loss:  0.4737368 Validation Decoder Loss:  1.0356268
Encoder Loss:  0.4579874  || Decoder Loss:  0.47315642 Validation Decoder Loss:  1.0426513
Model: siamese_net_lr_0.7806725153341371 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0426513
Model: "sequential_396"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_143 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_430 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_144 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_118 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_398"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_150 (Conv2D)          (None, 2270, 20, 1)       339       
_________________________________________________________________
dropout_432 (Dropout)        (None, 2270, 20, 1)       0         
_________________________________________________________________
conv2d_151 (Conv2D)          (None, 2220, 20, 1)       52        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_399"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_150 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_434 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_151 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.18350944  || Decoder Loss:  0.44693825 Validation Decoder Loss:  1.0065376
Encoder Loss:  0.1274716  || Decoder Loss:  0.49751228 Validation Decoder Loss:  1.0032988
Encoder Loss:  0.12902397  || Decoder Loss:  0.49700195 Validation Decoder Loss:  1.0008744
Encoder Loss:  0.12751253  || Decoder Loss:  0.4966786 Validation Decoder Loss:  1.000063
Encoder Loss:  0.12784025  || Decoder Loss:  0.49622416 Validation Decoder Loss:  1.0008607
Encoder Loss:  0.116625935  || Decoder Loss:  0.43693912 Validation Decoder Loss:  0.34362572
Encoder Loss:  0.049015876  || Decoder Loss:  0.044015203 Validation Decoder Loss:  0.33419067
Encoder Loss:  0.04764898  || Decoder Loss:  0.036170576 Validation Decoder Loss:  0.3338378
Encoder Loss:  0.047633566  || Decoder Loss:  0.036116943 Validation Decoder Loss:  0.3338092
Encoder Loss:  0.047650915  || Decoder Loss:  0.036098268 Validation Decoder Loss:  0.33374286
Encoder Loss:  0.04761374  || Decoder Loss:  0.03605477 Validation Decoder Loss:  0.33375394
Encoder Loss:  0.04761439  || Decoder Loss:  0.03603558 Validation Decoder Loss:  0.3336415
Encoder Loss:  0.047604557  || Decoder Loss:  0.0359862 Validation Decoder Loss:  0.3337134
Encoder Loss:  0.04759155  || Decoder Loss:  0.035938665 Validation Decoder Loss:  0.33393013
Encoder Loss:  0.047582507  || Decoder Loss:  0.03589109 Validation Decoder Loss:  0.33376896
Encoder Loss:  0.047572665  || Decoder Loss:  0.035846002 Validation Decoder Loss:  0.33373785
Encoder Loss:  0.047564674  || Decoder Loss:  0.035789434 Validation Decoder Loss:  0.33376494
Encoder Loss:  0.047563463  || Decoder Loss:  0.035754815 Validation Decoder Loss:  0.3337934
Encoder Loss:  0.04754537  || Decoder Loss:  0.035687882 Validation Decoder Loss:  0.33389717
Encoder Loss:  0.047540154  || Decoder Loss:  0.035648853 Validation Decoder Loss:  0.3337464
Encoder Loss:  0.04752915  || Decoder Loss:  0.0355873 Validation Decoder Loss:  0.3341917
Encoder Loss:  0.047527913  || Decoder Loss:  0.035550978 Validation Decoder Loss:  0.33396354
Encoder Loss:  0.047514215  || Decoder Loss:  0.035492197 Validation Decoder Loss:  0.3341192
Encoder Loss:  0.047506895  || Decoder Loss:  0.03545025 Validation Decoder Loss:  0.33434862
Encoder Loss:  0.047544837  || Decoder Loss:  0.035630435 Validation Decoder Loss:  0.3343835
Encoder Loss:  0.047506776  || Decoder Loss:  0.035416428 Validation Decoder Loss:  0.3343174
Encoder Loss:  0.04752071  || Decoder Loss:  0.03551103 Validation Decoder Loss:  0.33436292
Encoder Loss:  0.04752496  || Decoder Loss:  0.03550879 Validation Decoder Loss:  0.3346269
Encoder Loss:  0.04750856  || Decoder Loss:  0.03537287 Validation Decoder Loss:  0.33454284
Encoder Loss:  0.047575817  || Decoder Loss:  0.035657536 Validation Decoder Loss:  0.3341667
Encoder Loss:  0.047540218  || Decoder Loss:  0.035431206 Validation Decoder Loss:  0.3348436
Encoder Loss:  0.04801209  || Decoder Loss:  0.038237676 Validation Decoder Loss:  0.33468452
Encoder Loss:  0.04748177  || Decoder Loss:  0.035301678 Validation Decoder Loss:  0.33458447
Encoder Loss:  0.04748278  || Decoder Loss:  0.035312455 Validation Decoder Loss:  0.33515146
Encoder Loss:  0.047480136  || Decoder Loss:  0.035272926 Validation Decoder Loss:  0.3346308
Encoder Loss:  0.047469713  || Decoder Loss:  0.035244416 Validation Decoder Loss:  0.33456907
Encoder Loss:  0.047479782  || Decoder Loss:  0.035281103 Validation Decoder Loss:  0.33435762
Encoder Loss:  0.047457  || Decoder Loss:  0.035184167 Validation Decoder Loss:  0.33435938
Encoder Loss:  0.047550604  || Decoder Loss:  0.035644963 Validation Decoder Loss:  0.33369645
Encoder Loss:  0.047466353  || Decoder Loss:  0.0352368 Validation Decoder Loss:  0.33420968
Model: siamese_net_lr_0.2526013030300542 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33420968
Model: "sequential_400"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_146 (Conv3D (None, 70, 19, 20, 1)     106       
_________________________________________________________________
dropout_436 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_147 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_119 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 167
Trainable params: 167
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_402"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_152 (Conv2D)          (None, 2260, 20, 1)       349       
_________________________________________________________________
dropout_438 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_153 (Conv2D)          (None, 2220, 20, 1)       42        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_403"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_152 (Conv2D (None, 2520, 20, 1)       302       
_________________________________________________________________
dropout_440 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_153 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39026546  || Decoder Loss:  0.4400874 Validation Decoder Loss:  0.9940903
Encoder Loss:  0.41802895  || Decoder Loss:  0.4974576 Validation Decoder Loss:  0.9988621
Encoder Loss:  0.41789886  || Decoder Loss:  0.49741435 Validation Decoder Loss:  0.99937475
Encoder Loss:  0.41746864  || Decoder Loss:  0.49725032 Validation Decoder Loss:  0.9998511
Encoder Loss:  0.4172557  || Decoder Loss:  0.49702725 Validation Decoder Loss:  1.0001788
Encoder Loss:  0.4169664  || Decoder Loss:  0.4967067 Validation Decoder Loss:  1.0002215
Encoder Loss:  0.41654846  || Decoder Loss:  0.4961823 Validation Decoder Loss:  0.9998186
Encoder Loss:  0.41595128  || Decoder Loss:  0.49546593 Validation Decoder Loss:  0.99910116
Encoder Loss:  0.4155068  || Decoder Loss:  0.4949289 Validation Decoder Loss:  0.998996
Encoder Loss:  0.41527802  || Decoder Loss:  0.49464646 Validation Decoder Loss:  0.99949694
Encoder Loss:  0.41505364  || Decoder Loss:  0.49437124 Validation Decoder Loss:  1.0001917
Encoder Loss:  0.41472206  || Decoder Loss:  0.49396497 Validation Decoder Loss:  1.0019072
Encoder Loss:  0.41408864  || Decoder Loss:  0.49320155 Validation Decoder Loss:  1.0060158
Encoder Loss:  0.41257092  || Decoder Loss:  0.49134076 Validation Decoder Loss:  1.0170422
Encoder Loss:  0.41170746  || Decoder Loss:  0.49029776 Validation Decoder Loss:  1.0175971
Encoder Loss:  0.41096714  || Decoder Loss:  0.48940232 Validation Decoder Loss:  1.0186323
Encoder Loss:  0.41031888  || Decoder Loss:  0.4886084 Validation Decoder Loss:  1.0195253
Encoder Loss:  0.40939862  || Decoder Loss:  0.48748317 Validation Decoder Loss:  1.0242345
Encoder Loss:  0.40808982  || Decoder Loss:  0.48589107 Validation Decoder Loss:  1.0249064
Encoder Loss:  0.4063491  || Decoder Loss:  0.48377183 Validation Decoder Loss:  1.0280102
Encoder Loss:  0.40452984  || Decoder Loss:  0.4815546 Validation Decoder Loss:  1.0125668
Encoder Loss:  0.40506327  || Decoder Loss:  0.48216617 Validation Decoder Loss:  1.0225201
Encoder Loss:  0.4001898  || Decoder Loss:  0.4762136 Validation Decoder Loss:  0.9248279
Encoder Loss:  0.41955748  || Decoder Loss:  0.49975216 Validation Decoder Loss:  0.988057
Encoder Loss:  0.41687682  || Decoder Loss:  0.4965872 Validation Decoder Loss:  0.99121004
Encoder Loss:  0.41432858  || Decoder Loss:  0.49345157 Validation Decoder Loss:  0.9996173
Encoder Loss:  0.40780896  || Decoder Loss:  0.48552912 Validation Decoder Loss:  0.9966821
Encoder Loss:  0.40872562  || Decoder Loss:  0.48666978 Validation Decoder Loss:  0.9883292
Encoder Loss:  0.3444931  || Decoder Loss:  0.40847015 Validation Decoder Loss:  0.9864521
Encoder Loss:  0.41825935  || Decoder Loss:  0.49826306 Validation Decoder Loss:  0.9880415
Encoder Loss:  0.4174769  || Decoder Loss:  0.49732104 Validation Decoder Loss:  0.9898495
Encoder Loss:  0.41595864  || Decoder Loss:  0.49542663 Validation Decoder Loss:  0.9792181
Encoder Loss:  0.41660327  || Decoder Loss:  0.49620494 Validation Decoder Loss:  0.9945642
Encoder Loss:  0.41767696  || Decoder Loss:  0.49752843 Validation Decoder Loss:  0.9947002
Encoder Loss:  0.41759264  || Decoder Loss:  0.49745446 Validation Decoder Loss:  0.995224
Encoder Loss:  0.4175519  || Decoder Loss:  0.49739638 Validation Decoder Loss:  0.9953835
Encoder Loss:  0.41752952  || Decoder Loss:  0.49735475 Validation Decoder Loss:  0.9958
Encoder Loss:  0.4174772  || Decoder Loss:  0.49728635 Validation Decoder Loss:  0.99615335
Encoder Loss:  0.41740453  || Decoder Loss:  0.49722764 Validation Decoder Loss:  0.996553
Encoder Loss:  0.41739324  || Decoder Loss:  0.49717277 Validation Decoder Loss:  0.9966708
Model: siamese_net_lr_0.8015785039340544 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99667084
Model: "sequential_404"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_149 (Conv3D (None, 69, 10, 20, 1)     37        
_________________________________________________________________
dropout_442 (Dropout)        (None, 69, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_150 (Conv3D (None, 74, 30, 20, 1)     73        
_________________________________________________________________
reshape_120 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 110
Trainable params: 110
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_406"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_154 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_444 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_407"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_154 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_446 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_155 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31610295  || Decoder Loss:  0.3446229 Validation Decoder Loss:  0.39033353
Encoder Loss:  0.40495464  || Decoder Loss:  0.4805746 Validation Decoder Loss:  1.6371527
Encoder Loss:  0.40738812  || Decoder Loss:  0.48416626 Validation Decoder Loss:  1.6536298
Encoder Loss:  0.42753264  || Decoder Loss:  0.50881726 Validation Decoder Loss:  1.0279424
Encoder Loss:  0.42178848  || Decoder Loss:  0.5026598 Validation Decoder Loss:  1.0056393
Encoder Loss:  0.4205463  || Decoder Loss:  0.5014367 Validation Decoder Loss:  1.0013702
Encoder Loss:  0.4174164  || Decoder Loss:  0.4975592 Validation Decoder Loss:  0.9897822
Encoder Loss:  0.417276  || Decoder Loss:  0.49738944 Validation Decoder Loss:  0.9961288
Encoder Loss:  0.4188273  || Decoder Loss:  0.49950543 Validation Decoder Loss:  1.0007005
Encoder Loss:  0.4176363  || Decoder Loss:  0.4980658 Validation Decoder Loss:  0.9969758
Encoder Loss:  0.415379  || Decoder Loss:  0.49537 Validation Decoder Loss:  0.99670154
Encoder Loss:  0.41473728  || Decoder Loss:  0.4945758 Validation Decoder Loss:  0.9972657
Encoder Loss:  0.41765115  || Decoder Loss:  0.49808124 Validation Decoder Loss:  1.0046949
Encoder Loss:  0.41799027  || Decoder Loss:  0.49855277 Validation Decoder Loss:  1.0028355
Encoder Loss:  0.41597384  || Decoder Loss:  0.49609601 Validation Decoder Loss:  1.001892
Encoder Loss:  0.41456574  || Decoder Loss:  0.49437878 Validation Decoder Loss:  1.0063834
Encoder Loss:  0.41449288  || Decoder Loss:  0.4942899 Validation Decoder Loss:  1.0064371
Encoder Loss:  0.4154332  || Decoder Loss:  0.4954368 Validation Decoder Loss:  1.00957
Encoder Loss:  0.41438168  || Decoder Loss:  0.49415374 Validation Decoder Loss:  0.9912995
Encoder Loss:  0.37250173  || Decoder Loss:  0.44310406 Validation Decoder Loss:  1.0762652
Encoder Loss:  0.42298087  || Decoder Loss:  0.5046364 Validation Decoder Loss:  1.0354234
Encoder Loss:  0.4223569  || Decoder Loss:  0.5038528 Validation Decoder Loss:  0.9771122
Encoder Loss:  0.41920403  || Decoder Loss:  0.5000287 Validation Decoder Loss:  0.9944018
Encoder Loss:  0.38357848  || Decoder Loss:  0.45660505 Validation Decoder Loss:  1.0927305
Encoder Loss:  0.35758507  || Decoder Loss:  0.42492172 Validation Decoder Loss:  0.44419572
Encoder Loss:  0.24870843  || Decoder Loss:  0.29220885 Validation Decoder Loss:  1.013694
Encoder Loss:  0.35130066  || Decoder Loss:  0.417261 Validation Decoder Loss:  1.0144871
Encoder Loss:  0.42467228  || Decoder Loss:  0.5066909 Validation Decoder Loss:  0.99329823
Encoder Loss:  0.40734065  || Decoder Loss:  0.48557076 Validation Decoder Loss:  0.87359095
Encoder Loss:  0.41011992  || Decoder Loss:  0.48895797 Validation Decoder Loss:  1.0094533
Encoder Loss:  0.4012844  || Decoder Loss:  0.4781881 Validation Decoder Loss:  1.6286948
Encoder Loss:  0.30887774  || Decoder Loss:  0.3655514 Validation Decoder Loss:  0.36850888
Encoder Loss:  0.44056788  || Decoder Loss:  0.5260717 Validation Decoder Loss:  0.55805665
Encoder Loss:  0.43430135  || Decoder Loss:  0.5184338 Validation Decoder Loss:  1.0009555
Encoder Loss:  0.42068905  || Decoder Loss:  0.5018423 Validation Decoder Loss:  1.0591621
Encoder Loss:  0.41878894  || Decoder Loss:  0.49952525 Validation Decoder Loss:  0.9948794
Encoder Loss:  0.42385304  || Decoder Loss:  0.5056797 Validation Decoder Loss:  0.4126807
Encoder Loss:  0.4392846  || Decoder Loss:  0.5245082 Validation Decoder Loss:  1.050191
Encoder Loss:  0.42106387  || Decoder Loss:  0.5022993 Validation Decoder Loss:  1.0135038
Encoder Loss:  0.42073342  || Decoder Loss:  0.5018964 Validation Decoder Loss:  0.98861945
Model: siamese_net_lr_0.833790148974879 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.98861945
Model: "sequential_408"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_152 (Conv3D (None, 70, 9, 20, 1)      36        
_________________________________________________________________
dropout_448 (Dropout)        (None, 70, 9, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_153 (Conv3D (None, 74, 30, 20, 1)     71        
_________________________________________________________________
reshape_121 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 107
Trainable params: 107
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_410"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_156 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_450 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 2220, 20, 1)       282       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_411"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_156 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_452 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_157 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.24242614  || Decoder Loss:  0.39275056 Validation Decoder Loss:  0.58122635
Encoder Loss:  0.26597655  || Decoder Loss:  0.5208723 Validation Decoder Loss:  1.017369
Encoder Loss:  0.2556242  || Decoder Loss:  0.4984123 Validation Decoder Loss:  1.014646
Encoder Loss:  0.25445238  || Decoder Loss:  0.49584827 Validation Decoder Loss:  1.0140679
Encoder Loss:  0.25408024  || Decoder Loss:  0.49506232 Validation Decoder Loss:  1.0132384
Encoder Loss:  0.25353622  || Decoder Loss:  0.4938822 Validation Decoder Loss:  1.0141783
Encoder Loss:  0.25365534  || Decoder Loss:  0.49413773 Validation Decoder Loss:  1.0120714
Encoder Loss:  0.25447026  || Decoder Loss:  0.49581516 Validation Decoder Loss:  1.0197881
Encoder Loss:  0.25140533  || Decoder Loss:  0.48917398 Validation Decoder Loss:  0.998509
Encoder Loss:  0.24231476  || Decoder Loss:  0.46940982 Validation Decoder Loss:  0.58837456
Encoder Loss:  0.19623823  || Decoder Loss:  0.36891487 Validation Decoder Loss:  0.5134219
Encoder Loss:  0.06983039  || Decoder Loss:  0.09322823 Validation Decoder Loss:  0.3414068
Encoder Loss:  0.04360269  || Decoder Loss:  0.036027886 Validation Decoder Loss:  0.33395007
Encoder Loss:  0.04347832  || Decoder Loss:  0.035758268 Validation Decoder Loss:  0.33989012
Encoder Loss:  0.043364666  || Decoder Loss:  0.035509422 Validation Decoder Loss:  0.33703327
Encoder Loss:  0.043294195  || Decoder Loss:  0.035359778 Validation Decoder Loss:  0.33354557
Encoder Loss:  0.043187104  || Decoder Loss:  0.03512871 Validation Decoder Loss:  0.33493948
Encoder Loss:  0.043051332  || Decoder Loss:  0.03483235 Validation Decoder Loss:  0.33653894
Encoder Loss:  0.042998582  || Decoder Loss:  0.03471706 Validation Decoder Loss:  0.33948034
Encoder Loss:  0.04302412  || Decoder Loss:  0.034767352 Validation Decoder Loss:  0.34181684
Encoder Loss:  0.042966753  || Decoder Loss:  0.034641992 Validation Decoder Loss:  0.34254014
Encoder Loss:  0.042905115  || Decoder Loss:  0.03451434 Validation Decoder Loss:  0.3393597
Encoder Loss:  0.04293353  || Decoder Loss:  0.034572408 Validation Decoder Loss:  0.3361274
Encoder Loss:  0.042920247  || Decoder Loss:  0.034545444 Validation Decoder Loss:  0.3463495
Encoder Loss:  0.042980853  || Decoder Loss:  0.03467196 Validation Decoder Loss:  0.3363405
Encoder Loss:  0.04299855  || Decoder Loss:  0.034712754 Validation Decoder Loss:  0.34019226
Encoder Loss:  0.042991813  || Decoder Loss:  0.0347029 Validation Decoder Loss:  0.35224146
Encoder Loss:  0.04320936  || Decoder Loss:  0.035170693 Validation Decoder Loss:  0.33936244
Encoder Loss:  0.04302551  || Decoder Loss:  0.034759816 Validation Decoder Loss:  0.3436947
Encoder Loss:  0.043006252  || Decoder Loss:  0.034733202 Validation Decoder Loss:  0.34248948
Encoder Loss:  0.042937927  || Decoder Loss:  0.03458635 Validation Decoder Loss:  0.33836716
Encoder Loss:  0.043134686  || Decoder Loss:  0.03500827 Validation Decoder Loss:  0.34421903
Encoder Loss:  0.043027095  || Decoder Loss:  0.034779076 Validation Decoder Loss:  0.3370177
Encoder Loss:  0.04292481  || Decoder Loss:  0.034561764 Validation Decoder Loss:  0.34215516
Encoder Loss:  0.042872634  || Decoder Loss:  0.03444506 Validation Decoder Loss:  0.3344105
Encoder Loss:  0.04291065  || Decoder Loss:  0.034523 Validation Decoder Loss:  0.33856848
Encoder Loss:  0.042913485  || Decoder Loss:  0.034529213 Validation Decoder Loss:  0.33757633
Encoder Loss:  0.04290468  || Decoder Loss:  0.034506634 Validation Decoder Loss:  0.33613038
Encoder Loss:  0.04340967  || Decoder Loss:  0.03561201 Validation Decoder Loss:  0.3261283
Encoder Loss:  0.042972885  || Decoder Loss:  0.034664486 Validation Decoder Loss:  0.34228432
Model: siamese_net_lr_0.14480720904642774 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34228426
Model: "sequential_413"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_158 (Conv2D)          (None, 2260, 20, 1)       349       
_________________________________________________________________
dropout_454 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_159 (Conv2D)          (None, 2220, 20, 1)       42        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_414"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_158 (Conv2D (None, 2550, 20, 1)       332       
_________________________________________________________________
dropout_456 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_159 (Conv2D (None, 2607, 20, 1)       59        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_416"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_160 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_458 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_161 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_417"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_160 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_460 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_161 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_418"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_155 (Conv3D (None, 68, 10, 20, 1)     11        
_________________________________________________________________
dropout_462 (Dropout)        (None, 68, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_156 (Conv3D (None, 74, 30, 20, 1)     22        
_________________________________________________________________
reshape_122 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 33
Trainable params: 33
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_420"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_162 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_464 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_163 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_421"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_162 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_466 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_163 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4626288  || Decoder Loss:  0.5075973 Validation Decoder Loss:  0.34239176
Encoder Loss:  0.39450532  || Decoder Loss:  0.4358232 Validation Decoder Loss:  0.97357917
Encoder Loss:  0.3784526  || Decoder Loss:  0.4179286 Validation Decoder Loss:  0.3539399
Encoder Loss:  0.18843517  || Decoder Loss:  0.2050735 Validation Decoder Loss:  0.37172303
Encoder Loss:  0.18556589  || Decoder Loss:  0.20186076 Validation Decoder Loss:  0.3451687
Encoder Loss:  0.14052819  || Decoder Loss:  0.15140948 Validation Decoder Loss:  0.46070576
Encoder Loss:  0.054503053  || Decoder Loss:  0.05504388 Validation Decoder Loss:  0.3569857
Encoder Loss:  0.037847318  || Decoder Loss:  0.036386084 Validation Decoder Loss:  0.3510465
Encoder Loss:  0.03757954  || Decoder Loss:  0.03608607 Validation Decoder Loss:  0.35241726
Encoder Loss:  0.037446912  || Decoder Loss:  0.03593747 Validation Decoder Loss:  0.3528328
Encoder Loss:  0.037358306  || Decoder Loss:  0.03583833 Validation Decoder Loss:  0.35315022
Encoder Loss:  0.037291236  || Decoder Loss:  0.03576311 Validation Decoder Loss:  0.3533731
Encoder Loss:  0.037232924  || Decoder Loss:  0.035697725 Validation Decoder Loss:  0.3533197
Encoder Loss:  0.03717831  || Decoder Loss:  0.035636574 Validation Decoder Loss:  0.35335174
Encoder Loss:  0.037125397  || Decoder Loss:  0.03557737 Validation Decoder Loss:  0.35326433
Encoder Loss:  0.03707085  || Decoder Loss:  0.035516232 Validation Decoder Loss:  0.35321015
Encoder Loss:  0.037014123  || Decoder Loss:  0.035452668 Validation Decoder Loss:  0.35313445
Encoder Loss:  0.036957923  || Decoder Loss:  0.035389822 Validation Decoder Loss:  0.35305458
Encoder Loss:  0.036900293  || Decoder Loss:  0.035325114 Validation Decoder Loss:  0.35279596
Encoder Loss:  0.03684246  || Decoder Loss:  0.035260405 Validation Decoder Loss:  0.3526523
Encoder Loss:  0.036823757  || Decoder Loss:  0.035239253 Validation Decoder Loss:  0.35267168
Encoder Loss:  0.03673216  || Decoder Loss:  0.035136916 Validation Decoder Loss:  0.35256934
Encoder Loss:  0.036664803  || Decoder Loss:  0.035061404 Validation Decoder Loss:  0.35257655
Encoder Loss:  0.0366033  || Decoder Loss:  0.034992527 Validation Decoder Loss:  0.35262844
Encoder Loss:  0.036542267  || Decoder Loss:  0.03492423 Validation Decoder Loss:  0.35249507
Encoder Loss:  0.036483526  || Decoder Loss:  0.03485851 Validation Decoder Loss:  0.3525448
Encoder Loss:  0.03642678  || Decoder Loss:  0.034794714 Validation Decoder Loss:  0.3531232
Encoder Loss:  0.036363825  || Decoder Loss:  0.034724247 Validation Decoder Loss:  0.35289836
Encoder Loss:  0.036307808  || Decoder Loss:  0.03466154 Validation Decoder Loss:  0.35373902
Encoder Loss:  0.03625636  || Decoder Loss:  0.034603946 Validation Decoder Loss:  0.35379738
Encoder Loss:  0.036205284  || Decoder Loss:  0.03454665 Validation Decoder Loss:  0.35410893
Encoder Loss:  0.036152236  || Decoder Loss:  0.03448735 Validation Decoder Loss:  0.35386944
Encoder Loss:  0.0361126  || Decoder Loss:  0.03444288 Validation Decoder Loss:  0.3545317
Encoder Loss:  0.036067203  || Decoder Loss:  0.034392096 Validation Decoder Loss:  0.35447505
Encoder Loss:  0.03602955  || Decoder Loss:  0.034349937 Validation Decoder Loss:  0.35443264
Encoder Loss:  0.03598405  || Decoder Loss:  0.034298908 Validation Decoder Loss:  0.35506326
Encoder Loss:  0.035944268  || Decoder Loss:  0.03425439 Validation Decoder Loss:  0.35438418
Encoder Loss:  0.03590844  || Decoder Loss:  0.034213893 Validation Decoder Loss:  0.35559118
Encoder Loss:  0.035884306  || Decoder Loss:  0.034186233 Validation Decoder Loss:  0.35592884
Encoder Loss:  0.035839442  || Decoder Loss:  0.034135975 Validation Decoder Loss:  0.35733545
Model: siamese_net_lr_0.5690603627637156 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35733545
Model: "sequential_422"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_158 (Conv3D (None, 70, 19, 20, 1)     50        
_________________________________________________________________
dropout_468 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_159 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_123 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_424"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_164 (Conv2D)          (None, 2270, 20, 1)       339       
_________________________________________________________________
dropout_470 (Dropout)        (None, 2270, 20, 1)       0         
_________________________________________________________________
conv2d_165 (Conv2D)          (None, 2220, 20, 1)       52        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_425"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_164 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_472 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_165 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21824552  || Decoder Loss:  0.2959074 Validation Decoder Loss:  1.1866705
Encoder Loss:  0.075971395  || Decoder Loss:  0.5032378 Validation Decoder Loss:  1.002528
Encoder Loss:  0.065632  || Decoder Loss:  0.4991565 Validation Decoder Loss:  1.0025252
Encoder Loss:  0.06537629  || Decoder Loss:  0.49728948 Validation Decoder Loss:  0.9998357
Encoder Loss:  0.06529341  || Decoder Loss:  0.49530545 Validation Decoder Loss:  0.998118
Encoder Loss:  0.06518533  || Decoder Loss:  0.49236247 Validation Decoder Loss:  1.0015254
Encoder Loss:  0.064932175  || Decoder Loss:  0.48503917 Validation Decoder Loss:  0.98074985
Encoder Loss:  0.056671  || Decoder Loss:  0.24427652 Validation Decoder Loss:  0.336013
Encoder Loss:  0.049553256  || Decoder Loss:  0.036811378 Validation Decoder Loss:  0.33418298
Encoder Loss:  0.049538523  || Decoder Loss:  0.036409296 Validation Decoder Loss:  0.334362
Encoder Loss:  0.0495348  || Decoder Loss:  0.036307726 Validation Decoder Loss:  0.33421373
Encoder Loss:  0.04953267  || Decoder Loss:  0.036240615 Validation Decoder Loss:  0.33445698
Encoder Loss:  0.04953049  || Decoder Loss:  0.036197677 Validation Decoder Loss:  0.33430552
Encoder Loss:  0.04952868  || Decoder Loss:  0.03615903 Validation Decoder Loss:  0.33423594
Encoder Loss:  0.04952735  || Decoder Loss:  0.036131803 Validation Decoder Loss:  0.3342237
Encoder Loss:  0.049526468  || Decoder Loss:  0.03610987 Validation Decoder Loss:  0.33421722
Encoder Loss:  0.049527276  || Decoder Loss:  0.0360942 Validation Decoder Loss:  0.33420938
Encoder Loss:  0.049527317  || Decoder Loss:  0.036094245 Validation Decoder Loss:  0.334273
Encoder Loss:  0.049526196  || Decoder Loss:  0.03605863 Validation Decoder Loss:  0.33425957
Encoder Loss:  0.049526792  || Decoder Loss:  0.036056794 Validation Decoder Loss:  0.33417362
Encoder Loss:  0.049526405  || Decoder Loss:  0.036037162 Validation Decoder Loss:  0.33414972
Encoder Loss:  0.049521394  || Decoder Loss:  0.036004175 Validation Decoder Loss:  0.3342994
Encoder Loss:  0.049521383  || Decoder Loss:  0.035974555 Validation Decoder Loss:  0.33430225
Encoder Loss:  0.049520668  || Decoder Loss:  0.035965685 Validation Decoder Loss:  0.33421832
Encoder Loss:  0.049521256  || Decoder Loss:  0.03596061 Validation Decoder Loss:  0.33416235
Encoder Loss:  0.049530093  || Decoder Loss:  0.035968624 Validation Decoder Loss:  0.3340909
Encoder Loss:  0.04951996  || Decoder Loss:  0.03592577 Validation Decoder Loss:  0.33413523
Encoder Loss:  0.049522117  || Decoder Loss:  0.03590314 Validation Decoder Loss:  0.33385774
Encoder Loss:  0.049522705  || Decoder Loss:  0.03587804 Validation Decoder Loss:  0.3339242
Encoder Loss:  0.04952753  || Decoder Loss:  0.03589721 Validation Decoder Loss:  0.334072
Encoder Loss:  0.049548637  || Decoder Loss:  0.035903897 Validation Decoder Loss:  0.3341464
Encoder Loss:  0.04954958  || Decoder Loss:  0.03616011 Validation Decoder Loss:  0.33405972
Encoder Loss:  0.04952405  || Decoder Loss:  0.035787605 Validation Decoder Loss:  0.33410883
Encoder Loss:  0.049554925  || Decoder Loss:  0.035796884 Validation Decoder Loss:  0.3342619
Encoder Loss:  0.049708385  || Decoder Loss:  0.036353927 Validation Decoder Loss:  0.33449697
Encoder Loss:  0.04973834  || Decoder Loss:  0.036450103 Validation Decoder Loss:  0.33563137
Encoder Loss:  0.05010833  || Decoder Loss:  0.036406025 Validation Decoder Loss:  0.33415973
Encoder Loss:  0.04955235  || Decoder Loss:  0.035703525 Validation Decoder Loss:  0.3343591
Encoder Loss:  0.04953968  || Decoder Loss:  0.035645735 Validation Decoder Loss:  0.3347398
Encoder Loss:  0.049508497  || Decoder Loss:  0.035598353 Validation Decoder Loss:  0.33429235
Model: siamese_net_lr_0.2633664812665928 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33429235
Model: "sequential_426"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_161 (Conv3D (None, 70, 19, 20, 1)     106       
_________________________________________________________________
dropout_474 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_162 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_124 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 167
Trainable params: 167
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_428"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_166 (Conv2D)          (None, 2230, 20, 1)       379       
_________________________________________________________________
dropout_476 (Dropout)        (None, 2230, 20, 1)       0         
_________________________________________________________________
conv2d_167 (Conv2D)          (None, 2220, 20, 1)       12        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_429"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_166 (Conv2D (None, 2570, 20, 1)       352       
_________________________________________________________________
dropout_478 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_167 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15777245  || Decoder Loss:  0.42571625 Validation Decoder Loss:  1.0072019
Encoder Loss:  0.07435949  || Decoder Loss:  0.33969516 Validation Decoder Loss:  0.4499538
Encoder Loss:  0.060021248  || Decoder Loss:  0.15864512 Validation Decoder Loss:  0.37052444
Encoder Loss:  0.049828287  || Decoder Loss:  0.045309752 Validation Decoder Loss:  0.33245555
Encoder Loss:  0.049032263  || Decoder Loss:  0.035850473 Validation Decoder Loss:  0.3319803
Encoder Loss:  0.049000155  || Decoder Loss:  0.03577163 Validation Decoder Loss:  0.33164367
Encoder Loss:  0.048979245  || Decoder Loss:  0.035720874 Validation Decoder Loss:  0.33142787
Encoder Loss:  0.048945908  || Decoder Loss:  0.035685703 Validation Decoder Loss:  0.33158562
Encoder Loss:  0.049002465  || Decoder Loss:  0.035672717 Validation Decoder Loss:  0.33151263
Encoder Loss:  0.048949286  || Decoder Loss:  0.035654575 Validation Decoder Loss:  0.33143052
Encoder Loss:  0.04896094  || Decoder Loss:  0.035628624 Validation Decoder Loss:  0.33106273
Encoder Loss:  0.04893167  || Decoder Loss:  0.03560847 Validation Decoder Loss:  0.33160737
Encoder Loss:  0.04893809  || Decoder Loss:  0.035606865 Validation Decoder Loss:  0.3315748
Encoder Loss:  0.048923474  || Decoder Loss:  0.03556712 Validation Decoder Loss:  0.33114824
Encoder Loss:  0.04890851  || Decoder Loss:  0.035550777 Validation Decoder Loss:  0.33122087
Encoder Loss:  0.04887578  || Decoder Loss:  0.0355057 Validation Decoder Loss:  0.3310445
Encoder Loss:  0.048908517  || Decoder Loss:  0.03549194 Validation Decoder Loss:  0.33125865
Encoder Loss:  0.048984863  || Decoder Loss:  0.035495706 Validation Decoder Loss:  0.33141625
Encoder Loss:  0.048865557  || Decoder Loss:  0.035449505 Validation Decoder Loss:  0.3314169
Encoder Loss:  0.048878007  || Decoder Loss:  0.035458215 Validation Decoder Loss:  0.33139354
Encoder Loss:  0.04891055  || Decoder Loss:  0.03545182 Validation Decoder Loss:  0.33140677
Encoder Loss:  0.048856854  || Decoder Loss:  0.03540421 Validation Decoder Loss:  0.33167443
Encoder Loss:  0.048874043  || Decoder Loss:  0.03538366 Validation Decoder Loss:  0.33131558
Encoder Loss:  0.048901897  || Decoder Loss:  0.035547186 Validation Decoder Loss:  0.3314996
Encoder Loss:  0.0488982  || Decoder Loss:  0.035414264 Validation Decoder Loss:  0.33136886
Encoder Loss:  0.048867784  || Decoder Loss:  0.035383847 Validation Decoder Loss:  0.33140874
Encoder Loss:  0.04885466  || Decoder Loss:  0.035431325 Validation Decoder Loss:  0.33134985
Encoder Loss:  0.04882185  || Decoder Loss:  0.03538403 Validation Decoder Loss:  0.33194774
Encoder Loss:  0.04884058  || Decoder Loss:  0.035406645 Validation Decoder Loss:  0.3311587
Encoder Loss:  0.048829947  || Decoder Loss:  0.035445206 Validation Decoder Loss:  0.33128884
Encoder Loss:  0.048822306  || Decoder Loss:  0.035357676 Validation Decoder Loss:  0.3315997
Encoder Loss:  0.048818592  || Decoder Loss:  0.035317216 Validation Decoder Loss:  0.3314448
Encoder Loss:  0.048854556  || Decoder Loss:  0.035396334 Validation Decoder Loss:  0.33155316
Encoder Loss:  0.048805606  || Decoder Loss:  0.03525743 Validation Decoder Loss:  0.33142036
Encoder Loss:  0.048804745  || Decoder Loss:  0.035240494 Validation Decoder Loss:  0.33174548
Encoder Loss:  0.048812132  || Decoder Loss:  0.035220586 Validation Decoder Loss:  0.3319363
Encoder Loss:  0.04885564  || Decoder Loss:  0.035227913 Validation Decoder Loss:  0.3312511
Encoder Loss:  0.04890684  || Decoder Loss:  0.035273507 Validation Decoder Loss:  0.33128947
Encoder Loss:  0.048799153  || Decoder Loss:  0.035104517 Validation Decoder Loss:  0.3312319
Encoder Loss:  0.048804685  || Decoder Loss:  0.035104763 Validation Decoder Loss:  0.3312173
Model: siamese_net_lr_0.05903935848905359 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3312173
Model: "sequential_430"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_164 (Conv3D (None, 67, 10, 20, 1)     9         
_________________________________________________________________
dropout_480 (Dropout)        (None, 67, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_165 (Conv3D (None, 74, 30, 20, 1)     25        
_________________________________________________________________
reshape_125 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 34
Trainable params: 34
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_432"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_168 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_482 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_169 (Conv2D)          (None, 2220, 20, 1)       362       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_433"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_168 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_484 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_169 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16226727  || Decoder Loss:  0.49068505 Validation Decoder Loss:  0.37662953
Encoder Loss:  0.07847262  || Decoder Loss:  0.16676822 Validation Decoder Loss:  0.35157824
Encoder Loss:  0.07667625  || Decoder Loss:  0.15939735 Validation Decoder Loss:  0.36237055
Encoder Loss:  0.06043302  || Decoder Loss:  0.09274932 Validation Decoder Loss:  0.3566389
Encoder Loss:  0.046345286  || Decoder Loss:  0.034966018 Validation Decoder Loss:  0.35540867
Encoder Loss:  0.04627926  || Decoder Loss:  0.034707323 Validation Decoder Loss:  0.35506216
Encoder Loss:  0.046260934  || Decoder Loss:  0.034639202 Validation Decoder Loss:  0.35265678
Encoder Loss:  0.04622975  || Decoder Loss:  0.03451048 Validation Decoder Loss:  0.35295692
Encoder Loss:  0.046184268  || Decoder Loss:  0.034327473 Validation Decoder Loss:  0.3515573
Encoder Loss:  0.04615377  || Decoder Loss:  0.034199912 Validation Decoder Loss:  0.3478774
Encoder Loss:  0.1545618  || Decoder Loss:  0.4440184 Validation Decoder Loss:  0.9566787
Encoder Loss:  0.156783  || Decoder Loss:  0.48079494 Validation Decoder Loss:  0.9880069
Encoder Loss:  0.15967095  || Decoder Loss:  0.49966758 Validation Decoder Loss:  0.9291882
Encoder Loss:  0.15951714  || Decoder Loss:  0.49541953 Validation Decoder Loss:  0.99583876
Encoder Loss:  0.15972917  || Decoder Loss:  0.50010663 Validation Decoder Loss:  0.99030054
Encoder Loss:  0.15940326  || Decoder Loss:  0.49873295 Validation Decoder Loss:  0.9991884
Encoder Loss:  0.15857112  || Decoder Loss:  0.4949003 Validation Decoder Loss:  0.9601347
Encoder Loss:  0.16051117  || Decoder Loss:  0.50250554 Validation Decoder Loss:  0.99559397
Encoder Loss:  0.15900223  || Decoder Loss:  0.49709618 Validation Decoder Loss:  0.9980269
Encoder Loss:  0.15905507  || Decoder Loss:  0.4973274 Validation Decoder Loss:  0.99881124
Encoder Loss:  0.15891331  || Decoder Loss:  0.496763 Validation Decoder Loss:  0.99794257
Encoder Loss:  0.1589238  || Decoder Loss:  0.49680763 Validation Decoder Loss:  0.9967569
Encoder Loss:  0.1589586  || Decoder Loss:  0.49695098 Validation Decoder Loss:  0.9981214
Encoder Loss:  0.15889516  || Decoder Loss:  0.49669242 Validation Decoder Loss:  0.9974226
Encoder Loss:  0.15903601  || Decoder Loss:  0.49726325 Validation Decoder Loss:  0.99820256
Encoder Loss:  0.15898624  || Decoder Loss:  0.4970607 Validation Decoder Loss:  1.0045544
Encoder Loss:  0.15910889  || Decoder Loss:  0.49756417 Validation Decoder Loss:  0.99780405
Encoder Loss:  0.1590359  || Decoder Loss:  0.4970591 Validation Decoder Loss:  0.9976077
Encoder Loss:  0.1588954  || Decoder Loss:  0.49665543 Validation Decoder Loss:  0.99869144
Encoder Loss:  0.13762926  || Decoder Loss:  0.4094552 Validation Decoder Loss:  0.9945166
Encoder Loss:  0.15537415  || Decoder Loss:  0.48224637 Validation Decoder Loss:  0.99455553
Encoder Loss:  0.15850116  || Decoder Loss:  0.49507493 Validation Decoder Loss:  0.9740906
Encoder Loss:  0.1594823  || Decoder Loss:  0.49909443 Validation Decoder Loss:  1.0017489
Encoder Loss:  0.1601064  || Decoder Loss:  0.5016562 Validation Decoder Loss:  1.0030243
Encoder Loss:  0.15963164  || Decoder Loss:  0.49970448 Validation Decoder Loss:  1.0054938
Encoder Loss:  0.15893625  || Decoder Loss:  0.49684733 Validation Decoder Loss:  0.9971128
Encoder Loss:  0.1591486  || Decoder Loss:  0.49771485 Validation Decoder Loss:  0.9922299
Encoder Loss:  0.12586288  || Decoder Loss:  0.35688484 Validation Decoder Loss:  0.372087
Encoder Loss:  0.054222494  || Decoder Loss:  0.06731504 Validation Decoder Loss:  0.372209
Encoder Loss:  0.054112367  || Decoder Loss:  0.066862 Validation Decoder Loss:  0.36345136
Model: siamese_net_lr_0.3312368055782823 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36345136
Model: "sequential_434"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_167 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_486 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_168 (Conv3D (None, 74, 30, 20, 1)     163       
_________________________________________________________________
reshape_126 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 167
Trainable params: 167
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_436"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_170 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_488 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_171 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_437"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_170 (Conv2D (None, 2520, 20, 1)       302       
_________________________________________________________________
dropout_490 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_171 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36109164  || Decoder Loss:  0.43025547 Validation Decoder Loss:  0.4061047
Encoder Loss:  0.119212516  || Decoder Loss:  0.13529043 Validation Decoder Loss:  0.46690607
Encoder Loss:  0.13354339  || Decoder Loss:  0.15299642 Validation Decoder Loss:  0.4665457
Encoder Loss:  0.16759662  || Decoder Loss:  0.19497736 Validation Decoder Loss:  0.55401266
Encoder Loss:  0.33186218  || Decoder Loss:  0.3975221 Validation Decoder Loss:  1.016167
Encoder Loss:  0.40764314  || Decoder Loss:  0.49097487 Validation Decoder Loss:  1.0124769
Encoder Loss:  0.24973196  || Decoder Loss:  0.29626784 Validation Decoder Loss:  0.6242372
Encoder Loss:  0.232449  || Decoder Loss:  0.2749601 Validation Decoder Loss:  0.7558165
Encoder Loss:  0.16082096  || Decoder Loss:  0.1866325 Validation Decoder Loss:  0.57243234
Encoder Loss:  0.43037975  || Decoder Loss:  0.51900846 Validation Decoder Loss:  1.0123935
Encoder Loss:  0.34192386  || Decoder Loss:  0.40990302 Validation Decoder Loss:  1.6266849
Encoder Loss:  0.4303721  || Decoder Loss:  0.5122216 Validation Decoder Loss:  1.6254389
Encoder Loss:  0.44522193  || Decoder Loss:  0.5350261 Validation Decoder Loss:  0.36896688
Encoder Loss:  0.3741539  || Decoder Loss:  0.44774708 Validation Decoder Loss:  1.6217498
Encoder Loss:  0.4304534  || Decoder Loss:  0.51748437 Validation Decoder Loss:  0.36084488
Encoder Loss:  0.37219507  || Decoder Loss:  0.44588837 Validation Decoder Loss:  1.6171868
Encoder Loss:  0.40824008  || Decoder Loss:  0.49099648 Validation Decoder Loss:  0.3636439
Encoder Loss:  0.3660491  || Decoder Loss:  0.43891993 Validation Decoder Loss:  1.6177611
Encoder Loss:  0.4026562  || Decoder Loss:  0.48388442 Validation Decoder Loss:  0.36211604
Encoder Loss:  0.374189  || Decoder Loss:  0.44851863 Validation Decoder Loss:  0.36421135
Encoder Loss:  0.39753884  || Decoder Loss:  0.47748253 Validation Decoder Loss:  1.6142601
Encoder Loss:  0.43442306  || Decoder Loss:  0.5232596 Validation Decoder Loss:  1.0541903
Encoder Loss:  0.41832474  || Decoder Loss:  0.5030314 Validation Decoder Loss:  0.9606984
Encoder Loss:  0.41462722  || Decoder Loss:  0.49944836 Validation Decoder Loss:  0.9993937
Encoder Loss:  0.41384715  || Decoder Loss:  0.49863806 Validation Decoder Loss:  0.99546266
Encoder Loss:  0.41336253  || Decoder Loss:  0.49804202 Validation Decoder Loss:  0.99545664
Encoder Loss:  0.41301456  || Decoder Loss:  0.49761283 Validation Decoder Loss:  0.99541104
Encoder Loss:  0.41278675  || Decoder Loss:  0.49733207 Validation Decoder Loss:  0.9960257
Encoder Loss:  0.41255814  || Decoder Loss:  0.49705002 Validation Decoder Loss:  0.9964926
Encoder Loss:  0.41259366  || Decoder Loss:  0.49709344 Validation Decoder Loss:  0.9969373
Encoder Loss:  0.41241118  || Decoder Loss:  0.49686858 Validation Decoder Loss:  0.9994823
Encoder Loss:  0.41255298  || Decoder Loss:  0.4970359 Validation Decoder Loss:  0.99889135
Encoder Loss:  0.41262776  || Decoder Loss:  0.4970658 Validation Decoder Loss:  0.98723495
Encoder Loss:  0.24100925  || Decoder Loss:  0.2855216 Validation Decoder Loss:  0.36517346
Encoder Loss:  0.046498645  || Decoder Loss:  0.045682102 Validation Decoder Loss:  0.36860532
Encoder Loss:  0.04586452  || Decoder Loss:  0.04489996 Validation Decoder Loss:  0.37009588
Encoder Loss:  0.0450141  || Decoder Loss:  0.043851495 Validation Decoder Loss:  0.37385994
Encoder Loss:  0.04381527  || Decoder Loss:  0.042373385 Validation Decoder Loss:  0.37700808
Encoder Loss:  0.043985996  || Decoder Loss:  0.042584006 Validation Decoder Loss:  0.40050292
Encoder Loss:  0.06381269  || Decoder Loss:  0.06703126 Validation Decoder Loss:  0.493053
Model: siamese_net_lr_0.8098712377437441 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.49305296
Model: "sequential_439"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_172 (Conv2D)          (None, 2300, 20, 1)       309       
_________________________________________________________________
dropout_492 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_173 (Conv2D)          (None, 2220, 20, 1)       82        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_440"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_172 (Conv2D (None, 2450, 20, 1)       232       
_________________________________________________________________
dropout_494 (Dropout)        (None, 2450, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_173 (Conv2D (None, 2607, 20, 1)       159       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_441"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_170 (Conv3D (None, 68, 30, 20, 1)     131       
_________________________________________________________________
dropout_496 (Dropout)        (None, 68, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_171 (Conv3D (None, 74, 30, 20, 1)     8         
_________________________________________________________________
reshape_127 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_443"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_174 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_498 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_175 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_444"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_174 (Conv2D (None, 2390, 20, 1)       172       
_________________________________________________________________
dropout_500 (Dropout)        (None, 2390, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_175 (Conv2D (None, 2607, 20, 1)       219       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.21080944  || Decoder Loss:  0.21460302 Validation Decoder Loss:  1.5571864
Encoder Loss:  0.54746526  || Decoder Loss:  0.58658963 Validation Decoder Loss:  1.5362661
Encoder Loss:  0.4478509  || Decoder Loss:  0.48021504 Validation Decoder Loss:  0.43441653
Encoder Loss:  0.08358775  || Decoder Loss:  0.0863004 Validation Decoder Loss:  0.4322427
Encoder Loss:  0.08293196  || Decoder Loss:  0.085597456 Validation Decoder Loss:  0.43010294
Encoder Loss:  0.0827068  || Decoder Loss:  0.085354894 Validation Decoder Loss:  0.4287226
Encoder Loss:  0.083372265  || Decoder Loss:  0.08607768 Validation Decoder Loss:  0.42773515
Encoder Loss:  0.085462525  || Decoder Loss:  0.08833953 Validation Decoder Loss:  0.4283554
Encoder Loss:  0.09221605  || Decoder Loss:  0.09564678 Validation Decoder Loss:  0.43096748
Encoder Loss:  0.098253496  || Decoder Loss:  0.10217942 Validation Decoder Loss:  0.43249756
Encoder Loss:  0.10462066  || Decoder Loss:  0.10906918 Validation Decoder Loss:  0.43429017
Encoder Loss:  0.11150268  || Decoder Loss:  0.11651328 Validation Decoder Loss:  0.43665528
Encoder Loss:  0.116199836  || Decoder Loss:  0.12159441 Validation Decoder Loss:  0.43561885
Encoder Loss:  0.11853036  || Decoder Loss:  0.12411752 Validation Decoder Loss:  0.4342119
Encoder Loss:  0.118093275  || Decoder Loss:  0.123645104 Validation Decoder Loss:  0.43221873
Encoder Loss:  0.12367556  || Decoder Loss:  0.12968192 Validation Decoder Loss:  0.43086833
Encoder Loss:  0.11995955  || Decoder Loss:  0.12566394 Validation Decoder Loss:  0.42394248
Encoder Loss:  0.11272736  || Decoder Loss:  0.1178417 Validation Decoder Loss:  0.42044893
Encoder Loss:  0.1142334  || Decoder Loss:  0.119469956 Validation Decoder Loss:  0.41854316
Encoder Loss:  0.11023798  || Decoder Loss:  0.11514945 Validation Decoder Loss:  0.41394114
Encoder Loss:  0.10939061  || Decoder Loss:  0.114232674 Validation Decoder Loss:  0.412803
Encoder Loss:  0.105597585  || Decoder Loss:  0.110130675 Validation Decoder Loss:  0.40958205
Encoder Loss:  0.10346794  || Decoder Loss:  0.10782721 Validation Decoder Loss:  0.4080323
Encoder Loss:  0.10175788  || Decoder Loss:  0.10597746 Validation Decoder Loss:  0.40576842
Encoder Loss:  0.09873297  || Decoder Loss:  0.102706194 Validation Decoder Loss:  0.40376952
Encoder Loss:  0.09527895  || Decoder Loss:  0.0989703 Validation Decoder Loss:  0.4015575
Encoder Loss:  0.09251741  || Decoder Loss:  0.095983274 Validation Decoder Loss:  0.40156746
Encoder Loss:  0.12878843  || Decoder Loss:  0.13519675 Validation Decoder Loss:  0.4212953
Encoder Loss:  0.14053848  || Decoder Loss:  0.14792243 Validation Decoder Loss:  0.35231465
Encoder Loss:  0.1501402  || Decoder Loss:  0.15830833 Validation Decoder Loss:  0.43708795
Encoder Loss:  0.14110655  || Decoder Loss:  0.1485381 Validation Decoder Loss:  0.42460525
Encoder Loss:  0.12728983  || Decoder Loss:  0.13359334 Validation Decoder Loss:  0.4196663
Encoder Loss:  0.117685944  || Decoder Loss:  0.12320645 Validation Decoder Loss:  0.41353595
Encoder Loss:  0.11531808  || Decoder Loss:  0.12064502 Validation Decoder Loss:  0.41348672
Encoder Loss:  0.11502468  || Decoder Loss:  0.120328255 Validation Decoder Loss:  0.41094223
Encoder Loss:  0.10978753  || Decoder Loss:  0.11466377 Validation Decoder Loss:  0.4099693
Encoder Loss:  0.10747555  || Decoder Loss:  0.112163275 Validation Decoder Loss:  0.40907508
Encoder Loss:  0.10619495  || Decoder Loss:  0.110778004 Validation Decoder Loss:  0.40802252
Encoder Loss:  0.10375075  || Decoder Loss:  0.10813485 Validation Decoder Loss:  0.4067868
Encoder Loss:  0.10650351  || Decoder Loss:  0.111111015 Validation Decoder Loss:  0.40716955
Model: siamese_net_lr_0.24745655129909647 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.40716958
Model: "sequential_446"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_176 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_502 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_177 (Conv2D)          (None, 2220, 20, 1)       242       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_447"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_176 (Conv2D (None, 2580, 20, 1)       362       
_________________________________________________________________
dropout_504 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_177 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_448"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_173 (Conv3D (None, 68, 10, 20, 1)     11        
_________________________________________________________________
dropout_506 (Dropout)        (None, 68, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_174 (Conv3D (None, 74, 30, 20, 1)     85        
_________________________________________________________________
reshape_128 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 96
Trainable params: 96
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_450"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_178 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_508 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_179 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_451"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_178 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_510 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_179 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31945994  || Decoder Loss:  0.33602303 Validation Decoder Loss:  1.6324997
Encoder Loss:  0.457727  || Decoder Loss:  0.49818698 Validation Decoder Loss:  0.99722207
Encoder Loss:  0.45541888  || Decoder Loss:  0.4959277 Validation Decoder Loss:  1.0092276
Encoder Loss:  0.45514226  || Decoder Loss:  0.49569106 Validation Decoder Loss:  1.0037284
Encoder Loss:  0.45488366  || Decoder Loss:  0.49538505 Validation Decoder Loss:  0.99251467
Encoder Loss:  0.45481354  || Decoder Loss:  0.495726 Validation Decoder Loss:  1.0000557
Encoder Loss:  0.45395043  || Decoder Loss:  0.49495605 Validation Decoder Loss:  0.9999312
Encoder Loss:  0.45394093  || Decoder Loss:  0.49494594 Validation Decoder Loss:  0.9999489
Encoder Loss:  0.45389533  || Decoder Loss:  0.49489582 Validation Decoder Loss:  1.0000366
Encoder Loss:  0.4538269  || Decoder Loss:  0.4948203 Validation Decoder Loss:  1.0002456
Encoder Loss:  0.45368335  || Decoder Loss:  0.49466214 Validation Decoder Loss:  1.0004048
Encoder Loss:  0.45323154  || Decoder Loss:  0.49416438 Validation Decoder Loss:  1.0027754
Encoder Loss:  0.17375638  || Decoder Loss:  0.18631825 Validation Decoder Loss:  0.43170738
Encoder Loss:  0.08053599  || Decoder Loss:  0.08363546 Validation Decoder Loss:  0.33364308
Encoder Loss:  0.04307698  || Decoder Loss:  0.042373646 Validation Decoder Loss:  0.3374512
Encoder Loss:  0.03606389  || Decoder Loss:  0.03464884 Validation Decoder Loss:  0.34028557
Encoder Loss:  0.44562078  || Decoder Loss:  0.48578098 Validation Decoder Loss:  1.0033062
Encoder Loss:  0.45780793  || Decoder Loss:  0.49920535 Validation Decoder Loss:  1.0033019
Encoder Loss:  0.45778987  || Decoder Loss:  0.49918544 Validation Decoder Loss:  1.0033274
Encoder Loss:  0.4576502  || Decoder Loss:  0.49903134 Validation Decoder Loss:  1.0044299
Encoder Loss:  0.45741093  || Decoder Loss:  0.4987681 Validation Decoder Loss:  1.003808
Encoder Loss:  0.45668763  || Decoder Loss:  0.49797085 Validation Decoder Loss:  1.0021683
Encoder Loss:  0.45811597  || Decoder Loss:  0.49954507 Validation Decoder Loss:  1.0040737
Encoder Loss:  0.45766845  || Decoder Loss:  0.49905175 Validation Decoder Loss:  1.0044204
Encoder Loss:  0.45696548  || Decoder Loss:  0.4982683 Validation Decoder Loss:  0.9906529
Encoder Loss:  0.45863193  || Decoder Loss:  0.5001129 Validation Decoder Loss:  0.99619764
Encoder Loss:  0.45948112  || Decoder Loss:  0.5010483 Validation Decoder Loss:  0.9963305
Encoder Loss:  0.45881677  || Decoder Loss:  0.5003171 Validation Decoder Loss:  0.9970258
Encoder Loss:  0.45743883  || Decoder Loss:  0.49879882 Validation Decoder Loss:  0.998136
Encoder Loss:  0.45928508  || Decoder Loss:  0.5008326 Validation Decoder Loss:  0.99797606
Encoder Loss:  0.45871684  || Decoder Loss:  0.50020677 Validation Decoder Loss:  0.98998517
Encoder Loss:  0.4579379  || Decoder Loss:  0.49934852 Validation Decoder Loss:  0.98004806
Encoder Loss:  0.45252421  || Decoder Loss:  0.49338567 Validation Decoder Loss:  1.004705
Encoder Loss:  0.45940742  || Decoder Loss:  0.5009671 Validation Decoder Loss:  1.000597
Encoder Loss:  0.45866656  || Decoder Loss:  0.5001509 Validation Decoder Loss:  0.99950415
Encoder Loss:  0.45869482  || Decoder Loss:  0.50018233 Validation Decoder Loss:  0.9987885
Encoder Loss:  0.4597676  || Decoder Loss:  0.50136435 Validation Decoder Loss:  0.99702257
Encoder Loss:  0.45941883  || Decoder Loss:  0.5009798 Validation Decoder Loss:  1.0007257
Encoder Loss:  0.45905048  || Decoder Loss:  0.5005743 Validation Decoder Loss:  1.0150665
Encoder Loss:  0.45916352  || Decoder Loss:  0.500323 Validation Decoder Loss:  0.99628717
Model: siamese_net_lr_0.45831322796971874 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99628717
Model: "sequential_452"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_176 (Conv3D (None, 67, 10, 20, 1)     25        
_________________________________________________________________
dropout_512 (Dropout)        (None, 67, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_177 (Conv3D (None, 74, 30, 20, 1)     169       
_________________________________________________________________
reshape_129 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 194
Trainable params: 194
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_454"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_180 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_514 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_181 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_455"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_180 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_516 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_181 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4002661  || Decoder Loss:  0.47874 Validation Decoder Loss:  1.0888287
Encoder Loss:  0.4182767  || Decoder Loss:  0.5027099 Validation Decoder Loss:  1.0922402
Encoder Loss:  0.41157544  || Decoder Loss:  0.4951907 Validation Decoder Loss:  1.0805091
Encoder Loss:  0.41371253  || Decoder Loss:  0.49796322 Validation Decoder Loss:  0.9892576
Encoder Loss:  0.4177827  || Decoder Loss:  0.5038788 Validation Decoder Loss:  0.9790347
Encoder Loss:  0.4175265  || Decoder Loss:  0.5053604 Validation Decoder Loss:  0.9894047
Encoder Loss:  0.41682026  || Decoder Loss:  0.50450784 Validation Decoder Loss:  0.98157287
Encoder Loss:  0.4157669  || Decoder Loss:  0.50377023 Validation Decoder Loss:  0.979653
Encoder Loss:  0.41583657  || Decoder Loss:  0.5038694 Validation Decoder Loss:  0.98516953
Encoder Loss:  0.41340905  || Decoder Loss:  0.5008902 Validation Decoder Loss:  0.9921368
Encoder Loss:  0.41154578  || Decoder Loss:  0.4985778 Validation Decoder Loss:  0.9996643
Encoder Loss:  0.41010514  || Decoder Loss:  0.49678242 Validation Decoder Loss:  1.0064906
Encoder Loss:  0.4092357  || Decoder Loss:  0.495706 Validation Decoder Loss:  1.008771
Encoder Loss:  0.40889508  || Decoder Loss:  0.4952644 Validation Decoder Loss:  1.0116305
Encoder Loss:  0.40861875  || Decoder Loss:  0.49491814 Validation Decoder Loss:  1.0141084
Encoder Loss:  0.40851113  || Decoder Loss:  0.49468884 Validation Decoder Loss:  1.012984
Encoder Loss:  0.40795788  || Decoder Loss:  0.49398437 Validation Decoder Loss:  1.0066986
Encoder Loss:  0.38763908  || Decoder Loss:  0.46860296 Validation Decoder Loss:  0.96353054
Encoder Loss:  0.3134283  || Decoder Loss:  0.37684035 Validation Decoder Loss:  0.41899452
Encoder Loss:  0.074663766  || Decoder Loss:  0.0805978 Validation Decoder Loss:  0.41336834
Encoder Loss:  0.07677273  || Decoder Loss:  0.08321518 Validation Decoder Loss:  0.41569108
Encoder Loss:  0.07951446  || Decoder Loss:  0.08661721 Validation Decoder Loss:  0.4192536
Encoder Loss:  0.081372775  || Decoder Loss:  0.08892319 Validation Decoder Loss:  0.42023212
Encoder Loss:  0.08288642  || Decoder Loss:  0.09080099 Validation Decoder Loss:  0.4267356
Encoder Loss:  0.08565638  || Decoder Loss:  0.0942379 Validation Decoder Loss:  0.4278263
Encoder Loss:  0.08749601  || Decoder Loss:  0.096519955 Validation Decoder Loss:  0.43458554
Encoder Loss:  0.09032761  || Decoder Loss:  0.10003417 Validation Decoder Loss:  0.4326026
Encoder Loss:  0.09096796  || Decoder Loss:  0.10082839 Validation Decoder Loss:  0.43834686
Encoder Loss:  0.09644088  || Decoder Loss:  0.10761853 Validation Decoder Loss:  0.45891738
Encoder Loss:  0.11641295  || Decoder Loss:  0.13239864 Validation Decoder Loss:  0.48936316
Encoder Loss:  0.11697918  || Decoder Loss:  0.13310155 Validation Decoder Loss:  0.49662784
Encoder Loss:  0.12904945  || Decoder Loss:  0.14807737 Validation Decoder Loss:  0.55048907
Encoder Loss:  0.18051632  || Decoder Loss:  0.21193422 Validation Decoder Loss:  0.6831851
Encoder Loss:  0.21955186  || Decoder Loss:  0.26036692 Validation Decoder Loss:  0.6183982
Encoder Loss:  0.23026574  || Decoder Loss:  0.27365968 Validation Decoder Loss:  0.98735
Encoder Loss:  0.4102752  || Decoder Loss:  0.49700347 Validation Decoder Loss:  0.98920906
Encoder Loss:  0.409961  || Decoder Loss:  0.4966131 Validation Decoder Loss:  0.99047947
Encoder Loss:  0.4100191  || Decoder Loss:  0.49668545 Validation Decoder Loss:  0.9914665
Encoder Loss:  0.4097746  || Decoder Loss:  0.49638146 Validation Decoder Loss:  0.9935205
Encoder Loss:  0.40932915  || Decoder Loss:  0.49582946 Validation Decoder Loss:  0.9960498
Model: siamese_net_lr_0.8862720847294033 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9960498
Model: "sequential_456"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_179 (Conv3D (None, 70, 5, 20, 1)      8         
_________________________________________________________________
dropout_518 (Dropout)        (None, 70, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_180 (Conv3D (None, 74, 30, 20, 1)     31        
_________________________________________________________________
reshape_130 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_458"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_182 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_520 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_183 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_459"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_182 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_522 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_183 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29329884  || Decoder Loss:  0.34898055 Validation Decoder Loss:  0.9486624
Encoder Loss:  0.1668736  || Decoder Loss:  0.20718274 Validation Decoder Loss:  0.61912453
Encoder Loss:  0.23186447  || Decoder Loss:  0.29463387 Validation Decoder Loss:  0.7408211
Encoder Loss:  0.058362965  || Decoder Loss:  0.0612393 Validation Decoder Loss:  0.33697015
Encoder Loss:  0.040156737  || Decoder Loss:  0.0367491 Validation Decoder Loss:  0.33723044
Encoder Loss:  0.039999932  || Decoder Loss:  0.036539577 Validation Decoder Loss:  0.3369528
Encoder Loss:  0.039843597  || Decoder Loss:  0.036329903 Validation Decoder Loss:  0.3363019
Encoder Loss:  0.039684426  || Decoder Loss:  0.03611658 Validation Decoder Loss:  0.33583182
Encoder Loss:  0.03952978  || Decoder Loss:  0.035908476 Validation Decoder Loss:  0.33516273
Encoder Loss:  0.039390508  || Decoder Loss:  0.035717595 Validation Decoder Loss:  0.3348475
Encoder Loss:  0.039258596  || Decoder Loss:  0.035543334 Validation Decoder Loss:  0.33448523
Encoder Loss:  0.0391444  || Decoder Loss:  0.03538992 Validation Decoder Loss:  0.33439314
Encoder Loss:  0.039029762  || Decoder Loss:  0.035237294 Validation Decoder Loss:  0.334024
Encoder Loss:  0.038928423  || Decoder Loss:  0.035098616 Validation Decoder Loss:  0.33401066
Encoder Loss:  0.0388244  || Decoder Loss:  0.03495547 Validation Decoder Loss:  0.33377683
Encoder Loss:  0.038732216  || Decoder Loss:  0.034836475 Validation Decoder Loss:  0.33403775
Encoder Loss:  0.03864703  || Decoder Loss:  0.03472288 Validation Decoder Loss:  0.33391225
Encoder Loss:  0.038579963  || Decoder Loss:  0.03463152 Validation Decoder Loss:  0.3344025
Encoder Loss:  0.038527824  || Decoder Loss:  0.03456013 Validation Decoder Loss:  0.3333481
Encoder Loss:  0.038483825  || Decoder Loss:  0.03450327 Validation Decoder Loss:  0.33393136
Encoder Loss:  0.038436815  || Decoder Loss:  0.03444158 Validation Decoder Loss:  0.33365655
Encoder Loss:  0.038395766  || Decoder Loss:  0.03438488 Validation Decoder Loss:  0.334026
Encoder Loss:  0.038345672  || Decoder Loss:  0.03431765 Validation Decoder Loss:  0.3337432
Encoder Loss:  0.038289443  || Decoder Loss:  0.03424437 Validation Decoder Loss:  0.33363014
Encoder Loss:  0.03825232  || Decoder Loss:  0.034186825 Validation Decoder Loss:  0.33399826
Encoder Loss:  0.038176015  || Decoder Loss:  0.034091014 Validation Decoder Loss:  0.3339138
Encoder Loss:  0.03809841  || Decoder Loss:  0.03398471 Validation Decoder Loss:  0.33392864
Encoder Loss:  0.037979405  || Decoder Loss:  0.03382436 Validation Decoder Loss:  0.3333367
Encoder Loss:  0.037764978  || Decoder Loss:  0.03353066 Validation Decoder Loss:  0.3324571
Encoder Loss:  0.037635166  || Decoder Loss:  0.03336002 Validation Decoder Loss:  0.33307263
Encoder Loss:  0.0374306  || Decoder Loss:  0.033082556 Validation Decoder Loss:  0.33632743
Encoder Loss:  0.037347488  || Decoder Loss:  0.032969445 Validation Decoder Loss:  0.33304828
Encoder Loss:  0.037268933  || Decoder Loss:  0.032868534 Validation Decoder Loss:  0.33244538
Encoder Loss:  0.037244074  || Decoder Loss:  0.03283353 Validation Decoder Loss:  0.3342678
Encoder Loss:  0.037213244  || Decoder Loss:  0.032792874 Validation Decoder Loss:  0.33412394
Encoder Loss:  0.037176453  || Decoder Loss:  0.03274194 Validation Decoder Loss:  0.3371628
Encoder Loss:  0.037173036  || Decoder Loss:  0.032733373 Validation Decoder Loss:  0.33767784
Encoder Loss:  0.03720236  || Decoder Loss:  0.032768823 Validation Decoder Loss:  0.33578566
Encoder Loss:  0.037098747  || Decoder Loss:  0.03263846 Validation Decoder Loss:  0.33436874
Encoder Loss:  0.037083313  || Decoder Loss:  0.032619372 Validation Decoder Loss:  0.3330497
Model: siamese_net_lr_0.061299979405488765 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3330497
Model: "sequential_460"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_182 (Conv3D (None, 67, 20, 20, 1)     49        
_________________________________________________________________
dropout_524 (Dropout)        (None, 67, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_183 (Conv3D (None, 74, 30, 20, 1)     89        
_________________________________________________________________
reshape_131 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 138
Trainable params: 138
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_462"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_184 (Conv2D)          (None, 2290, 20, 1)       319       
_________________________________________________________________
dropout_526 (Dropout)        (None, 2290, 20, 1)       0         
_________________________________________________________________
conv2d_185 (Conv2D)          (None, 2220, 20, 1)       72        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_463"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_184 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_528 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_185 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.065106146  || Decoder Loss:  0.062025677 Validation Decoder Loss:  0.3610805
Encoder Loss:  0.052399136  || Decoder Loss:  0.059795283 Validation Decoder Loss:  0.35305834
Encoder Loss:  0.051825956  || Decoder Loss:  0.06092017 Validation Decoder Loss:  0.35578763
Encoder Loss:  0.05209908  || Decoder Loss:  0.06078214 Validation Decoder Loss:  0.3460157
Encoder Loss:  0.052656356  || Decoder Loss:  0.06598441 Validation Decoder Loss:  0.36025596
Encoder Loss:  0.1001096  || Decoder Loss:  0.45656666 Validation Decoder Loss:  1.0222135
Encoder Loss:  0.10463787  || Decoder Loss:  0.49660075 Validation Decoder Loss:  1.0198193
Encoder Loss:  0.101961546  || Decoder Loss:  0.4747504 Validation Decoder Loss:  0.39166364
Encoder Loss:  0.1033365  || Decoder Loss:  0.4859898 Validation Decoder Loss:  1.0214934
Encoder Loss:  0.102333516  || Decoder Loss:  0.47775224 Validation Decoder Loss:  0.99519455
Encoder Loss:  0.09829543  || Decoder Loss:  0.44479442 Validation Decoder Loss:  0.34450457
Encoder Loss:  0.0907635  || Decoder Loss:  0.3830733 Validation Decoder Loss:  1.0141011
Encoder Loss:  0.10321329  || Decoder Loss:  0.4849382 Validation Decoder Loss:  1.0024983
Encoder Loss:  0.10493669  || Decoder Loss:  0.4991373 Validation Decoder Loss:  0.9975544
Encoder Loss:  0.104322575  || Decoder Loss:  0.49406663 Validation Decoder Loss:  1.0558462
Encoder Loss:  0.10455663  || Decoder Loss:  0.49598885 Validation Decoder Loss:  1.0246797
Encoder Loss:  0.095189475  || Decoder Loss:  0.41943055 Validation Decoder Loss:  0.30777743
Encoder Loss:  0.088263944  || Decoder Loss:  0.36281037 Validation Decoder Loss:  1.5611067
Encoder Loss:  0.056804456  || Decoder Loss:  0.10543037 Validation Decoder Loss:  0.34474778
Encoder Loss:  0.07787659  || Decoder Loss:  0.27774876 Validation Decoder Loss:  0.33992398
Encoder Loss:  0.048292052  || Decoder Loss:  0.035928465 Validation Decoder Loss:  0.34470803
Encoder Loss:  0.07124047  || Decoder Loss:  0.21796389 Validation Decoder Loss:  0.33168924
Encoder Loss:  0.048362426  || Decoder Loss:  0.036134772 Validation Decoder Loss:  0.33234316
Encoder Loss:  0.048300013  || Decoder Loss:  0.035976425 Validation Decoder Loss:  0.332095
Encoder Loss:  0.048291054  || Decoder Loss:  0.035894226 Validation Decoder Loss:  0.33229622
Encoder Loss:  0.04829225  || Decoder Loss:  0.035900105 Validation Decoder Loss:  0.3337263
Encoder Loss:  0.048303925  || Decoder Loss:  0.036018614 Validation Decoder Loss:  0.33351374
Encoder Loss:  0.048304386  || Decoder Loss:  0.036029924 Validation Decoder Loss:  0.33444446
Encoder Loss:  0.04827517  || Decoder Loss:  0.03575545 Validation Decoder Loss:  0.33625427
Encoder Loss:  0.0482629  || Decoder Loss:  0.035724267 Validation Decoder Loss:  0.33698094
Encoder Loss:  0.048283145  || Decoder Loss:  0.03589563 Validation Decoder Loss:  0.34258288
Encoder Loss:  0.048304364  || Decoder Loss:  0.03606628 Validation Decoder Loss:  0.33695057
Encoder Loss:  0.048247207  || Decoder Loss:  0.03558826 Validation Decoder Loss:  0.3394715
Encoder Loss:  0.04825492  || Decoder Loss:  0.03564751 Validation Decoder Loss:  0.3446251
Encoder Loss:  0.048238385  || Decoder Loss:  0.03551901 Validation Decoder Loss:  0.34081414
Encoder Loss:  0.048987612  || Decoder Loss:  0.041606307 Validation Decoder Loss:  0.3907485
Encoder Loss:  0.06941441  || Decoder Loss:  0.13827138 Validation Decoder Loss:  0.33320642
Encoder Loss:  0.04855459  || Decoder Loss:  0.035756458 Validation Decoder Loss:  0.33336508
Encoder Loss:  0.048511423  || Decoder Loss:  0.03613471 Validation Decoder Loss:  0.3330009
Encoder Loss:  0.048412237  || Decoder Loss:  0.03583235 Validation Decoder Loss:  0.33250898
Model: siamese_net_lr_0.144893239300372 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33250898
Model: "sequential_464"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_185 (Conv3D (None, 70, 27, 20, 1)     50        
_________________________________________________________________
dropout_530 (Dropout)        (None, 70, 27, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_186 (Conv3D (None, 74, 30, 20, 1)     21        
_________________________________________________________________
reshape_132 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 71
Trainable params: 71
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_466"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_186 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_532 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_187 (Conv2D)          (None, 2220, 20, 1)       212       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_467"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_186 (Conv2D (None, 2350, 20, 1)       132       
_________________________________________________________________
dropout_534 (Dropout)        (None, 2350, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_187 (Conv2D (None, 2607, 20, 1)       259       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32543018  || Decoder Loss:  0.25575054 Validation Decoder Loss:  0.5862287
Encoder Loss:  0.057887055  || Decoder Loss:  0.071966454 Validation Decoder Loss:  0.3411595
Encoder Loss:  0.07991531  || Decoder Loss:  0.13421704 Validation Decoder Loss:  0.35219634
Encoder Loss:  0.15195422  || Decoder Loss:  0.3515235 Validation Decoder Loss:  0.996149
Encoder Loss:  0.1992923  || Decoder Loss:  0.4908791 Validation Decoder Loss:  1.0041598
Encoder Loss:  0.20110933  || Decoder Loss:  0.49692982 Validation Decoder Loss:  0.98602366
Encoder Loss:  0.082793035  || Decoder Loss:  0.14638248 Validation Decoder Loss:  0.35272717
Encoder Loss:  0.08452348  || Decoder Loss:  0.15056042 Validation Decoder Loss:  0.35492927
Encoder Loss:  0.07562732  || Decoder Loss:  0.12411322 Validation Decoder Loss:  0.35246617
Encoder Loss:  0.19090095  || Decoder Loss:  0.4577577 Validation Decoder Loss:  0.99487936
Encoder Loss:  0.2002436  || Decoder Loss:  0.494954 Validation Decoder Loss:  0.9959438
Encoder Loss:  0.2000647  || Decoder Loss:  0.49393263 Validation Decoder Loss:  0.9779631
Encoder Loss:  0.20007516  || Decoder Loss:  0.49412003 Validation Decoder Loss:  0.9966763
Encoder Loss:  0.20010181  || Decoder Loss:  0.49413693 Validation Decoder Loss:  1.0006747
Encoder Loss:  0.19936155  || Decoder Loss:  0.49144527 Validation Decoder Loss:  1.000448
Encoder Loss:  0.20168667  || Decoder Loss:  0.49895218 Validation Decoder Loss:  0.99603844
Encoder Loss:  0.2003426  || Decoder Loss:  0.49488792 Validation Decoder Loss:  0.9947275
Encoder Loss:  0.1989932  || Decoder Loss:  0.49086228 Validation Decoder Loss:  0.99240047
Encoder Loss:  0.19594635  || Decoder Loss:  0.482034 Validation Decoder Loss:  1.1165586
Encoder Loss:  0.20664908  || Decoder Loss:  0.5076691 Validation Decoder Loss:  0.99484825
Encoder Loss:  0.20023297  || Decoder Loss:  0.494863 Validation Decoder Loss:  1.0014095
Encoder Loss:  0.20080605  || Decoder Loss:  0.49629977 Validation Decoder Loss:  0.99841034
Encoder Loss:  0.20045078  || Decoder Loss:  0.49524263 Validation Decoder Loss:  1.015339
Encoder Loss:  0.20201555  || Decoder Loss:  0.4973662 Validation Decoder Loss:  0.99603903
Encoder Loss:  0.19982398  || Decoder Loss:  0.49377602 Validation Decoder Loss:  1.0012612
Encoder Loss:  0.18689756  || Decoder Loss:  0.4554886 Validation Decoder Loss:  0.7071604
Encoder Loss:  0.10584907  || Decoder Loss:  0.2154224 Validation Decoder Loss:  0.90879154
Encoder Loss:  0.17946586  || Decoder Loss:  0.43347657 Validation Decoder Loss:  0.4572709
Encoder Loss:  0.07386913  || Decoder Loss:  0.120696984 Validation Decoder Loss:  0.99752635
Encoder Loss:  0.20252351  || Decoder Loss:  0.5017725 Validation Decoder Loss:  0.99830526
Encoder Loss:  0.20160812  || Decoder Loss:  0.49905705 Validation Decoder Loss:  0.994516
Encoder Loss:  0.20043641  || Decoder Loss:  0.49559307 Validation Decoder Loss:  0.99388325
Encoder Loss:  0.18358028  || Decoder Loss:  0.44566485 Validation Decoder Loss:  0.38973987
Encoder Loss:  0.10469699  || Decoder Loss:  0.21201068 Validation Decoder Loss:  0.99649924
Encoder Loss:  0.1989472  || Decoder Loss:  0.4911815 Validation Decoder Loss:  0.99702114
Encoder Loss:  0.19887783  || Decoder Loss:  0.49097183 Validation Decoder Loss:  0.99579835
Encoder Loss:  0.20023128  || Decoder Loss:  0.49498296 Validation Decoder Loss:  0.99563897
Encoder Loss:  0.19978218  || Decoder Loss:  0.49365127 Validation Decoder Loss:  0.9985416
Encoder Loss:  0.19636576  || Decoder Loss:  0.48353273 Validation Decoder Loss:  0.9935944
Encoder Loss:  0.19472185  || Decoder Loss:  0.4786611 Validation Decoder Loss:  0.9886901
Model: siamese_net_lr_0.9310093561119315 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9886901
Model: "sequential_468"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_188 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_536 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_189 (Conv3D (None, 74, 30, 20, 1)     183       
_________________________________________________________________
reshape_133 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_470"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_188 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_538 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_189 (Conv2D)          (None, 2220, 20, 1)       372       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_471"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_188 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_540 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_189 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35929137  || Decoder Loss:  0.49509665 Validation Decoder Loss:  1.1188833
Encoder Loss:  0.35992762  || Decoder Loss:  0.5007641 Validation Decoder Loss:  1.0139344
Encoder Loss:  0.3553714  || Decoder Loss:  0.494966 Validation Decoder Loss:  1.0059675
Encoder Loss:  0.35868615  || Decoder Loss:  0.49853286 Validation Decoder Loss:  1.0148182
Encoder Loss:  0.35446724  || Decoder Loss:  0.49413422 Validation Decoder Loss:  1.0101087
Encoder Loss:  0.35461876  || Decoder Loss:  0.4938552 Validation Decoder Loss:  1.0111012
Encoder Loss:  0.35352385  || Decoder Loss:  0.4925729 Validation Decoder Loss:  1.0029576
Encoder Loss:  0.35530776  || Decoder Loss:  0.49446082 Validation Decoder Loss:  1.0018272
Encoder Loss:  0.3535283  || Decoder Loss:  0.49267033 Validation Decoder Loss:  1.005338
Encoder Loss:  0.3529226  || Decoder Loss:  0.49131608 Validation Decoder Loss:  0.99911606
Encoder Loss:  0.3529799  || Decoder Loss:  0.4918741 Validation Decoder Loss:  0.99998844
Encoder Loss:  0.35199165  || Decoder Loss:  0.49014378 Validation Decoder Loss:  0.99988353
Encoder Loss:  0.3512794  || Decoder Loss:  0.48929146 Validation Decoder Loss:  0.9999927
Encoder Loss:  0.352501  || Decoder Loss:  0.49119815 Validation Decoder Loss:  1.0413208
Encoder Loss:  0.35518208  || Decoder Loss:  0.49415952 Validation Decoder Loss:  1.0069742
Encoder Loss:  0.35266894  || Decoder Loss:  0.49150634 Validation Decoder Loss:  0.99658716
Encoder Loss:  0.35547593  || Decoder Loss:  0.49532092 Validation Decoder Loss:  1.0287452
Encoder Loss:  0.35526225  || Decoder Loss:  0.49514896 Validation Decoder Loss:  1.0087128
Encoder Loss:  0.3541652  || Decoder Loss:  0.49364567 Validation Decoder Loss:  1.0096389
Encoder Loss:  0.35427  || Decoder Loss:  0.4934148 Validation Decoder Loss:  1.0068458
Encoder Loss:  0.3535547  || Decoder Loss:  0.49282786 Validation Decoder Loss:  1.0064914
Encoder Loss:  0.3531834  || Decoder Loss:  0.49226207 Validation Decoder Loss:  1.0055104
Encoder Loss:  0.3518723  || Decoder Loss:  0.49036205 Validation Decoder Loss:  1.0417469
Encoder Loss:  0.35297766  || Decoder Loss:  0.4910627 Validation Decoder Loss:  1.009199
Encoder Loss:  0.34879503  || Decoder Loss:  0.4858567 Validation Decoder Loss:  1.0510838
Encoder Loss:  0.35171846  || Decoder Loss:  0.49015674 Validation Decoder Loss:  0.98098844
Encoder Loss:  0.3603834  || Decoder Loss:  0.50274354 Validation Decoder Loss:  0.97518003
Encoder Loss:  0.3557607  || Decoder Loss:  0.49592417 Validation Decoder Loss:  1.0599527
Encoder Loss:  0.35765526  || Decoder Loss:  0.49876958 Validation Decoder Loss:  1.0406436
Encoder Loss:  0.36355808  || Decoder Loss:  0.5072275 Validation Decoder Loss:  0.996804
Encoder Loss:  0.3581678  || Decoder Loss:  0.49951863 Validation Decoder Loss:  1.0034612
Encoder Loss:  0.35640392  || Decoder Loss:  0.49666455 Validation Decoder Loss:  1.0062321
Encoder Loss:  0.35475817  || Decoder Loss:  0.49457797 Validation Decoder Loss:  1.0100245
Encoder Loss:  0.35432267  || Decoder Loss:  0.4939104 Validation Decoder Loss:  1.0092635
Encoder Loss:  0.3535126  || Decoder Loss:  0.49277732 Validation Decoder Loss:  1.0051908
Encoder Loss:  0.35298446  || Decoder Loss:  0.49176311 Validation Decoder Loss:  1.0016916
Encoder Loss:  0.3523314  || Decoder Loss:  0.49103367 Validation Decoder Loss:  1.0003979
Encoder Loss:  0.34924236  || Decoder Loss:  0.48650968 Validation Decoder Loss:  0.9994208
Encoder Loss:  0.34841955  || Decoder Loss:  0.485293 Validation Decoder Loss:  0.99967647
Encoder Loss:  0.3462898  || Decoder Loss:  0.48223096 Validation Decoder Loss:  0.99723107
Model: siamese_net_lr_0.5082309075762821 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9972311
Model: "sequential_472"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_191 (Conv3D (None, 65, 10, 20, 1)     13        
_________________________________________________________________
dropout_542 (Dropout)        (None, 65, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_192 (Conv3D (None, 74, 30, 20, 1)     121       
_________________________________________________________________
reshape_134 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 134
Trainable params: 134
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_474"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_190 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_544 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_191 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_475"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_190 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_546 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_191 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.15808754  || Decoder Loss:  0.30843598 Validation Decoder Loss:  1.5800624
Encoder Loss:  0.1945445  || Decoder Loss:  0.5300119 Validation Decoder Loss:  0.3202856
Encoder Loss:  0.12652303  || Decoder Loss:  0.30556953 Validation Decoder Loss:  0.61059344
Encoder Loss:  0.1643405  || Decoder Loss:  0.4319706 Validation Decoder Loss:  1.1353575
Encoder Loss:  0.13785207  || Decoder Loss:  0.3434774 Validation Decoder Loss:  1.1288936
Encoder Loss:  0.13395898  || Decoder Loss:  0.33048925 Validation Decoder Loss:  0.9853966
Encoder Loss:  0.1162092  || Decoder Loss:  0.27119598 Validation Decoder Loss:  0.925812
Encoder Loss:  0.14221203  || Decoder Loss:  0.35808888 Validation Decoder Loss:  1.2520123
Encoder Loss:  0.16508892  || Decoder Loss:  0.43453982 Validation Decoder Loss:  1.2364485
Encoder Loss:  0.1613459  || Decoder Loss:  0.42202935 Validation Decoder Loss:  0.8005718
Encoder Loss:  0.15648104  || Decoder Loss:  0.4057725 Validation Decoder Loss:  0.39220032
Encoder Loss:  0.1484558  || Decoder Loss:  0.37895587 Validation Decoder Loss:  1.1533197
Encoder Loss:  0.1741547  || Decoder Loss:  0.46482635 Validation Decoder Loss:  0.99452674
Encoder Loss:  0.18493591  || Decoder Loss:  0.50086945 Validation Decoder Loss:  0.99497193
Encoder Loss:  0.18495636  || Decoder Loss:  0.50094604 Validation Decoder Loss:  0.995017
Encoder Loss:  0.18491934  || Decoder Loss:  0.5008245 Validation Decoder Loss:  0.99517184
Encoder Loss:  0.18492793  || Decoder Loss:  0.5008521 Validation Decoder Loss:  0.99535215
Encoder Loss:  0.18494095  || Decoder Loss:  0.50089324 Validation Decoder Loss:  0.99514425
Encoder Loss:  0.18491298  || Decoder Loss:  0.5007978 Validation Decoder Loss:  0.99511075
Encoder Loss:  0.18490213  || Decoder Loss:  0.50074565 Validation Decoder Loss:  0.99465567
Encoder Loss:  0.18490137  || Decoder Loss:  0.50072896 Validation Decoder Loss:  0.99619985
Encoder Loss:  0.18498918  || Decoder Loss:  0.50101626 Validation Decoder Loss:  0.99495983
Encoder Loss:  0.1849156  || Decoder Loss:  0.5007951 Validation Decoder Loss:  0.99558234
Encoder Loss:  0.18489738  || Decoder Loss:  0.50074637 Validation Decoder Loss:  0.9954231
Encoder Loss:  0.18491058  || Decoder Loss:  0.5007884 Validation Decoder Loss:  0.9956399
Encoder Loss:  0.18490131  || Decoder Loss:  0.50075966 Validation Decoder Loss:  0.99569255
Encoder Loss:  0.18491071  || Decoder Loss:  0.5007829 Validation Decoder Loss:  0.9954707
Encoder Loss:  0.18492347  || Decoder Loss:  0.500805 Validation Decoder Loss:  0.99560535
Encoder Loss:  0.18491836  || Decoder Loss:  0.5008058 Validation Decoder Loss:  0.99557805
Encoder Loss:  0.1848614  || Decoder Loss:  0.5006327 Validation Decoder Loss:  0.99544275
Encoder Loss:  0.18491992  || Decoder Loss:  0.50080675 Validation Decoder Loss:  0.99561274
Encoder Loss:  0.18490893  || Decoder Loss:  0.5007722 Validation Decoder Loss:  0.9955627
Encoder Loss:  0.18490574  || Decoder Loss:  0.50077075 Validation Decoder Loss:  0.9958556
Encoder Loss:  0.1849101  || Decoder Loss:  0.50077295 Validation Decoder Loss:  0.9955872
Encoder Loss:  0.18488061  || Decoder Loss:  0.50068563 Validation Decoder Loss:  0.9956746
Encoder Loss:  0.18487692  || Decoder Loss:  0.50067663 Validation Decoder Loss:  0.9954639
Encoder Loss:  0.18486495  || Decoder Loss:  0.50064445 Validation Decoder Loss:  0.99562263
Encoder Loss:  0.18487366  || Decoder Loss:  0.5006743 Validation Decoder Loss:  0.9955553
Encoder Loss:  0.18489285  || Decoder Loss:  0.5007012 Validation Decoder Loss:  0.9956081
Encoder Loss:  0.18487297  || Decoder Loss:  0.50067097 Validation Decoder Loss:  0.99553144
Model: siamese_net_lr_0.5077118720091068 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.99553144
Model: "sequential_477"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_192 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_548 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_193 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_478"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_192 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_550 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_193 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_479"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_194 (Conv3D (None, 70, 19, 20, 1)     50        
_________________________________________________________________
dropout_552 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_195 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_135 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 111
Trainable params: 111
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_481"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_194 (Conv2D)          (None, 2250, 20, 1)       359       
_________________________________________________________________
dropout_554 (Dropout)        (None, 2250, 20, 1)       0         
_________________________________________________________________
conv2d_195 (Conv2D)          (None, 2220, 20, 1)       32        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_482"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_194 (Conv2D (None, 2570, 20, 1)       352       
_________________________________________________________________
dropout_556 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_195 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.32683483  || Decoder Loss:  0.36156163 Validation Decoder Loss:  0.9813818
Encoder Loss:  0.43176776  || Decoder Loss:  0.50212103 Validation Decoder Loss:  1.009824
Encoder Loss:  0.42966694  || Decoder Loss:  0.49991044 Validation Decoder Loss:  1.0046462
Encoder Loss:  0.42660704  || Decoder Loss:  0.49635154 Validation Decoder Loss:  1.001417
Encoder Loss:  0.3863549  || Decoder Loss:  0.4487136 Validation Decoder Loss:  0.33735573
Encoder Loss:  0.039986297  || Decoder Loss:  0.037952792 Validation Decoder Loss:  0.3333411
Encoder Loss:  0.039641723  || Decoder Loss:  0.03752659 Validation Decoder Loss:  0.3336276
Encoder Loss:  0.043537334  || Decoder Loss:  0.042145383 Validation Decoder Loss:  0.3348444
Encoder Loss:  0.03958286  || Decoder Loss:  0.037304357 Validation Decoder Loss:  0.33471042
Encoder Loss:  0.038561713  || Decoder Loss:  0.036299728 Validation Decoder Loss:  0.33380902
Encoder Loss:  0.03839553  || Decoder Loss:  0.03622054 Validation Decoder Loss:  0.3329746
Encoder Loss:  0.039248336  || Decoder Loss:  0.037242495 Validation Decoder Loss:  0.3325627
Encoder Loss:  0.037911672  || Decoder Loss:  0.035659026 Validation Decoder Loss:  0.3323397
Encoder Loss:  0.03782935  || Decoder Loss:  0.035562254 Validation Decoder Loss:  0.33207265
Encoder Loss:  0.03779433  || Decoder Loss:  0.03552016 Validation Decoder Loss:  0.33240736
Encoder Loss:  0.037716266  || Decoder Loss:  0.035427086 Validation Decoder Loss:  0.3320585
Encoder Loss:  0.03847321  || Decoder Loss:  0.03632625 Validation Decoder Loss:  0.3331915
Encoder Loss:  0.03789308  || Decoder Loss:  0.035637368 Validation Decoder Loss:  0.3321819
Encoder Loss:  0.041015558  || Decoder Loss:  0.03931935 Validation Decoder Loss:  0.3324221
Encoder Loss:  0.037759613  || Decoder Loss:  0.035479516 Validation Decoder Loss:  0.33182037
Encoder Loss:  0.0391445  || Decoder Loss:  0.037091948 Validation Decoder Loss:  0.33253527
Encoder Loss:  0.037812263  || Decoder Loss:  0.03554085 Validation Decoder Loss:  0.33245242
Encoder Loss:  0.03779978  || Decoder Loss:  0.035523716 Validation Decoder Loss:  0.33242303
Encoder Loss:  0.040921245  || Decoder Loss:  0.039210226 Validation Decoder Loss:  0.3555952
Encoder Loss:  0.15477376  || Decoder Loss:  0.1742004 Validation Decoder Loss:  0.33342072
Encoder Loss:  0.03772973  || Decoder Loss:  0.03544258 Validation Decoder Loss:  0.3323682
Encoder Loss:  0.03770951  || Decoder Loss:  0.03541736 Validation Decoder Loss:  0.33262888
Encoder Loss:  0.03767805  || Decoder Loss:  0.035380922 Validation Decoder Loss:  0.33324516
Encoder Loss:  0.03768253  || Decoder Loss:  0.03538634 Validation Decoder Loss:  0.33241695
Encoder Loss:  0.03768907  || Decoder Loss:  0.03539487 Validation Decoder Loss:  0.33246854
Encoder Loss:  0.037680954  || Decoder Loss:  0.035384424 Validation Decoder Loss:  0.33245176
Encoder Loss:  0.037745886  || Decoder Loss:  0.035462238 Validation Decoder Loss:  0.33279294
Encoder Loss:  0.037770923  || Decoder Loss:  0.035489395 Validation Decoder Loss:  0.33262646
Encoder Loss:  0.03775642  || Decoder Loss:  0.035473127 Validation Decoder Loss:  0.33169138
Encoder Loss:  0.0377702  || Decoder Loss:  0.035490815 Validation Decoder Loss:  0.3326369
Encoder Loss:  0.03775441  || Decoder Loss:  0.0354717 Validation Decoder Loss:  0.33219475
Encoder Loss:  0.037780724  || Decoder Loss:  0.035503767 Validation Decoder Loss:  0.331953
Encoder Loss:  0.30683574  || Decoder Loss:  0.35460785 Validation Decoder Loss:  0.9876076
Encoder Loss:  0.10600312  || Decoder Loss:  0.11642014 Validation Decoder Loss:  0.33405486
Encoder Loss:  0.03776638  || Decoder Loss:  0.03548764 Validation Decoder Loss:  0.33174413
Model: siamese_net_lr_0.12559925877236253 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33174413
Model: "sequential_483"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_197 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_558 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_198 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_136 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_485"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_196 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_560 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_197 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_486"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_196 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_562 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_197 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33662263  || Decoder Loss:  0.7577367 Validation Decoder Loss:  1.6418557
Encoder Loss:  0.22111546  || Decoder Loss:  0.526016 Validation Decoder Loss:  1.0127577
Encoder Loss:  0.20968212  || Decoder Loss:  0.49443948 Validation Decoder Loss:  1.0188587
Encoder Loss:  0.21012321  || Decoder Loss:  0.49573642 Validation Decoder Loss:  1.0159926
Encoder Loss:  0.20983239  || Decoder Loss:  0.49484795 Validation Decoder Loss:  1.0132087
Encoder Loss:  0.20988089  || Decoder Loss:  0.49498847 Validation Decoder Loss:  1.015938
Encoder Loss:  0.2098523  || Decoder Loss:  0.49489254 Validation Decoder Loss:  1.0155141
Encoder Loss:  0.2097752  || Decoder Loss:  0.49465218 Validation Decoder Loss:  1.0166925
Encoder Loss:  0.20975119  || Decoder Loss:  0.49459428 Validation Decoder Loss:  1.0146029
Encoder Loss:  0.209911  || Decoder Loss:  0.4950037 Validation Decoder Loss:  1.017298
Encoder Loss:  0.20967887  || Decoder Loss:  0.49443617 Validation Decoder Loss:  1.0128851
Encoder Loss:  0.21030356  || Decoder Loss:  0.49614576 Validation Decoder Loss:  1.0151882
Encoder Loss:  0.20977667  || Decoder Loss:  0.49465382 Validation Decoder Loss:  1.015121
Encoder Loss:  0.20974065  || Decoder Loss:  0.4946071 Validation Decoder Loss:  1.0149997
Encoder Loss:  0.20974174  || Decoder Loss:  0.4945613 Validation Decoder Loss:  1.0148443
Encoder Loss:  0.20970024  || Decoder Loss:  0.4944809 Validation Decoder Loss:  1.0147278
Encoder Loss:  0.20970963  || Decoder Loss:  0.49439916 Validation Decoder Loss:  1.0143414
Encoder Loss:  0.20962438  || Decoder Loss:  0.49423936 Validation Decoder Loss:  1.0139595
Encoder Loss:  0.20957376  || Decoder Loss:  0.49413466 Validation Decoder Loss:  1.0133975
Encoder Loss:  0.20949091  || Decoder Loss:  0.49388894 Validation Decoder Loss:  1.0124545
Encoder Loss:  0.20939526  || Decoder Loss:  0.49363446 Validation Decoder Loss:  1.0110455
Encoder Loss:  0.20936419  || Decoder Loss:  0.49345443 Validation Decoder Loss:  1.0095212
Encoder Loss:  0.20938167  || Decoder Loss:  0.49353573 Validation Decoder Loss:  1.0021427
Encoder Loss:  0.2076551  || Decoder Loss:  0.48875004 Validation Decoder Loss:  1.0449101
Encoder Loss:  0.21997814  || Decoder Loss:  0.5230873 Validation Decoder Loss:  1.4535267
Encoder Loss:  0.23760346  || Decoder Loss:  0.5721293 Validation Decoder Loss:  1.0707532
Encoder Loss:  0.21738754  || Decoder Loss:  0.5157158 Validation Decoder Loss:  1.0058305
Encoder Loss:  0.2099125  || Decoder Loss:  0.4950972 Validation Decoder Loss:  0.9796529
Encoder Loss:  0.20960304  || Decoder Loss:  0.49427697 Validation Decoder Loss:  0.9985346
Encoder Loss:  0.20873074  || Decoder Loss:  0.49179024 Validation Decoder Loss:  0.93978405
Encoder Loss:  0.18879719  || Decoder Loss:  0.43632203 Validation Decoder Loss:  1.1752274
Encoder Loss:  0.16641009  || Decoder Loss:  0.37401807 Validation Decoder Loss:  0.74548
Encoder Loss:  0.15198413  || Decoder Loss:  0.33386636 Validation Decoder Loss:  1.6457134
Encoder Loss:  0.19833253  || Decoder Loss:  0.4629285 Validation Decoder Loss:  0.95282376
Encoder Loss:  0.20917481  || Decoder Loss:  0.4931091 Validation Decoder Loss:  1.0320059
Encoder Loss:  0.21367116  || Decoder Loss:  0.50563294 Validation Decoder Loss:  1.0023248
Encoder Loss:  0.21053432  || Decoder Loss:  0.4968902 Validation Decoder Loss:  1.0148276
Encoder Loss:  0.21066095  || Decoder Loss:  0.4972333 Validation Decoder Loss:  0.96774876
Encoder Loss:  0.20761448  || Decoder Loss:  0.48876247 Validation Decoder Loss:  1.050212
Encoder Loss:  0.2162801  || Decoder Loss:  0.51284945 Validation Decoder Loss:  0.9792509
Model: siamese_net_lr_0.8138216645122821 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9792509
Model: "sequential_487"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_200 (Conv3D (None, 68, 20, 20, 1)     21        
_________________________________________________________________
dropout_564 (Dropout)        (None, 68, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_201 (Conv3D (None, 74, 30, 20, 1)     78        
_________________________________________________________________
reshape_137 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_489"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_198 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_566 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_199 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_490"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_198 (Conv2D (None, 2520, 20, 1)       302       
_________________________________________________________________
dropout_568 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_199 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.67298883  || Decoder Loss:  0.8110191 Validation Decoder Loss:  0.35301632
Encoder Loss:  0.39956203  || Decoder Loss:  0.50946 Validation Decoder Loss:  0.36218452
Encoder Loss:  0.39910734  || Decoder Loss:  0.51990247 Validation Decoder Loss:  1.0065128
Encoder Loss:  0.37542525  || Decoder Loss:  0.49473023 Validation Decoder Loss:  0.9963785
Encoder Loss:  0.37385887  || Decoder Loss:  0.49405286 Validation Decoder Loss:  0.98675245
Encoder Loss:  0.36933017  || Decoder Loss:  0.4878244 Validation Decoder Loss:  0.8979187
Encoder Loss:  0.35246247  || Decoder Loss:  0.46442658 Validation Decoder Loss:  0.4744446
Encoder Loss:  0.11529127  || Decoder Loss:  0.13919917 Validation Decoder Loss:  0.33999693
Encoder Loss:  0.046552  || Decoder Loss:  0.04475611 Validation Decoder Loss:  0.33961555
Encoder Loss:  0.044174276  || Decoder Loss:  0.04171615 Validation Decoder Loss:  0.34067228
Encoder Loss:  0.044188328  || Decoder Loss:  0.04146339 Validation Decoder Loss:  0.33872887
Encoder Loss:  0.042787418  || Decoder Loss:  0.039905977 Validation Decoder Loss:  0.33783275
Encoder Loss:  0.04258336  || Decoder Loss:  0.039598893 Validation Decoder Loss:  0.33516884
Encoder Loss:  0.04337769  || Decoder Loss:  0.040464595 Validation Decoder Loss:  0.33747643
Encoder Loss:  0.045092646  || Decoder Loss:  0.04244826 Validation Decoder Loss:  0.36187166
Encoder Loss:  0.100135475  || Decoder Loss:  0.11794237 Validation Decoder Loss:  1.0291126
Encoder Loss:  0.072409734  || Decoder Loss:  0.080622844 Validation Decoder Loss:  0.33948457
Encoder Loss:  0.041121274  || Decoder Loss:  0.037612654 Validation Decoder Loss:  0.33822203
Encoder Loss:  0.077801384  || Decoder Loss:  0.08672987 Validation Decoder Loss:  0.39171886
Encoder Loss:  0.044605512  || Decoder Loss:  0.042182434 Validation Decoder Loss:  0.3378305
Encoder Loss:  0.04069713  || Decoder Loss:  0.037142437 Validation Decoder Loss:  0.3375653
Encoder Loss:  0.041350674  || Decoder Loss:  0.03797523 Validation Decoder Loss:  0.33626437
Encoder Loss:  0.04189134  || Decoder Loss:  0.03862325 Validation Decoder Loss:  0.33685872
Encoder Loss:  0.040793296  || Decoder Loss:  0.037264414 Validation Decoder Loss:  0.33638346
Encoder Loss:  0.040785946  || Decoder Loss:  0.037277292 Validation Decoder Loss:  0.33663797
Encoder Loss:  0.040835902  || Decoder Loss:  0.037269734 Validation Decoder Loss:  0.33587962
Encoder Loss:  0.041201044  || Decoder Loss:  0.0376206 Validation Decoder Loss:  0.33664486
Encoder Loss:  0.040941495  || Decoder Loss:  0.037387654 Validation Decoder Loss:  0.33681986
Encoder Loss:  0.074629076  || Decoder Loss:  0.083483286 Validation Decoder Loss:  0.7201694
Encoder Loss:  0.094441116  || Decoder Loss:  0.110890254 Validation Decoder Loss:  0.33593798
Encoder Loss:  0.07122721  || Decoder Loss:  0.07846269 Validation Decoder Loss:  1.2570446
Encoder Loss:  0.38448772  || Decoder Loss:  0.50848985 Validation Decoder Loss:  0.9969361
Encoder Loss:  0.37323812  || Decoder Loss:  0.49329507 Validation Decoder Loss:  0.9956708
Encoder Loss:  0.28860733  || Decoder Loss:  0.37714586 Validation Decoder Loss:  0.3364749
Encoder Loss:  0.03978277  || Decoder Loss:  0.035902843 Validation Decoder Loss:  0.33642915
Encoder Loss:  0.039551005  || Decoder Loss:  0.03563281 Validation Decoder Loss:  0.33622754
Encoder Loss:  0.0395703  || Decoder Loss:  0.03563563 Validation Decoder Loss:  0.33561957
Encoder Loss:  0.03957688  || Decoder Loss:  0.03566146 Validation Decoder Loss:  0.33538014
Encoder Loss:  0.039622948  || Decoder Loss:  0.035663545 Validation Decoder Loss:  0.33536923
Encoder Loss:  0.03971124  || Decoder Loss:  0.0357148 Validation Decoder Loss:  0.33248878
Model: siamese_net_lr_0.48491957373044353 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33248878
Model: "sequential_491"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_203 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_570 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_204 (Conv3D (None, 74, 30, 20, 1)     19        
_________________________________________________________________
reshape_138 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 29
Trainable params: 29
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_493"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_200 (Conv2D)          (None, 2430, 20, 1)       179       
_________________________________________________________________
dropout_572 (Dropout)        (None, 2430, 20, 1)       0         
_________________________________________________________________
conv2d_201 (Conv2D)          (None, 2220, 20, 1)       212       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_494"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_200 (Conv2D (None, 2280, 20, 1)       62        
_________________________________________________________________
dropout_574 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_201 (Conv2D (None, 2607, 20, 1)       329       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19480814  || Decoder Loss:  0.21856555 Validation Decoder Loss:  0.35823983
Encoder Loss:  0.054244556  || Decoder Loss:  0.056013007 Validation Decoder Loss:  0.3597592
Encoder Loss:  0.05425456  || Decoder Loss:  0.056023784 Validation Decoder Loss:  0.3600632
Encoder Loss:  0.054446053  || Decoder Loss:  0.056428447 Validation Decoder Loss:  0.36103338
Encoder Loss:  0.05426588  || Decoder Loss:  0.056189265 Validation Decoder Loss:  0.3620338
Encoder Loss:  0.054019473  || Decoder Loss:  0.055831723 Validation Decoder Loss:  0.3629419
Encoder Loss:  0.05370208  || Decoder Loss:  0.055370763 Validation Decoder Loss:  0.36369365
Encoder Loss:  0.053150583  || Decoder Loss:  0.054569826 Validation Decoder Loss:  0.36400336
Encoder Loss:  0.051499054  || Decoder Loss:  0.052171096 Validation Decoder Loss:  0.3631893
Encoder Loss:  0.05302456  || Decoder Loss:  0.05438696 Validation Decoder Loss:  0.3632297
Encoder Loss:  0.05098386  || Decoder Loss:  0.05142289 Validation Decoder Loss:  0.3597443
Encoder Loss:  0.045603305  || Decoder Loss:  0.043607637 Validation Decoder Loss:  0.35612246
Encoder Loss:  0.04377374  || Decoder Loss:  0.0409503 Validation Decoder Loss:  0.3521013
Encoder Loss:  0.0428673  || Decoder Loss:  0.039633837 Validation Decoder Loss:  0.35099265
Encoder Loss:  0.04244173  || Decoder Loss:  0.039015803 Validation Decoder Loss:  0.3498181
Encoder Loss:  0.04225401  || Decoder Loss:  0.038743366 Validation Decoder Loss:  0.34932753
Encoder Loss:  0.042166453  || Decoder Loss:  0.038616296 Validation Decoder Loss:  0.348985
Encoder Loss:  0.042091586  || Decoder Loss:  0.03850765 Validation Decoder Loss:  0.34883592
Encoder Loss:  0.042029962  || Decoder Loss:  0.038418237 Validation Decoder Loss:  0.34882072
Encoder Loss:  0.041973993  || Decoder Loss:  0.038336802 Validation Decoder Loss:  0.34886307
Encoder Loss:  0.041916627  || Decoder Loss:  0.038253155 Validation Decoder Loss:  0.34886357
Encoder Loss:  0.041871957  || Decoder Loss:  0.038187362 Validation Decoder Loss:  0.34922883
Encoder Loss:  0.041885704  || Decoder Loss:  0.038186762 Validation Decoder Loss:  0.34916812
Encoder Loss:  0.04199365  || Decoder Loss:  0.038357414 Validation Decoder Loss:  0.34740964
Encoder Loss:  0.04192816  || Decoder Loss:  0.038271103 Validation Decoder Loss:  0.34749818
Encoder Loss:  0.041834947  || Decoder Loss:  0.03813675 Validation Decoder Loss:  0.34648323
Encoder Loss:  0.041759033  || Decoder Loss:  0.038026694 Validation Decoder Loss:  0.34649032
Encoder Loss:  0.041691944  || Decoder Loss:  0.037929457 Validation Decoder Loss:  0.3466494
Encoder Loss:  0.04162265  || Decoder Loss:  0.037829094 Validation Decoder Loss:  0.34644425
Encoder Loss:  0.041560903  || Decoder Loss:  0.03773957 Validation Decoder Loss:  0.34635198
Encoder Loss:  0.041510466  || Decoder Loss:  0.03766635 Validation Decoder Loss:  0.34681755
Encoder Loss:  0.04146261  || Decoder Loss:  0.03759699 Validation Decoder Loss:  0.34712526
Encoder Loss:  0.041409798  || Decoder Loss:  0.0375203 Validation Decoder Loss:  0.34745646
Encoder Loss:  0.041379474  || Decoder Loss:  0.037476197 Validation Decoder Loss:  0.34702444
Encoder Loss:  0.04135394  || Decoder Loss:  0.03743885 Validation Decoder Loss:  0.3479452
Encoder Loss:  0.041339017  || Decoder Loss:  0.037417214 Validation Decoder Loss:  0.34764305
Encoder Loss:  0.04132817  || Decoder Loss:  0.03740184 Validation Decoder Loss:  0.34847578
Encoder Loss:  0.04127453  || Decoder Loss:  0.037323643 Validation Decoder Loss:  0.34905577
Encoder Loss:  0.041250326  || Decoder Loss:  0.037288867 Validation Decoder Loss:  0.34907788
Encoder Loss:  0.0412284  || Decoder Loss:  0.037257105 Validation Decoder Loss:  0.34893468
Model: siamese_net_lr_0.16224511389935664 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34893468
Model: "sequential_495"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_206 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_576 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_207 (Conv3D (None, 74, 30, 20, 1)     55        
_________________________________________________________________
reshape_139 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 59
Trainable params: 59
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_497"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_202 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_578 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_203 (Conv2D)          (None, 2220, 20, 1)       362       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_498"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_202 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_580 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_203 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.30202582  || Decoder Loss:  0.4361581 Validation Decoder Loss:  0.30255997
Encoder Loss:  0.31222624  || Decoder Loss:  0.48279586 Validation Decoder Loss:  0.34444803
Encoder Loss:  0.31518403  || Decoder Loss:  0.4908041 Validation Decoder Loss:  0.32017666
Encoder Loss:  0.30710715  || Decoder Loss:  0.47714478 Validation Decoder Loss:  1.4791508
Encoder Loss:  0.3280362  || Decoder Loss:  0.514189 Validation Decoder Loss:  0.9984914
Encoder Loss:  0.31580573  || Decoder Loss:  0.49500468 Validation Decoder Loss:  0.99276674
Encoder Loss:  0.31614688  || Decoder Loss:  0.49565342 Validation Decoder Loss:  0.99299884
Encoder Loss:  0.31597468  || Decoder Loss:  0.49536666 Validation Decoder Loss:  0.99331677
Encoder Loss:  0.31591555  || Decoder Loss:  0.49526936 Validation Decoder Loss:  0.9929509
Encoder Loss:  0.31606922  || Decoder Loss:  0.49552238 Validation Decoder Loss:  0.9957618
Encoder Loss:  0.31605217  || Decoder Loss:  0.49547988 Validation Decoder Loss:  1.0046072
Encoder Loss:  0.31853053  || Decoder Loss:  0.49887615 Validation Decoder Loss:  1.0115193
Encoder Loss:  0.31692675  || Decoder Loss:  0.49626634 Validation Decoder Loss:  0.99641645
Encoder Loss:  0.31601536  || Decoder Loss:  0.49543658 Validation Decoder Loss:  0.99594283
Encoder Loss:  0.3158579  || Decoder Loss:  0.49517247 Validation Decoder Loss:  0.9954412
Encoder Loss:  0.31585094  || Decoder Loss:  0.49516106 Validation Decoder Loss:  0.9959208
Encoder Loss:  0.31579548  || Decoder Loss:  0.49506775 Validation Decoder Loss:  0.99546134
Encoder Loss:  0.31568438  || Decoder Loss:  0.49487916 Validation Decoder Loss:  0.9937432
Encoder Loss:  0.31509885  || Decoder Loss:  0.493899 Validation Decoder Loss:  0.9870646
Encoder Loss:  0.31364873  || Decoder Loss:  0.49146497 Validation Decoder Loss:  0.98511374
Encoder Loss:  0.3166082  || Decoder Loss:  0.49641845 Validation Decoder Loss:  0.98088086
Encoder Loss:  0.3209275  || Decoder Loss:  0.5028668 Validation Decoder Loss:  1.008515
Encoder Loss:  0.31743583  || Decoder Loss:  0.49573657 Validation Decoder Loss:  0.9990449
Encoder Loss:  0.3161819  || Decoder Loss:  0.49570045 Validation Decoder Loss:  1.0005176
Encoder Loss:  0.31591025  || Decoder Loss:  0.49525517 Validation Decoder Loss:  1.0000873
Encoder Loss:  0.31584594  || Decoder Loss:  0.495148 Validation Decoder Loss:  1.0009651
Encoder Loss:  0.31540534  || Decoder Loss:  0.4944045 Validation Decoder Loss:  1.0030407
Encoder Loss:  0.31391603  || Decoder Loss:  0.49191025 Validation Decoder Loss:  1.0239251
Encoder Loss:  0.31627437  || Decoder Loss:  0.4958394 Validation Decoder Loss:  0.99837375
Encoder Loss:  0.32045612  || Decoder Loss:  0.50282496 Validation Decoder Loss:  1.0067339
Encoder Loss:  0.32239488  || Decoder Loss:  0.50577444 Validation Decoder Loss:  0.9998387
Encoder Loss:  0.32056  || Decoder Loss:  0.5029702 Validation Decoder Loss:  1.0046194
Encoder Loss:  0.32070178  || Decoder Loss:  0.5032323 Validation Decoder Loss:  0.99880266
Encoder Loss:  0.31987694  || Decoder Loss:  0.50187105 Validation Decoder Loss:  1.0006161
Encoder Loss:  0.3178223  || Decoder Loss:  0.49846295 Validation Decoder Loss:  0.9983057
Encoder Loss:  0.28883886  || Decoder Loss:  0.44993043 Validation Decoder Loss:  0.9980365
Encoder Loss:  0.3125066  || Decoder Loss:  0.48956218 Validation Decoder Loss:  0.9986336
Encoder Loss:  0.3163227  || Decoder Loss:  0.4959507 Validation Decoder Loss:  0.99941266
Encoder Loss:  0.3160836  || Decoder Loss:  0.49555123 Validation Decoder Loss:  0.99841434
Encoder Loss:  0.31575418  || Decoder Loss:  0.49499977 Validation Decoder Loss:  0.9986556
Model: siamese_net_lr_0.26043594584561686 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9986556
Model: "sequential_499"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_209 (Conv3D (None, 70, 29, 20, 1)     92        
_________________________________________________________________
dropout_582 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_210 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_140 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 103
Trainable params: 103
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_501"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_204 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_584 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_205 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_502"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_204 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_586 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_205 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.49127266  || Decoder Loss:  0.51048756 Validation Decoder Loss:  1.0755622
Encoder Loss:  0.45158023  || Decoder Loss:  0.49801937 Validation Decoder Loss:  0.9745292
Encoder Loss:  0.44013295  || Decoder Loss:  0.4854253 Validation Decoder Loss:  0.90262294
Encoder Loss:  0.43426886  || Decoder Loss:  0.4788532 Validation Decoder Loss:  1.013123
Encoder Loss:  0.44253033  || Decoder Loss:  0.4882289 Validation Decoder Loss:  1.0220063
Encoder Loss:  0.42599934  || Decoder Loss:  0.46982902 Validation Decoder Loss:  0.99125695
Encoder Loss:  0.4186964  || Decoder Loss:  0.46165714 Validation Decoder Loss:  1.0259753
Encoder Loss:  0.43507794  || Decoder Loss:  0.4799215 Validation Decoder Loss:  0.9695761
Encoder Loss:  0.43453228  || Decoder Loss:  0.47943044 Validation Decoder Loss:  0.94163585
Encoder Loss:  0.43560487  || Decoder Loss:  0.48067725 Validation Decoder Loss:  0.96755296
Encoder Loss:  0.4114474  || Decoder Loss:  0.45349362 Validation Decoder Loss:  0.7260147
Encoder Loss:  0.42811364  || Decoder Loss:  0.47228074 Validation Decoder Loss:  0.96887064
Encoder Loss:  0.4137075  || Decoder Loss:  0.45618156 Validation Decoder Loss:  1.041892
Encoder Loss:  0.41764548  || Decoder Loss:  0.46040455 Validation Decoder Loss:  0.96117306
Encoder Loss:  0.41411468  || Decoder Loss:  0.45669094 Validation Decoder Loss:  0.97676873
Encoder Loss:  0.43989673  || Decoder Loss:  0.48551208 Validation Decoder Loss:  0.9858125
Encoder Loss:  0.42222416  || Decoder Loss:  0.4657153 Validation Decoder Loss:  0.98732936
Encoder Loss:  0.41969937  || Decoder Loss:  0.4629553 Validation Decoder Loss:  0.9844417
Encoder Loss:  0.41582048  || Decoder Loss:  0.4585665 Validation Decoder Loss:  0.9801599
Encoder Loss:  0.42463237  || Decoder Loss:  0.46845195 Validation Decoder Loss:  0.9988674
Encoder Loss:  0.4144659  || Decoder Loss:  0.45707932 Validation Decoder Loss:  0.9343847
Encoder Loss:  0.393621  || Decoder Loss:  0.43381333 Validation Decoder Loss:  0.865206
Encoder Loss:  0.4226839  || Decoder Loss:  0.46626076 Validation Decoder Loss:  0.9771358
Encoder Loss:  0.40805352  || Decoder Loss:  0.4499617 Validation Decoder Loss:  0.98475295
Encoder Loss:  0.39607242  || Decoder Loss:  0.43648022 Validation Decoder Loss:  0.98532486
Encoder Loss:  0.31808013  || Decoder Loss:  0.34945723 Validation Decoder Loss:  0.6666123
Encoder Loss:  0.13838679  || Decoder Loss:  0.14870785 Validation Decoder Loss:  0.5215948
Encoder Loss:  0.06757398  || Decoder Loss:  0.06957137 Validation Decoder Loss:  0.37901706
Encoder Loss:  0.06038373  || Decoder Loss:  0.06157024 Validation Decoder Loss:  0.35917503
Encoder Loss:  0.059860397  || Decoder Loss:  0.06098551 Validation Decoder Loss:  0.36547953
Encoder Loss:  0.055619985  || Decoder Loss:  0.05623232 Validation Decoder Loss:  0.36171418
Encoder Loss:  0.054661557  || Decoder Loss:  0.0551694 Validation Decoder Loss:  0.36167002
Encoder Loss:  0.053224806  || Decoder Loss:  0.05358694 Validation Decoder Loss:  0.3619843
Encoder Loss:  0.052514598  || Decoder Loss:  0.05278955 Validation Decoder Loss:  0.3613341
Encoder Loss:  0.052555628  || Decoder Loss:  0.05282221 Validation Decoder Loss:  0.3645813
Encoder Loss:  0.05254102  || Decoder Loss:  0.05279548 Validation Decoder Loss:  0.37094975
Encoder Loss:  0.05495673  || Decoder Loss:  0.05542968 Validation Decoder Loss:  0.36107108
Encoder Loss:  0.05505826  || Decoder Loss:  0.055638514 Validation Decoder Loss:  0.36086017
Encoder Loss:  0.056257583  || Decoder Loss:  0.05696072 Validation Decoder Loss:  0.3652236
Encoder Loss:  0.055379715  || Decoder Loss:  0.055850502 Validation Decoder Loss:  0.35912186
Model: siamese_net_lr_0.6454817203136589 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35912186
Model: "sequential_503"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_212 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_588 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_213 (Conv3D (None, 74, 30, 20, 1)     99        
_________________________________________________________________
reshape_141 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 105
Trainable params: 105
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_505"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_206 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_590 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_207 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_506"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_206 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_592 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_207 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.060865134  || Decoder Loss:  0.06001244 Validation Decoder Loss:  0.33630374
Encoder Loss:  0.039752673  || Decoder Loss:  0.034153726 Validation Decoder Loss:  0.333098
Encoder Loss:  0.0389434  || Decoder Loss:  0.032900643 Validation Decoder Loss:  0.3312657
Encoder Loss:  0.038595345  || Decoder Loss:  0.03236234 Validation Decoder Loss:  0.32951272
Encoder Loss:  0.05117426  || Decoder Loss:  0.05169351 Validation Decoder Loss:  0.3408653
Encoder Loss:  0.041062  || Decoder Loss:  0.036177985 Validation Decoder Loss:  0.33512473
Encoder Loss:  0.04061799  || Decoder Loss:  0.035493154 Validation Decoder Loss:  0.33711785
Encoder Loss:  0.039854873  || Decoder Loss:  0.034312744 Validation Decoder Loss:  0.33180296
Encoder Loss:  0.03932167  || Decoder Loss:  0.033487655 Validation Decoder Loss:  0.3364008
Encoder Loss:  0.06934503  || Decoder Loss:  0.07989827 Validation Decoder Loss:  0.33809668
Encoder Loss:  0.041078817  || Decoder Loss:  0.036196932 Validation Decoder Loss:  0.33625156
Encoder Loss:  0.040703878  || Decoder Loss:  0.03562428 Validation Decoder Loss:  0.34087104
Encoder Loss:  0.11185811  || Decoder Loss:  0.14542717 Validation Decoder Loss:  0.98775244
Encoder Loss:  0.34018838  || Decoder Loss:  0.49859187 Validation Decoder Loss:  0.9866189
Encoder Loss:  0.1963762  || Decoder Loss:  0.2762762 Validation Decoder Loss:  0.33327025
Encoder Loss:  0.04084868  || Decoder Loss:  0.035851117 Validation Decoder Loss:  0.34003544
Encoder Loss:  0.04066978  || Decoder Loss:  0.035574082 Validation Decoder Loss:  0.330066
Encoder Loss:  0.040303167  || Decoder Loss:  0.035006262 Validation Decoder Loss:  0.3402831
Encoder Loss:  0.039896935  || Decoder Loss:  0.034378268 Validation Decoder Loss:  0.331625
Encoder Loss:  0.03968576  || Decoder Loss:  0.03405087 Validation Decoder Loss:  0.34976143
Encoder Loss:  0.039385345  || Decoder Loss:  0.033585683 Validation Decoder Loss:  0.34651867
Encoder Loss:  0.3469905  || Decoder Loss:  0.50590295 Validation Decoder Loss:  1.0499114
Encoder Loss:  0.3406207  || Decoder Loss:  0.49804235 Validation Decoder Loss:  1.002472
Encoder Loss:  0.33861202  || Decoder Loss:  0.4960767 Validation Decoder Loss:  0.9973454
Encoder Loss:  0.33844352  || Decoder Loss:  0.49589255 Validation Decoder Loss:  0.9972447
Encoder Loss:  0.338297  || Decoder Loss:  0.49566787 Validation Decoder Loss:  0.99663293
Encoder Loss:  0.33590233  || Decoder Loss:  0.4919688 Validation Decoder Loss:  0.9983616
Encoder Loss:  0.06859925  || Decoder Loss:  0.078751236 Validation Decoder Loss:  0.34854862
Encoder Loss:  0.040212855  || Decoder Loss:  0.034869164 Validation Decoder Loss:  0.34260446
Encoder Loss:  0.039918046  || Decoder Loss:  0.034413166 Validation Decoder Loss:  0.33874324
Encoder Loss:  0.039391067  || Decoder Loss:  0.033598214 Validation Decoder Loss:  0.3368473
Encoder Loss:  0.038922995  || Decoder Loss:  0.03287385 Validation Decoder Loss:  0.36365148
Encoder Loss:  0.055824805  || Decoder Loss:  0.05898411 Validation Decoder Loss:  0.3580807
Encoder Loss:  0.040044848  || Decoder Loss:  0.03460889 Validation Decoder Loss:  0.3440141
Encoder Loss:  0.03925641  || Decoder Loss:  0.033389922 Validation Decoder Loss:  0.34291142
Encoder Loss:  0.03929574  || Decoder Loss:  0.033450395 Validation Decoder Loss:  0.33585706
Encoder Loss:  0.039070617  || Decoder Loss:  0.033101976 Validation Decoder Loss:  0.34845746
Encoder Loss:  0.03913074  || Decoder Loss:  0.033194084 Validation Decoder Loss:  0.33321956
Encoder Loss:  0.041636735  || Decoder Loss:  0.037056744 Validation Decoder Loss:  0.3675539
Encoder Loss:  0.050783146  || Decoder Loss:  0.05120899 Validation Decoder Loss:  0.33401608
Model: siamese_net_lr_0.01932613120427932 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33401608
Model: "sequential_507"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_215 (Conv3D (None, 68, 10, 20, 1)     31        
_________________________________________________________________
dropout_594 (Dropout)        (None, 68, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_216 (Conv3D (None, 74, 30, 20, 1)     148       
_________________________________________________________________
reshape_142 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 179
Trainable params: 179
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_509"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_208 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_596 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_209 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_510"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_208 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_598 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_209 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.29277635  || Decoder Loss:  0.45694298 Validation Decoder Loss:  1.0166286
Encoder Loss:  0.30221406  || Decoder Loss:  0.49493134 Validation Decoder Loss:  1.0161656
Encoder Loss:  0.30224663  || Decoder Loss:  0.49498668 Validation Decoder Loss:  1.0137877
Encoder Loss:  0.30209652  || Decoder Loss:  0.4947181 Validation Decoder Loss:  1.0144476
Encoder Loss:  0.30154672  || Decoder Loss:  0.4937397 Validation Decoder Loss:  1.0041897
Encoder Loss:  0.2992829  || Decoder Loss:  0.4897511 Validation Decoder Loss:  1.0175111
Encoder Loss:  0.30371958  || Decoder Loss:  0.49744743 Validation Decoder Loss:  1.0208396
Encoder Loss:  0.30233693  || Decoder Loss:  0.49514773 Validation Decoder Loss:  1.0242043
Encoder Loss:  0.30249572  || Decoder Loss:  0.4954277 Validation Decoder Loss:  1.0182254
Encoder Loss:  0.30021414  || Decoder Loss:  0.4914009 Validation Decoder Loss:  1.0137023
Encoder Loss:  0.30417228  || Decoder Loss:  0.4983308 Validation Decoder Loss:  0.9670453
Encoder Loss:  0.30521584  || Decoder Loss:  0.50022906 Validation Decoder Loss:  0.98696244
Encoder Loss:  0.3024591  || Decoder Loss:  0.4953628 Validation Decoder Loss:  0.9459561
Encoder Loss:  0.2978438  || Decoder Loss:  0.48713967 Validation Decoder Loss:  0.9906654
Encoder Loss:  0.3037498  || Decoder Loss:  0.49764457 Validation Decoder Loss:  0.9997449
Encoder Loss:  0.30370367  || Decoder Loss:  0.49756244 Validation Decoder Loss:  0.9992606
Encoder Loss:  0.30332223  || Decoder Loss:  0.49688163 Validation Decoder Loss:  1.0004944
Encoder Loss:  0.30199128  || Decoder Loss:  0.4945243 Validation Decoder Loss:  1.0351202
Encoder Loss:  0.30503932  || Decoder Loss:  0.49991748 Validation Decoder Loss:  1.0031502
Encoder Loss:  0.30164614  || Decoder Loss:  0.49394116 Validation Decoder Loss:  0.6180228
Encoder Loss:  0.29989064  || Decoder Loss:  0.45928943 Validation Decoder Loss:  0.882401
Encoder Loss:  0.29735366  || Decoder Loss:  0.482836 Validation Decoder Loss:  1.543471
Encoder Loss:  0.32332122  || Decoder Loss:  0.52930593 Validation Decoder Loss:  1.280092
Encoder Loss:  0.3039476  || Decoder Loss:  0.4955015 Validation Decoder Loss:  0.49759948
Encoder Loss:  0.27779704  || Decoder Loss:  0.44926852 Validation Decoder Loss:  1.5188742
Encoder Loss:  0.29256842  || Decoder Loss:  0.47694054 Validation Decoder Loss:  0.7097851
Encoder Loss:  0.29017684  || Decoder Loss:  0.47365296 Validation Decoder Loss:  1.0671532
Encoder Loss:  0.3039613  || Decoder Loss:  0.49784428 Validation Decoder Loss:  1.0034437
Encoder Loss:  0.30187428  || Decoder Loss:  0.49432486 Validation Decoder Loss:  0.9928082
Encoder Loss:  0.3028994  || Decoder Loss:  0.49612227 Validation Decoder Loss:  0.9888674
Encoder Loss:  0.29608446  || Decoder Loss:  0.48411942 Validation Decoder Loss:  0.76697063
Encoder Loss:  0.28901282  || Decoder Loss:  0.47163978 Validation Decoder Loss:  0.82350945
Encoder Loss:  0.2984243  || Decoder Loss:  0.48824233 Validation Decoder Loss:  0.8557472
Encoder Loss:  0.3067554  || Decoder Loss:  0.50293833 Validation Decoder Loss:  1.016209
Encoder Loss:  0.3019788  || Decoder Loss:  0.4945139 Validation Decoder Loss:  1.0212219
Encoder Loss:  0.26662484  || Decoder Loss:  0.4321447 Validation Decoder Loss:  1.1067958
Encoder Loss:  0.2506443  || Decoder Loss:  0.40395156 Validation Decoder Loss:  1.1538417
Encoder Loss:  0.2618263  || Decoder Loss:  0.4236799 Validation Decoder Loss:  1.0385919
Encoder Loss:  0.302544  || Decoder Loss:  0.49551272 Validation Decoder Loss:  1.030722
Encoder Loss:  0.30254865  || Decoder Loss:  0.4955222 Validation Decoder Loss:  1.0154507
Model: siamese_net_lr_0.9892121941750741 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0154507
Model: "sequential_511"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_218 (Conv3D (None, 65, 10, 20, 1)     5         
_________________________________________________________________
dropout_600 (Dropout)        (None, 65, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_219 (Conv3D (None, 74, 30, 20, 1)     31        
_________________________________________________________________
reshape_143 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 36
Trainable params: 36
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_210 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_602 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_211 (Conv2D)          (None, 2220, 20, 1)       302       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_514"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_210 (Conv2D (None, 2470, 20, 1)       252       
_________________________________________________________________
dropout_604 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_211 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11564026  || Decoder Loss:  0.24953909 Validation Decoder Loss:  0.3765937
Encoder Loss:  0.045875773  || Decoder Loss:  0.036914077 Validation Decoder Loss:  0.3639993
Encoder Loss:  0.04554986  || Decoder Loss:  0.035877854 Validation Decoder Loss:  0.35574925
Encoder Loss:  0.045066606  || Decoder Loss:  0.03435077 Validation Decoder Loss:  0.34697393
Encoder Loss:  0.1809248  || Decoder Loss:  0.46299657 Validation Decoder Loss:  0.99725735
Encoder Loss:  0.19132552  || Decoder Loss:  0.495968 Validation Decoder Loss:  1.0046108
Encoder Loss:  0.19173893  || Decoder Loss:  0.49728146 Validation Decoder Loss:  0.9778809
Encoder Loss:  0.18753701  || Decoder Loss:  0.46053576 Validation Decoder Loss:  0.6530523
Encoder Loss:  0.18504305  || Decoder Loss:  0.46457398 Validation Decoder Loss:  0.38323635
Encoder Loss:  0.18365198  || Decoder Loss:  0.46235144 Validation Decoder Loss:  0.40787944
Encoder Loss:  0.19194548  || Decoder Loss:  0.49019796 Validation Decoder Loss:  1.0991879
Encoder Loss:  0.19436252  || Decoder Loss:  0.5026767 Validation Decoder Loss:  1.0004306
Encoder Loss:  0.18237896  || Decoder Loss:  0.46776402 Validation Decoder Loss:  0.3580106
Encoder Loss:  0.05747653  || Decoder Loss:  0.07358536 Validation Decoder Loss:  0.37479866
Encoder Loss:  0.04888556  || Decoder Loss:  0.046474718 Validation Decoder Loss:  0.35055023
Encoder Loss:  0.045801  || Decoder Loss:  0.036740955 Validation Decoder Loss:  0.3465984
Encoder Loss:  0.045647603  || Decoder Loss:  0.036256727 Validation Decoder Loss:  0.35039037
Encoder Loss:  0.04526124  || Decoder Loss:  0.035035383 Validation Decoder Loss:  0.3606295
Encoder Loss:  0.049005553  || Decoder Loss:  0.04684293 Validation Decoder Loss:  0.34307653
Encoder Loss:  0.04507844  || Decoder Loss:  0.034449283 Validation Decoder Loss:  0.3496752
Encoder Loss:  0.04516286  || Decoder Loss:  0.0347151 Validation Decoder Loss:  0.3558988
Encoder Loss:  0.045316815  || Decoder Loss:  0.035201784 Validation Decoder Loss:  0.35895273
Encoder Loss:  0.04526397  || Decoder Loss:  0.035033863 Validation Decoder Loss:  0.33730483
Encoder Loss:  0.045280952  || Decoder Loss:  0.035084084 Validation Decoder Loss:  0.33974063
Encoder Loss:  0.045337204  || Decoder Loss:  0.035257343 Validation Decoder Loss:  0.33890688
Encoder Loss:  0.19976342  || Decoder Loss:  0.52257556 Validation Decoder Loss:  0.99356234
Encoder Loss:  0.18989122  || Decoder Loss:  0.4914792 Validation Decoder Loss:  0.5978553
Encoder Loss:  0.06929988  || Decoder Loss:  0.11088493 Validation Decoder Loss:  0.34423754
Encoder Loss:  0.04537359  || Decoder Loss:  0.03537154 Validation Decoder Loss:  0.36089262
Encoder Loss:  0.04539153  || Decoder Loss:  0.03542968 Validation Decoder Loss:  0.35327396
Encoder Loss:  0.045364887  || Decoder Loss:  0.035348725 Validation Decoder Loss:  0.3514463
Encoder Loss:  0.28474534  || Decoder Loss:  0.7842982 Validation Decoder Loss:  1.608305
Encoder Loss:  0.22577134  || Decoder Loss:  0.60471225 Validation Decoder Loss:  0.99689233
Encoder Loss:  0.1905482  || Decoder Loss:  0.4935686 Validation Decoder Loss:  0.9762962
Encoder Loss:  0.07271873  || Decoder Loss:  0.121696666 Validation Decoder Loss:  0.44295138
Encoder Loss:  0.059008285  || Decoder Loss:  0.078426264 Validation Decoder Loss:  0.44910392
Encoder Loss:  0.059065975  || Decoder Loss:  0.078608304 Validation Decoder Loss:  0.45494393
Encoder Loss:  0.059657082  || Decoder Loss:  0.08047219 Validation Decoder Loss:  0.4570049
Encoder Loss:  0.1365184  || Decoder Loss:  0.32304677 Validation Decoder Loss:  1.3702769
Encoder Loss:  0.1741218  || Decoder Loss:  0.44172323 Validation Decoder Loss:  0.9837388
Model: siamese_net_lr_0.08802341902280114 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9837388
Model: "sequential_515"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_221 (Conv3D (None, 70, 9, 20, 1)      36        
_________________________________________________________________
dropout_606 (Dropout)        (None, 70, 9, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_222 (Conv3D (None, 74, 30, 20, 1)     31        
_________________________________________________________________
reshape_144 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 67
Trainable params: 67
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_517"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_212 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_608 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_213 (Conv2D)          (None, 2220, 20, 1)       302       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_518"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_212 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_610 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_213 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23841101  || Decoder Loss:  0.4869945 Validation Decoder Loss:  0.98143387
Encoder Loss:  0.08199152  || Decoder Loss:  0.12527844 Validation Decoder Loss:  0.4468974
Encoder Loss:  0.061778806  || Decoder Loss:  0.077884056 Validation Decoder Loss:  0.5265533
Encoder Loss:  0.079488784  || Decoder Loss:  0.119824335 Validation Decoder Loss:  0.50524306
Encoder Loss:  0.21707466  || Decoder Loss:  0.4456418 Validation Decoder Loss:  0.9987921
Encoder Loss:  0.23924719  || Decoder Loss:  0.49815127 Validation Decoder Loss:  1.0015417
Encoder Loss:  0.23885286  || Decoder Loss:  0.49722084 Validation Decoder Loss:  0.99850047
Encoder Loss:  0.23882845  || Decoder Loss:  0.49716365 Validation Decoder Loss:  1.0002278
Encoder Loss:  0.23859608  || Decoder Loss:  0.49661332 Validation Decoder Loss:  0.99639523
Encoder Loss:  0.23700339  || Decoder Loss:  0.49284035 Validation Decoder Loss:  0.99327624
Encoder Loss:  0.23814596  || Decoder Loss:  0.49554554 Validation Decoder Loss:  1.0016692
Encoder Loss:  0.23720865  || Decoder Loss:  0.493325 Validation Decoder Loss:  0.99706995
Encoder Loss:  0.23949341  || Decoder Loss:  0.49873585 Validation Decoder Loss:  1.0087748
Encoder Loss:  0.23988402  || Decoder Loss:  0.49966106 Validation Decoder Loss:  0.9976784
Encoder Loss:  0.23814857  || Decoder Loss:  0.49555108 Validation Decoder Loss:  0.99825656
Encoder Loss:  0.23898481  || Decoder Loss:  0.49753323 Validation Decoder Loss:  1.0106227
Encoder Loss:  0.2388173  || Decoder Loss:  0.49713504 Validation Decoder Loss:  0.9768494
Encoder Loss:  0.27403894  || Decoder Loss:  0.5791019 Validation Decoder Loss:  1.0102801
Encoder Loss:  0.11800385  || Decoder Loss:  0.21102671 Validation Decoder Loss:  0.4397623
Encoder Loss:  0.07012209  || Decoder Loss:  0.0976441 Validation Decoder Loss:  0.42791903
Encoder Loss:  0.06746079  || Decoder Loss:  0.091345996 Validation Decoder Loss:  0.41278937
Encoder Loss:  0.06728799  || Decoder Loss:  0.09093803 Validation Decoder Loss:  0.39927393
Encoder Loss:  0.0668647  || Decoder Loss:  0.0899356 Validation Decoder Loss:  0.39913508
Encoder Loss:  0.064860344  || Decoder Loss:  0.08518937 Validation Decoder Loss:  0.3862214
Encoder Loss:  0.06854376  || Decoder Loss:  0.09391158 Validation Decoder Loss:  0.36939386
Encoder Loss:  0.18650587  || Decoder Loss:  0.37325916 Validation Decoder Loss:  0.9945515
Encoder Loss:  0.21323346  || Decoder Loss:  0.43655384 Validation Decoder Loss:  0.98464304
Encoder Loss:  0.21027851  || Decoder Loss:  0.42955655 Validation Decoder Loss:  0.99326736
Encoder Loss:  0.23583242  || Decoder Loss:  0.49007115 Validation Decoder Loss:  0.99905324
Encoder Loss:  0.22731525  || Decoder Loss:  0.46990028 Validation Decoder Loss:  0.980306
Encoder Loss:  0.24171141  || Decoder Loss:  0.5039908 Validation Decoder Loss:  0.9912238
Encoder Loss:  0.2390871  || Decoder Loss:  0.49777672 Validation Decoder Loss:  0.9864899
Encoder Loss:  0.23868997  || Decoder Loss:  0.496835 Validation Decoder Loss:  0.98437524
Encoder Loss:  0.23952414  || Decoder Loss:  0.4988108 Validation Decoder Loss:  0.9997049
Encoder Loss:  0.23933582  || Decoder Loss:  0.49836376 Validation Decoder Loss:  0.97543436
Encoder Loss:  0.23465247  || Decoder Loss:  0.48724744 Validation Decoder Loss:  1.00351
Encoder Loss:  0.22478646  || Decoder Loss:  0.463912 Validation Decoder Loss:  0.9462955
Encoder Loss:  0.23860075  || Decoder Loss:  0.49662617 Validation Decoder Loss:  0.94309956
Encoder Loss:  0.23842089  || Decoder Loss:  0.4961993 Validation Decoder Loss:  0.9935118
Encoder Loss:  0.22008277  || Decoder Loss:  0.45275772 Validation Decoder Loss:  0.8694371
Model: siamese_net_lr_0.8971638038767366 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.8694371
Model: "sequential_519"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_224 (Conv3D (None, 68, 30, 20, 1)     31        
_________________________________________________________________
dropout_612 (Dropout)        (None, 68, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_225 (Conv3D (None, 74, 30, 20, 1)     8         
_________________________________________________________________
reshape_145 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_521"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_214 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_614 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_215 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_522"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_214 (Conv2D (None, 2400, 20, 1)       182       
_________________________________________________________________
dropout_616 (Dropout)        (None, 2400, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_215 (Conv2D (None, 2607, 20, 1)       209       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16392013  || Decoder Loss:  0.159021 Validation Decoder Loss:  0.40165251
Encoder Loss:  0.05465139  || Decoder Loss:  0.05992424 Validation Decoder Loss:  0.39246792
Encoder Loss:  0.05202586  || Decoder Loss:  0.05833799 Validation Decoder Loss:  0.39011967
Encoder Loss:  0.050984807  || Decoder Loss:  0.057208225 Validation Decoder Loss:  0.38083792
Encoder Loss:  0.050604805  || Decoder Loss:  0.05512569 Validation Decoder Loss:  0.36993504
Encoder Loss:  0.05104041  || Decoder Loss:  0.06856248 Validation Decoder Loss:  0.3873287
Encoder Loss:  0.050849706  || Decoder Loss:  0.062205967 Validation Decoder Loss:  0.38684475
Encoder Loss:  0.050785523  || Decoder Loss:  0.062305707 Validation Decoder Loss:  0.38733947
Encoder Loss:  0.050736647  || Decoder Loss:  0.062430877 Validation Decoder Loss:  0.38709652
Encoder Loss:  0.05086018  || Decoder Loss:  0.06279885 Validation Decoder Loss:  0.38977826
Encoder Loss:  0.050749943  || Decoder Loss:  0.06316535 Validation Decoder Loss:  0.38929486
Encoder Loss:  0.050776858  || Decoder Loss:  0.06339658 Validation Decoder Loss:  0.39033237
Encoder Loss:  0.050717104  || Decoder Loss:  0.06367567 Validation Decoder Loss:  0.39219818
Encoder Loss:  0.050798297  || Decoder Loss:  0.06393072 Validation Decoder Loss:  0.39361194
Encoder Loss:  0.050719123  || Decoder Loss:  0.064168274 Validation Decoder Loss:  0.39437416
Encoder Loss:  0.05470057  || Decoder Loss:  0.064996965 Validation Decoder Loss:  0.38402405
Encoder Loss:  0.053214528  || Decoder Loss:  0.06653033 Validation Decoder Loss:  0.40309832
Encoder Loss:  0.05227855  || Decoder Loss:  0.06556453 Validation Decoder Loss:  0.4010792
Encoder Loss:  0.057475146  || Decoder Loss:  0.06549719 Validation Decoder Loss:  0.40272927
Encoder Loss:  0.051160164  || Decoder Loss:  0.06546776 Validation Decoder Loss:  0.4015877
Encoder Loss:  0.053136166  || Decoder Loss:  0.06544139 Validation Decoder Loss:  0.40060645
Encoder Loss:  0.05189496  || Decoder Loss:  0.06538731 Validation Decoder Loss:  0.40103227
Encoder Loss:  0.05094583  || Decoder Loss:  0.065304585 Validation Decoder Loss:  0.4013533
Encoder Loss:  0.05076076  || Decoder Loss:  0.0652457 Validation Decoder Loss:  0.40119028
Encoder Loss:  0.05080489  || Decoder Loss:  0.065189235 Validation Decoder Loss:  0.40085286
Encoder Loss:  0.051137723  || Decoder Loss:  0.065073 Validation Decoder Loss:  0.4016134
Encoder Loss:  0.05382529  || Decoder Loss:  0.06483891 Validation Decoder Loss:  0.40100583
Encoder Loss:  0.051957663  || Decoder Loss:  0.064520605 Validation Decoder Loss:  0.40104687
Encoder Loss:  0.050869923  || Decoder Loss:  0.06403044 Validation Decoder Loss:  0.40107036
Encoder Loss:  0.050555054  || Decoder Loss:  0.06294682 Validation Decoder Loss:  0.3985656
Encoder Loss:  0.050435096  || Decoder Loss:  0.060065623 Validation Decoder Loss:  0.38003278
Encoder Loss:  0.050409425  || Decoder Loss:  0.059250746 Validation Decoder Loss:  0.3813644
Encoder Loss:  0.05040014  || Decoder Loss:  0.059260737 Validation Decoder Loss:  0.38075387
Encoder Loss:  0.05039915  || Decoder Loss:  0.059294637 Validation Decoder Loss:  0.3800149
Encoder Loss:  0.05039118  || Decoder Loss:  0.05924512 Validation Decoder Loss:  0.37922528
Encoder Loss:  0.050382007  || Decoder Loss:  0.059220657 Validation Decoder Loss:  0.37868637
Encoder Loss:  0.05037549  || Decoder Loss:  0.05916159 Validation Decoder Loss:  0.3782093
Encoder Loss:  0.05037879  || Decoder Loss:  0.059134517 Validation Decoder Loss:  0.37773663
Encoder Loss:  0.0503758  || Decoder Loss:  0.059066426 Validation Decoder Loss:  0.37700546
Encoder Loss:  0.050363146  || Decoder Loss:  0.05899208 Validation Decoder Loss:  0.37662274
Model: siamese_net_lr_0.31397397493028595 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37662274
Model: "sequential_523"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_227 (Conv3D (None, 68, 10, 20, 1)     31        
_________________________________________________________________
dropout_618 (Dropout)        (None, 68, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_228 (Conv3D (None, 74, 30, 20, 1)     22        
_________________________________________________________________
reshape_146 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 53
Trainable params: 53
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_525"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_216 (Conv2D)          (None, 2540, 20, 1)       69        
_________________________________________________________________
dropout_620 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_217 (Conv2D)          (None, 2220, 20, 1)       322       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_526"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_216 (Conv2D (None, 2470, 20, 1)       252       
_________________________________________________________________
dropout_622 (Dropout)        (None, 2470, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_217 (Conv2D (None, 2607, 20, 1)       139       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.2518161  || Decoder Loss:  0.47994187 Validation Decoder Loss:  0.6679657
Encoder Loss:  0.12703234  || Decoder Loss:  0.23005947 Validation Decoder Loss:  0.35971993
Encoder Loss:  0.10703918  || Decoder Loss:  0.18339972 Validation Decoder Loss:  0.3030166
Encoder Loss:  0.083323754  || Decoder Loss:  0.12787591 Validation Decoder Loss:  0.2837471
Encoder Loss:  0.07970719  || Decoder Loss:  0.11946125 Validation Decoder Loss:  0.28232515
Encoder Loss:  0.07711231  || Decoder Loss:  0.11340155 Validation Decoder Loss:  0.43716034
Encoder Loss:  0.08576526  || Decoder Loss:  0.1336788 Validation Decoder Loss:  0.28387314
Encoder Loss:  0.09302906  || Decoder Loss:  0.15069377 Validation Decoder Loss:  0.2943899
Encoder Loss:  0.103559166  || Decoder Loss:  0.17537579 Validation Decoder Loss:  0.29297525
Encoder Loss:  0.10312639  || Decoder Loss:  0.17436612 Validation Decoder Loss:  0.2927854
Encoder Loss:  0.10251674  || Decoder Loss:  0.17294012 Validation Decoder Loss:  0.29160172
Encoder Loss:  0.069640115  || Decoder Loss:  0.09597182 Validation Decoder Loss:  0.36850405
Encoder Loss:  0.043660715  || Decoder Loss:  0.03514894 Validation Decoder Loss:  0.3517667
Encoder Loss:  0.043398686  || Decoder Loss:  0.034534838 Validation Decoder Loss:  0.350645
Encoder Loss:  0.04330814  || Decoder Loss:  0.034322485 Validation Decoder Loss:  0.35024512
Encoder Loss:  0.043240033  || Decoder Loss:  0.03416539 Validation Decoder Loss:  0.3503015
Encoder Loss:  0.043187212  || Decoder Loss:  0.034038324 Validation Decoder Loss:  0.35017025
Encoder Loss:  0.04314136  || Decoder Loss:  0.0339323 Validation Decoder Loss:  0.3500161
Encoder Loss:  0.043107685  || Decoder Loss:  0.033852566 Validation Decoder Loss:  0.3500679
Encoder Loss:  0.043077882  || Decoder Loss:  0.03378487 Validation Decoder Loss:  0.34986606
Encoder Loss:  0.043033548  || Decoder Loss:  0.033678662 Validation Decoder Loss:  0.34982285
Encoder Loss:  0.042999502  || Decoder Loss:  0.033602513 Validation Decoder Loss:  0.35044658
Encoder Loss:  0.04295993  || Decoder Loss:  0.033507094 Validation Decoder Loss:  0.3501789
Encoder Loss:  0.042906962  || Decoder Loss:  0.03338442 Validation Decoder Loss:  0.35003757
Encoder Loss:  0.04285994  || Decoder Loss:  0.03327756 Validation Decoder Loss:  0.35101223
Encoder Loss:  0.042835418  || Decoder Loss:  0.03322023 Validation Decoder Loss:  0.3526341
Encoder Loss:  0.04280186  || Decoder Loss:  0.03314186 Validation Decoder Loss:  0.35437143
Encoder Loss:  0.042765703  || Decoder Loss:  0.033051394 Validation Decoder Loss:  0.35496846
Encoder Loss:  0.042703986  || Decoder Loss:  0.03290935 Validation Decoder Loss:  0.35712606
Encoder Loss:  0.04265406  || Decoder Loss:  0.032797962 Validation Decoder Loss:  0.35374954
Encoder Loss:  0.04261706  || Decoder Loss:  0.032702502 Validation Decoder Loss:  0.3542297
Encoder Loss:  0.0425632  || Decoder Loss:  0.03258353 Validation Decoder Loss:  0.35148096
Encoder Loss:  0.04255538  || Decoder Loss:  0.032558635 Validation Decoder Loss:  0.34899575
Encoder Loss:  0.042505354  || Decoder Loss:  0.032449674 Validation Decoder Loss:  0.34832832
Encoder Loss:  0.042497467  || Decoder Loss:  0.03242219 Validation Decoder Loss:  0.3484055
Encoder Loss:  0.042503446  || Decoder Loss:  0.03243523 Validation Decoder Loss:  0.35109302
Encoder Loss:  0.042541247  || Decoder Loss:  0.032527894 Validation Decoder Loss:  0.3483907
Encoder Loss:  0.04259023  || Decoder Loss:  0.032645933 Validation Decoder Loss:  0.34749037
Encoder Loss:  0.18274137  || Decoder Loss:  0.36076638 Validation Decoder Loss:  0.9943449
Encoder Loss:  0.24083664  || Decoder Loss:  0.49677563 Validation Decoder Loss:  0.9943538
Model: siamese_net_lr_0.5981540042377667 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9943538
Model: "sequential_527"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_230 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_624 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_231 (Conv3D (None, 74, 30, 20, 1)     163       
_________________________________________________________________
reshape_147 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 167
Trainable params: 167
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_529"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_218 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_626 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_219 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_530"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_218 (Conv2D (None, 2520, 20, 1)       302       
_________________________________________________________________
dropout_628 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_219 (Conv2D (None, 2607, 20, 1)       89        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.27017537  || Decoder Loss:  0.2773622 Validation Decoder Loss:  0.3643633
Encoder Loss:  0.4363217  || Decoder Loss:  0.5050383 Validation Decoder Loss:  1.6526561
Encoder Loss:  0.43327102  || Decoder Loss:  0.50260717 Validation Decoder Loss:  0.4015934
Encoder Loss:  0.427001  || Decoder Loss:  0.49560195 Validation Decoder Loss:  0.42243367
Encoder Loss:  0.37926242  || Decoder Loss:  0.4389053 Validation Decoder Loss:  1.6711068
Encoder Loss:  0.42966798  || Decoder Loss:  0.49870056 Validation Decoder Loss:  1.0790356
Encoder Loss:  0.42988834  || Decoder Loss:  0.49905628 Validation Decoder Loss:  0.9943217
Encoder Loss:  0.42752418  || Decoder Loss:  0.4962517 Validation Decoder Loss:  1.0236369
Encoder Loss:  0.4282797  || Decoder Loss:  0.49741733 Validation Decoder Loss:  0.9955274
Encoder Loss:  0.4257172  || Decoder Loss:  0.49427754 Validation Decoder Loss:  1.016449
Encoder Loss:  0.42343816  || Decoder Loss:  0.49151465 Validation Decoder Loss:  1.0109992
Encoder Loss:  0.42291215  || Decoder Loss:  0.49105966 Validation Decoder Loss:  1.0123452
Encoder Loss:  0.42139274  || Decoder Loss:  0.48988274 Validation Decoder Loss:  1.0118853
Encoder Loss:  0.42097053  || Decoder Loss:  0.48960534 Validation Decoder Loss:  1.011421
Encoder Loss:  0.42064607  || Decoder Loss:  0.4892067 Validation Decoder Loss:  1.0101467
Encoder Loss:  0.42006966  || Decoder Loss:  0.4885277 Validation Decoder Loss:  1.0044057
Encoder Loss:  0.42338058  || Decoder Loss:  0.49244556 Validation Decoder Loss:  0.9998528
Encoder Loss:  0.4273197  || Decoder Loss:  0.49704024 Validation Decoder Loss:  0.9923667
Encoder Loss:  0.43010178  || Decoder Loss:  0.50042254 Validation Decoder Loss:  0.9928769
Encoder Loss:  0.42679608  || Decoder Loss:  0.49651328 Validation Decoder Loss:  0.9963188
Encoder Loss:  0.42342594  || Decoder Loss:  0.49252006 Validation Decoder Loss:  1.0064881
Encoder Loss:  0.41296738  || Decoder Loss:  0.48012707 Validation Decoder Loss:  1.2417865
Encoder Loss:  0.40201318  || Decoder Loss:  0.46714634 Validation Decoder Loss:  1.2611
Encoder Loss:  0.42321345  || Decoder Loss:  0.49226928 Validation Decoder Loss:  1.0004246
Encoder Loss:  0.4264954  || Decoder Loss:  0.49615872 Validation Decoder Loss:  1.0040312
Encoder Loss:  0.40803257  || Decoder Loss:  0.47427955 Validation Decoder Loss:  1.3359917
Encoder Loss:  0.39218783  || Decoder Loss:  0.45550302 Validation Decoder Loss:  1.0491602
Encoder Loss:  0.40982082  || Decoder Loss:  0.47639838 Validation Decoder Loss:  1.0055645
Encoder Loss:  0.42553973  || Decoder Loss:  0.49502563 Validation Decoder Loss:  1.0148854
Encoder Loss:  0.425007  || Decoder Loss:  0.49439496 Validation Decoder Loss:  1.0072635
Encoder Loss:  0.42236918  || Decoder Loss:  0.49126792 Validation Decoder Loss:  1.0090379
Encoder Loss:  0.4218976  || Decoder Loss:  0.49070996 Validation Decoder Loss:  1.0191628
Encoder Loss:  0.41748035  || Decoder Loss:  0.48539758 Validation Decoder Loss:  1.0022969
Encoder Loss:  0.42747787  || Decoder Loss:  0.49732247 Validation Decoder Loss:  1.003927
Encoder Loss:  0.42778286  || Decoder Loss:  0.4976838 Validation Decoder Loss:  1.0001348
Encoder Loss:  0.42782143  || Decoder Loss:  0.49773 Validation Decoder Loss:  0.9989525
Encoder Loss:  0.4276668  || Decoder Loss:  0.4975465 Validation Decoder Loss:  0.9991878
Encoder Loss:  0.42732236  || Decoder Loss:  0.49713886 Validation Decoder Loss:  0.99989206
Encoder Loss:  0.4263582  || Decoder Loss:  0.49599564 Validation Decoder Loss:  0.99771595
Encoder Loss:  0.42505524  || Decoder Loss:  0.49445143 Validation Decoder Loss:  1.0003049
Model: siamese_net_lr_0.9442597757698687 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0003049
Model: "sequential_532"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_220 (Conv2D)          (None, 2520, 20, 1)       89        
_________________________________________________________________
dropout_630 (Dropout)        (None, 2520, 20, 1)       0         
_________________________________________________________________
conv2d_221 (Conv2D)          (None, 2220, 20, 1)       302       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_533"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_220 (Conv2D (None, 2370, 20, 1)       152       
_________________________________________________________________
dropout_632 (Dropout)        (None, 2370, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_221 (Conv2D (None, 2607, 20, 1)       239       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_534"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_233 (Conv3D (None, 66, 5, 20, 1)      4         
_________________________________________________________________
dropout_634 (Dropout)        (None, 66, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_234 (Conv3D (None, 74, 30, 20, 1)     235       
_________________________________________________________________
reshape_148 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 239
Trainable params: 239
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_536"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_222 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_636 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_223 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_537"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_222 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_638 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_223 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1168565  || Decoder Loss:  0.51220757 Validation Decoder Loss:  0.97937524
Encoder Loss:  0.09592715  || Decoder Loss:  0.5029198 Validation Decoder Loss:  1.0121775
Encoder Loss:  0.095228165  || Decoder Loss:  0.49765432 Validation Decoder Loss:  1.0185608
Encoder Loss:  0.092633955  || Decoder Loss:  0.49549785 Validation Decoder Loss:  1.0138502
Encoder Loss:  0.0923434  || Decoder Loss:  0.4954113 Validation Decoder Loss:  1.0170631
Encoder Loss:  0.08873173  || Decoder Loss:  0.49495795 Validation Decoder Loss:  1.0164524
Encoder Loss:  0.087675534  || Decoder Loss:  0.49489135 Validation Decoder Loss:  1.016315
Encoder Loss:  0.08958272  || Decoder Loss:  0.4947935 Validation Decoder Loss:  1.0186248
Encoder Loss:  0.09177516  || Decoder Loss:  0.4947897 Validation Decoder Loss:  1.0231836
Encoder Loss:  0.08999229  || Decoder Loss:  0.49499616 Validation Decoder Loss:  1.0143515
Encoder Loss:  0.09148267  || Decoder Loss:  0.49481288 Validation Decoder Loss:  1.0155067
Encoder Loss:  0.09054187  || Decoder Loss:  0.49443915 Validation Decoder Loss:  1.0161066
Encoder Loss:  0.08904048  || Decoder Loss:  0.49401784 Validation Decoder Loss:  1.010813
Encoder Loss:  0.08964062  || Decoder Loss:  0.49322522 Validation Decoder Loss:  1.0030079
Encoder Loss:  0.088873  || Decoder Loss:  0.49209332 Validation Decoder Loss:  1.0030668
Encoder Loss:  0.08871614  || Decoder Loss:  0.49155045 Validation Decoder Loss:  1.0027497
Encoder Loss:  0.087960996  || Decoder Loss:  0.49126938 Validation Decoder Loss:  1.002636
Encoder Loss:  0.08750036  || Decoder Loss:  0.49085647 Validation Decoder Loss:  1.0023291
Encoder Loss:  0.08738941  || Decoder Loss:  0.4898021 Validation Decoder Loss:  1.0032973
Encoder Loss:  0.087757036  || Decoder Loss:  0.48913217 Validation Decoder Loss:  1.0038087
Encoder Loss:  0.088380754  || Decoder Loss:  0.4897464 Validation Decoder Loss:  1.0146903
Encoder Loss:  0.08904069  || Decoder Loss:  0.49397293 Validation Decoder Loss:  1.0112504
Encoder Loss:  0.09014256  || Decoder Loss:  0.49188727 Validation Decoder Loss:  1.0030099
Encoder Loss:  0.087384835  || Decoder Loss:  0.48959482 Validation Decoder Loss:  1.004616
Encoder Loss:  0.08860905  || Decoder Loss:  0.48976365 Validation Decoder Loss:  0.98847175
Encoder Loss:  0.08983157  || Decoder Loss:  0.5007998 Validation Decoder Loss:  1.0196266
Encoder Loss:  0.08936208  || Decoder Loss:  0.49559394 Validation Decoder Loss:  1.0190501
Encoder Loss:  0.092649244  || Decoder Loss:  0.49533424 Validation Decoder Loss:  1.0179181
Encoder Loss:  0.08768548  || Decoder Loss:  0.4950814 Validation Decoder Loss:  1.016165
Encoder Loss:  0.08746724  || Decoder Loss:  0.49497613 Validation Decoder Loss:  1.0157208
Encoder Loss:  0.08652546  || Decoder Loss:  0.49478295 Validation Decoder Loss:  1.0159274
Encoder Loss:  0.08632742  || Decoder Loss:  0.49479198 Validation Decoder Loss:  1.016871
Encoder Loss:  0.08788545  || Decoder Loss:  0.49489278 Validation Decoder Loss:  1.0167285
Encoder Loss:  0.0878225  || Decoder Loss:  0.49469125 Validation Decoder Loss:  1.0165589
Encoder Loss:  0.08876049  || Decoder Loss:  0.49461156 Validation Decoder Loss:  1.0146012
Encoder Loss:  0.08774256  || Decoder Loss:  0.49443302 Validation Decoder Loss:  1.0162823
Encoder Loss:  0.087823726  || Decoder Loss:  0.49432772 Validation Decoder Loss:  1.0149426
Encoder Loss:  0.08674205  || Decoder Loss:  0.49411675 Validation Decoder Loss:  1.0149007
Encoder Loss:  0.0871345  || Decoder Loss:  0.49388215 Validation Decoder Loss:  1.0140576
Encoder Loss:  0.08749397  || Decoder Loss:  0.49324596 Validation Decoder Loss:  1.0102937
Model: siamese_net_lr_0.6741960025332211 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0102937
Model: "sequential_539"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_224 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_640 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_225 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_540"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_224 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_642 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_225 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_541"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_236 (Conv3D (None, 70, 29, 20, 1)     148       
_________________________________________________________________
dropout_644 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_237 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_149 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_543"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_226 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_646 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_227 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_544"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_226 (Conv2D (None, 2400, 20, 1)       182       
_________________________________________________________________
dropout_648 (Dropout)        (None, 2400, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_227 (Conv2D (None, 2607, 20, 1)       209       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23620035  || Decoder Loss:  0.32157 Validation Decoder Loss:  0.9318756
Encoder Loss:  0.22505756  || Decoder Loss:  0.48648512 Validation Decoder Loss:  1.0838966
Encoder Loss:  0.24123678  || Decoder Loss:  0.5031638 Validation Decoder Loss:  0.988937
Encoder Loss:  0.22390026  || Decoder Loss:  0.48754418 Validation Decoder Loss:  0.9438061
Encoder Loss:  0.21597824  || Decoder Loss:  0.46784937 Validation Decoder Loss:  0.91522396
Encoder Loss:  0.22061571  || Decoder Loss:  0.47822678 Validation Decoder Loss:  1.0487902
Encoder Loss:  0.21645504  || Decoder Loss:  0.46895844 Validation Decoder Loss:  0.92230093
Encoder Loss:  0.21499321  || Decoder Loss:  0.46538848 Validation Decoder Loss:  0.92610276
Encoder Loss:  0.22480454  || Decoder Loss:  0.48826858 Validation Decoder Loss:  0.9501938
Encoder Loss:  0.22342859  || Decoder Loss:  0.48689613 Validation Decoder Loss:  0.9331744
Encoder Loss:  0.21990733  || Decoder Loss:  0.47791675 Validation Decoder Loss:  0.93763006
Encoder Loss:  0.21837008  || Decoder Loss:  0.47277057 Validation Decoder Loss:  1.0804584
Encoder Loss:  0.2291464  || Decoder Loss:  0.5007535 Validation Decoder Loss:  1.0586821
Encoder Loss:  0.22109985  || Decoder Loss:  0.4813833 Validation Decoder Loss:  1.0173541
Encoder Loss:  0.21663421  || Decoder Loss:  0.46986347 Validation Decoder Loss:  0.9806155
Encoder Loss:  0.21307503  || Decoder Loss:  0.46110326 Validation Decoder Loss:  0.94232494
Encoder Loss:  0.20935804  || Decoder Loss:  0.45138988 Validation Decoder Loss:  0.92309463
Encoder Loss:  0.21481712  || Decoder Loss:  0.46531418 Validation Decoder Loss:  0.9317619
Encoder Loss:  0.22257547  || Decoder Loss:  0.4836783 Validation Decoder Loss:  0.92258364
Encoder Loss:  0.2111635  || Decoder Loss:  0.45479655 Validation Decoder Loss:  0.93655795
Encoder Loss:  0.22132118  || Decoder Loss:  0.48204356 Validation Decoder Loss:  0.94531655
Encoder Loss:  0.2214326  || Decoder Loss:  0.48228967 Validation Decoder Loss:  1.0248637
Encoder Loss:  0.22626625  || Decoder Loss:  0.49427792 Validation Decoder Loss:  0.998192
Encoder Loss:  0.2229185  || Decoder Loss:  0.48594502 Validation Decoder Loss:  0.9910297
Encoder Loss:  0.22036591  || Decoder Loss:  0.4798149 Validation Decoder Loss:  0.98120874
Encoder Loss:  0.21558265  || Decoder Loss:  0.46707916 Validation Decoder Loss:  0.95376676
Encoder Loss:  0.20922014  || Decoder Loss:  0.4509946 Validation Decoder Loss:  1.0756907
Encoder Loss:  0.22397839  || Decoder Loss:  0.4876236 Validation Decoder Loss:  0.9710591
Encoder Loss:  0.20215817  || Decoder Loss:  0.43327144 Validation Decoder Loss:  0.9029083
Encoder Loss:  0.21541949  || Decoder Loss:  0.46716517 Validation Decoder Loss:  1.0242629
Encoder Loss:  0.22506766  || Decoder Loss:  0.49161857 Validation Decoder Loss:  0.99230266
Encoder Loss:  0.21603516  || Decoder Loss:  0.4687594 Validation Decoder Loss:  1.007097
Encoder Loss:  0.2149541  || Decoder Loss:  0.46596718 Validation Decoder Loss:  1.0040126
Encoder Loss:  0.21432796  || Decoder Loss:  0.46354207 Validation Decoder Loss:  1.0031223
Encoder Loss:  0.204032  || Decoder Loss:  0.4385351 Validation Decoder Loss:  0.91203195
Encoder Loss:  0.20724839  || Decoder Loss:  0.44630545 Validation Decoder Loss:  1.0530643
Encoder Loss:  0.19973825  || Decoder Loss:  0.42531174 Validation Decoder Loss:  0.7299714
Encoder Loss:  0.21493097  || Decoder Loss:  0.46540043 Validation Decoder Loss:  0.98528796
Encoder Loss:  0.2151996  || Decoder Loss:  0.4668172 Validation Decoder Loss:  0.969509
Encoder Loss:  0.21257651  || Decoder Loss:  0.460372 Validation Decoder Loss:  0.95312315
Model: siamese_net_lr_0.7084724821347108 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.95312315
Model: "sequential_545"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_239 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_650 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_240 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_150 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_547"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_228 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_652 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_548"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_228 (Conv2D (None, 2570, 20, 1)       352       
_________________________________________________________________
dropout_654 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_229 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.35714275  || Decoder Loss:  0.4222863 Validation Decoder Loss:  0.9973552
Encoder Loss:  0.3941426  || Decoder Loss:  0.4968253 Validation Decoder Loss:  0.99256825
Encoder Loss:  0.39411676  || Decoder Loss:  0.4967019 Validation Decoder Loss:  0.99391377
Encoder Loss:  0.39262292  || Decoder Loss:  0.49467155 Validation Decoder Loss:  0.99770445
Encoder Loss:  0.38885733  || Decoder Loss:  0.4899464 Validation Decoder Loss:  1.0315696
Encoder Loss:  0.3873377  || Decoder Loss:  0.48793885 Validation Decoder Loss:  1.0040221
Encoder Loss:  0.39116046  || Decoder Loss:  0.49313012 Validation Decoder Loss:  0.93796873
Encoder Loss:  0.3830332  || Decoder Loss:  0.48240662 Validation Decoder Loss:  1.0465808
Encoder Loss:  0.3862138  || Decoder Loss:  0.4867093 Validation Decoder Loss:  1.0275154
Encoder Loss:  0.3828543  || Decoder Loss:  0.48238593 Validation Decoder Loss:  1.0660615
Encoder Loss:  0.38500336  || Decoder Loss:  0.48520604 Validation Decoder Loss:  0.9006432
Encoder Loss:  0.37909192  || Decoder Loss:  0.47712052 Validation Decoder Loss:  1.0089071
Encoder Loss:  0.3897047  || Decoder Loss:  0.4913372 Validation Decoder Loss:  1.0806655
Encoder Loss:  0.38815048  || Decoder Loss:  0.48922113 Validation Decoder Loss:  1.0276058
Encoder Loss:  0.38120747  || Decoder Loss:  0.48036325 Validation Decoder Loss:  1.0199878
Encoder Loss:  0.38086808  || Decoder Loss:  0.4799256 Validation Decoder Loss:  1.0269644
Encoder Loss:  0.3890102  || Decoder Loss:  0.49045697 Validation Decoder Loss:  1.0327029
Encoder Loss:  0.3847401  || Decoder Loss:  0.48488274 Validation Decoder Loss:  0.8849752
Encoder Loss:  0.3831085  || Decoder Loss:  0.4825878 Validation Decoder Loss:  0.9769096
Encoder Loss:  0.37860096  || Decoder Loss:  0.4768757 Validation Decoder Loss:  1.0835725
Encoder Loss:  0.38170165  || Decoder Loss:  0.48102218 Validation Decoder Loss:  0.83016807
Encoder Loss:  0.3751345  || Decoder Loss:  0.4724208 Validation Decoder Loss:  0.9931681
Encoder Loss:  0.39642292  || Decoder Loss:  0.5001871 Validation Decoder Loss:  0.99970895
Encoder Loss:  0.39047375  || Decoder Loss:  0.4924568 Validation Decoder Loss:  1.0217249
Encoder Loss:  0.3269159  || Decoder Loss:  0.40986192 Validation Decoder Loss:  0.35812533
Encoder Loss:  0.058692575  || Decoder Loss:  0.061295584 Validation Decoder Loss:  0.346965
Encoder Loss:  0.04590838  || Decoder Loss:  0.04468245 Validation Decoder Loss:  0.33335626
Encoder Loss:  0.043791275  || Decoder Loss:  0.041931 Validation Decoder Loss:  0.34664667
Encoder Loss:  0.04218021  || Decoder Loss:  0.039837077 Validation Decoder Loss:  0.3366013
Encoder Loss:  0.043136466  || Decoder Loss:  0.041079953 Validation Decoder Loss:  0.3336718
Encoder Loss:  0.15524216  || Decoder Loss:  0.18516575 Validation Decoder Loss:  0.33474106
Encoder Loss:  0.05379385  || Decoder Loss:  0.054898858 Validation Decoder Loss:  0.33562756
Encoder Loss:  0.21324159  || Decoder Loss:  0.26208997 Validation Decoder Loss:  0.33782727
Encoder Loss:  0.04530632  || Decoder Loss:  0.04386194 Validation Decoder Loss:  0.33096546
Encoder Loss:  0.043491106  || Decoder Loss:  0.04153315 Validation Decoder Loss:  0.33268377
Encoder Loss:  0.04420405  || Decoder Loss:  0.042467136 Validation Decoder Loss:  0.33714765
Encoder Loss:  0.045431457  || Decoder Loss:  0.044062287 Validation Decoder Loss:  0.3345372
Encoder Loss:  0.04435121  || Decoder Loss:  0.04265869 Validation Decoder Loss:  0.33474284
Encoder Loss:  0.044833902  || Decoder Loss:  0.04328609 Validation Decoder Loss:  0.3409571
Encoder Loss:  0.0429242  || Decoder Loss:  0.040804483 Validation Decoder Loss:  0.33960912
Model: siamese_net_lr_0.6523276996646787 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3396091
Model: "sequential_549"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_242 (Conv3D (None, 67, 30, 20, 1)     41        
_________________________________________________________________
dropout_656 (Dropout)        (None, 67, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_243 (Conv3D (None, 74, 30, 20, 1)     9         
_________________________________________________________________
reshape_151 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_551"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_230 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_658 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_231 (Conv2D)          (None, 2220, 20, 1)       372       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_552"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_230 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_660 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_231 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.20731597  || Decoder Loss:  0.12054424 Validation Decoder Loss:  0.4399987
Encoder Loss:  0.3482422  || Decoder Loss:  0.47685584 Validation Decoder Loss:  1.0065696
Encoder Loss:  0.35069907  || Decoder Loss:  0.48817348 Validation Decoder Loss:  0.93731785
Encoder Loss:  0.34795487  || Decoder Loss:  0.4840017 Validation Decoder Loss:  0.923632
Encoder Loss:  0.3429008  || Decoder Loss:  0.4749877 Validation Decoder Loss:  0.88478386
Encoder Loss:  0.34547478  || Decoder Loss:  0.48053247 Validation Decoder Loss:  1.0232098
Encoder Loss:  0.3534692  || Decoder Loss:  0.49223942 Validation Decoder Loss:  1.0566669
Encoder Loss:  0.3506664  || Decoder Loss:  0.48745158 Validation Decoder Loss:  1.0885873
Encoder Loss:  0.33839667  || Decoder Loss:  0.47003415 Validation Decoder Loss:  0.9808528
Encoder Loss:  0.3528  || Decoder Loss:  0.491815 Validation Decoder Loss:  0.9148368
Encoder Loss:  0.33775845  || Decoder Loss:  0.4688698 Validation Decoder Loss:  1.043773
Encoder Loss:  0.34343538  || Decoder Loss:  0.47783908 Validation Decoder Loss:  1.1360571
Encoder Loss:  0.35314882  || Decoder Loss:  0.4909528 Validation Decoder Loss:  0.97472185
Encoder Loss:  0.3392891  || Decoder Loss:  0.47192067 Validation Decoder Loss:  1.0335596
Encoder Loss:  0.3536702  || Decoder Loss:  0.49292687 Validation Decoder Loss:  1.0365063
Encoder Loss:  0.3485583  || Decoder Loss:  0.4856179 Validation Decoder Loss:  0.9988785
Encoder Loss:  0.31335914  || Decoder Loss:  0.43383145 Validation Decoder Loss:  0.9289702
Encoder Loss:  0.334649  || Decoder Loss:  0.46536514 Validation Decoder Loss:  0.89932865
Encoder Loss:  0.32578537  || Decoder Loss:  0.45187375 Validation Decoder Loss:  0.9718522
Encoder Loss:  0.30776614  || Decoder Loss:  0.42591378 Validation Decoder Loss:  0.4782719
Encoder Loss:  0.1704705  || Decoder Loss:  0.225077 Validation Decoder Loss:  0.5246937
Encoder Loss:  0.065018676  || Decoder Loss:  0.07146514 Validation Decoder Loss:  0.65675145
Encoder Loss:  0.05551408  || Decoder Loss:  0.057327453 Validation Decoder Loss:  0.3561294
Encoder Loss:  0.050351992  || Decoder Loss:  0.050069008 Validation Decoder Loss:  0.36318487
Encoder Loss:  0.050221566  || Decoder Loss:  0.049977098 Validation Decoder Loss:  0.34852952
Encoder Loss:  0.05118673  || Decoder Loss:  0.050979406 Validation Decoder Loss:  0.35351253
Encoder Loss:  0.051591482  || Decoder Loss:  0.05161272 Validation Decoder Loss:  0.3463747
Encoder Loss:  0.05995159  || Decoder Loss:  0.06372749 Validation Decoder Loss:  0.41258305
Encoder Loss:  0.051792942  || Decoder Loss:  0.05209547 Validation Decoder Loss:  0.34552348
Encoder Loss:  0.08275509  || Decoder Loss:  0.096924946 Validation Decoder Loss:  0.39320168
Encoder Loss:  0.06101782  || Decoder Loss:  0.06566566 Validation Decoder Loss:  0.37821192
Encoder Loss:  0.06606353  || Decoder Loss:  0.073148444 Validation Decoder Loss:  0.35189128
Encoder Loss:  0.04839933  || Decoder Loss:  0.04723895 Validation Decoder Loss:  0.3473313
Encoder Loss:  0.048611946  || Decoder Loss:  0.047592558 Validation Decoder Loss:  0.34666398
Encoder Loss:  0.0500277  || Decoder Loss:  0.049531784 Validation Decoder Loss:  0.38419732
Encoder Loss:  0.050600898  || Decoder Loss:  0.05050875 Validation Decoder Loss:  0.35992435
Encoder Loss:  0.0649077  || Decoder Loss:  0.07120192 Validation Decoder Loss:  0.41727203
Encoder Loss:  0.050127454  || Decoder Loss:  0.049858168 Validation Decoder Loss:  0.3499843
Encoder Loss:  0.050643396  || Decoder Loss:  0.050372515 Validation Decoder Loss:  0.35027474
Encoder Loss:  0.091465704  || Decoder Loss:  0.11007248 Validation Decoder Loss:  0.38674408
Model: siamese_net_lr_0.5266502518000189 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38674408
Model: "sequential_553"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_245 (Conv3D (None, 70, 29, 20, 1)     176       
_________________________________________________________________
dropout_662 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_246 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_152 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 187
Trainable params: 187
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_555"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_232 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_664 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_233 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_556"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_232 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_666 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_233 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.22980942  || Decoder Loss:  0.35426915 Validation Decoder Loss:  0.36441624
Encoder Loss:  0.0647301  || Decoder Loss:  0.0659786 Validation Decoder Loss:  0.34586975
Encoder Loss:  0.047819518  || Decoder Loss:  0.041247085 Validation Decoder Loss:  0.3462245
Encoder Loss:  0.046437796  || Decoder Loss:  0.040562663 Validation Decoder Loss:  0.34629673
Encoder Loss:  0.045852885  || Decoder Loss:  0.039697915 Validation Decoder Loss:  0.3460216
Encoder Loss:  0.04566613  || Decoder Loss:  0.04004526 Validation Decoder Loss:  0.34569418
Encoder Loss:  0.04524948  || Decoder Loss:  0.039255947 Validation Decoder Loss:  0.34400794
Encoder Loss:  0.045173913  || Decoder Loss:  0.039181147 Validation Decoder Loss:  0.34088373
Encoder Loss:  0.045498673  || Decoder Loss:  0.039926775 Validation Decoder Loss:  0.3454326
Encoder Loss:  0.044716083  || Decoder Loss:  0.038222846 Validation Decoder Loss:  0.33799365
Encoder Loss:  0.045677662  || Decoder Loss:  0.04036422 Validation Decoder Loss:  0.34893575
Encoder Loss:  0.04598785  || Decoder Loss:  0.041026264 Validation Decoder Loss:  0.3474524
Encoder Loss:  0.045574438  || Decoder Loss:  0.040124778 Validation Decoder Loss:  0.34581882
Encoder Loss:  0.045045342  || Decoder Loss:  0.03896541 Validation Decoder Loss:  0.34412393
Encoder Loss:  0.045600172  || Decoder Loss:  0.040201202 Validation Decoder Loss:  0.34989288
Encoder Loss:  0.04628026  || Decoder Loss:  0.041643806 Validation Decoder Loss:  0.34940708
Encoder Loss:  0.046085693  || Decoder Loss:  0.04126016 Validation Decoder Loss:  0.3488902
Encoder Loss:  0.045905866  || Decoder Loss:  0.04088031 Validation Decoder Loss:  0.3479156
Encoder Loss:  0.045714565  || Decoder Loss:  0.040462032 Validation Decoder Loss:  0.34754908
Encoder Loss:  0.04562868  || Decoder Loss:  0.040282022 Validation Decoder Loss:  0.34695196
Encoder Loss:  0.04528661  || Decoder Loss:  0.039487332 Validation Decoder Loss:  0.34656242
Encoder Loss:  0.045431737  || Decoder Loss:  0.039791945 Validation Decoder Loss:  0.34641027
Encoder Loss:  0.045055605  || Decoder Loss:  0.038976785 Validation Decoder Loss:  0.34604567
Encoder Loss:  0.04478349  || Decoder Loss:  0.03840165 Validation Decoder Loss:  0.34112045
Encoder Loss:  0.045846254  || Decoder Loss:  0.040752433 Validation Decoder Loss:  0.3490201
Encoder Loss:  0.045906037  || Decoder Loss:  0.040845264 Validation Decoder Loss:  0.34815884
Encoder Loss:  0.04562191  || Decoder Loss:  0.040268164 Validation Decoder Loss:  0.34739172
Encoder Loss:  0.04540295  || Decoder Loss:  0.039778575 Validation Decoder Loss:  0.346209
Encoder Loss:  0.045110885  || Decoder Loss:  0.03913342 Validation Decoder Loss:  0.34559095
Encoder Loss:  0.044864688  || Decoder Loss:  0.038584318 Validation Decoder Loss:  0.3445716
Encoder Loss:  0.045132894  || Decoder Loss:  0.039122798 Validation Decoder Loss:  0.34780288
Encoder Loss:  0.045214925  || Decoder Loss:  0.039368622 Validation Decoder Loss:  0.34588987
Encoder Loss:  0.050070718  || Decoder Loss:  0.04707916 Validation Decoder Loss:  0.34455687
Encoder Loss:  0.045550868  || Decoder Loss:  0.03996044 Validation Decoder Loss:  0.34893042
Encoder Loss:  0.04557227  || Decoder Loss:  0.040164698 Validation Decoder Loss:  0.34793422
Encoder Loss:  0.045412965  || Decoder Loss:  0.039812513 Validation Decoder Loss:  0.34712
Encoder Loss:  0.04525687  || Decoder Loss:  0.039463896 Validation Decoder Loss:  0.34629178
Encoder Loss:  0.045075122  || Decoder Loss:  0.03906473 Validation Decoder Loss:  0.3454592
Encoder Loss:  0.044738296  || Decoder Loss:  0.038320366 Validation Decoder Loss:  0.34383827
Encoder Loss:  0.04728041  || Decoder Loss:  0.043944344 Validation Decoder Loss:  0.34911832
Model: siamese_net_lr_0.0838547182658336 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34911832
Model: "sequential_557"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_248 (Conv3D (None, 70, 20, 20, 1)     85        
_________________________________________________________________
dropout_668 (Dropout)        (None, 70, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_249 (Conv3D (None, 74, 30, 20, 1)     56        
_________________________________________________________________
reshape_153 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 141
Trainable params: 141
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_559"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_234 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_670 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_235 (Conv2D)          (None, 2220, 20, 1)       372       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_560"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_234 (Conv2D (None, 2260, 20, 1)       42        
_________________________________________________________________
dropout_672 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_235 (Conv2D (None, 2607, 20, 1)       349       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23529811  || Decoder Loss:  0.2496453 Validation Decoder Loss:  0.37146133
Encoder Loss:  0.13392712  || Decoder Loss:  0.16909465 Validation Decoder Loss:  0.38006437
Encoder Loss:  0.057693053  || Decoder Loss:  0.060749773 Validation Decoder Loss:  0.35528398
Encoder Loss:  0.04743329  || Decoder Loss:  0.04531663 Validation Decoder Loss:  0.35418236
Encoder Loss:  0.046927586  || Decoder Loss:  0.04489099 Validation Decoder Loss:  0.35262918
Encoder Loss:  0.04684161  || Decoder Loss:  0.044644948 Validation Decoder Loss:  0.3518902
Encoder Loss:  0.046692964  || Decoder Loss:  0.044446856 Validation Decoder Loss:  0.3511494
Encoder Loss:  0.046519455  || Decoder Loss:  0.044261605 Validation Decoder Loss:  0.3509356
Encoder Loss:  0.046326235  || Decoder Loss:  0.044033643 Validation Decoder Loss:  0.35075393
Encoder Loss:  0.04610189  || Decoder Loss:  0.043826967 Validation Decoder Loss:  0.35062015
Encoder Loss:  0.04599324  || Decoder Loss:  0.043635778 Validation Decoder Loss:  0.3504873
Encoder Loss:  0.04582039  || Decoder Loss:  0.043398198 Validation Decoder Loss:  0.35115156
Encoder Loss:  0.045702167  || Decoder Loss:  0.043157104 Validation Decoder Loss:  0.3527115
Encoder Loss:  0.045520727  || Decoder Loss:  0.04299957 Validation Decoder Loss:  0.35249525
Encoder Loss:  0.04534359  || Decoder Loss:  0.042763766 Validation Decoder Loss:  0.35212123
Encoder Loss:  0.045155644  || Decoder Loss:  0.04249926 Validation Decoder Loss:  0.35263914
Encoder Loss:  0.044895783  || Decoder Loss:  0.042106733 Validation Decoder Loss:  0.35229754
Encoder Loss:  0.044302247  || Decoder Loss:  0.041207008 Validation Decoder Loss:  0.350437
Encoder Loss:  0.08017316  || Decoder Loss:  0.09628388 Validation Decoder Loss:  0.3576349
Encoder Loss:  0.048240706  || Decoder Loss:  0.04726412 Validation Decoder Loss:  0.35690296
Encoder Loss:  0.047869865  || Decoder Loss:  0.046696115 Validation Decoder Loss:  0.35685638
Encoder Loss:  0.047807444  || Decoder Loss:  0.046602868 Validation Decoder Loss:  0.35689867
Encoder Loss:  0.0478063  || Decoder Loss:  0.046600737 Validation Decoder Loss:  0.35703707
Encoder Loss:  0.047763802  || Decoder Loss:  0.046541438 Validation Decoder Loss:  0.35708907
Encoder Loss:  0.047721397  || Decoder Loss:  0.046473753 Validation Decoder Loss:  0.35697845
Encoder Loss:  0.04766999  || Decoder Loss:  0.046397448 Validation Decoder Loss:  0.35679746
Encoder Loss:  0.04765408  || Decoder Loss:  0.046375208 Validation Decoder Loss:  0.35705447
Encoder Loss:  0.047618818  || Decoder Loss:  0.046324596 Validation Decoder Loss:  0.35713622
Encoder Loss:  0.047596015  || Decoder Loss:  0.04629103 Validation Decoder Loss:  0.3570742
Encoder Loss:  0.047542963  || Decoder Loss:  0.04621192 Validation Decoder Loss:  0.35709012
Encoder Loss:  0.047519807  || Decoder Loss:  0.04617771 Validation Decoder Loss:  0.35722473
Encoder Loss:  0.04748971  || Decoder Loss:  0.04613251 Validation Decoder Loss:  0.3571385
Encoder Loss:  0.047456175  || Decoder Loss:  0.046082303 Validation Decoder Loss:  0.35719278
Encoder Loss:  0.047456753  || Decoder Loss:  0.046083156 Validation Decoder Loss:  0.35701525
Encoder Loss:  0.04746854  || Decoder Loss:  0.046098895 Validation Decoder Loss:  0.3571115
Encoder Loss:  0.047435217  || Decoder Loss:  0.046052657 Validation Decoder Loss:  0.3571468
Encoder Loss:  0.04742759  || Decoder Loss:  0.046040002 Validation Decoder Loss:  0.3570926
Encoder Loss:  0.047364842  || Decoder Loss:  0.045946576 Validation Decoder Loss:  0.3571635
Encoder Loss:  0.04731795  || Decoder Loss:  0.04587327 Validation Decoder Loss:  0.35712832
Encoder Loss:  0.047285534  || Decoder Loss:  0.045824148 Validation Decoder Loss:  0.357189
Model: siamese_net_lr_0.19094326178244744 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.357189
Model: "sequential_561"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_251 (Conv3D (None, 70, 5, 20, 1)      8         
_________________________________________________________________
dropout_674 (Dropout)        (None, 70, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_252 (Conv3D (None, 74, 30, 20, 1)     71        
_________________________________________________________________
reshape_154 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 79
Trainable params: 79
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_563"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_236 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_676 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_237 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_564"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_236 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_678 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_237 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974983 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974983 Validation Decoder Loss:  0.37322983
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974983 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322983
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322983
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322983
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974976 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.05997498 Validation Decoder Loss:  0.37322986
Encoder Loss:  0.14539236  || Decoder Loss:  0.059974983 Validation Decoder Loss:  0.37322986
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37322986
Model: "sequential_566"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_238 (Conv2D)          (None, 2320, 20, 1)       289       
_________________________________________________________________
dropout_680 (Dropout)        (None, 2320, 20, 1)       0         
_________________________________________________________________
conv2d_239 (Conv2D)          (None, 2220, 20, 1)       102       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_567"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_238 (Conv2D (None, 2420, 20, 1)       202       
_________________________________________________________________
dropout_682 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_239 (Conv2D (None, 2607, 20, 1)       189       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_568"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_254 (Conv3D (None, 67, 30, 20, 1)     73        
_________________________________________________________________
dropout_684 (Dropout)        (None, 67, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_255 (Conv3D (None, 74, 30, 20, 1)     9         
_________________________________________________________________
reshape_155 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 82
Trainable params: 82
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_570"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_240 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_686 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_241 (Conv2D)          (None, 2220, 20, 1)       362       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_571"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_240 (Conv2D (None, 2370, 20, 1)       152       
_________________________________________________________________
dropout_688 (Dropout)        (None, 2370, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_241 (Conv2D (None, 2607, 20, 1)       239       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.23837928  || Decoder Loss:  0.4231189 Validation Decoder Loss:  1.395658
Encoder Loss:  0.25044745  || Decoder Loss:  0.48633838 Validation Decoder Loss:  1.2153779
Encoder Loss:  0.24129699  || Decoder Loss:  0.4674726 Validation Decoder Loss:  1.2765472
Encoder Loss:  0.2376984  || Decoder Loss:  0.45964688 Validation Decoder Loss:  0.59114444
Encoder Loss:  0.22835533  || Decoder Loss:  0.4392245 Validation Decoder Loss:  1.114811
Encoder Loss:  0.2490242  || Decoder Loss:  0.483964 Validation Decoder Loss:  1.2943621
Encoder Loss:  0.23758529  || Decoder Loss:  0.45956084 Validation Decoder Loss:  0.3399961
Encoder Loss:  0.1949791  || Decoder Loss:  0.278819 Validation Decoder Loss:  0.34973508
Encoder Loss:  0.054066077  || Decoder Loss:  0.056396026 Validation Decoder Loss:  0.37457803
Encoder Loss:  0.053760223  || Decoder Loss:  0.055980835 Validation Decoder Loss:  0.34509373
Encoder Loss:  0.054070424  || Decoder Loss:  0.054936685 Validation Decoder Loss:  0.36359626
Encoder Loss:  0.051362153  || Decoder Loss:  0.051163148 Validation Decoder Loss:  0.35107774
Encoder Loss:  0.05056558  || Decoder Loss:  0.050051436 Validation Decoder Loss:  0.3414711
Encoder Loss:  0.05278022  || Decoder Loss:  0.05312462 Validation Decoder Loss:  0.38289908
Encoder Loss:  0.05146852  || Decoder Loss:  0.051917586 Validation Decoder Loss:  0.35151058
Encoder Loss:  0.050990354  || Decoder Loss:  0.051177725 Validation Decoder Loss:  0.34320134
Encoder Loss:  0.053799283  || Decoder Loss:  0.055098608 Validation Decoder Loss:  0.34962827
Encoder Loss:  0.052522577  || Decoder Loss:  0.054334454 Validation Decoder Loss:  0.35685953
Encoder Loss:  0.051542357  || Decoder Loss:  0.052194692 Validation Decoder Loss:  0.3539631
Encoder Loss:  0.05261817  || Decoder Loss:  0.053981848 Validation Decoder Loss:  0.39470795
Encoder Loss:  0.05249608  || Decoder Loss:  0.05415058 Validation Decoder Loss:  0.3503858
Encoder Loss:  0.05189043  || Decoder Loss:  0.05275605 Validation Decoder Loss:  0.36295384
Encoder Loss:  0.0520253  || Decoder Loss:  0.05333974 Validation Decoder Loss:  0.34933496
Encoder Loss:  0.052719522  || Decoder Loss:  0.054560028 Validation Decoder Loss:  0.34980378
Encoder Loss:  0.05213031  || Decoder Loss:  0.05322056 Validation Decoder Loss:  0.3459159
Encoder Loss:  0.052619215  || Decoder Loss:  0.054482084 Validation Decoder Loss:  0.35804534
Encoder Loss:  0.05177351  || Decoder Loss:  0.05301666 Validation Decoder Loss:  0.34743387
Encoder Loss:  0.052606188  || Decoder Loss:  0.0543 Validation Decoder Loss:  0.35940665
Encoder Loss:  0.052087396  || Decoder Loss:  0.053679775 Validation Decoder Loss:  0.35111818
Encoder Loss:  0.05158561  || Decoder Loss:  0.052582856 Validation Decoder Loss:  0.35201532
Encoder Loss:  0.05135922  || Decoder Loss:  0.052159376 Validation Decoder Loss:  0.3595164
Encoder Loss:  0.052234534  || Decoder Loss:  0.053782612 Validation Decoder Loss:  0.36303696
Encoder Loss:  0.05176497  || Decoder Loss:  0.053042106 Validation Decoder Loss:  0.35349315
Encoder Loss:  0.05188521  || Decoder Loss:  0.05312439 Validation Decoder Loss:  0.35273132
Encoder Loss:  0.05133065  || Decoder Loss:  0.052193675 Validation Decoder Loss:  0.35204005
Encoder Loss:  0.051955637  || Decoder Loss:  0.05357869 Validation Decoder Loss:  0.3535785
Encoder Loss:  0.050977074  || Decoder Loss:  0.05151185 Validation Decoder Loss:  0.35488647
Encoder Loss:  0.05168491  || Decoder Loss:  0.052577168 Validation Decoder Loss:  0.35744843
Encoder Loss:  0.051452562  || Decoder Loss:  0.052503243 Validation Decoder Loss:  0.35595694
Encoder Loss:  0.05134293  || Decoder Loss:  0.052183166 Validation Decoder Loss:  0.3551377
Model: siamese_net_lr_0.3568646392427821 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3551377
Model: "sequential_572"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_257 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_690 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_258 (Conv3D (None, 74, 30, 20, 1)     99        
_________________________________________________________________
reshape_156 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 105
Trainable params: 105
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_574"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_242 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_692 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_243 (Conv2D)          (None, 2220, 20, 1)       222       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_575"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_242 (Conv2D (None, 2280, 20, 1)       62        
_________________________________________________________________
dropout_694 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_243 (Conv2D (None, 2607, 20, 1)       329       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.10575199  || Decoder Loss:  0.47365963 Validation Decoder Loss:  0.99928445
Encoder Loss:  0.08141328  || Decoder Loss:  0.49609455 Validation Decoder Loss:  0.99869084
Encoder Loss:  0.07465854  || Decoder Loss:  0.4960745 Validation Decoder Loss:  0.998284
Encoder Loss:  0.0758251  || Decoder Loss:  0.49606517 Validation Decoder Loss:  0.9980551
Encoder Loss:  0.07915631  || Decoder Loss:  0.4960587 Validation Decoder Loss:  0.9979446
Encoder Loss:  0.07461213  || Decoder Loss:  0.49604347 Validation Decoder Loss:  0.99791276
Encoder Loss:  0.07147532  || Decoder Loss:  0.4960363 Validation Decoder Loss:  0.9978622
Encoder Loss:  0.068968944  || Decoder Loss:  0.49600577 Validation Decoder Loss:  0.99783343
Encoder Loss:  0.06895633  || Decoder Loss:  0.49598762 Validation Decoder Loss:  0.99781466
Encoder Loss:  0.068952195  || Decoder Loss:  0.4959747 Validation Decoder Loss:  0.9977759
Encoder Loss:  0.06895131  || Decoder Loss:  0.4959601 Validation Decoder Loss:  0.9977482
Encoder Loss:  0.06895045  || Decoder Loss:  0.4959417 Validation Decoder Loss:  0.9977144
Encoder Loss:  0.06894932  || Decoder Loss:  0.4959132 Validation Decoder Loss:  0.9976665
Encoder Loss:  0.06894768  || Decoder Loss:  0.49587765 Validation Decoder Loss:  0.9976202
Encoder Loss:  0.06894606  || Decoder Loss:  0.49584067 Validation Decoder Loss:  0.9975436
Encoder Loss:  0.068943664  || Decoder Loss:  0.49578547 Validation Decoder Loss:  0.9974405
Encoder Loss:  0.06894055  || Decoder Loss:  0.49571314 Validation Decoder Loss:  0.9972813
Encoder Loss:  0.06893632  || Decoder Loss:  0.4956135 Validation Decoder Loss:  0.9970379
Encoder Loss:  0.0689313  || Decoder Loss:  0.49549755 Validation Decoder Loss:  0.99670607
Encoder Loss:  0.06892636  || Decoder Loss:  0.495385 Validation Decoder Loss:  0.99631983
Encoder Loss:  0.0689214  || Decoder Loss:  0.49527204 Validation Decoder Loss:  0.9958849
Encoder Loss:  0.068913795  || Decoder Loss:  0.49509132 Validation Decoder Loss:  0.9951351
Encoder Loss:  0.06889988  || Decoder Loss:  0.4947688 Validation Decoder Loss:  0.9931321
Encoder Loss:  0.06887263  || Decoder Loss:  0.4941289 Validation Decoder Loss:  0.98903793
Encoder Loss:  0.06884207  || Decoder Loss:  0.49340832 Validation Decoder Loss:  0.9838083
Encoder Loss:  0.06872922  || Decoder Loss:  0.4907543 Validation Decoder Loss:  1.0004885
Encoder Loss:  0.069031395  || Decoder Loss:  0.4978683 Validation Decoder Loss:  0.99667823
Encoder Loss:  0.06879818  || Decoder Loss:  0.49237058 Validation Decoder Loss:  0.95283
Encoder Loss:  0.06850423  || Decoder Loss:  0.48545206 Validation Decoder Loss:  0.955704
Encoder Loss:  0.068697326  || Decoder Loss:  0.49000585 Validation Decoder Loss:  0.9911613
Encoder Loss:  0.06869816  || Decoder Loss:  0.49002814 Validation Decoder Loss:  0.8287747
Encoder Loss:  0.06602061  || Decoder Loss:  0.42701286 Validation Decoder Loss:  1.0118647
Encoder Loss:  0.06845564  || Decoder Loss:  0.48432073 Validation Decoder Loss:  0.9988494
Encoder Loss:  0.0677961  || Decoder Loss:  0.46879607 Validation Decoder Loss:  0.98783326
Encoder Loss:  0.06331409  || Decoder Loss:  0.36328182 Validation Decoder Loss:  0.39568245
Encoder Loss:  0.050711583  || Decoder Loss:  0.06664503 Validation Decoder Loss:  0.38505912
Encoder Loss:  0.049867854  || Decoder Loss:  0.0467158 Validation Decoder Loss:  0.38375235
Encoder Loss:  0.049809266  || Decoder Loss:  0.045216095 Validation Decoder Loss:  0.38631153
Encoder Loss:  0.049757313  || Decoder Loss:  0.043987293 Validation Decoder Loss:  0.39028323
Encoder Loss:  0.049741764  || Decoder Loss:  0.04368218 Validation Decoder Loss:  0.38992482
Model: siamese_net_lr_0.517066748913019 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.38992482
Model: "sequential_576"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_260 (Conv3D (None, 70, 29, 20, 1)     148       
_________________________________________________________________
dropout_696 (Dropout)        (None, 70, 29, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_261 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_157 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 159
Trainable params: 159
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_578"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_244 (Conv2D)          (None, 2580, 20, 1)       29        
_________________________________________________________________
dropout_698 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_245 (Conv2D)          (None, 2220, 20, 1)       362       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_579"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_244 (Conv2D (None, 2370, 20, 1)       152       
_________________________________________________________________
dropout_700 (Dropout)        (None, 2370, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_245 (Conv2D (None, 2607, 20, 1)       239       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12164136  || Decoder Loss:  0.19320644 Validation Decoder Loss:  0.4113027
Encoder Loss:  0.18038636  || Decoder Loss:  0.591387 Validation Decoder Loss:  1.244198
Encoder Loss:  0.15530367  || Decoder Loss:  0.52068645 Validation Decoder Loss:  0.7514771
Encoder Loss:  0.11602651  || Decoder Loss:  0.3450039 Validation Decoder Loss:  0.6065774
Encoder Loss:  0.091183364  || Decoder Loss:  0.23345846 Validation Decoder Loss:  0.43420547
Encoder Loss:  0.08542714  || Decoder Loss:  0.20799524 Validation Decoder Loss:  0.47870117
Encoder Loss:  0.076057315  || Decoder Loss:  0.1656826 Validation Decoder Loss:  0.38486603
Encoder Loss:  0.093529366  || Decoder Loss:  0.24294876 Validation Decoder Loss:  0.34961668
Encoder Loss:  0.06630371  || Decoder Loss:  0.12193373 Validation Decoder Loss:  0.50882083
Encoder Loss:  0.049307108  || Decoder Loss:  0.045817763 Validation Decoder Loss:  0.34915596
Encoder Loss:  0.049461976  || Decoder Loss:  0.046345934 Validation Decoder Loss:  0.34653762
Encoder Loss:  0.049088374  || Decoder Loss:  0.044612594 Validation Decoder Loss:  0.34748638
Encoder Loss:  0.049131494  || Decoder Loss:  0.044751503 Validation Decoder Loss:  0.35473326
Encoder Loss:  0.04922821  || Decoder Loss:  0.04532949 Validation Decoder Loss:  0.34731615
Encoder Loss:  0.050981533  || Decoder Loss:  0.053095613 Validation Decoder Loss:  0.37121242
Encoder Loss:  0.049085  || Decoder Loss:  0.045095637 Validation Decoder Loss:  0.3498407
Encoder Loss:  0.051904917  || Decoder Loss:  0.057883028 Validation Decoder Loss:  0.35213262
Encoder Loss:  0.048384596  || Decoder Loss:  0.04158906 Validation Decoder Loss:  0.34701145
Encoder Loss:  0.049677867  || Decoder Loss:  0.045956817 Validation Decoder Loss:  0.35706154
Encoder Loss:  0.057692457  || Decoder Loss:  0.071747124 Validation Decoder Loss:  0.34789273
Encoder Loss:  0.048718616  || Decoder Loss:  0.043672994 Validation Decoder Loss:  0.35210365
Encoder Loss:  0.050857726  || Decoder Loss:  0.05316297 Validation Decoder Loss:  0.352545
Encoder Loss:  0.04908174  || Decoder Loss:  0.04516893 Validation Decoder Loss:  0.36521697
Encoder Loss:  0.049722955  || Decoder Loss:  0.04770452 Validation Decoder Loss:  0.35187125
Encoder Loss:  0.049078565  || Decoder Loss:  0.04493359 Validation Decoder Loss:  0.5321268
Encoder Loss:  0.05024292  || Decoder Loss:  0.049768273 Validation Decoder Loss:  0.34677336
Encoder Loss:  0.048121184  || Decoder Loss:  0.04077635 Validation Decoder Loss:  0.34725648
Encoder Loss:  0.048940144  || Decoder Loss:  0.04405251 Validation Decoder Loss:  0.34707552
Encoder Loss:  0.048813116  || Decoder Loss:  0.04402802 Validation Decoder Loss:  0.4145698
Encoder Loss:  0.048777904  || Decoder Loss:  0.043910127 Validation Decoder Loss:  0.4087093
Encoder Loss:  0.049552094  || Decoder Loss:  0.047369547 Validation Decoder Loss:  0.38970897
Encoder Loss:  0.04860281  || Decoder Loss:  0.042876016 Validation Decoder Loss:  0.3466122
Encoder Loss:  0.050614778  || Decoder Loss:  0.051168557 Validation Decoder Loss:  0.34815335
Encoder Loss:  0.047933456  || Decoder Loss:  0.040131062 Validation Decoder Loss:  0.34741533
Encoder Loss:  0.04845583  || Decoder Loss:  0.04227214 Validation Decoder Loss:  0.36728042
Encoder Loss:  0.048191033  || Decoder Loss:  0.041172367 Validation Decoder Loss:  0.35025266
Encoder Loss:  0.049245045  || Decoder Loss:  0.045965277 Validation Decoder Loss:  0.36121678
Encoder Loss:  0.04826893  || Decoder Loss:  0.041653685 Validation Decoder Loss:  0.3463869
Encoder Loss:  0.04806612  || Decoder Loss:  0.04036723 Validation Decoder Loss:  0.34740114
Encoder Loss:  0.079967655  || Decoder Loss:  0.1822577 Validation Decoder Loss:  0.50101304
Model: siamese_net_lr_0.10638103376149893 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.50101304
Model: "sequential_580"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_263 (Conv3D (None, 67, 30, 20, 1)     89        
_________________________________________________________________
dropout_702 (Dropout)        (None, 67, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_264 (Conv3D (None, 74, 30, 20, 1)     9         
_________________________________________________________________
reshape_158 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 98
Trainable params: 98
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_582"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_246 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_704 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_247 (Conv2D)          (None, 2220, 20, 1)       382       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_583"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_246 (Conv2D (None, 2400, 20, 1)       182       
_________________________________________________________________
dropout_706 (Dropout)        (None, 2400, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_247 (Conv2D (None, 2607, 20, 1)       209       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.50178117  || Decoder Loss:  0.634847 Validation Decoder Loss:  1.4241091
Encoder Loss:  0.36691338  || Decoder Loss:  0.5471296 Validation Decoder Loss:  0.95031786
Encoder Loss:  0.328288  || Decoder Loss:  0.49845836 Validation Decoder Loss:  0.97202235
Encoder Loss:  0.32798767  || Decoder Loss:  0.4979882 Validation Decoder Loss:  0.9766518
Encoder Loss:  0.32439572  || Decoder Loss:  0.4919429 Validation Decoder Loss:  1.0022233
Encoder Loss:  0.31784484  || Decoder Loss:  0.48139247 Validation Decoder Loss:  1.0031791
Encoder Loss:  0.3166528  || Decoder Loss:  0.479372 Validation Decoder Loss:  1.006522
Encoder Loss:  0.3145486  || Decoder Loss:  0.476228 Validation Decoder Loss:  1.0001073
Encoder Loss:  0.31387708  || Decoder Loss:  0.47493836 Validation Decoder Loss:  1.0031395
Encoder Loss:  0.31340173  || Decoder Loss:  0.47409314 Validation Decoder Loss:  1.0092491
Encoder Loss:  0.3141031  || Decoder Loss:  0.47491553 Validation Decoder Loss:  1.0242128
Encoder Loss:  0.31477848  || Decoder Loss:  0.47493458 Validation Decoder Loss:  0.9969443
Encoder Loss:  0.31342962  || Decoder Loss:  0.4737404 Validation Decoder Loss:  1.0062726
Encoder Loss:  0.31228516  || Decoder Loss:  0.47256252 Validation Decoder Loss:  0.99329406
Encoder Loss:  0.31191742  || Decoder Loss:  0.47188768 Validation Decoder Loss:  1.0127821
Encoder Loss:  0.31111795  || Decoder Loss:  0.47075438 Validation Decoder Loss:  1.0149754
Encoder Loss:  0.31158018  || Decoder Loss:  0.4710869 Validation Decoder Loss:  1.007515
Encoder Loss:  0.31227306  || Decoder Loss:  0.47211224 Validation Decoder Loss:  1.0374029
Encoder Loss:  0.31067064  || Decoder Loss:  0.47007188 Validation Decoder Loss:  1.0208035
Encoder Loss:  0.31050462  || Decoder Loss:  0.46947843 Validation Decoder Loss:  1.0039397
Encoder Loss:  0.3103469  || Decoder Loss:  0.46932903 Validation Decoder Loss:  1.0217991
Encoder Loss:  0.3099533  || Decoder Loss:  0.46880943 Validation Decoder Loss:  1.023443
Encoder Loss:  0.30991122  || Decoder Loss:  0.46860477 Validation Decoder Loss:  1.01302
Encoder Loss:  0.30997136  || Decoder Loss:  0.46861362 Validation Decoder Loss:  1.0335749
Encoder Loss:  0.30907533  || Decoder Loss:  0.46756673 Validation Decoder Loss:  1.0209811
Encoder Loss:  0.30859175  || Decoder Loss:  0.46676528 Validation Decoder Loss:  1.0200704
Encoder Loss:  0.30812517  || Decoder Loss:  0.46587518 Validation Decoder Loss:  1.0186398
Encoder Loss:  0.30762717  || Decoder Loss:  0.4650965 Validation Decoder Loss:  1.0268306
Encoder Loss:  0.30457944  || Decoder Loss:  0.46001542 Validation Decoder Loss:  1.009891
Encoder Loss:  0.30415988  || Decoder Loss:  0.45932716 Validation Decoder Loss:  1.1463734
Encoder Loss:  0.3251716  || Decoder Loss:  0.49255943 Validation Decoder Loss:  0.9730647
Encoder Loss:  0.32154578  || Decoder Loss:  0.4867314 Validation Decoder Loss:  1.0265694
Encoder Loss:  0.32065216  || Decoder Loss:  0.48586583 Validation Decoder Loss:  1.0153651
Encoder Loss:  0.31394058  || Decoder Loss:  0.47508508 Validation Decoder Loss:  0.9068152
Encoder Loss:  0.30872744  || Decoder Loss:  0.4670101 Validation Decoder Loss:  0.8333852
Encoder Loss:  0.3226524  || Decoder Loss:  0.4894222 Validation Decoder Loss:  0.9693531
Encoder Loss:  0.32752147  || Decoder Loss:  0.49730203 Validation Decoder Loss:  0.9428196
Encoder Loss:  0.32666665  || Decoder Loss:  0.49490452 Validation Decoder Loss:  0.9995294
Encoder Loss:  0.3233327  || Decoder Loss:  0.49058083 Validation Decoder Loss:  0.92795295
Encoder Loss:  0.31198362  || Decoder Loss:  0.47227058 Validation Decoder Loss:  0.9595047
Model: siamese_net_lr_0.6839942895218791 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9595047
Model: "sequential_584"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_266 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_708 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_267 (Conv3D (None, 74, 30, 20, 1)     79        
_________________________________________________________________
reshape_159 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_586"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_248 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_710 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_249 (Conv2D)          (None, 2220, 20, 1)       202       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_587"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_248 (Conv2D (None, 2270, 20, 1)       52        
_________________________________________________________________
dropout_712 (Dropout)        (None, 2270, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_249 (Conv2D (None, 2607, 20, 1)       339       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.061465193  || Decoder Loss:  0.32210994 Validation Decoder Loss:  0.36893576
Encoder Loss:  0.04995862  || Decoder Loss:  0.04841302 Validation Decoder Loss:  0.33890623
Encoder Loss:  0.04970374  || Decoder Loss:  0.041213322 Validation Decoder Loss:  0.33963388
Encoder Loss:  0.0496928  || Decoder Loss:  0.04083232 Validation Decoder Loss:  0.339446
Encoder Loss:  0.04968278  || Decoder Loss:  0.04051858 Validation Decoder Loss:  0.3401694
Encoder Loss:  0.0496663  || Decoder Loss:  0.04001662 Validation Decoder Loss:  0.34470668
Encoder Loss:  0.04965873  || Decoder Loss:  0.039715767 Validation Decoder Loss:  0.33701098
Encoder Loss:  0.049652085  || Decoder Loss:  0.039554607 Validation Decoder Loss:  0.34073418
Encoder Loss:  0.06252915  || Decoder Loss:  0.39028513 Validation Decoder Loss:  1.018802
Encoder Loss:  0.06546697  || Decoder Loss:  0.49596214 Validation Decoder Loss:  1.0171207
Encoder Loss:  0.06544182  || Decoder Loss:  0.49520284 Validation Decoder Loss:  1.015584
Encoder Loss:  0.06541803  || Decoder Loss:  0.49451715 Validation Decoder Loss:  1.0150043
Encoder Loss:  0.065361  || Decoder Loss:  0.49275953 Validation Decoder Loss:  0.984179
Encoder Loss:  0.052952882  || Decoder Loss:  0.13481379 Validation Decoder Loss:  0.35776287
Encoder Loss:  0.049832594  || Decoder Loss:  0.04494749 Validation Decoder Loss:  0.351314
Encoder Loss:  0.049817216  || Decoder Loss:  0.04430954 Validation Decoder Loss:  0.35390663
Encoder Loss:  0.049812235  || Decoder Loss:  0.044299822 Validation Decoder Loss:  0.34704936
Encoder Loss:  0.04982272  || Decoder Loss:  0.04464657 Validation Decoder Loss:  0.3608685
Encoder Loss:  0.049816333  || Decoder Loss:  0.044483274 Validation Decoder Loss:  0.35841596
Encoder Loss:  0.049807265  || Decoder Loss:  0.044196963 Validation Decoder Loss:  0.35877374
Encoder Loss:  0.049818  || Decoder Loss:  0.044421412 Validation Decoder Loss:  0.3509607
Encoder Loss:  0.049799155  || Decoder Loss:  0.04389109 Validation Decoder Loss:  0.33861643
Encoder Loss:  0.050921425  || Decoder Loss:  0.0755288 Validation Decoder Loss:  1.6018834
Encoder Loss:  0.051538844  || Decoder Loss:  0.06869742 Validation Decoder Loss:  0.36012027
Encoder Loss:  0.050046433  || Decoder Loss:  0.05125535 Validation Decoder Loss:  0.3635582
Encoder Loss:  0.0500108  || Decoder Loss:  0.05025271 Validation Decoder Loss:  0.3587191
Encoder Loss:  0.04998437  || Decoder Loss:  0.049497236 Validation Decoder Loss:  0.35644698
Encoder Loss:  0.04997324  || Decoder Loss:  0.04916106 Validation Decoder Loss:  0.35429066
Encoder Loss:  0.049963303  || Decoder Loss:  0.048878275 Validation Decoder Loss:  0.35151303
Encoder Loss:  0.04994385  || Decoder Loss:  0.048318315 Validation Decoder Loss:  0.3467479
Encoder Loss:  0.04980024  || Decoder Loss:  0.04412447 Validation Decoder Loss:  0.3489619
Encoder Loss:  0.049774684  || Decoder Loss:  0.043403402 Validation Decoder Loss:  0.35108984
Encoder Loss:  0.04981049  || Decoder Loss:  0.044412542 Validation Decoder Loss:  0.34681702
Encoder Loss:  0.049750194  || Decoder Loss:  0.04264769 Validation Decoder Loss:  0.34766656
Encoder Loss:  0.049719978  || Decoder Loss:  0.041784734 Validation Decoder Loss:  0.35658327
Encoder Loss:  0.049781833  || Decoder Loss:  0.04352936 Validation Decoder Loss:  0.35075134
Encoder Loss:  0.049748473  || Decoder Loss:  0.042588558 Validation Decoder Loss:  0.36415988
Encoder Loss:  0.04977352  || Decoder Loss:  0.043268837 Validation Decoder Loss:  0.3488137
Encoder Loss:  0.06420482  || Decoder Loss:  0.4589424 Validation Decoder Loss:  0.96747255
Encoder Loss:  0.05973091  || Decoder Loss:  0.33050016 Validation Decoder Loss:  0.33549052
Model: siamese_net_lr_0.21318337507191962 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33549052
Model: "sequential_588"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_269 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_714 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_270 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_160 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_590"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_250 (Conv2D)          (None, 2240, 20, 1)       369       
_________________________________________________________________
dropout_716 (Dropout)        (None, 2240, 20, 1)       0         
_________________________________________________________________
conv2d_251 (Conv2D)          (None, 2220, 20, 1)       22        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_591"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_250 (Conv2D (None, 2580, 20, 1)       362       
_________________________________________________________________
dropout_718 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_251 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13814545  || Decoder Loss:  0.13322791 Validation Decoder Loss:  0.37494493
Encoder Loss:  0.30686185  || Decoder Loss:  0.30902076 Validation Decoder Loss:  0.7238859
Encoder Loss:  0.47752425  || Decoder Loss:  0.48674893 Validation Decoder Loss:  0.98873246
Encoder Loss:  0.4809001  || Decoder Loss:  0.4901992 Validation Decoder Loss:  1.0104996
Encoder Loss:  0.47787404  || Decoder Loss:  0.48710644 Validation Decoder Loss:  1.0669167
Encoder Loss:  0.47815946  || Decoder Loss:  0.48739702 Validation Decoder Loss:  1.045785
Encoder Loss:  0.4756808  || Decoder Loss:  0.48486274 Validation Decoder Loss:  1.0296342
Encoder Loss:  0.4726632  || Decoder Loss:  0.4817824 Validation Decoder Loss:  1.0374303
Encoder Loss:  0.4688439  || Decoder Loss:  0.47788033 Validation Decoder Loss:  1.0366831
Encoder Loss:  0.47024602  || Decoder Loss:  0.47931135 Validation Decoder Loss:  1.0360346
Encoder Loss:  0.4580907  || Decoder Loss:  0.46689335 Validation Decoder Loss:  1.101362
Encoder Loss:  0.46663696  || Decoder Loss:  0.4756246 Validation Decoder Loss:  0.95925695
Encoder Loss:  0.3761631  || Decoder Loss:  0.38319796 Validation Decoder Loss:  0.49648944
Encoder Loss:  0.06109118  || Decoder Loss:  0.06131859 Validation Decoder Loss:  0.34428763
Encoder Loss:  0.13903669  || Decoder Loss:  0.14095107 Validation Decoder Loss:  0.97774446
Encoder Loss:  0.47861463  || Decoder Loss:  0.48786384 Validation Decoder Loss:  0.9889438
Encoder Loss:  0.28878072  || Decoder Loss:  0.2939273 Validation Decoder Loss:  0.33518904
Encoder Loss:  0.03911997  || Decoder Loss:  0.038865946 Validation Decoder Loss:  0.36899757
Encoder Loss:  0.13284379  || Decoder Loss:  0.13461079 Validation Decoder Loss:  0.33045638
Encoder Loss:  0.035536587  || Decoder Loss:  0.035218578 Validation Decoder Loss:  0.3317032
Encoder Loss:  0.035748273  || Decoder Loss:  0.035432976 Validation Decoder Loss:  0.33160892
Encoder Loss:  0.06446218  || Decoder Loss:  0.064755686 Validation Decoder Loss:  0.3309064
Encoder Loss:  0.036432542  || Decoder Loss:  0.036135923 Validation Decoder Loss:  0.3303826
Encoder Loss:  0.35502094  || Decoder Loss:  0.36157122 Validation Decoder Loss:  0.8548523
Encoder Loss:  0.16083649  || Decoder Loss:  0.16322792 Validation Decoder Loss:  0.33265433
Encoder Loss:  0.039650008  || Decoder Loss:  0.039418086 Validation Decoder Loss:  0.33182514
Encoder Loss:  0.06573311  || Decoder Loss:  0.066061184 Validation Decoder Loss:  0.3454515
Encoder Loss:  0.036865875  || Decoder Loss:  0.036581118 Validation Decoder Loss:  0.33155364
Encoder Loss:  0.03542575  || Decoder Loss:  0.035108462 Validation Decoder Loss:  0.3319543
Encoder Loss:  0.035562355  || Decoder Loss:  0.03524785 Validation Decoder Loss:  0.33002543
Encoder Loss:  0.23443241  || Decoder Loss:  0.2383444 Validation Decoder Loss:  0.3388269
Encoder Loss:  0.0423396  || Decoder Loss:  0.04216986 Validation Decoder Loss:  0.35174215
Encoder Loss:  0.044778142  || Decoder Loss:  0.0446642 Validation Decoder Loss:  0.35124236
Encoder Loss:  0.038539864  || Decoder Loss:  0.03829048 Validation Decoder Loss:  0.4411133
Encoder Loss:  0.111883186  || Decoder Loss:  0.11320677 Validation Decoder Loss:  0.33386695
Encoder Loss:  0.036231853  || Decoder Loss:  0.0359316 Validation Decoder Loss:  0.33229017
Encoder Loss:  0.040233623  || Decoder Loss:  0.04002048 Validation Decoder Loss:  0.37423506
Encoder Loss:  0.038135536  || Decoder Loss:  0.037876174 Validation Decoder Loss:  0.33134192
Encoder Loss:  0.048575092  || Decoder Loss:  0.048540656 Validation Decoder Loss:  0.3419856
Encoder Loss:  0.04786006  || Decoder Loss:  0.04780677 Validation Decoder Loss:  0.33942443
Model: siamese_net_lr_0.7607530239087835 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33942443
Model: "sequential_592"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_272 (Conv3D (None, 70, 9, 20, 1)      36        
_________________________________________________________________
dropout_720 (Dropout)        (None, 70, 9, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_273 (Conv3D (None, 74, 30, 20, 1)     71        
_________________________________________________________________
reshape_161 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 107
Trainable params: 107
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_594"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_252 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_722 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_253 (Conv2D)          (None, 2220, 20, 1)       272       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_595"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_252 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_724 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_253 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.11157762  || Decoder Loss:  0.17361976 Validation Decoder Loss:  0.3763438
Encoder Loss:  0.052317467  || Decoder Loss:  0.054906994 Validation Decoder Loss:  0.36689514
Encoder Loss:  0.052991375  || Decoder Loss:  0.056516066 Validation Decoder Loss:  0.36857727
Encoder Loss:  0.052387334  || Decoder Loss:  0.05520548 Validation Decoder Loss:  0.3595808
Encoder Loss:  0.05107193  || Decoder Loss:  0.05231376 Validation Decoder Loss:  0.34397176
Encoder Loss:  0.05092301  || Decoder Loss:  0.051968526 Validation Decoder Loss:  0.35263917
Encoder Loss:  0.050440323  || Decoder Loss:  0.050908636 Validation Decoder Loss:  0.3560382
Encoder Loss:  0.052102055  || Decoder Loss:  0.054555893 Validation Decoder Loss:  0.3476584
Encoder Loss:  0.054008745  || Decoder Loss:  0.058770705 Validation Decoder Loss:  0.36542314
Encoder Loss:  0.055137534  || Decoder Loss:  0.06126119 Validation Decoder Loss:  0.36893353
Encoder Loss:  0.054767597  || Decoder Loss:  0.0604354 Validation Decoder Loss:  0.37821966
Encoder Loss:  0.0542486  || Decoder Loss:  0.059288803 Validation Decoder Loss:  0.38386875
Encoder Loss:  0.05249279  || Decoder Loss:  0.055441044 Validation Decoder Loss:  0.34962928
Encoder Loss:  0.04516775  || Decoder Loss:  0.03935627 Validation Decoder Loss:  0.35094634
Encoder Loss:  0.04363523  || Decoder Loss:  0.035985466 Validation Decoder Loss:  0.33871323
Encoder Loss:  0.04314211  || Decoder Loss:  0.034907807 Validation Decoder Loss:  0.33504
Encoder Loss:  0.043151766  || Decoder Loss:  0.034920804 Validation Decoder Loss:  0.34541756
Encoder Loss:  0.043041583  || Decoder Loss:  0.03468415 Validation Decoder Loss:  0.34017172
Encoder Loss:  0.043017264  || Decoder Loss:  0.034628782 Validation Decoder Loss:  0.3297934
Encoder Loss:  0.043171577  || Decoder Loss:  0.03496742 Validation Decoder Loss:  0.3432271
Encoder Loss:  0.043000687  || Decoder Loss:  0.034594253 Validation Decoder Loss:  0.3442318
Encoder Loss:  0.074822456  || Decoder Loss:  0.10458354 Validation Decoder Loss:  1.0033491
Encoder Loss:  0.25427374  || Decoder Loss:  0.4992931 Validation Decoder Loss:  1.003268
Encoder Loss:  0.254265  || Decoder Loss:  0.4992751 Validation Decoder Loss:  1.003474
Encoder Loss:  0.25424433  || Decoder Loss:  0.49922055 Validation Decoder Loss:  1.0030599
Encoder Loss:  0.2542204  || Decoder Loss:  0.49917725 Validation Decoder Loss:  1.0034013
Encoder Loss:  0.25419682  || Decoder Loss:  0.4991168 Validation Decoder Loss:  1.0028713
Encoder Loss:  0.25412574  || Decoder Loss:  0.49897033 Validation Decoder Loss:  1.0026282
Encoder Loss:  0.25405392  || Decoder Loss:  0.49881116 Validation Decoder Loss:  1.0078336
Encoder Loss:  0.2540246  || Decoder Loss:  0.4987448 Validation Decoder Loss:  1.0013618
Encoder Loss:  0.25274357  || Decoder Loss:  0.4959322 Validation Decoder Loss:  1.0081201
Encoder Loss:  0.25381705  || Decoder Loss:  0.49828595 Validation Decoder Loss:  0.9958039
Encoder Loss:  0.25459683  || Decoder Loss:  0.50001144 Validation Decoder Loss:  0.9955566
Encoder Loss:  0.25478578  || Decoder Loss:  0.5004254 Validation Decoder Loss:  0.9972933
Encoder Loss:  0.2544848  || Decoder Loss:  0.49976486 Validation Decoder Loss:  0.9962858
Encoder Loss:  0.25487974  || Decoder Loss:  0.5006315 Validation Decoder Loss:  0.9960878
Encoder Loss:  0.2545441  || Decoder Loss:  0.49989757 Validation Decoder Loss:  0.99538445
Encoder Loss:  0.2542976  || Decoder Loss:  0.4993508 Validation Decoder Loss:  0.98998487
Encoder Loss:  0.25517812  || Decoder Loss:  0.5012807 Validation Decoder Loss:  0.9963716
Encoder Loss:  0.25459984  || Decoder Loss:  0.5000213 Validation Decoder Loss:  0.9956894
Model: siamese_net_lr_0.4466770839818699 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9956894
Model: "sequential_596"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_275 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_726 (Dropout)        (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_276 (Conv3D (None, 74, 30, 20, 1)     15        
_________________________________________________________________
reshape_162 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 27
Trainable params: 27
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_598"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_254 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_728 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_255 (Conv2D)          (None, 2220, 20, 1)       222       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_599"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_254 (Conv2D (None, 2280, 20, 1)       62        
_________________________________________________________________
dropout_730 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_255 (Conv2D (None, 2607, 20, 1)       329       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.12559754  || Decoder Loss:  0.48504123 Validation Decoder Loss:  1.0056052
Encoder Loss:  0.0886822  || Decoder Loss:  0.33864337 Validation Decoder Loss:  0.3523044
Encoder Loss:  0.06431437  || Decoder Loss:  0.099732 Validation Decoder Loss:  0.3962687
Encoder Loss:  0.07573326  || Decoder Loss:  0.22685632 Validation Decoder Loss:  0.35710514
Encoder Loss:  0.052775107  || Decoder Loss:  0.04570003 Validation Decoder Loss:  0.35360202
Encoder Loss:  0.053261507  || Decoder Loss:  0.045019582 Validation Decoder Loss:  0.35674632
Encoder Loss:  0.05404387  || Decoder Loss:  0.045494467 Validation Decoder Loss:  0.3551143
Encoder Loss:  0.05208046  || Decoder Loss:  0.045253605 Validation Decoder Loss:  0.35468364
Encoder Loss:  0.052031506  || Decoder Loss:  0.045137554 Validation Decoder Loss:  0.3548909
Encoder Loss:  0.052850127  || Decoder Loss:  0.04491997 Validation Decoder Loss:  0.3542889
Encoder Loss:  0.05219495  || Decoder Loss:  0.04507142 Validation Decoder Loss:  0.35466164
Encoder Loss:  0.05255316  || Decoder Loss:  0.044740234 Validation Decoder Loss:  0.3557918
Encoder Loss:  0.052100215  || Decoder Loss:  0.044682465 Validation Decoder Loss:  0.35730132
Encoder Loss:  0.05252045  || Decoder Loss:  0.044270582 Validation Decoder Loss:  0.3537582
Encoder Loss:  0.06152699  || Decoder Loss:  0.1323633 Validation Decoder Loss:  0.37573218
Encoder Loss:  0.051088285  || Decoder Loss:  0.04526145 Validation Decoder Loss:  0.35665312
Encoder Loss:  0.054551825  || Decoder Loss:  0.048234478 Validation Decoder Loss:  0.3566153
Encoder Loss:  0.060165536  || Decoder Loss:  0.11650678 Validation Decoder Loss:  0.35719293
Encoder Loss:  0.052771002  || Decoder Loss:  0.057673022 Validation Decoder Loss:  0.3536564
Encoder Loss:  0.0519008  || Decoder Loss:  0.044594903 Validation Decoder Loss:  0.3566683
Encoder Loss:  0.05224887  || Decoder Loss:  0.04432527 Validation Decoder Loss:  0.3535452
Encoder Loss:  0.05221565  || Decoder Loss:  0.044202313 Validation Decoder Loss:  0.3536008
Encoder Loss:  0.05149374  || Decoder Loss:  0.044267826 Validation Decoder Loss:  0.35545984
Encoder Loss:  0.051138252  || Decoder Loss:  0.044424195 Validation Decoder Loss:  0.3557042
Encoder Loss:  0.053284753  || Decoder Loss:  0.04443676 Validation Decoder Loss:  0.35551658
Encoder Loss:  0.052472405  || Decoder Loss:  0.044101764 Validation Decoder Loss:  0.35624945
Encoder Loss:  0.051495977  || Decoder Loss:  0.044194054 Validation Decoder Loss:  0.35664082
Encoder Loss:  0.050864793  || Decoder Loss:  0.044065375 Validation Decoder Loss:  0.35566595
Encoder Loss:  0.050974857  || Decoder Loss:  0.0438339 Validation Decoder Loss:  0.375085
Encoder Loss:  0.091263875  || Decoder Loss:  0.3871538 Validation Decoder Loss:  0.4777702
Encoder Loss:  0.06374588  || Decoder Loss:  0.15355426 Validation Decoder Loss:  0.35643396
Encoder Loss:  0.050644636  || Decoder Loss:  0.044193134 Validation Decoder Loss:  0.35355
Encoder Loss:  0.050278492  || Decoder Loss:  0.04405945 Validation Decoder Loss:  0.354594
Encoder Loss:  0.0524004  || Decoder Loss:  0.044261422 Validation Decoder Loss:  0.35471794
Encoder Loss:  0.05156852  || Decoder Loss:  0.04393506 Validation Decoder Loss:  0.35567856
Encoder Loss:  0.051475525  || Decoder Loss:  0.043963928 Validation Decoder Loss:  0.356278
Encoder Loss:  0.051660247  || Decoder Loss:  0.044162065 Validation Decoder Loss:  0.35406324
Encoder Loss:  0.05138236  || Decoder Loss:  0.043567732 Validation Decoder Loss:  0.35565335
Encoder Loss:  0.05130473  || Decoder Loss:  0.04380987 Validation Decoder Loss:  0.35578936
Encoder Loss:  0.07611126  || Decoder Loss:  0.2725778 Validation Decoder Loss:  0.73870134
Model: siamese_net_lr_0.1020949390500646 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.73870134
Model: "sequential_600"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_278 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_732 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_279 (Conv3D (None, 74, 30, 20, 1)     43        
_________________________________________________________________
reshape_163 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_602"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_256 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_734 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_257 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_603"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_256 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_736 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_257 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.33235103  || Decoder Loss:  0.43518162 Validation Decoder Loss:  0.39036006
Encoder Loss:  0.056581084  || Decoder Loss:  0.058978245 Validation Decoder Loss:  0.36470175
Encoder Loss:  0.0392736  || Decoder Loss:  0.035342082 Validation Decoder Loss:  0.36589515
Encoder Loss:  0.039263837  || Decoder Loss:  0.035329472 Validation Decoder Loss:  0.35121527
Encoder Loss:  0.03895326  || Decoder Loss:  0.034906007 Validation Decoder Loss:  0.34680936
Encoder Loss:  0.31450117  || Decoder Loss:  0.4079828 Validation Decoder Loss:  0.9590436
Encoder Loss:  0.37625146  || Decoder Loss:  0.49350408 Validation Decoder Loss:  1.0899377
Encoder Loss:  0.37967256  || Decoder Loss:  0.49876747 Validation Decoder Loss:  0.9929713
Encoder Loss:  0.37616765  || Decoder Loss:  0.49519172 Validation Decoder Loss:  0.9964284
Encoder Loss:  0.37620685  || Decoder Loss:  0.4955541 Validation Decoder Loss:  0.99732774
Encoder Loss:  0.37572414  || Decoder Loss:  0.49489638 Validation Decoder Loss:  0.98887604
Encoder Loss:  0.37282443  || Decoder Loss:  0.4909364 Validation Decoder Loss:  1.0050254
Encoder Loss:  0.37422797  || Decoder Loss:  0.49284393 Validation Decoder Loss:  0.5250424
Encoder Loss:  0.23548666  || Decoder Loss:  0.30335033 Validation Decoder Loss:  0.40814644
Encoder Loss:  0.12147255  || Decoder Loss:  0.14762096 Validation Decoder Loss:  0.35866782
Encoder Loss:  0.03913377  || Decoder Loss:  0.035155013 Validation Decoder Loss:  0.3524994
Encoder Loss:  0.039275285  || Decoder Loss:  0.035322122 Validation Decoder Loss:  0.34890258
Encoder Loss:  0.039387558  || Decoder Loss:  0.03550385 Validation Decoder Loss:  0.34545204
Encoder Loss:  0.039479114  || Decoder Loss:  0.035628587 Validation Decoder Loss:  0.3565833
Encoder Loss:  0.03934348  || Decoder Loss:  0.035442688 Validation Decoder Loss:  0.37285465
Encoder Loss:  0.03944841  || Decoder Loss:  0.035585944 Validation Decoder Loss:  0.34604347
Encoder Loss:  0.039791886  || Decoder Loss:  0.03605359 Validation Decoder Loss:  0.3345679
Encoder Loss:  0.07854067  || Decoder Loss:  0.08897937 Validation Decoder Loss:  0.34272733
Encoder Loss:  0.08846231  || Decoder Loss:  0.10253241 Validation Decoder Loss:  0.9963129
Encoder Loss:  0.23724513  || Decoder Loss:  0.3057511 Validation Decoder Loss:  0.34484822
Encoder Loss:  0.039790943  || Decoder Loss:  0.036051277 Validation Decoder Loss:  0.34115905
Encoder Loss:  0.038863953  || Decoder Loss:  0.034788024 Validation Decoder Loss:  0.34116387
Encoder Loss:  0.13639969  || Decoder Loss:  0.16800562 Validation Decoder Loss:  0.9911595
Encoder Loss:  0.13687168  || Decoder Loss:  0.16864513 Validation Decoder Loss:  0.3459565
Encoder Loss:  0.038829323  || Decoder Loss:  0.034741472 Validation Decoder Loss:  0.3468978
Encoder Loss:  0.038859654  || Decoder Loss:  0.034782704 Validation Decoder Loss:  0.3421778
Encoder Loss:  0.03888011  || Decoder Loss:  0.034810185 Validation Decoder Loss:  0.34316355
Encoder Loss:  0.039347872  || Decoder Loss:  0.035448957 Validation Decoder Loss:  0.34868613
Encoder Loss:  0.038979117  || Decoder Loss:  0.03494528 Validation Decoder Loss:  0.34276062
Encoder Loss:  0.038830347  || Decoder Loss:  0.0347417 Validation Decoder Loss:  0.34972447
Encoder Loss:  0.06342534  || Decoder Loss:  0.06818227 Validation Decoder Loss:  0.3748516
Encoder Loss:  0.061592165  || Decoder Loss:  0.06583247 Validation Decoder Loss:  0.38668072
Encoder Loss:  0.05786661  || Decoder Loss:  0.060744368 Validation Decoder Loss:  0.35628694
Encoder Loss:  0.054842588  || Decoder Loss:  0.056613617 Validation Decoder Loss:  0.34589908
Encoder Loss:  0.054798875  || Decoder Loss:  0.05655423 Validation Decoder Loss:  0.3473676
Model: siamese_net_lr_0.16718169072480546 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3473676
Model: "sequential_604"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_281 (Conv3D (None, 70, 9, 20, 1)      36        
_________________________________________________________________
dropout_738 (Dropout)        (None, 70, 9, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_282 (Conv3D (None, 74, 30, 20, 1)     111       
_________________________________________________________________
reshape_164 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_606"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_258 (Conv2D)          (None, 2500, 20, 1)       109       
_________________________________________________________________
dropout_740 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_259 (Conv2D)          (None, 2220, 20, 1)       282       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_607"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_258 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_742 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_259 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.17832646  || Decoder Loss:  0.12679824 Validation Decoder Loss:  0.379668
Encoder Loss:  0.052919317  || Decoder Loss:  0.055436306 Validation Decoder Loss:  0.37544364
Encoder Loss:  0.051668372  || Decoder Loss:  0.053140815 Validation Decoder Loss:  0.37120727
Encoder Loss:  0.050713204  || Decoder Loss:  0.051334877 Validation Decoder Loss:  0.36432552
Encoder Loss:  0.050075058  || Decoder Loss:  0.050128356 Validation Decoder Loss:  0.3591412
Encoder Loss:  0.049561687  || Decoder Loss:  0.04915309 Validation Decoder Loss:  0.3552083
Encoder Loss:  0.04906527  || Decoder Loss:  0.048208665 Validation Decoder Loss:  0.35153162
Encoder Loss:  0.04861339  || Decoder Loss:  0.047349066 Validation Decoder Loss:  0.3477952
Encoder Loss:  0.048171833  || Decoder Loss:  0.04650887 Validation Decoder Loss:  0.34391177
Encoder Loss:  0.047697607  || Decoder Loss:  0.045606125 Validation Decoder Loss:  0.3400014
Encoder Loss:  0.04717878  || Decoder Loss:  0.044618253 Validation Decoder Loss:  0.33703396
Encoder Loss:  0.046385106  || Decoder Loss:  0.043106895 Validation Decoder Loss:  0.3344918
Encoder Loss:  0.051123887  || Decoder Loss:  0.052130643 Validation Decoder Loss:  0.34884197
Encoder Loss:  0.049513508  || Decoder Loss:  0.049064323 Validation Decoder Loss:  0.33012205
Encoder Loss:  0.045900907  || Decoder Loss:  0.04218584 Validation Decoder Loss:  0.32803935
Encoder Loss:  0.04702503  || Decoder Loss:  0.04432542 Validation Decoder Loss:  0.3459546
Encoder Loss:  0.051916655  || Decoder Loss:  0.053640887 Validation Decoder Loss:  0.34080598
Encoder Loss:  0.051141366  || Decoder Loss:  0.052166395 Validation Decoder Loss:  0.3334849
Encoder Loss:  0.044043887  || Decoder Loss:  0.038650937 Validation Decoder Loss:  0.33593923
Encoder Loss:  0.041454304  || Decoder Loss:  0.033720344 Validation Decoder Loss:  0.3358225
Encoder Loss:  0.041295424  || Decoder Loss:  0.033416368 Validation Decoder Loss:  0.33611292
Encoder Loss:  0.04119762  || Decoder Loss:  0.033231545 Validation Decoder Loss:  0.33602732
Encoder Loss:  0.0411293  || Decoder Loss:  0.033103302 Validation Decoder Loss:  0.33607832
Encoder Loss:  0.041061226  || Decoder Loss:  0.032972053 Validation Decoder Loss:  0.33597505
Encoder Loss:  0.040990572  || Decoder Loss:  0.032836184 Validation Decoder Loss:  0.33569157
Encoder Loss:  0.040904187  || Decoder Loss:  0.03267354 Validation Decoder Loss:  0.33562326
Encoder Loss:  0.040809702  || Decoder Loss:  0.032492872 Validation Decoder Loss:  0.33537114
Encoder Loss:  0.04070517  || Decoder Loss:  0.032294583 Validation Decoder Loss:  0.33507267
Encoder Loss:  0.040590663  || Decoder Loss:  0.032077357 Validation Decoder Loss:  0.3344367
Encoder Loss:  0.040497497  || Decoder Loss:  0.031899966 Validation Decoder Loss:  0.334093
Encoder Loss:  0.04044794  || Decoder Loss:  0.031805307 Validation Decoder Loss:  0.33419177
Encoder Loss:  0.040420283  || Decoder Loss:  0.031751648 Validation Decoder Loss:  0.33424884
Encoder Loss:  0.040399108  || Decoder Loss:  0.03171276 Validation Decoder Loss:  0.3342388
Encoder Loss:  0.040383752  || Decoder Loss:  0.031683218 Validation Decoder Loss:  0.33435017
Encoder Loss:  0.040371828  || Decoder Loss:  0.031661373 Validation Decoder Loss:  0.33445096
Encoder Loss:  0.04036089  || Decoder Loss:  0.031641573 Validation Decoder Loss:  0.33468544
Encoder Loss:  0.04034611  || Decoder Loss:  0.0316135 Validation Decoder Loss:  0.33470464
Encoder Loss:  0.040332675  || Decoder Loss:  0.031586558 Validation Decoder Loss:  0.33424097
Encoder Loss:  0.040326234  || Decoder Loss:  0.031574976 Validation Decoder Loss:  0.33477643
Encoder Loss:  0.040329076  || Decoder Loss:  0.03157985 Validation Decoder Loss:  0.33446258
Model: siamese_net_lr_0.01256302530122299 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.33446258
Model: "sequential_609"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_260 (Conv2D)          (None, 2400, 20, 1)       209       
_________________________________________________________________
dropout_744 (Dropout)        (None, 2400, 20, 1)       0         
_________________________________________________________________
conv2d_261 (Conv2D)          (None, 2220, 20, 1)       182       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_610"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_260 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_746 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_261 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_611"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_284 (Conv3D (None, 74, 5, 20, 1)      12        
_________________________________________________________________
dropout_748 (Dropout)        (None, 74, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_285 (Conv3D (None, 74, 30, 20, 1)     11        
_________________________________________________________________
reshape_165 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_613"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_262 (Conv2D)          (None, 2420, 20, 1)       189       
_________________________________________________________________
dropout_750 (Dropout)        (None, 2420, 20, 1)       0         
_________________________________________________________________
conv2d_263 (Conv2D)          (None, 2220, 20, 1)       202       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_614"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_262 (Conv2D (None, 2260, 20, 1)       42        
_________________________________________________________________
dropout_752 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_263 (Conv2D (None, 2607, 20, 1)       349       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4021067  || Decoder Loss:  0.42384207 Validation Decoder Loss:  0.99552476
Encoder Loss:  0.46832103  || Decoder Loss:  0.5009085 Validation Decoder Loss:  0.99862117
Encoder Loss:  0.4669944  || Decoder Loss:  0.49948108 Validation Decoder Loss:  0.988602
Encoder Loss:  0.46619958  || Decoder Loss:  0.49844664 Validation Decoder Loss:  0.99874413
Encoder Loss:  0.4638927  || Decoder Loss:  0.49618745 Validation Decoder Loss:  0.99503565
Encoder Loss:  0.46329495  || Decoder Loss:  0.4956046 Validation Decoder Loss:  1.0023494
Encoder Loss:  0.4629646  || Decoder Loss:  0.49519637 Validation Decoder Loss:  0.9895772
Encoder Loss:  0.46224767  || Decoder Loss:  0.49451023 Validation Decoder Loss:  0.998531
Encoder Loss:  0.46233112  || Decoder Loss:  0.4945513 Validation Decoder Loss:  0.9936271
Encoder Loss:  0.46222472  || Decoder Loss:  0.49452087 Validation Decoder Loss:  0.9982907
Encoder Loss:  0.461889  || Decoder Loss:  0.49410346 Validation Decoder Loss:  0.99366397
Encoder Loss:  0.4618605  || Decoder Loss:  0.49414653 Validation Decoder Loss:  0.9986527
Encoder Loss:  0.46153  || Decoder Loss:  0.49373996 Validation Decoder Loss:  0.9934561
Encoder Loss:  0.46166027  || Decoder Loss:  0.49393678 Validation Decoder Loss:  1.005786
Encoder Loss:  0.46258453  || Decoder Loss:  0.49479493 Validation Decoder Loss:  0.9848179
Encoder Loss:  0.46268472  || Decoder Loss:  0.4947252 Validation Decoder Loss:  1.0034235
Encoder Loss:  0.46242684  || Decoder Loss:  0.4944053 Validation Decoder Loss:  0.9980277
Encoder Loss:  0.46211722  || Decoder Loss:  0.4942658 Validation Decoder Loss:  0.99078584
Encoder Loss:  0.4621433  || Decoder Loss:  0.49423707 Validation Decoder Loss:  0.9986259
Encoder Loss:  0.46216023  || Decoder Loss:  0.49420297 Validation Decoder Loss:  0.996395
Encoder Loss:  0.46192724  || Decoder Loss:  0.49398562 Validation Decoder Loss:  0.995994
Encoder Loss:  0.46183914  || Decoder Loss:  0.49391136 Validation Decoder Loss:  0.9955965
Encoder Loss:  0.46175125  || Decoder Loss:  0.49383458 Validation Decoder Loss:  0.99516964
Encoder Loss:  0.46165875  || Decoder Loss:  0.4937504 Validation Decoder Loss:  0.99469423
Encoder Loss:  0.4615575  || Decoder Loss:  0.49365512 Validation Decoder Loss:  0.9941391
Encoder Loss:  0.46110308  || Decoder Loss:  0.4934055 Validation Decoder Loss:  0.99327666
Encoder Loss:  0.46097133  || Decoder Loss:  0.4931703 Validation Decoder Loss:  0.9947916
Encoder Loss:  0.46080735  || Decoder Loss:  0.49312478 Validation Decoder Loss:  0.9936799
Encoder Loss:  0.4603942  || Decoder Loss:  0.49270615 Validation Decoder Loss:  0.9942653
Encoder Loss:  0.4601265  || Decoder Loss:  0.4923218 Validation Decoder Loss:  0.9932255
Encoder Loss:  0.4614496  || Decoder Loss:  0.49369496 Validation Decoder Loss:  0.99932706
Encoder Loss:  0.46971667  || Decoder Loss:  0.5026341 Validation Decoder Loss:  0.99089575
Encoder Loss:  0.46354753  || Decoder Loss:  0.49597654 Validation Decoder Loss:  1.0057087
Encoder Loss:  0.45767638  || Decoder Loss:  0.48974788 Validation Decoder Loss:  1.0051279
Encoder Loss:  0.45428598  || Decoder Loss:  0.4860901 Validation Decoder Loss:  0.962933
Encoder Loss:  0.42981833  || Decoder Loss:  0.4596891 Validation Decoder Loss:  0.91639054
Encoder Loss:  0.46448874  || Decoder Loss:  0.49709985 Validation Decoder Loss:  0.9404974
Encoder Loss:  0.45836473  || Decoder Loss:  0.49049214 Validation Decoder Loss:  0.94538397
Encoder Loss:  0.43816766  || Decoder Loss:  0.46869949 Validation Decoder Loss:  0.91788983
Encoder Loss:  0.4554599  || Decoder Loss:  0.48737076 Validation Decoder Loss:  0.9723963
Model: siamese_net_lr_0.7475741957575615 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9723963
Model: "sequential_616"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_264 (Conv2D)          (None, 2230, 20, 1)       379       
_________________________________________________________________
dropout_754 (Dropout)        (None, 2230, 20, 1)       0         
_________________________________________________________________
conv2d_265 (Conv2D)          (None, 2220, 20, 1)       12        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_617"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_264 (Conv2D (None, 2570, 20, 1)       352       
_________________________________________________________________
dropout_756 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_265 (Conv2D (None, 2607, 20, 1)       39        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_618"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_287 (Conv3D (None, 66, 10, 20, 1)     7         
_________________________________________________________________
dropout_758 (Dropout)        (None, 66, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_288 (Conv3D (None, 74, 30, 20, 1)     190       
_________________________________________________________________
reshape_166 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 197
Trainable params: 197
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_620"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_266 (Conv2D)          (None, 2590, 20, 1)       19        
_________________________________________________________________
dropout_760 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_267 (Conv2D)          (None, 2220, 20, 1)       372       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_621"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_266 (Conv2D (None, 2480, 20, 1)       262       
_________________________________________________________________
dropout_762 (Dropout)        (None, 2480, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_267 (Conv2D (None, 2607, 20, 1)       129       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1318399  || Decoder Loss:  0.49974295 Validation Decoder Loss:  0.9943498
Encoder Loss:  0.11853049  || Decoder Loss:  0.5048985 Validation Decoder Loss:  0.99655193
Encoder Loss:  0.11620784  || Decoder Loss:  0.494686 Validation Decoder Loss:  1.0157977
Encoder Loss:  0.11740831  || Decoder Loss:  0.5009534 Validation Decoder Loss:  1.0111809
Encoder Loss:  0.11626582  || Decoder Loss:  0.49670905 Validation Decoder Loss:  1.0148451
Encoder Loss:  0.116773516  || Decoder Loss:  0.49364758 Validation Decoder Loss:  1.0078726
Encoder Loss:  0.11634792  || Decoder Loss:  0.49662238 Validation Decoder Loss:  1.0190082
Encoder Loss:  0.115774214  || Decoder Loss:  0.4947038 Validation Decoder Loss:  1.0197263
Encoder Loss:  0.11669007  || Decoder Loss:  0.49534905 Validation Decoder Loss:  1.020797
Encoder Loss:  0.1173238  || Decoder Loss:  0.4952191 Validation Decoder Loss:  1.0162113
Encoder Loss:  0.11572346  || Decoder Loss:  0.4942814 Validation Decoder Loss:  1.0149276
Encoder Loss:  0.115591764  || Decoder Loss:  0.49372378 Validation Decoder Loss:  1.010632
Encoder Loss:  0.115607776  || Decoder Loss:  0.49346897 Validation Decoder Loss:  1.0105234
Encoder Loss:  0.11760224  || Decoder Loss:  0.49566388 Validation Decoder Loss:  0.9972748
Encoder Loss:  0.11602023  || Decoder Loss:  0.4970256 Validation Decoder Loss:  1.0021073
Encoder Loss:  0.11634133  || Decoder Loss:  0.49746498 Validation Decoder Loss:  1.0156645
Encoder Loss:  0.11618334  || Decoder Loss:  0.49634984 Validation Decoder Loss:  1.0322251
Encoder Loss:  0.11677881  || Decoder Loss:  0.49571654 Validation Decoder Loss:  1.0167801
Encoder Loss:  0.11578781  || Decoder Loss:  0.49504048 Validation Decoder Loss:  1.0130432
Encoder Loss:  0.11608234  || Decoder Loss:  0.49481612 Validation Decoder Loss:  1.0296648
Encoder Loss:  0.116951235  || Decoder Loss:  0.49510327 Validation Decoder Loss:  1.0149078
Encoder Loss:  0.11567779  || Decoder Loss:  0.49449039 Validation Decoder Loss:  1.0147655
Encoder Loss:  0.11565358  || Decoder Loss:  0.49437505 Validation Decoder Loss:  1.0179187
Encoder Loss:  0.11702595  || Decoder Loss:  0.49487436 Validation Decoder Loss:  1.0138671
Encoder Loss:  0.1155403  || Decoder Loss:  0.49377415 Validation Decoder Loss:  1.0132806
Encoder Loss:  0.11554259  || Decoder Loss:  0.49326527 Validation Decoder Loss:  1.0052184
Encoder Loss:  0.115636885  || Decoder Loss:  0.49330306 Validation Decoder Loss:  1.0446562
Encoder Loss:  0.11637666  || Decoder Loss:  0.49359503 Validation Decoder Loss:  1.006711
Encoder Loss:  0.11532812  || Decoder Loss:  0.4923693 Validation Decoder Loss:  1.0062947
Encoder Loss:  0.11570362  || Decoder Loss:  0.4923434 Validation Decoder Loss:  1.0066031
Encoder Loss:  0.11549635  || Decoder Loss:  0.49221906 Validation Decoder Loss:  1.0060455
Encoder Loss:  0.115470074  || Decoder Loss:  0.49298897 Validation Decoder Loss:  1.0047418
Encoder Loss:  0.11524542  || Decoder Loss:  0.49162605 Validation Decoder Loss:  1.0054388
Encoder Loss:  0.115121596  || Decoder Loss:  0.4907912 Validation Decoder Loss:  1.0133564
Encoder Loss:  0.119731404  || Decoder Loss:  0.5158278 Validation Decoder Loss:  1.0150211
Encoder Loss:  0.11584664  || Decoder Loss:  0.49554244 Validation Decoder Loss:  1.0158122
Encoder Loss:  0.1158263  || Decoder Loss:  0.49538925 Validation Decoder Loss:  1.0072597
Encoder Loss:  0.1161077  || Decoder Loss:  0.4955233 Validation Decoder Loss:  1.0148036
Encoder Loss:  0.115783006  || Decoder Loss:  0.49494618 Validation Decoder Loss:  1.016526
Encoder Loss:  0.11716451  || Decoder Loss:  0.494775 Validation Decoder Loss:  1.0170279
Model: siamese_net_lr_0.36991323715963836 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0170279
Model: "sequential_622"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_290 (Conv3D (None, 68, 30, 20, 1)     91        
_________________________________________________________________
dropout_764 (Dropout)        (None, 68, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_291 (Conv3D (None, 74, 30, 20, 1)     8         
_________________________________________________________________
reshape_167 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_624"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_268 (Conv2D)          (None, 2530, 20, 1)       79        
_________________________________________________________________
dropout_766 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_269 (Conv2D)          (None, 2220, 20, 1)       312       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_625"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_268 (Conv2D (None, 2390, 20, 1)       172       
_________________________________________________________________
dropout_768 (Dropout)        (None, 2390, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_269 (Conv2D (None, 2607, 20, 1)       219       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.106417015  || Decoder Loss:  0.14821957 Validation Decoder Loss:  0.37566668
Encoder Loss:  0.055301875  || Decoder Loss:  0.05986529 Validation Decoder Loss:  0.36740157
Encoder Loss:  0.056388095  || Decoder Loss:  0.059529252 Validation Decoder Loss:  0.35138965
Encoder Loss:  0.056002203  || Decoder Loss:  0.06017416 Validation Decoder Loss:  0.36459076
Encoder Loss:  0.05380132  || Decoder Loss:  0.05824255 Validation Decoder Loss:  0.36513817
Encoder Loss:  0.05368819  || Decoder Loss:  0.05785227 Validation Decoder Loss:  0.36304533
Encoder Loss:  0.054015025  || Decoder Loss:  0.058148183 Validation Decoder Loss:  0.37118804
Encoder Loss:  0.054663368  || Decoder Loss:  0.058319822 Validation Decoder Loss:  0.35795778
Encoder Loss:  0.053439986  || Decoder Loss:  0.05741465 Validation Decoder Loss:  0.35495433
Encoder Loss:  0.053042755  || Decoder Loss:  0.05638928 Validation Decoder Loss:  0.350557
Encoder Loss:  0.05701312  || Decoder Loss:  0.056733325 Validation Decoder Loss:  0.34843588
Encoder Loss:  0.054660305  || Decoder Loss:  0.058063794 Validation Decoder Loss:  0.3478706
Encoder Loss:  0.053484727  || Decoder Loss:  0.057544094 Validation Decoder Loss:  0.3483315
Encoder Loss:  0.05313364  || Decoder Loss:  0.056794647 Validation Decoder Loss:  0.34849024
Encoder Loss:  0.052933205  || Decoder Loss:  0.056361694 Validation Decoder Loss:  0.34949002
Encoder Loss:  0.05278448  || Decoder Loss:  0.056031685 Validation Decoder Loss:  0.34987545
Encoder Loss:  0.0536888  || Decoder Loss:  0.05799343 Validation Decoder Loss:  0.35071295
Encoder Loss:  0.052678905  || Decoder Loss:  0.055728313 Validation Decoder Loss:  0.34961304
Encoder Loss:  0.05262687  || Decoder Loss:  0.055652853 Validation Decoder Loss:  0.3493303
Encoder Loss:  0.052666176  || Decoder Loss:  0.055549856 Validation Decoder Loss:  0.34929615
Encoder Loss:  0.053256873  || Decoder Loss:  0.055658273 Validation Decoder Loss:  0.34913447
Encoder Loss:  0.05318468  || Decoder Loss:  0.056037836 Validation Decoder Loss:  0.34813407
Encoder Loss:  0.053833865  || Decoder Loss:  0.056666404 Validation Decoder Loss:  0.34861743
Encoder Loss:  0.052790962  || Decoder Loss:  0.056046132 Validation Decoder Loss:  0.34900936
Encoder Loss:  0.052719105  || Decoder Loss:  0.0558462 Validation Decoder Loss:  0.34880298
Encoder Loss:  0.05273741  || Decoder Loss:  0.055788994 Validation Decoder Loss:  0.34956902
Encoder Loss:  0.053749442  || Decoder Loss:  0.05596609 Validation Decoder Loss:  0.34876764
Encoder Loss:  0.05274095  || Decoder Loss:  0.055827137 Validation Decoder Loss:  0.34839106
Encoder Loss:  0.05259396  || Decoder Loss:  0.05554686 Validation Decoder Loss:  0.34501666
Encoder Loss:  0.05342412  || Decoder Loss:  0.05581821 Validation Decoder Loss:  0.34561902
Encoder Loss:  0.053598866  || Decoder Loss:  0.05670791 Validation Decoder Loss:  0.34497774
Encoder Loss:  0.05293441  || Decoder Loss:  0.056128472 Validation Decoder Loss:  0.34507906
Encoder Loss:  0.052633382  || Decoder Loss:  0.055686627 Validation Decoder Loss:  0.3457725
Encoder Loss:  0.052880332  || Decoder Loss:  0.056071796 Validation Decoder Loss:  0.34591073
Encoder Loss:  0.059747532  || Decoder Loss:  0.06664569 Validation Decoder Loss:  0.36319175
Encoder Loss:  0.05985802  || Decoder Loss:  0.07130942 Validation Decoder Loss:  0.36511368
Encoder Loss:  0.056848116  || Decoder Loss:  0.06490026 Validation Decoder Loss:  0.3512172
Encoder Loss:  0.05618213  || Decoder Loss:  0.06344974 Validation Decoder Loss:  0.35219485
Encoder Loss:  0.05584121  || Decoder Loss:  0.0627114 Validation Decoder Loss:  0.35383052
Encoder Loss:  0.055437613  || Decoder Loss:  0.061801087 Validation Decoder Loss:  0.3544246
Model: siamese_net_lr_0.22775271122426016 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35442457
Model: "sequential_627"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_270 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_770 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_271 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_628"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_270 (Conv2D (None, 2590, 20, 1)       372       
_________________________________________________________________
dropout_772 (Dropout)        (None, 2590, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_271 (Conv2D (None, 2607, 20, 1)       19        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_629"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_293 (Conv3D (None, 67, 20, 20, 1)     49        
_________________________________________________________________
dropout_774 (Dropout)        (None, 67, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_294 (Conv3D (None, 74, 30, 20, 1)     89        
_________________________________________________________________
reshape_168 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 138
Trainable params: 138
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_631"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_272 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_776 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_273 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_632"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_272 (Conv2D (None, 2580, 20, 1)       362       
_________________________________________________________________
dropout_778 (Dropout)        (None, 2580, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_273 (Conv2D (None, 2607, 20, 1)       29        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.59657013  || Decoder Loss:  0.61678785 Validation Decoder Loss:  0.38608304
Encoder Loss:  0.094883576  || Decoder Loss:  0.06728129 Validation Decoder Loss:  0.38395405
Encoder Loss:  0.16212434  || Decoder Loss:  0.14482827 Validation Decoder Loss:  0.5244541
Encoder Loss:  0.42250344  || Decoder Loss:  0.44551417 Validation Decoder Loss:  1.1174153
Encoder Loss:  0.44502747  || Decoder Loss:  0.47899956 Validation Decoder Loss:  0.9972015
Encoder Loss:  0.45901284  || Decoder Loss:  0.49645782 Validation Decoder Loss:  1.0011686
Encoder Loss:  0.442772  || Decoder Loss:  0.47877982 Validation Decoder Loss:  1.0048972
Encoder Loss:  0.43328816  || Decoder Loss:  0.4684241 Validation Decoder Loss:  1.0132622
Encoder Loss:  0.43106973  || Decoder Loss:  0.4660093 Validation Decoder Loss:  1.0056369
Encoder Loss:  0.4248017  || Decoder Loss:  0.45916608 Validation Decoder Loss:  1.001447
Encoder Loss:  0.40939754  || Decoder Loss:  0.44232455 Validation Decoder Loss:  1.0223229
Encoder Loss:  0.41455132  || Decoder Loss:  0.4479678 Validation Decoder Loss:  0.86179215
Encoder Loss:  0.42044476  || Decoder Loss:  0.4543631 Validation Decoder Loss:  0.99585414
Encoder Loss:  0.4346019  || Decoder Loss:  0.4698798 Validation Decoder Loss:  1.0130763
Encoder Loss:  0.42864296  || Decoder Loss:  0.4633534 Validation Decoder Loss:  0.91308665
Encoder Loss:  0.41744706  || Decoder Loss:  0.45114806 Validation Decoder Loss:  1.00479
Encoder Loss:  0.4449814  || Decoder Loss:  0.48123124 Validation Decoder Loss:  1.0193154
Encoder Loss:  0.4231382  || Decoder Loss:  0.45736748 Validation Decoder Loss:  0.99285704
Encoder Loss:  0.41719693  || Decoder Loss:  0.45090026 Validation Decoder Loss:  0.92385423
Encoder Loss:  0.38285244  || Decoder Loss:  0.41340157 Validation Decoder Loss:  0.6933999
Encoder Loss:  0.38191575  || Decoder Loss:  0.4123748 Validation Decoder Loss:  0.94970614
Encoder Loss:  0.4087737  || Decoder Loss:  0.4417045 Validation Decoder Loss:  0.93391764
Encoder Loss:  0.37402982  || Decoder Loss:  0.4037657 Validation Decoder Loss:  0.8278526
Encoder Loss:  0.21178848  || Decoder Loss:  0.22662559 Validation Decoder Loss:  0.5054513
Encoder Loss:  0.10900382  || Decoder Loss:  0.11439565 Validation Decoder Loss:  0.35684583
Encoder Loss:  0.045961447  || Decoder Loss:  0.04557127 Validation Decoder Loss:  0.33951363
Encoder Loss:  0.040346794  || Decoder Loss:  0.039445363 Validation Decoder Loss:  0.33453405
Encoder Loss:  0.0388495  || Decoder Loss:  0.037818547 Validation Decoder Loss:  0.33281022
Encoder Loss:  0.03783256  || Decoder Loss:  0.036705386 Validation Decoder Loss:  0.3328405
Encoder Loss:  0.037426695  || Decoder Loss:  0.03625754 Validation Decoder Loss:  0.33137047
Encoder Loss:  0.037542045  || Decoder Loss:  0.036377355 Validation Decoder Loss:  0.33264348
Encoder Loss:  0.03758377  || Decoder Loss:  0.03642946 Validation Decoder Loss:  0.33338282
Encoder Loss:  0.037679914  || Decoder Loss:  0.03653948 Validation Decoder Loss:  0.33210075
Encoder Loss:  0.03774069  || Decoder Loss:  0.036594957 Validation Decoder Loss:  0.3394014
Encoder Loss:  0.037991405  || Decoder Loss:  0.036873206 Validation Decoder Loss:  0.33269727
Encoder Loss:  0.03744007  || Decoder Loss:  0.03627134 Validation Decoder Loss:  0.33162516
Encoder Loss:  0.037677966  || Decoder Loss:  0.036534026 Validation Decoder Loss:  0.33252326
Encoder Loss:  0.037821043  || Decoder Loss:  0.036689244 Validation Decoder Loss:  0.33197471
Encoder Loss:  0.037849475  || Decoder Loss:  0.036717463 Validation Decoder Loss:  0.3323484
Encoder Loss:  0.037765294  || Decoder Loss:  0.03663157 Validation Decoder Loss:  0.3335154
Model: siamese_net_lr_0.6042171158283346 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3335154
Model: "sequential_633"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_296 (Conv3D (None, 64, 10, 20, 1)     3         
_________________________________________________________________
dropout_780 (Dropout)        (None, 64, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_297 (Conv3D (None, 74, 30, 20, 1)     232       
_________________________________________________________________
reshape_169 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 235
Trainable params: 235
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_635"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_274 (Conv2D)          (None, 2490, 20, 1)       119       
_________________________________________________________________
dropout_782 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_275 (Conv2D)          (None, 2220, 20, 1)       272       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_636"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_274 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_784 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_275 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4217176  || Decoder Loss:  0.5599711 Validation Decoder Loss:  0.8140503
Encoder Loss:  0.37135726  || Decoder Loss:  0.50346935 Validation Decoder Loss:  1.1103399
Encoder Loss:  0.37402672  || Decoder Loss:  0.50558245 Validation Decoder Loss:  1.0494409
Encoder Loss:  0.3661126  || Decoder Loss:  0.49616256 Validation Decoder Loss:  1.110276
Encoder Loss:  0.36657712  || Decoder Loss:  0.49735245 Validation Decoder Loss:  1.0230277
Encoder Loss:  0.36400014  || Decoder Loss:  0.4958936 Validation Decoder Loss:  1.0065644
Encoder Loss:  0.36444005  || Decoder Loss:  0.49555847 Validation Decoder Loss:  0.98835033
Encoder Loss:  0.3615466  || Decoder Loss:  0.49173737 Validation Decoder Loss:  1.0407571
Encoder Loss:  0.36372784  || Decoder Loss:  0.4948429 Validation Decoder Loss:  0.98524237
Encoder Loss:  0.36452714  || Decoder Loss:  0.49612758 Validation Decoder Loss:  1.0462182
Encoder Loss:  0.3645607  || Decoder Loss:  0.49641007 Validation Decoder Loss:  1.0138583
Encoder Loss:  0.36278138  || Decoder Loss:  0.49486506 Validation Decoder Loss:  0.95824057
Encoder Loss:  0.3705271  || Decoder Loss:  0.50454015 Validation Decoder Loss:  1.0037135
Encoder Loss:  0.37202644  || Decoder Loss:  0.50454587 Validation Decoder Loss:  1.0219123
Encoder Loss:  0.3705713  || Decoder Loss:  0.5054854 Validation Decoder Loss:  1.000529
Encoder Loss:  0.37156495  || Decoder Loss:  0.50645655 Validation Decoder Loss:  1.0009708
Encoder Loss:  0.37191242  || Decoder Loss:  0.50644493 Validation Decoder Loss:  0.9974915
Encoder Loss:  0.37092435  || Decoder Loss:  0.5055324 Validation Decoder Loss:  0.9831825
Encoder Loss:  0.3692463  || Decoder Loss:  0.5037608 Validation Decoder Loss:  0.9875523
Encoder Loss:  0.3683522  || Decoder Loss:  0.5030731 Validation Decoder Loss:  0.988083
Encoder Loss:  0.36791533  || Decoder Loss:  0.5016656 Validation Decoder Loss:  1.005429
Encoder Loss:  0.36579487  || Decoder Loss:  0.49940875 Validation Decoder Loss:  1.0002737
Encoder Loss:  0.36505505  || Decoder Loss:  0.49768594 Validation Decoder Loss:  1.0187297
Encoder Loss:  0.36346996  || Decoder Loss:  0.49660712 Validation Decoder Loss:  1.0155139
Encoder Loss:  0.36322263  || Decoder Loss:  0.49506202 Validation Decoder Loss:  1.0241078
Encoder Loss:  0.36343166  || Decoder Loss:  0.49573094 Validation Decoder Loss:  1.0152452
Encoder Loss:  0.3625396  || Decoder Loss:  0.49417263 Validation Decoder Loss:  1.0074439
Encoder Loss:  0.36221382  || Decoder Loss:  0.49398312 Validation Decoder Loss:  1.0100075
Encoder Loss:  0.3625362  || Decoder Loss:  0.49455863 Validation Decoder Loss:  1.0403214
Encoder Loss:  0.36439654  || Decoder Loss:  0.4965606 Validation Decoder Loss:  1.0235405
Encoder Loss:  0.3625044  || Decoder Loss:  0.49525493 Validation Decoder Loss:  1.0202025
Encoder Loss:  0.36241326  || Decoder Loss:  0.49478814 Validation Decoder Loss:  1.0254972
Encoder Loss:  0.36337894  || Decoder Loss:  0.49511638 Validation Decoder Loss:  1.0180526
Encoder Loss:  0.36257964  || Decoder Loss:  0.49536836 Validation Decoder Loss:  1.0163009
Encoder Loss:  0.35906625  || Decoder Loss:  0.49110875 Validation Decoder Loss:  0.99677134
Encoder Loss:  0.1334431  || Decoder Loss:  0.16909516 Validation Decoder Loss:  0.3627243
Encoder Loss:  0.07225658  || Decoder Loss:  0.081766024 Validation Decoder Loss:  0.36380485
Encoder Loss:  0.071624905  || Decoder Loss:  0.08086385 Validation Decoder Loss:  0.36592233
Encoder Loss:  0.07083879  || Decoder Loss:  0.07974219 Validation Decoder Loss:  0.36631885
Encoder Loss:  0.06999717  || Decoder Loss:  0.078540966 Validation Decoder Loss:  0.36568534
Model: siamese_net_lr_0.5747369002135063 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.36568534
Model: "sequential_637"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_299 (Conv3D (None, 67, 10, 20, 1)     25        
_________________________________________________________________
dropout_786 (Dropout)        (None, 67, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_300 (Conv3D (None, 74, 30, 20, 1)     25        
_________________________________________________________________
reshape_170 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 50
Trainable params: 50
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_639"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_276 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_788 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_277 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_640"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_276 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_790 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_277 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.14069845  || Decoder Loss:  0.21559574 Validation Decoder Loss:  0.9766909
Encoder Loss:  0.25740328  || Decoder Loss:  0.44844356 Validation Decoder Loss:  0.5981226
Encoder Loss:  0.23254685  || Decoder Loss:  0.40068597 Validation Decoder Loss:  0.65895593
Encoder Loss:  0.23063952  || Decoder Loss:  0.3970292 Validation Decoder Loss:  0.48230183
Encoder Loss:  0.16632202  || Decoder Loss:  0.27346334 Validation Decoder Loss:  0.5706673
Encoder Loss:  0.1207128  || Decoder Loss:  0.18584007 Validation Decoder Loss:  0.37500682
Encoder Loss:  0.042214613  || Decoder Loss:  0.035026774 Validation Decoder Loss:  0.35956702
Encoder Loss:  0.041649953  || Decoder Loss:  0.03394709 Validation Decoder Loss:  0.36048773
Encoder Loss:  0.041593444  || Decoder Loss:  0.033830382 Validation Decoder Loss:  0.3557437
Encoder Loss:  0.041517213  || Decoder Loss:  0.03369145 Validation Decoder Loss:  0.35348377
Encoder Loss:  0.041493006  || Decoder Loss:  0.033647563 Validation Decoder Loss:  0.35074568
Encoder Loss:  0.041563615  || Decoder Loss:  0.033778857 Validation Decoder Loss:  0.35303584
Encoder Loss:  0.041612435  || Decoder Loss:  0.033877537 Validation Decoder Loss:  0.35328782
Encoder Loss:  0.041682  || Decoder Loss:  0.03401445 Validation Decoder Loss:  0.35004926
Encoder Loss:  0.041707244  || Decoder Loss:  0.034064185 Validation Decoder Loss:  0.35093254
Encoder Loss:  0.041739188  || Decoder Loss:  0.034123965 Validation Decoder Loss:  0.35459298
Encoder Loss:  0.041726418  || Decoder Loss:  0.034100406 Validation Decoder Loss:  0.35114267
Encoder Loss:  0.04167395  || Decoder Loss:  0.034000605 Validation Decoder Loss:  0.35006753
Encoder Loss:  0.041647926  || Decoder Loss:  0.03395051 Validation Decoder Loss:  0.3514072
Encoder Loss:  0.041679043  || Decoder Loss:  0.034005895 Validation Decoder Loss:  0.35598528
Encoder Loss:  0.041619796  || Decoder Loss:  0.033894856 Validation Decoder Loss:  0.3540067
Encoder Loss:  0.23952302  || Decoder Loss:  0.40060866 Validation Decoder Loss:  1.0026664
Encoder Loss:  0.2852415  || Decoder Loss:  0.5007901 Validation Decoder Loss:  1.0027354
Encoder Loss:  0.28442496  || Decoder Loss:  0.50002134 Validation Decoder Loss:  1.0044469
Encoder Loss:  0.28376395  || Decoder Loss:  0.49887967 Validation Decoder Loss:  1.0069933
Encoder Loss:  0.2827132  || Decoder Loss:  0.49670917 Validation Decoder Loss:  1.0104318
Encoder Loss:  0.28193223  || Decoder Loss:  0.49499816 Validation Decoder Loss:  1.0088017
Encoder Loss:  0.281243  || Decoder Loss:  0.4939389 Validation Decoder Loss:  1.0083296
Encoder Loss:  0.28054997  || Decoder Loss:  0.49270824 Validation Decoder Loss:  1.006685
Encoder Loss:  0.28020537  || Decoder Loss:  0.49194905 Validation Decoder Loss:  1.0123036
Encoder Loss:  0.279908  || Decoder Loss:  0.49139634 Validation Decoder Loss:  0.99978197
Encoder Loss:  0.24265094  || Decoder Loss:  0.4198908 Validation Decoder Loss:  0.456867
Encoder Loss:  0.07861663  || Decoder Loss:  0.104680374 Validation Decoder Loss:  0.41170806
Encoder Loss:  0.10590564  || Decoder Loss:  0.15719461 Validation Decoder Loss:  0.68608606
Encoder Loss:  0.0898349  || Decoder Loss:  0.12616831 Validation Decoder Loss:  0.34022695
Encoder Loss:  0.047310874  || Decoder Loss:  0.04465569 Validation Decoder Loss:  0.36248857
Encoder Loss:  0.057939105  || Decoder Loss:  0.06479806 Validation Decoder Loss:  0.45424178
Encoder Loss:  0.06748264  || Decoder Loss:  0.083166905 Validation Decoder Loss:  0.33660477
Encoder Loss:  0.04294254  || Decoder Loss:  0.036278684 Validation Decoder Loss:  0.33625412
Encoder Loss:  0.064030714  || Decoder Loss:  0.076569796 Validation Decoder Loss:  0.51238585
Model: siamese_net_lr_0.7333312229184215 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.51238585
Model: "sequential_641"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_302 (Conv3D (None, 68, 20, 20, 1)     41        
_________________________________________________________________
dropout_792 (Dropout)        (None, 68, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_303 (Conv3D (None, 74, 30, 20, 1)     78        
_________________________________________________________________
reshape_171 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 119
Trainable params: 119
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_643"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_278 (Conv2D)          (None, 2290, 20, 1)       319       
_________________________________________________________________
dropout_794 (Dropout)        (None, 2290, 20, 1)       0         
_________________________________________________________________
conv2d_279 (Conv2D)          (None, 2220, 20, 1)       72        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_644"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_278 (Conv2D (None, 2510, 20, 1)       292       
_________________________________________________________________
dropout_796 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_279 (Conv2D (None, 2607, 20, 1)       99        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.16080269  || Decoder Loss:  0.18114622 Validation Decoder Loss:  0.34014326
Encoder Loss:  0.036702026  || Decoder Loss:  0.034212727 Validation Decoder Loss:  0.34249616
Encoder Loss:  0.24519755  || Decoder Loss:  0.28127542 Validation Decoder Loss:  0.57891923
Encoder Loss:  0.35080773  || Decoder Loss:  0.40657902 Validation Decoder Loss:  0.99643505
Encoder Loss:  0.2834782  || Decoder Loss:  0.32676005 Validation Decoder Loss:  0.3432767
Encoder Loss:  0.0385973  || Decoder Loss:  0.03647188 Validation Decoder Loss:  0.3390605
Encoder Loss:  0.13049594  || Decoder Loss:  0.14528617 Validation Decoder Loss:  0.341097
Encoder Loss:  0.039666835  || Decoder Loss:  0.03774957 Validation Decoder Loss:  0.3371968
Encoder Loss:  0.038807668  || Decoder Loss:  0.03673085 Validation Decoder Loss:  0.33585083
Encoder Loss:  0.039702  || Decoder Loss:  0.03778803 Validation Decoder Loss:  0.3345986
Encoder Loss:  0.038091723  || Decoder Loss:  0.035883136 Validation Decoder Loss:  0.33425814
Encoder Loss:  0.037953407  || Decoder Loss:  0.035718426 Validation Decoder Loss:  0.3347329
Encoder Loss:  0.0377916  || Decoder Loss:  0.03552673 Validation Decoder Loss:  0.33417165
Encoder Loss:  0.20811705  || Decoder Loss:  0.2374134 Validation Decoder Loss:  0.33729106
Encoder Loss:  0.038311433  || Decoder Loss:  0.03614358 Validation Decoder Loss:  0.3355994
Encoder Loss:  0.039340083  || Decoder Loss:  0.037489887 Validation Decoder Loss:  0.38308015
Encoder Loss:  0.390172  || Decoder Loss:  0.4392736 Validation Decoder Loss:  1.599341
Encoder Loss:  0.43777788  || Decoder Loss:  0.50787485 Validation Decoder Loss:  0.8955619
Encoder Loss:  0.06101239  || Decoder Loss:  0.06301958 Validation Decoder Loss:  0.33736834
Encoder Loss:  0.03874919  || Decoder Loss:  0.03663813 Validation Decoder Loss:  0.33645582
Encoder Loss:  0.03828468  || Decoder Loss:  0.03608896 Validation Decoder Loss:  0.33711547
Encoder Loss:  0.038383648  || Decoder Loss:  0.036204632 Validation Decoder Loss:  0.33650082
Encoder Loss:  0.038227767  || Decoder Loss:  0.03602363 Validation Decoder Loss:  0.33613056
Encoder Loss:  0.052433267  || Decoder Loss:  0.052830838 Validation Decoder Loss:  0.33237326
Encoder Loss:  0.06950921  || Decoder Loss:  0.07300746 Validation Decoder Loss:  0.33480608
Encoder Loss:  0.037899267  || Decoder Loss:  0.035639748 Validation Decoder Loss:  0.33691758
Encoder Loss:  0.038052  || Decoder Loss:  0.03579126 Validation Decoder Loss:  0.3378256
Encoder Loss:  0.066817746  || Decoder Loss:  0.069889754 Validation Decoder Loss:  0.3346386
Encoder Loss:  0.037907418  || Decoder Loss:  0.035647042 Validation Decoder Loss:  0.3355152
Encoder Loss:  0.0468085  || Decoder Loss:  0.046154257 Validation Decoder Loss:  0.33573854
Encoder Loss:  0.037973445  || Decoder Loss:  0.03571259 Validation Decoder Loss:  0.33226943
Encoder Loss:  0.044859696  || Decoder Loss:  0.043858748 Validation Decoder Loss:  0.337157
Encoder Loss:  0.068986386  || Decoder Loss:  0.07245415 Validation Decoder Loss:  0.33293903
Encoder Loss:  0.039992794  || Decoder Loss:  0.038119137 Validation Decoder Loss:  0.36148497
Encoder Loss:  0.06298037  || Decoder Loss:  0.06351194 Validation Decoder Loss:  0.3734745
Encoder Loss:  0.06238077  || Decoder Loss:  0.06467081 Validation Decoder Loss:  0.38307685
Encoder Loss:  0.05967447  || Decoder Loss:  0.061461214 Validation Decoder Loss:  0.36504605
Encoder Loss:  0.053967647  || Decoder Loss:  0.054696873 Validation Decoder Loss:  0.3545316
Encoder Loss:  0.05307056  || Decoder Loss:  0.053632904 Validation Decoder Loss:  0.35897171
Encoder Loss:  0.054747753  || Decoder Loss:  0.055623766 Validation Decoder Loss:  0.35432258
Model: siamese_net_lr_0.1488326028791797 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35432258
Model: "sequential_645"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_305 (Conv3D (None, 70, 23, 20, 1)     134       
_________________________________________________________________
dropout_798 (Dropout)        (None, 70, 23, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_306 (Conv3D (None, 74, 30, 20, 1)     41        
_________________________________________________________________
reshape_172 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 175
Trainable params: 175
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_647"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_280 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_800 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_281 (Conv2D)          (None, 2220, 20, 1)       222       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_648"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_280 (Conv2D (None, 2360, 20, 1)       142       
_________________________________________________________________
dropout_802 (Dropout)        (None, 2360, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_281 (Conv2D (None, 2607, 20, 1)       249       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.1392192  || Decoder Loss:  0.1516309 Validation Decoder Loss:  0.35965908
Encoder Loss:  0.055067264  || Decoder Loss:  0.06082293 Validation Decoder Loss:  0.3635903
Encoder Loss:  0.057125155  || Decoder Loss:  0.060613647 Validation Decoder Loss:  0.36578876
Encoder Loss:  0.06002872  || Decoder Loss:  0.06037429 Validation Decoder Loss:  0.36831713
Encoder Loss:  0.054811005  || Decoder Loss:  0.06013547 Validation Decoder Loss:  0.37100613
Encoder Loss:  0.0540611  || Decoder Loss:  0.05988765 Validation Decoder Loss:  0.37313402
Encoder Loss:  0.05311988  || Decoder Loss:  0.059635498 Validation Decoder Loss:  0.37449405
Encoder Loss:  0.052842945  || Decoder Loss:  0.059373975 Validation Decoder Loss:  0.3762136
Encoder Loss:  0.05271788  || Decoder Loss:  0.059104234 Validation Decoder Loss:  0.3784818
Encoder Loss:  0.05258013  || Decoder Loss:  0.058820896 Validation Decoder Loss:  0.38043827
Encoder Loss:  0.05246192  || Decoder Loss:  0.058513742 Validation Decoder Loss:  0.38263282
Encoder Loss:  0.052376922  || Decoder Loss:  0.058173515 Validation Decoder Loss:  0.3850766
Encoder Loss:  0.05223387  || Decoder Loss:  0.05778909 Validation Decoder Loss:  0.38718852
Encoder Loss:  0.052082404  || Decoder Loss:  0.057313908 Validation Decoder Loss:  0.3882684
Encoder Loss:  0.051887784  || Decoder Loss:  0.05665626 Validation Decoder Loss:  0.3859347
Encoder Loss:  0.051717628  || Decoder Loss:  0.056073967 Validation Decoder Loss:  0.37711278
Encoder Loss:  0.051758174  || Decoder Loss:  0.05594691 Validation Decoder Loss:  0.3792011
Encoder Loss:  0.051893335  || Decoder Loss:  0.05586166 Validation Decoder Loss:  0.37851763
Encoder Loss:  0.05164794  || Decoder Loss:  0.055775035 Validation Decoder Loss:  0.37827808
Encoder Loss:  0.05157547  || Decoder Loss:  0.055593405 Validation Decoder Loss:  0.3777392
Encoder Loss:  0.051455542  || Decoder Loss:  0.05524 Validation Decoder Loss:  0.376627
Encoder Loss:  0.051205482  || Decoder Loss:  0.054344364 Validation Decoder Loss:  0.3728811
Encoder Loss:  0.050695058  || Decoder Loss:  0.05243795 Validation Decoder Loss:  0.3555565
Encoder Loss:  0.050535355  || Decoder Loss:  0.051871654 Validation Decoder Loss:  0.3578673
Encoder Loss:  0.050512683  || Decoder Loss:  0.051784143 Validation Decoder Loss:  0.3570156
Encoder Loss:  0.050490435  || Decoder Loss:  0.05171321 Validation Decoder Loss:  0.3568629
Encoder Loss:  0.050472613  || Decoder Loss:  0.051658973 Validation Decoder Loss:  0.35646775
Encoder Loss:  0.05045642  || Decoder Loss:  0.051598154 Validation Decoder Loss:  0.3562352
Encoder Loss:  0.05043759  || Decoder Loss:  0.051540148 Validation Decoder Loss:  0.3559609
Encoder Loss:  0.05042286  || Decoder Loss:  0.05148396 Validation Decoder Loss:  0.35572037
Encoder Loss:  0.050411616  || Decoder Loss:  0.051438857 Validation Decoder Loss:  0.3556178
Encoder Loss:  0.05042566  || Decoder Loss:  0.051398613 Validation Decoder Loss:  0.35503748
Encoder Loss:  0.05040379  || Decoder Loss:  0.05133992 Validation Decoder Loss:  0.35527438
Encoder Loss:  0.050448284  || Decoder Loss:  0.05130179 Validation Decoder Loss:  0.3553088
Encoder Loss:  0.05271297  || Decoder Loss:  0.051441647 Validation Decoder Loss:  0.35632345
Encoder Loss:  0.07691064  || Decoder Loss:  0.05143883 Validation Decoder Loss:  0.3559227
Encoder Loss:  0.06558037  || Decoder Loss:  0.05150383 Validation Decoder Loss:  0.35427684
Encoder Loss:  0.053242516  || Decoder Loss:  0.05142995 Validation Decoder Loss:  0.35273197
Encoder Loss:  0.05053025  || Decoder Loss:  0.05140718 Validation Decoder Loss:  0.35306716
Encoder Loss:  0.05039085  || Decoder Loss:  0.051314477 Validation Decoder Loss:  0.35313156
Model: siamese_net_lr_0.4748756685609385 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.35313156
Model: "sequential_649"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_308 (Conv3D (None, 67, 20, 20, 1)     49        
_________________________________________________________________
dropout_804 (Dropout)        (None, 67, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_309 (Conv3D (None, 74, 30, 20, 1)     89        
_________________________________________________________________
reshape_173 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 138
Trainable params: 138
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_651"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_282 (Conv2D)          (None, 2260, 20, 1)       349       
_________________________________________________________________
dropout_806 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_283 (Conv2D)          (None, 2220, 20, 1)       42        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_652"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_282 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_808 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_283 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.4600713  || Decoder Loss:  0.49751365 Validation Decoder Loss:  0.7316147
Encoder Loss:  0.44482365  || Decoder Loss:  0.48584098 Validation Decoder Loss:  0.95845234
Encoder Loss:  0.45260745  || Decoder Loss:  0.49037045 Validation Decoder Loss:  1.015836
Encoder Loss:  0.45321652  || Decoder Loss:  0.49533734 Validation Decoder Loss:  1.0197825
Encoder Loss:  0.45134336  || Decoder Loss:  0.49328044 Validation Decoder Loss:  1.0136327
Encoder Loss:  0.44687203  || Decoder Loss:  0.4883175 Validation Decoder Loss:  1.0227339
Encoder Loss:  0.44376  || Decoder Loss:  0.48486215 Validation Decoder Loss:  1.0623056
Encoder Loss:  0.454543  || Decoder Loss:  0.49675274 Validation Decoder Loss:  1.0178851
Encoder Loss:  0.4477153  || Decoder Loss:  0.4892642 Validation Decoder Loss:  1.0205939
Encoder Loss:  0.24718939  || Decoder Loss:  0.26779675 Validation Decoder Loss:  0.33803123
Encoder Loss:  0.041922864  || Decoder Loss:  0.041076165 Validation Decoder Loss:  0.3336774
Encoder Loss:  0.039387032  || Decoder Loss:  0.03827692 Validation Decoder Loss:  0.33363134
Encoder Loss:  0.0621133  || Decoder Loss:  0.06337582 Validation Decoder Loss:  0.3346489
Encoder Loss:  0.038223296  || Decoder Loss:  0.036991995 Validation Decoder Loss:  0.3335183
Encoder Loss:  0.25180075  || Decoder Loss:  0.27287072 Validation Decoder Loss:  1.0036418
Encoder Loss:  0.44886148  || Decoder Loss:  0.4905525 Validation Decoder Loss:  0.99283814
Encoder Loss:  0.22860956  || Decoder Loss:  0.24727894 Validation Decoder Loss:  0.33393657
Encoder Loss:  0.03822739  || Decoder Loss:  0.036996633 Validation Decoder Loss:  0.3336349
Encoder Loss:  0.06468886  || Decoder Loss:  0.066217534 Validation Decoder Loss:  0.33433667
Encoder Loss:  0.038162515  || Decoder Loss:  0.03692513 Validation Decoder Loss:  0.33195597
Encoder Loss:  0.038478363  || Decoder Loss:  0.03727382 Validation Decoder Loss:  0.33489457
Encoder Loss:  0.40943545  || Decoder Loss:  0.44696075 Validation Decoder Loss:  1.0158434
Encoder Loss:  0.13481587  || Decoder Loss:  0.14368097 Validation Decoder Loss:  0.3397017
Encoder Loss:  0.03830206  || Decoder Loss:  0.037078712 Validation Decoder Loss:  0.33827567
Encoder Loss:  0.038228337  || Decoder Loss:  0.036997214 Validation Decoder Loss:  0.33729434
Encoder Loss:  0.051512197  || Decoder Loss:  0.0516696 Validation Decoder Loss:  0.33911958
Encoder Loss:  0.03778154  || Decoder Loss:  0.03650367 Validation Decoder Loss:  0.33595654
Encoder Loss:  0.0380617  || Decoder Loss:  0.036813065 Validation Decoder Loss:  0.33566612
Encoder Loss:  0.04041939  || Decoder Loss:  0.039417107 Validation Decoder Loss:  0.33880845
Encoder Loss:  0.037762824  || Decoder Loss:  0.036482435 Validation Decoder Loss:  0.33533743
Encoder Loss:  0.037966486  || Decoder Loss:  0.036707968 Validation Decoder Loss:  0.34728605
Encoder Loss:  0.03983602  || Decoder Loss:  0.038772844 Validation Decoder Loss:  0.34337142
Encoder Loss:  0.03776251  || Decoder Loss:  0.036482576 Validation Decoder Loss:  0.3363541
Encoder Loss:  0.22064997  || Decoder Loss:  0.23848614 Validation Decoder Loss:  1.026993
Encoder Loss:  0.4355034  || Decoder Loss:  0.47579753 Validation Decoder Loss:  0.9967264
Encoder Loss:  0.4424934  || Decoder Loss:  0.48351815 Validation Decoder Loss:  0.95410955
Encoder Loss:  0.2291616  || Decoder Loss:  0.2478877 Validation Decoder Loss:  0.334328
Encoder Loss:  0.2940708  || Decoder Loss:  0.319534 Validation Decoder Loss:  1.0265672
Encoder Loss:  0.45260105  || Decoder Loss:  0.49468228 Validation Decoder Loss:  1.0208564
Encoder Loss:  0.45283586  || Decoder Loss:  0.49494255 Validation Decoder Loss:  1.0057203
2019-11-21 00:47:34.221296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Model: siamese_net_lr_0.3749949804330092 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0057203
Model: "sequential_653"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_311 (Conv3D (None, 67, 20, 20, 1)     17        
_________________________________________________________________
dropout_810 (Dropout)        (None, 67, 20, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_312 (Conv3D (None, 74, 30, 20, 1)     89        
_________________________________________________________________
reshape_174 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 106
Trainable params: 106
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_655"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_284 (Conv2D)          (None, 2220, 20, 1)       389       
_________________________________________________________________
dropout_812 (Dropout)        (None, 2220, 20, 1)       0         
_________________________________________________________________
conv2d_285 (Conv2D)          (None, 2220, 20, 1)       2         
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_656"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_284 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_814 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_285 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.13136746  || Decoder Loss:  0.40690136 Validation Decoder Loss:  0.99825966
Encoder Loss:  0.0924268  || Decoder Loss:  0.49504155 Validation Decoder Loss:  0.84109366
Encoder Loss:  0.11244528  || Decoder Loss:  0.44394767 Validation Decoder Loss:  1.0020839
Encoder Loss:  0.0931604  || Decoder Loss:  0.5018139 Validation Decoder Loss:  0.9733741
Encoder Loss:  0.12327888  || Decoder Loss:  0.43705818 Validation Decoder Loss:  1.0306199
Encoder Loss:  0.09198566  || Decoder Loss:  0.4948115 Validation Decoder Loss:  1.0071435
Encoder Loss:  0.09276203  || Decoder Loss:  0.4961476 Validation Decoder Loss:  1.0151882
Encoder Loss:  0.09214818  || Decoder Loss:  0.49409053 Validation Decoder Loss:  1.0139172
Encoder Loss:  0.093341395  || Decoder Loss:  0.49617222 Validation Decoder Loss:  0.9614975
Encoder Loss:  0.097909406  || Decoder Loss:  0.48561043 Validation Decoder Loss:  1.0280548
Encoder Loss:  0.0922822  || Decoder Loss:  0.4952564 Validation Decoder Loss:  0.91963136
Encoder Loss:  0.09566316  || Decoder Loss:  0.4914111 Validation Decoder Loss:  1.0342716
Encoder Loss:  0.09343141  || Decoder Loss:  0.49691144 Validation Decoder Loss:  1.011461
Encoder Loss:  0.09194095  || Decoder Loss:  0.49327713 Validation Decoder Loss:  1.0091171
Encoder Loss:  0.09209367  || Decoder Loss:  0.49250302 Validation Decoder Loss:  0.97282135
Encoder Loss:  0.09915955  || Decoder Loss:  0.49507454 Validation Decoder Loss:  1.0212957
Encoder Loss:  0.0920033  || Decoder Loss:  0.49408844 Validation Decoder Loss:  1.0004836
Encoder Loss:  0.09239824  || Decoder Loss:  0.49392793 Validation Decoder Loss:  1.0011061
Encoder Loss:  0.091653325  || Decoder Loss:  0.4909549 Validation Decoder Loss:  1.0030962
Encoder Loss:  0.08249992  || Decoder Loss:  0.39343208 Validation Decoder Loss:  0.3542867
Encoder Loss:  0.05959746  || Decoder Loss:  0.12782228 Validation Decoder Loss:  0.3414955
Encoder Loss:  0.04945813  || Decoder Loss:  0.04281708 Validation Decoder Loss:  0.33906522
Encoder Loss:  0.04919478  || Decoder Loss:  0.040220402 Validation Decoder Loss:  0.33342463
Encoder Loss:  0.049726304  || Decoder Loss:  0.04497084 Validation Decoder Loss:  0.3343595
Encoder Loss:  0.04913381  || Decoder Loss:  0.04051093 Validation Decoder Loss:  0.40822327
Encoder Loss:  0.10668037  || Decoder Loss:  0.46321055 Validation Decoder Loss:  1.0272627
Encoder Loss:  0.091310285  || Decoder Loss:  0.48710334 Validation Decoder Loss:  1.3056653
Encoder Loss:  0.089662276  || Decoder Loss:  0.46942198 Validation Decoder Loss:  1.0559475
Encoder Loss:  0.09157919  || Decoder Loss:  0.4870822 Validation Decoder Loss:  0.87598133
Encoder Loss:  0.09448294  || Decoder Loss:  0.51889724 Validation Decoder Loss:  1.0056922
Encoder Loss:  0.092038915  || Decoder Loss:  0.4952254 Validation Decoder Loss:  0.999077
Encoder Loss:  0.0926275  || Decoder Loss:  0.49755228 Validation Decoder Loss:  1.0137542
Encoder Loss:  0.092076175  || Decoder Loss:  0.49474633 Validation Decoder Loss:  1.0214903
Encoder Loss:  0.091916494  || Decoder Loss:  0.4930086 Validation Decoder Loss:  0.88945043
Encoder Loss:  0.09686249  || Decoder Loss:  0.5320916 Validation Decoder Loss:  1.0095186
Encoder Loss:  0.0919039  || Decoder Loss:  0.49444398 Validation Decoder Loss:  1.0132052
Encoder Loss:  0.09233819  || Decoder Loss:  0.49866268 Validation Decoder Loss:  1.0130451
Encoder Loss:  0.09209656  || Decoder Loss:  0.4954687 Validation Decoder Loss:  1.2638252
Encoder Loss:  0.09458917  || Decoder Loss:  0.5015413 Validation Decoder Loss:  1.0103737
Encoder Loss:  0.09172923  || Decoder Loss:  0.4921965 Validation Decoder Loss:  1.0294077
Model: siamese_net_lr_0.1295774673236966 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0294077
Model: "sequential_657"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_314 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_816 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_315 (Conv3D (None, 74, 30, 20, 1)     99        
_________________________________________________________________
reshape_175 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 105
Trainable params: 105
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_659"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_286 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_818 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_287 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_660"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_286 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_820 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_287 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.064372204 Validation Decoder Loss:  0.37631762
Encoder Loss:  0.41641414  || Decoder Loss:  0.06437221 Validation Decoder Loss:  0.37631762
Model: siamese_net_lr_1e-14 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37631762
Model: "sequential_661"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_317 (Conv3D (None, 65, 10, 20, 1)     13        
_________________________________________________________________
dropout_822 (Dropout)        (None, 65, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_318 (Conv3D (None, 74, 30, 20, 1)     121       
_________________________________________________________________
reshape_176 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 134
Trainable params: 134
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_663"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_288 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_824 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_289 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_664"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_288 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_826 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_289 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.06617491  || Decoder Loss:  0.060237393 Validation Decoder Loss:  0.36065602
Encoder Loss:  0.054329775  || Decoder Loss:  0.059951257 Validation Decoder Loss:  0.36369136
Encoder Loss:  0.052514955  || Decoder Loss:  0.05820868 Validation Decoder Loss:  0.3494131
Encoder Loss:  0.1573007  || Decoder Loss:  0.4852615 Validation Decoder Loss:  1.0004771
Encoder Loss:  0.1510337  || Decoder Loss:  0.49500453 Validation Decoder Loss:  1.0008032
Encoder Loss:  0.14582731  || Decoder Loss:  0.49477696 Validation Decoder Loss:  1.0008533
Encoder Loss:  0.14570309  || Decoder Loss:  0.49452826 Validation Decoder Loss:  1.0006841
Encoder Loss:  0.14518255  || Decoder Loss:  0.49212372 Validation Decoder Loss:  1.0125611
Encoder Loss:  0.14711016  || Decoder Loss:  0.50094783 Validation Decoder Loss:  0.99587727
Encoder Loss:  0.14719437  || Decoder Loss:  0.5012176 Validation Decoder Loss:  0.99726987
Encoder Loss:  0.09300902  || Decoder Loss:  0.24975857 Validation Decoder Loss:  0.36871183
Encoder Loss:  0.055665903  || Decoder Loss:  0.07629504 Validation Decoder Loss:  0.37583032
Encoder Loss:  0.055363346  || Decoder Loss:  0.07488748 Validation Decoder Loss:  0.37082824
Encoder Loss:  0.13553952  || Decoder Loss:  0.44732884 Validation Decoder Loss:  1.00367
Encoder Loss:  0.14655642  || Decoder Loss:  0.49850643 Validation Decoder Loss:  1.0011265
Encoder Loss:  0.1469455  || Decoder Loss:  0.4997582 Validation Decoder Loss:  1.0013808
Encoder Loss:  0.14667238  || Decoder Loss:  0.4990256 Validation Decoder Loss:  1.0031629
Encoder Loss:  0.14662726  || Decoder Loss:  0.4988406 Validation Decoder Loss:  1.0034397
Encoder Loss:  0.12990566  || Decoder Loss:  0.4211523 Validation Decoder Loss:  1.2035202
Encoder Loss:  0.13652372  || Decoder Loss:  0.4518769 Validation Decoder Loss:  0.9941204
Encoder Loss:  0.14112651  || Decoder Loss:  0.47191605 Validation Decoder Loss:  1.6317333
Encoder Loss:  0.14784855  || Decoder Loss:  0.5045298 Validation Decoder Loss:  1.0071769
Encoder Loss:  0.14662987  || Decoder Loss:  0.49886695 Validation Decoder Loss:  1.0112311
Encoder Loss:  0.1465809  || Decoder Loss:  0.49863082 Validation Decoder Loss:  1.0098089
Encoder Loss:  0.147246  || Decoder Loss:  0.5017175 Validation Decoder Loss:  1.0094197
Encoder Loss:  0.119253665  || Decoder Loss:  0.37166962 Validation Decoder Loss:  1.0182931
Encoder Loss:  0.14168695  || Decoder Loss:  0.47550923 Validation Decoder Loss:  1.0051906
Encoder Loss:  0.14692354  || Decoder Loss:  0.50021994 Validation Decoder Loss:  1.0040566
Encoder Loss:  0.14629745  || Decoder Loss:  0.4973018 Validation Decoder Loss:  0.922675
Encoder Loss:  0.09174712  || Decoder Loss:  0.24389252 Validation Decoder Loss:  1.0496662
Encoder Loss:  0.14728823  || Decoder Loss:  0.5018971 Validation Decoder Loss:  0.9968324
Encoder Loss:  0.14707202  || Decoder Loss:  0.50088763 Validation Decoder Loss:  0.9904709
Encoder Loss:  0.14973432  || Decoder Loss:  0.51303965 Validation Decoder Loss:  1.0025542
Encoder Loss:  0.14737895  || Decoder Loss:  0.50233597 Validation Decoder Loss:  0.9973355
Encoder Loss:  0.14710802  || Decoder Loss:  0.50107104 Validation Decoder Loss:  0.99664867
Encoder Loss:  0.14707416  || Decoder Loss:  0.50090563 Validation Decoder Loss:  0.9966116
Encoder Loss:  0.14707379  || Decoder Loss:  0.5008881 Validation Decoder Loss:  0.99664116
Encoder Loss:  0.14705843  || Decoder Loss:  0.5008355 Validation Decoder Loss:  0.9966403
Encoder Loss:  0.1470343  || Decoder Loss:  0.5007189 Validation Decoder Loss:  0.99658847
Encoder Loss:  0.14675952  || Decoder Loss:  0.49944913 Validation Decoder Loss:  0.9995043
Model: siamese_net_lr_0.4291871327261711 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9995043
Model: "sequential_665"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_320 (Conv3D (None, 65, 22, 20, 1)     29        
_________________________________________________________________
dropout_828 (Dropout)        (None, 65, 22, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_321 (Conv3D (None, 74, 30, 20, 1)     91        
_________________________________________________________________
reshape_177 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 120
Trainable params: 120
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_667"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_290 (Conv2D)          (None, 2600, 20, 1)       9         
_________________________________________________________________
dropout_830 (Dropout)        (None, 2600, 20, 1)       0         
_________________________________________________________________
conv2d_291 (Conv2D)          (None, 2220, 20, 1)       382       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_668"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_290 (Conv2D (None, 2280, 20, 1)       62        
_________________________________________________________________
dropout_832 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_291 (Conv2D (None, 2607, 20, 1)       329       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.28363103  || Decoder Loss:  0.23352833 Validation Decoder Loss:  0.39032313
Encoder Loss:  0.18350586  || Decoder Loss:  0.07309662 Validation Decoder Loss:  0.40350327
Encoder Loss:  0.20473148  || Decoder Loss:  0.10653597 Validation Decoder Loss:  0.3853927
Encoder Loss:  0.28031677  || Decoder Loss:  0.23546484 Validation Decoder Loss:  1.6162694
Encoder Loss:  0.7518224  || Decoder Loss:  0.9235843 Validation Decoder Loss:  1.6166136
Encoder Loss:  0.75069565  || Decoder Loss:  0.9231278 Validation Decoder Loss:  1.6172321
Encoder Loss:  0.74794304  || Decoder Loss:  0.9213265 Validation Decoder Loss:  1.6175375
Encoder Loss:  0.49975678  || Decoder Loss:  0.5667671 Validation Decoder Loss:  0.38504803
Encoder Loss:  0.17926188  || Decoder Loss:  0.07554541 Validation Decoder Loss:  0.38558775
Encoder Loss:  0.17344229  || Decoder Loss:  0.075581275 Validation Decoder Loss:  0.38639307
Encoder Loss:  0.10691994  || Decoder Loss:  0.075853445 Validation Decoder Loss:  0.3870959
Encoder Loss:  0.088019006  || Decoder Loss:  0.076014206 Validation Decoder Loss:  0.38775977
Encoder Loss:  0.088418484  || Decoder Loss:  0.07621933 Validation Decoder Loss:  0.38818175
Encoder Loss:  0.16713008  || Decoder Loss:  0.18219757 Validation Decoder Loss:  0.639738
Encoder Loss:  0.2029741  || Decoder Loss:  0.2687855 Validation Decoder Loss:  0.3884887
Encoder Loss:  0.07631126  || Decoder Loss:  0.08097894 Validation Decoder Loss:  0.39032406
Encoder Loss:  0.43559295  || Decoder Loss:  0.6251198 Validation Decoder Loss:  1.5208277
Encoder Loss:  0.4341101  || Decoder Loss:  0.6254681 Validation Decoder Loss:  0.74193645
Encoder Loss:  0.1428245  || Decoder Loss:  0.18887204 Validation Decoder Loss:  0.57339895
Encoder Loss:  0.12036208  || Decoder Loss:  0.15516302 Validation Decoder Loss:  0.5569998
Encoder Loss:  0.20640707  || Decoder Loss:  0.2841617 Validation Decoder Loss:  1.1698622
Encoder Loss:  0.44415832  || Decoder Loss:  0.64084727 Validation Decoder Loss:  1.1694655
Encoder Loss:  0.5084244  || Decoder Loss:  0.73727095 Validation Decoder Loss:  1.3684014
Encoder Loss:  0.5406774  || Decoder Loss:  0.7856568 Validation Decoder Loss:  1.3696134
Encoder Loss:  0.48473617  || Decoder Loss:  0.7017323 Validation Decoder Loss:  0.9514835
Encoder Loss:  0.25878114  || Decoder Loss:  0.3628971 Validation Decoder Loss:  0.8004608
Encoder Loss:  0.18956016  || Decoder Loss:  0.2590995 Validation Decoder Loss:  0.73494333
Encoder Loss:  0.26962492  || Decoder Loss:  0.3791507 Validation Decoder Loss:  1.5178533
Encoder Loss:  0.46911222  || Decoder Loss:  0.6783722 Validation Decoder Loss:  1.4141569
Encoder Loss:  0.43373176  || Decoder Loss:  0.62532336 Validation Decoder Loss:  1.4551256
Encoder Loss:  0.4459258  || Decoder Loss:  0.64362276 Validation Decoder Loss:  1.4905232
Encoder Loss:  0.45783177  || Decoder Loss:  0.6614884 Validation Decoder Loss:  1.4615935
Encoder Loss:  0.42221367  || Decoder Loss:  0.6080537 Validation Decoder Loss:  1.1656234
Encoder Loss:  0.33169365  || Decoder Loss:  0.4723252 Validation Decoder Loss:  1.0223752
Encoder Loss:  0.2626976  || Decoder Loss:  0.36886293 Validation Decoder Loss:  0.8222113
Encoder Loss:  0.36637515  || Decoder Loss:  0.52426344 Validation Decoder Loss:  1.1541704
Encoder Loss:  0.22384024  || Decoder Loss:  0.31057733 Validation Decoder Loss:  1.1534665
Encoder Loss:  0.3318687  || Decoder Loss:  0.47260678 Validation Decoder Loss:  1.2226464
Encoder Loss:  0.26784986  || Decoder Loss:  0.3766045 Validation Decoder Loss:  1.0136724
Encoder Loss:  0.26985845  || Decoder Loss:  0.37961808 Validation Decoder Loss:  1.1129684
Model: siamese_net_lr_0.6645582993279828 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.1129684
Model: "sequential_670"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_292 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_834 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_293 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_671"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_292 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_836 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_293 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_673"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_294 (Conv2D)          (None, 2410, 20, 1)       199       
_________________________________________________________________
dropout_838 (Dropout)        (None, 2410, 20, 1)       0         
_________________________________________________________________
conv2d_295 (Conv2D)          (None, 2220, 20, 1)       192       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_674"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_294 (Conv2D (None, 2340, 20, 1)       122       
_________________________________________________________________
dropout_840 (Dropout)        (None, 2340, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_295 (Conv2D (None, 2607, 20, 1)       269       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_675"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_323 (Conv3D (None, 70, 19, 20, 1)     78        
_________________________________________________________________
dropout_842 (Dropout)        (None, 70, 19, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_324 (Conv3D (None, 74, 30, 20, 1)     61        
_________________________________________________________________
reshape_178 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 139
Trainable params: 139
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_677"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_296 (Conv2D)          (None, 2280, 20, 1)       329       
_________________________________________________________________
dropout_844 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_297 (Conv2D)          (None, 2220, 20, 1)       62        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_678"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_296 (Conv2D (None, 2560, 20, 1)       342       
_________________________________________________________________
dropout_846 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_297 (Conv2D (None, 2607, 20, 1)       49        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.36982903  || Decoder Loss:  0.26543826 Validation Decoder Loss:  0.3936079
Encoder Loss:  0.33536902  || Decoder Loss:  0.059869356 Validation Decoder Loss:  0.3924665
Encoder Loss:  0.31533545  || Decoder Loss:  0.11094552 Validation Decoder Loss:  0.3702265
Encoder Loss:  0.18545362  || Decoder Loss:  0.4500995 Validation Decoder Loss:  0.37093478
Encoder Loss:  0.1698266  || Decoder Loss:  0.42557406 Validation Decoder Loss:  1.5743015
Encoder Loss:  0.15146227  || Decoder Loss:  0.50395787 Validation Decoder Loss:  0.37070495
Encoder Loss:  0.13857237  || Decoder Loss:  0.4305434 Validation Decoder Loss:  1.2491138
Encoder Loss:  0.15205835  || Decoder Loss:  0.55092317 Validation Decoder Loss:  1.487745
Encoder Loss:  0.14891525  || Decoder Loss:  0.51953584 Validation Decoder Loss:  0.9106723
Encoder Loss:  0.14419729  || Decoder Loss:  0.49644905 Validation Decoder Loss:  0.47960195
Encoder Loss:  0.12962538  || Decoder Loss:  0.4684943 Validation Decoder Loss:  0.5330599
Encoder Loss:  0.13614395  || Decoder Loss:  0.47987294 Validation Decoder Loss:  0.5724523
Encoder Loss:  0.13740116  || Decoder Loss:  0.45591548 Validation Decoder Loss:  0.8204782
Encoder Loss:  0.13781747  || Decoder Loss:  0.4855383 Validation Decoder Loss:  0.4752702
Encoder Loss:  0.13974741  || Decoder Loss:  0.5030396 Validation Decoder Loss:  1.1965076
Encoder Loss:  0.13871628  || Decoder Loss:  0.5205543 Validation Decoder Loss:  1.0562912
Encoder Loss:  0.13000964  || Decoder Loss:  0.4765677 Validation Decoder Loss:  1.3941451
Encoder Loss:  0.1282982  || Decoder Loss:  0.48633358 Validation Decoder Loss:  0.93642366
Encoder Loss:  0.12413127  || Decoder Loss:  0.44415846 Validation Decoder Loss:  0.8198713
Encoder Loss:  0.13313591  || Decoder Loss:  0.4999625 Validation Decoder Loss:  0.8070297
Encoder Loss:  0.12330804  || Decoder Loss:  0.4424418 Validation Decoder Loss:  1.6831872
Encoder Loss:  0.13483097  || Decoder Loss:  0.490985 Validation Decoder Loss:  1.5015221
Encoder Loss:  0.13047148  || Decoder Loss:  0.50232375 Validation Decoder Loss:  0.9799169
Encoder Loss:  0.12614535  || Decoder Loss:  0.4885527 Validation Decoder Loss:  1.0572923
Encoder Loss:  0.12639599  || Decoder Loss:  0.48920968 Validation Decoder Loss:  1.0268991
Encoder Loss:  0.12573254  || Decoder Loss:  0.4876788 Validation Decoder Loss:  1.0278972
Encoder Loss:  0.12562162  || Decoder Loss:  0.4870648 Validation Decoder Loss:  1.0245851
Encoder Loss:  0.1254446  || Decoder Loss:  0.48606437 Validation Decoder Loss:  1.0272547
Encoder Loss:  0.12527995  || Decoder Loss:  0.48518696 Validation Decoder Loss:  1.0275606
Encoder Loss:  0.12518531  || Decoder Loss:  0.48455715 Validation Decoder Loss:  1.028157
Encoder Loss:  0.12503342  || Decoder Loss:  0.48373428 Validation Decoder Loss:  1.0307201
Encoder Loss:  0.12490473  || Decoder Loss:  0.48289707 Validation Decoder Loss:  1.0318595
Encoder Loss:  0.124716  || Decoder Loss:  0.4819167 Validation Decoder Loss:  1.0330455
Encoder Loss:  0.124544576  || Decoder Loss:  0.48089367 Validation Decoder Loss:  1.034274
Encoder Loss:  0.12434656  || Decoder Loss:  0.47969514 Validation Decoder Loss:  1.0348692
Encoder Loss:  0.124091685  || Decoder Loss:  0.47816548 Validation Decoder Loss:  1.0342
Encoder Loss:  0.12387825  || Decoder Loss:  0.47691336 Validation Decoder Loss:  1.0349132
Encoder Loss:  0.123667926  || Decoder Loss:  0.47577748 Validation Decoder Loss:  1.0349493
Encoder Loss:  0.123498656  || Decoder Loss:  0.4747287 Validation Decoder Loss:  1.035965
Encoder Loss:  0.12334761  || Decoder Loss:  0.4738323 Validation Decoder Loss:  1.034279
Model: siamese_net_lr_0.7940646462914047 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.034279
Model: "sequential_679"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_326 (Conv3D (None, 70, 9, 20, 1)      36        
_________________________________________________________________
dropout_848 (Dropout)        (None, 70, 9, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_327 (Conv3D (None, 74, 30, 20, 1)     71        
_________________________________________________________________
reshape_179 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 107
Trainable params: 107
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_681"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 2510, 20, 1)       99        
_________________________________________________________________
dropout_850 (Dropout)        (None, 2510, 20, 1)       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 2220, 20, 1)       292       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_682"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_298 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_852 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_299 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.07817988  || Decoder Loss:  0.07626686 Validation Decoder Loss:  0.37226272
Encoder Loss:  0.05706666  || Decoder Loss:  0.057690173 Validation Decoder Loss:  0.36758524
Encoder Loss:  0.053672317  || Decoder Loss:  0.053932212 Validation Decoder Loss:  0.36002374
Encoder Loss:  0.053557448  || Decoder Loss:  0.05308552 Validation Decoder Loss:  0.35544282
Encoder Loss:  0.05378466  || Decoder Loss:  0.054284234 Validation Decoder Loss:  0.3547475
Encoder Loss:  0.05246518  || Decoder Loss:  0.052791815 Validation Decoder Loss:  0.3608063
Encoder Loss:  0.05294153  || Decoder Loss:  0.05333884 Validation Decoder Loss:  0.3747456
Encoder Loss:  0.052408144  || Decoder Loss:  0.052733134 Validation Decoder Loss:  0.35371286
Encoder Loss:  0.054734692  || Decoder Loss:  0.055381812 Validation Decoder Loss:  0.37327528
Encoder Loss:  0.05486742  || Decoder Loss:  0.055535026 Validation Decoder Loss:  0.3556996
Encoder Loss:  0.05199475  || Decoder Loss:  0.052244104 Validation Decoder Loss:  0.3521003
Encoder Loss:  0.052556306  || Decoder Loss:  0.052644514 Validation Decoder Loss:  0.35293734
Encoder Loss:  0.052780997  || Decoder Loss:  0.05315981 Validation Decoder Loss:  0.35096425
Encoder Loss:  0.055297755  || Decoder Loss:  0.056025952 Validation Decoder Loss:  0.37334636
Encoder Loss:  0.05450993  || Decoder Loss:  0.05512244 Validation Decoder Loss:  0.3531075
Encoder Loss:  0.05138385  || Decoder Loss:  0.051569406 Validation Decoder Loss:  0.35172582
Encoder Loss:  0.05185099  || Decoder Loss:  0.052100457 Validation Decoder Loss:  0.35848674
Encoder Loss:  0.05168437  || Decoder Loss:  0.0518362 Validation Decoder Loss:  0.35200453
Encoder Loss:  0.19886547  || Decoder Loss:  0.21925011 Validation Decoder Loss:  1.6417408
Encoder Loss:  0.11980618  || Decoder Loss:  0.12947044 Validation Decoder Loss:  0.3687001
Encoder Loss:  0.062096883  || Decoder Loss:  0.063770264 Validation Decoder Loss:  0.37253886
Encoder Loss:  0.061963134  || Decoder Loss:  0.06361924 Validation Decoder Loss:  0.3742296
Encoder Loss:  0.061797004  || Decoder Loss:  0.06342976 Validation Decoder Loss:  0.37417948
Encoder Loss:  0.061623883  || Decoder Loss:  0.063233316 Validation Decoder Loss:  0.3758915
Encoder Loss:  0.061459493  || Decoder Loss:  0.063044794 Validation Decoder Loss:  0.37708288
Encoder Loss:  0.06125738  || Decoder Loss:  0.062815025 Validation Decoder Loss:  0.37606406
Encoder Loss:  0.061014164  || Decoder Loss:  0.062538974 Validation Decoder Loss:  0.3777081
Encoder Loss:  0.060756583  || Decoder Loss:  0.06224476 Validation Decoder Loss:  0.37776014
Encoder Loss:  0.060651466  || Decoder Loss:  0.0621258 Validation Decoder Loss:  0.38373825
Encoder Loss:  0.06059408  || Decoder Loss:  0.062060274 Validation Decoder Loss:  0.36269176
Encoder Loss:  0.3366909  || Decoder Loss:  0.37640792 Validation Decoder Loss:  1.0018547
Encoder Loss:  0.44534168  || Decoder Loss:  0.5001112 Validation Decoder Loss:  0.998718
Encoder Loss:  0.44542542  || Decoder Loss:  0.50020593 Validation Decoder Loss:  1.0078022
Encoder Loss:  0.44443357  || Decoder Loss:  0.49907655 Validation Decoder Loss:  1.000577
Encoder Loss:  0.4445805  || Decoder Loss:  0.49924362 Validation Decoder Loss:  1.0065786
Encoder Loss:  0.44426918  || Decoder Loss:  0.49888933 Validation Decoder Loss:  0.9959918
Encoder Loss:  0.44534165  || Decoder Loss:  0.50011057 Validation Decoder Loss:  1.0012586
Encoder Loss:  0.44469696  || Decoder Loss:  0.49937654 Validation Decoder Loss:  1.0021617
Encoder Loss:  0.44440025  || Decoder Loss:  0.49903893 Validation Decoder Loss:  1.0051613
Encoder Loss:  0.4443864  || Decoder Loss:  0.499023 Validation Decoder Loss:  1.0063695
Model: siamese_net_lr_0.3453328146714745 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.0063695
Model: "sequential_683"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_329 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_854 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_330 (Conv3D (None, 74, 30, 20, 1)     99        
_________________________________________________________________
reshape_180 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 105
Trainable params: 105
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_685"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_300 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_856 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_686"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_300 (Conv2D (None, 2530, 20, 1)       312       
_________________________________________________________________
dropout_858 (Dropout)        (None, 2530, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_301 (Conv2D (None, 2607, 20, 1)       79        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.43080315  || Decoder Loss:  0.4333953 Validation Decoder Loss:  0.99778664
Encoder Loss:  0.49236324  || Decoder Loss:  0.49609357 Validation Decoder Loss:  0.9980104
Encoder Loss:  0.49233413  || Decoder Loss:  0.49606717 Validation Decoder Loss:  0.9986044
Encoder Loss:  0.4923581  || Decoder Loss:  0.49610406 Validation Decoder Loss:  0.9981259
Encoder Loss:  0.492337  || Decoder Loss:  0.49607128 Validation Decoder Loss:  0.9976514
Encoder Loss:  0.49231815  || Decoder Loss:  0.4960512 Validation Decoder Loss:  0.9981359
Encoder Loss:  0.49236715  || Decoder Loss:  0.4960775 Validation Decoder Loss:  0.9976616
Encoder Loss:  0.49224195  || Decoder Loss:  0.4959565 Validation Decoder Loss:  0.9973499
Encoder Loss:  0.49230143  || Decoder Loss:  0.49604622 Validation Decoder Loss:  0.99779737
Encoder Loss:  0.4922192  || Decoder Loss:  0.49597254 Validation Decoder Loss:  0.9977565
Encoder Loss:  0.4921771  || Decoder Loss:  0.4959335 Validation Decoder Loss:  0.9976175
Encoder Loss:  0.49213132  || Decoder Loss:  0.49588868 Validation Decoder Loss:  0.9975681
Encoder Loss:  0.4920871  || Decoder Loss:  0.49584407 Validation Decoder Loss:  0.99752575
Encoder Loss:  0.49202916  || Decoder Loss:  0.4957857 Validation Decoder Loss:  0.99744827
Encoder Loss:  0.4919563  || Decoder Loss:  0.49571228 Validation Decoder Loss:  0.99733555
Encoder Loss:  0.4918728  || Decoder Loss:  0.49562785 Validation Decoder Loss:  0.9972208
Encoder Loss:  0.49178085  || Decoder Loss:  0.4955354 Validation Decoder Loss:  0.9970434
Encoder Loss:  0.49167985  || Decoder Loss:  0.49543363 Validation Decoder Loss:  0.996841
Encoder Loss:  0.49158958  || Decoder Loss:  0.49534255 Validation Decoder Loss:  0.9965742
Encoder Loss:  0.49148324  || Decoder Loss:  0.49523517 Validation Decoder Loss:  0.996245
Encoder Loss:  0.4911199  || Decoder Loss:  0.49486867 Validation Decoder Loss:  0.996382
Encoder Loss:  0.49069232  || Decoder Loss:  0.49443737 Validation Decoder Loss:  0.99630696
Encoder Loss:  0.490453  || Decoder Loss:  0.4941962 Validation Decoder Loss:  0.9921099
Encoder Loss:  0.48982534  || Decoder Loss:  0.49356315 Validation Decoder Loss:  0.99265146
Encoder Loss:  0.4887054  || Decoder Loss:  0.4924339 Validation Decoder Loss:  0.98718476
Encoder Loss:  0.46521533  || Decoder Loss:  0.4687441 Validation Decoder Loss:  0.9177324
Encoder Loss:  0.4897544  || Decoder Loss:  0.49349168 Validation Decoder Loss:  0.9883833
Encoder Loss:  0.49060178  || Decoder Loss:  0.49434608 Validation Decoder Loss:  0.9868635
Encoder Loss:  0.4900908  || Decoder Loss:  0.4938308 Validation Decoder Loss:  1.0123068
Encoder Loss:  0.47418177  || Decoder Loss:  0.47778606 Validation Decoder Loss:  1.018503
Encoder Loss:  0.49660397  || Decoder Loss:  0.5003994 Validation Decoder Loss:  0.9984033
Encoder Loss:  0.48941773  || Decoder Loss:  0.4931522 Validation Decoder Loss:  0.9854866
Encoder Loss:  0.48308972  || Decoder Loss:  0.48677045 Validation Decoder Loss:  0.9876872
Encoder Loss:  0.49118984  || Decoder Loss:  0.49493927 Validation Decoder Loss:  0.9747305
Encoder Loss:  0.48324883  || Decoder Loss:  0.48693085 Validation Decoder Loss:  0.9962112
Encoder Loss:  0.49341652  || Decoder Loss:  0.49718514 Validation Decoder Loss:  0.99529123
Encoder Loss:  0.48934594  || Decoder Loss:  0.49307975 Validation Decoder Loss:  0.9771788
Encoder Loss:  0.42323098  || Decoder Loss:  0.42640293 Validation Decoder Loss:  0.9635118
Encoder Loss:  0.48553985  || Decoder Loss:  0.48924145 Validation Decoder Loss:  0.98973584
Encoder Loss:  0.48649743  || Decoder Loss:  0.49020714 Validation Decoder Loss:  0.98378503
Model: siamese_net_lr_0.18144755436799195 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.98378503
Model: "sequential_687"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_332 (Conv3D (None, 70, 5, 20, 1)      8         
_________________________________________________________________
dropout_860 (Dropout)        (None, 70, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_333 (Conv3D (None, 74, 30, 20, 1)     91        
_________________________________________________________________
reshape_181 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 99
Trainable params: 99
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_689"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_302 (Conv2D)          (None, 2440, 20, 1)       169       
_________________________________________________________________
dropout_862 (Dropout)        (None, 2440, 20, 1)       0         
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 2220, 20, 1)       222       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_690"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_302 (Conv2D (None, 2260, 20, 1)       42        
_________________________________________________________________
dropout_864 (Dropout)        (None, 2260, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_303 (Conv2D (None, 2607, 20, 1)       349       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.31772554  || Decoder Loss:  0.36775735 Validation Decoder Loss:  1.4890516
Encoder Loss:  0.3937469  || Decoder Loss:  0.5163811 Validation Decoder Loss:  1.0946958
Encoder Loss:  0.38389876  || Decoder Loss:  0.5040782 Validation Decoder Loss:  1.0290235
Encoder Loss:  0.37949178  || Decoder Loss:  0.4979376 Validation Decoder Loss:  1.0139829
Encoder Loss:  0.37927514  || Decoder Loss:  0.49801335 Validation Decoder Loss:  1.0125653
Encoder Loss:  0.3761898  || Decoder Loss:  0.49554455 Validation Decoder Loss:  1.012588
Encoder Loss:  0.3750391  || Decoder Loss:  0.49545565 Validation Decoder Loss:  1.0105531
Encoder Loss:  0.37530556  || Decoder Loss:  0.49464175 Validation Decoder Loss:  1.0208802
Encoder Loss:  0.3752072  || Decoder Loss:  0.49533445 Validation Decoder Loss:  1.0152981
Encoder Loss:  0.3745282  || Decoder Loss:  0.49469525 Validation Decoder Loss:  1.0123173
Encoder Loss:  0.37681675  || Decoder Loss:  0.49495497 Validation Decoder Loss:  1.0161092
Encoder Loss:  0.37430352  || Decoder Loss:  0.49452236 Validation Decoder Loss:  1.0138001
Encoder Loss:  0.3744759  || Decoder Loss:  0.49455655 Validation Decoder Loss:  1.0181608
Encoder Loss:  0.37455344  || Decoder Loss:  0.49437848 Validation Decoder Loss:  1.0148963
Encoder Loss:  0.37393367  || Decoder Loss:  0.49387553 Validation Decoder Loss:  1.0074693
Encoder Loss:  0.37358055  || Decoder Loss:  0.4933045 Validation Decoder Loss:  1.0317363
Encoder Loss:  0.37547004  || Decoder Loss:  0.49473876 Validation Decoder Loss:  1.0112522
Encoder Loss:  0.3726369  || Decoder Loss:  0.49256092 Validation Decoder Loss:  1.00981
Encoder Loss:  0.3711956  || Decoder Loss:  0.49061027 Validation Decoder Loss:  1.0015574
Encoder Loss:  0.36957893  || Decoder Loss:  0.48860916 Validation Decoder Loss:  1.004446
Encoder Loss:  0.36988094  || Decoder Loss:  0.48826241 Validation Decoder Loss:  1.0049238
Encoder Loss:  0.36838123  || Decoder Loss:  0.48632744 Validation Decoder Loss:  0.9944863
Encoder Loss:  0.36775416  || Decoder Loss:  0.48581773 Validation Decoder Loss:  0.9961177
Encoder Loss:  0.37002763  || Decoder Loss:  0.4885194 Validation Decoder Loss:  1.0054431
Encoder Loss:  0.3740223  || Decoder Loss:  0.49234605 Validation Decoder Loss:  1.0101125
Encoder Loss:  0.36926392  || Decoder Loss:  0.487813 Validation Decoder Loss:  1.0028584
Encoder Loss:  0.36587536  || Decoder Loss:  0.4834954 Validation Decoder Loss:  0.9916245
Encoder Loss:  0.36706284  || Decoder Loss:  0.4848946 Validation Decoder Loss:  0.99632704
Encoder Loss:  0.36471152  || Decoder Loss:  0.48201993 Validation Decoder Loss:  0.9940728
Encoder Loss:  0.36390063  || Decoder Loss:  0.48096898 Validation Decoder Loss:  0.9988692
Encoder Loss:  0.37144753  || Decoder Loss:  0.49076274 Validation Decoder Loss:  1.0177256
Encoder Loss:  0.36895764  || Decoder Loss:  0.4880183 Validation Decoder Loss:  1.0135217
Encoder Loss:  0.36868808  || Decoder Loss:  0.48710534 Validation Decoder Loss:  0.9630625
Encoder Loss:  0.3705162  || Decoder Loss:  0.48964396 Validation Decoder Loss:  1.0444936
Encoder Loss:  0.37550473  || Decoder Loss:  0.4960569 Validation Decoder Loss:  1.0100455
Encoder Loss:  0.3717999  || Decoder Loss:  0.49191356 Validation Decoder Loss:  1.0034983
Encoder Loss:  0.37040615  || Decoder Loss:  0.48963737 Validation Decoder Loss:  0.9787663
Encoder Loss:  0.3702198  || Decoder Loss:  0.48920247 Validation Decoder Loss:  0.9199574
Encoder Loss:  0.37108764  || Decoder Loss:  0.4903604 Validation Decoder Loss:  0.85745275
Encoder Loss:  0.35390034  || Decoder Loss:  0.46641514 Validation Decoder Loss:  0.37706065
Model: siamese_net_lr_0.8730904289134763 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37706065
Model: "sequential_691"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_335 (Conv3D (None, 67, 30, 20, 1)     57        
_________________________________________________________________
dropout_866 (Dropout)        (None, 67, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_336 (Conv3D (None, 74, 30, 20, 1)     9         
_________________________________________________________________
reshape_182 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 66
Trainable params: 66
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_693"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_304 (Conv2D)          (None, 2550, 20, 1)       59        
_________________________________________________________________
dropout_868 (Dropout)        (None, 2550, 20, 1)       0         
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 2220, 20, 1)       332       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_694"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_304 (Conv2D (None, 2380, 20, 1)       162       
_________________________________________________________________
dropout_870 (Dropout)        (None, 2380, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_305 (Conv2D (None, 2607, 20, 1)       229       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.39417127  || Decoder Loss:  0.26930422 Validation Decoder Loss:  0.39870074
Encoder Loss:  0.3676269  || Decoder Loss:  0.06695147 Validation Decoder Loss:  0.40165716
Encoder Loss:  0.34645566  || Decoder Loss:  0.2032762 Validation Decoder Loss:  0.39619583
Encoder Loss:  0.27873123  || Decoder Loss:  0.5420618 Validation Decoder Loss:  1.4605405
Encoder Loss:  0.13975315  || Decoder Loss:  0.4056779 Validation Decoder Loss:  1.518198
Encoder Loss:  0.15821211  || Decoder Loss:  0.4945742 Validation Decoder Loss:  0.35044312
Encoder Loss:  0.12544759  || Decoder Loss:  0.4150437 Validation Decoder Loss:  0.43229666
Encoder Loss:  0.1429882  || Decoder Loss:  0.47874752 Validation Decoder Loss:  0.422935
Encoder Loss:  0.13314058  || Decoder Loss:  0.45332345 Validation Decoder Loss:  0.8829385
Encoder Loss:  0.06525591  || Decoder Loss:  0.11680124 Validation Decoder Loss:  0.2743826
Encoder Loss:  0.049709864  || Decoder Loss:  0.042500116 Validation Decoder Loss:  0.34050268
Encoder Loss:  0.049082693  || Decoder Loss:  0.040454593 Validation Decoder Loss:  0.3459106
Encoder Loss:  0.049000293  || Decoder Loss:  0.040125154 Validation Decoder Loss:  0.34598604
Encoder Loss:  0.049140364  || Decoder Loss:  0.039992906 Validation Decoder Loss:  0.34597135
Encoder Loss:  0.04858652  || Decoder Loss:  0.039889816 Validation Decoder Loss:  0.34586716
Encoder Loss:  0.048474535  || Decoder Loss:  0.039801754 Validation Decoder Loss:  0.3458246
Encoder Loss:  0.048659515  || Decoder Loss:  0.039722458 Validation Decoder Loss:  0.34635872
Encoder Loss:  0.048981752  || Decoder Loss:  0.039650112 Validation Decoder Loss:  0.34579015
Encoder Loss:  0.048782606  || Decoder Loss:  0.039590433 Validation Decoder Loss:  0.34627056
Encoder Loss:  0.04916717  || Decoder Loss:  0.039538026 Validation Decoder Loss:  0.3462767
Encoder Loss:  0.049267784  || Decoder Loss:  0.039498612 Validation Decoder Loss:  0.34578103
Encoder Loss:  0.048887063  || Decoder Loss:  0.039458178 Validation Decoder Loss:  0.34583956
Encoder Loss:  0.048983015  || Decoder Loss:  0.039409377 Validation Decoder Loss:  0.34629115
Encoder Loss:  0.04855801  || Decoder Loss:  0.039364174 Validation Decoder Loss:  0.34607834
Encoder Loss:  0.04844441  || Decoder Loss:  0.03930528 Validation Decoder Loss:  0.34721485
Encoder Loss:  0.048917223  || Decoder Loss:  0.0393751 Validation Decoder Loss:  0.34593925
Encoder Loss:  0.04858315  || Decoder Loss:  0.039274804 Validation Decoder Loss:  0.34633446
Encoder Loss:  0.048883673  || Decoder Loss:  0.039246097 Validation Decoder Loss:  0.34610957
Encoder Loss:  0.04876212  || Decoder Loss:  0.039223902 Validation Decoder Loss:  0.346125
Encoder Loss:  0.04884464  || Decoder Loss:  0.039197825 Validation Decoder Loss:  0.34622553
Encoder Loss:  0.048371863  || Decoder Loss:  0.0391595 Validation Decoder Loss:  0.3463624
Encoder Loss:  0.04831111  || Decoder Loss:  0.039121546 Validation Decoder Loss:  0.34660965
Encoder Loss:  0.0483025  || Decoder Loss:  0.0390941 Validation Decoder Loss:  0.34537733
Encoder Loss:  0.04839402  || Decoder Loss:  0.03904343 Validation Decoder Loss:  0.34628543
Encoder Loss:  0.04858099  || Decoder Loss:  0.039146084 Validation Decoder Loss:  0.3458588
Encoder Loss:  0.04873891  || Decoder Loss:  0.03910681 Validation Decoder Loss:  0.3461679
Encoder Loss:  0.04846547  || Decoder Loss:  0.039006528 Validation Decoder Loss:  0.34598994
Encoder Loss:  0.048541598  || Decoder Loss:  0.039031833 Validation Decoder Loss:  0.34605992
Encoder Loss:  0.04871653  || Decoder Loss:  0.039047405 Validation Decoder Loss:  0.34382707
Encoder Loss:  0.04853795  || Decoder Loss:  0.03914733 Validation Decoder Loss:  0.34566855
Model: siamese_net_lr_0.6883569205937943 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.34566858
Model: "sequential_695"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_338 (Conv3D (None, 65, 10, 20, 1)     13        
_________________________________________________________________
dropout_872 (Dropout)        (None, 65, 10, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_339 (Conv3D (None, 74, 30, 20, 1)     211       
_________________________________________________________________
reshape_183 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 224
Trainable params: 224
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_697"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_306 (Conv2D)          (None, 2570, 20, 1)       39        
_________________________________________________________________
dropout_874 (Dropout)        (None, 2570, 20, 1)       0         
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 2220, 20, 1)       352       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_698"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_306 (Conv2D (None, 2500, 20, 1)       282       
_________________________________________________________________
dropout_876 (Dropout)        (None, 2500, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_307 (Conv2D (None, 2607, 20, 1)       109       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.38797268  || Decoder Loss:  0.445853 Validation Decoder Loss:  1.0130439
Encoder Loss:  0.3864461  || Decoder Loss:  0.4486393 Validation Decoder Loss:  0.4062205
Encoder Loss:  0.06715212  || Decoder Loss:  0.07028644 Validation Decoder Loss:  0.3575818
Encoder Loss:  0.037679065  || Decoder Loss:  0.03537234 Validation Decoder Loss:  0.33403385
Encoder Loss:  0.037806004  || Decoder Loss:  0.035532106 Validation Decoder Loss:  0.3489983
Encoder Loss:  0.038048163  || Decoder Loss:  0.035829455 Validation Decoder Loss:  0.3356767
Encoder Loss:  0.0381852  || Decoder Loss:  0.035936303 Validation Decoder Loss:  0.33550578
Encoder Loss:  0.03749168  || Decoder Loss:  0.035167597 Validation Decoder Loss:  0.33546534
Encoder Loss:  0.037263066  || Decoder Loss:  0.03490464 Validation Decoder Loss:  0.3340722
Encoder Loss:  0.037556507  || Decoder Loss:  0.035252612 Validation Decoder Loss:  0.3335433
Encoder Loss:  0.03697466  || Decoder Loss:  0.03456307 Validation Decoder Loss:  0.33294278
Encoder Loss:  0.036824103  || Decoder Loss:  0.034384493 Validation Decoder Loss:  0.33183238
Encoder Loss:  0.036993727  || Decoder Loss:  0.034585677 Validation Decoder Loss:  0.33171985
Encoder Loss:  0.036509603  || Decoder Loss:  0.034011785 Validation Decoder Loss:  0.33082372
Encoder Loss:  0.037016507  || Decoder Loss:  0.034611404 Validation Decoder Loss:  0.33142743
Encoder Loss:  0.049305715  || Decoder Loss:  0.048640296 Validation Decoder Loss:  0.33355045
Encoder Loss:  0.037515484  || Decoder Loss:  0.035004422 Validation Decoder Loss:  0.34426463
Encoder Loss:  0.036635622  || Decoder Loss:  0.03415961 Validation Decoder Loss:  0.34396318
Encoder Loss:  0.0364681  || Decoder Loss:  0.03396182 Validation Decoder Loss:  0.34220126
Encoder Loss:  0.036501035  || Decoder Loss:  0.03400068 Validation Decoder Loss:  0.3388285
Encoder Loss:  0.036442894  || Decoder Loss:  0.033932015 Validation Decoder Loss:  0.3371287
Encoder Loss:  0.03709024  || Decoder Loss:  0.03469907 Validation Decoder Loss:  0.3355551
Encoder Loss:  0.036236793  || Decoder Loss:  0.033687826 Validation Decoder Loss:  0.33366716
Encoder Loss:  0.036915477  || Decoder Loss:  0.034492984 Validation Decoder Loss:  0.33510804
Encoder Loss:  0.03626659  || Decoder Loss:  0.03372398 Validation Decoder Loss:  0.3321232
Encoder Loss:  0.03789617  || Decoder Loss:  0.03565512 Validation Decoder Loss:  0.33238417
Encoder Loss:  0.036669403  || Decoder Loss:  0.034201 Validation Decoder Loss:  0.33279696
Encoder Loss:  0.036353678  || Decoder Loss:  0.033826653 Validation Decoder Loss:  0.33079582
Encoder Loss:  0.036959194  || Decoder Loss:  0.034543917 Validation Decoder Loss:  0.32903594
Encoder Loss:  0.036415197  || Decoder Loss:  0.03389921 Validation Decoder Loss:  0.32991973
Encoder Loss:  0.12871884  || Decoder Loss:  0.14307278 Validation Decoder Loss:  0.3703043
Encoder Loss:  0.22246045  || Decoder Loss:  0.25437716 Validation Decoder Loss:  0.33653224
Encoder Loss:  0.037517384  || Decoder Loss:  0.03520648 Validation Decoder Loss:  0.33376592
Encoder Loss:  0.036989834  || Decoder Loss:  0.034581482 Validation Decoder Loss:  0.33113366
Encoder Loss:  0.03649935  || Decoder Loss:  0.03400012 Validation Decoder Loss:  0.32330573
Encoder Loss:  0.036375877  || Decoder Loss:  0.033853814 Validation Decoder Loss:  0.33953136
Encoder Loss:  0.036386028  || Decoder Loss:  0.033865433 Validation Decoder Loss:  0.32331848
Encoder Loss:  0.037019335  || Decoder Loss:  0.034610096 Validation Decoder Loss:  0.33083722
Encoder Loss:  0.036286652  || Decoder Loss:  0.03374824 Validation Decoder Loss:  0.32985574
Encoder Loss:  0.03695693  || Decoder Loss:  0.034542575 Validation Decoder Loss:  0.3312229
Model: siamese_net_lr_0.021254810066071234 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.3312229
Model: "sequential_699"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_341 (Conv3D (None, 68, 5, 20, 1)      6         
_________________________________________________________________
dropout_878 (Dropout)        (None, 68, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_342 (Conv3D (None, 74, 30, 20, 1)     183       
_________________________________________________________________
reshape_184 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_701"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_308 (Conv2D)          (None, 2460, 20, 1)       149       
_________________________________________________________________
dropout_880 (Dropout)        (None, 2460, 20, 1)       0         
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 2220, 20, 1)       242       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_702"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_308 (Conv2D (None, 2280, 20, 1)       62        
_________________________________________________________________
dropout_882 (Dropout)        (None, 2280, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_309 (Conv2D (None, 2607, 20, 1)       329       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.26207197  || Decoder Loss:  0.30062428 Validation Decoder Loss:  0.41533664
Encoder Loss:  0.40766734  || Decoder Loss:  0.47530586 Validation Decoder Loss:  1.0171436
Encoder Loss:  0.42415902  || Decoder Loss:  0.49491656 Validation Decoder Loss:  1.0148021
Encoder Loss:  0.42350745  || Decoder Loss:  0.49414155 Validation Decoder Loss:  1.0135505
Encoder Loss:  0.4234713  || Decoder Loss:  0.49409807 Validation Decoder Loss:  1.0124017
Encoder Loss:  0.40373012  || Decoder Loss:  0.47062397 Validation Decoder Loss:  0.6561625
Encoder Loss:  0.39387217  || Decoder Loss:  0.45889947 Validation Decoder Loss:  1.0163536
Encoder Loss:  0.42359614  || Decoder Loss:  0.49424666 Validation Decoder Loss:  1.0156977
Encoder Loss:  0.42245498  || Decoder Loss:  0.4928876 Validation Decoder Loss:  1.0074878
Encoder Loss:  0.42266372  || Decoder Loss:  0.49313718 Validation Decoder Loss:  0.98753786
Encoder Loss:  0.4081144  || Decoder Loss:  0.47583354 Validation Decoder Loss:  1.0105295
Encoder Loss:  0.42400897  || Decoder Loss:  0.49473408 Validation Decoder Loss:  1.0166988
Encoder Loss:  0.4251722  || Decoder Loss:  0.49611846 Validation Decoder Loss:  1.015204
Encoder Loss:  0.42413142  || Decoder Loss:  0.49488232 Validation Decoder Loss:  1.0140901
Encoder Loss:  0.42388427  || Decoder Loss:  0.49458817 Validation Decoder Loss:  1.0124977
Encoder Loss:  0.4255629  || Decoder Loss:  0.49658057 Validation Decoder Loss:  1.0162907
Encoder Loss:  0.4238243  || Decoder Loss:  0.49451283 Validation Decoder Loss:  1.0214896
Encoder Loss:  0.42588103  || Decoder Loss:  0.49689075 Validation Decoder Loss:  1.0169088
Encoder Loss:  0.42395854  || Decoder Loss:  0.49467695 Validation Decoder Loss:  1.0159466
Encoder Loss:  0.4238161  || Decoder Loss:  0.49450883 Validation Decoder Loss:  1.0157773
Encoder Loss:  0.42375523  || Decoder Loss:  0.4944355 Validation Decoder Loss:  1.0155017
Encoder Loss:  0.42362413  || Decoder Loss:  0.494279 Validation Decoder Loss:  1.0153197
Encoder Loss:  0.42331845  || Decoder Loss:  0.49391598 Validation Decoder Loss:  1.0135093
Encoder Loss:  0.4230622  || Decoder Loss:  0.49361137 Validation Decoder Loss:  1.0130405
Encoder Loss:  0.39962003  || Decoder Loss:  0.46573615 Validation Decoder Loss:  0.34787688
Encoder Loss:  0.04737059  || Decoder Loss:  0.046871208 Validation Decoder Loss:  0.34495312
Encoder Loss:  0.0429494  || Decoder Loss:  0.041613728 Validation Decoder Loss:  0.33400634
Encoder Loss:  0.04221492  || Decoder Loss:  0.040740732 Validation Decoder Loss:  0.3263653
Encoder Loss:  0.054635838  || Decoder Loss:  0.055510283 Validation Decoder Loss:  0.33730155
Encoder Loss:  0.041615855  || Decoder Loss:  0.04002692 Validation Decoder Loss:  0.33471245
Encoder Loss:  0.04149919  || Decoder Loss:  0.039889913 Validation Decoder Loss:  0.33745515
Encoder Loss:  0.041407146  || Decoder Loss:  0.0397804 Validation Decoder Loss:  0.36162737
Encoder Loss:  0.049960244  || Decoder Loss:  0.049950358 Validation Decoder Loss:  0.34390178
Encoder Loss:  0.04121295  || Decoder Loss:  0.039548583 Validation Decoder Loss:  0.3391307
Encoder Loss:  0.040866062  || Decoder Loss:  0.039135147 Validation Decoder Loss:  0.35214287
Encoder Loss:  0.04098771  || Decoder Loss:  0.039281365 Validation Decoder Loss:  0.3456896
Encoder Loss:  0.042684432  || Decoder Loss:  0.04129885 Validation Decoder Loss:  0.34281588
Encoder Loss:  0.06036845  || Decoder Loss:  0.062326666 Validation Decoder Loss:  0.3287357
Encoder Loss:  0.041921154  || Decoder Loss:  0.040391356 Validation Decoder Loss:  0.34339994
Encoder Loss:  0.04304149  || Decoder Loss:  0.04172207 Validation Decoder Loss:  0.37301654
Model: siamese_net_lr_0.8787376751526319 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.37301654
Model: "sequential_703"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_344 (Conv3D (None, 72, 5, 20, 1)      10        
_________________________________________________________________
dropout_884 (Dropout)        (None, 72, 5, 20, 1)      0         
_________________________________________________________________
conv3d_transpose_345 (Conv3D (None, 74, 30, 20, 1)     79        
_________________________________________________________________
reshape_185 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 89
Trainable params: 89
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_705"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_310 (Conv2D)          (None, 2560, 20, 1)       49        
_________________________________________________________________
dropout_886 (Dropout)        (None, 2560, 20, 1)       0         
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 2220, 20, 1)       342       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_706"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_310 (Conv2D (None, 2490, 20, 1)       272       
_________________________________________________________________
dropout_888 (Dropout)        (None, 2490, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_311 (Conv2D (None, 2607, 20, 1)       119       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.3374442  || Decoder Loss:  0.5097805 Validation Decoder Loss:  0.9301257
Encoder Loss:  0.31899136  || Decoder Loss:  0.48833752 Validation Decoder Loss:  1.0326033
Encoder Loss:  0.32418773  || Decoder Loss:  0.49979335 Validation Decoder Loss:  0.99000776
Encoder Loss:  0.3200759  || Decoder Loss:  0.49553916 Validation Decoder Loss:  1.0304141
Encoder Loss:  0.32023555  || Decoder Loss:  0.49733365 Validation Decoder Loss:  1.0146197
Encoder Loss:  0.31839812  || Decoder Loss:  0.494676 Validation Decoder Loss:  1.0147141
Encoder Loss:  0.31836742  || Decoder Loss:  0.4946295 Validation Decoder Loss:  1.0146716
Encoder Loss:  0.3183222  || Decoder Loss:  0.49455574 Validation Decoder Loss:  1.0147134
Encoder Loss:  0.3182797  || Decoder Loss:  0.49448463 Validation Decoder Loss:  1.0145924
Encoder Loss:  0.31821737  || Decoder Loss:  0.49438325 Validation Decoder Loss:  1.0143187
Encoder Loss:  0.31811285  || Decoder Loss:  0.4942098 Validation Decoder Loss:  1.0139773
Encoder Loss:  0.31800887  || Decoder Loss:  0.4940379 Validation Decoder Loss:  1.013452
Encoder Loss:  0.31772828  || Decoder Loss:  0.49357364 Validation Decoder Loss:  1.0121524
Encoder Loss:  0.3170636  || Decoder Loss:  0.492472 Validation Decoder Loss:  1.0049214
Encoder Loss:  0.31542674  || Decoder Loss:  0.48975396 Validation Decoder Loss:  0.97735345
Encoder Loss:  0.28634617  || Decoder Loss:  0.44157696 Validation Decoder Loss:  0.47227043
Encoder Loss:  0.17617363  || Decoder Loss:  0.25904334 Validation Decoder Loss:  0.33620435
Encoder Loss:  0.04053528  || Decoder Loss:  0.034316044 Validation Decoder Loss:  0.33562556
Encoder Loss:  0.040432043  || Decoder Loss:  0.034143962 Validation Decoder Loss:  0.33538264
Encoder Loss:  0.04036737  || Decoder Loss:  0.034037646 Validation Decoder Loss:  0.33408082
Encoder Loss:  0.040302724  || Decoder Loss:  0.03392857 Validation Decoder Loss:  0.3346243
Encoder Loss:  0.040257663  || Decoder Loss:  0.033854958 Validation Decoder Loss:  0.33400908
Encoder Loss:  0.040205535  || Decoder Loss:  0.03376924 Validation Decoder Loss:  0.33347738
Encoder Loss:  0.04018017  || Decoder Loss:  0.03372561 Validation Decoder Loss:  0.3342837
Encoder Loss:  0.040139455  || Decoder Loss:  0.033660162 Validation Decoder Loss:  0.33315662
Encoder Loss:  0.04012636  || Decoder Loss:  0.03363577 Validation Decoder Loss:  0.33324587
Encoder Loss:  0.040075146  || Decoder Loss:  0.03354996 Validation Decoder Loss:  0.33530855
Encoder Loss:  0.040057093  || Decoder Loss:  0.033521455 Validation Decoder Loss:  0.334145
Encoder Loss:  0.040202323  || Decoder Loss:  0.033759065 Validation Decoder Loss:  0.3294088
Encoder Loss:  0.04012406  || Decoder Loss:  0.033631776 Validation Decoder Loss:  0.329869
Encoder Loss:  0.040086173  || Decoder Loss:  0.0335673 Validation Decoder Loss:  0.33480513
Encoder Loss:  0.040236417  || Decoder Loss:  0.03381573 Validation Decoder Loss:  0.3289964
Encoder Loss:  0.23501763  || Decoder Loss:  0.35639995 Validation Decoder Loss:  0.3884008
Encoder Loss:  0.33272672  || Decoder Loss:  0.51834327 Validation Decoder Loss:  1.0233889
Encoder Loss:  0.31933346  || Decoder Loss:  0.49623066 Validation Decoder Loss:  1.0140591
Encoder Loss:  0.31868866  || Decoder Loss:  0.49516374 Validation Decoder Loss:  1.0153861
Encoder Loss:  0.31816307  || Decoder Loss:  0.4942933 Validation Decoder Loss:  1.0168697
Encoder Loss:  0.3184909  || Decoder Loss:  0.49483672 Validation Decoder Loss:  1.0168128
Encoder Loss:  0.31927833  || Decoder Loss:  0.49613875 Validation Decoder Loss:  1.0153185
Encoder Loss:  0.3184817  || Decoder Loss:  0.49481973 Validation Decoder Loss:  1.014218
Model: siamese_net_lr_0.9889164034268162 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 1.014218
Model: "sequential_708"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_312 (Conv2D)          (None, 2300, 20, 1)       309       
_________________________________________________________________
dropout_890 (Dropout)        (None, 2300, 20, 1)       0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 2220, 20, 1)       82        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_709"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_312 (Conv2D (None, 2540, 20, 1)       322       
_________________________________________________________________
dropout_892 (Dropout)        (None, 2540, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_313 (Conv2D (None, 2607, 20, 1)       69        
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_710"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_transpose_347 (Conv3D (None, 73, 30, 20, 1)     181       
_________________________________________________________________
dropout_894 (Dropout)        (None, 73, 30, 20, 1)     0         
_________________________________________________________________
conv3d_transpose_348 (Conv3D (None, 74, 30, 20, 1)     3         
_________________________________________________________________
reshape_186 (Reshape)        (None, 2220, 20, 1)       0         
=================================================================
Total params: 184
Trainable params: 184
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_712"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_314 (Conv2D)          (None, 2390, 20, 1)       219       
_________________________________________________________________
dropout_896 (Dropout)        (None, 2390, 20, 1)       0         
_________________________________________________________________
conv2d_315 (Conv2D)          (None, 2220, 20, 1)       172       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_713"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_transpose_314 (Conv2D (None, 2390, 20, 1)       172       
_________________________________________________________________
dropout_898 (Dropout)        (None, 2390, 20, 1)       0         
_________________________________________________________________
conv2d_transpose_315 (Conv2D (None, 2607, 20, 1)       219       
=================================================================
Total params: 391
Trainable params: 391
Non-trainable params: 0
_________________________________________________________________
None
Starting training
Encoder Loss:  0.19722293  || Decoder Loss:  0.12773402 Validation Decoder Loss:  0.38279405
Encoder Loss:  0.15561342  || Decoder Loss:  0.06035501 Validation Decoder Loss:  0.38931215
Encoder Loss:  0.25220424  || Decoder Loss:  0.22467087 Validation Decoder Loss:  0.8037857
Encoder Loss:  0.3810162  || Decoder Loss:  0.460958 Validation Decoder Loss:  1.2743038
Encoder Loss:  0.3939572  || Decoder Loss:  0.48817822 Validation Decoder Loss:  1.277938
Encoder Loss:  0.3938546  || Decoder Loss:  0.48053467 Validation Decoder Loss:  1.0248361
Encoder Loss:  0.38125482  || Decoder Loss:  0.47063997 Validation Decoder Loss:  1.0828933
Encoder Loss:  0.3735901  || Decoder Loss:  0.462312 Validation Decoder Loss:  1.0095611
Encoder Loss:  0.35364252  || Decoder Loss:  0.4412267 Validation Decoder Loss:  1.1285026
Encoder Loss:  0.35779884  || Decoder Loss:  0.44357717 Validation Decoder Loss:  1.1648145
Encoder Loss:  0.39624768  || Decoder Loss:  0.48887718 Validation Decoder Loss:  1.1552088
Encoder Loss:  0.37672442  || Decoder Loss:  0.4654761 Validation Decoder Loss:  1.0016286
Encoder Loss:  0.34328344  || Decoder Loss:  0.42768955 Validation Decoder Loss:  1.1053419
Encoder Loss:  0.3475863  || Decoder Loss:  0.43180278 Validation Decoder Loss:  1.0875043
Encoder Loss:  0.35037008  || Decoder Loss:  0.4349786 Validation Decoder Loss:  1.0197908
Encoder Loss:  0.34216782  || Decoder Loss:  0.42714354 Validation Decoder Loss:  1.1222228
Encoder Loss:  0.3604482  || Decoder Loss:  0.44778836 Validation Decoder Loss:  1.0149574
Encoder Loss:  0.34234664  || Decoder Loss:  0.42595163 Validation Decoder Loss:  1.1802014
Encoder Loss:  0.3855724  || Decoder Loss:  0.47827655 Validation Decoder Loss:  1.2142005
Encoder Loss:  0.37407792  || Decoder Loss:  0.46371782 Validation Decoder Loss:  1.0994295
Encoder Loss:  0.3567929  || Decoder Loss:  0.44402358 Validation Decoder Loss:  1.0032313
Encoder Loss:  0.33648443  || Decoder Loss:  0.41987324 Validation Decoder Loss:  1.1539338
Encoder Loss:  0.36377618  || Decoder Loss:  0.4536945 Validation Decoder Loss:  1.0698957
Encoder Loss:  0.34485054  || Decoder Loss:  0.43009886 Validation Decoder Loss:  1.0744474
Encoder Loss:  0.33986285  || Decoder Loss:  0.42460984 Validation Decoder Loss:  1.0623176
Encoder Loss:  0.33960307  || Decoder Loss:  0.42441067 Validation Decoder Loss:  1.0395197
Encoder Loss:  0.33075234  || Decoder Loss:  0.41329274 Validation Decoder Loss:  1.071821
Encoder Loss:  0.34380025  || Decoder Loss:  0.4298517 Validation Decoder Loss:  0.9709501
Encoder Loss:  0.31822017  || Decoder Loss:  0.3981983 Validation Decoder Loss:  0.9851863
Encoder Loss:  0.39994577  || Decoder Loss:  0.50502837 Validation Decoder Loss:  0.90204823
Encoder Loss:  0.41590354  || Decoder Loss:  0.5292541 Validation Decoder Loss:  0.7715463
Encoder Loss:  0.40744445  || Decoder Loss:  0.51637304 Validation Decoder Loss:  0.93566716
Encoder Loss:  0.4139835  || Decoder Loss:  0.528332 Validation Decoder Loss:  0.71574605
Encoder Loss:  0.3890025  || Decoder Loss:  0.49153927 Validation Decoder Loss:  0.8569926
Encoder Loss:  0.40538523  || Decoder Loss:  0.5154576 Validation Decoder Loss:  0.7799186
Encoder Loss:  0.39695504  || Decoder Loss:  0.5047891 Validation Decoder Loss:  0.74149644
Encoder Loss:  0.37363532  || Decoder Loss:  0.4727569 Validation Decoder Loss:  0.92365384
Encoder Loss:  0.34839547  || Decoder Loss:  0.44237453 Validation Decoder Loss:  1.193032
Encoder Loss:  0.34907892  || Decoder Loss:  0.44135615 Validation Decoder Loss:  1.2066071
Encoder Loss:  0.34950078  || Decoder Loss:  0.44210532 Validation Decoder Loss:  0.9898387
Model: siamese_net_lr_0.8540505517513644 Train Intances: 1600 | Validation Instances: 64 | Validation Loss: 0.9898387
Optimizing at level  3
FINISHED NAS
best_loss, best_depth 0.31570756435394287 2
[(74, 30, 20, 1)] [(2220, 20, 1)]
[(2220, 20, 1)] [(2220, 20, 1)]
[(2607, 20, 1)] [(2220, 20, 1)]
